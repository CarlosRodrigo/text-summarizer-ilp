<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="FT943-12341">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>Some 160km west of Tokyo in Japan&amp;apost;s coastal Tokai region is what may be the world&amp;apost;s most dense array of geophysical instruments.</content>
      <tokens>
        <token id="1" string="Some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="160km" lemma="160km" stem="160km" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="west" lemma="west" stem="west" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Tokyo" lemma="Tokyo" stem="tokyo" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="6" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="Japan" lemma="Japan" stem="japan" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="8" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="coastal" lemma="coastal" stem="coastal" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="Tokai" lemma="Tokai" stem="tokai" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="11" string="region" lemma="region" stem="region" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="may" lemma="may" stem="mai" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="most" lemma="most" stem="most" pos="RBS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="dense" lemma="dense" stem="dens" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="array" lemma="array" stem="arrai" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="geophysical" lemma="geophysical" stem="geophys" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="instruments" lemma="instrument" stem="instrument" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT Some) (NN 160km) (NN west)) (PP (IN of) (NP (NP (NNP Tokyo)) (PP (IN in) (NP (NP (NNP Japan) (POS 's)) (JJ coastal) (NNP Tokai) (NN region)))))) (VP (VBZ is) (SBAR (WHNP (WP what)) (S (VP (MD may) (VP (VB be) (NP (NP (NP (DT the) (NN world) (POS 's)) (RBS most) (JJ dense) (NN array)) (PP (IN of) (NP (JJ geophysical) (NNS instruments))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="be the world 's most dense array of geophysical instruments" type="VP">
          <tokens>
            <token id="15" string="be" />
            <token id="16" string="the" />
            <token id="17" string="world" />
            <token id="18" string="'s" />
            <token id="19" string="most" />
            <token id="20" string="dense" />
            <token id="21" string="array" />
            <token id="22" string="of" />
            <token id="23" string="geophysical" />
            <token id="24" string="instruments" />
          </tokens>
        </chunking>
        <chunking id="2" string="is what may be the world 's most dense array of geophysical instruments" type="VP">
          <tokens>
            <token id="12" string="is" />
            <token id="13" string="what" />
            <token id="14" string="may" />
            <token id="15" string="be" />
            <token id="16" string="the" />
            <token id="17" string="world" />
            <token id="18" string="'s" />
            <token id="19" string="most" />
            <token id="20" string="dense" />
            <token id="21" string="array" />
            <token id="22" string="of" />
            <token id="23" string="geophysical" />
            <token id="24" string="instruments" />
          </tokens>
        </chunking>
        <chunking id="3" string="geophysical instruments" type="NP">
          <tokens>
            <token id="23" string="geophysical" />
            <token id="24" string="instruments" />
          </tokens>
        </chunking>
        <chunking id="4" string="Japan 's coastal Tokai region" type="NP">
          <tokens>
            <token id="7" string="Japan" />
            <token id="8" string="'s" />
            <token id="9" string="coastal" />
            <token id="10" string="Tokai" />
            <token id="11" string="region" />
          </tokens>
        </chunking>
        <chunking id="5" string="Some 160km west of Tokyo in Japan 's coastal Tokai region" type="NP">
          <tokens>
            <token id="1" string="Some" />
            <token id="2" string="160km" />
            <token id="3" string="west" />
            <token id="4" string="of" />
            <token id="5" string="Tokyo" />
            <token id="6" string="in" />
            <token id="7" string="Japan" />
            <token id="8" string="'s" />
            <token id="9" string="coastal" />
            <token id="10" string="Tokai" />
            <token id="11" string="region" />
          </tokens>
        </chunking>
        <chunking id="6" string="may be the world 's most dense array of geophysical instruments" type="VP">
          <tokens>
            <token id="14" string="may" />
            <token id="15" string="be" />
            <token id="16" string="the" />
            <token id="17" string="world" />
            <token id="18" string="'s" />
            <token id="19" string="most" />
            <token id="20" string="dense" />
            <token id="21" string="array" />
            <token id="22" string="of" />
            <token id="23" string="geophysical" />
            <token id="24" string="instruments" />
          </tokens>
        </chunking>
        <chunking id="7" string="Tokyo" type="NP">
          <tokens>
            <token id="5" string="Tokyo" />
          </tokens>
        </chunking>
        <chunking id="8" string="what may be the world 's most dense array of geophysical instruments" type="SBAR">
          <tokens>
            <token id="13" string="what" />
            <token id="14" string="may" />
            <token id="15" string="be" />
            <token id="16" string="the" />
            <token id="17" string="world" />
            <token id="18" string="'s" />
            <token id="19" string="most" />
            <token id="20" string="dense" />
            <token id="21" string="array" />
            <token id="22" string="of" />
            <token id="23" string="geophysical" />
            <token id="24" string="instruments" />
          </tokens>
        </chunking>
        <chunking id="9" string="the world 's most dense array of geophysical instruments" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="world" />
            <token id="18" string="'s" />
            <token id="19" string="most" />
            <token id="20" string="dense" />
            <token id="21" string="array" />
            <token id="22" string="of" />
            <token id="23" string="geophysical" />
            <token id="24" string="instruments" />
          </tokens>
        </chunking>
        <chunking id="10" string="the world 's most dense array" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="world" />
            <token id="18" string="'s" />
            <token id="19" string="most" />
            <token id="20" string="dense" />
            <token id="21" string="array" />
          </tokens>
        </chunking>
        <chunking id="11" string="Tokyo in Japan 's coastal Tokai region" type="NP">
          <tokens>
            <token id="5" string="Tokyo" />
            <token id="6" string="in" />
            <token id="7" string="Japan" />
            <token id="8" string="'s" />
            <token id="9" string="coastal" />
            <token id="10" string="Tokai" />
            <token id="11" string="region" />
          </tokens>
        </chunking>
        <chunking id="12" string="Some 160km west" type="NP">
          <tokens>
            <token id="1" string="Some" />
            <token id="2" string="160km" />
            <token id="3" string="west" />
          </tokens>
        </chunking>
        <chunking id="13" string="Japan 's" type="NP">
          <tokens>
            <token id="7" string="Japan" />
            <token id="8" string="'s" />
          </tokens>
        </chunking>
        <chunking id="14" string="the world 's" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="world" />
            <token id="18" string="'s" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">west</governor>
          <dependent id="1">Some</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">west</governor>
          <dependent id="2">160km</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">is</governor>
          <dependent id="3">west</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">Tokyo</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">west</governor>
          <dependent id="5">Tokyo</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">region</governor>
          <dependent id="6">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">region</governor>
          <dependent id="7">Japan</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">Japan</governor>
          <dependent id="8">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">region</governor>
          <dependent id="9">coastal</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">region</governor>
          <dependent id="10">Tokai</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">Tokyo</governor>
          <dependent id="11">region</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">is</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">array</governor>
          <dependent id="13">what</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="21">array</governor>
          <dependent id="14">may</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="21">array</governor>
          <dependent id="15">be</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">world</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="21">array</governor>
          <dependent id="17">world</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">world</governor>
          <dependent id="18">'s</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="21">array</governor>
          <dependent id="19">most</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">array</governor>
          <dependent id="20">dense</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="12">is</governor>
          <dependent id="21">array</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">instruments</governor>
          <dependent id="22">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">instruments</governor>
          <dependent id="23">geophysical</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">array</governor>
          <dependent id="24">instruments</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Tokai" type="LOCATION" score="0.0">
          <tokens>
            <token id="10" string="Tokai" />
          </tokens>
        </entity>
        <entity id="2" string="Japan" type="LOCATION" score="0.0">
          <tokens>
            <token id="7" string="Japan" />
          </tokens>
        </entity>
        <entity id="3" string="Tokyo" type="LOCATION" score="0.0">
          <tokens>
            <token id="5" string="Tokyo" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="false">
      <content>More than 150 meters and gauges track seismic activity, rock strain, crustal tilt, tidal movements and ground water levels.</content>
      <tokens>
        <token id="1" string="More" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="150" lemma="150" stem="150" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="4" string="meters" lemma="meter" stem="meter" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="gauges" lemma="gauge" stem="gaug" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="track" lemma="track" stem="track" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="seismic" lemma="seismic" stem="seismic" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="activity" lemma="activity" stem="activ" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="rock" lemma="rock" stem="rock" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="strain" lemma="strain" stem="strain" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="crustal" lemma="crustal" stem="crustal" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="tilt" lemma="tilt" stem="tilt" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="tidal" lemma="tidal" stem="tidal" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="movements" lemma="movement" stem="movement" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="ground" lemma="ground" stem="ground" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="water" lemma="water" stem="water" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="levels" lemma="level" stem="level" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (QP (JJR More) (IN than) (CD 150)) (NX (NX (NNS meters)) (CC and))) (VP (VBZ gauges) (NP (NP (NN track) (JJ seismic) (NN activity)) (, ,) (NP (NN rock) (NN strain)) (, ,) (NP (JJ crustal) (NN tilt)) (, ,) (NP (JJ tidal) (NNS movements)) (CC and) (NP (NN ground) (NN water) (NNS levels)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="track seismic activity , rock strain , crustal tilt , tidal movements and ground water levels" type="NP">
          <tokens>
            <token id="7" string="track" />
            <token id="8" string="seismic" />
            <token id="9" string="activity" />
            <token id="10" string="," />
            <token id="11" string="rock" />
            <token id="12" string="strain" />
            <token id="13" string="," />
            <token id="14" string="crustal" />
            <token id="15" string="tilt" />
            <token id="16" string="," />
            <token id="17" string="tidal" />
            <token id="18" string="movements" />
            <token id="19" string="and" />
            <token id="20" string="ground" />
            <token id="21" string="water" />
            <token id="22" string="levels" />
          </tokens>
        </chunking>
        <chunking id="2" string="gauges track seismic activity , rock strain , crustal tilt , tidal movements and ground water levels" type="VP">
          <tokens>
            <token id="6" string="gauges" />
            <token id="7" string="track" />
            <token id="8" string="seismic" />
            <token id="9" string="activity" />
            <token id="10" string="," />
            <token id="11" string="rock" />
            <token id="12" string="strain" />
            <token id="13" string="," />
            <token id="14" string="crustal" />
            <token id="15" string="tilt" />
            <token id="16" string="," />
            <token id="17" string="tidal" />
            <token id="18" string="movements" />
            <token id="19" string="and" />
            <token id="20" string="ground" />
            <token id="21" string="water" />
            <token id="22" string="levels" />
          </tokens>
        </chunking>
        <chunking id="3" string="ground water levels" type="NP">
          <tokens>
            <token id="20" string="ground" />
            <token id="21" string="water" />
            <token id="22" string="levels" />
          </tokens>
        </chunking>
        <chunking id="4" string="tidal movements" type="NP">
          <tokens>
            <token id="17" string="tidal" />
            <token id="18" string="movements" />
          </tokens>
        </chunking>
        <chunking id="5" string="track seismic activity" type="NP">
          <tokens>
            <token id="7" string="track" />
            <token id="8" string="seismic" />
            <token id="9" string="activity" />
          </tokens>
        </chunking>
        <chunking id="6" string="crustal tilt" type="NP">
          <tokens>
            <token id="14" string="crustal" />
            <token id="15" string="tilt" />
          </tokens>
        </chunking>
        <chunking id="7" string="More than 150 meters and" type="NP">
          <tokens>
            <token id="1" string="More" />
            <token id="2" string="than" />
            <token id="3" string="150" />
            <token id="4" string="meters" />
            <token id="5" string="and" />
          </tokens>
        </chunking>
        <chunking id="8" string="rock strain" type="NP">
          <tokens>
            <token id="11" string="rock" />
            <token id="12" string="strain" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="3">150</governor>
          <dependent id="1">More</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="1">More</governor>
          <dependent id="2">than</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="4">meters</governor>
          <dependent id="3">150</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">gauges</governor>
          <dependent id="4">meters</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">meters</governor>
          <dependent id="5">and</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">gauges</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">activity</governor>
          <dependent id="7">track</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">activity</governor>
          <dependent id="8">seismic</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">gauges</governor>
          <dependent id="9">activity</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">strain</governor>
          <dependent id="11">rock</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">activity</governor>
          <dependent id="12">strain</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">tilt</governor>
          <dependent id="14">crustal</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">activity</governor>
          <dependent id="15">tilt</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">movements</governor>
          <dependent id="17">tidal</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">activity</governor>
          <dependent id="18">movements</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">activity</governor>
          <dependent id="19">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">levels</governor>
          <dependent id="20">ground</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">levels</governor>
          <dependent id="21">water</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">activity</governor>
          <dependent id="22">levels</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="150" type="NUMBER" score="0.0">
          <tokens>
            <token id="3" string="150" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>The data are telemetered to Tokyo where they are monitored around the clock in the hope that six experts, to be summoned at a moment&amp;apost;s notice, will recognise unusual phenomena that may indicate an imminent earthquake.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="data" lemma="datum" stem="data" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="telemetered" lemma="telemeter" stem="telemet" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Tokyo" lemma="Tokyo" stem="tokyo" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="7" string="where" lemma="where" stem="where" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="monitored" lemma="monitor" stem="monitor" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="around" lemma="around" stem="around" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="clock" lemma="clock" stem="clock" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="hope" lemma="hope" stem="hope" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="six" lemma="six" stem="six" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="true" />
        <token id="19" string="experts" lemma="expert" stem="expert" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="summoned" lemma="summon" stem="summon" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="moment" lemma="moment" stem="moment" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="notice" lemma="notice" stem="notic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="recognise" lemma="recognise" stem="recognis" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="unusual" lemma="unusual" stem="unusu" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="phenomena" lemma="phenomenon" stem="phenomena" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="may" lemma="may" stem="mai" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="indicate" lemma="indicate" stem="indic" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="imminent" lemma="imminent" stem="immin" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="earthquake" lemma="earthquake" stem="earthquak" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="40" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NNS data)) (VP (VBP are) (VP (VBN telemetered) (PP (TO to) (NP (NNP Tokyo))) (SBAR (WHADVP (WRB where)) (S (NP (PRP they)) (VP (VBP are) (VP (VBN monitored) (PP (IN around) (NP (NP (DT the) (NN clock)) (PP (IN in) (NP (DT the) (NN hope))))) (SBAR (IN that) (S (NP (CD six) (NNS experts)) (, ,) (S (VP (TO to) (VP (VB be) (VP (VBN summoned) (PP (IN at) (NP (NP (DT a) (NN moment) (POS 's)) (NN notice))))))) (, ,) (VP (MD will) (VP (VB recognise) (NP (NP (JJ unusual) (NNS phenomena)) (SBAR (WHNP (WDT that)) (S (VP (MD may) (VP (VB indicate) (NP (DT an) (JJ imminent) (NN earthquake))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a moment 's notice" type="NP">
          <tokens>
            <token id="25" string="a" />
            <token id="26" string="moment" />
            <token id="27" string="'s" />
            <token id="28" string="notice" />
          </tokens>
        </chunking>
        <chunking id="2" string="recognise unusual phenomena that may indicate an imminent earthquake" type="VP">
          <tokens>
            <token id="31" string="recognise" />
            <token id="32" string="unusual" />
            <token id="33" string="phenomena" />
            <token id="34" string="that" />
            <token id="35" string="may" />
            <token id="36" string="indicate" />
            <token id="37" string="an" />
            <token id="38" string="imminent" />
            <token id="39" string="earthquake" />
          </tokens>
        </chunking>
        <chunking id="3" string="monitored around the clock in the hope that six experts , to be summoned at a moment 's notice , will recognise unusual phenomena that may indicate an imminent earthquake" type="VP">
          <tokens>
            <token id="10" string="monitored" />
            <token id="11" string="around" />
            <token id="12" string="the" />
            <token id="13" string="clock" />
            <token id="14" string="in" />
            <token id="15" string="the" />
            <token id="16" string="hope" />
            <token id="17" string="that" />
            <token id="18" string="six" />
            <token id="19" string="experts" />
            <token id="20" string="," />
            <token id="21" string="to" />
            <token id="22" string="be" />
            <token id="23" string="summoned" />
            <token id="24" string="at" />
            <token id="25" string="a" />
            <token id="26" string="moment" />
            <token id="27" string="'s" />
            <token id="28" string="notice" />
            <token id="29" string="," />
            <token id="30" string="will" />
            <token id="31" string="recognise" />
            <token id="32" string="unusual" />
            <token id="33" string="phenomena" />
            <token id="34" string="that" />
            <token id="35" string="may" />
            <token id="36" string="indicate" />
            <token id="37" string="an" />
            <token id="38" string="imminent" />
            <token id="39" string="earthquake" />
          </tokens>
        </chunking>
        <chunking id="4" string="The data" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="data" />
          </tokens>
        </chunking>
        <chunking id="5" string="a moment 's" type="NP">
          <tokens>
            <token id="25" string="a" />
            <token id="26" string="moment" />
            <token id="27" string="'s" />
          </tokens>
        </chunking>
        <chunking id="6" string="be summoned at a moment 's notice" type="VP">
          <tokens>
            <token id="22" string="be" />
            <token id="23" string="summoned" />
            <token id="24" string="at" />
            <token id="25" string="a" />
            <token id="26" string="moment" />
            <token id="27" string="'s" />
            <token id="28" string="notice" />
          </tokens>
        </chunking>
        <chunking id="7" string="indicate an imminent earthquake" type="VP">
          <tokens>
            <token id="36" string="indicate" />
            <token id="37" string="an" />
            <token id="38" string="imminent" />
            <token id="39" string="earthquake" />
          </tokens>
        </chunking>
        <chunking id="8" string="unusual phenomena" type="NP">
          <tokens>
            <token id="32" string="unusual" />
            <token id="33" string="phenomena" />
          </tokens>
        </chunking>
        <chunking id="9" string="telemetered to Tokyo where they are monitored around the clock in the hope that six experts , to be summoned at a moment 's notice , will recognise unusual phenomena that may indicate an imminent earthquake" type="VP">
          <tokens>
            <token id="4" string="telemetered" />
            <token id="5" string="to" />
            <token id="6" string="Tokyo" />
            <token id="7" string="where" />
            <token id="8" string="they" />
            <token id="9" string="are" />
            <token id="10" string="monitored" />
            <token id="11" string="around" />
            <token id="12" string="the" />
            <token id="13" string="clock" />
            <token id="14" string="in" />
            <token id="15" string="the" />
            <token id="16" string="hope" />
            <token id="17" string="that" />
            <token id="18" string="six" />
            <token id="19" string="experts" />
            <token id="20" string="," />
            <token id="21" string="to" />
            <token id="22" string="be" />
            <token id="23" string="summoned" />
            <token id="24" string="at" />
            <token id="25" string="a" />
            <token id="26" string="moment" />
            <token id="27" string="'s" />
            <token id="28" string="notice" />
            <token id="29" string="," />
            <token id="30" string="will" />
            <token id="31" string="recognise" />
            <token id="32" string="unusual" />
            <token id="33" string="phenomena" />
            <token id="34" string="that" />
            <token id="35" string="may" />
            <token id="36" string="indicate" />
            <token id="37" string="an" />
            <token id="38" string="imminent" />
            <token id="39" string="earthquake" />
          </tokens>
        </chunking>
        <chunking id="10" string="that six experts , to be summoned at a moment 's notice , will recognise unusual phenomena that may indicate an imminent earthquake" type="SBAR">
          <tokens>
            <token id="17" string="that" />
            <token id="18" string="six" />
            <token id="19" string="experts" />
            <token id="20" string="," />
            <token id="21" string="to" />
            <token id="22" string="be" />
            <token id="23" string="summoned" />
            <token id="24" string="at" />
            <token id="25" string="a" />
            <token id="26" string="moment" />
            <token id="27" string="'s" />
            <token id="28" string="notice" />
            <token id="29" string="," />
            <token id="30" string="will" />
            <token id="31" string="recognise" />
            <token id="32" string="unusual" />
            <token id="33" string="phenomena" />
            <token id="34" string="that" />
            <token id="35" string="may" />
            <token id="36" string="indicate" />
            <token id="37" string="an" />
            <token id="38" string="imminent" />
            <token id="39" string="earthquake" />
          </tokens>
        </chunking>
        <chunking id="11" string="where they are monitored around the clock in the hope that six experts , to be summoned at a moment 's notice , will recognise unusual phenomena that may indicate an imminent earthquake" type="SBAR">
          <tokens>
            <token id="7" string="where" />
            <token id="8" string="they" />
            <token id="9" string="are" />
            <token id="10" string="monitored" />
            <token id="11" string="around" />
            <token id="12" string="the" />
            <token id="13" string="clock" />
            <token id="14" string="in" />
            <token id="15" string="the" />
            <token id="16" string="hope" />
            <token id="17" string="that" />
            <token id="18" string="six" />
            <token id="19" string="experts" />
            <token id="20" string="," />
            <token id="21" string="to" />
            <token id="22" string="be" />
            <token id="23" string="summoned" />
            <token id="24" string="at" />
            <token id="25" string="a" />
            <token id="26" string="moment" />
            <token id="27" string="'s" />
            <token id="28" string="notice" />
            <token id="29" string="," />
            <token id="30" string="will" />
            <token id="31" string="recognise" />
            <token id="32" string="unusual" />
            <token id="33" string="phenomena" />
            <token id="34" string="that" />
            <token id="35" string="may" />
            <token id="36" string="indicate" />
            <token id="37" string="an" />
            <token id="38" string="imminent" />
            <token id="39" string="earthquake" />
          </tokens>
        </chunking>
        <chunking id="12" string="summoned at a moment 's notice" type="VP">
          <tokens>
            <token id="23" string="summoned" />
            <token id="24" string="at" />
            <token id="25" string="a" />
            <token id="26" string="moment" />
            <token id="27" string="'s" />
            <token id="28" string="notice" />
          </tokens>
        </chunking>
        <chunking id="13" string="six experts" type="NP">
          <tokens>
            <token id="18" string="six" />
            <token id="19" string="experts" />
          </tokens>
        </chunking>
        <chunking id="14" string="the clock in the hope" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="clock" />
            <token id="14" string="in" />
            <token id="15" string="the" />
            <token id="16" string="hope" />
          </tokens>
        </chunking>
        <chunking id="15" string="are telemetered to Tokyo where they are monitored around the clock in the hope that six experts , to be summoned at a moment 's notice , will recognise unusual phenomena that may indicate an imminent earthquake" type="VP">
          <tokens>
            <token id="3" string="are" />
            <token id="4" string="telemetered" />
            <token id="5" string="to" />
            <token id="6" string="Tokyo" />
            <token id="7" string="where" />
            <token id="8" string="they" />
            <token id="9" string="are" />
            <token id="10" string="monitored" />
            <token id="11" string="around" />
            <token id="12" string="the" />
            <token id="13" string="clock" />
            <token id="14" string="in" />
            <token id="15" string="the" />
            <token id="16" string="hope" />
            <token id="17" string="that" />
            <token id="18" string="six" />
            <token id="19" string="experts" />
            <token id="20" string="," />
            <token id="21" string="to" />
            <token id="22" string="be" />
            <token id="23" string="summoned" />
            <token id="24" string="at" />
            <token id="25" string="a" />
            <token id="26" string="moment" />
            <token id="27" string="'s" />
            <token id="28" string="notice" />
            <token id="29" string="," />
            <token id="30" string="will" />
            <token id="31" string="recognise" />
            <token id="32" string="unusual" />
            <token id="33" string="phenomena" />
            <token id="34" string="that" />
            <token id="35" string="may" />
            <token id="36" string="indicate" />
            <token id="37" string="an" />
            <token id="38" string="imminent" />
            <token id="39" string="earthquake" />
          </tokens>
        </chunking>
        <chunking id="16" string="an imminent earthquake" type="NP">
          <tokens>
            <token id="37" string="an" />
            <token id="38" string="imminent" />
            <token id="39" string="earthquake" />
          </tokens>
        </chunking>
        <chunking id="17" string="are monitored around the clock in the hope that six experts , to be summoned at a moment 's notice , will recognise unusual phenomena that may indicate an imminent earthquake" type="VP">
          <tokens>
            <token id="9" string="are" />
            <token id="10" string="monitored" />
            <token id="11" string="around" />
            <token id="12" string="the" />
            <token id="13" string="clock" />
            <token id="14" string="in" />
            <token id="15" string="the" />
            <token id="16" string="hope" />
            <token id="17" string="that" />
            <token id="18" string="six" />
            <token id="19" string="experts" />
            <token id="20" string="," />
            <token id="21" string="to" />
            <token id="22" string="be" />
            <token id="23" string="summoned" />
            <token id="24" string="at" />
            <token id="25" string="a" />
            <token id="26" string="moment" />
            <token id="27" string="'s" />
            <token id="28" string="notice" />
            <token id="29" string="," />
            <token id="30" string="will" />
            <token id="31" string="recognise" />
            <token id="32" string="unusual" />
            <token id="33" string="phenomena" />
            <token id="34" string="that" />
            <token id="35" string="may" />
            <token id="36" string="indicate" />
            <token id="37" string="an" />
            <token id="38" string="imminent" />
            <token id="39" string="earthquake" />
          </tokens>
        </chunking>
        <chunking id="18" string="may indicate an imminent earthquake" type="VP">
          <tokens>
            <token id="35" string="may" />
            <token id="36" string="indicate" />
            <token id="37" string="an" />
            <token id="38" string="imminent" />
            <token id="39" string="earthquake" />
          </tokens>
        </chunking>
        <chunking id="19" string="the clock" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="clock" />
          </tokens>
        </chunking>
        <chunking id="20" string="that may indicate an imminent earthquake" type="SBAR">
          <tokens>
            <token id="34" string="that" />
            <token id="35" string="may" />
            <token id="36" string="indicate" />
            <token id="37" string="an" />
            <token id="38" string="imminent" />
            <token id="39" string="earthquake" />
          </tokens>
        </chunking>
        <chunking id="21" string="will recognise unusual phenomena that may indicate an imminent earthquake" type="VP">
          <tokens>
            <token id="30" string="will" />
            <token id="31" string="recognise" />
            <token id="32" string="unusual" />
            <token id="33" string="phenomena" />
            <token id="34" string="that" />
            <token id="35" string="may" />
            <token id="36" string="indicate" />
            <token id="37" string="an" />
            <token id="38" string="imminent" />
            <token id="39" string="earthquake" />
          </tokens>
        </chunking>
        <chunking id="22" string="they" type="NP">
          <tokens>
            <token id="8" string="they" />
          </tokens>
        </chunking>
        <chunking id="23" string="unusual phenomena that may indicate an imminent earthquake" type="NP">
          <tokens>
            <token id="32" string="unusual" />
            <token id="33" string="phenomena" />
            <token id="34" string="that" />
            <token id="35" string="may" />
            <token id="36" string="indicate" />
            <token id="37" string="an" />
            <token id="38" string="imminent" />
            <token id="39" string="earthquake" />
          </tokens>
        </chunking>
        <chunking id="24" string="Tokyo" type="NP">
          <tokens>
            <token id="6" string="Tokyo" />
          </tokens>
        </chunking>
        <chunking id="25" string="to be summoned at a moment 's notice" type="VP">
          <tokens>
            <token id="21" string="to" />
            <token id="22" string="be" />
            <token id="23" string="summoned" />
            <token id="24" string="at" />
            <token id="25" string="a" />
            <token id="26" string="moment" />
            <token id="27" string="'s" />
            <token id="28" string="notice" />
          </tokens>
        </chunking>
        <chunking id="26" string="the hope" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="hope" />
          </tokens>
        </chunking>
        <chunking id="27" string="where" type="WHADVP">
          <tokens>
            <token id="7" string="where" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">data</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="4">telemetered</governor>
          <dependent id="2">data</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="4">telemetered</governor>
          <dependent id="3">are</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">telemetered</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">Tokyo</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">telemetered</governor>
          <dependent id="6">Tokyo</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">monitored</governor>
          <dependent id="7">where</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="10">monitored</governor>
          <dependent id="8">they</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="10">monitored</governor>
          <dependent id="9">are</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">telemetered</governor>
          <dependent id="10">monitored</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">clock</governor>
          <dependent id="11">around</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">clock</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">monitored</governor>
          <dependent id="13">clock</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">hope</governor>
          <dependent id="14">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">hope</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">clock</governor>
          <dependent id="16">hope</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="31">recognise</governor>
          <dependent id="17">that</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="19">experts</governor>
          <dependent id="18">six</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="31">recognise</governor>
          <dependent id="19">experts</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="23">summoned</governor>
          <dependent id="21">to</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="23">summoned</governor>
          <dependent id="22">be</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="31">recognise</governor>
          <dependent id="23">summoned</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">notice</governor>
          <dependent id="24">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">moment</governor>
          <dependent id="25">a</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="28">notice</governor>
          <dependent id="26">moment</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">moment</governor>
          <dependent id="27">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">summoned</governor>
          <dependent id="28">notice</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="31">recognise</governor>
          <dependent id="30">will</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">monitored</governor>
          <dependent id="31">recognise</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="33">phenomena</governor>
          <dependent id="32">unusual</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="31">recognise</governor>
          <dependent id="33">phenomena</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="36">indicate</governor>
          <dependent id="34">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="36">indicate</governor>
          <dependent id="35">may</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="33">phenomena</governor>
          <dependent id="36">indicate</dependent>
        </dependency>
        <dependency type="det">
          <governor id="39">earthquake</governor>
          <dependent id="37">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="39">earthquake</governor>
          <dependent id="38">imminent</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="36">indicate</governor>
          <dependent id="39">earthquake</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="six" type="NUMBER" score="0.0">
          <tokens>
            <token id="18" string="six" />
          </tokens>
        </entity>
        <entity id="2" string="Tokyo" type="LOCATION" score="0.0">
          <tokens>
            <token id="6" string="Tokyo" />
          </tokens>
        </entity>
        <entity id="3" string="earthquake" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="39" string="earthquake" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>If the committee so advises, Japan&amp;apost;s prime minister will issue an earthquake warning for the Tokai area.</content>
      <tokens>
        <token id="1" string="If" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="committee" lemma="committee" stem="committe" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="so" lemma="so" stem="so" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="advises" lemma="advise" stem="advis" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Japan" lemma="Japan" stem="japan" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="8" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="prime" lemma="prime" stem="prime" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="minister" lemma="minister" stem="minist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="issue" lemma="issue" stem="issu" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="earthquake" lemma="earthquake" stem="earthquak" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="15" string="warning" lemma="warn" stem="warn" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="Tokai" lemma="Tokai" stem="tokai" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="19" string="area" lemma="area" stem="area" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN If) (S (NP (DT the) (NN committee)) (ADVP (RB so)) (VP (VBZ advises)))) (, ,) (NP (NP (NNP Japan) (POS 's)) (JJ prime) (NN minister)) (VP (MD will) (VP (VB issue) (NP (NP (DT an) (NN earthquake)) (VP (VBG warning) (PP (IN for) (NP (DT the) (NNP Tokai) (NN area))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the Tokai area" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="Tokai" />
            <token id="19" string="area" />
          </tokens>
        </chunking>
        <chunking id="2" string="Japan 's prime minister" type="NP">
          <tokens>
            <token id="7" string="Japan" />
            <token id="8" string="'s" />
            <token id="9" string="prime" />
            <token id="10" string="minister" />
          </tokens>
        </chunking>
        <chunking id="3" string="issue an earthquake warning for the Tokai area" type="VP">
          <tokens>
            <token id="12" string="issue" />
            <token id="13" string="an" />
            <token id="14" string="earthquake" />
            <token id="15" string="warning" />
            <token id="16" string="for" />
            <token id="17" string="the" />
            <token id="18" string="Tokai" />
            <token id="19" string="area" />
          </tokens>
        </chunking>
        <chunking id="4" string="warning for the Tokai area" type="VP">
          <tokens>
            <token id="15" string="warning" />
            <token id="16" string="for" />
            <token id="17" string="the" />
            <token id="18" string="Tokai" />
            <token id="19" string="area" />
          </tokens>
        </chunking>
        <chunking id="5" string="will issue an earthquake warning for the Tokai area" type="VP">
          <tokens>
            <token id="11" string="will" />
            <token id="12" string="issue" />
            <token id="13" string="an" />
            <token id="14" string="earthquake" />
            <token id="15" string="warning" />
            <token id="16" string="for" />
            <token id="17" string="the" />
            <token id="18" string="Tokai" />
            <token id="19" string="area" />
          </tokens>
        </chunking>
        <chunking id="6" string="an earthquake warning for the Tokai area" type="NP">
          <tokens>
            <token id="13" string="an" />
            <token id="14" string="earthquake" />
            <token id="15" string="warning" />
            <token id="16" string="for" />
            <token id="17" string="the" />
            <token id="18" string="Tokai" />
            <token id="19" string="area" />
          </tokens>
        </chunking>
        <chunking id="7" string="an earthquake" type="NP">
          <tokens>
            <token id="13" string="an" />
            <token id="14" string="earthquake" />
          </tokens>
        </chunking>
        <chunking id="8" string="If the committee so advises" type="SBAR">
          <tokens>
            <token id="1" string="If" />
            <token id="2" string="the" />
            <token id="3" string="committee" />
            <token id="4" string="so" />
            <token id="5" string="advises" />
          </tokens>
        </chunking>
        <chunking id="9" string="advises" type="VP">
          <tokens>
            <token id="5" string="advises" />
          </tokens>
        </chunking>
        <chunking id="10" string="the committee" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="committee" />
          </tokens>
        </chunking>
        <chunking id="11" string="Japan 's" type="NP">
          <tokens>
            <token id="7" string="Japan" />
            <token id="8" string="'s" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="5">advises</governor>
          <dependent id="1">If</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">committee</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">advises</governor>
          <dependent id="3">committee</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">advises</governor>
          <dependent id="4">so</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="12">issue</governor>
          <dependent id="5">advises</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="10">minister</governor>
          <dependent id="7">Japan</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">Japan</governor>
          <dependent id="8">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">minister</governor>
          <dependent id="9">prime</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">issue</governor>
          <dependent id="10">minister</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">issue</governor>
          <dependent id="11">will</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">issue</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">earthquake</governor>
          <dependent id="13">an</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">issue</governor>
          <dependent id="14">earthquake</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="14">earthquake</governor>
          <dependent id="15">warning</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">area</governor>
          <dependent id="16">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">area</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">area</governor>
          <dependent id="18">Tokai</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">warning</governor>
          <dependent id="19">area</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Tokai" type="LOCATION" score="0.0">
          <tokens>
            <token id="18" string="Tokai" />
          </tokens>
        </entity>
        <entity id="2" string="Japan" type="LOCATION" score="0.0">
          <tokens>
            <token id="7" string="Japan" />
          </tokens>
        </entity>
        <entity id="3" string="earthquake" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="14" string="earthquake" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>Trains will be stopped, traffic routed out of the area, stores closed and pupils let out of schools.</content>
      <tokens>
        <token id="1" string="Trains" lemma="train" stem="train" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="stopped" lemma="stop" stem="stop" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="traffic" lemma="traffic" stem="traffic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="routed" lemma="route" stem="rout" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="out" lemma="out" stem="out" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="area" lemma="area" stem="area" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="stores" lemma="store" stem="store" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="closed" lemma="close" stem="close" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="pupils" lemma="pupil" stem="pupil" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="let" lemma="let" stem="let" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="out" lemma="out" stem="out" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="schools" lemma="school" stem="school" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NNS Trains)) (VP (MD will) (VP (VB be) (VP (VBN stopped))))) (, ,) (S (NP (NN traffic)) (VP (VBD routed) (PRT (IN out)) (PP (IN of) (NP (DT the) (NN area))))) (, ,) (S (NP (NNS stores)) (VP (VBD closed))) (CC and) (S (NP (NNS pupils)) (VP (VBP let) (PRT (IN out)) (PP (IN of) (NP (NNS schools))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="pupils" type="NP">
          <tokens>
            <token id="16" string="pupils" />
          </tokens>
        </chunking>
        <chunking id="2" string="Trains" type="NP">
          <tokens>
            <token id="1" string="Trains" />
          </tokens>
        </chunking>
        <chunking id="3" string="the area" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="area" />
          </tokens>
        </chunking>
        <chunking id="4" string="stopped" type="VP">
          <tokens>
            <token id="4" string="stopped" />
          </tokens>
        </chunking>
        <chunking id="5" string="schools" type="NP">
          <tokens>
            <token id="20" string="schools" />
          </tokens>
        </chunking>
        <chunking id="6" string="routed out of the area" type="VP">
          <tokens>
            <token id="7" string="routed" />
            <token id="8" string="out" />
            <token id="9" string="of" />
            <token id="10" string="the" />
            <token id="11" string="area" />
          </tokens>
        </chunking>
        <chunking id="7" string="stores" type="NP">
          <tokens>
            <token id="13" string="stores" />
          </tokens>
        </chunking>
        <chunking id="8" string="will be stopped" type="VP">
          <tokens>
            <token id="2" string="will" />
            <token id="3" string="be" />
            <token id="4" string="stopped" />
          </tokens>
        </chunking>
        <chunking id="9" string="be stopped" type="VP">
          <tokens>
            <token id="3" string="be" />
            <token id="4" string="stopped" />
          </tokens>
        </chunking>
        <chunking id="10" string="traffic" type="NP">
          <tokens>
            <token id="6" string="traffic" />
          </tokens>
        </chunking>
        <chunking id="11" string="closed" type="VP">
          <tokens>
            <token id="14" string="closed" />
          </tokens>
        </chunking>
        <chunking id="12" string="let out of schools" type="VP">
          <tokens>
            <token id="17" string="let" />
            <token id="18" string="out" />
            <token id="19" string="of" />
            <token id="20" string="schools" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="4">stopped</governor>
          <dependent id="1">Trains</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">stopped</governor>
          <dependent id="2">will</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="4">stopped</governor>
          <dependent id="3">be</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">stopped</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">routed</governor>
          <dependent id="6">traffic</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">stopped</governor>
          <dependent id="7">routed</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="7">routed</governor>
          <dependent id="8">out</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">area</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">area</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">routed</governor>
          <dependent id="11">area</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">closed</governor>
          <dependent id="13">stores</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">stopped</governor>
          <dependent id="14">closed</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">stopped</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">let</governor>
          <dependent id="16">pupils</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">stopped</governor>
          <dependent id="17">let</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="17">let</governor>
          <dependent id="18">out</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">schools</governor>
          <dependent id="19">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">let</governor>
          <dependent id="20">schools</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="6" has_coreference="false">
      <content>Areas prone to landslides and tidal waves will be evacuated.</content>
      <tokens>
        <token id="1" string="Areas" lemma="area" stem="area" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="prone" lemma="prone" stem="prone" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="landslides" lemma="landslide" stem="landslid" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="tidal" lemma="tidal" stem="tidal" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="waves" lemma="wave" stem="wave" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="evacuated" lemma="evacuate" stem="evacu" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNS Areas)) (ADJP (JJ prone) (PP (TO to) (NP (NP (NNS landslides)) (CC and) (NP (JJ tidal) (NNS waves)))))) (VP (MD will) (VP (VB be) (VP (VBN evacuated)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="prone to landslides and tidal waves" type="ADJP">
          <tokens>
            <token id="2" string="prone" />
            <token id="3" string="to" />
            <token id="4" string="landslides" />
            <token id="5" string="and" />
            <token id="6" string="tidal" />
            <token id="7" string="waves" />
          </tokens>
        </chunking>
        <chunking id="2" string="landslides and tidal waves" type="NP">
          <tokens>
            <token id="4" string="landslides" />
            <token id="5" string="and" />
            <token id="6" string="tidal" />
            <token id="7" string="waves" />
          </tokens>
        </chunking>
        <chunking id="3" string="landslides" type="NP">
          <tokens>
            <token id="4" string="landslides" />
          </tokens>
        </chunking>
        <chunking id="4" string="evacuated" type="VP">
          <tokens>
            <token id="10" string="evacuated" />
          </tokens>
        </chunking>
        <chunking id="5" string="tidal waves" type="NP">
          <tokens>
            <token id="6" string="tidal" />
            <token id="7" string="waves" />
          </tokens>
        </chunking>
        <chunking id="6" string="will be evacuated" type="VP">
          <tokens>
            <token id="8" string="will" />
            <token id="9" string="be" />
            <token id="10" string="evacuated" />
          </tokens>
        </chunking>
        <chunking id="7" string="Areas prone to landslides and tidal waves" type="NP">
          <tokens>
            <token id="1" string="Areas" />
            <token id="2" string="prone" />
            <token id="3" string="to" />
            <token id="4" string="landslides" />
            <token id="5" string="and" />
            <token id="6" string="tidal" />
            <token id="7" string="waves" />
          </tokens>
        </chunking>
        <chunking id="8" string="be evacuated" type="VP">
          <tokens>
            <token id="9" string="be" />
            <token id="10" string="evacuated" />
          </tokens>
        </chunking>
        <chunking id="9" string="Areas" type="NP">
          <tokens>
            <token id="1" string="Areas" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="10">evacuated</governor>
          <dependent id="1">Areas</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="1">Areas</governor>
          <dependent id="2">prone</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">landslides</governor>
          <dependent id="3">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">prone</governor>
          <dependent id="4">landslides</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">landslides</governor>
          <dependent id="5">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">waves</governor>
          <dependent id="6">tidal</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">landslides</governor>
          <dependent id="7">waves</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="10">evacuated</governor>
          <dependent id="8">will</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="10">evacuated</governor>
          <dependent id="9">be</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">evacuated</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="7" has_coreference="false">
      <content>Hospitals, firefighters and rescue crews will go on alert.</content>
      <tokens>
        <token id="1" string="Hospitals" lemma="hospital" stem="hospit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="firefighters" lemma="firefighter" stem="firefight" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="rescue" lemma="rescue" stem="rescu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="crews" lemma="crew" stem="crew" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="go" lemma="go" stem="go" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="alert" lemma="alert" stem="alert" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNS Hospitals) (, ,) (NNS firefighters) (CC and) (NN rescue) (NNS crews)) (VP (MD will) (VP (VB go) (PP (IN on) (ADJP (JJ alert))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Hospitals , firefighters and rescue crews" type="NP">
          <tokens>
            <token id="1" string="Hospitals" />
            <token id="2" string="," />
            <token id="3" string="firefighters" />
            <token id="4" string="and" />
            <token id="5" string="rescue" />
            <token id="6" string="crews" />
          </tokens>
        </chunking>
        <chunking id="2" string="alert" type="ADJP">
          <tokens>
            <token id="10" string="alert" />
          </tokens>
        </chunking>
        <chunking id="3" string="will go on alert" type="VP">
          <tokens>
            <token id="7" string="will" />
            <token id="8" string="go" />
            <token id="9" string="on" />
            <token id="10" string="alert" />
          </tokens>
        </chunking>
        <chunking id="4" string="go on alert" type="VP">
          <tokens>
            <token id="8" string="go" />
            <token id="9" string="on" />
            <token id="10" string="alert" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">firefighters</governor>
          <dependent id="1">Hospitals</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">go</governor>
          <dependent id="3">firefighters</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">firefighters</governor>
          <dependent id="4">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">crews</governor>
          <dependent id="5">rescue</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">firefighters</governor>
          <dependent id="6">crews</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">go</governor>
          <dependent id="7">will</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">go</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">alert</governor>
          <dependent id="9">on</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="8">go</governor>
          <dependent id="10">alert</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="8" has_coreference="false">
      <content>And then everyone will wait for an earthquake measuring eight on the Richter scale.</content>
      <tokens>
        <token id="1" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="everyone" lemma="everyone" stem="everyon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="wait" lemma="wait" stem="wait" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="earthquake" lemma="earthquake" stem="earthquak" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="9" string="measuring" lemma="measure" stem="measur" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="eight" lemma="eight" stem="eight" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="11" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="Richter" lemma="Richter" stem="richter" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="14" string="scale" lemma="scale" stem="scale" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC And) (ADVP (RB then)) (NP (NN everyone)) (VP (MD will) (VP (VB wait) (PP (IN for) (NP (NP (DT an) (NN earthquake)) (VP (VBG measuring) (NP (CD eight)) (PP (IN on) (NP (DT the) (NNP Richter) (NN scale)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the Richter scale" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="Richter" />
            <token id="14" string="scale" />
          </tokens>
        </chunking>
        <chunking id="2" string="everyone" type="NP">
          <tokens>
            <token id="3" string="everyone" />
          </tokens>
        </chunking>
        <chunking id="3" string="measuring eight on the Richter scale" type="VP">
          <tokens>
            <token id="9" string="measuring" />
            <token id="10" string="eight" />
            <token id="11" string="on" />
            <token id="12" string="the" />
            <token id="13" string="Richter" />
            <token id="14" string="scale" />
          </tokens>
        </chunking>
        <chunking id="4" string="wait for an earthquake measuring eight on the Richter scale" type="VP">
          <tokens>
            <token id="5" string="wait" />
            <token id="6" string="for" />
            <token id="7" string="an" />
            <token id="8" string="earthquake" />
            <token id="9" string="measuring" />
            <token id="10" string="eight" />
            <token id="11" string="on" />
            <token id="12" string="the" />
            <token id="13" string="Richter" />
            <token id="14" string="scale" />
          </tokens>
        </chunking>
        <chunking id="5" string="an earthquake" type="NP">
          <tokens>
            <token id="7" string="an" />
            <token id="8" string="earthquake" />
          </tokens>
        </chunking>
        <chunking id="6" string="an earthquake measuring eight on the Richter scale" type="NP">
          <tokens>
            <token id="7" string="an" />
            <token id="8" string="earthquake" />
            <token id="9" string="measuring" />
            <token id="10" string="eight" />
            <token id="11" string="on" />
            <token id="12" string="the" />
            <token id="13" string="Richter" />
            <token id="14" string="scale" />
          </tokens>
        </chunking>
        <chunking id="7" string="eight" type="NP">
          <tokens>
            <token id="10" string="eight" />
          </tokens>
        </chunking>
        <chunking id="8" string="will wait for an earthquake measuring eight on the Richter scale" type="VP">
          <tokens>
            <token id="4" string="will" />
            <token id="5" string="wait" />
            <token id="6" string="for" />
            <token id="7" string="an" />
            <token id="8" string="earthquake" />
            <token id="9" string="measuring" />
            <token id="10" string="eight" />
            <token id="11" string="on" />
            <token id="12" string="the" />
            <token id="13" string="Richter" />
            <token id="14" string="scale" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="5">wait</governor>
          <dependent id="1">And</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">wait</governor>
          <dependent id="2">then</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">wait</governor>
          <dependent id="3">everyone</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">wait</governor>
          <dependent id="4">will</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">wait</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">earthquake</governor>
          <dependent id="6">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">earthquake</governor>
          <dependent id="7">an</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">wait</governor>
          <dependent id="8">earthquake</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="8">earthquake</governor>
          <dependent id="9">measuring</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">measuring</governor>
          <dependent id="10">eight</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">scale</governor>
          <dependent id="11">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">scale</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">scale</governor>
          <dependent id="13">Richter</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">measuring</governor>
          <dependent id="14">scale</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="earthquake" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="8" string="earthquake" />
          </tokens>
        </entity>
        <entity id="2" string="Richter" type="PERSON" score="0.0">
          <tokens>
            <token id="13" string="Richter" />
          </tokens>
        </entity>
        <entity id="3" string="eight" type="NUMBER" score="0.0">
          <tokens>
            <token id="10" string="eight" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>Long after the rest of the world has abandoned hope of predicting earthquakes, Japan continues to spend Dollars 2.5m (Pounds 1.6m) a year monitoring the Tokai region and close to Dollars 100m more on general earthquake prediction research.</content>
      <tokens>
        <token id="1" string="Long" lemma="long" stem="long" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="rest" lemma="rest" stem="rest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="abandoned" lemma="abandon" stem="abandon" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="hope" lemma="hope" stem="hope" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="predicting" lemma="predict" stem="predict" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="earthquakes" lemma="earthquake" stem="earthquak" pos="NNS" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="true" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="Japan" lemma="Japan" stem="japan" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="16" string="continues" lemma="continue" stem="continu" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="spend" lemma="spend" stem="spend" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="Dollars" lemma="Dollars" stem="dollar" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="2.5" lemma="2.5" stem="2.5" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="21" string="m" lemma="m" stem="m" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="Pounds" lemma="pound" stem="pound" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="1.6" lemma="1.6" stem="1.6" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="25" string="m" lemma="m" stem="m" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="28" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="29" string="monitoring" lemma="monitor" stem="monitor" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="31" string="Tokai" lemma="Tokai" stem="tokai" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="32" string="region" lemma="region" stem="region" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="33" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="34" string="close" lemma="close" stem="close" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="35" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="36" string="Dollars" lemma="Dollars" stem="dollar" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="37" string="100m" lemma="100m" stem="100m" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="true" />
        <token id="38" string="more" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="39" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="40" string="general" lemma="general" stem="gener" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="41" string="earthquake" lemma="earthquake" stem="earthquak" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="true" />
        <token id="42" string="prediction" lemma="prediction" stem="predict" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="43" string="research" lemma="research" stem="research" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="44" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (ADVP (RB Long)) (IN after) (S (NP (NP (DT the) (NN rest)) (PP (IN of) (NP (DT the) (NN world)))) (VP (VBZ has) (VP (VBN abandoned) (NP (NP (NN hope)) (PP (IN of) (S (VP (VBG predicting) (NP (NNS earthquakes)))))))))) (, ,) (NP (NNP Japan)) (VP (VBZ continues) (S (VP (TO to) (VP (VB spend) (NP (NP (NNP Dollars) (CD 2.5) (NN m)) (PRN (-LRB- -LRB-) (NP (NP (NNS Pounds)) (NP (CD 1.6) (NN m))) (-RRB- -RRB-)) (NP (DT a) (NN year))) (S (VP (VBG monitoring) (NP (DT the) (ADJP (ADJP (NP (NP (NNP Tokai) (NN region) (CC and) (NN close)) (PP (TO to) (NP (NNP Dollars) (CD 100m)))) (JJR more)) (PP (IN on) (NP (JJ general) (NN earthquake)))) (NN prediction) (NN research)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Dollars 2.5 m" type="NP">
          <tokens>
            <token id="19" string="Dollars" />
            <token id="20" string="2.5" />
            <token id="21" string="m" />
          </tokens>
        </chunking>
        <chunking id="2" string="Long after the rest of the world has abandoned hope of predicting earthquakes" type="SBAR">
          <tokens>
            <token id="1" string="Long" />
            <token id="2" string="after" />
            <token id="3" string="the" />
            <token id="4" string="rest" />
            <token id="5" string="of" />
            <token id="6" string="the" />
            <token id="7" string="world" />
            <token id="8" string="has" />
            <token id="9" string="abandoned" />
            <token id="10" string="hope" />
            <token id="11" string="of" />
            <token id="12" string="predicting" />
            <token id="13" string="earthquakes" />
          </tokens>
        </chunking>
        <chunking id="3" string="Japan" type="NP">
          <tokens>
            <token id="15" string="Japan" />
          </tokens>
        </chunking>
        <chunking id="4" string="Dollars 100m" type="NP">
          <tokens>
            <token id="36" string="Dollars" />
            <token id="37" string="100m" />
          </tokens>
        </chunking>
        <chunking id="5" string="Tokai region and close to Dollars 100m more on general earthquake" type="ADJP">
          <tokens>
            <token id="31" string="Tokai" />
            <token id="32" string="region" />
            <token id="33" string="and" />
            <token id="34" string="close" />
            <token id="35" string="to" />
            <token id="36" string="Dollars" />
            <token id="37" string="100m" />
            <token id="38" string="more" />
            <token id="39" string="on" />
            <token id="40" string="general" />
            <token id="41" string="earthquake" />
          </tokens>
        </chunking>
        <chunking id="6" string="predicting earthquakes" type="VP">
          <tokens>
            <token id="12" string="predicting" />
            <token id="13" string="earthquakes" />
          </tokens>
        </chunking>
        <chunking id="7" string="the Tokai region and close to Dollars 100m more on general earthquake prediction research" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="Tokai" />
            <token id="32" string="region" />
            <token id="33" string="and" />
            <token id="34" string="close" />
            <token id="35" string="to" />
            <token id="36" string="Dollars" />
            <token id="37" string="100m" />
            <token id="38" string="more" />
            <token id="39" string="on" />
            <token id="40" string="general" />
            <token id="41" string="earthquake" />
            <token id="42" string="prediction" />
            <token id="43" string="research" />
          </tokens>
        </chunking>
        <chunking id="8" string="spend Dollars 2.5 m -LRB- Pounds 1.6 m -RRB- a year monitoring the Tokai region and close to Dollars 100m more on general earthquake prediction research" type="VP">
          <tokens>
            <token id="18" string="spend" />
            <token id="19" string="Dollars" />
            <token id="20" string="2.5" />
            <token id="21" string="m" />
            <token id="22" string="(" />
            <token id="23" string="Pounds" />
            <token id="24" string="1.6" />
            <token id="25" string="m" />
            <token id="26" string=")" />
            <token id="27" string="a" />
            <token id="28" string="year" />
            <token id="29" string="monitoring" />
            <token id="30" string="the" />
            <token id="31" string="Tokai" />
            <token id="32" string="region" />
            <token id="33" string="and" />
            <token id="34" string="close" />
            <token id="35" string="to" />
            <token id="36" string="Dollars" />
            <token id="37" string="100m" />
            <token id="38" string="more" />
            <token id="39" string="on" />
            <token id="40" string="general" />
            <token id="41" string="earthquake" />
            <token id="42" string="prediction" />
            <token id="43" string="research" />
          </tokens>
        </chunking>
        <chunking id="9" string="the rest" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="rest" />
          </tokens>
        </chunking>
        <chunking id="10" string="continues to spend Dollars 2.5 m -LRB- Pounds 1.6 m -RRB- a year monitoring the Tokai region and close to Dollars 100m more on general earthquake prediction research" type="VP">
          <tokens>
            <token id="16" string="continues" />
            <token id="17" string="to" />
            <token id="18" string="spend" />
            <token id="19" string="Dollars" />
            <token id="20" string="2.5" />
            <token id="21" string="m" />
            <token id="22" string="(" />
            <token id="23" string="Pounds" />
            <token id="24" string="1.6" />
            <token id="25" string="m" />
            <token id="26" string=")" />
            <token id="27" string="a" />
            <token id="28" string="year" />
            <token id="29" string="monitoring" />
            <token id="30" string="the" />
            <token id="31" string="Tokai" />
            <token id="32" string="region" />
            <token id="33" string="and" />
            <token id="34" string="close" />
            <token id="35" string="to" />
            <token id="36" string="Dollars" />
            <token id="37" string="100m" />
            <token id="38" string="more" />
            <token id="39" string="on" />
            <token id="40" string="general" />
            <token id="41" string="earthquake" />
            <token id="42" string="prediction" />
            <token id="43" string="research" />
          </tokens>
        </chunking>
        <chunking id="11" string="has abandoned hope of predicting earthquakes" type="VP">
          <tokens>
            <token id="8" string="has" />
            <token id="9" string="abandoned" />
            <token id="10" string="hope" />
            <token id="11" string="of" />
            <token id="12" string="predicting" />
            <token id="13" string="earthquakes" />
          </tokens>
        </chunking>
        <chunking id="12" string="Pounds 1.6 m" type="NP">
          <tokens>
            <token id="23" string="Pounds" />
            <token id="24" string="1.6" />
            <token id="25" string="m" />
          </tokens>
        </chunking>
        <chunking id="13" string="general earthquake" type="NP">
          <tokens>
            <token id="40" string="general" />
            <token id="41" string="earthquake" />
          </tokens>
        </chunking>
        <chunking id="14" string="hope" type="NP">
          <tokens>
            <token id="10" string="hope" />
          </tokens>
        </chunking>
        <chunking id="15" string="Dollars 2.5 m -LRB- Pounds 1.6 m -RRB- a year" type="NP">
          <tokens>
            <token id="19" string="Dollars" />
            <token id="20" string="2.5" />
            <token id="21" string="m" />
            <token id="22" string="(" />
            <token id="23" string="Pounds" />
            <token id="24" string="1.6" />
            <token id="25" string="m" />
            <token id="26" string=")" />
            <token id="27" string="a" />
            <token id="28" string="year" />
          </tokens>
        </chunking>
        <chunking id="16" string="the world" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="world" />
          </tokens>
        </chunking>
        <chunking id="17" string="1.6 m" type="NP">
          <tokens>
            <token id="24" string="1.6" />
            <token id="25" string="m" />
          </tokens>
        </chunking>
        <chunking id="18" string="abandoned hope of predicting earthquakes" type="VP">
          <tokens>
            <token id="9" string="abandoned" />
            <token id="10" string="hope" />
            <token id="11" string="of" />
            <token id="12" string="predicting" />
            <token id="13" string="earthquakes" />
          </tokens>
        </chunking>
        <chunking id="19" string="earthquakes" type="NP">
          <tokens>
            <token id="13" string="earthquakes" />
          </tokens>
        </chunking>
        <chunking id="20" string="Pounds" type="NP">
          <tokens>
            <token id="23" string="Pounds" />
          </tokens>
        </chunking>
        <chunking id="21" string="the rest of the world" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="rest" />
            <token id="5" string="of" />
            <token id="6" string="the" />
            <token id="7" string="world" />
          </tokens>
        </chunking>
        <chunking id="22" string="Tokai region and close to Dollars 100m" type="NP">
          <tokens>
            <token id="31" string="Tokai" />
            <token id="32" string="region" />
            <token id="33" string="and" />
            <token id="34" string="close" />
            <token id="35" string="to" />
            <token id="36" string="Dollars" />
            <token id="37" string="100m" />
          </tokens>
        </chunking>
        <chunking id="23" string="monitoring the Tokai region and close to Dollars 100m more on general earthquake prediction research" type="VP">
          <tokens>
            <token id="29" string="monitoring" />
            <token id="30" string="the" />
            <token id="31" string="Tokai" />
            <token id="32" string="region" />
            <token id="33" string="and" />
            <token id="34" string="close" />
            <token id="35" string="to" />
            <token id="36" string="Dollars" />
            <token id="37" string="100m" />
            <token id="38" string="more" />
            <token id="39" string="on" />
            <token id="40" string="general" />
            <token id="41" string="earthquake" />
            <token id="42" string="prediction" />
            <token id="43" string="research" />
          </tokens>
        </chunking>
        <chunking id="24" string="to spend Dollars 2.5 m -LRB- Pounds 1.6 m -RRB- a year monitoring the Tokai region and close to Dollars 100m more on general earthquake prediction research" type="VP">
          <tokens>
            <token id="17" string="to" />
            <token id="18" string="spend" />
            <token id="19" string="Dollars" />
            <token id="20" string="2.5" />
            <token id="21" string="m" />
            <token id="22" string="(" />
            <token id="23" string="Pounds" />
            <token id="24" string="1.6" />
            <token id="25" string="m" />
            <token id="26" string=")" />
            <token id="27" string="a" />
            <token id="28" string="year" />
            <token id="29" string="monitoring" />
            <token id="30" string="the" />
            <token id="31" string="Tokai" />
            <token id="32" string="region" />
            <token id="33" string="and" />
            <token id="34" string="close" />
            <token id="35" string="to" />
            <token id="36" string="Dollars" />
            <token id="37" string="100m" />
            <token id="38" string="more" />
            <token id="39" string="on" />
            <token id="40" string="general" />
            <token id="41" string="earthquake" />
            <token id="42" string="prediction" />
            <token id="43" string="research" />
          </tokens>
        </chunking>
        <chunking id="25" string="a year" type="NP">
          <tokens>
            <token id="27" string="a" />
            <token id="28" string="year" />
          </tokens>
        </chunking>
        <chunking id="26" string="Tokai region and close" type="NP">
          <tokens>
            <token id="31" string="Tokai" />
            <token id="32" string="region" />
            <token id="33" string="and" />
            <token id="34" string="close" />
          </tokens>
        </chunking>
        <chunking id="27" string="Tokai region and close to Dollars 100m more" type="ADJP">
          <tokens>
            <token id="31" string="Tokai" />
            <token id="32" string="region" />
            <token id="33" string="and" />
            <token id="34" string="close" />
            <token id="35" string="to" />
            <token id="36" string="Dollars" />
            <token id="37" string="100m" />
            <token id="38" string="more" />
          </tokens>
        </chunking>
        <chunking id="28" string="hope of predicting earthquakes" type="NP">
          <tokens>
            <token id="10" string="hope" />
            <token id="11" string="of" />
            <token id="12" string="predicting" />
            <token id="13" string="earthquakes" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="9">abandoned</governor>
          <dependent id="1">Long</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">abandoned</governor>
          <dependent id="2">after</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">rest</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">abandoned</governor>
          <dependent id="4">rest</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">world</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">world</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">rest</governor>
          <dependent id="7">world</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">abandoned</governor>
          <dependent id="8">has</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="16">continues</governor>
          <dependent id="9">abandoned</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">abandoned</governor>
          <dependent id="10">hope</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">predicting</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="10">hope</governor>
          <dependent id="12">predicting</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">predicting</governor>
          <dependent id="13">earthquakes</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">continues</governor>
          <dependent id="15">Japan</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="16">continues</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">spend</governor>
          <dependent id="17">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="16">continues</governor>
          <dependent id="18">spend</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">m</governor>
          <dependent id="19">Dollars</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="21">m</governor>
          <dependent id="20">2.5</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">spend</governor>
          <dependent id="21">m</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="21">m</governor>
          <dependent id="23">Pounds</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="25">m</governor>
          <dependent id="24">1.6</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="23">Pounds</governor>
          <dependent id="25">m</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">year</governor>
          <dependent id="27">a</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="21">m</governor>
          <dependent id="28">year</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="18">spend</governor>
          <dependent id="29">monitoring</dependent>
        </dependency>
        <dependency type="det">
          <governor id="43">research</governor>
          <dependent id="30">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="32">region</governor>
          <dependent id="31">Tokai</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="38">more</governor>
          <dependent id="32">region</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="32">region</governor>
          <dependent id="33">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="32">region</governor>
          <dependent id="34">close</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">Dollars</governor>
          <dependent id="35">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="32">region</governor>
          <dependent id="36">Dollars</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="36">Dollars</governor>
          <dependent id="37">100m</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="43">research</governor>
          <dependent id="38">more</dependent>
        </dependency>
        <dependency type="case">
          <governor id="41">earthquake</governor>
          <dependent id="39">on</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="41">earthquake</governor>
          <dependent id="40">general</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="38">more</governor>
          <dependent id="41">earthquake</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="43">research</governor>
          <dependent id="42">prediction</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="29">monitoring</governor>
          <dependent id="43">research</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Tokai" type="LOCATION" score="0.0">
          <tokens>
            <token id="31" string="Tokai" />
          </tokens>
        </entity>
        <entity id="2" string="Japan" type="LOCATION" score="0.0">
          <tokens>
            <token id="15" string="Japan" />
          </tokens>
        </entity>
        <entity id="3" string="2.5" type="NUMBER" score="0.0">
          <tokens>
            <token id="20" string="2.5" />
          </tokens>
        </entity>
        <entity id="4" string="1.6" type="NUMBER" score="0.0">
          <tokens>
            <token id="24" string="1.6" />
          </tokens>
        </entity>
        <entity id="5" string="a year" type="DURATION" score="0.0">
          <tokens>
            <token id="27" string="a" />
            <token id="28" string="year" />
          </tokens>
        </entity>
        <entity id="6" string="earthquake" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="41" string="earthquake" />
          </tokens>
        </entity>
        <entity id="7" string="100m" type="NUMBER" score="0.0">
          <tokens>
            <token id="37" string="100m" />
          </tokens>
        </entity>
        <entity id="8" string="earthquakes" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="13" string="earthquakes" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>For prediction believers, it is a small price to pay, as Japan is one of the world&amp;apost;s most earthquake-prone countries.</content>
      <tokens>
        <token id="1" string="For" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="prediction" lemma="prediction" stem="predict" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="believers" lemma="believer" stem="believ" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="small" lemma="small" stem="small" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="price" lemma="price" stem="price" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="pay" lemma="pay" stem="pai" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Japan" lemma="Japan" stem="japan" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="15" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="17" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="most" lemma="most" stem="most" pos="RBS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="earthquake-prone" lemma="earthquake-prone" stem="earthquake-pron" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="countries" lemma="country" stem="countri" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN For) (NP (NN prediction) (NNS believers))) (, ,) (NP (PRP it)) (VP (VBZ is) (NP (DT a) (JJ small) (NN price) (S (VP (TO to) (VP (VB pay))))) (, ,) (SBAR (IN as) (S (NP (NNP Japan)) (VP (VBZ is) (NP (NP (CD one)) (PP (IN of) (NP (NP (DT the) (NN world) (POS 's)) (ADJP (RBS most) (JJ earthquake-prone)) (NNS countries)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="one of the world 's most earthquake-prone countries" type="NP">
          <tokens>
            <token id="16" string="one" />
            <token id="17" string="of" />
            <token id="18" string="the" />
            <token id="19" string="world" />
            <token id="20" string="'s" />
            <token id="21" string="most" />
            <token id="22" string="earthquake-prone" />
            <token id="23" string="countries" />
          </tokens>
        </chunking>
        <chunking id="2" string="one" type="NP">
          <tokens>
            <token id="16" string="one" />
          </tokens>
        </chunking>
        <chunking id="3" string="is a small price to pay , as Japan is one of the world 's most earthquake-prone countries" type="VP">
          <tokens>
            <token id="6" string="is" />
            <token id="7" string="a" />
            <token id="8" string="small" />
            <token id="9" string="price" />
            <token id="10" string="to" />
            <token id="11" string="pay" />
            <token id="12" string="," />
            <token id="13" string="as" />
            <token id="14" string="Japan" />
            <token id="15" string="is" />
            <token id="16" string="one" />
            <token id="17" string="of" />
            <token id="18" string="the" />
            <token id="19" string="world" />
            <token id="20" string="'s" />
            <token id="21" string="most" />
            <token id="22" string="earthquake-prone" />
            <token id="23" string="countries" />
          </tokens>
        </chunking>
        <chunking id="4" string="Japan" type="NP">
          <tokens>
            <token id="14" string="Japan" />
          </tokens>
        </chunking>
        <chunking id="5" string="pay" type="VP">
          <tokens>
            <token id="11" string="pay" />
          </tokens>
        </chunking>
        <chunking id="6" string="it" type="NP">
          <tokens>
            <token id="5" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="as Japan is one of the world 's most earthquake-prone countries" type="SBAR">
          <tokens>
            <token id="13" string="as" />
            <token id="14" string="Japan" />
            <token id="15" string="is" />
            <token id="16" string="one" />
            <token id="17" string="of" />
            <token id="18" string="the" />
            <token id="19" string="world" />
            <token id="20" string="'s" />
            <token id="21" string="most" />
            <token id="22" string="earthquake-prone" />
            <token id="23" string="countries" />
          </tokens>
        </chunking>
        <chunking id="8" string="is one of the world 's most earthquake-prone countries" type="VP">
          <tokens>
            <token id="15" string="is" />
            <token id="16" string="one" />
            <token id="17" string="of" />
            <token id="18" string="the" />
            <token id="19" string="world" />
            <token id="20" string="'s" />
            <token id="21" string="most" />
            <token id="22" string="earthquake-prone" />
            <token id="23" string="countries" />
          </tokens>
        </chunking>
        <chunking id="9" string="a small price to pay" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="small" />
            <token id="9" string="price" />
            <token id="10" string="to" />
            <token id="11" string="pay" />
          </tokens>
        </chunking>
        <chunking id="10" string="most earthquake-prone" type="ADJP">
          <tokens>
            <token id="21" string="most" />
            <token id="22" string="earthquake-prone" />
          </tokens>
        </chunking>
        <chunking id="11" string="prediction believers" type="NP">
          <tokens>
            <token id="2" string="prediction" />
            <token id="3" string="believers" />
          </tokens>
        </chunking>
        <chunking id="12" string="the world 's most earthquake-prone countries" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="world" />
            <token id="20" string="'s" />
            <token id="21" string="most" />
            <token id="22" string="earthquake-prone" />
            <token id="23" string="countries" />
          </tokens>
        </chunking>
        <chunking id="13" string="to pay" type="VP">
          <tokens>
            <token id="10" string="to" />
            <token id="11" string="pay" />
          </tokens>
        </chunking>
        <chunking id="14" string="the world 's" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="world" />
            <token id="20" string="'s" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">believers</governor>
          <dependent id="1">For</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">believers</governor>
          <dependent id="2">prediction</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">price</governor>
          <dependent id="3">believers</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">price</governor>
          <dependent id="5">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="9">price</governor>
          <dependent id="6">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">price</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">price</governor>
          <dependent id="8">small</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">price</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">pay</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="9">price</governor>
          <dependent id="11">pay</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">one</governor>
          <dependent id="13">as</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">one</governor>
          <dependent id="14">Japan</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="16">one</governor>
          <dependent id="15">is</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="9">price</governor>
          <dependent id="16">one</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">countries</governor>
          <dependent id="17">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">world</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="23">countries</governor>
          <dependent id="19">world</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">world</governor>
          <dependent id="20">'s</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="22">earthquake-prone</governor>
          <dependent id="21">most</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">countries</governor>
          <dependent id="22">earthquake-prone</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">one</governor>
          <dependent id="23">countries</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="16" string="one" />
          </tokens>
        </entity>
        <entity id="2" string="Japan" type="LOCATION" score="0.0">
          <tokens>
            <token id="14" string="Japan" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>But for increasingly vocal sceptics in Japan, it is at best a misguided effort that wastes money and is dangerously misleading the public.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="increasingly" lemma="increasingly" stem="increasingli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="vocal" lemma="vocal" stem="vocal" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="sceptics" lemma="sceptic" stem="sceptic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Japan" lemma="Japan" stem="japan" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="best" lemma="best" stem="best" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="misguided" lemma="misguided" stem="misguid" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="effort" lemma="effort" stem="effort" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="wastes" lemma="waste" stem="wast" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="money" lemma="money" stem="monei" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="dangerously" lemma="dangerously" stem="danger" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="misleading" lemma="mislead" stem="mislead" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="24" string="public" lemma="public" stem="public" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (PP (IN for) (NP (NP (ADJP (RB increasingly) (JJ vocal)) (NNS sceptics)) (PP (IN in) (NP (NNP Japan))))) (, ,) (NP (PRP it)) (VP (VBZ is) (NP (ADVP (IN at) (JJS best)) (NP (DT a) (JJ misguided) (NN effort)) (SBAR (WHNP (WDT that)) (S (VP (VP (VBZ wastes) (NP (NN money))) (CC and) (VP (VBZ is) (ADVP (RB dangerously)) (VP (VBG misleading) (NP (DT the) (NN public))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="increasingly vocal sceptics" type="NP">
          <tokens>
            <token id="3" string="increasingly" />
            <token id="4" string="vocal" />
            <token id="5" string="sceptics" />
          </tokens>
        </chunking>
        <chunking id="2" string="Japan" type="NP">
          <tokens>
            <token id="7" string="Japan" />
          </tokens>
        </chunking>
        <chunking id="3" string="increasingly vocal" type="ADJP">
          <tokens>
            <token id="3" string="increasingly" />
            <token id="4" string="vocal" />
          </tokens>
        </chunking>
        <chunking id="4" string="the public" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="public" />
          </tokens>
        </chunking>
        <chunking id="5" string="at best a misguided effort that wastes money and is dangerously misleading the public" type="NP">
          <tokens>
            <token id="11" string="at" />
            <token id="12" string="best" />
            <token id="13" string="a" />
            <token id="14" string="misguided" />
            <token id="15" string="effort" />
            <token id="16" string="that" />
            <token id="17" string="wastes" />
            <token id="18" string="money" />
            <token id="19" string="and" />
            <token id="20" string="is" />
            <token id="21" string="dangerously" />
            <token id="22" string="misleading" />
            <token id="23" string="the" />
            <token id="24" string="public" />
          </tokens>
        </chunking>
        <chunking id="6" string="wastes money and is dangerously misleading the public" type="VP">
          <tokens>
            <token id="17" string="wastes" />
            <token id="18" string="money" />
            <token id="19" string="and" />
            <token id="20" string="is" />
            <token id="21" string="dangerously" />
            <token id="22" string="misleading" />
            <token id="23" string="the" />
            <token id="24" string="public" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="9" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="is dangerously misleading the public" type="VP">
          <tokens>
            <token id="20" string="is" />
            <token id="21" string="dangerously" />
            <token id="22" string="misleading" />
            <token id="23" string="the" />
            <token id="24" string="public" />
          </tokens>
        </chunking>
        <chunking id="9" string="money" type="NP">
          <tokens>
            <token id="18" string="money" />
          </tokens>
        </chunking>
        <chunking id="10" string="a misguided effort" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="misguided" />
            <token id="15" string="effort" />
          </tokens>
        </chunking>
        <chunking id="11" string="is at best a misguided effort that wastes money and is dangerously misleading the public" type="VP">
          <tokens>
            <token id="10" string="is" />
            <token id="11" string="at" />
            <token id="12" string="best" />
            <token id="13" string="a" />
            <token id="14" string="misguided" />
            <token id="15" string="effort" />
            <token id="16" string="that" />
            <token id="17" string="wastes" />
            <token id="18" string="money" />
            <token id="19" string="and" />
            <token id="20" string="is" />
            <token id="21" string="dangerously" />
            <token id="22" string="misleading" />
            <token id="23" string="the" />
            <token id="24" string="public" />
          </tokens>
        </chunking>
        <chunking id="12" string="misleading the public" type="VP">
          <tokens>
            <token id="22" string="misleading" />
            <token id="23" string="the" />
            <token id="24" string="public" />
          </tokens>
        </chunking>
        <chunking id="13" string="increasingly vocal sceptics in Japan" type="NP">
          <tokens>
            <token id="3" string="increasingly" />
            <token id="4" string="vocal" />
            <token id="5" string="sceptics" />
            <token id="6" string="in" />
            <token id="7" string="Japan" />
          </tokens>
        </chunking>
        <chunking id="14" string="wastes money" type="VP">
          <tokens>
            <token id="17" string="wastes" />
            <token id="18" string="money" />
          </tokens>
        </chunking>
        <chunking id="15" string="that wastes money and is dangerously misleading the public" type="SBAR">
          <tokens>
            <token id="16" string="that" />
            <token id="17" string="wastes" />
            <token id="18" string="money" />
            <token id="19" string="and" />
            <token id="20" string="is" />
            <token id="21" string="dangerously" />
            <token id="22" string="misleading" />
            <token id="23" string="the" />
            <token id="24" string="public" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="15">effort</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">sceptics</governor>
          <dependent id="2">for</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">vocal</governor>
          <dependent id="3">increasingly</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">sceptics</governor>
          <dependent id="4">vocal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">effort</governor>
          <dependent id="5">sceptics</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">Japan</governor>
          <dependent id="6">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">sceptics</governor>
          <dependent id="7">Japan</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">effort</governor>
          <dependent id="9">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="15">effort</governor>
          <dependent id="10">is</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">best</governor>
          <dependent id="11">at</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">effort</governor>
          <dependent id="12">best</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">effort</governor>
          <dependent id="13">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">effort</governor>
          <dependent id="14">misguided</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">effort</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">wastes</governor>
          <dependent id="16">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="15">effort</governor>
          <dependent id="17">wastes</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">wastes</governor>
          <dependent id="18">money</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="17">wastes</governor>
          <dependent id="19">and</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="22">misleading</governor>
          <dependent id="20">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="22">misleading</governor>
          <dependent id="21">dangerously</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">wastes</governor>
          <dependent id="22">misleading</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">public</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">misleading</governor>
          <dependent id="24">public</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Japan" type="LOCATION" score="0.0">
          <tokens>
            <token id="7" string="Japan" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="12" has_coreference="false">
      <content>Despite the protests, however, Japan&amp;apost;s earthquake prediction programme rolls along on inertia, insularity and unrealistic public expectations.</content>
      <tokens>
        <token id="1" string="Despite" lemma="despite" stem="despit" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="protests" lemma="protest" stem="protest" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="however" lemma="however" stem="howev" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Japan" lemma="Japan" stem="japan" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="8" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="earthquake" lemma="earthquake" stem="earthquak" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="true" is_refers="false" />
        <token id="10" string="prediction" lemma="prediction" stem="predict" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="programme" lemma="programme" stem="programm" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="rolls" lemma="roll" stem="roll" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="along" lemma="along" stem="along" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="inertia" lemma="inertia" stem="inertia" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="insularity" lemma="insularity" stem="insular" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="unrealistic" lemma="unrealistic" stem="unrealist" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="public" lemma="public" stem="public" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="expectations" lemma="expectation" stem="expect" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (FRAG (PP (IN Despite) (NP (NP (NP (DT the) (NNS protests)) (, ,) (ADVP (RB however))) (, ,) (NP (NP (NNP Japan) (POS 's)) (NN earthquake) (NN prediction) (NN programme) (NNS rolls)) (ADVP (IN along) (PP (IN on) (NP (NN inertia) (, ,) (NN insularity) (CC and) (JJ unrealistic) (JJ public) (NNS expectations)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="inertia , insularity and unrealistic public expectations" type="NP">
          <tokens>
            <token id="15" string="inertia" />
            <token id="16" string="," />
            <token id="17" string="insularity" />
            <token id="18" string="and" />
            <token id="19" string="unrealistic" />
            <token id="20" string="public" />
            <token id="21" string="expectations" />
          </tokens>
        </chunking>
        <chunking id="2" string="the protests , however , Japan 's earthquake prediction programme rolls along on inertia , insularity and unrealistic public expectations" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="protests" />
            <token id="4" string="," />
            <token id="5" string="however" />
            <token id="6" string="," />
            <token id="7" string="Japan" />
            <token id="8" string="'s" />
            <token id="9" string="earthquake" />
            <token id="10" string="prediction" />
            <token id="11" string="programme" />
            <token id="12" string="rolls" />
            <token id="13" string="along" />
            <token id="14" string="on" />
            <token id="15" string="inertia" />
            <token id="16" string="," />
            <token id="17" string="insularity" />
            <token id="18" string="and" />
            <token id="19" string="unrealistic" />
            <token id="20" string="public" />
            <token id="21" string="expectations" />
          </tokens>
        </chunking>
        <chunking id="3" string="the protests" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="protests" />
          </tokens>
        </chunking>
        <chunking id="4" string="the protests , however" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="protests" />
            <token id="4" string="," />
            <token id="5" string="however" />
          </tokens>
        </chunking>
        <chunking id="5" string="Japan 's" type="NP">
          <tokens>
            <token id="7" string="Japan" />
            <token id="8" string="'s" />
          </tokens>
        </chunking>
        <chunking id="6" string="Japan 's earthquake prediction programme rolls" type="NP">
          <tokens>
            <token id="7" string="Japan" />
            <token id="8" string="'s" />
            <token id="9" string="earthquake" />
            <token id="10" string="prediction" />
            <token id="11" string="programme" />
            <token id="12" string="rolls" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">protests</governor>
          <dependent id="1">Despite</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">protests</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">protests</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">protests</governor>
          <dependent id="5">however</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="12">rolls</governor>
          <dependent id="7">Japan</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">Japan</governor>
          <dependent id="8">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">rolls</governor>
          <dependent id="9">earthquake</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">rolls</governor>
          <dependent id="10">prediction</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">rolls</governor>
          <dependent id="11">programme</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="3">protests</governor>
          <dependent id="12">rolls</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">protests</governor>
          <dependent id="13">along</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">expectations</governor>
          <dependent id="14">on</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">insularity</governor>
          <dependent id="15">inertia</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">expectations</governor>
          <dependent id="17">insularity</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="17">insularity</governor>
          <dependent id="18">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">insularity</governor>
          <dependent id="19">unrealistic</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">expectations</governor>
          <dependent id="20">public</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">along</governor>
          <dependent id="21">expectations</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Japan" type="LOCATION" score="0.0">
          <tokens>
            <token id="7" string="Japan" />
          </tokens>
        </entity>
        <entity id="2" string="earthquake" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="9" string="earthquake" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>Japan made earthquake prediction a national project in 1965 when scientists throughout the world were optimistic about prediction.</content>
      <tokens>
        <token id="1" string="Japan" lemma="Japan" stem="japan" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="2" string="made" lemma="make" stem="made" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="earthquake" lemma="earthquake" stem="earthquak" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="4" string="prediction" lemma="prediction" stem="predict" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="national" lemma="national" stem="nation" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="project" lemma="project" stem="project" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="1965" lemma="1965" stem="1965" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="10" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="scientists" lemma="scientist" stem="scientist" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="throughout" lemma="throughout" stem="throughout" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="optimistic" lemma="optimistic" stem="optimist" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="prediction" lemma="prediction" stem="predict" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Japan)) (VP (VBD made) (NP (NN earthquake) (NN prediction)) (NP (NP (DT a) (JJ national) (NN project)) (PP (IN in) (NP (CD 1965))) (SBAR (WHADVP (WRB when)) (S (NP (NP (NNS scientists)) (PP (IN throughout) (NP (DT the) (NN world)))) (VP (VBD were) (ADJP (JJ optimistic) (PP (IN about) (NP (NN prediction))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="when scientists throughout the world were optimistic about prediction" type="SBAR">
          <tokens>
            <token id="10" string="when" />
            <token id="11" string="scientists" />
            <token id="12" string="throughout" />
            <token id="13" string="the" />
            <token id="14" string="world" />
            <token id="15" string="were" />
            <token id="16" string="optimistic" />
            <token id="17" string="about" />
            <token id="18" string="prediction" />
          </tokens>
        </chunking>
        <chunking id="2" string="earthquake prediction" type="NP">
          <tokens>
            <token id="3" string="earthquake" />
            <token id="4" string="prediction" />
          </tokens>
        </chunking>
        <chunking id="3" string="Japan" type="NP">
          <tokens>
            <token id="1" string="Japan" />
          </tokens>
        </chunking>
        <chunking id="4" string="the world" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="world" />
          </tokens>
        </chunking>
        <chunking id="5" string="a national project" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="national" />
            <token id="7" string="project" />
          </tokens>
        </chunking>
        <chunking id="6" string="were optimistic about prediction" type="VP">
          <tokens>
            <token id="15" string="were" />
            <token id="16" string="optimistic" />
            <token id="17" string="about" />
            <token id="18" string="prediction" />
          </tokens>
        </chunking>
        <chunking id="7" string="when" type="WHADVP">
          <tokens>
            <token id="10" string="when" />
          </tokens>
        </chunking>
        <chunking id="8" string="1965" type="NP">
          <tokens>
            <token id="9" string="1965" />
          </tokens>
        </chunking>
        <chunking id="9" string="scientists" type="NP">
          <tokens>
            <token id="11" string="scientists" />
          </tokens>
        </chunking>
        <chunking id="10" string="scientists throughout the world" type="NP">
          <tokens>
            <token id="11" string="scientists" />
            <token id="12" string="throughout" />
            <token id="13" string="the" />
            <token id="14" string="world" />
          </tokens>
        </chunking>
        <chunking id="11" string="prediction" type="NP">
          <tokens>
            <token id="18" string="prediction" />
          </tokens>
        </chunking>
        <chunking id="12" string="made earthquake prediction a national project in 1965 when scientists throughout the world were optimistic about prediction" type="VP">
          <tokens>
            <token id="2" string="made" />
            <token id="3" string="earthquake" />
            <token id="4" string="prediction" />
            <token id="5" string="a" />
            <token id="6" string="national" />
            <token id="7" string="project" />
            <token id="8" string="in" />
            <token id="9" string="1965" />
            <token id="10" string="when" />
            <token id="11" string="scientists" />
            <token id="12" string="throughout" />
            <token id="13" string="the" />
            <token id="14" string="world" />
            <token id="15" string="were" />
            <token id="16" string="optimistic" />
            <token id="17" string="about" />
            <token id="18" string="prediction" />
          </tokens>
        </chunking>
        <chunking id="13" string="a national project in 1965 when scientists throughout the world were optimistic about prediction" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="national" />
            <token id="7" string="project" />
            <token id="8" string="in" />
            <token id="9" string="1965" />
            <token id="10" string="when" />
            <token id="11" string="scientists" />
            <token id="12" string="throughout" />
            <token id="13" string="the" />
            <token id="14" string="world" />
            <token id="15" string="were" />
            <token id="16" string="optimistic" />
            <token id="17" string="about" />
            <token id="18" string="prediction" />
          </tokens>
        </chunking>
        <chunking id="14" string="optimistic about prediction" type="ADJP">
          <tokens>
            <token id="16" string="optimistic" />
            <token id="17" string="about" />
            <token id="18" string="prediction" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">made</governor>
          <dependent id="1">Japan</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">made</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">prediction</governor>
          <dependent id="3">earthquake</dependent>
        </dependency>
        <dependency type="iobj">
          <governor id="2">made</governor>
          <dependent id="4">prediction</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">project</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">project</governor>
          <dependent id="6">national</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">made</governor>
          <dependent id="7">project</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">1965</governor>
          <dependent id="8">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">project</governor>
          <dependent id="9">1965</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">optimistic</governor>
          <dependent id="10">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">optimistic</governor>
          <dependent id="11">scientists</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">world</governor>
          <dependent id="12">throughout</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">world</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">scientists</governor>
          <dependent id="14">world</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="16">optimistic</governor>
          <dependent id="15">were</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="7">project</governor>
          <dependent id="16">optimistic</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">prediction</governor>
          <dependent id="17">about</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">optimistic</governor>
          <dependent id="18">prediction</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1965" type="DATE" score="0.0">
          <tokens>
            <token id="9" string="1965" />
          </tokens>
        </entity>
        <entity id="2" string="Japan" type="LOCATION" score="0.0">
          <tokens>
            <token id="1" string="Japan" />
          </tokens>
        </entity>
        <entity id="3" string="earthquake" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="3" string="earthquake" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="14" has_coreference="false">
      <content>Research was also being taken seriously in the US, Russia and China.</content>
      <tokens>
        <token id="1" string="Research" lemma="research" stem="research" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="being" lemma="be" stem="be" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="taken" lemma="take" stem="taken" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="seriously" lemma="seriously" stem="serious" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="US" lemma="US" stem="us" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Russia" lemma="Russia" stem="russia" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="12" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="China" lemma="China" stem="china" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NN Research)) (VP (VBD was) (ADVP (RB also)) (VP (VBG being) (VP (VBN taken) (ADVP (RB seriously)) (PP (IN in) (NP (NP (DT the) (NNP US)) (, ,) (NP (NNP Russia)) (CC and) (NP (NNP China))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the US" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="US" />
          </tokens>
        </chunking>
        <chunking id="2" string="China" type="NP">
          <tokens>
            <token id="13" string="China" />
          </tokens>
        </chunking>
        <chunking id="3" string="Research" type="NP">
          <tokens>
            <token id="1" string="Research" />
          </tokens>
        </chunking>
        <chunking id="4" string="being taken seriously in the US , Russia and China" type="VP">
          <tokens>
            <token id="4" string="being" />
            <token id="5" string="taken" />
            <token id="6" string="seriously" />
            <token id="7" string="in" />
            <token id="8" string="the" />
            <token id="9" string="US" />
            <token id="10" string="," />
            <token id="11" string="Russia" />
            <token id="12" string="and" />
            <token id="13" string="China" />
          </tokens>
        </chunking>
        <chunking id="5" string="the US , Russia and China" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="US" />
            <token id="10" string="," />
            <token id="11" string="Russia" />
            <token id="12" string="and" />
            <token id="13" string="China" />
          </tokens>
        </chunking>
        <chunking id="6" string="was also being taken seriously in the US , Russia and China" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="also" />
            <token id="4" string="being" />
            <token id="5" string="taken" />
            <token id="6" string="seriously" />
            <token id="7" string="in" />
            <token id="8" string="the" />
            <token id="9" string="US" />
            <token id="10" string="," />
            <token id="11" string="Russia" />
            <token id="12" string="and" />
            <token id="13" string="China" />
          </tokens>
        </chunking>
        <chunking id="7" string="taken seriously in the US , Russia and China" type="VP">
          <tokens>
            <token id="5" string="taken" />
            <token id="6" string="seriously" />
            <token id="7" string="in" />
            <token id="8" string="the" />
            <token id="9" string="US" />
            <token id="10" string="," />
            <token id="11" string="Russia" />
            <token id="12" string="and" />
            <token id="13" string="China" />
          </tokens>
        </chunking>
        <chunking id="8" string="Russia" type="NP">
          <tokens>
            <token id="11" string="Russia" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="5">taken</governor>
          <dependent id="1">Research</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">taken</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">taken</governor>
          <dependent id="3">also</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="5">taken</governor>
          <dependent id="4">being</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">taken</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">taken</governor>
          <dependent id="6">seriously</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">US</governor>
          <dependent id="7">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">US</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">taken</governor>
          <dependent id="9">US</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">US</governor>
          <dependent id="11">Russia</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">US</governor>
          <dependent id="12">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">US</governor>
          <dependent id="13">China</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="China" type="LOCATION" score="0.0">
          <tokens>
            <token id="13" string="China" />
          </tokens>
        </entity>
        <entity id="2" string="US" type="LOCATION" score="0.0">
          <tokens>
            <token id="9" string="US" />
          </tokens>
        </entity>
        <entity id="3" string="Russia" type="LOCATION" score="0.0">
          <tokens>
            <token id="11" string="Russia" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>In Japan, prediction took on urgency when seismologists concluded that the Tokai area was overdue for a significant quake.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Japan" lemma="Japan" stem="japan" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="prediction" lemma="prediction" stem="predict" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="took" lemma="take" stem="took" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="on" lemma="on" stem="on" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="urgency" lemma="urgency" stem="urgenc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="seismologists" lemma="seismologist" stem="seismologist" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="concluded" lemma="conclude" stem="conclud" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Tokai" lemma="Tokai" stem="tokai" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="14" string="area" lemma="area" stem="area" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="overdue" lemma="overdue" stem="overdu" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="significant" lemma="significant" stem="signific" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="quake" lemma="quake" stem="quak" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (NNP Japan))) (, ,) (NP (NN prediction)) (VP (VBD took) (PRT (RP on)) (NP (NN urgency)) (SBAR (WHADVP (WRB when)) (S (NP (NNS seismologists)) (VP (VBD concluded) (SBAR (IN that) (S (NP (DT the) (NNP Tokai) (NN area)) (VP (VBD was) (ADJP (JJ overdue) (PP (IN for) (NP (DT a) (JJ significant) (NN quake))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the Tokai area" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="Tokai" />
            <token id="14" string="area" />
          </tokens>
        </chunking>
        <chunking id="2" string="a significant quake" type="NP">
          <tokens>
            <token id="18" string="a" />
            <token id="19" string="significant" />
            <token id="20" string="quake" />
          </tokens>
        </chunking>
        <chunking id="3" string="seismologists" type="NP">
          <tokens>
            <token id="9" string="seismologists" />
          </tokens>
        </chunking>
        <chunking id="4" string="Japan" type="NP">
          <tokens>
            <token id="2" string="Japan" />
          </tokens>
        </chunking>
        <chunking id="5" string="was overdue for a significant quake" type="VP">
          <tokens>
            <token id="15" string="was" />
            <token id="16" string="overdue" />
            <token id="17" string="for" />
            <token id="18" string="a" />
            <token id="19" string="significant" />
            <token id="20" string="quake" />
          </tokens>
        </chunking>
        <chunking id="6" string="took on urgency when seismologists concluded that the Tokai area was overdue for a significant quake" type="VP">
          <tokens>
            <token id="5" string="took" />
            <token id="6" string="on" />
            <token id="7" string="urgency" />
            <token id="8" string="when" />
            <token id="9" string="seismologists" />
            <token id="10" string="concluded" />
            <token id="11" string="that" />
            <token id="12" string="the" />
            <token id="13" string="Tokai" />
            <token id="14" string="area" />
            <token id="15" string="was" />
            <token id="16" string="overdue" />
            <token id="17" string="for" />
            <token id="18" string="a" />
            <token id="19" string="significant" />
            <token id="20" string="quake" />
          </tokens>
        </chunking>
        <chunking id="7" string="when seismologists concluded that the Tokai area was overdue for a significant quake" type="SBAR">
          <tokens>
            <token id="8" string="when" />
            <token id="9" string="seismologists" />
            <token id="10" string="concluded" />
            <token id="11" string="that" />
            <token id="12" string="the" />
            <token id="13" string="Tokai" />
            <token id="14" string="area" />
            <token id="15" string="was" />
            <token id="16" string="overdue" />
            <token id="17" string="for" />
            <token id="18" string="a" />
            <token id="19" string="significant" />
            <token id="20" string="quake" />
          </tokens>
        </chunking>
        <chunking id="8" string="when" type="WHADVP">
          <tokens>
            <token id="8" string="when" />
          </tokens>
        </chunking>
        <chunking id="9" string="overdue for a significant quake" type="ADJP">
          <tokens>
            <token id="16" string="overdue" />
            <token id="17" string="for" />
            <token id="18" string="a" />
            <token id="19" string="significant" />
            <token id="20" string="quake" />
          </tokens>
        </chunking>
        <chunking id="10" string="concluded that the Tokai area was overdue for a significant quake" type="VP">
          <tokens>
            <token id="10" string="concluded" />
            <token id="11" string="that" />
            <token id="12" string="the" />
            <token id="13" string="Tokai" />
            <token id="14" string="area" />
            <token id="15" string="was" />
            <token id="16" string="overdue" />
            <token id="17" string="for" />
            <token id="18" string="a" />
            <token id="19" string="significant" />
            <token id="20" string="quake" />
          </tokens>
        </chunking>
        <chunking id="11" string="urgency" type="NP">
          <tokens>
            <token id="7" string="urgency" />
          </tokens>
        </chunking>
        <chunking id="12" string="that the Tokai area was overdue for a significant quake" type="SBAR">
          <tokens>
            <token id="11" string="that" />
            <token id="12" string="the" />
            <token id="13" string="Tokai" />
            <token id="14" string="area" />
            <token id="15" string="was" />
            <token id="16" string="overdue" />
            <token id="17" string="for" />
            <token id="18" string="a" />
            <token id="19" string="significant" />
            <token id="20" string="quake" />
          </tokens>
        </chunking>
        <chunking id="13" string="prediction" type="NP">
          <tokens>
            <token id="4" string="prediction" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">Japan</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">took</governor>
          <dependent id="2">Japan</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">took</governor>
          <dependent id="4">prediction</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">took</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="5">took</governor>
          <dependent id="6">on</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">took</governor>
          <dependent id="7">urgency</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">concluded</governor>
          <dependent id="8">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">concluded</governor>
          <dependent id="9">seismologists</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="5">took</governor>
          <dependent id="10">concluded</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">overdue</governor>
          <dependent id="11">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">area</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">area</governor>
          <dependent id="13">Tokai</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">overdue</governor>
          <dependent id="14">area</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="16">overdue</governor>
          <dependent id="15">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">concluded</governor>
          <dependent id="16">overdue</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">quake</governor>
          <dependent id="17">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">quake</governor>
          <dependent id="18">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">quake</governor>
          <dependent id="19">significant</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">overdue</governor>
          <dependent id="20">quake</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Tokai" type="LOCATION" score="0.0">
          <tokens>
            <token id="13" string="Tokai" />
          </tokens>
        </entity>
        <entity id="2" string="Japan" type="LOCATION" score="0.0">
          <tokens>
            <token id="2" string="Japan" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>The Suruga Trough, a deep submarine trench running just offshore, forms the boundary between two of the earth&amp;apost;s tectonic plates.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Suruga" lemma="Suruga" stem="suruga" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Trough" lemma="Trough" stem="trough" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="deep" lemma="deep" stem="deep" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="submarine" lemma="submarine" stem="submarin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="trench" lemma="trench" stem="trench" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="running" lemma="run" stem="run" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="offshore" lemma="offshore" stem="offshor" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="forms" lemma="form" stem="form" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="boundary" lemma="boundary" stem="boundari" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="between" lemma="between" stem="between" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="true" />
        <token id="18" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="earth" lemma="earth" stem="earth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="tectonic" lemma="tectonic" stem="tecton" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="plates" lemma="plate" stem="plate" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (NNP Suruga) (NNP Trough)) (, ,) (NP (NP (DT a) (JJ deep) (NN submarine) (NN trench)) (VP (VBG running) (ADVP (RB just)) (ADVP (RB offshore)))) (, ,)) (VP (VBZ forms) (NP (NP (DT the) (NN boundary)) (PP (IN between) (NP (CD two))) (PP (IN of) (NP (NP (DT the) (NN earth) (POS 's)) (JJ tectonic) (NNS plates))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="The Suruga Trough , a deep submarine trench running just offshore ," type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Suruga" />
            <token id="3" string="Trough" />
            <token id="4" string="," />
            <token id="5" string="a" />
            <token id="6" string="deep" />
            <token id="7" string="submarine" />
            <token id="8" string="trench" />
            <token id="9" string="running" />
            <token id="10" string="just" />
            <token id="11" string="offshore" />
            <token id="12" string="," />
          </tokens>
        </chunking>
        <chunking id="2" string="the boundary" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="boundary" />
          </tokens>
        </chunking>
        <chunking id="3" string="The Suruga Trough" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Suruga" />
            <token id="3" string="Trough" />
          </tokens>
        </chunking>
        <chunking id="4" string="forms the boundary between two of the earth 's tectonic plates" type="VP">
          <tokens>
            <token id="13" string="forms" />
            <token id="14" string="the" />
            <token id="15" string="boundary" />
            <token id="16" string="between" />
            <token id="17" string="two" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="earth" />
            <token id="21" string="'s" />
            <token id="22" string="tectonic" />
            <token id="23" string="plates" />
          </tokens>
        </chunking>
        <chunking id="5" string="a deep submarine trench" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="deep" />
            <token id="7" string="submarine" />
            <token id="8" string="trench" />
          </tokens>
        </chunking>
        <chunking id="6" string="running just offshore" type="VP">
          <tokens>
            <token id="9" string="running" />
            <token id="10" string="just" />
            <token id="11" string="offshore" />
          </tokens>
        </chunking>
        <chunking id="7" string="two" type="NP">
          <tokens>
            <token id="17" string="two" />
          </tokens>
        </chunking>
        <chunking id="8" string="the boundary between two of the earth 's tectonic plates" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="boundary" />
            <token id="16" string="between" />
            <token id="17" string="two" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="earth" />
            <token id="21" string="'s" />
            <token id="22" string="tectonic" />
            <token id="23" string="plates" />
          </tokens>
        </chunking>
        <chunking id="9" string="a deep submarine trench running just offshore" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="deep" />
            <token id="7" string="submarine" />
            <token id="8" string="trench" />
            <token id="9" string="running" />
            <token id="10" string="just" />
            <token id="11" string="offshore" />
          </tokens>
        </chunking>
        <chunking id="10" string="the earth 's" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="earth" />
            <token id="21" string="'s" />
          </tokens>
        </chunking>
        <chunking id="11" string="the earth 's tectonic plates" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="earth" />
            <token id="21" string="'s" />
            <token id="22" string="tectonic" />
            <token id="23" string="plates" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">Trough</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Trough</governor>
          <dependent id="2">Suruga</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">forms</governor>
          <dependent id="3">Trough</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">trench</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">trench</governor>
          <dependent id="6">deep</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">trench</governor>
          <dependent id="7">submarine</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="3">Trough</governor>
          <dependent id="8">trench</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="8">trench</governor>
          <dependent id="9">running</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">running</governor>
          <dependent id="10">just</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">running</governor>
          <dependent id="11">offshore</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">forms</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">boundary</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">forms</governor>
          <dependent id="15">boundary</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">two</governor>
          <dependent id="16">between</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">boundary</governor>
          <dependent id="17">two</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">plates</governor>
          <dependent id="18">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">earth</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="23">plates</governor>
          <dependent id="20">earth</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">earth</governor>
          <dependent id="21">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">plates</governor>
          <dependent id="22">tectonic</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">boundary</governor>
          <dependent id="23">plates</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="17" string="two" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="17" has_coreference="false">
      <content>The Philippine Sea Plate is diving beneath the Eurasian Plate.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Philippine" lemma="Philippine" stem="philippin" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="3" string="Sea" lemma="Sea" stem="sea" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="4" string="Plate" lemma="Plate" stem="plate" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="5" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="diving" lemma="diving" stem="dive" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="beneath" lemma="beneath" stem="beneath" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Eurasian" lemma="eurasian" stem="eurasian" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="Plate" lemma="plate" stem="plate" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NNP Philippine) (NNP Sea) (NNP Plate)) (VP (VBZ is) (ADJP (JJ diving) (PP (IN beneath) (NP (DT the) (JJ Eurasian) (NN Plate))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the Eurasian Plate" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="Eurasian" />
            <token id="10" string="Plate" />
          </tokens>
        </chunking>
        <chunking id="2" string="diving beneath the Eurasian Plate" type="ADJP">
          <tokens>
            <token id="6" string="diving" />
            <token id="7" string="beneath" />
            <token id="8" string="the" />
            <token id="9" string="Eurasian" />
            <token id="10" string="Plate" />
          </tokens>
        </chunking>
        <chunking id="3" string="The Philippine Sea Plate" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Philippine" />
            <token id="3" string="Sea" />
            <token id="4" string="Plate" />
          </tokens>
        </chunking>
        <chunking id="4" string="is diving beneath the Eurasian Plate" type="VP">
          <tokens>
            <token id="5" string="is" />
            <token id="6" string="diving" />
            <token id="7" string="beneath" />
            <token id="8" string="the" />
            <token id="9" string="Eurasian" />
            <token id="10" string="Plate" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="4">Plate</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">Plate</governor>
          <dependent id="2">Philippine</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">Plate</governor>
          <dependent id="3">Sea</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">diving</governor>
          <dependent id="4">Plate</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">diving</governor>
          <dependent id="5">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">diving</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">Plate</governor>
          <dependent id="7">beneath</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">Plate</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">Plate</governor>
          <dependent id="9">Eurasian</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">diving</governor>
          <dependent id="10">Plate</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Philippine Sea Plate" type="LOCATION" score="0.0">
          <tokens>
            <token id="2" string="Philippine" />
            <token id="3" string="Sea" />
            <token id="4" string="Plate" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="18" has_coreference="true">
      <content>Friction between these plates causes the area&amp;apost;s earthquakes.</content>
      <tokens>
        <token id="1" string="Friction" lemma="friction" stem="friction" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="between" lemma="between" stem="between" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="these" lemma="these" stem="these" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="plates" lemma="plate" stem="plate" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="causes" lemma="cause" stem="caus" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="area" lemma="area" stem="area" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="earthquakes" lemma="earthquake" stem="earthquak" pos="NNS" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NN Friction)) (PP (IN between) (NP (DT these) (NNS plates)))) (VP (VBZ causes) (NP (NP (DT the) (NN area) (POS 's)) (NNS earthquakes))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="these plates" type="NP">
          <tokens>
            <token id="3" string="these" />
            <token id="4" string="plates" />
          </tokens>
        </chunking>
        <chunking id="2" string="the area 's" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="area" />
            <token id="8" string="'s" />
          </tokens>
        </chunking>
        <chunking id="3" string="Friction" type="NP">
          <tokens>
            <token id="1" string="Friction" />
          </tokens>
        </chunking>
        <chunking id="4" string="the area 's earthquakes" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="area" />
            <token id="8" string="'s" />
            <token id="9" string="earthquakes" />
          </tokens>
        </chunking>
        <chunking id="5" string="causes the area 's earthquakes" type="VP">
          <tokens>
            <token id="5" string="causes" />
            <token id="6" string="the" />
            <token id="7" string="area" />
            <token id="8" string="'s" />
            <token id="9" string="earthquakes" />
          </tokens>
        </chunking>
        <chunking id="6" string="Friction between these plates" type="NP">
          <tokens>
            <token id="1" string="Friction" />
            <token id="2" string="between" />
            <token id="3" string="these" />
            <token id="4" string="plates" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">causes</governor>
          <dependent id="1">Friction</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">plates</governor>
          <dependent id="2">between</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">plates</governor>
          <dependent id="3">these</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Friction</governor>
          <dependent id="4">plates</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">causes</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">area</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="9">earthquakes</governor>
          <dependent id="7">area</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">area</governor>
          <dependent id="8">'s</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">causes</governor>
          <dependent id="9">earthquakes</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="earthquakes" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="9" string="earthquakes" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="19" has_coreference="false">
      <content>The Tokai section last ruptured in 1854.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Tokai" lemma="Tokai" stem="tokai" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="3" string="section" lemma="section" stem="section" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="ruptured" lemma="rupture" stem="ruptur" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="1854" lemma="1854" stem="1854" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NNP Tokai) (NN section)) (ADVP (JJ last)) (VP (VBN ruptured) (PP (IN in) (NP (CD 1854)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="ruptured in 1854" type="VP">
          <tokens>
            <token id="5" string="ruptured" />
            <token id="6" string="in" />
            <token id="7" string="1854" />
          </tokens>
        </chunking>
        <chunking id="2" string="The Tokai section" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Tokai" />
            <token id="3" string="section" />
          </tokens>
        </chunking>
        <chunking id="3" string="1854" type="NP">
          <tokens>
            <token id="7" string="1854" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">section</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">section</governor>
          <dependent id="2">Tokai</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">ruptured</governor>
          <dependent id="3">section</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">ruptured</governor>
          <dependent id="4">last</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">ruptured</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">1854</governor>
          <dependent id="6">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">ruptured</governor>
          <dependent id="7">1854</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1854" type="DATE" score="0.0">
          <tokens>
            <token id="7" string="1854" />
          </tokens>
        </entity>
        <entity id="2" string="Tokai" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="2" string="Tokai" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="20" has_coreference="true">
      <content>If the entire section ruptures again, the resulting quake could reach eight on the Richter scale, endangering the lives of 10m residents in the area.</content>
      <tokens>
        <token id="1" string="If" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="entire" lemma="entire" stem="entir" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="section" lemma="section" stem="section" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="ruptures" lemma="rupture" stem="ruptur" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="again" lemma="again" stem="again" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="resulting" lemma="result" stem="result" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="quake" lemma="quake" stem="quak" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="reach" lemma="reach" stem="reach" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="eight" lemma="eight" stem="eight" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="14" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="Richter" lemma="Richter" stem="richter" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="scale" lemma="scale" stem="scale" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="endangering" lemma="endanger" stem="endang" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="lives" lemma="life" stem="live" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="10m" lemma="10m" stem="10m" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="residents" lemma="resident" stem="resid" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="27" string="area" lemma="area" stem="area" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN If) (S (NP (DT the) (JJ entire) (NN section) (NNS ruptures)) (ADVP (RB again)))) (, ,) (NP (DT the) (VBG resulting) (NN quake)) (VP (MD could) (VP (VB reach) (NP (CD eight)) (PP (IN on) (NP (DT the) (NNP Richter) (NN scale))) (, ,) (S (VP (VBG endangering) (NP (NP (DT the) (NNS lives)) (PP (IN of) (NP (NN 10m) (NNS residents)))) (PP (IN in) (NP (DT the) (NN area))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the entire section ruptures" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="entire" />
            <token id="4" string="section" />
            <token id="5" string="ruptures" />
          </tokens>
        </chunking>
        <chunking id="2" string="the resulting quake" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="resulting" />
            <token id="10" string="quake" />
          </tokens>
        </chunking>
        <chunking id="3" string="the Richter scale" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="Richter" />
            <token id="17" string="scale" />
          </tokens>
        </chunking>
        <chunking id="4" string="endangering the lives of 10m residents in the area" type="VP">
          <tokens>
            <token id="19" string="endangering" />
            <token id="20" string="the" />
            <token id="21" string="lives" />
            <token id="22" string="of" />
            <token id="23" string="10m" />
            <token id="24" string="residents" />
            <token id="25" string="in" />
            <token id="26" string="the" />
            <token id="27" string="area" />
          </tokens>
        </chunking>
        <chunking id="5" string="the area" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="area" />
          </tokens>
        </chunking>
        <chunking id="6" string="reach eight on the Richter scale , endangering the lives of 10m residents in the area" type="VP">
          <tokens>
            <token id="12" string="reach" />
            <token id="13" string="eight" />
            <token id="14" string="on" />
            <token id="15" string="the" />
            <token id="16" string="Richter" />
            <token id="17" string="scale" />
            <token id="18" string="," />
            <token id="19" string="endangering" />
            <token id="20" string="the" />
            <token id="21" string="lives" />
            <token id="22" string="of" />
            <token id="23" string="10m" />
            <token id="24" string="residents" />
            <token id="25" string="in" />
            <token id="26" string="the" />
            <token id="27" string="area" />
          </tokens>
        </chunking>
        <chunking id="7" string="could reach eight on the Richter scale , endangering the lives of 10m residents in the area" type="VP">
          <tokens>
            <token id="11" string="could" />
            <token id="12" string="reach" />
            <token id="13" string="eight" />
            <token id="14" string="on" />
            <token id="15" string="the" />
            <token id="16" string="Richter" />
            <token id="17" string="scale" />
            <token id="18" string="," />
            <token id="19" string="endangering" />
            <token id="20" string="the" />
            <token id="21" string="lives" />
            <token id="22" string="of" />
            <token id="23" string="10m" />
            <token id="24" string="residents" />
            <token id="25" string="in" />
            <token id="26" string="the" />
            <token id="27" string="area" />
          </tokens>
        </chunking>
        <chunking id="8" string="the lives" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="lives" />
          </tokens>
        </chunking>
        <chunking id="9" string="the lives of 10m residents" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="lives" />
            <token id="22" string="of" />
            <token id="23" string="10m" />
            <token id="24" string="residents" />
          </tokens>
        </chunking>
        <chunking id="10" string="10m residents" type="NP">
          <tokens>
            <token id="23" string="10m" />
            <token id="24" string="residents" />
          </tokens>
        </chunking>
        <chunking id="11" string="If the entire section ruptures again" type="SBAR">
          <tokens>
            <token id="1" string="If" />
            <token id="2" string="the" />
            <token id="3" string="entire" />
            <token id="4" string="section" />
            <token id="5" string="ruptures" />
            <token id="6" string="again" />
          </tokens>
        </chunking>
        <chunking id="12" string="eight" type="NP">
          <tokens>
            <token id="13" string="eight" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="5">ruptures</governor>
          <dependent id="1">If</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">ruptures</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">ruptures</governor>
          <dependent id="3">entire</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">ruptures</governor>
          <dependent id="4">section</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="12">reach</governor>
          <dependent id="5">ruptures</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">ruptures</governor>
          <dependent id="6">again</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">quake</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">quake</governor>
          <dependent id="9">resulting</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">reach</governor>
          <dependent id="10">quake</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">reach</governor>
          <dependent id="11">could</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">reach</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">reach</governor>
          <dependent id="13">eight</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">scale</governor>
          <dependent id="14">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">scale</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">scale</governor>
          <dependent id="16">Richter</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">reach</governor>
          <dependent id="17">scale</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="12">reach</governor>
          <dependent id="19">endangering</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">lives</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">endangering</governor>
          <dependent id="21">lives</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">residents</governor>
          <dependent id="22">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">residents</governor>
          <dependent id="23">10m</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">lives</governor>
          <dependent id="24">residents</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">area</governor>
          <dependent id="25">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">area</governor>
          <dependent id="26">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">endangering</governor>
          <dependent id="27">area</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="eight" type="NUMBER" score="0.0">
          <tokens>
            <token id="13" string="eight" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="21" has_coreference="false">
      <content>That prospect led to the 1978 Large-Scale Earthquake Countermeasures Act, which established the warning procedure and launched hazard mitigation and emergency response programmes.</content>
      <tokens>
        <token id="1" string="That" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="prospect" lemma="prospect" stem="prospect" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="led" lemma="lead" stem="led" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="1978" lemma="1978" stem="1978" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="7" string="Large-Scale" lemma="Large-Scale" stem="large-scal" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="8" string="Earthquake" lemma="Earthquake" stem="earthquak" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="9" string="Countermeasures" lemma="countermeasure" stem="countermeasur" pos="NNS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="10" string="Act" lemma="Act" stem="act" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="established" lemma="establish" stem="establish" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="warning" lemma="warning" stem="warn" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="procedure" lemma="procedure" stem="procedur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="launched" lemma="launch" stem="launch" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="hazard" lemma="hazard" stem="hazard" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="mitigation" lemma="mitigation" stem="mitig" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="emergency" lemma="emergency" stem="emerg" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="response" lemma="response" stem="respons" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="programmes" lemma="programme" stem="programm" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT That) (NN prospect)) (VP (VBD led) (PP (TO to) (NP (DT the) (CD 1978) (NNP Large-Scale) (NNP Earthquake) (NNS Countermeasures))) (NP (NP (NNP Act)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VP (VBD established) (NP (DT the) (NN warning) (NN procedure))) (CC and) (VP (VBD launched) (NP (NN hazard) (NN mitigation) (CC and) (NN emergency) (NN response) (NNS programmes)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Act" type="NP">
          <tokens>
            <token id="10" string="Act" />
          </tokens>
        </chunking>
        <chunking id="2" string="established the warning procedure" type="VP">
          <tokens>
            <token id="13" string="established" />
            <token id="14" string="the" />
            <token id="15" string="warning" />
            <token id="16" string="procedure" />
          </tokens>
        </chunking>
        <chunking id="3" string="the warning procedure" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="warning" />
            <token id="16" string="procedure" />
          </tokens>
        </chunking>
        <chunking id="4" string="the 1978 Large-Scale Earthquake Countermeasures" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="1978" />
            <token id="7" string="Large-Scale" />
            <token id="8" string="Earthquake" />
            <token id="9" string="Countermeasures" />
          </tokens>
        </chunking>
        <chunking id="5" string="hazard mitigation and emergency response programmes" type="NP">
          <tokens>
            <token id="19" string="hazard" />
            <token id="20" string="mitigation" />
            <token id="21" string="and" />
            <token id="22" string="emergency" />
            <token id="23" string="response" />
            <token id="24" string="programmes" />
          </tokens>
        </chunking>
        <chunking id="6" string="That prospect" type="NP">
          <tokens>
            <token id="1" string="That" />
            <token id="2" string="prospect" />
          </tokens>
        </chunking>
        <chunking id="7" string="Act , which established the warning procedure and launched hazard mitigation and emergency response programmes" type="NP">
          <tokens>
            <token id="10" string="Act" />
            <token id="11" string="," />
            <token id="12" string="which" />
            <token id="13" string="established" />
            <token id="14" string="the" />
            <token id="15" string="warning" />
            <token id="16" string="procedure" />
            <token id="17" string="and" />
            <token id="18" string="launched" />
            <token id="19" string="hazard" />
            <token id="20" string="mitigation" />
            <token id="21" string="and" />
            <token id="22" string="emergency" />
            <token id="23" string="response" />
            <token id="24" string="programmes" />
          </tokens>
        </chunking>
        <chunking id="8" string="established the warning procedure and launched hazard mitigation and emergency response programmes" type="VP">
          <tokens>
            <token id="13" string="established" />
            <token id="14" string="the" />
            <token id="15" string="warning" />
            <token id="16" string="procedure" />
            <token id="17" string="and" />
            <token id="18" string="launched" />
            <token id="19" string="hazard" />
            <token id="20" string="mitigation" />
            <token id="21" string="and" />
            <token id="22" string="emergency" />
            <token id="23" string="response" />
            <token id="24" string="programmes" />
          </tokens>
        </chunking>
        <chunking id="9" string="which established the warning procedure and launched hazard mitigation and emergency response programmes" type="SBAR">
          <tokens>
            <token id="12" string="which" />
            <token id="13" string="established" />
            <token id="14" string="the" />
            <token id="15" string="warning" />
            <token id="16" string="procedure" />
            <token id="17" string="and" />
            <token id="18" string="launched" />
            <token id="19" string="hazard" />
            <token id="20" string="mitigation" />
            <token id="21" string="and" />
            <token id="22" string="emergency" />
            <token id="23" string="response" />
            <token id="24" string="programmes" />
          </tokens>
        </chunking>
        <chunking id="10" string="launched hazard mitigation and emergency response programmes" type="VP">
          <tokens>
            <token id="18" string="launched" />
            <token id="19" string="hazard" />
            <token id="20" string="mitigation" />
            <token id="21" string="and" />
            <token id="22" string="emergency" />
            <token id="23" string="response" />
            <token id="24" string="programmes" />
          </tokens>
        </chunking>
        <chunking id="11" string="led to the 1978 Large-Scale Earthquake Countermeasures Act , which established the warning procedure and launched hazard mitigation and emergency response programmes" type="VP">
          <tokens>
            <token id="3" string="led" />
            <token id="4" string="to" />
            <token id="5" string="the" />
            <token id="6" string="1978" />
            <token id="7" string="Large-Scale" />
            <token id="8" string="Earthquake" />
            <token id="9" string="Countermeasures" />
            <token id="10" string="Act" />
            <token id="11" string="," />
            <token id="12" string="which" />
            <token id="13" string="established" />
            <token id="14" string="the" />
            <token id="15" string="warning" />
            <token id="16" string="procedure" />
            <token id="17" string="and" />
            <token id="18" string="launched" />
            <token id="19" string="hazard" />
            <token id="20" string="mitigation" />
            <token id="21" string="and" />
            <token id="22" string="emergency" />
            <token id="23" string="response" />
            <token id="24" string="programmes" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">prospect</governor>
          <dependent id="1">That</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">led</governor>
          <dependent id="2">prospect</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">led</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Countermeasures</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">Countermeasures</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="9">Countermeasures</governor>
          <dependent id="6">1978</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Countermeasures</governor>
          <dependent id="7">Large-Scale</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Countermeasures</governor>
          <dependent id="8">Earthquake</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">led</governor>
          <dependent id="9">Countermeasures</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">led</governor>
          <dependent id="10">Act</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">established</governor>
          <dependent id="12">which</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="10">Act</governor>
          <dependent id="13">established</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">procedure</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">procedure</governor>
          <dependent id="15">warning</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">established</governor>
          <dependent id="16">procedure</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">established</governor>
          <dependent id="17">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">established</governor>
          <dependent id="18">launched</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">mitigation</governor>
          <dependent id="19">hazard</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">launched</governor>
          <dependent id="20">mitigation</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="20">mitigation</governor>
          <dependent id="21">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">programmes</governor>
          <dependent id="22">emergency</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">programmes</governor>
          <dependent id="23">response</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="20">mitigation</governor>
          <dependent id="24">programmes</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Large-Scale Earthquake Countermeasures Act" type="MISC" score="0.0">
          <tokens>
            <token id="7" string="Large-Scale" />
            <token id="8" string="Earthquake" />
            <token id="9" string="Countermeasures" />
            <token id="10" string="Act" />
          </tokens>
        </entity>
        <entity id="2" string="1978" type="DATE" score="0.0">
          <tokens>
            <token id="6" string="1978" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="22" has_coreference="false">
      <content>Since then, optimism about prediction has faded.</content>
      <tokens>
        <token id="1" string="Since" lemma="since" stem="sinc" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="optimism" lemma="optimism" stem="optim" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="prediction" lemma="prediction" stem="predict" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="faded" lemma="fade" stem="fade" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN Since) (NP (RB then))) (, ,) (NP (NP (NN optimism)) (PP (IN about) (NP (NN prediction)))) (VP (VBZ has) (VP (VBN faded))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="has faded" type="VP">
          <tokens>
            <token id="7" string="has" />
            <token id="8" string="faded" />
          </tokens>
        </chunking>
        <chunking id="2" string="optimism" type="NP">
          <tokens>
            <token id="4" string="optimism" />
          </tokens>
        </chunking>
        <chunking id="3" string="optimism about prediction" type="NP">
          <tokens>
            <token id="4" string="optimism" />
            <token id="5" string="about" />
            <token id="6" string="prediction" />
          </tokens>
        </chunking>
        <chunking id="4" string="prediction" type="NP">
          <tokens>
            <token id="6" string="prediction" />
          </tokens>
        </chunking>
        <chunking id="5" string="then" type="NP">
          <tokens>
            <token id="2" string="then" />
          </tokens>
        </chunking>
        <chunking id="6" string="faded" type="VP">
          <tokens>
            <token id="8" string="faded" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">then</governor>
          <dependent id="1">Since</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">faded</governor>
          <dependent id="2">then</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">faded</governor>
          <dependent id="4">optimism</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">prediction</governor>
          <dependent id="5">about</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">optimism</governor>
          <dependent id="6">prediction</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">faded</governor>
          <dependent id="7">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">faded</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="23" has_coreference="true">
      <content>Even prediction supporters admit there is no scientific theory on which to base a forecast.</content>
      <tokens>
        <token id="1" string="Even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="prediction" lemma="prediction" stem="predict" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="supporters" lemma="supporter" stem="support" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="admit" lemma="admit" stem="admit" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="scientific" lemma="scientific" stem="scientif" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="theory" lemma="theory" stem="theori" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="base" lemma="base" stem="base" pos="VB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="forecast" lemma="forecast" stem="forecast" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (RB Even) (NN prediction) (NNS supporters)) (VP (VBP admit) (SBAR (S (NP (EX there)) (VP (VBZ is) (NP (NP (DT no) (JJ scientific) (NN theory)) (PP (IN on) (SBAR (WHNP (WDT which)) (S (VP (TO to) (VP (VB base) (NP (DT a) (NN forecast)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="there" type="NP">
          <tokens>
            <token id="5" string="there" />
          </tokens>
        </chunking>
        <chunking id="2" string="to base a forecast" type="VP">
          <tokens>
            <token id="12" string="to" />
            <token id="13" string="base" />
            <token id="14" string="a" />
            <token id="15" string="forecast" />
          </tokens>
        </chunking>
        <chunking id="3" string="admit there is no scientific theory on which to base a forecast" type="VP">
          <tokens>
            <token id="4" string="admit" />
            <token id="5" string="there" />
            <token id="6" string="is" />
            <token id="7" string="no" />
            <token id="8" string="scientific" />
            <token id="9" string="theory" />
            <token id="10" string="on" />
            <token id="11" string="which" />
            <token id="12" string="to" />
            <token id="13" string="base" />
            <token id="14" string="a" />
            <token id="15" string="forecast" />
          </tokens>
        </chunking>
        <chunking id="4" string="there is no scientific theory on which to base a forecast" type="SBAR">
          <tokens>
            <token id="5" string="there" />
            <token id="6" string="is" />
            <token id="7" string="no" />
            <token id="8" string="scientific" />
            <token id="9" string="theory" />
            <token id="10" string="on" />
            <token id="11" string="which" />
            <token id="12" string="to" />
            <token id="13" string="base" />
            <token id="14" string="a" />
            <token id="15" string="forecast" />
          </tokens>
        </chunking>
        <chunking id="5" string="Even prediction supporters" type="NP">
          <tokens>
            <token id="1" string="Even" />
            <token id="2" string="prediction" />
            <token id="3" string="supporters" />
          </tokens>
        </chunking>
        <chunking id="6" string="no scientific theory on which to base a forecast" type="NP">
          <tokens>
            <token id="7" string="no" />
            <token id="8" string="scientific" />
            <token id="9" string="theory" />
            <token id="10" string="on" />
            <token id="11" string="which" />
            <token id="12" string="to" />
            <token id="13" string="base" />
            <token id="14" string="a" />
            <token id="15" string="forecast" />
          </tokens>
        </chunking>
        <chunking id="7" string="a forecast" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="forecast" />
          </tokens>
        </chunking>
        <chunking id="8" string="which to base a forecast" type="SBAR">
          <tokens>
            <token id="11" string="which" />
            <token id="12" string="to" />
            <token id="13" string="base" />
            <token id="14" string="a" />
            <token id="15" string="forecast" />
          </tokens>
        </chunking>
        <chunking id="9" string="is no scientific theory on which to base a forecast" type="VP">
          <tokens>
            <token id="6" string="is" />
            <token id="7" string="no" />
            <token id="8" string="scientific" />
            <token id="9" string="theory" />
            <token id="10" string="on" />
            <token id="11" string="which" />
            <token id="12" string="to" />
            <token id="13" string="base" />
            <token id="14" string="a" />
            <token id="15" string="forecast" />
          </tokens>
        </chunking>
        <chunking id="10" string="base a forecast" type="VP">
          <tokens>
            <token id="13" string="base" />
            <token id="14" string="a" />
            <token id="15" string="forecast" />
          </tokens>
        </chunking>
        <chunking id="11" string="no scientific theory" type="NP">
          <tokens>
            <token id="7" string="no" />
            <token id="8" string="scientific" />
            <token id="9" string="theory" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="3">supporters</governor>
          <dependent id="1">Even</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">supporters</governor>
          <dependent id="2">prediction</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">admit</governor>
          <dependent id="3">supporters</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">admit</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="6">is</governor>
          <dependent id="5">there</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">admit</governor>
          <dependent id="6">is</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="9">theory</governor>
          <dependent id="7">no</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">theory</governor>
          <dependent id="8">scientific</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">is</governor>
          <dependent id="9">theory</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">base</governor>
          <dependent id="10">on</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">base</governor>
          <dependent id="11">which</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">base</governor>
          <dependent id="12">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="9">theory</governor>
          <dependent id="13">base</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">forecast</governor>
          <dependent id="14">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">base</governor>
          <dependent id="15">forecast</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="24" has_coreference="false">
      <content>Prediction hinges on spotting anomalous phenomena, or precursors.</content>
      <tokens>
        <token id="1" string="Prediction" lemma="prediction" stem="predict" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="hinges" lemma="hinge" stem="hing" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="spotting" lemma="spot" stem="spot" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="anomalous" lemma="anomalous" stem="anomal" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="phenomena" lemma="phenomenon" stem="phenomena" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="precursors" lemma="precursor" stem="precursor" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NN Prediction)) (VP (VBZ hinges) (PP (IN on) (S (VP (VBG spotting) (NP (NP (JJ anomalous) (NNS phenomena)) (, ,) (CC or) (NP (NNS precursors))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="anomalous phenomena , or precursors" type="NP">
          <tokens>
            <token id="5" string="anomalous" />
            <token id="6" string="phenomena" />
            <token id="7" string="," />
            <token id="8" string="or" />
            <token id="9" string="precursors" />
          </tokens>
        </chunking>
        <chunking id="2" string="precursors" type="NP">
          <tokens>
            <token id="9" string="precursors" />
          </tokens>
        </chunking>
        <chunking id="3" string="Prediction" type="NP">
          <tokens>
            <token id="1" string="Prediction" />
          </tokens>
        </chunking>
        <chunking id="4" string="anomalous phenomena" type="NP">
          <tokens>
            <token id="5" string="anomalous" />
            <token id="6" string="phenomena" />
          </tokens>
        </chunking>
        <chunking id="5" string="hinges on spotting anomalous phenomena , or precursors" type="VP">
          <tokens>
            <token id="2" string="hinges" />
            <token id="3" string="on" />
            <token id="4" string="spotting" />
            <token id="5" string="anomalous" />
            <token id="6" string="phenomena" />
            <token id="7" string="," />
            <token id="8" string="or" />
            <token id="9" string="precursors" />
          </tokens>
        </chunking>
        <chunking id="6" string="spotting anomalous phenomena , or precursors" type="VP">
          <tokens>
            <token id="4" string="spotting" />
            <token id="5" string="anomalous" />
            <token id="6" string="phenomena" />
            <token id="7" string="," />
            <token id="8" string="or" />
            <token id="9" string="precursors" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">hinges</governor>
          <dependent id="1">Prediction</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">hinges</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="4">spotting</governor>
          <dependent id="3">on</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="2">hinges</governor>
          <dependent id="4">spotting</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">phenomena</governor>
          <dependent id="5">anomalous</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">spotting</governor>
          <dependent id="6">phenomena</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">phenomena</governor>
          <dependent id="8">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">phenomena</governor>
          <dependent id="9">precursors</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="25" has_coreference="true">
      <content>Unfortunately, it has proved impossible to conclude consistently and definitively whether the signspredictors look for - swarms of small earthquakes, unusual bulges and creeps in the earth&amp;apost;s crust, sudden changes in geomagnetism or electrical resistivity - are precursors or simply background geologic noise.</content>
      <tokens>
        <token id="1" string="Unfortunately" lemma="unfortunately" stem="unfortun" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="proved" lemma="prove" stem="prove" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="impossible" lemma="impossible" stem="imposs" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="conclude" lemma="conclude" stem="conclud" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="consistently" lemma="consistently" stem="consist" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="definitively" lemma="definitively" stem="definit" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="whether" lemma="whether" stem="whether" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="signspredictors" lemma="signspredictor" stem="signspredictor" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="look" lemma="look" stem="look" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="-" lemma="-" stem="-" pos=":" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="swarms" lemma="swarm" stem="swarm" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="small" lemma="small" stem="small" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="earthquakes" lemma="earthquake" stem="earthquak" pos="NNS" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="true" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="23" string="unusual" lemma="unusual" stem="unusu" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="bulges" lemma="bulge" stem="bulg" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="25" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="26" string="creeps" lemma="creep" stem="creep" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="27" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="28" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="29" string="earth" lemma="earth" stem="earth" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="30" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="31" string="crust" lemma="crust" stem="crust" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="32" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="33" string="sudden" lemma="sudden" stem="sudden" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="34" string="changes" lemma="change" stem="chang" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="35" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="36" string="geomagnetism" lemma="geomagnetism" stem="geomagnet" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="37" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="38" string="electrical" lemma="electrical" stem="electr" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="39" string="resistivity" lemma="resistivity" stem="resist" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="40" string="-" lemma="-" stem="-" pos=":" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="41" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="precursors" lemma="precursor" stem="precursor" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="simply" lemma="simply" stem="simpli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="45" string="background" lemma="background" stem="background" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="46" string="geologic" lemma="geologic" stem="geolog" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="47" string="noise" lemma="noise" stem="nois" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="48" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Unfortunately)) (, ,) (NP (PRP it)) (VP (VBZ has) (VP (VBN proved) (ADJP (JJ impossible) (S (VP (TO to) (VP (VB conclude) (ADVP (ADVP (RB consistently)) (CC and) (ADVP (RB definitively))) (SBAR (IN whether) (S (NP (DT the) (NNS signspredictors)) (VP (VBP look) (SBAR (IN for) (S (NP (PRN (: -) (NP (NP (NP (NNS swarms)) (PP (IN of) (NP (JJ small) (NNS earthquakes)))) (, ,) (NP (NP (JJ unusual) (NNS bulges) (CC and) (NNS creeps)) (PP (IN in) (NP (NP (DT the) (NN earth) (POS 's)) (NN crust)))) (, ,) (NP (NP (JJ sudden) (NNS changes)) (PP (IN in) (NP (NN geomagnetism) (CC or) (JJ electrical) (NN resistivity))))) (: -))) (VP (VBP are) (NP (NP (NNS precursors)) (CC or) (ADVP (RB simply)) (NP (NN background) (JJ geologic) (NN noise))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="whether the signspredictors look for - swarms of small earthquakes , unusual bulges and creeps in the earth 's crust , sudden changes in geomagnetism or electrical resistivity - are precursors or simply background geologic noise" type="SBAR">
          <tokens>
            <token id="12" string="whether" />
            <token id="13" string="the" />
            <token id="14" string="signspredictors" />
            <token id="15" string="look" />
            <token id="16" string="for" />
            <token id="17" string="-" />
            <token id="18" string="swarms" />
            <token id="19" string="of" />
            <token id="20" string="small" />
            <token id="21" string="earthquakes" />
            <token id="22" string="," />
            <token id="23" string="unusual" />
            <token id="24" string="bulges" />
            <token id="25" string="and" />
            <token id="26" string="creeps" />
            <token id="27" string="in" />
            <token id="28" string="the" />
            <token id="29" string="earth" />
            <token id="30" string="'s" />
            <token id="31" string="crust" />
            <token id="32" string="," />
            <token id="33" string="sudden" />
            <token id="34" string="changes" />
            <token id="35" string="in" />
            <token id="36" string="geomagnetism" />
            <token id="37" string="or" />
            <token id="38" string="electrical" />
            <token id="39" string="resistivity" />
            <token id="40" string="-" />
            <token id="41" string="are" />
            <token id="42" string="precursors" />
            <token id="43" string="or" />
            <token id="44" string="simply" />
            <token id="45" string="background" />
            <token id="46" string="geologic" />
            <token id="47" string="noise" />
          </tokens>
        </chunking>
        <chunking id="2" string="for - swarms of small earthquakes , unusual bulges and creeps in the earth 's crust , sudden changes in geomagnetism or electrical resistivity - are precursors or simply background geologic noise" type="SBAR">
          <tokens>
            <token id="16" string="for" />
            <token id="17" string="-" />
            <token id="18" string="swarms" />
            <token id="19" string="of" />
            <token id="20" string="small" />
            <token id="21" string="earthquakes" />
            <token id="22" string="," />
            <token id="23" string="unusual" />
            <token id="24" string="bulges" />
            <token id="25" string="and" />
            <token id="26" string="creeps" />
            <token id="27" string="in" />
            <token id="28" string="the" />
            <token id="29" string="earth" />
            <token id="30" string="'s" />
            <token id="31" string="crust" />
            <token id="32" string="," />
            <token id="33" string="sudden" />
            <token id="34" string="changes" />
            <token id="35" string="in" />
            <token id="36" string="geomagnetism" />
            <token id="37" string="or" />
            <token id="38" string="electrical" />
            <token id="39" string="resistivity" />
            <token id="40" string="-" />
            <token id="41" string="are" />
            <token id="42" string="precursors" />
            <token id="43" string="or" />
            <token id="44" string="simply" />
            <token id="45" string="background" />
            <token id="46" string="geologic" />
            <token id="47" string="noise" />
          </tokens>
        </chunking>
        <chunking id="3" string="proved impossible to conclude consistently and definitively whether the signspredictors look for - swarms of small earthquakes , unusual bulges and creeps in the earth 's crust , sudden changes in geomagnetism or electrical resistivity - are precursors or simply background geologic noise" type="VP">
          <tokens>
            <token id="5" string="proved" />
            <token id="6" string="impossible" />
            <token id="7" string="to" />
            <token id="8" string="conclude" />
            <token id="9" string="consistently" />
            <token id="10" string="and" />
            <token id="11" string="definitively" />
            <token id="12" string="whether" />
            <token id="13" string="the" />
            <token id="14" string="signspredictors" />
            <token id="15" string="look" />
            <token id="16" string="for" />
            <token id="17" string="-" />
            <token id="18" string="swarms" />
            <token id="19" string="of" />
            <token id="20" string="small" />
            <token id="21" string="earthquakes" />
            <token id="22" string="," />
            <token id="23" string="unusual" />
            <token id="24" string="bulges" />
            <token id="25" string="and" />
            <token id="26" string="creeps" />
            <token id="27" string="in" />
            <token id="28" string="the" />
            <token id="29" string="earth" />
            <token id="30" string="'s" />
            <token id="31" string="crust" />
            <token id="32" string="," />
            <token id="33" string="sudden" />
            <token id="34" string="changes" />
            <token id="35" string="in" />
            <token id="36" string="geomagnetism" />
            <token id="37" string="or" />
            <token id="38" string="electrical" />
            <token id="39" string="resistivity" />
            <token id="40" string="-" />
            <token id="41" string="are" />
            <token id="42" string="precursors" />
            <token id="43" string="or" />
            <token id="44" string="simply" />
            <token id="45" string="background" />
            <token id="46" string="geologic" />
            <token id="47" string="noise" />
          </tokens>
        </chunking>
        <chunking id="4" string="it" type="NP">
          <tokens>
            <token id="3" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="the earth 's crust" type="NP">
          <tokens>
            <token id="28" string="the" />
            <token id="29" string="earth" />
            <token id="30" string="'s" />
            <token id="31" string="crust" />
          </tokens>
        </chunking>
        <chunking id="6" string="conclude consistently and definitively whether the signspredictors look for - swarms of small earthquakes , unusual bulges and creeps in the earth 's crust , sudden changes in geomagnetism or electrical resistivity - are precursors or simply background geologic noise" type="VP">
          <tokens>
            <token id="8" string="conclude" />
            <token id="9" string="consistently" />
            <token id="10" string="and" />
            <token id="11" string="definitively" />
            <token id="12" string="whether" />
            <token id="13" string="the" />
            <token id="14" string="signspredictors" />
            <token id="15" string="look" />
            <token id="16" string="for" />
            <token id="17" string="-" />
            <token id="18" string="swarms" />
            <token id="19" string="of" />
            <token id="20" string="small" />
            <token id="21" string="earthquakes" />
            <token id="22" string="," />
            <token id="23" string="unusual" />
            <token id="24" string="bulges" />
            <token id="25" string="and" />
            <token id="26" string="creeps" />
            <token id="27" string="in" />
            <token id="28" string="the" />
            <token id="29" string="earth" />
            <token id="30" string="'s" />
            <token id="31" string="crust" />
            <token id="32" string="," />
            <token id="33" string="sudden" />
            <token id="34" string="changes" />
            <token id="35" string="in" />
            <token id="36" string="geomagnetism" />
            <token id="37" string="or" />
            <token id="38" string="electrical" />
            <token id="39" string="resistivity" />
            <token id="40" string="-" />
            <token id="41" string="are" />
            <token id="42" string="precursors" />
            <token id="43" string="or" />
            <token id="44" string="simply" />
            <token id="45" string="background" />
            <token id="46" string="geologic" />
            <token id="47" string="noise" />
          </tokens>
        </chunking>
        <chunking id="7" string="look for - swarms of small earthquakes , unusual bulges and creeps in the earth 's crust , sudden changes in geomagnetism or electrical resistivity - are precursors or simply background geologic noise" type="VP">
          <tokens>
            <token id="15" string="look" />
            <token id="16" string="for" />
            <token id="17" string="-" />
            <token id="18" string="swarms" />
            <token id="19" string="of" />
            <token id="20" string="small" />
            <token id="21" string="earthquakes" />
            <token id="22" string="," />
            <token id="23" string="unusual" />
            <token id="24" string="bulges" />
            <token id="25" string="and" />
            <token id="26" string="creeps" />
            <token id="27" string="in" />
            <token id="28" string="the" />
            <token id="29" string="earth" />
            <token id="30" string="'s" />
            <token id="31" string="crust" />
            <token id="32" string="," />
            <token id="33" string="sudden" />
            <token id="34" string="changes" />
            <token id="35" string="in" />
            <token id="36" string="geomagnetism" />
            <token id="37" string="or" />
            <token id="38" string="electrical" />
            <token id="39" string="resistivity" />
            <token id="40" string="-" />
            <token id="41" string="are" />
            <token id="42" string="precursors" />
            <token id="43" string="or" />
            <token id="44" string="simply" />
            <token id="45" string="background" />
            <token id="46" string="geologic" />
            <token id="47" string="noise" />
          </tokens>
        </chunking>
        <chunking id="8" string="sudden changes" type="NP">
          <tokens>
            <token id="33" string="sudden" />
            <token id="34" string="changes" />
          </tokens>
        </chunking>
        <chunking id="9" string="geomagnetism or electrical resistivity" type="NP">
          <tokens>
            <token id="36" string="geomagnetism" />
            <token id="37" string="or" />
            <token id="38" string="electrical" />
            <token id="39" string="resistivity" />
          </tokens>
        </chunking>
        <chunking id="10" string="precursors or simply background geologic noise" type="NP">
          <tokens>
            <token id="42" string="precursors" />
            <token id="43" string="or" />
            <token id="44" string="simply" />
            <token id="45" string="background" />
            <token id="46" string="geologic" />
            <token id="47" string="noise" />
          </tokens>
        </chunking>
        <chunking id="11" string="unusual bulges and creeps" type="NP">
          <tokens>
            <token id="23" string="unusual" />
            <token id="24" string="bulges" />
            <token id="25" string="and" />
            <token id="26" string="creeps" />
          </tokens>
        </chunking>
        <chunking id="12" string="swarms" type="NP">
          <tokens>
            <token id="18" string="swarms" />
          </tokens>
        </chunking>
        <chunking id="13" string="swarms of small earthquakes , unusual bulges and creeps in the earth 's crust , sudden changes in geomagnetism or electrical resistivity" type="NP">
          <tokens>
            <token id="18" string="swarms" />
            <token id="19" string="of" />
            <token id="20" string="small" />
            <token id="21" string="earthquakes" />
            <token id="22" string="," />
            <token id="23" string="unusual" />
            <token id="24" string="bulges" />
            <token id="25" string="and" />
            <token id="26" string="creeps" />
            <token id="27" string="in" />
            <token id="28" string="the" />
            <token id="29" string="earth" />
            <token id="30" string="'s" />
            <token id="31" string="crust" />
            <token id="32" string="," />
            <token id="33" string="sudden" />
            <token id="34" string="changes" />
            <token id="35" string="in" />
            <token id="36" string="geomagnetism" />
            <token id="37" string="or" />
            <token id="38" string="electrical" />
            <token id="39" string="resistivity" />
          </tokens>
        </chunking>
        <chunking id="14" string="sudden changes in geomagnetism or electrical resistivity" type="NP">
          <tokens>
            <token id="33" string="sudden" />
            <token id="34" string="changes" />
            <token id="35" string="in" />
            <token id="36" string="geomagnetism" />
            <token id="37" string="or" />
            <token id="38" string="electrical" />
            <token id="39" string="resistivity" />
          </tokens>
        </chunking>
        <chunking id="15" string="precursors" type="NP">
          <tokens>
            <token id="42" string="precursors" />
          </tokens>
        </chunking>
        <chunking id="16" string="has proved impossible to conclude consistently and definitively whether the signspredictors look for - swarms of small earthquakes , unusual bulges and creeps in the earth 's crust , sudden changes in geomagnetism or electrical resistivity - are precursors or simply background geologic noise" type="VP">
          <tokens>
            <token id="4" string="has" />
            <token id="5" string="proved" />
            <token id="6" string="impossible" />
            <token id="7" string="to" />
            <token id="8" string="conclude" />
            <token id="9" string="consistently" />
            <token id="10" string="and" />
            <token id="11" string="definitively" />
            <token id="12" string="whether" />
            <token id="13" string="the" />
            <token id="14" string="signspredictors" />
            <token id="15" string="look" />
            <token id="16" string="for" />
            <token id="17" string="-" />
            <token id="18" string="swarms" />
            <token id="19" string="of" />
            <token id="20" string="small" />
            <token id="21" string="earthquakes" />
            <token id="22" string="," />
            <token id="23" string="unusual" />
            <token id="24" string="bulges" />
            <token id="25" string="and" />
            <token id="26" string="creeps" />
            <token id="27" string="in" />
            <token id="28" string="the" />
            <token id="29" string="earth" />
            <token id="30" string="'s" />
            <token id="31" string="crust" />
            <token id="32" string="," />
            <token id="33" string="sudden" />
            <token id="34" string="changes" />
            <token id="35" string="in" />
            <token id="36" string="geomagnetism" />
            <token id="37" string="or" />
            <token id="38" string="electrical" />
            <token id="39" string="resistivity" />
            <token id="40" string="-" />
            <token id="41" string="are" />
            <token id="42" string="precursors" />
            <token id="43" string="or" />
            <token id="44" string="simply" />
            <token id="45" string="background" />
            <token id="46" string="geologic" />
            <token id="47" string="noise" />
          </tokens>
        </chunking>
        <chunking id="17" string="swarms of small earthquakes" type="NP">
          <tokens>
            <token id="18" string="swarms" />
            <token id="19" string="of" />
            <token id="20" string="small" />
            <token id="21" string="earthquakes" />
          </tokens>
        </chunking>
        <chunking id="18" string="small earthquakes" type="NP">
          <tokens>
            <token id="20" string="small" />
            <token id="21" string="earthquakes" />
          </tokens>
        </chunking>
        <chunking id="19" string="impossible to conclude consistently and definitively whether the signspredictors look for - swarms of small earthquakes , unusual bulges and creeps in the earth 's crust , sudden changes in geomagnetism or electrical resistivity - are precursors or simply background geologic noise" type="ADJP">
          <tokens>
            <token id="6" string="impossible" />
            <token id="7" string="to" />
            <token id="8" string="conclude" />
            <token id="9" string="consistently" />
            <token id="10" string="and" />
            <token id="11" string="definitively" />
            <token id="12" string="whether" />
            <token id="13" string="the" />
            <token id="14" string="signspredictors" />
            <token id="15" string="look" />
            <token id="16" string="for" />
            <token id="17" string="-" />
            <token id="18" string="swarms" />
            <token id="19" string="of" />
            <token id="20" string="small" />
            <token id="21" string="earthquakes" />
            <token id="22" string="," />
            <token id="23" string="unusual" />
            <token id="24" string="bulges" />
            <token id="25" string="and" />
            <token id="26" string="creeps" />
            <token id="27" string="in" />
            <token id="28" string="the" />
            <token id="29" string="earth" />
            <token id="30" string="'s" />
            <token id="31" string="crust" />
            <token id="32" string="," />
            <token id="33" string="sudden" />
            <token id="34" string="changes" />
            <token id="35" string="in" />
            <token id="36" string="geomagnetism" />
            <token id="37" string="or" />
            <token id="38" string="electrical" />
            <token id="39" string="resistivity" />
            <token id="40" string="-" />
            <token id="41" string="are" />
            <token id="42" string="precursors" />
            <token id="43" string="or" />
            <token id="44" string="simply" />
            <token id="45" string="background" />
            <token id="46" string="geologic" />
            <token id="47" string="noise" />
          </tokens>
        </chunking>
        <chunking id="20" string="the earth 's" type="NP">
          <tokens>
            <token id="28" string="the" />
            <token id="29" string="earth" />
            <token id="30" string="'s" />
          </tokens>
        </chunking>
        <chunking id="21" string="- swarms of small earthquakes , unusual bulges and creeps in the earth 's crust , sudden changes in geomagnetism or electrical resistivity -" type="NP">
          <tokens>
            <token id="17" string="-" />
            <token id="18" string="swarms" />
            <token id="19" string="of" />
            <token id="20" string="small" />
            <token id="21" string="earthquakes" />
            <token id="22" string="," />
            <token id="23" string="unusual" />
            <token id="24" string="bulges" />
            <token id="25" string="and" />
            <token id="26" string="creeps" />
            <token id="27" string="in" />
            <token id="28" string="the" />
            <token id="29" string="earth" />
            <token id="30" string="'s" />
            <token id="31" string="crust" />
            <token id="32" string="," />
            <token id="33" string="sudden" />
            <token id="34" string="changes" />
            <token id="35" string="in" />
            <token id="36" string="geomagnetism" />
            <token id="37" string="or" />
            <token id="38" string="electrical" />
            <token id="39" string="resistivity" />
            <token id="40" string="-" />
          </tokens>
        </chunking>
        <chunking id="22" string="are precursors or simply background geologic noise" type="VP">
          <tokens>
            <token id="41" string="are" />
            <token id="42" string="precursors" />
            <token id="43" string="or" />
            <token id="44" string="simply" />
            <token id="45" string="background" />
            <token id="46" string="geologic" />
            <token id="47" string="noise" />
          </tokens>
        </chunking>
        <chunking id="23" string="background geologic noise" type="NP">
          <tokens>
            <token id="45" string="background" />
            <token id="46" string="geologic" />
            <token id="47" string="noise" />
          </tokens>
        </chunking>
        <chunking id="24" string="to conclude consistently and definitively whether the signspredictors look for - swarms of small earthquakes , unusual bulges and creeps in the earth 's crust , sudden changes in geomagnetism or electrical resistivity - are precursors or simply background geologic noise" type="VP">
          <tokens>
            <token id="7" string="to" />
            <token id="8" string="conclude" />
            <token id="9" string="consistently" />
            <token id="10" string="and" />
            <token id="11" string="definitively" />
            <token id="12" string="whether" />
            <token id="13" string="the" />
            <token id="14" string="signspredictors" />
            <token id="15" string="look" />
            <token id="16" string="for" />
            <token id="17" string="-" />
            <token id="18" string="swarms" />
            <token id="19" string="of" />
            <token id="20" string="small" />
            <token id="21" string="earthquakes" />
            <token id="22" string="," />
            <token id="23" string="unusual" />
            <token id="24" string="bulges" />
            <token id="25" string="and" />
            <token id="26" string="creeps" />
            <token id="27" string="in" />
            <token id="28" string="the" />
            <token id="29" string="earth" />
            <token id="30" string="'s" />
            <token id="31" string="crust" />
            <token id="32" string="," />
            <token id="33" string="sudden" />
            <token id="34" string="changes" />
            <token id="35" string="in" />
            <token id="36" string="geomagnetism" />
            <token id="37" string="or" />
            <token id="38" string="electrical" />
            <token id="39" string="resistivity" />
            <token id="40" string="-" />
            <token id="41" string="are" />
            <token id="42" string="precursors" />
            <token id="43" string="or" />
            <token id="44" string="simply" />
            <token id="45" string="background" />
            <token id="46" string="geologic" />
            <token id="47" string="noise" />
          </tokens>
        </chunking>
        <chunking id="25" string="unusual bulges and creeps in the earth 's crust" type="NP">
          <tokens>
            <token id="23" string="unusual" />
            <token id="24" string="bulges" />
            <token id="25" string="and" />
            <token id="26" string="creeps" />
            <token id="27" string="in" />
            <token id="28" string="the" />
            <token id="29" string="earth" />
            <token id="30" string="'s" />
            <token id="31" string="crust" />
          </tokens>
        </chunking>
        <chunking id="26" string="the signspredictors" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="signspredictors" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="5">proved</governor>
          <dependent id="1">Unfortunately</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">proved</governor>
          <dependent id="3">it</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">proved</governor>
          <dependent id="4">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">proved</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">proved</governor>
          <dependent id="6">impossible</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">conclude</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">impossible</governor>
          <dependent id="8">conclude</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">and</governor>
          <dependent id="9">consistently</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">conclude</governor>
          <dependent id="10">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">and</governor>
          <dependent id="11">definitively</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">look</governor>
          <dependent id="12">whether</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">signspredictors</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">look</governor>
          <dependent id="14">signspredictors</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="8">conclude</governor>
          <dependent id="15">look</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="42">precursors</governor>
          <dependent id="16">for</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="42">precursors</governor>
          <dependent id="18">swarms</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">earthquakes</governor>
          <dependent id="19">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">earthquakes</governor>
          <dependent id="20">small</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">swarms</governor>
          <dependent id="21">earthquakes</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">bulges</governor>
          <dependent id="23">unusual</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="18">swarms</governor>
          <dependent id="24">bulges</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="24">bulges</governor>
          <dependent id="25">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="24">bulges</governor>
          <dependent id="26">creeps</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">crust</governor>
          <dependent id="27">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">earth</governor>
          <dependent id="28">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="31">crust</governor>
          <dependent id="29">earth</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">earth</governor>
          <dependent id="30">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">bulges</governor>
          <dependent id="31">crust</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="34">changes</governor>
          <dependent id="33">sudden</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="18">swarms</governor>
          <dependent id="34">changes</dependent>
        </dependency>
        <dependency type="case">
          <governor id="39">resistivity</governor>
          <dependent id="35">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="39">resistivity</governor>
          <dependent id="36">geomagnetism</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="36">geomagnetism</governor>
          <dependent id="37">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="36">geomagnetism</governor>
          <dependent id="38">electrical</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="34">changes</governor>
          <dependent id="39">resistivity</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="42">precursors</governor>
          <dependent id="41">are</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="15">look</governor>
          <dependent id="42">precursors</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="42">precursors</governor>
          <dependent id="43">or</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="47">noise</governor>
          <dependent id="44">simply</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="47">noise</governor>
          <dependent id="45">background</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="47">noise</governor>
          <dependent id="46">geologic</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="42">precursors</governor>
          <dependent id="47">noise</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="earthquakes" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="21" string="earthquakes" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="26" has_coreference="false">
      <content>Precursors are often only recognised as such after a large earthquake.</content>
      <tokens>
        <token id="1" string="Precursors" lemma="precursor" stem="precursor" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="often" lemma="often" stem="often" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="only" lemma="only" stem="onli" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="recognised" lemma="recognise" stem="recognis" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="such" lemma="such" stem="such" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="large" lemma="large" stem="larg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="earthquake" lemma="earthquake" stem="earthquak" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNS Precursors)) (SBAR (S (VP (VBP are) (ADVP (RB often)) (ADVP (RB only)))))) (VP (VBD recognised) (PP (IN as) (NP (JJ such))) (PP (IN after) (NP (DT a) (JJ large) (NN earthquake)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="recognised as such after a large earthquake" type="VP">
          <tokens>
            <token id="5" string="recognised" />
            <token id="6" string="as" />
            <token id="7" string="such" />
            <token id="8" string="after" />
            <token id="9" string="a" />
            <token id="10" string="large" />
            <token id="11" string="earthquake" />
          </tokens>
        </chunking>
        <chunking id="2" string="such" type="NP">
          <tokens>
            <token id="7" string="such" />
          </tokens>
        </chunking>
        <chunking id="3" string="Precursors are often only" type="NP">
          <tokens>
            <token id="1" string="Precursors" />
            <token id="2" string="are" />
            <token id="3" string="often" />
            <token id="4" string="only" />
          </tokens>
        </chunking>
        <chunking id="4" string="are often only" type="SBAR">
          <tokens>
            <token id="2" string="are" />
            <token id="3" string="often" />
            <token id="4" string="only" />
          </tokens>
        </chunking>
        <chunking id="5" string="Precursors" type="NP">
          <tokens>
            <token id="1" string="Precursors" />
          </tokens>
        </chunking>
        <chunking id="6" string="a large earthquake" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="large" />
            <token id="11" string="earthquake" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">recognised</governor>
          <dependent id="1">Precursors</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="1">Precursors</governor>
          <dependent id="2">are</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="2">are</governor>
          <dependent id="3">often</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="2">are</governor>
          <dependent id="4">only</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">recognised</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">such</governor>
          <dependent id="6">as</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">recognised</governor>
          <dependent id="7">such</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">earthquake</governor>
          <dependent id="8">after</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">earthquake</governor>
          <dependent id="9">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">earthquake</governor>
          <dependent id="10">large</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">recognised</governor>
          <dependent id="11">earthquake</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="earthquake" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="11" string="earthquake" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="27" has_coreference="false">
      <content>And many earthquakes occur without any identifiable precursor, even in retrospect.</content>
      <tokens>
        <token id="1" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="many" lemma="many" stem="mani" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="earthquakes" lemma="earthquake" stem="earthquak" pos="NNS" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="4" string="occur" lemma="occur" stem="occur" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="without" lemma="without" stem="without" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="any" lemma="any" stem="ani" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="identifiable" lemma="identifiable" stem="identifi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="precursor" lemma="precursor" stem="precursor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="retrospect" lemma="retrospect" stem="retrospect" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC And) (NP (JJ many) (NNS earthquakes)) (VP (VBP occur) (PP (PP (IN without) (NP (DT any) (JJ identifiable) (NN precursor))) (, ,) (RB even) (PP (IN in) (NP (NN retrospect))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="any identifiable precursor" type="NP">
          <tokens>
            <token id="6" string="any" />
            <token id="7" string="identifiable" />
            <token id="8" string="precursor" />
          </tokens>
        </chunking>
        <chunking id="2" string="many earthquakes" type="NP">
          <tokens>
            <token id="2" string="many" />
            <token id="3" string="earthquakes" />
          </tokens>
        </chunking>
        <chunking id="3" string="occur without any identifiable precursor , even in retrospect" type="VP">
          <tokens>
            <token id="4" string="occur" />
            <token id="5" string="without" />
            <token id="6" string="any" />
            <token id="7" string="identifiable" />
            <token id="8" string="precursor" />
            <token id="9" string="," />
            <token id="10" string="even" />
            <token id="11" string="in" />
            <token id="12" string="retrospect" />
          </tokens>
        </chunking>
        <chunking id="4" string="retrospect" type="NP">
          <tokens>
            <token id="12" string="retrospect" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="4">occur</governor>
          <dependent id="1">And</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">earthquakes</governor>
          <dependent id="2">many</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">occur</governor>
          <dependent id="3">earthquakes</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">occur</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">precursor</governor>
          <dependent id="5">without</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">precursor</governor>
          <dependent id="6">any</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">precursor</governor>
          <dependent id="7">identifiable</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">occur</governor>
          <dependent id="8">precursor</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="8">precursor</governor>
          <dependent id="10">even</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">retrospect</governor>
          <dependent id="11">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">precursor</governor>
          <dependent id="12">retrospect</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="earthquakes" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="3" string="earthquakes" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="28" has_coreference="false">
      <content>There are also questions as to whether Japan&amp;apost;s monitoring efforts are focused in the right place.</content>
      <tokens>
        <token id="1" string="There" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="questions" lemma="question" stem="question" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="whether" lemma="whether" stem="whether" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="Japan" lemma="Japan" stem="japan" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="9" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="monitoring" lemma="monitoring" stem="monitor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="efforts" lemma="effort" stem="effort" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="focused" lemma="focus" stem="focus" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="right" lemma="right" stem="right" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="17" string="place" lemma="place" stem="place" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (EX There)) (VP (VBP are) (ADVP (RB also)) (NP (NP (NNS questions)) (PP (IN as) (TO to) (SBAR (IN whether) (S (NP (NP (NNP Japan) (POS 's)) (NN monitoring) (NNS efforts)) (VP (VBP are) (VP (VBN focused) (PP (IN in) (NP (DT the) (JJ right) (NN place)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="are also questions as to whether Japan 's monitoring efforts are focused in the right place" type="VP">
          <tokens>
            <token id="2" string="are" />
            <token id="3" string="also" />
            <token id="4" string="questions" />
            <token id="5" string="as" />
            <token id="6" string="to" />
            <token id="7" string="whether" />
            <token id="8" string="Japan" />
            <token id="9" string="'s" />
            <token id="10" string="monitoring" />
            <token id="11" string="efforts" />
            <token id="12" string="are" />
            <token id="13" string="focused" />
            <token id="14" string="in" />
            <token id="15" string="the" />
            <token id="16" string="right" />
            <token id="17" string="place" />
          </tokens>
        </chunking>
        <chunking id="2" string="There" type="NP">
          <tokens>
            <token id="1" string="There" />
          </tokens>
        </chunking>
        <chunking id="3" string="whether Japan 's monitoring efforts are focused in the right place" type="SBAR">
          <tokens>
            <token id="7" string="whether" />
            <token id="8" string="Japan" />
            <token id="9" string="'s" />
            <token id="10" string="monitoring" />
            <token id="11" string="efforts" />
            <token id="12" string="are" />
            <token id="13" string="focused" />
            <token id="14" string="in" />
            <token id="15" string="the" />
            <token id="16" string="right" />
            <token id="17" string="place" />
          </tokens>
        </chunking>
        <chunking id="4" string="the right place" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="right" />
            <token id="17" string="place" />
          </tokens>
        </chunking>
        <chunking id="5" string="are focused in the right place" type="VP">
          <tokens>
            <token id="12" string="are" />
            <token id="13" string="focused" />
            <token id="14" string="in" />
            <token id="15" string="the" />
            <token id="16" string="right" />
            <token id="17" string="place" />
          </tokens>
        </chunking>
        <chunking id="6" string="Japan 's monitoring efforts" type="NP">
          <tokens>
            <token id="8" string="Japan" />
            <token id="9" string="'s" />
            <token id="10" string="monitoring" />
            <token id="11" string="efforts" />
          </tokens>
        </chunking>
        <chunking id="7" string="questions as to whether Japan 's monitoring efforts are focused in the right place" type="NP">
          <tokens>
            <token id="4" string="questions" />
            <token id="5" string="as" />
            <token id="6" string="to" />
            <token id="7" string="whether" />
            <token id="8" string="Japan" />
            <token id="9" string="'s" />
            <token id="10" string="monitoring" />
            <token id="11" string="efforts" />
            <token id="12" string="are" />
            <token id="13" string="focused" />
            <token id="14" string="in" />
            <token id="15" string="the" />
            <token id="16" string="right" />
            <token id="17" string="place" />
          </tokens>
        </chunking>
        <chunking id="8" string="questions" type="NP">
          <tokens>
            <token id="4" string="questions" />
          </tokens>
        </chunking>
        <chunking id="9" string="focused in the right place" type="VP">
          <tokens>
            <token id="13" string="focused" />
            <token id="14" string="in" />
            <token id="15" string="the" />
            <token id="16" string="right" />
            <token id="17" string="place" />
          </tokens>
        </chunking>
        <chunking id="10" string="Japan 's" type="NP">
          <tokens>
            <token id="8" string="Japan" />
            <token id="9" string="'s" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="expl">
          <governor id="2">are</governor>
          <dependent id="1">There</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">are</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="2">are</governor>
          <dependent id="3">also</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="2">are</governor>
          <dependent id="4">questions</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">focused</governor>
          <dependent id="5">as</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="5">as</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">focused</governor>
          <dependent id="7">whether</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">efforts</governor>
          <dependent id="8">Japan</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">Japan</governor>
          <dependent id="9">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">efforts</governor>
          <dependent id="10">monitoring</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="13">focused</governor>
          <dependent id="11">efforts</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="13">focused</governor>
          <dependent id="12">are</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="4">questions</governor>
          <dependent id="13">focused</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">place</governor>
          <dependent id="14">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">place</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">place</governor>
          <dependent id="16">right</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">focused</governor>
          <dependent id="17">place</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Japan" type="LOCATION" score="0.0">
          <tokens>
            <token id="8" string="Japan" />
          </tokens>
        </entity>
        <entity id="2" string="right" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="16" string="right" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="29" has_coreference="true">
      <content>Recent studies by seismologists at the Ministry of Construction have indicated the possibility of a significant quake occurring in the Izu area between Tokai and Tokyo.</content>
      <tokens>
        <token id="1" string="Recent" lemma="recent" stem="recent" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="studies" lemma="study" stem="studi" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="seismologists" lemma="seismologist" stem="seismologist" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Ministry" lemma="Ministry" stem="ministri" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="9" string="Construction" lemma="Construction" stem="construct" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="10" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="indicated" lemma="indicate" stem="indic" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="possibility" lemma="possibility" stem="possibl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="significant" lemma="significant" stem="signific" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="quake" lemma="quake" stem="quak" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="occurring" lemma="occur" stem="occur" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="Izu" lemma="Izu" stem="izu" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="22" string="area" lemma="area" stem="area" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="between" lemma="between" stem="between" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="Tokai" lemma="Tokai" stem="tokai" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="25" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="Tokyo" lemma="Tokyo" stem="tokyo" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (JJ Recent) (NNS studies)) (PP (IN by) (NP (NP (NNS seismologists)) (PP (IN at) (NP (NP (DT the) (NNP Ministry)) (PP (IN of) (NP (NNP Construction)))))))) (VP (VBP have) (VP (VBN indicated) (NP (NP (DT the) (NN possibility)) (PP (IN of) (NP (NP (DT a) (JJ significant) (NN quake)) (VP (VBG occurring) (PP (IN in) (NP (NP (DT the) (NNP Izu) (NN area)) (PP (IN between) (NP (NNP Tokai) (CC and) (NNP Tokyo))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="occurring in the Izu area between Tokai and Tokyo" type="VP">
          <tokens>
            <token id="18" string="occurring" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="Izu" />
            <token id="22" string="area" />
            <token id="23" string="between" />
            <token id="24" string="Tokai" />
            <token id="25" string="and" />
            <token id="26" string="Tokyo" />
          </tokens>
        </chunking>
        <chunking id="2" string="a significant quake" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="significant" />
            <token id="17" string="quake" />
          </tokens>
        </chunking>
        <chunking id="3" string="Construction" type="NP">
          <tokens>
            <token id="9" string="Construction" />
          </tokens>
        </chunking>
        <chunking id="4" string="the Izu area" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="Izu" />
            <token id="22" string="area" />
          </tokens>
        </chunking>
        <chunking id="5" string="seismologists" type="NP">
          <tokens>
            <token id="4" string="seismologists" />
          </tokens>
        </chunking>
        <chunking id="6" string="have indicated the possibility of a significant quake occurring in the Izu area between Tokai and Tokyo" type="VP">
          <tokens>
            <token id="10" string="have" />
            <token id="11" string="indicated" />
            <token id="12" string="the" />
            <token id="13" string="possibility" />
            <token id="14" string="of" />
            <token id="15" string="a" />
            <token id="16" string="significant" />
            <token id="17" string="quake" />
            <token id="18" string="occurring" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="Izu" />
            <token id="22" string="area" />
            <token id="23" string="between" />
            <token id="24" string="Tokai" />
            <token id="25" string="and" />
            <token id="26" string="Tokyo" />
          </tokens>
        </chunking>
        <chunking id="7" string="the Ministry" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="Ministry" />
          </tokens>
        </chunking>
        <chunking id="8" string="a significant quake occurring in the Izu area between Tokai and Tokyo" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="significant" />
            <token id="17" string="quake" />
            <token id="18" string="occurring" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="Izu" />
            <token id="22" string="area" />
            <token id="23" string="between" />
            <token id="24" string="Tokai" />
            <token id="25" string="and" />
            <token id="26" string="Tokyo" />
          </tokens>
        </chunking>
        <chunking id="9" string="Recent studies by seismologists at the Ministry of Construction" type="NP">
          <tokens>
            <token id="1" string="Recent" />
            <token id="2" string="studies" />
            <token id="3" string="by" />
            <token id="4" string="seismologists" />
            <token id="5" string="at" />
            <token id="6" string="the" />
            <token id="7" string="Ministry" />
            <token id="8" string="of" />
            <token id="9" string="Construction" />
          </tokens>
        </chunking>
        <chunking id="10" string="the Ministry of Construction" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="Ministry" />
            <token id="8" string="of" />
            <token id="9" string="Construction" />
          </tokens>
        </chunking>
        <chunking id="11" string="the Izu area between Tokai and Tokyo" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="Izu" />
            <token id="22" string="area" />
            <token id="23" string="between" />
            <token id="24" string="Tokai" />
            <token id="25" string="and" />
            <token id="26" string="Tokyo" />
          </tokens>
        </chunking>
        <chunking id="12" string="seismologists at the Ministry of Construction" type="NP">
          <tokens>
            <token id="4" string="seismologists" />
            <token id="5" string="at" />
            <token id="6" string="the" />
            <token id="7" string="Ministry" />
            <token id="8" string="of" />
            <token id="9" string="Construction" />
          </tokens>
        </chunking>
        <chunking id="13" string="Tokai and Tokyo" type="NP">
          <tokens>
            <token id="24" string="Tokai" />
            <token id="25" string="and" />
            <token id="26" string="Tokyo" />
          </tokens>
        </chunking>
        <chunking id="14" string="the possibility of a significant quake occurring in the Izu area between Tokai and Tokyo" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="possibility" />
            <token id="14" string="of" />
            <token id="15" string="a" />
            <token id="16" string="significant" />
            <token id="17" string="quake" />
            <token id="18" string="occurring" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="Izu" />
            <token id="22" string="area" />
            <token id="23" string="between" />
            <token id="24" string="Tokai" />
            <token id="25" string="and" />
            <token id="26" string="Tokyo" />
          </tokens>
        </chunking>
        <chunking id="15" string="the possibility" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="possibility" />
          </tokens>
        </chunking>
        <chunking id="16" string="indicated the possibility of a significant quake occurring in the Izu area between Tokai and Tokyo" type="VP">
          <tokens>
            <token id="11" string="indicated" />
            <token id="12" string="the" />
            <token id="13" string="possibility" />
            <token id="14" string="of" />
            <token id="15" string="a" />
            <token id="16" string="significant" />
            <token id="17" string="quake" />
            <token id="18" string="occurring" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="Izu" />
            <token id="22" string="area" />
            <token id="23" string="between" />
            <token id="24" string="Tokai" />
            <token id="25" string="and" />
            <token id="26" string="Tokyo" />
          </tokens>
        </chunking>
        <chunking id="17" string="Recent studies" type="NP">
          <tokens>
            <token id="1" string="Recent" />
            <token id="2" string="studies" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="2">studies</governor>
          <dependent id="1">Recent</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">indicated</governor>
          <dependent id="2">studies</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">seismologists</governor>
          <dependent id="3">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">studies</governor>
          <dependent id="4">seismologists</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">Ministry</governor>
          <dependent id="5">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">Ministry</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">seismologists</governor>
          <dependent id="7">Ministry</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Construction</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">Ministry</governor>
          <dependent id="9">Construction</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">indicated</governor>
          <dependent id="10">have</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">indicated</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">possibility</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">indicated</governor>
          <dependent id="13">possibility</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">quake</governor>
          <dependent id="14">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">quake</governor>
          <dependent id="15">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">quake</governor>
          <dependent id="16">significant</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">possibility</governor>
          <dependent id="17">quake</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="17">quake</governor>
          <dependent id="18">occurring</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">area</governor>
          <dependent id="19">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">area</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">area</governor>
          <dependent id="21">Izu</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">occurring</governor>
          <dependent id="22">area</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">Tokai</governor>
          <dependent id="23">between</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">area</governor>
          <dependent id="24">Tokai</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="24">Tokai</governor>
          <dependent id="25">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="24">Tokai</governor>
          <dependent id="26">Tokyo</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Izu" type="LOCATION" score="0.0">
          <tokens>
            <token id="21" string="Izu" />
          </tokens>
        </entity>
        <entity id="2" string="Ministry of Construction" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="7" string="Ministry" />
            <token id="8" string="of" />
            <token id="9" string="Construction" />
          </tokens>
        </entity>
        <entity id="3" string="Tokai" type="LOCATION" score="0.0">
          <tokens>
            <token id="24" string="Tokai" />
          </tokens>
        </entity>
        <entity id="4" string="Tokyo" type="LOCATION" score="0.0">
          <tokens>
            <token id="26" string="Tokyo" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="30" has_coreference="false">
      <content>The city is overdue for a big quake, according to several theories.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="city" lemma="city" stem="citi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="overdue" lemma="overdue" stem="overdu" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="big" lemma="big" stem="big" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="quake" lemma="quake" stem="quak" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="according" lemma="accord" stem="accord" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="several" lemma="several" stem="sever" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="theories" lemma="theory" stem="theori" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN city)) (VP (VBZ is) (ADJP (JJ overdue) (PP (IN for) (NP (DT a) (JJ big) (NN quake)))) (, ,) (PP (VBG according) (PP (TO to) (NP (JJ several) (NNS theories))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="is overdue for a big quake , according to several theories" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="overdue" />
            <token id="5" string="for" />
            <token id="6" string="a" />
            <token id="7" string="big" />
            <token id="8" string="quake" />
            <token id="9" string="," />
            <token id="10" string="according" />
            <token id="11" string="to" />
            <token id="12" string="several" />
            <token id="13" string="theories" />
          </tokens>
        </chunking>
        <chunking id="2" string="a big quake" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="big" />
            <token id="8" string="quake" />
          </tokens>
        </chunking>
        <chunking id="3" string="several theories" type="NP">
          <tokens>
            <token id="12" string="several" />
            <token id="13" string="theories" />
          </tokens>
        </chunking>
        <chunking id="4" string="The city" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="city" />
          </tokens>
        </chunking>
        <chunking id="5" string="overdue for a big quake" type="ADJP">
          <tokens>
            <token id="4" string="overdue" />
            <token id="5" string="for" />
            <token id="6" string="a" />
            <token id="7" string="big" />
            <token id="8" string="quake" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">city</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">overdue</governor>
          <dependent id="2">city</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">overdue</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">overdue</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">quake</governor>
          <dependent id="5">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">quake</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">quake</governor>
          <dependent id="7">big</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">overdue</governor>
          <dependent id="8">quake</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">theories</governor>
          <dependent id="10">according</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="10">according</governor>
          <dependent id="11">to</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">theories</governor>
          <dependent id="12">several</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">overdue</governor>
          <dependent id="13">theories</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="31" has_coreference="true">
      <content>Japan has had numerous killer quakes outside the Tokai monitoring network, including a 7.8 earthquake off the coast of Hokkaido last year that claimed more than 200 lives.</content>
      <tokens>
        <token id="1" string="Japan" lemma="Japan" stem="japan" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="2" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="had" lemma="have" stem="had" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="numerous" lemma="numerous" stem="numer" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="killer" lemma="killer" stem="killer" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="quakes" lemma="quake" stem="quak" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="outside" lemma="outside" stem="outsid" pos="IN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="Tokai" lemma="Tokai" stem="tokai" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="10" string="monitoring" lemma="monitoring" stem="monitor" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="network" lemma="network" stem="network" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="including" lemma="include" stem="includ" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="7.8" lemma="7.8" stem="7.8" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="16" string="earthquake" lemma="earthquake" stem="earthquak" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="true" is_refers="false" />
        <token id="17" string="off" lemma="off" stem="off" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="coast" lemma="coast" stem="coast" pos="NN" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="20" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="21" string="Hokkaido" lemma="Hokkaido" stem="hokkaido" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="22" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="23" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="24" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="25" string="claimed" lemma="claim" stem="claim" pos="VBD" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="26" string="more" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="27" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="28" string="200" lemma="200" stem="200" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="29" string="lives" lemma="life" stem="live" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Japan)) (VP (VBZ has) (VP (VBN had) (NP (NP (JJ numerous) (NN killer) (NNS quakes)) (PP (IN outside) (NP (DT the) (NNP Tokai) (NN monitoring) (NN network))) (, ,) (PP (VBG including) (NP (NP (DT a) (CD 7.8) (NN earthquake)) (PP (IN off) (NP (NP (DT the) (NN coast)) (PP (IN of) (NP (NNP Hokkaido))) (NP-TMP (JJ last) (NN year)) (SBAR (WHNP (IN that)) (S (VP (VBD claimed) (NP-TMP (QP (JJR more) (IN than) (CD 200)) (NNS lives)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="had numerous killer quakes outside the Tokai monitoring network , including a 7.8 earthquake off the coast of Hokkaido last year that claimed more than 200 lives" type="VP">
          <tokens>
            <token id="3" string="had" />
            <token id="4" string="numerous" />
            <token id="5" string="killer" />
            <token id="6" string="quakes" />
            <token id="7" string="outside" />
            <token id="8" string="the" />
            <token id="9" string="Tokai" />
            <token id="10" string="monitoring" />
            <token id="11" string="network" />
            <token id="12" string="," />
            <token id="13" string="including" />
            <token id="14" string="a" />
            <token id="15" string="7.8" />
            <token id="16" string="earthquake" />
            <token id="17" string="off" />
            <token id="18" string="the" />
            <token id="19" string="coast" />
            <token id="20" string="of" />
            <token id="21" string="Hokkaido" />
            <token id="22" string="last" />
            <token id="23" string="year" />
            <token id="24" string="that" />
            <token id="25" string="claimed" />
            <token id="26" string="more" />
            <token id="27" string="than" />
            <token id="28" string="200" />
            <token id="29" string="lives" />
          </tokens>
        </chunking>
        <chunking id="2" string="numerous killer quakes" type="NP">
          <tokens>
            <token id="4" string="numerous" />
            <token id="5" string="killer" />
            <token id="6" string="quakes" />
          </tokens>
        </chunking>
        <chunking id="3" string="claimed more than 200 lives" type="VP">
          <tokens>
            <token id="25" string="claimed" />
            <token id="26" string="more" />
            <token id="27" string="than" />
            <token id="28" string="200" />
            <token id="29" string="lives" />
          </tokens>
        </chunking>
        <chunking id="4" string="Japan" type="NP">
          <tokens>
            <token id="1" string="Japan" />
          </tokens>
        </chunking>
        <chunking id="5" string="Hokkaido" type="NP">
          <tokens>
            <token id="21" string="Hokkaido" />
          </tokens>
        </chunking>
        <chunking id="6" string="that claimed more than 200 lives" type="SBAR">
          <tokens>
            <token id="24" string="that" />
            <token id="25" string="claimed" />
            <token id="26" string="more" />
            <token id="27" string="than" />
            <token id="28" string="200" />
            <token id="29" string="lives" />
          </tokens>
        </chunking>
        <chunking id="7" string="numerous killer quakes outside the Tokai monitoring network , including a 7.8 earthquake off the coast of Hokkaido last year that claimed more than 200 lives" type="NP">
          <tokens>
            <token id="4" string="numerous" />
            <token id="5" string="killer" />
            <token id="6" string="quakes" />
            <token id="7" string="outside" />
            <token id="8" string="the" />
            <token id="9" string="Tokai" />
            <token id="10" string="monitoring" />
            <token id="11" string="network" />
            <token id="12" string="," />
            <token id="13" string="including" />
            <token id="14" string="a" />
            <token id="15" string="7.8" />
            <token id="16" string="earthquake" />
            <token id="17" string="off" />
            <token id="18" string="the" />
            <token id="19" string="coast" />
            <token id="20" string="of" />
            <token id="21" string="Hokkaido" />
            <token id="22" string="last" />
            <token id="23" string="year" />
            <token id="24" string="that" />
            <token id="25" string="claimed" />
            <token id="26" string="more" />
            <token id="27" string="than" />
            <token id="28" string="200" />
            <token id="29" string="lives" />
          </tokens>
        </chunking>
        <chunking id="8" string="the coast of Hokkaido last year that claimed more than 200 lives" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="coast" />
            <token id="20" string="of" />
            <token id="21" string="Hokkaido" />
            <token id="22" string="last" />
            <token id="23" string="year" />
            <token id="24" string="that" />
            <token id="25" string="claimed" />
            <token id="26" string="more" />
            <token id="27" string="than" />
            <token id="28" string="200" />
            <token id="29" string="lives" />
          </tokens>
        </chunking>
        <chunking id="9" string="a 7.8 earthquake off the coast of Hokkaido last year that claimed more than 200 lives" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="7.8" />
            <token id="16" string="earthquake" />
            <token id="17" string="off" />
            <token id="18" string="the" />
            <token id="19" string="coast" />
            <token id="20" string="of" />
            <token id="21" string="Hokkaido" />
            <token id="22" string="last" />
            <token id="23" string="year" />
            <token id="24" string="that" />
            <token id="25" string="claimed" />
            <token id="26" string="more" />
            <token id="27" string="than" />
            <token id="28" string="200" />
            <token id="29" string="lives" />
          </tokens>
        </chunking>
        <chunking id="10" string="the coast" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="coast" />
          </tokens>
        </chunking>
        <chunking id="11" string="the Tokai monitoring network" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="Tokai" />
            <token id="10" string="monitoring" />
            <token id="11" string="network" />
          </tokens>
        </chunking>
        <chunking id="12" string="a 7.8 earthquake" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="7.8" />
            <token id="16" string="earthquake" />
          </tokens>
        </chunking>
        <chunking id="13" string="has had numerous killer quakes outside the Tokai monitoring network , including a 7.8 earthquake off the coast of Hokkaido last year that claimed more than 200 lives" type="VP">
          <tokens>
            <token id="2" string="has" />
            <token id="3" string="had" />
            <token id="4" string="numerous" />
            <token id="5" string="killer" />
            <token id="6" string="quakes" />
            <token id="7" string="outside" />
            <token id="8" string="the" />
            <token id="9" string="Tokai" />
            <token id="10" string="monitoring" />
            <token id="11" string="network" />
            <token id="12" string="," />
            <token id="13" string="including" />
            <token id="14" string="a" />
            <token id="15" string="7.8" />
            <token id="16" string="earthquake" />
            <token id="17" string="off" />
            <token id="18" string="the" />
            <token id="19" string="coast" />
            <token id="20" string="of" />
            <token id="21" string="Hokkaido" />
            <token id="22" string="last" />
            <token id="23" string="year" />
            <token id="24" string="that" />
            <token id="25" string="claimed" />
            <token id="26" string="more" />
            <token id="27" string="than" />
            <token id="28" string="200" />
            <token id="29" string="lives" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">had</governor>
          <dependent id="1">Japan</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="3">had</governor>
          <dependent id="2">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">had</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">quakes</governor>
          <dependent id="4">numerous</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">quakes</governor>
          <dependent id="5">killer</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">had</governor>
          <dependent id="6">quakes</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">network</governor>
          <dependent id="7">outside</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">network</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">network</governor>
          <dependent id="9">Tokai</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">network</governor>
          <dependent id="10">monitoring</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">quakes</governor>
          <dependent id="11">network</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">earthquake</governor>
          <dependent id="13">including</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">earthquake</governor>
          <dependent id="14">a</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="16">earthquake</governor>
          <dependent id="15">7.8</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">quakes</governor>
          <dependent id="16">earthquake</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">coast</governor>
          <dependent id="17">off</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">coast</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">earthquake</governor>
          <dependent id="19">coast</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">Hokkaido</governor>
          <dependent id="20">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">coast</governor>
          <dependent id="21">Hokkaido</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">year</governor>
          <dependent id="22">last</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="19">coast</governor>
          <dependent id="23">year</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">claimed</governor>
          <dependent id="24">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="19">coast</governor>
          <dependent id="25">claimed</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="28">200</governor>
          <dependent id="26">more</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="26">more</governor>
          <dependent id="27">than</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="29">lives</governor>
          <dependent id="28">200</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="25">claimed</governor>
          <dependent id="29">lives</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="7.8" type="NUMBER" score="0.0">
          <tokens>
            <token id="15" string="7.8" />
          </tokens>
        </entity>
        <entity id="2" string="200" type="NUMBER" score="0.0">
          <tokens>
            <token id="28" string="200" />
          </tokens>
        </entity>
        <entity id="3" string="Tokai" type="LOCATION" score="0.0">
          <tokens>
            <token id="9" string="Tokai" />
          </tokens>
        </entity>
        <entity id="4" string="Japan" type="LOCATION" score="0.0">
          <tokens>
            <token id="1" string="Japan" />
          </tokens>
        </entity>
        <entity id="5" string="earthquake" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="16" string="earthquake" />
          </tokens>
        </entity>
        <entity id="6" string="coast of Hokkaido" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="19" string="coast" />
            <token id="20" string="of" />
            <token id="21" string="Hokkaido" />
          </tokens>
        </entity>
        <entity id="7" string="last year" type="DATE" score="0.0">
          <tokens>
            <token id="22" string="last" />
            <token id="23" string="year" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="32" has_coreference="true">
      <content>Kiyoo Mogi, chairman of the six-member panel that will make the call on the Tokai earthquake and former head of the University of Tokyo&amp;apost;s Earthquake Research Institute, says several factors make the Tokai region more suited than others for what he calls &amp;apost;a national experiment&amp;apost;.</content>
      <tokens>
        <token id="1" string="Kiyoo" lemma="Kiyoo" stem="kiyoo" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="Mogi" lemma="Mogi" stem="mogi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="chairman" lemma="chairman" stem="chairman" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="six-member" lemma="six-member" stem="six-memb" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="panel" lemma="panel" stem="panel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="make" lemma="make" stem="make" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="call" lemma="call" stem="call" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="Tokai" lemma="Tokai" stem="tokai" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="17" string="earthquake" lemma="earthquake" stem="earthquak" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="18" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="former" lemma="former" stem="former" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="head" lemma="head" stem="head" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="University" lemma="University" stem="univers" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="24" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="25" string="Tokyo" lemma="Tokyo" stem="tokyo" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="26" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="27" string="Earthquake" lemma="Earthquake" stem="earthquak" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="28" string="Research" lemma="Research" stem="research" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="29" string="Institute" lemma="Institute" stem="institut" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="30" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="several" lemma="several" stem="sever" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="factors" lemma="factor" stem="factor" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="make" lemma="make" stem="make" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="Tokai" lemma="Tokai" stem="tokai" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="37" string="region" lemma="region" stem="region" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="suited" lemma="suit" stem="suit" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="others" lemma="other" stem="other" pos="NNS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="42" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="43" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="44" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="45" string="calls" lemma="call" stem="call" pos="VBZ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="46" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="47" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="48" string="national" lemma="national" stem="nation" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="49" string="experiment" lemma="experiment" stem="experi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="50" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="51" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Kiyoo) (NNP Mogi)) (, ,) (NP (NP (NN chairman)) (PP (IN of) (NP (DT the) (JJ six-member) (NN panel))) (SBAR (WHNP (WDT that)) (S (VP (MD will) (VP (VB make) (NP (DT the) (NN call)) (PP (IN on) (NP (NP (DT the) (NNP Tokai) (NN earthquake) (CC and) (JJ former) (NN head)) (PP (IN of) (NP (NP (DT the) (NNP University)) (PP (IN of) (NP (NP (NNP Tokyo) (POS 's)) (NNP Earthquake) (NNP Research) (NNP Institute)))))))))))) (, ,)) (VP (VBZ says) (SBAR (S (NP (JJ several) (NNS factors)) (VP (VBP make) (S (NP (NP (DT the) (NNP Tokai) (NN region)) (VP (ADVP (RBR more)) (VBN suited) (PP (IN than) (NP (NP (NNS others)) (PP (IN for) (SBAR (WHNP (WP what)) (S (NP (PRP he)) (VP (VBZ calls))))) ('' '))))) (NP (DT a) (JJ national) (NN experiment) ('' '))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the Tokai region more suited than others for what he calls '" type="NP">
          <tokens>
            <token id="35" string="the" />
            <token id="36" string="Tokai" />
            <token id="37" string="region" />
            <token id="38" string="more" />
            <token id="39" string="suited" />
            <token id="40" string="than" />
            <token id="41" string="others" />
            <token id="42" string="for" />
            <token id="43" string="what" />
            <token id="44" string="he" />
            <token id="45" string="calls" />
            <token id="46" string="'" />
          </tokens>
        </chunking>
        <chunking id="2" string="Kiyoo Mogi" type="NP">
          <tokens>
            <token id="1" string="Kiyoo" />
            <token id="2" string="Mogi" />
          </tokens>
        </chunking>
        <chunking id="3" string="that will make the call on the Tokai earthquake and former head of the University of Tokyo 's Earthquake Research Institute" type="SBAR">
          <tokens>
            <token id="9" string="that" />
            <token id="10" string="will" />
            <token id="11" string="make" />
            <token id="12" string="the" />
            <token id="13" string="call" />
            <token id="14" string="on" />
            <token id="15" string="the" />
            <token id="16" string="Tokai" />
            <token id="17" string="earthquake" />
            <token id="18" string="and" />
            <token id="19" string="former" />
            <token id="20" string="head" />
            <token id="21" string="of" />
            <token id="22" string="the" />
            <token id="23" string="University" />
            <token id="24" string="of" />
            <token id="25" string="Tokyo" />
            <token id="26" string="'s" />
            <token id="27" string="Earthquake" />
            <token id="28" string="Research" />
            <token id="29" string="Institute" />
          </tokens>
        </chunking>
        <chunking id="4" string="the Tokai earthquake and former head" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="Tokai" />
            <token id="17" string="earthquake" />
            <token id="18" string="and" />
            <token id="19" string="former" />
            <token id="20" string="head" />
          </tokens>
        </chunking>
        <chunking id="5" string="Tokyo 's Earthquake Research Institute" type="NP">
          <tokens>
            <token id="25" string="Tokyo" />
            <token id="26" string="'s" />
            <token id="27" string="Earthquake" />
            <token id="28" string="Research" />
            <token id="29" string="Institute" />
          </tokens>
        </chunking>
        <chunking id="6" string="chairman" type="NP">
          <tokens>
            <token id="4" string="chairman" />
          </tokens>
        </chunking>
        <chunking id="7" string="Tokyo 's" type="NP">
          <tokens>
            <token id="25" string="Tokyo" />
            <token id="26" string="'s" />
          </tokens>
        </chunking>
        <chunking id="8" string="more suited than others for what he calls '" type="VP">
          <tokens>
            <token id="38" string="more" />
            <token id="39" string="suited" />
            <token id="40" string="than" />
            <token id="41" string="others" />
            <token id="42" string="for" />
            <token id="43" string="what" />
            <token id="44" string="he" />
            <token id="45" string="calls" />
            <token id="46" string="'" />
          </tokens>
        </chunking>
        <chunking id="9" string="will make the call on the Tokai earthquake and former head of the University of Tokyo 's Earthquake Research Institute" type="VP">
          <tokens>
            <token id="10" string="will" />
            <token id="11" string="make" />
            <token id="12" string="the" />
            <token id="13" string="call" />
            <token id="14" string="on" />
            <token id="15" string="the" />
            <token id="16" string="Tokai" />
            <token id="17" string="earthquake" />
            <token id="18" string="and" />
            <token id="19" string="former" />
            <token id="20" string="head" />
            <token id="21" string="of" />
            <token id="22" string="the" />
            <token id="23" string="University" />
            <token id="24" string="of" />
            <token id="25" string="Tokyo" />
            <token id="26" string="'s" />
            <token id="27" string="Earthquake" />
            <token id="28" string="Research" />
            <token id="29" string="Institute" />
          </tokens>
        </chunking>
        <chunking id="10" string="make the call on the Tokai earthquake and former head of the University of Tokyo 's Earthquake Research Institute" type="VP">
          <tokens>
            <token id="11" string="make" />
            <token id="12" string="the" />
            <token id="13" string="call" />
            <token id="14" string="on" />
            <token id="15" string="the" />
            <token id="16" string="Tokai" />
            <token id="17" string="earthquake" />
            <token id="18" string="and" />
            <token id="19" string="former" />
            <token id="20" string="head" />
            <token id="21" string="of" />
            <token id="22" string="the" />
            <token id="23" string="University" />
            <token id="24" string="of" />
            <token id="25" string="Tokyo" />
            <token id="26" string="'s" />
            <token id="27" string="Earthquake" />
            <token id="28" string="Research" />
            <token id="29" string="Institute" />
          </tokens>
        </chunking>
        <chunking id="11" string="calls" type="VP">
          <tokens>
            <token id="45" string="calls" />
          </tokens>
        </chunking>
        <chunking id="12" string="says several factors make the Tokai region more suited than others for what he calls ' a national experiment '" type="VP">
          <tokens>
            <token id="31" string="says" />
            <token id="32" string="several" />
            <token id="33" string="factors" />
            <token id="34" string="make" />
            <token id="35" string="the" />
            <token id="36" string="Tokai" />
            <token id="37" string="region" />
            <token id="38" string="more" />
            <token id="39" string="suited" />
            <token id="40" string="than" />
            <token id="41" string="others" />
            <token id="42" string="for" />
            <token id="43" string="what" />
            <token id="44" string="he" />
            <token id="45" string="calls" />
            <token id="46" string="'" />
            <token id="47" string="a" />
            <token id="48" string="national" />
            <token id="49" string="experiment" />
            <token id="50" string="'" />
          </tokens>
        </chunking>
        <chunking id="13" string="the Tokai earthquake and former head of the University of Tokyo 's Earthquake Research Institute" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="Tokai" />
            <token id="17" string="earthquake" />
            <token id="18" string="and" />
            <token id="19" string="former" />
            <token id="20" string="head" />
            <token id="21" string="of" />
            <token id="22" string="the" />
            <token id="23" string="University" />
            <token id="24" string="of" />
            <token id="25" string="Tokyo" />
            <token id="26" string="'s" />
            <token id="27" string="Earthquake" />
            <token id="28" string="Research" />
            <token id="29" string="Institute" />
          </tokens>
        </chunking>
        <chunking id="14" string="the call" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="call" />
          </tokens>
        </chunking>
        <chunking id="15" string="several factors" type="NP">
          <tokens>
            <token id="32" string="several" />
            <token id="33" string="factors" />
          </tokens>
        </chunking>
        <chunking id="16" string="chairman of the six-member panel that will make the call on the Tokai earthquake and former head of the University of Tokyo 's Earthquake Research Institute" type="NP">
          <tokens>
            <token id="4" string="chairman" />
            <token id="5" string="of" />
            <token id="6" string="the" />
            <token id="7" string="six-member" />
            <token id="8" string="panel" />
            <token id="9" string="that" />
            <token id="10" string="will" />
            <token id="11" string="make" />
            <token id="12" string="the" />
            <token id="13" string="call" />
            <token id="14" string="on" />
            <token id="15" string="the" />
            <token id="16" string="Tokai" />
            <token id="17" string="earthquake" />
            <token id="18" string="and" />
            <token id="19" string="former" />
            <token id="20" string="head" />
            <token id="21" string="of" />
            <token id="22" string="the" />
            <token id="23" string="University" />
            <token id="24" string="of" />
            <token id="25" string="Tokyo" />
            <token id="26" string="'s" />
            <token id="27" string="Earthquake" />
            <token id="28" string="Research" />
            <token id="29" string="Institute" />
          </tokens>
        </chunking>
        <chunking id="17" string="he" type="NP">
          <tokens>
            <token id="44" string="he" />
          </tokens>
        </chunking>
        <chunking id="18" string="the University" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="University" />
          </tokens>
        </chunking>
        <chunking id="19" string="make the Tokai region more suited than others for what he calls ' a national experiment '" type="VP">
          <tokens>
            <token id="34" string="make" />
            <token id="35" string="the" />
            <token id="36" string="Tokai" />
            <token id="37" string="region" />
            <token id="38" string="more" />
            <token id="39" string="suited" />
            <token id="40" string="than" />
            <token id="41" string="others" />
            <token id="42" string="for" />
            <token id="43" string="what" />
            <token id="44" string="he" />
            <token id="45" string="calls" />
            <token id="46" string="'" />
            <token id="47" string="a" />
            <token id="48" string="national" />
            <token id="49" string="experiment" />
            <token id="50" string="'" />
          </tokens>
        </chunking>
        <chunking id="20" string="Kiyoo Mogi , chairman of the six-member panel that will make the call on the Tokai earthquake and former head of the University of Tokyo 's Earthquake Research Institute ," type="NP">
          <tokens>
            <token id="1" string="Kiyoo" />
            <token id="2" string="Mogi" />
            <token id="3" string="," />
            <token id="4" string="chairman" />
            <token id="5" string="of" />
            <token id="6" string="the" />
            <token id="7" string="six-member" />
            <token id="8" string="panel" />
            <token id="9" string="that" />
            <token id="10" string="will" />
            <token id="11" string="make" />
            <token id="12" string="the" />
            <token id="13" string="call" />
            <token id="14" string="on" />
            <token id="15" string="the" />
            <token id="16" string="Tokai" />
            <token id="17" string="earthquake" />
            <token id="18" string="and" />
            <token id="19" string="former" />
            <token id="20" string="head" />
            <token id="21" string="of" />
            <token id="22" string="the" />
            <token id="23" string="University" />
            <token id="24" string="of" />
            <token id="25" string="Tokyo" />
            <token id="26" string="'s" />
            <token id="27" string="Earthquake" />
            <token id="28" string="Research" />
            <token id="29" string="Institute" />
            <token id="30" string="," />
          </tokens>
        </chunking>
        <chunking id="21" string="the University of Tokyo 's Earthquake Research Institute" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="University" />
            <token id="24" string="of" />
            <token id="25" string="Tokyo" />
            <token id="26" string="'s" />
            <token id="27" string="Earthquake" />
            <token id="28" string="Research" />
            <token id="29" string="Institute" />
          </tokens>
        </chunking>
        <chunking id="22" string="several factors make the Tokai region more suited than others for what he calls ' a national experiment '" type="SBAR">
          <tokens>
            <token id="32" string="several" />
            <token id="33" string="factors" />
            <token id="34" string="make" />
            <token id="35" string="the" />
            <token id="36" string="Tokai" />
            <token id="37" string="region" />
            <token id="38" string="more" />
            <token id="39" string="suited" />
            <token id="40" string="than" />
            <token id="41" string="others" />
            <token id="42" string="for" />
            <token id="43" string="what" />
            <token id="44" string="he" />
            <token id="45" string="calls" />
            <token id="46" string="'" />
            <token id="47" string="a" />
            <token id="48" string="national" />
            <token id="49" string="experiment" />
            <token id="50" string="'" />
          </tokens>
        </chunking>
        <chunking id="23" string="the Tokai region" type="NP">
          <tokens>
            <token id="35" string="the" />
            <token id="36" string="Tokai" />
            <token id="37" string="region" />
          </tokens>
        </chunking>
        <chunking id="24" string="others for what he calls '" type="NP">
          <tokens>
            <token id="41" string="others" />
            <token id="42" string="for" />
            <token id="43" string="what" />
            <token id="44" string="he" />
            <token id="45" string="calls" />
            <token id="46" string="'" />
          </tokens>
        </chunking>
        <chunking id="25" string="what he calls" type="SBAR">
          <tokens>
            <token id="43" string="what" />
            <token id="44" string="he" />
            <token id="45" string="calls" />
          </tokens>
        </chunking>
        <chunking id="26" string="a national experiment '" type="NP">
          <tokens>
            <token id="47" string="a" />
            <token id="48" string="national" />
            <token id="49" string="experiment" />
            <token id="50" string="'" />
          </tokens>
        </chunking>
        <chunking id="27" string="the six-member panel" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="six-member" />
            <token id="8" string="panel" />
          </tokens>
        </chunking>
        <chunking id="28" string="others" type="NP">
          <tokens>
            <token id="41" string="others" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Mogi</governor>
          <dependent id="1">Kiyoo</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="31">says</governor>
          <dependent id="2">Mogi</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="2">Mogi</governor>
          <dependent id="4">chairman</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">panel</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">panel</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">panel</governor>
          <dependent id="7">six-member</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">chairman</governor>
          <dependent id="8">panel</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">make</governor>
          <dependent id="9">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">make</governor>
          <dependent id="10">will</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="4">chairman</governor>
          <dependent id="11">make</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">call</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">make</governor>
          <dependent id="13">call</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">earthquake</governor>
          <dependent id="14">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">earthquake</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">earthquake</governor>
          <dependent id="16">Tokai</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">make</governor>
          <dependent id="17">earthquake</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="17">earthquake</governor>
          <dependent id="18">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">head</governor>
          <dependent id="19">former</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">earthquake</governor>
          <dependent id="20">head</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">University</governor>
          <dependent id="21">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">University</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">earthquake</governor>
          <dependent id="23">University</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">Institute</governor>
          <dependent id="24">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="29">Institute</governor>
          <dependent id="25">Tokyo</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">Tokyo</governor>
          <dependent id="26">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="29">Institute</governor>
          <dependent id="27">Earthquake</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="29">Institute</governor>
          <dependent id="28">Research</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">University</governor>
          <dependent id="29">Institute</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="31">says</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="33">factors</governor>
          <dependent id="32">several</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="34">make</governor>
          <dependent id="33">factors</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="31">says</governor>
          <dependent id="34">make</dependent>
        </dependency>
        <dependency type="det">
          <governor id="37">region</governor>
          <dependent id="35">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="37">region</governor>
          <dependent id="36">Tokai</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="49">experiment</governor>
          <dependent id="37">region</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="39">suited</governor>
          <dependent id="38">more</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="37">region</governor>
          <dependent id="39">suited</dependent>
        </dependency>
        <dependency type="case">
          <governor id="41">others</governor>
          <dependent id="40">than</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="39">suited</governor>
          <dependent id="41">others</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="45">calls</governor>
          <dependent id="42">for</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="45">calls</governor>
          <dependent id="43">what</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="45">calls</governor>
          <dependent id="44">he</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="41">others</governor>
          <dependent id="45">calls</dependent>
        </dependency>
        <dependency type="det">
          <governor id="49">experiment</governor>
          <dependent id="47">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="49">experiment</governor>
          <dependent id="48">national</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="34">make</governor>
          <dependent id="49">experiment</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="University of Tokyo 's Earthquake Research Institute" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="23" string="University" />
            <token id="24" string="of" />
            <token id="25" string="Tokyo" />
            <token id="26" string="'s" />
            <token id="27" string="Earthquake" />
            <token id="28" string="Research" />
            <token id="29" string="Institute" />
          </tokens>
        </entity>
        <entity id="2" string="Kiyoo Mogi" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Kiyoo" />
            <token id="2" string="Mogi" />
          </tokens>
        </entity>
        <entity id="3" string="Tokai" type="LOCATION" score="0.0">
          <tokens>
            <token id="16" string="Tokai" />
          </tokens>
        </entity>
        <entity id="4" string="earthquake" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="17" string="earthquake" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="33" has_coreference="true">
      <content>The region&amp;apost;s geology is straightforward, so they can narrow down the likely location of the anticipated earthquake.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="region" lemma="region" stem="region" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="geology" lemma="geology" stem="geologi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="straightforward" lemma="straightforward" stem="straightforward" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="so" lemma="so" stem="so" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="narrow" lemma="narrow" stem="narrow" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="down" lemma="down" stem="down" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="likely" lemma="likely" stem="like" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="location" lemma="location" stem="locat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="anticipated" lemma="anticipated" stem="anticip" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="earthquake" lemma="earthquake" stem="earthquak" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (DT The) (NN region) (POS 's)) (NN geology)) (VP (VBZ is) (ADJP (JJ straightforward)))) (, ,) (IN so) (S (NP (PRP they)) (VP (MD can) (VP (VB narrow) (PRT (RP down)) (NP (NP (DT the) (JJ likely) (NN location)) (PP (IN of) (NP (DT the) (JJ anticipated) (NN earthquake))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="The region 's geology" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="region" />
            <token id="3" string="'s" />
            <token id="4" string="geology" />
          </tokens>
        </chunking>
        <chunking id="2" string="straightforward" type="ADJP">
          <tokens>
            <token id="6" string="straightforward" />
          </tokens>
        </chunking>
        <chunking id="3" string="they" type="NP">
          <tokens>
            <token id="9" string="they" />
          </tokens>
        </chunking>
        <chunking id="4" string="can narrow down the likely location of the anticipated earthquake" type="VP">
          <tokens>
            <token id="10" string="can" />
            <token id="11" string="narrow" />
            <token id="12" string="down" />
            <token id="13" string="the" />
            <token id="14" string="likely" />
            <token id="15" string="location" />
            <token id="16" string="of" />
            <token id="17" string="the" />
            <token id="18" string="anticipated" />
            <token id="19" string="earthquake" />
          </tokens>
        </chunking>
        <chunking id="5" string="the anticipated earthquake" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="anticipated" />
            <token id="19" string="earthquake" />
          </tokens>
        </chunking>
        <chunking id="6" string="The region 's" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="region" />
            <token id="3" string="'s" />
          </tokens>
        </chunking>
        <chunking id="7" string="the likely location of the anticipated earthquake" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="likely" />
            <token id="15" string="location" />
            <token id="16" string="of" />
            <token id="17" string="the" />
            <token id="18" string="anticipated" />
            <token id="19" string="earthquake" />
          </tokens>
        </chunking>
        <chunking id="8" string="the likely location" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="likely" />
            <token id="15" string="location" />
          </tokens>
        </chunking>
        <chunking id="9" string="narrow down the likely location of the anticipated earthquake" type="VP">
          <tokens>
            <token id="11" string="narrow" />
            <token id="12" string="down" />
            <token id="13" string="the" />
            <token id="14" string="likely" />
            <token id="15" string="location" />
            <token id="16" string="of" />
            <token id="17" string="the" />
            <token id="18" string="anticipated" />
            <token id="19" string="earthquake" />
          </tokens>
        </chunking>
        <chunking id="10" string="is straightforward" type="VP">
          <tokens>
            <token id="5" string="is" />
            <token id="6" string="straightforward" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">region</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">geology</governor>
          <dependent id="2">region</dependent>
        </dependency>
        <dependency type="case">
          <governor id="2">region</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">straightforward</governor>
          <dependent id="4">geology</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">straightforward</governor>
          <dependent id="5">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">straightforward</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="6">straightforward</governor>
          <dependent id="8">so</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">narrow</governor>
          <dependent id="9">they</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">narrow</governor>
          <dependent id="10">can</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="6">straightforward</governor>
          <dependent id="11">narrow</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="11">narrow</governor>
          <dependent id="12">down</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">location</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">location</governor>
          <dependent id="14">likely</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">narrow</governor>
          <dependent id="15">location</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">earthquake</governor>
          <dependent id="16">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">earthquake</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">earthquake</governor>
          <dependent id="18">anticipated</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">location</governor>
          <dependent id="19">earthquake</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="earthquake" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="19" string="earthquake" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="34" has_coreference="true">
      <content>Historically, strain along the Suruga Trough has been released in infrequent large earthquakes, rather than numerous small ones.</content>
      <tokens>
        <token id="1" string="Historically" lemma="Historically" stem="histor" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="strain" lemma="strain" stem="strain" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="along" lemma="along" stem="along" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="Suruga" lemma="Suruga" stem="suruga" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="7" string="Trough" lemma="Trough" stem="trough" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="8" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="released" lemma="release" stem="releas" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="infrequent" lemma="infrequent" stem="infrequ" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="large" lemma="large" stem="larg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="earthquakes" lemma="earthquake" stem="earthquak" pos="NNS" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="rather" lemma="rather" stem="rather" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="numerous" lemma="numerous" stem="numer" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="small" lemma="small" stem="small" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="ones" lemma="one" stem="on" pos="NNS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Historically)) (, ,) (NP (NP (NN strain)) (PP (IN along) (NP (DT the) (NNP Suruga) (NNP Trough))))) (VP (VBZ has) (VP (VBN been) (VP (VBN released) (PP (IN in) (NP (NP (JJ infrequent) (JJ large) (NNS earthquakes)) (, ,) (CONJP (RB rather) (IN than)) (NP (JJ numerous) (JJ small) (NNS ones))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="strain" type="NP">
          <tokens>
            <token id="3" string="strain" />
          </tokens>
        </chunking>
        <chunking id="2" string="Historically , strain along the Suruga Trough" type="NP">
          <tokens>
            <token id="1" string="Historically" />
            <token id="2" string="," />
            <token id="3" string="strain" />
            <token id="4" string="along" />
            <token id="5" string="the" />
            <token id="6" string="Suruga" />
            <token id="7" string="Trough" />
          </tokens>
        </chunking>
        <chunking id="3" string="numerous small ones" type="NP">
          <tokens>
            <token id="18" string="numerous" />
            <token id="19" string="small" />
            <token id="20" string="ones" />
          </tokens>
        </chunking>
        <chunking id="4" string="infrequent large earthquakes , rather than numerous small ones" type="NP">
          <tokens>
            <token id="12" string="infrequent" />
            <token id="13" string="large" />
            <token id="14" string="earthquakes" />
            <token id="15" string="," />
            <token id="16" string="rather" />
            <token id="17" string="than" />
            <token id="18" string="numerous" />
            <token id="19" string="small" />
            <token id="20" string="ones" />
          </tokens>
        </chunking>
        <chunking id="5" string="strain along the Suruga Trough" type="NP">
          <tokens>
            <token id="3" string="strain" />
            <token id="4" string="along" />
            <token id="5" string="the" />
            <token id="6" string="Suruga" />
            <token id="7" string="Trough" />
          </tokens>
        </chunking>
        <chunking id="6" string="the Suruga Trough" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="Suruga" />
            <token id="7" string="Trough" />
          </tokens>
        </chunking>
        <chunking id="7" string="Historically" type="NP">
          <tokens>
            <token id="1" string="Historically" />
          </tokens>
        </chunking>
        <chunking id="8" string="has been released in infrequent large earthquakes , rather than numerous small ones" type="VP">
          <tokens>
            <token id="8" string="has" />
            <token id="9" string="been" />
            <token id="10" string="released" />
            <token id="11" string="in" />
            <token id="12" string="infrequent" />
            <token id="13" string="large" />
            <token id="14" string="earthquakes" />
            <token id="15" string="," />
            <token id="16" string="rather" />
            <token id="17" string="than" />
            <token id="18" string="numerous" />
            <token id="19" string="small" />
            <token id="20" string="ones" />
          </tokens>
        </chunking>
        <chunking id="9" string="released in infrequent large earthquakes , rather than numerous small ones" type="VP">
          <tokens>
            <token id="10" string="released" />
            <token id="11" string="in" />
            <token id="12" string="infrequent" />
            <token id="13" string="large" />
            <token id="14" string="earthquakes" />
            <token id="15" string="," />
            <token id="16" string="rather" />
            <token id="17" string="than" />
            <token id="18" string="numerous" />
            <token id="19" string="small" />
            <token id="20" string="ones" />
          </tokens>
        </chunking>
        <chunking id="10" string="infrequent large earthquakes" type="NP">
          <tokens>
            <token id="12" string="infrequent" />
            <token id="13" string="large" />
            <token id="14" string="earthquakes" />
          </tokens>
        </chunking>
        <chunking id="11" string="been released in infrequent large earthquakes , rather than numerous small ones" type="VP">
          <tokens>
            <token id="9" string="been" />
            <token id="10" string="released" />
            <token id="11" string="in" />
            <token id="12" string="infrequent" />
            <token id="13" string="large" />
            <token id="14" string="earthquakes" />
            <token id="15" string="," />
            <token id="16" string="rather" />
            <token id="17" string="than" />
            <token id="18" string="numerous" />
            <token id="19" string="small" />
            <token id="20" string="ones" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="10">released</governor>
          <dependent id="1">Historically</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="1">Historically</governor>
          <dependent id="3">strain</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">Trough</governor>
          <dependent id="4">along</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">Trough</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Trough</governor>
          <dependent id="6">Suruga</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">strain</governor>
          <dependent id="7">Trough</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="10">released</governor>
          <dependent id="8">has</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="10">released</governor>
          <dependent id="9">been</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">released</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">earthquakes</governor>
          <dependent id="11">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">earthquakes</governor>
          <dependent id="12">infrequent</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">earthquakes</governor>
          <dependent id="13">large</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">released</governor>
          <dependent id="14">earthquakes</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="14">earthquakes</governor>
          <dependent id="16">rather</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="16">rather</governor>
          <dependent id="17">than</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">ones</governor>
          <dependent id="18">numerous</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">ones</governor>
          <dependent id="19">small</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">earthquakes</governor>
          <dependent id="20">ones</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Suruga Trough" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="6" string="Suruga" />
            <token id="7" string="Trough" />
          </tokens>
        </entity>
        <entity id="2" string="earthquakes" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="14" string="earthquakes" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="35" has_coreference="true">
      <content>The evidence is that significant strain has accumulated along the fault since the region&amp;apost;s last big earthquake.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="evidence" lemma="evidence" stem="evid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="significant" lemma="significant" stem="signific" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="strain" lemma="strain" stem="strain" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="accumulated" lemma="accumulate" stem="accumul" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="along" lemma="along" stem="along" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="fault" lemma="fault" stem="fault" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="since" lemma="since" stem="sinc" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="region" lemma="region" stem="region" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="big" lemma="big" stem="big" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="earthquake" lemma="earthquake" stem="earthquak" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN evidence)) (VP (VBZ is) (SBAR (IN that) (S (NP (JJ significant) (NN strain)) (VP (VBZ has) (VP (VBN accumulated) (PP (IN along) (NP (NP (DT the) (NN fault)) (PP (IN since) (NP (NP (DT the) (NN region) (POS 's)) (JJ last) (JJ big) (NN earthquake)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the region 's last big earthquake" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="region" />
            <token id="15" string="'s" />
            <token id="16" string="last" />
            <token id="17" string="big" />
            <token id="18" string="earthquake" />
          </tokens>
        </chunking>
        <chunking id="2" string="that significant strain has accumulated along the fault since the region 's last big earthquake" type="SBAR">
          <tokens>
            <token id="4" string="that" />
            <token id="5" string="significant" />
            <token id="6" string="strain" />
            <token id="7" string="has" />
            <token id="8" string="accumulated" />
            <token id="9" string="along" />
            <token id="10" string="the" />
            <token id="11" string="fault" />
            <token id="12" string="since" />
            <token id="13" string="the" />
            <token id="14" string="region" />
            <token id="15" string="'s" />
            <token id="16" string="last" />
            <token id="17" string="big" />
            <token id="18" string="earthquake" />
          </tokens>
        </chunking>
        <chunking id="3" string="significant strain" type="NP">
          <tokens>
            <token id="5" string="significant" />
            <token id="6" string="strain" />
          </tokens>
        </chunking>
        <chunking id="4" string="the region 's" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="region" />
            <token id="15" string="'s" />
          </tokens>
        </chunking>
        <chunking id="5" string="the fault since the region 's last big earthquake" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="fault" />
            <token id="12" string="since" />
            <token id="13" string="the" />
            <token id="14" string="region" />
            <token id="15" string="'s" />
            <token id="16" string="last" />
            <token id="17" string="big" />
            <token id="18" string="earthquake" />
          </tokens>
        </chunking>
        <chunking id="6" string="is that significant strain has accumulated along the fault since the region 's last big earthquake" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="that" />
            <token id="5" string="significant" />
            <token id="6" string="strain" />
            <token id="7" string="has" />
            <token id="8" string="accumulated" />
            <token id="9" string="along" />
            <token id="10" string="the" />
            <token id="11" string="fault" />
            <token id="12" string="since" />
            <token id="13" string="the" />
            <token id="14" string="region" />
            <token id="15" string="'s" />
            <token id="16" string="last" />
            <token id="17" string="big" />
            <token id="18" string="earthquake" />
          </tokens>
        </chunking>
        <chunking id="7" string="has accumulated along the fault since the region 's last big earthquake" type="VP">
          <tokens>
            <token id="7" string="has" />
            <token id="8" string="accumulated" />
            <token id="9" string="along" />
            <token id="10" string="the" />
            <token id="11" string="fault" />
            <token id="12" string="since" />
            <token id="13" string="the" />
            <token id="14" string="region" />
            <token id="15" string="'s" />
            <token id="16" string="last" />
            <token id="17" string="big" />
            <token id="18" string="earthquake" />
          </tokens>
        </chunking>
        <chunking id="8" string="the fault" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="fault" />
          </tokens>
        </chunking>
        <chunking id="9" string="The evidence" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="evidence" />
          </tokens>
        </chunking>
        <chunking id="10" string="accumulated along the fault since the region 's last big earthquake" type="VP">
          <tokens>
            <token id="8" string="accumulated" />
            <token id="9" string="along" />
            <token id="10" string="the" />
            <token id="11" string="fault" />
            <token id="12" string="since" />
            <token id="13" string="the" />
            <token id="14" string="region" />
            <token id="15" string="'s" />
            <token id="16" string="last" />
            <token id="17" string="big" />
            <token id="18" string="earthquake" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">evidence</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">is</governor>
          <dependent id="2">evidence</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">accumulated</governor>
          <dependent id="4">that</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">strain</governor>
          <dependent id="5">significant</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">accumulated</governor>
          <dependent id="6">strain</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">accumulated</governor>
          <dependent id="7">has</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">is</governor>
          <dependent id="8">accumulated</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">fault</governor>
          <dependent id="9">along</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">fault</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">accumulated</governor>
          <dependent id="11">fault</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">earthquake</governor>
          <dependent id="12">since</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">region</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="18">earthquake</governor>
          <dependent id="14">region</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">region</governor>
          <dependent id="15">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">earthquake</governor>
          <dependent id="16">last</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">earthquake</governor>
          <dependent id="17">big</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">fault</governor>
          <dependent id="18">earthquake</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="earthquake" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="18" string="earthquake" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="36" has_coreference="false">
      <content>Recognising precursors will still be difficult.</content>
      <tokens>
        <token id="1" string="Recognising" lemma="recognise" stem="recognis" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="precursors" lemma="precursor" stem="precursor" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="still" lemma="still" stem="still" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="difficult" lemma="difficult" stem="difficult" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (VBG Recognising) (NNS precursors)) (VP (MD will) (ADVP (RB still)) (VP (VB be) (ADJP (JJ difficult)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="be difficult" type="VP">
          <tokens>
            <token id="5" string="be" />
            <token id="6" string="difficult" />
          </tokens>
        </chunking>
        <chunking id="2" string="difficult" type="ADJP">
          <tokens>
            <token id="6" string="difficult" />
          </tokens>
        </chunking>
        <chunking id="3" string="Recognising precursors" type="NP">
          <tokens>
            <token id="1" string="Recognising" />
            <token id="2" string="precursors" />
          </tokens>
        </chunking>
        <chunking id="4" string="will still be difficult" type="VP">
          <tokens>
            <token id="3" string="will" />
            <token id="4" string="still" />
            <token id="5" string="be" />
            <token id="6" string="difficult" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="2">precursors</governor>
          <dependent id="1">Recognising</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">difficult</governor>
          <dependent id="2">precursors</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">difficult</governor>
          <dependent id="3">will</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">difficult</governor>
          <dependent id="4">still</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">difficult</governor>
          <dependent id="5">be</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">difficult</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="37" has_coreference="true">
      <content>Mogi says they now believe that precursor patterns may be particular to each section of a fault.</content>
      <tokens>
        <token id="1" string="Mogi" lemma="Mogi" stem="mogi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="5" string="believe" lemma="believe" stem="believ" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="precursor" lemma="precursor" stem="precursor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="patterns" lemma="pattern" stem="pattern" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="may" lemma="may" stem="mai" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="particular" lemma="particular" stem="particular" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="each" lemma="each" stem="each" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="section" lemma="section" stem="section" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="fault" lemma="fault" stem="fault" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Mogi)) (VP (VBZ says) (SBAR (S (NP (PRP they)) (ADVP (RB now)) (VP (VBP believe) (SBAR (IN that) (S (NP (NN precursor) (NNS patterns)) (VP (MD may) (VP (VB be) (ADJP (JJ particular) (PP (TO to) (NP (NP (DT each) (NN section)) (PP (IN of) (NP (DT a) (NN fault)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a fault" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="fault" />
          </tokens>
        </chunking>
        <chunking id="2" string="each section" type="NP">
          <tokens>
            <token id="13" string="each" />
            <token id="14" string="section" />
          </tokens>
        </chunking>
        <chunking id="3" string="be particular to each section of a fault" type="VP">
          <tokens>
            <token id="10" string="be" />
            <token id="11" string="particular" />
            <token id="12" string="to" />
            <token id="13" string="each" />
            <token id="14" string="section" />
            <token id="15" string="of" />
            <token id="16" string="a" />
            <token id="17" string="fault" />
          </tokens>
        </chunking>
        <chunking id="4" string="Mogi" type="NP">
          <tokens>
            <token id="1" string="Mogi" />
          </tokens>
        </chunking>
        <chunking id="5" string="says they now believe that precursor patterns may be particular to each section of a fault" type="VP">
          <tokens>
            <token id="2" string="says" />
            <token id="3" string="they" />
            <token id="4" string="now" />
            <token id="5" string="believe" />
            <token id="6" string="that" />
            <token id="7" string="precursor" />
            <token id="8" string="patterns" />
            <token id="9" string="may" />
            <token id="10" string="be" />
            <token id="11" string="particular" />
            <token id="12" string="to" />
            <token id="13" string="each" />
            <token id="14" string="section" />
            <token id="15" string="of" />
            <token id="16" string="a" />
            <token id="17" string="fault" />
          </tokens>
        </chunking>
        <chunking id="6" string="they" type="NP">
          <tokens>
            <token id="3" string="they" />
          </tokens>
        </chunking>
        <chunking id="7" string="that precursor patterns may be particular to each section of a fault" type="SBAR">
          <tokens>
            <token id="6" string="that" />
            <token id="7" string="precursor" />
            <token id="8" string="patterns" />
            <token id="9" string="may" />
            <token id="10" string="be" />
            <token id="11" string="particular" />
            <token id="12" string="to" />
            <token id="13" string="each" />
            <token id="14" string="section" />
            <token id="15" string="of" />
            <token id="16" string="a" />
            <token id="17" string="fault" />
          </tokens>
        </chunking>
        <chunking id="8" string="particular to each section of a fault" type="ADJP">
          <tokens>
            <token id="11" string="particular" />
            <token id="12" string="to" />
            <token id="13" string="each" />
            <token id="14" string="section" />
            <token id="15" string="of" />
            <token id="16" string="a" />
            <token id="17" string="fault" />
          </tokens>
        </chunking>
        <chunking id="9" string="each section of a fault" type="NP">
          <tokens>
            <token id="13" string="each" />
            <token id="14" string="section" />
            <token id="15" string="of" />
            <token id="16" string="a" />
            <token id="17" string="fault" />
          </tokens>
        </chunking>
        <chunking id="10" string="precursor patterns" type="NP">
          <tokens>
            <token id="7" string="precursor" />
            <token id="8" string="patterns" />
          </tokens>
        </chunking>
        <chunking id="11" string="believe that precursor patterns may be particular to each section of a fault" type="VP">
          <tokens>
            <token id="5" string="believe" />
            <token id="6" string="that" />
            <token id="7" string="precursor" />
            <token id="8" string="patterns" />
            <token id="9" string="may" />
            <token id="10" string="be" />
            <token id="11" string="particular" />
            <token id="12" string="to" />
            <token id="13" string="each" />
            <token id="14" string="section" />
            <token id="15" string="of" />
            <token id="16" string="a" />
            <token id="17" string="fault" />
          </tokens>
        </chunking>
        <chunking id="12" string="they now believe that precursor patterns may be particular to each section of a fault" type="SBAR">
          <tokens>
            <token id="3" string="they" />
            <token id="4" string="now" />
            <token id="5" string="believe" />
            <token id="6" string="that" />
            <token id="7" string="precursor" />
            <token id="8" string="patterns" />
            <token id="9" string="may" />
            <token id="10" string="be" />
            <token id="11" string="particular" />
            <token id="12" string="to" />
            <token id="13" string="each" />
            <token id="14" string="section" />
            <token id="15" string="of" />
            <token id="16" string="a" />
            <token id="17" string="fault" />
          </tokens>
        </chunking>
        <chunking id="13" string="may be particular to each section of a fault" type="VP">
          <tokens>
            <token id="9" string="may" />
            <token id="10" string="be" />
            <token id="11" string="particular" />
            <token id="12" string="to" />
            <token id="13" string="each" />
            <token id="14" string="section" />
            <token id="15" string="of" />
            <token id="16" string="a" />
            <token id="17" string="fault" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">says</governor>
          <dependent id="1">Mogi</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">says</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">believe</governor>
          <dependent id="3">they</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">believe</governor>
          <dependent id="4">now</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">says</governor>
          <dependent id="5">believe</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">particular</governor>
          <dependent id="6">that</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">patterns</governor>
          <dependent id="7">precursor</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">particular</governor>
          <dependent id="8">patterns</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">particular</governor>
          <dependent id="9">may</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="11">particular</governor>
          <dependent id="10">be</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">believe</governor>
          <dependent id="11">particular</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">section</governor>
          <dependent id="12">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">section</governor>
          <dependent id="13">each</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">particular</governor>
          <dependent id="14">section</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">fault</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">fault</governor>
          <dependent id="16">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">section</governor>
          <dependent id="17">fault</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="now" type="DATE" score="0.0">
          <tokens>
            <token id="4" string="now" />
          </tokens>
        </entity>
        <entity id="2" string="Mogi" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Mogi" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="38" has_coreference="true">
      <content>He says if they knew what precursory phenomena occurred the last time that section of the fault slipped, in 1854, they would be able to predict the next earthquake.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="knew" lemma="know" stem="knew" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="precursory" lemma="precursory" stem="precursori" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="phenomena" lemma="phenomenon" stem="phenomena" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="occurred" lemma="occur" stem="occur" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="section" lemma="section" stem="section" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="fault" lemma="fault" stem="fault" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="18" string="slipped" lemma="slip" stem="slip" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="1854" lemma="1854" stem="1854" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="able" lemma="able" stem="abl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="predict" lemma="predict" stem="predict" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="next" lemma="next" stem="next" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="earthquake" lemma="earthquake" stem="earthquak" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VBZ says) (SBAR (IN if) (S (NP (PRP they)) (VP (VBD knew) (SBAR (WHNP (WP what)) (S (NP (NN precursory) (NNS phenomena)) (VP (VBD occurred) (NP (NP (DT the) (JJ last) (NN time)) (SBAR (WHNP (WDT that)) (S (NP (NP (NN section)) (PP (IN of) (NP (DT the) (NN fault)))) (VP (VBD slipped) (SBAR (S (, ,) (PP (IN in) (NP (CD 1854))) (, ,) (NP (PRP they)) (VP (MD would) (VP (VB be) (ADJP (JJ able) (S (VP (TO to) (VP (VB predict) (NP (DT the) (JJ next) (NN earthquake))))))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="says if they knew what precursory phenomena occurred the last time that section of the fault slipped , in 1854 , they would be able to predict the next earthquake" type="VP">
          <tokens>
            <token id="2" string="says" />
            <token id="3" string="if" />
            <token id="4" string="they" />
            <token id="5" string="knew" />
            <token id="6" string="what" />
            <token id="7" string="precursory" />
            <token id="8" string="phenomena" />
            <token id="9" string="occurred" />
            <token id="10" string="the" />
            <token id="11" string="last" />
            <token id="12" string="time" />
            <token id="13" string="that" />
            <token id="14" string="section" />
            <token id="15" string="of" />
            <token id="16" string="the" />
            <token id="17" string="fault" />
            <token id="18" string="slipped" />
            <token id="19" string="," />
            <token id="20" string="in" />
            <token id="21" string="1854" />
            <token id="22" string="," />
            <token id="23" string="they" />
            <token id="24" string="would" />
            <token id="25" string="be" />
            <token id="26" string="able" />
            <token id="27" string="to" />
            <token id="28" string="predict" />
            <token id="29" string="the" />
            <token id="30" string="next" />
            <token id="31" string="earthquake" />
          </tokens>
        </chunking>
        <chunking id="2" string=", in 1854 , they would be able to predict the next earthquake" type="SBAR">
          <tokens>
            <token id="19" string="," />
            <token id="20" string="in" />
            <token id="21" string="1854" />
            <token id="22" string="," />
            <token id="23" string="they" />
            <token id="24" string="would" />
            <token id="25" string="be" />
            <token id="26" string="able" />
            <token id="27" string="to" />
            <token id="28" string="predict" />
            <token id="29" string="the" />
            <token id="30" string="next" />
            <token id="31" string="earthquake" />
          </tokens>
        </chunking>
        <chunking id="3" string="the next earthquake" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="next" />
            <token id="31" string="earthquake" />
          </tokens>
        </chunking>
        <chunking id="4" string="what precursory phenomena occurred the last time that section of the fault slipped , in 1854 , they would be able to predict the next earthquake" type="SBAR">
          <tokens>
            <token id="6" string="what" />
            <token id="7" string="precursory" />
            <token id="8" string="phenomena" />
            <token id="9" string="occurred" />
            <token id="10" string="the" />
            <token id="11" string="last" />
            <token id="12" string="time" />
            <token id="13" string="that" />
            <token id="14" string="section" />
            <token id="15" string="of" />
            <token id="16" string="the" />
            <token id="17" string="fault" />
            <token id="18" string="slipped" />
            <token id="19" string="," />
            <token id="20" string="in" />
            <token id="21" string="1854" />
            <token id="22" string="," />
            <token id="23" string="they" />
            <token id="24" string="would" />
            <token id="25" string="be" />
            <token id="26" string="able" />
            <token id="27" string="to" />
            <token id="28" string="predict" />
            <token id="29" string="the" />
            <token id="30" string="next" />
            <token id="31" string="earthquake" />
          </tokens>
        </chunking>
        <chunking id="5" string="predict the next earthquake" type="VP">
          <tokens>
            <token id="28" string="predict" />
            <token id="29" string="the" />
            <token id="30" string="next" />
            <token id="31" string="earthquake" />
          </tokens>
        </chunking>
        <chunking id="6" string="the fault" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="fault" />
          </tokens>
        </chunking>
        <chunking id="7" string="occurred the last time that section of the fault slipped , in 1854 , they would be able to predict the next earthquake" type="VP">
          <tokens>
            <token id="9" string="occurred" />
            <token id="10" string="the" />
            <token id="11" string="last" />
            <token id="12" string="time" />
            <token id="13" string="that" />
            <token id="14" string="section" />
            <token id="15" string="of" />
            <token id="16" string="the" />
            <token id="17" string="fault" />
            <token id="18" string="slipped" />
            <token id="19" string="," />
            <token id="20" string="in" />
            <token id="21" string="1854" />
            <token id="22" string="," />
            <token id="23" string="they" />
            <token id="24" string="would" />
            <token id="25" string="be" />
            <token id="26" string="able" />
            <token id="27" string="to" />
            <token id="28" string="predict" />
            <token id="29" string="the" />
            <token id="30" string="next" />
            <token id="31" string="earthquake" />
          </tokens>
        </chunking>
        <chunking id="8" string="section" type="NP">
          <tokens>
            <token id="14" string="section" />
          </tokens>
        </chunking>
        <chunking id="9" string="if they knew what precursory phenomena occurred the last time that section of the fault slipped , in 1854 , they would be able to predict the next earthquake" type="SBAR">
          <tokens>
            <token id="3" string="if" />
            <token id="4" string="they" />
            <token id="5" string="knew" />
            <token id="6" string="what" />
            <token id="7" string="precursory" />
            <token id="8" string="phenomena" />
            <token id="9" string="occurred" />
            <token id="10" string="the" />
            <token id="11" string="last" />
            <token id="12" string="time" />
            <token id="13" string="that" />
            <token id="14" string="section" />
            <token id="15" string="of" />
            <token id="16" string="the" />
            <token id="17" string="fault" />
            <token id="18" string="slipped" />
            <token id="19" string="," />
            <token id="20" string="in" />
            <token id="21" string="1854" />
            <token id="22" string="," />
            <token id="23" string="they" />
            <token id="24" string="would" />
            <token id="25" string="be" />
            <token id="26" string="able" />
            <token id="27" string="to" />
            <token id="28" string="predict" />
            <token id="29" string="the" />
            <token id="30" string="next" />
            <token id="31" string="earthquake" />
          </tokens>
        </chunking>
        <chunking id="10" string="knew what precursory phenomena occurred the last time that section of the fault slipped , in 1854 , they would be able to predict the next earthquake" type="VP">
          <tokens>
            <token id="5" string="knew" />
            <token id="6" string="what" />
            <token id="7" string="precursory" />
            <token id="8" string="phenomena" />
            <token id="9" string="occurred" />
            <token id="10" string="the" />
            <token id="11" string="last" />
            <token id="12" string="time" />
            <token id="13" string="that" />
            <token id="14" string="section" />
            <token id="15" string="of" />
            <token id="16" string="the" />
            <token id="17" string="fault" />
            <token id="18" string="slipped" />
            <token id="19" string="," />
            <token id="20" string="in" />
            <token id="21" string="1854" />
            <token id="22" string="," />
            <token id="23" string="they" />
            <token id="24" string="would" />
            <token id="25" string="be" />
            <token id="26" string="able" />
            <token id="27" string="to" />
            <token id="28" string="predict" />
            <token id="29" string="the" />
            <token id="30" string="next" />
            <token id="31" string="earthquake" />
          </tokens>
        </chunking>
        <chunking id="11" string="slipped , in 1854 , they would be able to predict the next earthquake" type="VP">
          <tokens>
            <token id="18" string="slipped" />
            <token id="19" string="," />
            <token id="20" string="in" />
            <token id="21" string="1854" />
            <token id="22" string="," />
            <token id="23" string="they" />
            <token id="24" string="would" />
            <token id="25" string="be" />
            <token id="26" string="able" />
            <token id="27" string="to" />
            <token id="28" string="predict" />
            <token id="29" string="the" />
            <token id="30" string="next" />
            <token id="31" string="earthquake" />
          </tokens>
        </chunking>
        <chunking id="12" string="the last time that section of the fault slipped , in 1854 , they would be able to predict the next earthquake" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="last" />
            <token id="12" string="time" />
            <token id="13" string="that" />
            <token id="14" string="section" />
            <token id="15" string="of" />
            <token id="16" string="the" />
            <token id="17" string="fault" />
            <token id="18" string="slipped" />
            <token id="19" string="," />
            <token id="20" string="in" />
            <token id="21" string="1854" />
            <token id="22" string="," />
            <token id="23" string="they" />
            <token id="24" string="would" />
            <token id="25" string="be" />
            <token id="26" string="able" />
            <token id="27" string="to" />
            <token id="28" string="predict" />
            <token id="29" string="the" />
            <token id="30" string="next" />
            <token id="31" string="earthquake" />
          </tokens>
        </chunking>
        <chunking id="13" string="would be able to predict the next earthquake" type="VP">
          <tokens>
            <token id="24" string="would" />
            <token id="25" string="be" />
            <token id="26" string="able" />
            <token id="27" string="to" />
            <token id="28" string="predict" />
            <token id="29" string="the" />
            <token id="30" string="next" />
            <token id="31" string="earthquake" />
          </tokens>
        </chunking>
        <chunking id="14" string="they" type="NP">
          <tokens>
            <token id="4" string="they" />
          </tokens>
        </chunking>
        <chunking id="15" string="1854" type="NP">
          <tokens>
            <token id="21" string="1854" />
          </tokens>
        </chunking>
        <chunking id="16" string="to predict the next earthquake" type="VP">
          <tokens>
            <token id="27" string="to" />
            <token id="28" string="predict" />
            <token id="29" string="the" />
            <token id="30" string="next" />
            <token id="31" string="earthquake" />
          </tokens>
        </chunking>
        <chunking id="17" string="able to predict the next earthquake" type="ADJP">
          <tokens>
            <token id="26" string="able" />
            <token id="27" string="to" />
            <token id="28" string="predict" />
            <token id="29" string="the" />
            <token id="30" string="next" />
            <token id="31" string="earthquake" />
          </tokens>
        </chunking>
        <chunking id="18" string="section of the fault" type="NP">
          <tokens>
            <token id="14" string="section" />
            <token id="15" string="of" />
            <token id="16" string="the" />
            <token id="17" string="fault" />
          </tokens>
        </chunking>
        <chunking id="19" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="20" string="precursory phenomena" type="NP">
          <tokens>
            <token id="7" string="precursory" />
            <token id="8" string="phenomena" />
          </tokens>
        </chunking>
        <chunking id="21" string="the last time" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="last" />
            <token id="12" string="time" />
          </tokens>
        </chunking>
        <chunking id="22" string="that section of the fault slipped , in 1854 , they would be able to predict the next earthquake" type="SBAR">
          <tokens>
            <token id="13" string="that" />
            <token id="14" string="section" />
            <token id="15" string="of" />
            <token id="16" string="the" />
            <token id="17" string="fault" />
            <token id="18" string="slipped" />
            <token id="19" string="," />
            <token id="20" string="in" />
            <token id="21" string="1854" />
            <token id="22" string="," />
            <token id="23" string="they" />
            <token id="24" string="would" />
            <token id="25" string="be" />
            <token id="26" string="able" />
            <token id="27" string="to" />
            <token id="28" string="predict" />
            <token id="29" string="the" />
            <token id="30" string="next" />
            <token id="31" string="earthquake" />
          </tokens>
        </chunking>
        <chunking id="23" string="be able to predict the next earthquake" type="VP">
          <tokens>
            <token id="25" string="be" />
            <token id="26" string="able" />
            <token id="27" string="to" />
            <token id="28" string="predict" />
            <token id="29" string="the" />
            <token id="30" string="next" />
            <token id="31" string="earthquake" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">says</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">says</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">knew</governor>
          <dependent id="3">if</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">knew</governor>
          <dependent id="4">they</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="2">says</governor>
          <dependent id="5">knew</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">occurred</governor>
          <dependent id="6">what</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">phenomena</governor>
          <dependent id="7">precursory</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">occurred</governor>
          <dependent id="8">phenomena</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">knew</governor>
          <dependent id="9">occurred</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">time</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">time</governor>
          <dependent id="11">last</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">occurred</governor>
          <dependent id="12">time</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">slipped</governor>
          <dependent id="13">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">slipped</governor>
          <dependent id="14">section</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">fault</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">fault</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">section</governor>
          <dependent id="17">fault</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="12">time</governor>
          <dependent id="18">slipped</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">1854</governor>
          <dependent id="20">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">able</governor>
          <dependent id="21">1854</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">able</governor>
          <dependent id="23">they</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="26">able</governor>
          <dependent id="24">would</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="26">able</governor>
          <dependent id="25">be</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="18">slipped</governor>
          <dependent id="26">able</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="28">predict</governor>
          <dependent id="27">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="26">able</governor>
          <dependent id="28">predict</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">earthquake</governor>
          <dependent id="29">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="31">earthquake</governor>
          <dependent id="30">next</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="28">predict</governor>
          <dependent id="31">earthquake</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1854" type="DATE" score="0.0">
          <tokens>
            <token id="21" string="1854" />
          </tokens>
        </entity>
        <entity id="2" string="earthquake" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="31" string="earthquake" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="39" has_coreference="true">
      <content>Instead, the six experts are watching for the rapid uplift of the crust on the westward side of the trough that preceded quakes along adjacent sections of the fault in 1944 and 1946.</content>
      <tokens>
        <token id="1" string="Instead" lemma="instead" stem="instead" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="six" lemma="six" stem="six" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="5" string="experts" lemma="expert" stem="expert" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="watching" lemma="watch" stem="watch" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="rapid" lemma="rapid" stem="rapid" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="uplift" lemma="uplift" stem="uplift" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="crust" lemma="crust" stem="crust" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="westward" lemma="westward" stem="westward" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="side" lemma="side" stem="side" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="trough" lemma="trough" stem="trough" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="preceded" lemma="precede" stem="preced" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="quakes" lemma="quake" stem="quak" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="25" string="along" lemma="along" stem="along" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="adjacent" lemma="adjacent" stem="adjac" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="sections" lemma="section" stem="section" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="30" string="fault" lemma="fault" stem="fault" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="31" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="1944" lemma="1944" stem="1944" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="33" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="1946" lemma="1946" stem="1946" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="35" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Instead)) (, ,) (NP (DT the) (CD six) (NNS experts)) (VP (VBP are) (VP (VBG watching) (PP (IN for) (NP (NP (DT the) (JJ rapid) (NN uplift)) (PP (IN of) (NP (DT the) (NN crust))))) (PP (IN on) (NP (NP (DT the) (ADVP (RB westward)) (NN side)) (PP (IN of) (NP (NP (DT the) (NN trough)) (SBAR (WHNP (WDT that)) (S (VP (VBD preceded) (NP (NNS quakes)) (PP (IN along) (NP (NP (JJ adjacent) (NNS sections)) (PP (IN of) (NP (DT the) (NN fault))))) (PP (IN in) (NP (CD 1944) (CC and) (CD 1946)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the crust" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="crust" />
          </tokens>
        </chunking>
        <chunking id="2" string="1944 and 1946" type="NP">
          <tokens>
            <token id="32" string="1944" />
            <token id="33" string="and" />
            <token id="34" string="1946" />
          </tokens>
        </chunking>
        <chunking id="3" string="quakes" type="NP">
          <tokens>
            <token id="24" string="quakes" />
          </tokens>
        </chunking>
        <chunking id="4" string="the fault" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="fault" />
          </tokens>
        </chunking>
        <chunking id="5" string="are watching for the rapid uplift of the crust on the westward side of the trough that preceded quakes along adjacent sections of the fault in 1944 and 1946" type="VP">
          <tokens>
            <token id="6" string="are" />
            <token id="7" string="watching" />
            <token id="8" string="for" />
            <token id="9" string="the" />
            <token id="10" string="rapid" />
            <token id="11" string="uplift" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="crust" />
            <token id="15" string="on" />
            <token id="16" string="the" />
            <token id="17" string="westward" />
            <token id="18" string="side" />
            <token id="19" string="of" />
            <token id="20" string="the" />
            <token id="21" string="trough" />
            <token id="22" string="that" />
            <token id="23" string="preceded" />
            <token id="24" string="quakes" />
            <token id="25" string="along" />
            <token id="26" string="adjacent" />
            <token id="27" string="sections" />
            <token id="28" string="of" />
            <token id="29" string="the" />
            <token id="30" string="fault" />
            <token id="31" string="in" />
            <token id="32" string="1944" />
            <token id="33" string="and" />
            <token id="34" string="1946" />
          </tokens>
        </chunking>
        <chunking id="6" string="the rapid uplift" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="rapid" />
            <token id="11" string="uplift" />
          </tokens>
        </chunking>
        <chunking id="7" string="the trough" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="trough" />
          </tokens>
        </chunking>
        <chunking id="8" string="the six experts" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="six" />
            <token id="5" string="experts" />
          </tokens>
        </chunking>
        <chunking id="9" string="the westward side" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="westward" />
            <token id="18" string="side" />
          </tokens>
        </chunking>
        <chunking id="10" string="the trough that preceded quakes along adjacent sections of the fault in 1944 and 1946" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="trough" />
            <token id="22" string="that" />
            <token id="23" string="preceded" />
            <token id="24" string="quakes" />
            <token id="25" string="along" />
            <token id="26" string="adjacent" />
            <token id="27" string="sections" />
            <token id="28" string="of" />
            <token id="29" string="the" />
            <token id="30" string="fault" />
            <token id="31" string="in" />
            <token id="32" string="1944" />
            <token id="33" string="and" />
            <token id="34" string="1946" />
          </tokens>
        </chunking>
        <chunking id="11" string="adjacent sections of the fault" type="NP">
          <tokens>
            <token id="26" string="adjacent" />
            <token id="27" string="sections" />
            <token id="28" string="of" />
            <token id="29" string="the" />
            <token id="30" string="fault" />
          </tokens>
        </chunking>
        <chunking id="12" string="preceded quakes along adjacent sections of the fault in 1944 and 1946" type="VP">
          <tokens>
            <token id="23" string="preceded" />
            <token id="24" string="quakes" />
            <token id="25" string="along" />
            <token id="26" string="adjacent" />
            <token id="27" string="sections" />
            <token id="28" string="of" />
            <token id="29" string="the" />
            <token id="30" string="fault" />
            <token id="31" string="in" />
            <token id="32" string="1944" />
            <token id="33" string="and" />
            <token id="34" string="1946" />
          </tokens>
        </chunking>
        <chunking id="13" string="the westward side of the trough that preceded quakes along adjacent sections of the fault in 1944 and 1946" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="westward" />
            <token id="18" string="side" />
            <token id="19" string="of" />
            <token id="20" string="the" />
            <token id="21" string="trough" />
            <token id="22" string="that" />
            <token id="23" string="preceded" />
            <token id="24" string="quakes" />
            <token id="25" string="along" />
            <token id="26" string="adjacent" />
            <token id="27" string="sections" />
            <token id="28" string="of" />
            <token id="29" string="the" />
            <token id="30" string="fault" />
            <token id="31" string="in" />
            <token id="32" string="1944" />
            <token id="33" string="and" />
            <token id="34" string="1946" />
          </tokens>
        </chunking>
        <chunking id="14" string="watching for the rapid uplift of the crust on the westward side of the trough that preceded quakes along adjacent sections of the fault in 1944 and 1946" type="VP">
          <tokens>
            <token id="7" string="watching" />
            <token id="8" string="for" />
            <token id="9" string="the" />
            <token id="10" string="rapid" />
            <token id="11" string="uplift" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="crust" />
            <token id="15" string="on" />
            <token id="16" string="the" />
            <token id="17" string="westward" />
            <token id="18" string="side" />
            <token id="19" string="of" />
            <token id="20" string="the" />
            <token id="21" string="trough" />
            <token id="22" string="that" />
            <token id="23" string="preceded" />
            <token id="24" string="quakes" />
            <token id="25" string="along" />
            <token id="26" string="adjacent" />
            <token id="27" string="sections" />
            <token id="28" string="of" />
            <token id="29" string="the" />
            <token id="30" string="fault" />
            <token id="31" string="in" />
            <token id="32" string="1944" />
            <token id="33" string="and" />
            <token id="34" string="1946" />
          </tokens>
        </chunking>
        <chunking id="15" string="adjacent sections" type="NP">
          <tokens>
            <token id="26" string="adjacent" />
            <token id="27" string="sections" />
          </tokens>
        </chunking>
        <chunking id="16" string="the rapid uplift of the crust" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="rapid" />
            <token id="11" string="uplift" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="crust" />
          </tokens>
        </chunking>
        <chunking id="17" string="that preceded quakes along adjacent sections of the fault in 1944 and 1946" type="SBAR">
          <tokens>
            <token id="22" string="that" />
            <token id="23" string="preceded" />
            <token id="24" string="quakes" />
            <token id="25" string="along" />
            <token id="26" string="adjacent" />
            <token id="27" string="sections" />
            <token id="28" string="of" />
            <token id="29" string="the" />
            <token id="30" string="fault" />
            <token id="31" string="in" />
            <token id="32" string="1944" />
            <token id="33" string="and" />
            <token id="34" string="1946" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="7">watching</governor>
          <dependent id="1">Instead</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">experts</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="5">experts</governor>
          <dependent id="4">six</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">watching</governor>
          <dependent id="5">experts</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">watching</governor>
          <dependent id="6">are</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">watching</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">uplift</governor>
          <dependent id="8">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">uplift</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">uplift</governor>
          <dependent id="10">rapid</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">watching</governor>
          <dependent id="11">uplift</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">crust</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">crust</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">uplift</governor>
          <dependent id="14">crust</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">side</governor>
          <dependent id="15">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">side</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">side</governor>
          <dependent id="17">westward</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">watching</governor>
          <dependent id="18">side</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">trough</governor>
          <dependent id="19">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">trough</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">side</governor>
          <dependent id="21">trough</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">preceded</governor>
          <dependent id="22">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="21">trough</governor>
          <dependent id="23">preceded</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="23">preceded</governor>
          <dependent id="24">quakes</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">sections</governor>
          <dependent id="25">along</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="27">sections</governor>
          <dependent id="26">adjacent</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">preceded</governor>
          <dependent id="27">sections</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">fault</governor>
          <dependent id="28">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">fault</governor>
          <dependent id="29">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">sections</governor>
          <dependent id="30">fault</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">1944</governor>
          <dependent id="31">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">preceded</governor>
          <dependent id="32">1944</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="32">1944</governor>
          <dependent id="33">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="32">1944</governor>
          <dependent id="34">1946</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="six" type="NUMBER" score="0.0">
          <tokens>
            <token id="4" string="six" />
          </tokens>
        </entity>
        <entity id="2" string="1944" type="DATE" score="0.0">
          <tokens>
            <token id="32" string="1944" />
          </tokens>
        </entity>
        <entity id="3" string="1946" type="DATE" score="0.0">
          <tokens>
            <token id="34" string="1946" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="40" has_coreference="false">
      <content>This all makes a successful prediction a long shot.</content>
      <tokens>
        <token id="1" string="This" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="makes" lemma="make" stem="make" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="successful" lemma="successful" stem="success" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="prediction" lemma="prediction" stem="predict" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="long" lemma="long" stem="long" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="shot" lemma="shot" stem="shot" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT This)) (ADVP (DT all)) (VP (VBZ makes) (NP (NP (DT a) (JJ successful) (NN prediction)) (NP (DT a) (JJ long) (NN shot)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="makes a successful prediction a long shot" type="VP">
          <tokens>
            <token id="3" string="makes" />
            <token id="4" string="a" />
            <token id="5" string="successful" />
            <token id="6" string="prediction" />
            <token id="7" string="a" />
            <token id="8" string="long" />
            <token id="9" string="shot" />
          </tokens>
        </chunking>
        <chunking id="2" string="This" type="NP">
          <tokens>
            <token id="1" string="This" />
          </tokens>
        </chunking>
        <chunking id="3" string="a successful prediction a long shot" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="successful" />
            <token id="6" string="prediction" />
            <token id="7" string="a" />
            <token id="8" string="long" />
            <token id="9" string="shot" />
          </tokens>
        </chunking>
        <chunking id="4" string="a successful prediction" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="successful" />
            <token id="6" string="prediction" />
          </tokens>
        </chunking>
        <chunking id="5" string="a long shot" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="long" />
            <token id="9" string="shot" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">makes</governor>
          <dependent id="1">This</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">makes</governor>
          <dependent id="2">all</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">makes</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">prediction</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">prediction</governor>
          <dependent id="5">successful</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">makes</governor>
          <dependent id="6">prediction</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">shot</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">shot</governor>
          <dependent id="8">long</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="6">prediction</governor>
          <dependent id="9">shot</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="41" has_coreference="true">
      <content>Aside from the Tokai effort, scientists outside the programme are disturbed that it is so generously funded and has so little to show.</content>
      <tokens>
        <token id="1" string="Aside" lemma="aside" stem="aside" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="Tokai" lemma="Tokai" stem="tokai" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="5" string="effort" lemma="effort" stem="effort" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="scientists" lemma="scientist" stem="scientist" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="outside" lemma="outside" stem="outsid" pos="IN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="programme" lemma="programme" stem="programm" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="disturbed" lemma="disturb" stem="disturb" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="so" lemma="so" stem="so" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="generously" lemma="generously" stem="gener" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="funded" lemma="fund" stem="fund" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="so" lemma="so" stem="so" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="little" lemma="little" stem="littl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="show" lemma="show" stem="show" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (RB Aside) (PP (IN from) (NP (DT the) (NNP Tokai) (NN effort)))) (, ,) (NP (NP (NNS scientists)) (PP (IN outside) (NP (DT the) (NN programme)))) (VP (VP (VBP are) (VP (VBN disturbed) (SBAR (IN that) (S (NP (PRP it)) (VP (VBZ is) (ADVP (RB so)) (VP (ADVP (RB generously)) (VBN funded))))))) (CC and) (VP (VBZ has) (ADJP (RB so) (JJ little) (S (VP (TO to) (VP (VB show))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="are disturbed that it is so generously funded and has so little to show" type="VP">
          <tokens>
            <token id="11" string="are" />
            <token id="12" string="disturbed" />
            <token id="13" string="that" />
            <token id="14" string="it" />
            <token id="15" string="is" />
            <token id="16" string="so" />
            <token id="17" string="generously" />
            <token id="18" string="funded" />
            <token id="19" string="and" />
            <token id="20" string="has" />
            <token id="21" string="so" />
            <token id="22" string="little" />
            <token id="23" string="to" />
            <token id="24" string="show" />
          </tokens>
        </chunking>
        <chunking id="2" string="scientists outside the programme" type="NP">
          <tokens>
            <token id="7" string="scientists" />
            <token id="8" string="outside" />
            <token id="9" string="the" />
            <token id="10" string="programme" />
          </tokens>
        </chunking>
        <chunking id="3" string="is so generously funded" type="VP">
          <tokens>
            <token id="15" string="is" />
            <token id="16" string="so" />
            <token id="17" string="generously" />
            <token id="18" string="funded" />
          </tokens>
        </chunking>
        <chunking id="4" string="has so little to show" type="VP">
          <tokens>
            <token id="20" string="has" />
            <token id="21" string="so" />
            <token id="22" string="little" />
            <token id="23" string="to" />
            <token id="24" string="show" />
          </tokens>
        </chunking>
        <chunking id="5" string="show" type="VP">
          <tokens>
            <token id="24" string="show" />
          </tokens>
        </chunking>
        <chunking id="6" string="it" type="NP">
          <tokens>
            <token id="14" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="generously funded" type="VP">
          <tokens>
            <token id="17" string="generously" />
            <token id="18" string="funded" />
          </tokens>
        </chunking>
        <chunking id="8" string="disturbed that it is so generously funded" type="VP">
          <tokens>
            <token id="12" string="disturbed" />
            <token id="13" string="that" />
            <token id="14" string="it" />
            <token id="15" string="is" />
            <token id="16" string="so" />
            <token id="17" string="generously" />
            <token id="18" string="funded" />
          </tokens>
        </chunking>
        <chunking id="9" string="scientists" type="NP">
          <tokens>
            <token id="7" string="scientists" />
          </tokens>
        </chunking>
        <chunking id="10" string="to show" type="VP">
          <tokens>
            <token id="23" string="to" />
            <token id="24" string="show" />
          </tokens>
        </chunking>
        <chunking id="11" string="the Tokai effort" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="Tokai" />
            <token id="5" string="effort" />
          </tokens>
        </chunking>
        <chunking id="12" string="the programme" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="programme" />
          </tokens>
        </chunking>
        <chunking id="13" string="that it is so generously funded" type="SBAR">
          <tokens>
            <token id="13" string="that" />
            <token id="14" string="it" />
            <token id="15" string="is" />
            <token id="16" string="so" />
            <token id="17" string="generously" />
            <token id="18" string="funded" />
          </tokens>
        </chunking>
        <chunking id="14" string="so little to show" type="ADJP">
          <tokens>
            <token id="21" string="so" />
            <token id="22" string="little" />
            <token id="23" string="to" />
            <token id="24" string="show" />
          </tokens>
        </chunking>
        <chunking id="15" string="are disturbed that it is so generously funded" type="VP">
          <tokens>
            <token id="11" string="are" />
            <token id="12" string="disturbed" />
            <token id="13" string="that" />
            <token id="14" string="it" />
            <token id="15" string="is" />
            <token id="16" string="so" />
            <token id="17" string="generously" />
            <token id="18" string="funded" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="5">effort</governor>
          <dependent id="1">Aside</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="1">Aside</governor>
          <dependent id="2">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">effort</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">effort</governor>
          <dependent id="4">Tokai</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="12">disturbed</governor>
          <dependent id="5">effort</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="12">disturbed</governor>
          <dependent id="7">scientists</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">programme</governor>
          <dependent id="8">outside</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">programme</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">scientists</governor>
          <dependent id="10">programme</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="12">disturbed</governor>
          <dependent id="11">are</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">disturbed</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">funded</governor>
          <dependent id="13">that</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="18">funded</governor>
          <dependent id="14">it</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="18">funded</governor>
          <dependent id="15">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">funded</governor>
          <dependent id="16">so</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">funded</governor>
          <dependent id="17">generously</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="12">disturbed</governor>
          <dependent id="18">funded</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="12">disturbed</governor>
          <dependent id="19">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">disturbed</governor>
          <dependent id="20">has</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="22">little</governor>
          <dependent id="21">so</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="20">has</governor>
          <dependent id="22">little</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="24">show</governor>
          <dependent id="23">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="22">little</governor>
          <dependent id="24">show</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Tokai" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="4" string="Tokai" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="42" has_coreference="true">
      <content>Prediction research elsewhere withered as scientists who could not convince review committees of the scientific merit of their research lost their funding.</content>
      <tokens>
        <token id="1" string="Prediction" lemma="prediction" stem="predict" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="research" lemma="research" stem="research" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="elsewhere" lemma="elsewhere" stem="elsewher" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="withered" lemma="wither" stem="wither" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="scientists" lemma="scientist" stem="scientist" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="convince" lemma="convince" stem="convinc" pos="VB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="review" lemma="review" stem="review" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="committees" lemma="committee" stem="committe" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="scientific" lemma="scientific" stem="scientif" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="merit" lemma="merit" stem="merit" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="19" string="research" lemma="research" stem="research" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="lost" lemma="lose" stem="lost" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="funding" lemma="funding" stem="fund" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NN Prediction) (NN research)) (ADVP (RB elsewhere)) (VP (VBD withered) (SBAR (IN as) (S (NP (NP (NNS scientists)) (SBAR (WHNP (WP who)) (S (VP (MD could) (RB not) (VP (VB convince) (NP (NP (NN review) (NNS committees)) (PP (IN of) (NP (NP (DT the) (JJ scientific) (NN merit)) (PP (IN of) (NP (PRP$ their) (NN research))))))))))) (VP (VBD lost) (NP (PRP$ their) (NN funding)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="scientists who could not convince review committees of the scientific merit of their research" type="NP">
          <tokens>
            <token id="6" string="scientists" />
            <token id="7" string="who" />
            <token id="8" string="could" />
            <token id="9" string="not" />
            <token id="10" string="convince" />
            <token id="11" string="review" />
            <token id="12" string="committees" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="scientific" />
            <token id="16" string="merit" />
            <token id="17" string="of" />
            <token id="18" string="their" />
            <token id="19" string="research" />
          </tokens>
        </chunking>
        <chunking id="2" string="who could not convince review committees of the scientific merit of their research" type="SBAR">
          <tokens>
            <token id="7" string="who" />
            <token id="8" string="could" />
            <token id="9" string="not" />
            <token id="10" string="convince" />
            <token id="11" string="review" />
            <token id="12" string="committees" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="scientific" />
            <token id="16" string="merit" />
            <token id="17" string="of" />
            <token id="18" string="their" />
            <token id="19" string="research" />
          </tokens>
        </chunking>
        <chunking id="3" string="convince review committees of the scientific merit of their research" type="VP">
          <tokens>
            <token id="10" string="convince" />
            <token id="11" string="review" />
            <token id="12" string="committees" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="scientific" />
            <token id="16" string="merit" />
            <token id="17" string="of" />
            <token id="18" string="their" />
            <token id="19" string="research" />
          </tokens>
        </chunking>
        <chunking id="4" string="Prediction research" type="NP">
          <tokens>
            <token id="1" string="Prediction" />
            <token id="2" string="research" />
          </tokens>
        </chunking>
        <chunking id="5" string="the scientific merit of their research" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="scientific" />
            <token id="16" string="merit" />
            <token id="17" string="of" />
            <token id="18" string="their" />
            <token id="19" string="research" />
          </tokens>
        </chunking>
        <chunking id="6" string="as scientists who could not convince review committees of the scientific merit of their research lost their funding" type="SBAR">
          <tokens>
            <token id="5" string="as" />
            <token id="6" string="scientists" />
            <token id="7" string="who" />
            <token id="8" string="could" />
            <token id="9" string="not" />
            <token id="10" string="convince" />
            <token id="11" string="review" />
            <token id="12" string="committees" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="scientific" />
            <token id="16" string="merit" />
            <token id="17" string="of" />
            <token id="18" string="their" />
            <token id="19" string="research" />
            <token id="20" string="lost" />
            <token id="21" string="their" />
            <token id="22" string="funding" />
          </tokens>
        </chunking>
        <chunking id="7" string="withered as scientists who could not convince review committees of the scientific merit of their research lost their funding" type="VP">
          <tokens>
            <token id="4" string="withered" />
            <token id="5" string="as" />
            <token id="6" string="scientists" />
            <token id="7" string="who" />
            <token id="8" string="could" />
            <token id="9" string="not" />
            <token id="10" string="convince" />
            <token id="11" string="review" />
            <token id="12" string="committees" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="scientific" />
            <token id="16" string="merit" />
            <token id="17" string="of" />
            <token id="18" string="their" />
            <token id="19" string="research" />
            <token id="20" string="lost" />
            <token id="21" string="their" />
            <token id="22" string="funding" />
          </tokens>
        </chunking>
        <chunking id="8" string="scientists" type="NP">
          <tokens>
            <token id="6" string="scientists" />
          </tokens>
        </chunking>
        <chunking id="9" string="their funding" type="NP">
          <tokens>
            <token id="21" string="their" />
            <token id="22" string="funding" />
          </tokens>
        </chunking>
        <chunking id="10" string="the scientific merit" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="scientific" />
            <token id="16" string="merit" />
          </tokens>
        </chunking>
        <chunking id="11" string="their research" type="NP">
          <tokens>
            <token id="18" string="their" />
            <token id="19" string="research" />
          </tokens>
        </chunking>
        <chunking id="12" string="could not convince review committees of the scientific merit of their research" type="VP">
          <tokens>
            <token id="8" string="could" />
            <token id="9" string="not" />
            <token id="10" string="convince" />
            <token id="11" string="review" />
            <token id="12" string="committees" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="scientific" />
            <token id="16" string="merit" />
            <token id="17" string="of" />
            <token id="18" string="their" />
            <token id="19" string="research" />
          </tokens>
        </chunking>
        <chunking id="13" string="review committees" type="NP">
          <tokens>
            <token id="11" string="review" />
            <token id="12" string="committees" />
          </tokens>
        </chunking>
        <chunking id="14" string="lost their funding" type="VP">
          <tokens>
            <token id="20" string="lost" />
            <token id="21" string="their" />
            <token id="22" string="funding" />
          </tokens>
        </chunking>
        <chunking id="15" string="review committees of the scientific merit of their research" type="NP">
          <tokens>
            <token id="11" string="review" />
            <token id="12" string="committees" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="scientific" />
            <token id="16" string="merit" />
            <token id="17" string="of" />
            <token id="18" string="their" />
            <token id="19" string="research" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">research</governor>
          <dependent id="1">Prediction</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">withered</governor>
          <dependent id="2">research</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">withered</governor>
          <dependent id="3">elsewhere</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">withered</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="20">lost</governor>
          <dependent id="5">as</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">lost</governor>
          <dependent id="6">scientists</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">convince</governor>
          <dependent id="7">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="10">convince</governor>
          <dependent id="8">could</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="10">convince</governor>
          <dependent id="9">not</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="6">scientists</governor>
          <dependent id="10">convince</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">committees</governor>
          <dependent id="11">review</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">convince</governor>
          <dependent id="12">committees</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">merit</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">merit</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">merit</governor>
          <dependent id="15">scientific</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">committees</governor>
          <dependent id="16">merit</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">research</governor>
          <dependent id="17">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="19">research</governor>
          <dependent id="18">their</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">merit</governor>
          <dependent id="19">research</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">withered</governor>
          <dependent id="20">lost</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="22">funding</governor>
          <dependent id="21">their</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">lost</governor>
          <dependent id="22">funding</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="43" has_coreference="false">
      <content>Japan&amp;apost;s prediction research activities, primarily overseen by the Ministry of Education, Science and Culture, are subject to no such review.</content>
      <tokens>
        <token id="1" string="Japan" lemma="Japan" stem="japan" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="2" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="prediction" lemma="prediction" stem="predict" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="research" lemma="research" stem="research" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="activities" lemma="activity" stem="activ" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="primarily" lemma="primarily" stem="primarili" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="overseen" lemma="oversee" stem="overseen" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Ministry" lemma="Ministry" stem="ministri" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="13" string="Education" lemma="Education" stem="educat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="Science" lemma="Science" stem="scienc" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Culture" lemma="Culture" stem="cultur" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="subject" lemma="subject" stem="subject" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="such" lemma="such" stem="such" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="review" lemma="review" stem="review" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NP (NNP Japan) (POS 's)) (NN prediction) (NN research) (NNS activities)) (, ,) (VP (ADVP (RB primarily)) (VBN overseen) (PP (IN by) (NP (NP (DT the) (NNP Ministry)) (PP (IN of) (NP (NNP Education) (, ,) (NNP Science) (CC and) (NNP Culture)))))) (, ,)) (VP (VBP are) (ADJP (JJ subject) (PP (TO to) (NP (DT no) (JJ such) (NN review))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Japan 's prediction research activities" type="NP">
          <tokens>
            <token id="1" string="Japan" />
            <token id="2" string="'s" />
            <token id="3" string="prediction" />
            <token id="4" string="research" />
            <token id="5" string="activities" />
          </tokens>
        </chunking>
        <chunking id="2" string="primarily overseen by the Ministry of Education , Science and Culture" type="VP">
          <tokens>
            <token id="7" string="primarily" />
            <token id="8" string="overseen" />
            <token id="9" string="by" />
            <token id="10" string="the" />
            <token id="11" string="Ministry" />
            <token id="12" string="of" />
            <token id="13" string="Education" />
            <token id="14" string="," />
            <token id="15" string="Science" />
            <token id="16" string="and" />
            <token id="17" string="Culture" />
          </tokens>
        </chunking>
        <chunking id="3" string="the Ministry of Education , Science and Culture" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="Ministry" />
            <token id="12" string="of" />
            <token id="13" string="Education" />
            <token id="14" string="," />
            <token id="15" string="Science" />
            <token id="16" string="and" />
            <token id="17" string="Culture" />
          </tokens>
        </chunking>
        <chunking id="4" string="Education , Science and Culture" type="NP">
          <tokens>
            <token id="13" string="Education" />
            <token id="14" string="," />
            <token id="15" string="Science" />
            <token id="16" string="and" />
            <token id="17" string="Culture" />
          </tokens>
        </chunking>
        <chunking id="5" string="no such review" type="NP">
          <tokens>
            <token id="22" string="no" />
            <token id="23" string="such" />
            <token id="24" string="review" />
          </tokens>
        </chunking>
        <chunking id="6" string="the Ministry" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="Ministry" />
          </tokens>
        </chunking>
        <chunking id="7" string="are subject to no such review" type="VP">
          <tokens>
            <token id="19" string="are" />
            <token id="20" string="subject" />
            <token id="21" string="to" />
            <token id="22" string="no" />
            <token id="23" string="such" />
            <token id="24" string="review" />
          </tokens>
        </chunking>
        <chunking id="8" string="subject to no such review" type="ADJP">
          <tokens>
            <token id="20" string="subject" />
            <token id="21" string="to" />
            <token id="22" string="no" />
            <token id="23" string="such" />
            <token id="24" string="review" />
          </tokens>
        </chunking>
        <chunking id="9" string="Japan 's prediction research activities , primarily overseen by the Ministry of Education , Science and Culture ," type="NP">
          <tokens>
            <token id="1" string="Japan" />
            <token id="2" string="'s" />
            <token id="3" string="prediction" />
            <token id="4" string="research" />
            <token id="5" string="activities" />
            <token id="6" string="," />
            <token id="7" string="primarily" />
            <token id="8" string="overseen" />
            <token id="9" string="by" />
            <token id="10" string="the" />
            <token id="11" string="Ministry" />
            <token id="12" string="of" />
            <token id="13" string="Education" />
            <token id="14" string="," />
            <token id="15" string="Science" />
            <token id="16" string="and" />
            <token id="17" string="Culture" />
            <token id="18" string="," />
          </tokens>
        </chunking>
        <chunking id="10" string="Japan 's" type="NP">
          <tokens>
            <token id="1" string="Japan" />
            <token id="2" string="'s" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="5">activities</governor>
          <dependent id="1">Japan</dependent>
        </dependency>
        <dependency type="case">
          <governor id="1">Japan</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">activities</governor>
          <dependent id="3">prediction</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">activities</governor>
          <dependent id="4">research</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">subject</governor>
          <dependent id="5">activities</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">overseen</governor>
          <dependent id="7">primarily</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="5">activities</governor>
          <dependent id="8">overseen</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Ministry</governor>
          <dependent id="9">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">Ministry</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">overseen</governor>
          <dependent id="11">Ministry</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Education</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">Ministry</governor>
          <dependent id="13">Education</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">Education</governor>
          <dependent id="15">Science</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">Education</governor>
          <dependent id="16">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">Education</governor>
          <dependent id="17">Culture</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="20">subject</governor>
          <dependent id="19">are</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="20">subject</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">review</governor>
          <dependent id="21">to</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="24">review</governor>
          <dependent id="22">no</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">review</governor>
          <dependent id="23">such</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">subject</governor>
          <dependent id="24">review</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Japan" type="LOCATION" score="0.0">
          <tokens>
            <token id="1" string="Japan" />
          </tokens>
        </entity>
        <entity id="2" string="Ministry of Education" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="11" string="Ministry" />
            <token id="12" string="of" />
            <token id="13" string="Education" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="44" has_coreference="false">
      <content>A sub-committee of one of the ministry&amp;apost;s innumerable advisory bodies draws up five-year plans.</content>
      <tokens>
        <token id="1" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="sub-committee" lemma="sub-committee" stem="sub-committe" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="ministry" lemma="ministry" stem="ministri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="innumerable" lemma="innumerable" stem="innumer" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="advisory" lemma="advisory" stem="advisori" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="bodies" lemma="body" stem="bodi" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="draws" lemma="draw" stem="draw" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="five-year" lemma="five-year" stem="five-year" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="15" string="plans" lemma="plan" stem="plan" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT A) (NN sub-committee)) (PP (IN of) (NP (NP (CD one)) (PP (IN of) (NP (NP (DT the) (NN ministry) (POS 's)) (ADJP (JJ innumerable)) (JJ advisory) (NNS bodies)))))) (VP (VBZ draws) (PRT (RP up)) (NP (JJ five-year) (NNS plans))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="one of the ministry 's innumerable advisory bodies" type="NP">
          <tokens>
            <token id="4" string="one" />
            <token id="5" string="of" />
            <token id="6" string="the" />
            <token id="7" string="ministry" />
            <token id="8" string="'s" />
            <token id="9" string="innumerable" />
            <token id="10" string="advisory" />
            <token id="11" string="bodies" />
          </tokens>
        </chunking>
        <chunking id="2" string="one" type="NP">
          <tokens>
            <token id="4" string="one" />
          </tokens>
        </chunking>
        <chunking id="3" string="draws up five-year plans" type="VP">
          <tokens>
            <token id="12" string="draws" />
            <token id="13" string="up" />
            <token id="14" string="five-year" />
            <token id="15" string="plans" />
          </tokens>
        </chunking>
        <chunking id="4" string="A sub-committee of one of the ministry 's innumerable advisory bodies" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="sub-committee" />
            <token id="3" string="of" />
            <token id="4" string="one" />
            <token id="5" string="of" />
            <token id="6" string="the" />
            <token id="7" string="ministry" />
            <token id="8" string="'s" />
            <token id="9" string="innumerable" />
            <token id="10" string="advisory" />
            <token id="11" string="bodies" />
          </tokens>
        </chunking>
        <chunking id="5" string="the ministry 's" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="ministry" />
            <token id="8" string="'s" />
          </tokens>
        </chunking>
        <chunking id="6" string="innumerable" type="ADJP">
          <tokens>
            <token id="9" string="innumerable" />
          </tokens>
        </chunking>
        <chunking id="7" string="five-year plans" type="NP">
          <tokens>
            <token id="14" string="five-year" />
            <token id="15" string="plans" />
          </tokens>
        </chunking>
        <chunking id="8" string="the ministry 's innumerable advisory bodies" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="ministry" />
            <token id="8" string="'s" />
            <token id="9" string="innumerable" />
            <token id="10" string="advisory" />
            <token id="11" string="bodies" />
          </tokens>
        </chunking>
        <chunking id="9" string="A sub-committee" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="sub-committee" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">sub-committee</governor>
          <dependent id="1">A</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">draws</governor>
          <dependent id="2">sub-committee</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">one</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">sub-committee</governor>
          <dependent id="4">one</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">bodies</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">ministry</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">bodies</governor>
          <dependent id="7">ministry</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">ministry</governor>
          <dependent id="8">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">bodies</governor>
          <dependent id="9">innumerable</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">bodies</governor>
          <dependent id="10">advisory</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">one</governor>
          <dependent id="11">bodies</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">draws</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="12">draws</governor>
          <dependent id="13">up</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">plans</governor>
          <dependent id="14">five-year</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">draws</governor>
          <dependent id="15">plans</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="4" string="one" />
          </tokens>
        </entity>
        <entity id="2" string="five-year" type="DURATION" score="0.0">
          <tokens>
            <token id="14" string="five-year" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="45" has_coreference="false">
      <content>But, in effect, the budget is divided among researchers and institutions in the same proportions each year.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="effect" lemma="effect" stem="effect" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="budget" lemma="budget" stem="budget" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="divided" lemma="divide" stem="divid" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="among" lemma="among" stem="among" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="researchers" lemma="researcher" stem="research" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="institutions" lemma="institution" stem="institut" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="same" lemma="same" stem="same" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="proportions" lemma="proportion" stem="proport" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="each" lemma="each" stem="each" pos="DT" type="Word" isStopWord="true" ner="SET" is_referenced="false" is_refers="false" />
        <token id="19" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="SET" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (, ,) (PP (IN in) (NP (NN effect))) (, ,) (NP (DT the) (NN budget)) (VP (VBZ is) (VP (VBN divided) (PP (IN among) (NP (NNS researchers) (CC and) (NNS institutions))) (PP (IN in) (NP (NP (DT the) (JJ same) (NNS proportions)) (NP (DT each) (NN year)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the same proportions each year" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="same" />
            <token id="17" string="proportions" />
            <token id="18" string="each" />
            <token id="19" string="year" />
          </tokens>
        </chunking>
        <chunking id="2" string="the same proportions" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="same" />
            <token id="17" string="proportions" />
          </tokens>
        </chunking>
        <chunking id="3" string="each year" type="NP">
          <tokens>
            <token id="18" string="each" />
            <token id="19" string="year" />
          </tokens>
        </chunking>
        <chunking id="4" string="effect" type="NP">
          <tokens>
            <token id="4" string="effect" />
          </tokens>
        </chunking>
        <chunking id="5" string="researchers and institutions" type="NP">
          <tokens>
            <token id="11" string="researchers" />
            <token id="12" string="and" />
            <token id="13" string="institutions" />
          </tokens>
        </chunking>
        <chunking id="6" string="is divided among researchers and institutions in the same proportions each year" type="VP">
          <tokens>
            <token id="8" string="is" />
            <token id="9" string="divided" />
            <token id="10" string="among" />
            <token id="11" string="researchers" />
            <token id="12" string="and" />
            <token id="13" string="institutions" />
            <token id="14" string="in" />
            <token id="15" string="the" />
            <token id="16" string="same" />
            <token id="17" string="proportions" />
            <token id="18" string="each" />
            <token id="19" string="year" />
          </tokens>
        </chunking>
        <chunking id="7" string="the budget" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="budget" />
          </tokens>
        </chunking>
        <chunking id="8" string="divided among researchers and institutions in the same proportions each year" type="VP">
          <tokens>
            <token id="9" string="divided" />
            <token id="10" string="among" />
            <token id="11" string="researchers" />
            <token id="12" string="and" />
            <token id="13" string="institutions" />
            <token id="14" string="in" />
            <token id="15" string="the" />
            <token id="16" string="same" />
            <token id="17" string="proportions" />
            <token id="18" string="each" />
            <token id="19" string="year" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="9">divided</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">effect</governor>
          <dependent id="3">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">divided</governor>
          <dependent id="4">effect</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">budget</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="9">divided</governor>
          <dependent id="7">budget</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="9">divided</governor>
          <dependent id="8">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">divided</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">researchers</governor>
          <dependent id="10">among</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">divided</governor>
          <dependent id="11">researchers</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="11">researchers</governor>
          <dependent id="12">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">researchers</governor>
          <dependent id="13">institutions</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">proportions</governor>
          <dependent id="14">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">proportions</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">proportions</governor>
          <dependent id="16">same</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">divided</governor>
          <dependent id="17">proportions</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">year</governor>
          <dependent id="18">each</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="17">proportions</governor>
          <dependent id="19">year</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="each year" type="SET" score="0.0">
          <tokens>
            <token id="18" string="each" />
            <token id="19" string="year" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="46" has_coreference="false">
      <content>The public, and even public officials, remain largely unaware that Japan&amp;apost;s scientists are debating whether prediction is impossible or merely difficult.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="public" lemma="public" stem="public" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="public" lemma="public" stem="public" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="officials" lemma="official" stem="offici" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="remain" lemma="remain" stem="remain" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="largely" lemma="largely" stem="larg" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="unaware" lemma="unaware" stem="unawar" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Japan" lemma="Japan" stem="japan" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="14" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="scientists" lemma="scientist" stem="scientist" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="debating" lemma="debate" stem="debat" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="whether" lemma="whether" stem="whether" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="prediction" lemma="prediction" stem="predict" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="impossible" lemma="impossible" stem="imposs" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="merely" lemma="merely" stem="mere" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="difficult" lemma="difficult" stem="difficult" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (NN public)) (, ,) (CC and) (RB even) (NP (JJ public) (NNS officials)) (, ,)) (VP (VBP remain) (ADJP (RB largely) (JJ unaware) (SBAR (IN that) (S (NP (NP (NNP Japan) (POS 's)) (NNS scientists)) (VP (VBP are) (VP (VBG debating) (SBAR (IN whether) (S (NP (NN prediction)) (VP (VBZ is) (ADJP (ADJP (JJ impossible)) (CC or) (ADJP (RB merely) (JJ difficult)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="remain largely unaware that Japan 's scientists are debating whether prediction is impossible or merely difficult" type="VP">
          <tokens>
            <token id="9" string="remain" />
            <token id="10" string="largely" />
            <token id="11" string="unaware" />
            <token id="12" string="that" />
            <token id="13" string="Japan" />
            <token id="14" string="'s" />
            <token id="15" string="scientists" />
            <token id="16" string="are" />
            <token id="17" string="debating" />
            <token id="18" string="whether" />
            <token id="19" string="prediction" />
            <token id="20" string="is" />
            <token id="21" string="impossible" />
            <token id="22" string="or" />
            <token id="23" string="merely" />
            <token id="24" string="difficult" />
          </tokens>
        </chunking>
        <chunking id="2" string="that Japan 's scientists are debating whether prediction is impossible or merely difficult" type="SBAR">
          <tokens>
            <token id="12" string="that" />
            <token id="13" string="Japan" />
            <token id="14" string="'s" />
            <token id="15" string="scientists" />
            <token id="16" string="are" />
            <token id="17" string="debating" />
            <token id="18" string="whether" />
            <token id="19" string="prediction" />
            <token id="20" string="is" />
            <token id="21" string="impossible" />
            <token id="22" string="or" />
            <token id="23" string="merely" />
            <token id="24" string="difficult" />
          </tokens>
        </chunking>
        <chunking id="3" string="impossible or merely difficult" type="ADJP">
          <tokens>
            <token id="21" string="impossible" />
            <token id="22" string="or" />
            <token id="23" string="merely" />
            <token id="24" string="difficult" />
          </tokens>
        </chunking>
        <chunking id="4" string="The public , and even public officials ," type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="public" />
            <token id="3" string="," />
            <token id="4" string="and" />
            <token id="5" string="even" />
            <token id="6" string="public" />
            <token id="7" string="officials" />
            <token id="8" string="," />
          </tokens>
        </chunking>
        <chunking id="5" string="public officials" type="NP">
          <tokens>
            <token id="6" string="public" />
            <token id="7" string="officials" />
          </tokens>
        </chunking>
        <chunking id="6" string="merely difficult" type="ADJP">
          <tokens>
            <token id="23" string="merely" />
            <token id="24" string="difficult" />
          </tokens>
        </chunking>
        <chunking id="7" string="impossible" type="ADJP">
          <tokens>
            <token id="21" string="impossible" />
          </tokens>
        </chunking>
        <chunking id="8" string="whether prediction is impossible or merely difficult" type="SBAR">
          <tokens>
            <token id="18" string="whether" />
            <token id="19" string="prediction" />
            <token id="20" string="is" />
            <token id="21" string="impossible" />
            <token id="22" string="or" />
            <token id="23" string="merely" />
            <token id="24" string="difficult" />
          </tokens>
        </chunking>
        <chunking id="9" string="Japan 's scientists" type="NP">
          <tokens>
            <token id="13" string="Japan" />
            <token id="14" string="'s" />
            <token id="15" string="scientists" />
          </tokens>
        </chunking>
        <chunking id="10" string="debating whether prediction is impossible or merely difficult" type="VP">
          <tokens>
            <token id="17" string="debating" />
            <token id="18" string="whether" />
            <token id="19" string="prediction" />
            <token id="20" string="is" />
            <token id="21" string="impossible" />
            <token id="22" string="or" />
            <token id="23" string="merely" />
            <token id="24" string="difficult" />
          </tokens>
        </chunking>
        <chunking id="11" string="The public" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="public" />
          </tokens>
        </chunking>
        <chunking id="12" string="are debating whether prediction is impossible or merely difficult" type="VP">
          <tokens>
            <token id="16" string="are" />
            <token id="17" string="debating" />
            <token id="18" string="whether" />
            <token id="19" string="prediction" />
            <token id="20" string="is" />
            <token id="21" string="impossible" />
            <token id="22" string="or" />
            <token id="23" string="merely" />
            <token id="24" string="difficult" />
          </tokens>
        </chunking>
        <chunking id="13" string="prediction" type="NP">
          <tokens>
            <token id="19" string="prediction" />
          </tokens>
        </chunking>
        <chunking id="14" string="is impossible or merely difficult" type="VP">
          <tokens>
            <token id="20" string="is" />
            <token id="21" string="impossible" />
            <token id="22" string="or" />
            <token id="23" string="merely" />
            <token id="24" string="difficult" />
          </tokens>
        </chunking>
        <chunking id="15" string="Japan 's" type="NP">
          <tokens>
            <token id="13" string="Japan" />
            <token id="14" string="'s" />
          </tokens>
        </chunking>
        <chunking id="16" string="largely unaware that Japan 's scientists are debating whether prediction is impossible or merely difficult" type="ADJP">
          <tokens>
            <token id="10" string="largely" />
            <token id="11" string="unaware" />
            <token id="12" string="that" />
            <token id="13" string="Japan" />
            <token id="14" string="'s" />
            <token id="15" string="scientists" />
            <token id="16" string="are" />
            <token id="17" string="debating" />
            <token id="18" string="whether" />
            <token id="19" string="prediction" />
            <token id="20" string="is" />
            <token id="21" string="impossible" />
            <token id="22" string="or" />
            <token id="23" string="merely" />
            <token id="24" string="difficult" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">public</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">remain</governor>
          <dependent id="2">public</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">public</governor>
          <dependent id="4">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="2">public</governor>
          <dependent id="5">even</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">officials</governor>
          <dependent id="6">public</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="2">public</governor>
          <dependent id="7">officials</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">remain</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">unaware</governor>
          <dependent id="10">largely</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="9">remain</governor>
          <dependent id="11">unaware</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">debating</governor>
          <dependent id="12">that</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="15">scientists</governor>
          <dependent id="13">Japan</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Japan</governor>
          <dependent id="14">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">debating</governor>
          <dependent id="15">scientists</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="17">debating</governor>
          <dependent id="16">are</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">unaware</governor>
          <dependent id="17">debating</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="21">impossible</governor>
          <dependent id="18">whether</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">impossible</governor>
          <dependent id="19">prediction</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="21">impossible</governor>
          <dependent id="20">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="17">debating</governor>
          <dependent id="21">impossible</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="21">impossible</governor>
          <dependent id="22">or</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="24">difficult</governor>
          <dependent id="23">merely</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="21">impossible</governor>
          <dependent id="24">difficult</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Japan" type="LOCATION" score="0.0">
          <tokens>
            <token id="13" string="Japan" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="47" has_coreference="true">
      <content>Most citizens do not realise that Tokai is the only region in which the government even intends to attempt a short-term warning.</content>
      <tokens>
        <token id="1" string="Most" lemma="most" stem="most" pos="JJS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="citizens" lemma="citizen" stem="citizen" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="realise" lemma="realise" stem="realis" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Tokai" lemma="Tokai" stem="tokai" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="8" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="only" lemma="only" stem="onli" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="region" lemma="region" stem="region" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="government" lemma="government" stem="govern" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="intends" lemma="intend" stem="intend" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="attempt" lemma="attempt" stem="attempt" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="short-term" lemma="short-term" stem="short-term" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="22" string="warning" lemma="warning" stem="warn" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (JJS Most) (NNS citizens)) (VP (VBP do) (RB not) (VP (VB realise) (SBAR (IN that) (S (NP (NNP Tokai)) (VP (VBZ is) (NP (NP (DT the) (JJ only) (NN region)) (SBAR (WHPP (IN in) (WHNP (WDT which))) (S (NP (DT the) (NN government)) (ADVP (RB even)) (VP (VBZ intends) (S (VP (TO to) (VP (VB attempt) (NP (DT a) (JJ short-term) (NN warning)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="is the only region in which the government even intends to attempt a short-term warning" type="VP">
          <tokens>
            <token id="8" string="is" />
            <token id="9" string="the" />
            <token id="10" string="only" />
            <token id="11" string="region" />
            <token id="12" string="in" />
            <token id="13" string="which" />
            <token id="14" string="the" />
            <token id="15" string="government" />
            <token id="16" string="even" />
            <token id="17" string="intends" />
            <token id="18" string="to" />
            <token id="19" string="attempt" />
            <token id="20" string="a" />
            <token id="21" string="short-term" />
            <token id="22" string="warning" />
          </tokens>
        </chunking>
        <chunking id="2" string="in which the government even intends to attempt a short-term warning" type="SBAR">
          <tokens>
            <token id="12" string="in" />
            <token id="13" string="which" />
            <token id="14" string="the" />
            <token id="15" string="government" />
            <token id="16" string="even" />
            <token id="17" string="intends" />
            <token id="18" string="to" />
            <token id="19" string="attempt" />
            <token id="20" string="a" />
            <token id="21" string="short-term" />
            <token id="22" string="warning" />
          </tokens>
        </chunking>
        <chunking id="3" string="Tokai" type="NP">
          <tokens>
            <token id="7" string="Tokai" />
          </tokens>
        </chunking>
        <chunking id="4" string="attempt a short-term warning" type="VP">
          <tokens>
            <token id="19" string="attempt" />
            <token id="20" string="a" />
            <token id="21" string="short-term" />
            <token id="22" string="warning" />
          </tokens>
        </chunking>
        <chunking id="5" string="realise that Tokai is the only region in which the government even intends to attempt a short-term warning" type="VP">
          <tokens>
            <token id="5" string="realise" />
            <token id="6" string="that" />
            <token id="7" string="Tokai" />
            <token id="8" string="is" />
            <token id="9" string="the" />
            <token id="10" string="only" />
            <token id="11" string="region" />
            <token id="12" string="in" />
            <token id="13" string="which" />
            <token id="14" string="the" />
            <token id="15" string="government" />
            <token id="16" string="even" />
            <token id="17" string="intends" />
            <token id="18" string="to" />
            <token id="19" string="attempt" />
            <token id="20" string="a" />
            <token id="21" string="short-term" />
            <token id="22" string="warning" />
          </tokens>
        </chunking>
        <chunking id="6" string="to attempt a short-term warning" type="VP">
          <tokens>
            <token id="18" string="to" />
            <token id="19" string="attempt" />
            <token id="20" string="a" />
            <token id="21" string="short-term" />
            <token id="22" string="warning" />
          </tokens>
        </chunking>
        <chunking id="7" string="that Tokai is the only region in which the government even intends to attempt a short-term warning" type="SBAR">
          <tokens>
            <token id="6" string="that" />
            <token id="7" string="Tokai" />
            <token id="8" string="is" />
            <token id="9" string="the" />
            <token id="10" string="only" />
            <token id="11" string="region" />
            <token id="12" string="in" />
            <token id="13" string="which" />
            <token id="14" string="the" />
            <token id="15" string="government" />
            <token id="16" string="even" />
            <token id="17" string="intends" />
            <token id="18" string="to" />
            <token id="19" string="attempt" />
            <token id="20" string="a" />
            <token id="21" string="short-term" />
            <token id="22" string="warning" />
          </tokens>
        </chunking>
        <chunking id="8" string="Most citizens" type="NP">
          <tokens>
            <token id="1" string="Most" />
            <token id="2" string="citizens" />
          </tokens>
        </chunking>
        <chunking id="9" string="the only region in which the government even intends to attempt a short-term warning" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="only" />
            <token id="11" string="region" />
            <token id="12" string="in" />
            <token id="13" string="which" />
            <token id="14" string="the" />
            <token id="15" string="government" />
            <token id="16" string="even" />
            <token id="17" string="intends" />
            <token id="18" string="to" />
            <token id="19" string="attempt" />
            <token id="20" string="a" />
            <token id="21" string="short-term" />
            <token id="22" string="warning" />
          </tokens>
        </chunking>
        <chunking id="10" string="a short-term warning" type="NP">
          <tokens>
            <token id="20" string="a" />
            <token id="21" string="short-term" />
            <token id="22" string="warning" />
          </tokens>
        </chunking>
        <chunking id="11" string="the government" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="government" />
          </tokens>
        </chunking>
        <chunking id="12" string="intends to attempt a short-term warning" type="VP">
          <tokens>
            <token id="17" string="intends" />
            <token id="18" string="to" />
            <token id="19" string="attempt" />
            <token id="20" string="a" />
            <token id="21" string="short-term" />
            <token id="22" string="warning" />
          </tokens>
        </chunking>
        <chunking id="13" string="the only region" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="only" />
            <token id="11" string="region" />
          </tokens>
        </chunking>
        <chunking id="14" string="do not realise that Tokai is the only region in which the government even intends to attempt a short-term warning" type="VP">
          <tokens>
            <token id="3" string="do" />
            <token id="4" string="not" />
            <token id="5" string="realise" />
            <token id="6" string="that" />
            <token id="7" string="Tokai" />
            <token id="8" string="is" />
            <token id="9" string="the" />
            <token id="10" string="only" />
            <token id="11" string="region" />
            <token id="12" string="in" />
            <token id="13" string="which" />
            <token id="14" string="the" />
            <token id="15" string="government" />
            <token id="16" string="even" />
            <token id="17" string="intends" />
            <token id="18" string="to" />
            <token id="19" string="attempt" />
            <token id="20" string="a" />
            <token id="21" string="short-term" />
            <token id="22" string="warning" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="2">citizens</governor>
          <dependent id="1">Most</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">realise</governor>
          <dependent id="2">citizens</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">realise</governor>
          <dependent id="3">do</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">realise</governor>
          <dependent id="4">not</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">realise</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">region</governor>
          <dependent id="6">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">region</governor>
          <dependent id="7">Tokai</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="11">region</governor>
          <dependent id="8">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">region</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">region</governor>
          <dependent id="10">only</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">realise</governor>
          <dependent id="11">region</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">which</governor>
          <dependent id="12">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">intends</governor>
          <dependent id="13">which</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">government</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">intends</governor>
          <dependent id="15">government</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="17">intends</governor>
          <dependent id="16">even</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="11">region</governor>
          <dependent id="17">intends</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">attempt</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="17">intends</governor>
          <dependent id="19">attempt</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">warning</governor>
          <dependent id="20">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">warning</governor>
          <dependent id="21">short-term</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">attempt</governor>
          <dependent id="22">warning</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Tokai" type="LOCATION" score="0.0">
          <tokens>
            <token id="7" string="Tokai" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="48" has_coreference="true">
      <content>High public expectations are coming back to haunt the six-member panel of experts, which must conclude that the gathered data indicate either &amp;apost;a cause for concern&amp;apost; or &amp;apost;no cause for concern&amp;apost;.</content>
      <tokens>
        <token id="1" string="High" lemma="high" stem="high" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="public" lemma="public" stem="public" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="expectations" lemma="expectation" stem="expect" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="coming" lemma="come" stem="come" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="back" lemma="back" stem="back" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="haunt" lemma="haunt" stem="haunt" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="six-member" lemma="six-member" stem="six-memb" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="panel" lemma="panel" stem="panel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="experts" lemma="expert" stem="expert" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="must" lemma="must" stem="must" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="conclude" lemma="conclude" stem="conclud" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="gathered" lemma="gather" stem="gather" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="data" lemma="datum" stem="data" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="indicate" lemma="indicate" stem="indic" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="either" lemma="either" stem="either" pos="CC" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="cause" lemma="cause" stem="caus" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="concern" lemma="concern" stem="concern" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="'" lemma="`" stem="'" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="cause" lemma="cause" stem="caus" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="concern" lemma="concern" stem="concern" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (JJ High) (JJ public) (NNS expectations)) (VP (VBP are) (VP (VBG coming) (ADVP (RB back)) (S (VP (TO to) (VP (VB haunt) (NP (NP (DT the) (JJ six-member) (NN panel)) (PP (IN of) (NP (NP (NNS experts)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (MD must) (VP (VB conclude) (SBAR (IN that) (S (NP (DT the) (VBN gathered) (NNS data)) (VP (VBP indicate)))) (ADVP (CC either)) ('' ') (NP (NP (DT a) (NN cause)) (PP (IN for) (NP (NP (NN concern)) ('' ') (CC or) (`` `) (NP (NP (DT no) (NN cause)) (PP (IN for) (NP (NN concern) ('' '))))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="coming back to haunt the six-member panel of experts , which must conclude that the gathered data indicate either ' a cause for concern ' or ` no cause for concern '" type="VP">
          <tokens>
            <token id="5" string="coming" />
            <token id="6" string="back" />
            <token id="7" string="to" />
            <token id="8" string="haunt" />
            <token id="9" string="the" />
            <token id="10" string="six-member" />
            <token id="11" string="panel" />
            <token id="12" string="of" />
            <token id="13" string="experts" />
            <token id="14" string="," />
            <token id="15" string="which" />
            <token id="16" string="must" />
            <token id="17" string="conclude" />
            <token id="18" string="that" />
            <token id="19" string="the" />
            <token id="20" string="gathered" />
            <token id="21" string="data" />
            <token id="22" string="indicate" />
            <token id="23" string="either" />
            <token id="24" string="'" />
            <token id="25" string="a" />
            <token id="26" string="cause" />
            <token id="27" string="for" />
            <token id="28" string="concern" />
            <token id="29" string="'" />
            <token id="30" string="or" />
            <token id="31" string="'" />
            <token id="32" string="no" />
            <token id="33" string="cause" />
            <token id="34" string="for" />
            <token id="35" string="concern" />
            <token id="36" string="'" />
          </tokens>
        </chunking>
        <chunking id="2" string="High public expectations" type="NP">
          <tokens>
            <token id="1" string="High" />
            <token id="2" string="public" />
            <token id="3" string="expectations" />
          </tokens>
        </chunking>
        <chunking id="3" string="the six-member panel of experts , which must conclude that the gathered data indicate either ' a cause for concern ' or ` no cause for concern '" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="six-member" />
            <token id="11" string="panel" />
            <token id="12" string="of" />
            <token id="13" string="experts" />
            <token id="14" string="," />
            <token id="15" string="which" />
            <token id="16" string="must" />
            <token id="17" string="conclude" />
            <token id="18" string="that" />
            <token id="19" string="the" />
            <token id="20" string="gathered" />
            <token id="21" string="data" />
            <token id="22" string="indicate" />
            <token id="23" string="either" />
            <token id="24" string="'" />
            <token id="25" string="a" />
            <token id="26" string="cause" />
            <token id="27" string="for" />
            <token id="28" string="concern" />
            <token id="29" string="'" />
            <token id="30" string="or" />
            <token id="31" string="'" />
            <token id="32" string="no" />
            <token id="33" string="cause" />
            <token id="34" string="for" />
            <token id="35" string="concern" />
            <token id="36" string="'" />
          </tokens>
        </chunking>
        <chunking id="4" string="experts , which must conclude that the gathered data indicate either ' a cause for concern ' or ` no cause for concern '" type="NP">
          <tokens>
            <token id="13" string="experts" />
            <token id="14" string="," />
            <token id="15" string="which" />
            <token id="16" string="must" />
            <token id="17" string="conclude" />
            <token id="18" string="that" />
            <token id="19" string="the" />
            <token id="20" string="gathered" />
            <token id="21" string="data" />
            <token id="22" string="indicate" />
            <token id="23" string="either" />
            <token id="24" string="'" />
            <token id="25" string="a" />
            <token id="26" string="cause" />
            <token id="27" string="for" />
            <token id="28" string="concern" />
            <token id="29" string="'" />
            <token id="30" string="or" />
            <token id="31" string="'" />
            <token id="32" string="no" />
            <token id="33" string="cause" />
            <token id="34" string="for" />
            <token id="35" string="concern" />
            <token id="36" string="'" />
          </tokens>
        </chunking>
        <chunking id="5" string="no cause for concern '" type="NP">
          <tokens>
            <token id="32" string="no" />
            <token id="33" string="cause" />
            <token id="34" string="for" />
            <token id="35" string="concern" />
            <token id="36" string="'" />
          </tokens>
        </chunking>
        <chunking id="6" string="are coming back to haunt the six-member panel of experts , which must conclude that the gathered data indicate either ' a cause for concern ' or ` no cause for concern '" type="VP">
          <tokens>
            <token id="4" string="are" />
            <token id="5" string="coming" />
            <token id="6" string="back" />
            <token id="7" string="to" />
            <token id="8" string="haunt" />
            <token id="9" string="the" />
            <token id="10" string="six-member" />
            <token id="11" string="panel" />
            <token id="12" string="of" />
            <token id="13" string="experts" />
            <token id="14" string="," />
            <token id="15" string="which" />
            <token id="16" string="must" />
            <token id="17" string="conclude" />
            <token id="18" string="that" />
            <token id="19" string="the" />
            <token id="20" string="gathered" />
            <token id="21" string="data" />
            <token id="22" string="indicate" />
            <token id="23" string="either" />
            <token id="24" string="'" />
            <token id="25" string="a" />
            <token id="26" string="cause" />
            <token id="27" string="for" />
            <token id="28" string="concern" />
            <token id="29" string="'" />
            <token id="30" string="or" />
            <token id="31" string="'" />
            <token id="32" string="no" />
            <token id="33" string="cause" />
            <token id="34" string="for" />
            <token id="35" string="concern" />
            <token id="36" string="'" />
          </tokens>
        </chunking>
        <chunking id="7" string="concern ' or ` no cause for concern '" type="NP">
          <tokens>
            <token id="28" string="concern" />
            <token id="29" string="'" />
            <token id="30" string="or" />
            <token id="31" string="'" />
            <token id="32" string="no" />
            <token id="33" string="cause" />
            <token id="34" string="for" />
            <token id="35" string="concern" />
            <token id="36" string="'" />
          </tokens>
        </chunking>
        <chunking id="8" string="haunt the six-member panel of experts , which must conclude that the gathered data indicate either ' a cause for concern ' or ` no cause for concern '" type="VP">
          <tokens>
            <token id="8" string="haunt" />
            <token id="9" string="the" />
            <token id="10" string="six-member" />
            <token id="11" string="panel" />
            <token id="12" string="of" />
            <token id="13" string="experts" />
            <token id="14" string="," />
            <token id="15" string="which" />
            <token id="16" string="must" />
            <token id="17" string="conclude" />
            <token id="18" string="that" />
            <token id="19" string="the" />
            <token id="20" string="gathered" />
            <token id="21" string="data" />
            <token id="22" string="indicate" />
            <token id="23" string="either" />
            <token id="24" string="'" />
            <token id="25" string="a" />
            <token id="26" string="cause" />
            <token id="27" string="for" />
            <token id="28" string="concern" />
            <token id="29" string="'" />
            <token id="30" string="or" />
            <token id="31" string="'" />
            <token id="32" string="no" />
            <token id="33" string="cause" />
            <token id="34" string="for" />
            <token id="35" string="concern" />
            <token id="36" string="'" />
          </tokens>
        </chunking>
        <chunking id="9" string="conclude that the gathered data indicate either ' a cause for concern ' or ` no cause for concern '" type="VP">
          <tokens>
            <token id="17" string="conclude" />
            <token id="18" string="that" />
            <token id="19" string="the" />
            <token id="20" string="gathered" />
            <token id="21" string="data" />
            <token id="22" string="indicate" />
            <token id="23" string="either" />
            <token id="24" string="'" />
            <token id="25" string="a" />
            <token id="26" string="cause" />
            <token id="27" string="for" />
            <token id="28" string="concern" />
            <token id="29" string="'" />
            <token id="30" string="or" />
            <token id="31" string="'" />
            <token id="32" string="no" />
            <token id="33" string="cause" />
            <token id="34" string="for" />
            <token id="35" string="concern" />
            <token id="36" string="'" />
          </tokens>
        </chunking>
        <chunking id="10" string="concern" type="NP">
          <tokens>
            <token id="28" string="concern" />
          </tokens>
        </chunking>
        <chunking id="11" string="a cause" type="NP">
          <tokens>
            <token id="25" string="a" />
            <token id="26" string="cause" />
          </tokens>
        </chunking>
        <chunking id="12" string="the gathered data" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="gathered" />
            <token id="21" string="data" />
          </tokens>
        </chunking>
        <chunking id="13" string="the six-member panel" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="six-member" />
            <token id="11" string="panel" />
          </tokens>
        </chunking>
        <chunking id="14" string="which must conclude that the gathered data indicate either ' a cause for concern ' or ` no cause for concern '" type="SBAR">
          <tokens>
            <token id="15" string="which" />
            <token id="16" string="must" />
            <token id="17" string="conclude" />
            <token id="18" string="that" />
            <token id="19" string="the" />
            <token id="20" string="gathered" />
            <token id="21" string="data" />
            <token id="22" string="indicate" />
            <token id="23" string="either" />
            <token id="24" string="'" />
            <token id="25" string="a" />
            <token id="26" string="cause" />
            <token id="27" string="for" />
            <token id="28" string="concern" />
            <token id="29" string="'" />
            <token id="30" string="or" />
            <token id="31" string="'" />
            <token id="32" string="no" />
            <token id="33" string="cause" />
            <token id="34" string="for" />
            <token id="35" string="concern" />
            <token id="36" string="'" />
          </tokens>
        </chunking>
        <chunking id="15" string="no cause" type="NP">
          <tokens>
            <token id="32" string="no" />
            <token id="33" string="cause" />
          </tokens>
        </chunking>
        <chunking id="16" string="to haunt the six-member panel of experts , which must conclude that the gathered data indicate either ' a cause for concern ' or ` no cause for concern '" type="VP">
          <tokens>
            <token id="7" string="to" />
            <token id="8" string="haunt" />
            <token id="9" string="the" />
            <token id="10" string="six-member" />
            <token id="11" string="panel" />
            <token id="12" string="of" />
            <token id="13" string="experts" />
            <token id="14" string="," />
            <token id="15" string="which" />
            <token id="16" string="must" />
            <token id="17" string="conclude" />
            <token id="18" string="that" />
            <token id="19" string="the" />
            <token id="20" string="gathered" />
            <token id="21" string="data" />
            <token id="22" string="indicate" />
            <token id="23" string="either" />
            <token id="24" string="'" />
            <token id="25" string="a" />
            <token id="26" string="cause" />
            <token id="27" string="for" />
            <token id="28" string="concern" />
            <token id="29" string="'" />
            <token id="30" string="or" />
            <token id="31" string="'" />
            <token id="32" string="no" />
            <token id="33" string="cause" />
            <token id="34" string="for" />
            <token id="35" string="concern" />
            <token id="36" string="'" />
          </tokens>
        </chunking>
        <chunking id="17" string="must conclude that the gathered data indicate either ' a cause for concern ' or ` no cause for concern '" type="VP">
          <tokens>
            <token id="16" string="must" />
            <token id="17" string="conclude" />
            <token id="18" string="that" />
            <token id="19" string="the" />
            <token id="20" string="gathered" />
            <token id="21" string="data" />
            <token id="22" string="indicate" />
            <token id="23" string="either" />
            <token id="24" string="'" />
            <token id="25" string="a" />
            <token id="26" string="cause" />
            <token id="27" string="for" />
            <token id="28" string="concern" />
            <token id="29" string="'" />
            <token id="30" string="or" />
            <token id="31" string="'" />
            <token id="32" string="no" />
            <token id="33" string="cause" />
            <token id="34" string="for" />
            <token id="35" string="concern" />
            <token id="36" string="'" />
          </tokens>
        </chunking>
        <chunking id="18" string="that the gathered data indicate" type="SBAR">
          <tokens>
            <token id="18" string="that" />
            <token id="19" string="the" />
            <token id="20" string="gathered" />
            <token id="21" string="data" />
            <token id="22" string="indicate" />
          </tokens>
        </chunking>
        <chunking id="19" string="indicate" type="VP">
          <tokens>
            <token id="22" string="indicate" />
          </tokens>
        </chunking>
        <chunking id="20" string="experts" type="NP">
          <tokens>
            <token id="13" string="experts" />
          </tokens>
        </chunking>
        <chunking id="21" string="a cause for concern ' or ` no cause for concern '" type="NP">
          <tokens>
            <token id="25" string="a" />
            <token id="26" string="cause" />
            <token id="27" string="for" />
            <token id="28" string="concern" />
            <token id="29" string="'" />
            <token id="30" string="or" />
            <token id="31" string="'" />
            <token id="32" string="no" />
            <token id="33" string="cause" />
            <token id="34" string="for" />
            <token id="35" string="concern" />
            <token id="36" string="'" />
          </tokens>
        </chunking>
        <chunking id="22" string="concern '" type="NP">
          <tokens>
            <token id="35" string="concern" />
            <token id="36" string="'" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="3">expectations</governor>
          <dependent id="1">High</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">expectations</governor>
          <dependent id="2">public</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">coming</governor>
          <dependent id="3">expectations</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">coming</governor>
          <dependent id="4">are</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">coming</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">coming</governor>
          <dependent id="6">back</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">haunt</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">coming</governor>
          <dependent id="8">haunt</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">panel</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">panel</governor>
          <dependent id="10">six-member</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">haunt</governor>
          <dependent id="11">panel</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">experts</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">panel</governor>
          <dependent id="13">experts</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">conclude</governor>
          <dependent id="15">which</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="17">conclude</governor>
          <dependent id="16">must</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="13">experts</governor>
          <dependent id="17">conclude</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">indicate</governor>
          <dependent id="18">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">data</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">data</governor>
          <dependent id="20">gathered</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">indicate</governor>
          <dependent id="21">data</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="17">conclude</governor>
          <dependent id="22">indicate</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="17">conclude</governor>
          <dependent id="23">either</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">cause</governor>
          <dependent id="25">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">conclude</governor>
          <dependent id="26">cause</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">concern</governor>
          <dependent id="27">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">cause</governor>
          <dependent id="28">concern</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="28">concern</governor>
          <dependent id="30">or</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="33">cause</governor>
          <dependent id="32">no</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="28">concern</governor>
          <dependent id="33">cause</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">concern</governor>
          <dependent id="34">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="33">cause</governor>
          <dependent id="35">concern</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="49" has_coreference="true">
      <content>Mogi would like to add a third category between the two that would indicate &amp;apost;some level of concern&amp;apost;.</content>
      <tokens>
        <token id="1" string="Mogi" lemma="Mogi" stem="mogi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="like" lemma="like" stem="like" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="add" lemma="add" stem="add" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="third" lemma="third" stem="third" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="8" string="category" lemma="category" stem="categori" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="between" lemma="between" stem="between" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="12" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="indicate" lemma="indicate" stem="indic" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="'" lemma="`" stem="'" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="level" lemma="level" stem="level" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="concern" lemma="concern" stem="concern" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Mogi)) (VP (MD would) (VP (VB like) (S (VP (TO to) (VP (VB add) (NP (NP (DT a) (JJ third) (NN category)) (PP (IN between) (NP (DT the) (CD two))) (SBAR (WHNP (WDT that)) (S (VP (MD would) (VP (VB indicate) (`` `) (NP (NP (DT some) (NN level)) (PP (IN of) (NP (NN concern)))) ('' '))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a third category between the two that would indicate ` some level of concern '" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="third" />
            <token id="8" string="category" />
            <token id="9" string="between" />
            <token id="10" string="the" />
            <token id="11" string="two" />
            <token id="12" string="that" />
            <token id="13" string="would" />
            <token id="14" string="indicate" />
            <token id="15" string="'" />
            <token id="16" string="some" />
            <token id="17" string="level" />
            <token id="18" string="of" />
            <token id="19" string="concern" />
            <token id="20" string="'" />
          </tokens>
        </chunking>
        <chunking id="2" string="would like to add a third category between the two that would indicate ` some level of concern '" type="VP">
          <tokens>
            <token id="2" string="would" />
            <token id="3" string="like" />
            <token id="4" string="to" />
            <token id="5" string="add" />
            <token id="6" string="a" />
            <token id="7" string="third" />
            <token id="8" string="category" />
            <token id="9" string="between" />
            <token id="10" string="the" />
            <token id="11" string="two" />
            <token id="12" string="that" />
            <token id="13" string="would" />
            <token id="14" string="indicate" />
            <token id="15" string="'" />
            <token id="16" string="some" />
            <token id="17" string="level" />
            <token id="18" string="of" />
            <token id="19" string="concern" />
            <token id="20" string="'" />
          </tokens>
        </chunking>
        <chunking id="3" string="to add a third category between the two that would indicate ` some level of concern '" type="VP">
          <tokens>
            <token id="4" string="to" />
            <token id="5" string="add" />
            <token id="6" string="a" />
            <token id="7" string="third" />
            <token id="8" string="category" />
            <token id="9" string="between" />
            <token id="10" string="the" />
            <token id="11" string="two" />
            <token id="12" string="that" />
            <token id="13" string="would" />
            <token id="14" string="indicate" />
            <token id="15" string="'" />
            <token id="16" string="some" />
            <token id="17" string="level" />
            <token id="18" string="of" />
            <token id="19" string="concern" />
            <token id="20" string="'" />
          </tokens>
        </chunking>
        <chunking id="4" string="some level of concern" type="NP">
          <tokens>
            <token id="16" string="some" />
            <token id="17" string="level" />
            <token id="18" string="of" />
            <token id="19" string="concern" />
          </tokens>
        </chunking>
        <chunking id="5" string="Mogi" type="NP">
          <tokens>
            <token id="1" string="Mogi" />
          </tokens>
        </chunking>
        <chunking id="6" string="like to add a third category between the two that would indicate ` some level of concern '" type="VP">
          <tokens>
            <token id="3" string="like" />
            <token id="4" string="to" />
            <token id="5" string="add" />
            <token id="6" string="a" />
            <token id="7" string="third" />
            <token id="8" string="category" />
            <token id="9" string="between" />
            <token id="10" string="the" />
            <token id="11" string="two" />
            <token id="12" string="that" />
            <token id="13" string="would" />
            <token id="14" string="indicate" />
            <token id="15" string="'" />
            <token id="16" string="some" />
            <token id="17" string="level" />
            <token id="18" string="of" />
            <token id="19" string="concern" />
            <token id="20" string="'" />
          </tokens>
        </chunking>
        <chunking id="7" string="some level" type="NP">
          <tokens>
            <token id="16" string="some" />
            <token id="17" string="level" />
          </tokens>
        </chunking>
        <chunking id="8" string="that would indicate ` some level of concern '" type="SBAR">
          <tokens>
            <token id="12" string="that" />
            <token id="13" string="would" />
            <token id="14" string="indicate" />
            <token id="15" string="'" />
            <token id="16" string="some" />
            <token id="17" string="level" />
            <token id="18" string="of" />
            <token id="19" string="concern" />
            <token id="20" string="'" />
          </tokens>
        </chunking>
        <chunking id="9" string="concern" type="NP">
          <tokens>
            <token id="19" string="concern" />
          </tokens>
        </chunking>
        <chunking id="10" string="indicate ` some level of concern '" type="VP">
          <tokens>
            <token id="14" string="indicate" />
            <token id="15" string="'" />
            <token id="16" string="some" />
            <token id="17" string="level" />
            <token id="18" string="of" />
            <token id="19" string="concern" />
            <token id="20" string="'" />
          </tokens>
        </chunking>
        <chunking id="11" string="a third category" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="third" />
            <token id="8" string="category" />
          </tokens>
        </chunking>
        <chunking id="12" string="would indicate ` some level of concern '" type="VP">
          <tokens>
            <token id="13" string="would" />
            <token id="14" string="indicate" />
            <token id="15" string="'" />
            <token id="16" string="some" />
            <token id="17" string="level" />
            <token id="18" string="of" />
            <token id="19" string="concern" />
            <token id="20" string="'" />
          </tokens>
        </chunking>
        <chunking id="13" string="the two" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="two" />
          </tokens>
        </chunking>
        <chunking id="14" string="add a third category between the two that would indicate ` some level of concern '" type="VP">
          <tokens>
            <token id="5" string="add" />
            <token id="6" string="a" />
            <token id="7" string="third" />
            <token id="8" string="category" />
            <token id="9" string="between" />
            <token id="10" string="the" />
            <token id="11" string="two" />
            <token id="12" string="that" />
            <token id="13" string="would" />
            <token id="14" string="indicate" />
            <token id="15" string="'" />
            <token id="16" string="some" />
            <token id="17" string="level" />
            <token id="18" string="of" />
            <token id="19" string="concern" />
            <token id="20" string="'" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">like</governor>
          <dependent id="1">Mogi</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="3">like</governor>
          <dependent id="2">would</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">like</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">add</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">like</governor>
          <dependent id="5">add</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">category</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">category</governor>
          <dependent id="7">third</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">add</governor>
          <dependent id="8">category</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">two</governor>
          <dependent id="9">between</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">two</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">category</governor>
          <dependent id="11">two</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">indicate</governor>
          <dependent id="12">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="14">indicate</governor>
          <dependent id="13">would</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="8">category</governor>
          <dependent id="14">indicate</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">level</governor>
          <dependent id="16">some</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">indicate</governor>
          <dependent id="17">level</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">concern</governor>
          <dependent id="18">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">level</governor>
          <dependent id="19">concern</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="third" type="ORDINAL" score="0.0">
          <tokens>
            <token id="7" string="third" />
          </tokens>
        </entity>
        <entity id="2" string="Mogi" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Mogi" />
          </tokens>
        </entity>
        <entity id="3" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="11" string="two" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="50" has_coreference="true">
      <content>Many scientists agree a &amp;apost;maybe&amp;apost; is not unreasonable, given the state of the art.</content>
      <tokens>
        <token id="1" string="Many" lemma="many" stem="mani" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="scientists" lemma="scientist" stem="scientist" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="agree" lemma="agree" stem="agre" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="'" lemma="`" stem="'" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="maybe" lemma="maybe" stem="mayb" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="unreasonable" lemma="unreasonable" stem="unreason" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="given" lemma="give" stem="given" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="state" lemma="state" stem="state" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="art" lemma="art" stem="art" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (JJ Many) (NNS scientists)) (SBAR (S (VP (VBP agree) (S (NP (DT a)) (`` `) (ADJP (RB maybe)) ('' ')))))) (VP (VBZ is) (RB not) (ADJP (JJ unreasonable)) (, ,) (PP (VBN given) (NP (NP (DT the) (NN state)) (PP (IN of) (NP (DT the) (NN art)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a" type="NP">
          <tokens>
            <token id="4" string="a" />
          </tokens>
        </chunking>
        <chunking id="2" string="is not unreasonable , given the state of the art" type="VP">
          <tokens>
            <token id="8" string="is" />
            <token id="9" string="not" />
            <token id="10" string="unreasonable" />
            <token id="11" string="," />
            <token id="12" string="given" />
            <token id="13" string="the" />
            <token id="14" string="state" />
            <token id="15" string="of" />
            <token id="16" string="the" />
            <token id="17" string="art" />
          </tokens>
        </chunking>
        <chunking id="3" string="the state of the art" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="state" />
            <token id="15" string="of" />
            <token id="16" string="the" />
            <token id="17" string="art" />
          </tokens>
        </chunking>
        <chunking id="4" string="the state" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="state" />
          </tokens>
        </chunking>
        <chunking id="5" string="Many scientists agree a ` maybe '" type="NP">
          <tokens>
            <token id="1" string="Many" />
            <token id="2" string="scientists" />
            <token id="3" string="agree" />
            <token id="4" string="a" />
            <token id="5" string="'" />
            <token id="6" string="maybe" />
            <token id="7" string="'" />
          </tokens>
        </chunking>
        <chunking id="6" string="agree a ` maybe '" type="SBAR">
          <tokens>
            <token id="3" string="agree" />
            <token id="4" string="a" />
            <token id="5" string="'" />
            <token id="6" string="maybe" />
            <token id="7" string="'" />
          </tokens>
        </chunking>
        <chunking id="7" string="the art" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="art" />
          </tokens>
        </chunking>
        <chunking id="8" string="Many scientists" type="NP">
          <tokens>
            <token id="1" string="Many" />
            <token id="2" string="scientists" />
          </tokens>
        </chunking>
        <chunking id="9" string="maybe" type="ADJP">
          <tokens>
            <token id="6" string="maybe" />
          </tokens>
        </chunking>
        <chunking id="10" string="unreasonable" type="ADJP">
          <tokens>
            <token id="10" string="unreasonable" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="2">scientists</governor>
          <dependent id="1">Many</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">unreasonable</governor>
          <dependent id="2">scientists</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="2">scientists</governor>
          <dependent id="3">agree</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="6">maybe</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">agree</governor>
          <dependent id="6">maybe</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="10">unreasonable</governor>
          <dependent id="8">is</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="10">unreasonable</governor>
          <dependent id="9">not</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">unreasonable</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">state</governor>
          <dependent id="12">given</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">state</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">unreasonable</governor>
          <dependent id="14">state</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">art</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">art</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">state</governor>
          <dependent id="17">art</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="51" has_coreference="true">
      <content>Public officials, however, are insisting the experts make an &amp;apost;it&amp;apost;s coming&amp;apost; or &amp;apost;it&amp;apost;s not&amp;apost; decision.</content>
      <tokens>
        <token id="1" string="Public" lemma="Public" stem="public" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="officials" lemma="official" stem="offici" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="however" lemma="however" stem="howev" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="insisting" lemma="insist" stem="insist" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="experts" lemma="expert" stem="expert" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="make" lemma="make" stem="make" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="'" lemma="`" stem="'" pos="``" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="14" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="coming" lemma="come" stem="come" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="'" lemma="`" stem="'" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="decision" lemma="decision" stem="decis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Public) (NNS officials)) (, ,) (ADVP (RB however)) (, ,) (VP (VBP are) (VP (VBG insisting) (SBAR (SBAR (S (NP (DT the) (NNS experts)) (VP (VBP make) (NP (DT an) (S (`` `) (NP (PRP it)) (VP (VBZ 's) (VP (VBG coming))) ('' ')))))) (CC or) (SBAR (S (NP (`` `) (PRP it)) (VP (VBZ 's) (RB not))))) ('' ') (NP (NN decision)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="decision" type="NP">
          <tokens>
            <token id="23" string="decision" />
          </tokens>
        </chunking>
        <chunking id="2" string="` it" type="NP">
          <tokens>
            <token id="18" string="'" />
            <token id="19" string="it" />
          </tokens>
        </chunking>
        <chunking id="3" string="Public officials" type="NP">
          <tokens>
            <token id="1" string="Public" />
            <token id="2" string="officials" />
          </tokens>
        </chunking>
        <chunking id="4" string="the experts" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="experts" />
          </tokens>
        </chunking>
        <chunking id="5" string="it" type="NP">
          <tokens>
            <token id="13" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="'s coming" type="VP">
          <tokens>
            <token id="14" string="'s" />
            <token id="15" string="coming" />
          </tokens>
        </chunking>
        <chunking id="7" string="'s not" type="VP">
          <tokens>
            <token id="20" string="'s" />
            <token id="21" string="not" />
          </tokens>
        </chunking>
        <chunking id="8" string="are insisting the experts make an ` it 's coming ' or ` it 's not ' decision" type="VP">
          <tokens>
            <token id="6" string="are" />
            <token id="7" string="insisting" />
            <token id="8" string="the" />
            <token id="9" string="experts" />
            <token id="10" string="make" />
            <token id="11" string="an" />
            <token id="12" string="'" />
            <token id="13" string="it" />
            <token id="14" string="'s" />
            <token id="15" string="coming" />
            <token id="16" string="'" />
            <token id="17" string="or" />
            <token id="18" string="'" />
            <token id="19" string="it" />
            <token id="20" string="'s" />
            <token id="21" string="not" />
            <token id="22" string="'" />
            <token id="23" string="decision" />
          </tokens>
        </chunking>
        <chunking id="9" string="the experts make an ` it 's coming '" type="SBAR">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="experts" />
            <token id="10" string="make" />
            <token id="11" string="an" />
            <token id="12" string="'" />
            <token id="13" string="it" />
            <token id="14" string="'s" />
            <token id="15" string="coming" />
            <token id="16" string="'" />
          </tokens>
        </chunking>
        <chunking id="10" string="an ` it 's coming '" type="NP">
          <tokens>
            <token id="11" string="an" />
            <token id="12" string="'" />
            <token id="13" string="it" />
            <token id="14" string="'s" />
            <token id="15" string="coming" />
            <token id="16" string="'" />
          </tokens>
        </chunking>
        <chunking id="11" string="` it 's not" type="SBAR">
          <tokens>
            <token id="18" string="'" />
            <token id="19" string="it" />
            <token id="20" string="'s" />
            <token id="21" string="not" />
          </tokens>
        </chunking>
        <chunking id="12" string="the experts make an ` it 's coming ' or ` it 's not" type="SBAR">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="experts" />
            <token id="10" string="make" />
            <token id="11" string="an" />
            <token id="12" string="'" />
            <token id="13" string="it" />
            <token id="14" string="'s" />
            <token id="15" string="coming" />
            <token id="16" string="'" />
            <token id="17" string="or" />
            <token id="18" string="'" />
            <token id="19" string="it" />
            <token id="20" string="'s" />
            <token id="21" string="not" />
          </tokens>
        </chunking>
        <chunking id="13" string="insisting the experts make an ` it 's coming ' or ` it 's not ' decision" type="VP">
          <tokens>
            <token id="7" string="insisting" />
            <token id="8" string="the" />
            <token id="9" string="experts" />
            <token id="10" string="make" />
            <token id="11" string="an" />
            <token id="12" string="'" />
            <token id="13" string="it" />
            <token id="14" string="'s" />
            <token id="15" string="coming" />
            <token id="16" string="'" />
            <token id="17" string="or" />
            <token id="18" string="'" />
            <token id="19" string="it" />
            <token id="20" string="'s" />
            <token id="21" string="not" />
            <token id="22" string="'" />
            <token id="23" string="decision" />
          </tokens>
        </chunking>
        <chunking id="14" string="make an ` it 's coming '" type="VP">
          <tokens>
            <token id="10" string="make" />
            <token id="11" string="an" />
            <token id="12" string="'" />
            <token id="13" string="it" />
            <token id="14" string="'s" />
            <token id="15" string="coming" />
            <token id="16" string="'" />
          </tokens>
        </chunking>
        <chunking id="15" string="coming" type="VP">
          <tokens>
            <token id="15" string="coming" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">officials</governor>
          <dependent id="1">Public</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">insisting</governor>
          <dependent id="2">officials</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">insisting</governor>
          <dependent id="4">however</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">insisting</governor>
          <dependent id="6">are</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">insisting</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">experts</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">make</governor>
          <dependent id="9">experts</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="7">insisting</governor>
          <dependent id="10">make</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">make</governor>
          <dependent id="11">an</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">coming</governor>
          <dependent id="13">it</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="15">coming</governor>
          <dependent id="14">'s</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="11">an</governor>
          <dependent id="15">coming</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">make</governor>
          <dependent id="17">or</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">'s</governor>
          <dependent id="19">it</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">make</governor>
          <dependent id="20">'s</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="20">'s</governor>
          <dependent id="21">not</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">insisting</governor>
          <dependent id="23">decision</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="52" has_coreference="true">
      <content>Meanwhile, the controversy might be settled if the experts get their call from the technicians monitoring the Tokai data.</content>
      <tokens>
        <token id="1" string="Meanwhile" lemma="meanwhile" stem="meanwhil" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="controversy" lemma="controversy" stem="controversi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="might" lemma="might" stem="might" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="settled" lemma="settle" stem="settl" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="experts" lemma="expert" stem="expert" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="get" lemma="get" stem="get" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="call" lemma="call" stem="call" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="technicians" lemma="technician" stem="technician" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="monitoring" lemma="monitor" stem="monitor" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="Tokai" lemma="Tokai" stem="tokai" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="20" string="data" lemma="datum" stem="data" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Meanwhile)) (, ,) (NP (DT the) (NN controversy)) (VP (MD might) (VP (VB be) (VP (VBN settled) (SBAR (IN if) (S (NP (DT the) (NNS experts)) (VP (VBP get) (NP (PRP$ their) (NN call)) (PP (IN from) (S (NP (DT the) (NNS technicians)) (VP (VBG monitoring) (NP (DT the) (NNP Tokai) (NNS data))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="their call" type="NP">
          <tokens>
            <token id="12" string="their" />
            <token id="13" string="call" />
          </tokens>
        </chunking>
        <chunking id="2" string="get their call from the technicians monitoring the Tokai data" type="VP">
          <tokens>
            <token id="11" string="get" />
            <token id="12" string="their" />
            <token id="13" string="call" />
            <token id="14" string="from" />
            <token id="15" string="the" />
            <token id="16" string="technicians" />
            <token id="17" string="monitoring" />
            <token id="18" string="the" />
            <token id="19" string="Tokai" />
            <token id="20" string="data" />
          </tokens>
        </chunking>
        <chunking id="3" string="the Tokai data" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="Tokai" />
            <token id="20" string="data" />
          </tokens>
        </chunking>
        <chunking id="4" string="settled if the experts get their call from the technicians monitoring the Tokai data" type="VP">
          <tokens>
            <token id="7" string="settled" />
            <token id="8" string="if" />
            <token id="9" string="the" />
            <token id="10" string="experts" />
            <token id="11" string="get" />
            <token id="12" string="their" />
            <token id="13" string="call" />
            <token id="14" string="from" />
            <token id="15" string="the" />
            <token id="16" string="technicians" />
            <token id="17" string="monitoring" />
            <token id="18" string="the" />
            <token id="19" string="Tokai" />
            <token id="20" string="data" />
          </tokens>
        </chunking>
        <chunking id="5" string="be settled if the experts get their call from the technicians monitoring the Tokai data" type="VP">
          <tokens>
            <token id="6" string="be" />
            <token id="7" string="settled" />
            <token id="8" string="if" />
            <token id="9" string="the" />
            <token id="10" string="experts" />
            <token id="11" string="get" />
            <token id="12" string="their" />
            <token id="13" string="call" />
            <token id="14" string="from" />
            <token id="15" string="the" />
            <token id="16" string="technicians" />
            <token id="17" string="monitoring" />
            <token id="18" string="the" />
            <token id="19" string="Tokai" />
            <token id="20" string="data" />
          </tokens>
        </chunking>
        <chunking id="6" string="might be settled if the experts get their call from the technicians monitoring the Tokai data" type="VP">
          <tokens>
            <token id="5" string="might" />
            <token id="6" string="be" />
            <token id="7" string="settled" />
            <token id="8" string="if" />
            <token id="9" string="the" />
            <token id="10" string="experts" />
            <token id="11" string="get" />
            <token id="12" string="their" />
            <token id="13" string="call" />
            <token id="14" string="from" />
            <token id="15" string="the" />
            <token id="16" string="technicians" />
            <token id="17" string="monitoring" />
            <token id="18" string="the" />
            <token id="19" string="Tokai" />
            <token id="20" string="data" />
          </tokens>
        </chunking>
        <chunking id="7" string="the experts" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="experts" />
          </tokens>
        </chunking>
        <chunking id="8" string="the technicians" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="technicians" />
          </tokens>
        </chunking>
        <chunking id="9" string="if the experts get their call from the technicians monitoring the Tokai data" type="SBAR">
          <tokens>
            <token id="8" string="if" />
            <token id="9" string="the" />
            <token id="10" string="experts" />
            <token id="11" string="get" />
            <token id="12" string="their" />
            <token id="13" string="call" />
            <token id="14" string="from" />
            <token id="15" string="the" />
            <token id="16" string="technicians" />
            <token id="17" string="monitoring" />
            <token id="18" string="the" />
            <token id="19" string="Tokai" />
            <token id="20" string="data" />
          </tokens>
        </chunking>
        <chunking id="10" string="the controversy" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="controversy" />
          </tokens>
        </chunking>
        <chunking id="11" string="monitoring the Tokai data" type="VP">
          <tokens>
            <token id="17" string="monitoring" />
            <token id="18" string="the" />
            <token id="19" string="Tokai" />
            <token id="20" string="data" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="7">settled</governor>
          <dependent id="1">Meanwhile</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">controversy</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="7">settled</governor>
          <dependent id="4">controversy</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">settled</governor>
          <dependent id="5">might</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="7">settled</governor>
          <dependent id="6">be</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">settled</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">get</governor>
          <dependent id="8">if</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">experts</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">get</governor>
          <dependent id="10">experts</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="7">settled</governor>
          <dependent id="11">get</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="13">call</governor>
          <dependent id="12">their</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">get</governor>
          <dependent id="13">call</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">monitoring</governor>
          <dependent id="14">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">technicians</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">monitoring</governor>
          <dependent id="16">technicians</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="11">get</governor>
          <dependent id="17">monitoring</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">data</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">data</governor>
          <dependent id="19">Tokai</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">monitoring</governor>
          <dependent id="20">data</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Tokai" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="19" string="Tokai" />
          </tokens>
        </entity>
      </entities>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="1" type="PROPER">
      <referenced ids_tokens="7-8" string="Japan 's" id_sentence="1" />
      <mentions>
        <mention ids_tokens="15" string="Japan" id_sentence="9" />
        <mention ids_tokens="14" string="Japan" id_sentence="10" />
        <mention ids_tokens="7" string="Japan" id_sentence="11" />
        <mention ids_tokens="1" string="Japan" id_sentence="13" />
        <mention ids_tokens="2" string="Japan" id_sentence="15" />
        <mention ids_tokens="1" string="Japan" id_sentence="31" />
      </mentions>
    </coreference>
    <coreference id="2" type="PROPER">
      <referenced ids_tokens="10" string="Tokai" id_sentence="1" />
      <mentions>
        <mention ids_tokens="1-3" string="The region's" id_sentence="33" />
        <mention ids_tokens="13-15" string="the region's" id_sentence="35" />
        <mention ids_tokens="9-22" string="the only region in which the government even intends to attempt a short-term warning" id_sentence="47" />
      </mentions>
    </coreference>
    <coreference id="3" type="PROPER">
      <referenced ids_tokens="5-6-7-8-9-10-11" string="Tokyo in Japan 's coastal Tokai region" id_sentence="1" />
      <mentions>
        <mention ids_tokens="6" string="Tokyo" id_sentence="3" />
        <mention ids_tokens="26" string="Tokyo" id_sentence="29" />
      </mentions>
    </coreference>
    <coreference id="4" type="NOMINAL">
      <referenced ids_tokens="16-17-18" string="the world 's" id_sentence="1" />
      <mentions>
        <mention ids_tokens="6-7" string="the world" id_sentence="9" />
        <mention ids_tokens="13-14" string="the world" id_sentence="13" />
      </mentions>
    </coreference>
    <coreference id="6" type="NOMINAL">
      <referenced ids_tokens="3-4-5" string="the six experts" id_sentence="39" />
      <mentions>
        <mention ids_tokens="18-19" string="six experts" id_sentence="3" />
        <mention ids_tokens="13" string="experts" id_sentence="48" />
        <mention ids_tokens="8-9" string="the experts" id_sentence="51" />
        <mention ids_tokens="9-10" string="the experts" id_sentence="52" />
        <mention ids_tokens="12" string="their" id_sentence="52" />
      </mentions>
    </coreference>
    <coreference id="7" type="NOMINAL">
      <referenced ids_tokens="17-18-19" string="the Tokai area" id_sentence="4" />
      <mentions>
        <mention ids_tokens="10-11" string="the area" id_sentence="5" />
        <mention ids_tokens="6-8" string="the area's" id_sentence="18" />
        <mention ids_tokens="26-27" string="the area" id_sentence="20" />
      </mentions>
    </coreference>
    <coreference id="11" type="NOMINAL">
      <referenced ids_tokens="1-2" string="Prediction research" id_sentence="42" />
      <mentions>
        <mention ids_tokens="30-43" string="the Tokai region and close to Dollars 100m more on general earthquake prediction research" id_sentence="9" />
      </mentions>
    </coreference>
    <coreference id="14" type="PROPER">
      <referenced ids_tokens="10-11" string="the two" id_sentence="49" />
      <mentions>
        <mention ids_tokens="17" string="two" id_sentence="16" />
      </mentions>
    </coreference>
    <coreference id="15" type="PROPER">
      <referenced ids_tokens="5-6-7" string="the Suruga Trough" id_sentence="34" />
      <mentions>
        <mention ids_tokens="5-11" string="a deep submarine trench running just offshore" id_sentence="16" />
      </mentions>
    </coreference>
    <coreference id="17" type="NOMINAL">
      <referenced ids_tokens="7-8-9-10-11-12-13-14-15" string="no scientific theory on which to base a forecast" id_sentence="23" />
      <mentions>
        <mention ids_tokens="3" string="it" id_sentence="25" />
      </mentions>
    </coreference>
    <coreference id="21" type="NOMINAL">
      <referenced ids_tokens="28-29-30-31" string="the earth 's crust" id_sentence="25" />
      <mentions>
        <mention ids_tokens="13-14" string="the crust" id_sentence="39" />
      </mentions>
    </coreference>
    <coreference id="22" type="NOMINAL">
      <referenced ids_tokens="4-5-6-7-8-9-10-11-12-13-14-15-16-17-18-19-20-21-22-23-24-25-26-27-28-29" string="numerous killer quakes outside the Tokai monitoring network , including a 7.8 earthquake off the coast of Hokkaido last year that claimed more than 200 lives" id_sentence="31" />
      <mentions>
        <mention ids_tokens="24" string="quakes" id_sentence="39" />
      </mentions>
    </coreference>
    <coreference id="23" type="PROPER">
      <referenced ids_tokens="1-2" string="Kiyoo Mogi" id_sentence="32" />
      <mentions>
        <mention ids_tokens="1" string="Mogi" id_sentence="37" />
        <mention ids_tokens="1" string="He" id_sentence="38" />
        <mention ids_tokens="1" string="Mogi" id_sentence="49" />
      </mentions>
    </coreference>
    <coreference id="24" type="NOMINAL">
      <referenced ids_tokens="12-13" string="the call" id_sentence="32" />
      <mentions>
        <mention ids_tokens="12-13" string="their call" id_sentence="52" />
      </mentions>
    </coreference>
    <coreference id="25" type="NOMINAL">
      <referenced ids_tokens="41-42-43-44-45-46" string="others for what he calls '" id_sentence="32" />
      <mentions>
        <mention ids_tokens="9" string="they" id_sentence="33" />
      </mentions>
    </coreference>
    <coreference id="27" type="NOMINAL">
      <referenced ids_tokens="18-19-20" string="numerous small ones" id_sentence="34" />
      <mentions>
        <mention ids_tokens="3" string="they" id_sentence="37" />
        <mention ids_tokens="4" string="they" id_sentence="38" />
        <mention ids_tokens="23" string="they" id_sentence="38" />
      </mentions>
    </coreference>
    <coreference id="28" type="NOMINAL">
      <referenced ids_tokens="13-14-15-16-17" string="each section of a fault" id_sentence="37" />
      <mentions>
        <mention ids_tokens="14-17" string="section of the fault" id_sentence="38" />
      </mentions>
    </coreference>
    <coreference id="29" type="NOMINAL">
      <referenced ids_tokens="16-17" string="a fault" id_sentence="37" />
      <mentions>
        <mention ids_tokens="16-17" string="the fault" id_sentence="38" />
        <mention ids_tokens="29-30" string="the fault" id_sentence="39" />
      </mentions>
    </coreference>
    <coreference id="31" type="NOMINAL">
      <referenced ids_tokens="7-8-9-10" string="scientists outside the programme" id_sentence="41" />
      <mentions>
        <mention ids_tokens="18" string="their" id_sentence="42" />
      </mentions>
    </coreference>
    <coreference id="34" type="NOMINAL">
      <referenced ids_tokens="4" string="a" id_sentence="50" />
      <mentions>
        <mention ids_tokens="13" string="it" id_sentence="51" />
      </mentions>
    </coreference>
  </coreferences>
</document>
