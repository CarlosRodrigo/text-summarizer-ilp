<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="AP880330-0119">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>If the two sides trying to force changes in the 1990 census both get their way, the results would nearly balance one another, a population expert said Wednesday.</content>
      <tokens>
        <token id="1" string="If" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="4" string="sides" lemma="side" stem="side" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="trying" lemma="try" stem="try" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="force" lemma="force" stem="forc" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="changes" lemma="change" stem="chang" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="1990" lemma="1990" stem="1990" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="12" string="census" lemma="census" stem="censu" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="both" lemma="both" stem="both" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="get" lemma="get" stem="get" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="way" lemma="way" stem="wai" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="results" lemma="result" stem="result" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="nearly" lemma="nearly" stem="nearli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="balance" lemma="balance" stem="balanc" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="true" />
        <token id="24" string="another" lemma="another" stem="anoth" pos="DT" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="25" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="population" lemma="population" stem="popul" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="expert" lemma="expert" stem="expert" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="Wednesday" lemma="Wednesday" stem="wednesdai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="31" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (SBAR (IN If) (S (NP (NP (DT the) (CD two) (NNS sides)) (VP (VBG trying) (S (VP (TO to) (VP (VB force) (NP (NNS changes)) (PP (IN in) (NP (DT the) (CD 1990) (NN census)))))))) (ADVP (CC both)) (VP (VBP get) (NP (PRP$ their) (NN way))))) (, ,) (NP (DT the) (NNS results)) (VP (MD would) (ADVP (RB nearly)) (VP (VB balance) (NP (CD one) (DT another))))) (, ,) (NP (DT a) (NN population) (NN expert)) (VP (VBD said) (NP-TMP (NNP Wednesday))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the results" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="results" />
          </tokens>
        </chunking>
        <chunking id="2" string="force changes in the 1990 census" type="VP">
          <tokens>
            <token id="7" string="force" />
            <token id="8" string="changes" />
            <token id="9" string="in" />
            <token id="10" string="the" />
            <token id="11" string="1990" />
            <token id="12" string="census" />
          </tokens>
        </chunking>
        <chunking id="3" string="balance one another" type="VP">
          <tokens>
            <token id="22" string="balance" />
            <token id="23" string="one" />
            <token id="24" string="another" />
          </tokens>
        </chunking>
        <chunking id="4" string="changes" type="NP">
          <tokens>
            <token id="8" string="changes" />
          </tokens>
        </chunking>
        <chunking id="5" string="one another" type="NP">
          <tokens>
            <token id="23" string="one" />
            <token id="24" string="another" />
          </tokens>
        </chunking>
        <chunking id="6" string="the 1990 census" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="1990" />
            <token id="12" string="census" />
          </tokens>
        </chunking>
        <chunking id="7" string="get their way" type="VP">
          <tokens>
            <token id="14" string="get" />
            <token id="15" string="their" />
            <token id="16" string="way" />
          </tokens>
        </chunking>
        <chunking id="8" string="the two sides" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="two" />
            <token id="4" string="sides" />
          </tokens>
        </chunking>
        <chunking id="9" string="the two sides trying to force changes in the 1990 census" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="two" />
            <token id="4" string="sides" />
            <token id="5" string="trying" />
            <token id="6" string="to" />
            <token id="7" string="force" />
            <token id="8" string="changes" />
            <token id="9" string="in" />
            <token id="10" string="the" />
            <token id="11" string="1990" />
            <token id="12" string="census" />
          </tokens>
        </chunking>
        <chunking id="10" string="to force changes in the 1990 census" type="VP">
          <tokens>
            <token id="6" string="to" />
            <token id="7" string="force" />
            <token id="8" string="changes" />
            <token id="9" string="in" />
            <token id="10" string="the" />
            <token id="11" string="1990" />
            <token id="12" string="census" />
          </tokens>
        </chunking>
        <chunking id="11" string="trying to force changes in the 1990 census" type="VP">
          <tokens>
            <token id="5" string="trying" />
            <token id="6" string="to" />
            <token id="7" string="force" />
            <token id="8" string="changes" />
            <token id="9" string="in" />
            <token id="10" string="the" />
            <token id="11" string="1990" />
            <token id="12" string="census" />
          </tokens>
        </chunking>
        <chunking id="12" string="would nearly balance one another" type="VP">
          <tokens>
            <token id="20" string="would" />
            <token id="21" string="nearly" />
            <token id="22" string="balance" />
            <token id="23" string="one" />
            <token id="24" string="another" />
          </tokens>
        </chunking>
        <chunking id="13" string="If the two sides trying to force changes in the 1990 census both get their way" type="SBAR">
          <tokens>
            <token id="1" string="If" />
            <token id="2" string="the" />
            <token id="3" string="two" />
            <token id="4" string="sides" />
            <token id="5" string="trying" />
            <token id="6" string="to" />
            <token id="7" string="force" />
            <token id="8" string="changes" />
            <token id="9" string="in" />
            <token id="10" string="the" />
            <token id="11" string="1990" />
            <token id="12" string="census" />
            <token id="13" string="both" />
            <token id="14" string="get" />
            <token id="15" string="their" />
            <token id="16" string="way" />
          </tokens>
        </chunking>
        <chunking id="14" string="a population expert" type="NP">
          <tokens>
            <token id="26" string="a" />
            <token id="27" string="population" />
            <token id="28" string="expert" />
          </tokens>
        </chunking>
        <chunking id="15" string="said Wednesday" type="VP">
          <tokens>
            <token id="29" string="said" />
            <token id="30" string="Wednesday" />
          </tokens>
        </chunking>
        <chunking id="16" string="their way" type="NP">
          <tokens>
            <token id="15" string="their" />
            <token id="16" string="way" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="14">get</governor>
          <dependent id="1">If</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">sides</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="4">sides</governor>
          <dependent id="3">two</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">get</governor>
          <dependent id="4">sides</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="4">sides</governor>
          <dependent id="5">trying</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">force</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">trying</governor>
          <dependent id="7">force</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">force</governor>
          <dependent id="8">changes</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">census</governor>
          <dependent id="9">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">census</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="12">census</governor>
          <dependent id="11">1990</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">force</governor>
          <dependent id="12">census</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">get</governor>
          <dependent id="13">both</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="22">balance</governor>
          <dependent id="14">get</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="16">way</governor>
          <dependent id="15">their</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">get</governor>
          <dependent id="16">way</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">results</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">balance</governor>
          <dependent id="19">results</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="22">balance</governor>
          <dependent id="20">would</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="22">balance</governor>
          <dependent id="21">nearly</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="29">said</governor>
          <dependent id="22">balance</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">balance</governor>
          <dependent id="23">one</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="23">one</governor>
          <dependent id="24">another</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">expert</governor>
          <dependent id="26">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">expert</governor>
          <dependent id="27">population</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">said</governor>
          <dependent id="28">expert</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="29">said</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="29">said</governor>
          <dependent id="30">Wednesday</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="23" string="one" />
          </tokens>
        </entity>
        <entity id="2" string="Wednesday" type="DATE" score="0.0">
          <tokens>
            <token id="30" string="Wednesday" />
          </tokens>
        </entity>
        <entity id="3" string="1990" type="DATE" score="0.0">
          <tokens>
            <token id="11" string="1990" />
          </tokens>
        </entity>
        <entity id="4" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="3" string="two" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>The Census Bureau is under pressure to exclude illegal aliens from its national head count.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="Census" lemma="Census" stem="censu" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="3" string="Bureau" lemma="Bureau" stem="bureau" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="4" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="under" lemma="under" stem="under" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="pressure" lemma="pressure" stem="pressur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="exclude" lemma="exclude" stem="exclud" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="illegal" lemma="illegal" stem="illeg" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="aliens" lemma="alien" stem="alien" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="national" lemma="national" stem="nation" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="head" lemma="head" stem="head" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="count" lemma="count" stem="count" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NNP Census) (NNP Bureau)) (VP (VBZ is) (PP (IN under) (NP (NN pressure))) (S (VP (TO to) (VP (VB exclude) (NP (JJ illegal) (NNS aliens)) (PP (IN from) (NP (PRP$ its) (JJ national) (NN head) (NN count))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="illegal aliens" type="NP">
          <tokens>
            <token id="9" string="illegal" />
            <token id="10" string="aliens" />
          </tokens>
        </chunking>
        <chunking id="2" string="The Census Bureau" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Census" />
            <token id="3" string="Bureau" />
          </tokens>
        </chunking>
        <chunking id="3" string="to exclude illegal aliens from its national head count" type="VP">
          <tokens>
            <token id="7" string="to" />
            <token id="8" string="exclude" />
            <token id="9" string="illegal" />
            <token id="10" string="aliens" />
            <token id="11" string="from" />
            <token id="12" string="its" />
            <token id="13" string="national" />
            <token id="14" string="head" />
            <token id="15" string="count" />
          </tokens>
        </chunking>
        <chunking id="4" string="its national head count" type="NP">
          <tokens>
            <token id="12" string="its" />
            <token id="13" string="national" />
            <token id="14" string="head" />
            <token id="15" string="count" />
          </tokens>
        </chunking>
        <chunking id="5" string="is under pressure to exclude illegal aliens from its national head count" type="VP">
          <tokens>
            <token id="4" string="is" />
            <token id="5" string="under" />
            <token id="6" string="pressure" />
            <token id="7" string="to" />
            <token id="8" string="exclude" />
            <token id="9" string="illegal" />
            <token id="10" string="aliens" />
            <token id="11" string="from" />
            <token id="12" string="its" />
            <token id="13" string="national" />
            <token id="14" string="head" />
            <token id="15" string="count" />
          </tokens>
        </chunking>
        <chunking id="6" string="pressure" type="NP">
          <tokens>
            <token id="6" string="pressure" />
          </tokens>
        </chunking>
        <chunking id="7" string="exclude illegal aliens from its national head count" type="VP">
          <tokens>
            <token id="8" string="exclude" />
            <token id="9" string="illegal" />
            <token id="10" string="aliens" />
            <token id="11" string="from" />
            <token id="12" string="its" />
            <token id="13" string="national" />
            <token id="14" string="head" />
            <token id="15" string="count" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">Bureau</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Bureau</governor>
          <dependent id="2">Census</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">pressure</governor>
          <dependent id="3">Bureau</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">pressure</governor>
          <dependent id="4">is</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">pressure</governor>
          <dependent id="5">under</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">pressure</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">exclude</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">pressure</governor>
          <dependent id="8">exclude</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">aliens</governor>
          <dependent id="9">illegal</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">exclude</governor>
          <dependent id="10">aliens</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">count</governor>
          <dependent id="11">from</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="15">count</governor>
          <dependent id="12">its</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">count</governor>
          <dependent id="13">national</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">count</governor>
          <dependent id="14">head</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">exclude</governor>
          <dependent id="15">count</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Census Bureau" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="2" string="Census" />
            <token id="3" string="Bureau" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>Traditionally, it counts everyone living in the country.</content>
      <tokens>
        <token id="1" string="Traditionally" lemma="traditionally" stem="tradition" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="counts" lemma="count" stem="count" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="everyone" lemma="everyone" stem="everyon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="living" lemma="living" stem="live" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="country" lemma="country" stem="countri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Traditionally)) (, ,) (NP (PRP it)) (VP (VBZ counts) (NP (NP (NN everyone) (NN living)) (PP (IN in) (NP (DT the) (NN country))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="everyone living" type="NP">
          <tokens>
            <token id="5" string="everyone" />
            <token id="6" string="living" />
          </tokens>
        </chunking>
        <chunking id="2" string="the country" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="country" />
          </tokens>
        </chunking>
        <chunking id="3" string="counts everyone living in the country" type="VP">
          <tokens>
            <token id="4" string="counts" />
            <token id="5" string="everyone" />
            <token id="6" string="living" />
            <token id="7" string="in" />
            <token id="8" string="the" />
            <token id="9" string="country" />
          </tokens>
        </chunking>
        <chunking id="4" string="it" type="NP">
          <tokens>
            <token id="3" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="everyone living in the country" type="NP">
          <tokens>
            <token id="5" string="everyone" />
            <token id="6" string="living" />
            <token id="7" string="in" />
            <token id="8" string="the" />
            <token id="9" string="country" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="4">counts</governor>
          <dependent id="1">Traditionally</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">counts</governor>
          <dependent id="3">it</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">counts</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">living</governor>
          <dependent id="5">everyone</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">counts</governor>
          <dependent id="6">living</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">country</governor>
          <dependent id="7">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">country</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">living</governor>
          <dependent id="9">country</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>Groups which have filed suit to ignore the aliens contend large concentrations of them could result in in some states gaining seats in the House of Representatives at the expense of other states.</content>
      <tokens>
        <token id="1" string="Groups" lemma="group" stem="group" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="filed" lemma="file" stem="file" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="suit" lemma="suit" stem="suit" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="ignore" lemma="ignore" stem="ignor" pos="VB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="9" string="aliens" lemma="alien" stem="alien" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="10" string="contend" lemma="contend" stem="contend" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="large" lemma="large" stem="larg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="concentrations" lemma="concentration" stem="concentr" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="result" lemma="result" stem="result" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="states" lemma="state" stem="state" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="gaining" lemma="gain" stem="gain" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="seats" lemma="seat" stem="seat" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="25" string="House" lemma="House" stem="hous" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="26" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="27" string="Representatives" lemma="Representatives" stem="repres" pos="NNPS" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="28" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="expense" lemma="expense" stem="expens" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="states" lemma="state" stem="state" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNS Groups)) (SBAR (WHNP (WDT which)) (S (VP (VBP have) (VP (VBN filed) (NP (NN suit)) (S (VP (TO to) (VP (VB ignore) (NP (DT the) (NNS aliens)))))))))) (VP (VBP contend) (SBAR (S (NP (NP (JJ large) (NNS concentrations)) (PP (IN of) (NP (PRP them)))) (VP (MD could) (VP (VB result) (PP (IN in) (IN in) (NP (NP (DT some) (NNS states)) (VP (VBG gaining) (NP (NP (NNS seats)) (PP (IN in) (NP (NP (DT the) (NNP House)) (PP (IN of) (NP (NNPS Representatives)))))) (PP (IN at) (NP (NP (DT the) (NN expense)) (PP (IN of) (NP (JJ other) (NNS states))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="to ignore the aliens" type="VP">
          <tokens>
            <token id="6" string="to" />
            <token id="7" string="ignore" />
            <token id="8" string="the" />
            <token id="9" string="aliens" />
          </tokens>
        </chunking>
        <chunking id="2" string="large concentrations" type="NP">
          <tokens>
            <token id="11" string="large" />
            <token id="12" string="concentrations" />
          </tokens>
        </chunking>
        <chunking id="3" string="them" type="NP">
          <tokens>
            <token id="14" string="them" />
          </tokens>
        </chunking>
        <chunking id="4" string="some states gaining seats in the House of Representatives at the expense of other states" type="NP">
          <tokens>
            <token id="19" string="some" />
            <token id="20" string="states" />
            <token id="21" string="gaining" />
            <token id="22" string="seats" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="House" />
            <token id="26" string="of" />
            <token id="27" string="Representatives" />
            <token id="28" string="at" />
            <token id="29" string="the" />
            <token id="30" string="expense" />
            <token id="31" string="of" />
            <token id="32" string="other" />
            <token id="33" string="states" />
          </tokens>
        </chunking>
        <chunking id="5" string="large concentrations of them" type="NP">
          <tokens>
            <token id="11" string="large" />
            <token id="12" string="concentrations" />
            <token id="13" string="of" />
            <token id="14" string="them" />
          </tokens>
        </chunking>
        <chunking id="6" string="the expense" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="expense" />
          </tokens>
        </chunking>
        <chunking id="7" string="suit" type="NP">
          <tokens>
            <token id="5" string="suit" />
          </tokens>
        </chunking>
        <chunking id="8" string="which have filed suit to ignore the aliens" type="SBAR">
          <tokens>
            <token id="2" string="which" />
            <token id="3" string="have" />
            <token id="4" string="filed" />
            <token id="5" string="suit" />
            <token id="6" string="to" />
            <token id="7" string="ignore" />
            <token id="8" string="the" />
            <token id="9" string="aliens" />
          </tokens>
        </chunking>
        <chunking id="9" string="the aliens" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="aliens" />
          </tokens>
        </chunking>
        <chunking id="10" string="have filed suit to ignore the aliens" type="VP">
          <tokens>
            <token id="3" string="have" />
            <token id="4" string="filed" />
            <token id="5" string="suit" />
            <token id="6" string="to" />
            <token id="7" string="ignore" />
            <token id="8" string="the" />
            <token id="9" string="aliens" />
          </tokens>
        </chunking>
        <chunking id="11" string="large concentrations of them could result in in some states gaining seats in the House of Representatives at the expense of other states" type="SBAR">
          <tokens>
            <token id="11" string="large" />
            <token id="12" string="concentrations" />
            <token id="13" string="of" />
            <token id="14" string="them" />
            <token id="15" string="could" />
            <token id="16" string="result" />
            <token id="17" string="in" />
            <token id="18" string="in" />
            <token id="19" string="some" />
            <token id="20" string="states" />
            <token id="21" string="gaining" />
            <token id="22" string="seats" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="House" />
            <token id="26" string="of" />
            <token id="27" string="Representatives" />
            <token id="28" string="at" />
            <token id="29" string="the" />
            <token id="30" string="expense" />
            <token id="31" string="of" />
            <token id="32" string="other" />
            <token id="33" string="states" />
          </tokens>
        </chunking>
        <chunking id="12" string="contend large concentrations of them could result in in some states gaining seats in the House of Representatives at the expense of other states" type="VP">
          <tokens>
            <token id="10" string="contend" />
            <token id="11" string="large" />
            <token id="12" string="concentrations" />
            <token id="13" string="of" />
            <token id="14" string="them" />
            <token id="15" string="could" />
            <token id="16" string="result" />
            <token id="17" string="in" />
            <token id="18" string="in" />
            <token id="19" string="some" />
            <token id="20" string="states" />
            <token id="21" string="gaining" />
            <token id="22" string="seats" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="House" />
            <token id="26" string="of" />
            <token id="27" string="Representatives" />
            <token id="28" string="at" />
            <token id="29" string="the" />
            <token id="30" string="expense" />
            <token id="31" string="of" />
            <token id="32" string="other" />
            <token id="33" string="states" />
          </tokens>
        </chunking>
        <chunking id="13" string="the expense of other states" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="expense" />
            <token id="31" string="of" />
            <token id="32" string="other" />
            <token id="33" string="states" />
          </tokens>
        </chunking>
        <chunking id="14" string="ignore the aliens" type="VP">
          <tokens>
            <token id="7" string="ignore" />
            <token id="8" string="the" />
            <token id="9" string="aliens" />
          </tokens>
        </chunking>
        <chunking id="15" string="the House" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="House" />
          </tokens>
        </chunking>
        <chunking id="16" string="Representatives" type="NP">
          <tokens>
            <token id="27" string="Representatives" />
          </tokens>
        </chunking>
        <chunking id="17" string="other states" type="NP">
          <tokens>
            <token id="32" string="other" />
            <token id="33" string="states" />
          </tokens>
        </chunking>
        <chunking id="18" string="some states" type="NP">
          <tokens>
            <token id="19" string="some" />
            <token id="20" string="states" />
          </tokens>
        </chunking>
        <chunking id="19" string="seats" type="NP">
          <tokens>
            <token id="22" string="seats" />
          </tokens>
        </chunking>
        <chunking id="20" string="gaining seats in the House of Representatives at the expense of other states" type="VP">
          <tokens>
            <token id="21" string="gaining" />
            <token id="22" string="seats" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="House" />
            <token id="26" string="of" />
            <token id="27" string="Representatives" />
            <token id="28" string="at" />
            <token id="29" string="the" />
            <token id="30" string="expense" />
            <token id="31" string="of" />
            <token id="32" string="other" />
            <token id="33" string="states" />
          </tokens>
        </chunking>
        <chunking id="21" string="Groups" type="NP">
          <tokens>
            <token id="1" string="Groups" />
          </tokens>
        </chunking>
        <chunking id="22" string="filed suit to ignore the aliens" type="VP">
          <tokens>
            <token id="4" string="filed" />
            <token id="5" string="suit" />
            <token id="6" string="to" />
            <token id="7" string="ignore" />
            <token id="8" string="the" />
            <token id="9" string="aliens" />
          </tokens>
        </chunking>
        <chunking id="23" string="seats in the House of Representatives" type="NP">
          <tokens>
            <token id="22" string="seats" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="House" />
            <token id="26" string="of" />
            <token id="27" string="Representatives" />
          </tokens>
        </chunking>
        <chunking id="24" string="result in in some states gaining seats in the House of Representatives at the expense of other states" type="VP">
          <tokens>
            <token id="16" string="result" />
            <token id="17" string="in" />
            <token id="18" string="in" />
            <token id="19" string="some" />
            <token id="20" string="states" />
            <token id="21" string="gaining" />
            <token id="22" string="seats" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="House" />
            <token id="26" string="of" />
            <token id="27" string="Representatives" />
            <token id="28" string="at" />
            <token id="29" string="the" />
            <token id="30" string="expense" />
            <token id="31" string="of" />
            <token id="32" string="other" />
            <token id="33" string="states" />
          </tokens>
        </chunking>
        <chunking id="25" string="could result in in some states gaining seats in the House of Representatives at the expense of other states" type="VP">
          <tokens>
            <token id="15" string="could" />
            <token id="16" string="result" />
            <token id="17" string="in" />
            <token id="18" string="in" />
            <token id="19" string="some" />
            <token id="20" string="states" />
            <token id="21" string="gaining" />
            <token id="22" string="seats" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="House" />
            <token id="26" string="of" />
            <token id="27" string="Representatives" />
            <token id="28" string="at" />
            <token id="29" string="the" />
            <token id="30" string="expense" />
            <token id="31" string="of" />
            <token id="32" string="other" />
            <token id="33" string="states" />
          </tokens>
        </chunking>
        <chunking id="26" string="the House of Representatives" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="House" />
            <token id="26" string="of" />
            <token id="27" string="Representatives" />
          </tokens>
        </chunking>
        <chunking id="27" string="Groups which have filed suit to ignore the aliens" type="NP">
          <tokens>
            <token id="1" string="Groups" />
            <token id="2" string="which" />
            <token id="3" string="have" />
            <token id="4" string="filed" />
            <token id="5" string="suit" />
            <token id="6" string="to" />
            <token id="7" string="ignore" />
            <token id="8" string="the" />
            <token id="9" string="aliens" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="10">contend</governor>
          <dependent id="1">Groups</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">filed</governor>
          <dependent id="2">which</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">filed</governor>
          <dependent id="3">have</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="1">Groups</governor>
          <dependent id="4">filed</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">filed</governor>
          <dependent id="5">suit</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">ignore</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">filed</governor>
          <dependent id="7">ignore</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">aliens</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">ignore</governor>
          <dependent id="9">aliens</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">contend</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">concentrations</governor>
          <dependent id="11">large</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">result</governor>
          <dependent id="12">concentrations</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">them</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">concentrations</governor>
          <dependent id="14">them</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">result</governor>
          <dependent id="15">could</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">contend</governor>
          <dependent id="16">result</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">states</governor>
          <dependent id="17">in</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">states</governor>
          <dependent id="18">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">states</governor>
          <dependent id="19">some</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">result</governor>
          <dependent id="20">states</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="20">states</governor>
          <dependent id="21">gaining</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">gaining</governor>
          <dependent id="22">seats</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">House</governor>
          <dependent id="23">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">House</governor>
          <dependent id="24">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">seats</governor>
          <dependent id="25">House</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">Representatives</governor>
          <dependent id="26">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">House</governor>
          <dependent id="27">Representatives</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">expense</governor>
          <dependent id="28">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">expense</governor>
          <dependent id="29">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">gaining</governor>
          <dependent id="30">expense</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">states</governor>
          <dependent id="31">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="33">states</governor>
          <dependent id="32">other</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">expense</governor>
          <dependent id="33">states</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="House of Representatives" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="25" string="House" />
            <token id="26" string="of" />
            <token id="27" string="Representatives" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>Meanwhile, other groups want the final census totals to be increased to account for people who may be overlooked in the census _ most often blacks and Hispanics living in urban areas.</content>
      <tokens>
        <token id="1" string="Meanwhile" lemma="meanwhile" stem="meanwhil" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="groups" lemma="group" stem="group" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="want" lemma="want" stem="want" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="final" lemma="final" stem="final" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="census" lemma="census" stem="censu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="totals" lemma="total" stem="total" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="increased" lemma="increase" stem="increas" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="account" lemma="account" stem="account" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="may" lemma="may" stem="mai" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="overlooked" lemma="overlook" stem="overlook" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="census" lemma="census" stem="censu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="_" lemma="_" stem="_" pos="NN" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="most" lemma="most" stem="most" pos="RBS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="often" lemma="often" stem="often" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="blacks" lemma="black" stem="black" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="Hispanics" lemma="Hispanics" stem="hispan" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="30" string="living" lemma="live" stem="live" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="urban" lemma="urban" stem="urban" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="areas" lemma="area" stem="area" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Meanwhile)) (, ,) (NP (JJ other) (NNS groups)) (VP (VBP want) (SBAR (S (NP (DT the) (JJ final) (NN census)) (VP (VBZ totals) (S (VP (TO to) (VP (VB be) (VP (VBN increased) (S (VP (TO to) (VP (VB account) (PP (IN for) (NP (NP (NNS people)) (SBAR (WHNP (WP who)) (S (VP (MD may) (VP (VB be) (VP (VBN overlooked) (PP (IN in) (NP (NP (DT the) (NN census) (NN _)) (ADVP (RBS most) (RB often)))) (NP-TMP (NP (NNS blacks)) (CC and) (NP (NNPS Hispanics))) (S (VP (VBG living) (PP (IN in) (NP (JJ urban) (NNS areas))))))))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="be increased to account for people who may be overlooked in the census _ most often blacks and Hispanics living in urban areas" type="VP">
          <tokens>
            <token id="11" string="be" />
            <token id="12" string="increased" />
            <token id="13" string="to" />
            <token id="14" string="account" />
            <token id="15" string="for" />
            <token id="16" string="people" />
            <token id="17" string="who" />
            <token id="18" string="may" />
            <token id="19" string="be" />
            <token id="20" string="overlooked" />
            <token id="21" string="in" />
            <token id="22" string="the" />
            <token id="23" string="census" />
            <token id="24" string="_" />
            <token id="25" string="most" />
            <token id="26" string="often" />
            <token id="27" string="blacks" />
            <token id="28" string="and" />
            <token id="29" string="Hispanics" />
            <token id="30" string="living" />
            <token id="31" string="in" />
            <token id="32" string="urban" />
            <token id="33" string="areas" />
          </tokens>
        </chunking>
        <chunking id="2" string="the census _ most often" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="census" />
            <token id="24" string="_" />
            <token id="25" string="most" />
            <token id="26" string="often" />
          </tokens>
        </chunking>
        <chunking id="3" string="urban areas" type="NP">
          <tokens>
            <token id="32" string="urban" />
            <token id="33" string="areas" />
          </tokens>
        </chunking>
        <chunking id="4" string="people who may be overlooked in the census _ most often blacks and Hispanics living in urban areas" type="NP">
          <tokens>
            <token id="16" string="people" />
            <token id="17" string="who" />
            <token id="18" string="may" />
            <token id="19" string="be" />
            <token id="20" string="overlooked" />
            <token id="21" string="in" />
            <token id="22" string="the" />
            <token id="23" string="census" />
            <token id="24" string="_" />
            <token id="25" string="most" />
            <token id="26" string="often" />
            <token id="27" string="blacks" />
            <token id="28" string="and" />
            <token id="29" string="Hispanics" />
            <token id="30" string="living" />
            <token id="31" string="in" />
            <token id="32" string="urban" />
            <token id="33" string="areas" />
          </tokens>
        </chunking>
        <chunking id="5" string="blacks" type="NP">
          <tokens>
            <token id="27" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="6" string="other groups" type="NP">
          <tokens>
            <token id="3" string="other" />
            <token id="4" string="groups" />
          </tokens>
        </chunking>
        <chunking id="7" string="the census _" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="census" />
            <token id="24" string="_" />
          </tokens>
        </chunking>
        <chunking id="8" string="people" type="NP">
          <tokens>
            <token id="16" string="people" />
          </tokens>
        </chunking>
        <chunking id="9" string="be overlooked in the census _ most often blacks and Hispanics living in urban areas" type="VP">
          <tokens>
            <token id="19" string="be" />
            <token id="20" string="overlooked" />
            <token id="21" string="in" />
            <token id="22" string="the" />
            <token id="23" string="census" />
            <token id="24" string="_" />
            <token id="25" string="most" />
            <token id="26" string="often" />
            <token id="27" string="blacks" />
            <token id="28" string="and" />
            <token id="29" string="Hispanics" />
            <token id="30" string="living" />
            <token id="31" string="in" />
            <token id="32" string="urban" />
            <token id="33" string="areas" />
          </tokens>
        </chunking>
        <chunking id="10" string="may be overlooked in the census _ most often blacks and Hispanics living in urban areas" type="VP">
          <tokens>
            <token id="18" string="may" />
            <token id="19" string="be" />
            <token id="20" string="overlooked" />
            <token id="21" string="in" />
            <token id="22" string="the" />
            <token id="23" string="census" />
            <token id="24" string="_" />
            <token id="25" string="most" />
            <token id="26" string="often" />
            <token id="27" string="blacks" />
            <token id="28" string="and" />
            <token id="29" string="Hispanics" />
            <token id="30" string="living" />
            <token id="31" string="in" />
            <token id="32" string="urban" />
            <token id="33" string="areas" />
          </tokens>
        </chunking>
        <chunking id="11" string="want the final census totals to be increased to account for people who may be overlooked in the census _ most often blacks and Hispanics living in urban areas" type="VP">
          <tokens>
            <token id="5" string="want" />
            <token id="6" string="the" />
            <token id="7" string="final" />
            <token id="8" string="census" />
            <token id="9" string="totals" />
            <token id="10" string="to" />
            <token id="11" string="be" />
            <token id="12" string="increased" />
            <token id="13" string="to" />
            <token id="14" string="account" />
            <token id="15" string="for" />
            <token id="16" string="people" />
            <token id="17" string="who" />
            <token id="18" string="may" />
            <token id="19" string="be" />
            <token id="20" string="overlooked" />
            <token id="21" string="in" />
            <token id="22" string="the" />
            <token id="23" string="census" />
            <token id="24" string="_" />
            <token id="25" string="most" />
            <token id="26" string="often" />
            <token id="27" string="blacks" />
            <token id="28" string="and" />
            <token id="29" string="Hispanics" />
            <token id="30" string="living" />
            <token id="31" string="in" />
            <token id="32" string="urban" />
            <token id="33" string="areas" />
          </tokens>
        </chunking>
        <chunking id="12" string="who may be overlooked in the census _ most often blacks and Hispanics living in urban areas" type="SBAR">
          <tokens>
            <token id="17" string="who" />
            <token id="18" string="may" />
            <token id="19" string="be" />
            <token id="20" string="overlooked" />
            <token id="21" string="in" />
            <token id="22" string="the" />
            <token id="23" string="census" />
            <token id="24" string="_" />
            <token id="25" string="most" />
            <token id="26" string="often" />
            <token id="27" string="blacks" />
            <token id="28" string="and" />
            <token id="29" string="Hispanics" />
            <token id="30" string="living" />
            <token id="31" string="in" />
            <token id="32" string="urban" />
            <token id="33" string="areas" />
          </tokens>
        </chunking>
        <chunking id="13" string="the final census" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="final" />
            <token id="8" string="census" />
          </tokens>
        </chunking>
        <chunking id="14" string="totals to be increased to account for people who may be overlooked in the census _ most often blacks and Hispanics living in urban areas" type="VP">
          <tokens>
            <token id="9" string="totals" />
            <token id="10" string="to" />
            <token id="11" string="be" />
            <token id="12" string="increased" />
            <token id="13" string="to" />
            <token id="14" string="account" />
            <token id="15" string="for" />
            <token id="16" string="people" />
            <token id="17" string="who" />
            <token id="18" string="may" />
            <token id="19" string="be" />
            <token id="20" string="overlooked" />
            <token id="21" string="in" />
            <token id="22" string="the" />
            <token id="23" string="census" />
            <token id="24" string="_" />
            <token id="25" string="most" />
            <token id="26" string="often" />
            <token id="27" string="blacks" />
            <token id="28" string="and" />
            <token id="29" string="Hispanics" />
            <token id="30" string="living" />
            <token id="31" string="in" />
            <token id="32" string="urban" />
            <token id="33" string="areas" />
          </tokens>
        </chunking>
        <chunking id="15" string="account for people who may be overlooked in the census _ most often blacks and Hispanics living in urban areas" type="VP">
          <tokens>
            <token id="14" string="account" />
            <token id="15" string="for" />
            <token id="16" string="people" />
            <token id="17" string="who" />
            <token id="18" string="may" />
            <token id="19" string="be" />
            <token id="20" string="overlooked" />
            <token id="21" string="in" />
            <token id="22" string="the" />
            <token id="23" string="census" />
            <token id="24" string="_" />
            <token id="25" string="most" />
            <token id="26" string="often" />
            <token id="27" string="blacks" />
            <token id="28" string="and" />
            <token id="29" string="Hispanics" />
            <token id="30" string="living" />
            <token id="31" string="in" />
            <token id="32" string="urban" />
            <token id="33" string="areas" />
          </tokens>
        </chunking>
        <chunking id="16" string="to account for people who may be overlooked in the census _ most often blacks and Hispanics living in urban areas" type="VP">
          <tokens>
            <token id="13" string="to" />
            <token id="14" string="account" />
            <token id="15" string="for" />
            <token id="16" string="people" />
            <token id="17" string="who" />
            <token id="18" string="may" />
            <token id="19" string="be" />
            <token id="20" string="overlooked" />
            <token id="21" string="in" />
            <token id="22" string="the" />
            <token id="23" string="census" />
            <token id="24" string="_" />
            <token id="25" string="most" />
            <token id="26" string="often" />
            <token id="27" string="blacks" />
            <token id="28" string="and" />
            <token id="29" string="Hispanics" />
            <token id="30" string="living" />
            <token id="31" string="in" />
            <token id="32" string="urban" />
            <token id="33" string="areas" />
          </tokens>
        </chunking>
        <chunking id="17" string="the final census totals to be increased to account for people who may be overlooked in the census _ most often blacks and Hispanics living in urban areas" type="SBAR">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="final" />
            <token id="8" string="census" />
            <token id="9" string="totals" />
            <token id="10" string="to" />
            <token id="11" string="be" />
            <token id="12" string="increased" />
            <token id="13" string="to" />
            <token id="14" string="account" />
            <token id="15" string="for" />
            <token id="16" string="people" />
            <token id="17" string="who" />
            <token id="18" string="may" />
            <token id="19" string="be" />
            <token id="20" string="overlooked" />
            <token id="21" string="in" />
            <token id="22" string="the" />
            <token id="23" string="census" />
            <token id="24" string="_" />
            <token id="25" string="most" />
            <token id="26" string="often" />
            <token id="27" string="blacks" />
            <token id="28" string="and" />
            <token id="29" string="Hispanics" />
            <token id="30" string="living" />
            <token id="31" string="in" />
            <token id="32" string="urban" />
            <token id="33" string="areas" />
          </tokens>
        </chunking>
        <chunking id="18" string="to be increased to account for people who may be overlooked in the census _ most often blacks and Hispanics living in urban areas" type="VP">
          <tokens>
            <token id="10" string="to" />
            <token id="11" string="be" />
            <token id="12" string="increased" />
            <token id="13" string="to" />
            <token id="14" string="account" />
            <token id="15" string="for" />
            <token id="16" string="people" />
            <token id="17" string="who" />
            <token id="18" string="may" />
            <token id="19" string="be" />
            <token id="20" string="overlooked" />
            <token id="21" string="in" />
            <token id="22" string="the" />
            <token id="23" string="census" />
            <token id="24" string="_" />
            <token id="25" string="most" />
            <token id="26" string="often" />
            <token id="27" string="blacks" />
            <token id="28" string="and" />
            <token id="29" string="Hispanics" />
            <token id="30" string="living" />
            <token id="31" string="in" />
            <token id="32" string="urban" />
            <token id="33" string="areas" />
          </tokens>
        </chunking>
        <chunking id="19" string="Hispanics" type="NP">
          <tokens>
            <token id="29" string="Hispanics" />
          </tokens>
        </chunking>
        <chunking id="20" string="living in urban areas" type="VP">
          <tokens>
            <token id="30" string="living" />
            <token id="31" string="in" />
            <token id="32" string="urban" />
            <token id="33" string="areas" />
          </tokens>
        </chunking>
        <chunking id="21" string="increased to account for people who may be overlooked in the census _ most often blacks and Hispanics living in urban areas" type="VP">
          <tokens>
            <token id="12" string="increased" />
            <token id="13" string="to" />
            <token id="14" string="account" />
            <token id="15" string="for" />
            <token id="16" string="people" />
            <token id="17" string="who" />
            <token id="18" string="may" />
            <token id="19" string="be" />
            <token id="20" string="overlooked" />
            <token id="21" string="in" />
            <token id="22" string="the" />
            <token id="23" string="census" />
            <token id="24" string="_" />
            <token id="25" string="most" />
            <token id="26" string="often" />
            <token id="27" string="blacks" />
            <token id="28" string="and" />
            <token id="29" string="Hispanics" />
            <token id="30" string="living" />
            <token id="31" string="in" />
            <token id="32" string="urban" />
            <token id="33" string="areas" />
          </tokens>
        </chunking>
        <chunking id="22" string="overlooked in the census _ most often blacks and Hispanics living in urban areas" type="VP">
          <tokens>
            <token id="20" string="overlooked" />
            <token id="21" string="in" />
            <token id="22" string="the" />
            <token id="23" string="census" />
            <token id="24" string="_" />
            <token id="25" string="most" />
            <token id="26" string="often" />
            <token id="27" string="blacks" />
            <token id="28" string="and" />
            <token id="29" string="Hispanics" />
            <token id="30" string="living" />
            <token id="31" string="in" />
            <token id="32" string="urban" />
            <token id="33" string="areas" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="5">want</governor>
          <dependent id="1">Meanwhile</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">groups</governor>
          <dependent id="3">other</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">want</governor>
          <dependent id="4">groups</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">want</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">census</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">census</governor>
          <dependent id="7">final</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">totals</governor>
          <dependent id="8">census</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">want</governor>
          <dependent id="9">totals</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">increased</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="12">increased</governor>
          <dependent id="11">be</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="9">totals</governor>
          <dependent id="12">increased</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">account</governor>
          <dependent id="13">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="12">increased</governor>
          <dependent id="14">account</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">people</governor>
          <dependent id="15">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">account</governor>
          <dependent id="16">people</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="20">overlooked</governor>
          <dependent id="17">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="20">overlooked</governor>
          <dependent id="18">may</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="20">overlooked</governor>
          <dependent id="19">be</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="16">people</governor>
          <dependent id="20">overlooked</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">_</governor>
          <dependent id="21">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">_</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">_</governor>
          <dependent id="23">census</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">overlooked</governor>
          <dependent id="24">_</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="26">often</governor>
          <dependent id="25">most</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="24">_</governor>
          <dependent id="26">often</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="20">overlooked</governor>
          <dependent id="27">blacks</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="27">blacks</governor>
          <dependent id="28">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="27">blacks</governor>
          <dependent id="29">Hispanics</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="20">overlooked</governor>
          <dependent id="30">living</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">areas</governor>
          <dependent id="31">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="33">areas</governor>
          <dependent id="32">urban</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">living</governor>
          <dependent id="33">areas</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Hispanics" type="MISC" score="0.0">
          <tokens>
            <token id="29" string="Hispanics" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>At stake are the 435 seats in the House, which are distributed among the states on the basis of population.</content>
      <tokens>
        <token id="1" string="At" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="stake" lemma="stake" stem="stake" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="435" lemma="435" stem="435" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="6" string="seats" lemma="seat" stem="seat" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="House" lemma="House" stem="hous" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="distributed" lemma="distribute" stem="distribut" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="among" lemma="among" stem="among" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="states" lemma="state" stem="state" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="basis" lemma="basis" stem="basi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="population" lemma="population" stem="popul" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (PP (IN At) (NP (NN stake))) (VP (VBP are)) (NP (NP (DT the) (CD 435) (NNS seats)) (PP (IN in) (NP (DT the) (NNP House))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBP are) (VP (VBN distributed) (PP (IN among) (NP (NP (DT the) (NNS states)) (PP (IN on) (NP (NP (DT the) (NN basis)) (PP (IN of) (NP (NN population)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="are distributed among the states on the basis of population" type="VP">
          <tokens>
            <token id="12" string="are" />
            <token id="13" string="distributed" />
            <token id="14" string="among" />
            <token id="15" string="the" />
            <token id="16" string="states" />
            <token id="17" string="on" />
            <token id="18" string="the" />
            <token id="19" string="basis" />
            <token id="20" string="of" />
            <token id="21" string="population" />
          </tokens>
        </chunking>
        <chunking id="2" string="the House" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="House" />
          </tokens>
        </chunking>
        <chunking id="3" string="the 435 seats" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="435" />
            <token id="6" string="seats" />
          </tokens>
        </chunking>
        <chunking id="4" string="the 435 seats in the House , which are distributed among the states on the basis of population" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="435" />
            <token id="6" string="seats" />
            <token id="7" string="in" />
            <token id="8" string="the" />
            <token id="9" string="House" />
            <token id="10" string="," />
            <token id="11" string="which" />
            <token id="12" string="are" />
            <token id="13" string="distributed" />
            <token id="14" string="among" />
            <token id="15" string="the" />
            <token id="16" string="states" />
            <token id="17" string="on" />
            <token id="18" string="the" />
            <token id="19" string="basis" />
            <token id="20" string="of" />
            <token id="21" string="population" />
          </tokens>
        </chunking>
        <chunking id="5" string="distributed among the states on the basis of population" type="VP">
          <tokens>
            <token id="13" string="distributed" />
            <token id="14" string="among" />
            <token id="15" string="the" />
            <token id="16" string="states" />
            <token id="17" string="on" />
            <token id="18" string="the" />
            <token id="19" string="basis" />
            <token id="20" string="of" />
            <token id="21" string="population" />
          </tokens>
        </chunking>
        <chunking id="6" string="population" type="NP">
          <tokens>
            <token id="21" string="population" />
          </tokens>
        </chunking>
        <chunking id="7" string="the states" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="states" />
          </tokens>
        </chunking>
        <chunking id="8" string="the basis" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="basis" />
          </tokens>
        </chunking>
        <chunking id="9" string="are" type="VP">
          <tokens>
            <token id="3" string="are" />
          </tokens>
        </chunking>
        <chunking id="10" string="stake" type="NP">
          <tokens>
            <token id="2" string="stake" />
          </tokens>
        </chunking>
        <chunking id="11" string="which are distributed among the states on the basis of population" type="SBAR">
          <tokens>
            <token id="11" string="which" />
            <token id="12" string="are" />
            <token id="13" string="distributed" />
            <token id="14" string="among" />
            <token id="15" string="the" />
            <token id="16" string="states" />
            <token id="17" string="on" />
            <token id="18" string="the" />
            <token id="19" string="basis" />
            <token id="20" string="of" />
            <token id="21" string="population" />
          </tokens>
        </chunking>
        <chunking id="12" string="the basis of population" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="basis" />
            <token id="20" string="of" />
            <token id="21" string="population" />
          </tokens>
        </chunking>
        <chunking id="13" string="the states on the basis of population" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="states" />
            <token id="17" string="on" />
            <token id="18" string="the" />
            <token id="19" string="basis" />
            <token id="20" string="of" />
            <token id="21" string="population" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">stake</governor>
          <dependent id="1">At</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">are</governor>
          <dependent id="2">stake</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">are</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">seats</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="6">seats</governor>
          <dependent id="5">435</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">are</governor>
          <dependent id="6">seats</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">House</governor>
          <dependent id="7">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">House</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">seats</governor>
          <dependent id="9">House</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="13">distributed</governor>
          <dependent id="11">which</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="13">distributed</governor>
          <dependent id="12">are</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="6">seats</governor>
          <dependent id="13">distributed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">states</governor>
          <dependent id="14">among</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">states</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">distributed</governor>
          <dependent id="16">states</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">basis</governor>
          <dependent id="17">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">basis</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">states</governor>
          <dependent id="19">basis</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">population</governor>
          <dependent id="20">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">basis</governor>
          <dependent id="21">population</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="435" type="NUMBER" score="0.0">
          <tokens>
            <token id="5" string="435" />
          </tokens>
        </entity>
        <entity id="2" string="House" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="9" string="House" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>``If both sides get their way, the only change would be a flip-flop of one seat from California to Georgia,&amp;apost;&amp;apost; said William O&amp;apost;Hare, director of policy studies for the independent Population Reference Bureau.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="If" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="both" lemma="both" stem="both" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="sides" lemma="side" stem="side" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="get" lemma="get" stem="get" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="way" lemma="way" stem="wai" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="only" lemma="only" stem="onli" pos="JJ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="change" lemma="change" stem="chang" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="flip-flop" lemma="flip-flop" stem="flip-flop" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="18" string="seat" lemma="seat" stem="seat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="California" lemma="California" stem="california" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="21" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="Georgia" lemma="Georgia" stem="georgia" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="William" lemma="William" stem="william" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="27" string="O'Hare" lemma="O'Hare" stem="o'hare" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="28" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="director" lemma="director" stem="director" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="policy" lemma="policy" stem="polici" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="studies" lemma="study" stem="studi" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="independent" lemma="independent" stem="independ" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="36" string="Population" lemma="Population" stem="popul" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="37" string="Reference" lemma="Reference" stem="refer" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="38" string="Bureau" lemma="Bureau" stem="bureau" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="39" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (SBAR (IN If) (S (NP (DT both) (NNS sides)) (VP (VBP get) (NP (PRP$ their) (NN way))))) (, ,) (NP (DT the) (JJ only) (NN change)) (VP (MD would) (VP (VB be) (NP (NP (DT a) (NN flip-flop)) (PP (IN of) (NP (NP (CD one) (NN seat)) (PP (IN from) (NP (NNP California)))))) (PP (TO to) (NP (NNP Georgia)))))) (, ,) ('' '') (VP (VBD said)) (NP (NP (NNP William) (NNP O'Hare)) (, ,) (NP (NP (NN director)) (PP (IN of) (NP (NP (NN policy) (NNS studies)) (PP (IN for) (NP (DT the) (JJ independent) (NNP Population) (NNP Reference) (NNP Bureau))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="director" type="NP">
          <tokens>
            <token id="29" string="director" />
          </tokens>
        </chunking>
        <chunking id="2" string="policy studies for the independent Population Reference Bureau" type="NP">
          <tokens>
            <token id="31" string="policy" />
            <token id="32" string="studies" />
            <token id="33" string="for" />
            <token id="34" string="the" />
            <token id="35" string="independent" />
            <token id="36" string="Population" />
            <token id="37" string="Reference" />
            <token id="38" string="Bureau" />
          </tokens>
        </chunking>
        <chunking id="3" string="policy studies" type="NP">
          <tokens>
            <token id="31" string="policy" />
            <token id="32" string="studies" />
          </tokens>
        </chunking>
        <chunking id="4" string="California" type="NP">
          <tokens>
            <token id="20" string="California" />
          </tokens>
        </chunking>
        <chunking id="5" string="both sides" type="NP">
          <tokens>
            <token id="3" string="both" />
            <token id="4" string="sides" />
          </tokens>
        </chunking>
        <chunking id="6" string="get their way" type="VP">
          <tokens>
            <token id="5" string="get" />
            <token id="6" string="their" />
            <token id="7" string="way" />
          </tokens>
        </chunking>
        <chunking id="7" string="If both sides get their way" type="SBAR">
          <tokens>
            <token id="2" string="If" />
            <token id="3" string="both" />
            <token id="4" string="sides" />
            <token id="5" string="get" />
            <token id="6" string="their" />
            <token id="7" string="way" />
          </tokens>
        </chunking>
        <chunking id="8" string="be a flip-flop of one seat from California to Georgia" type="VP">
          <tokens>
            <token id="13" string="be" />
            <token id="14" string="a" />
            <token id="15" string="flip-flop" />
            <token id="16" string="of" />
            <token id="17" string="one" />
            <token id="18" string="seat" />
            <token id="19" string="from" />
            <token id="20" string="California" />
            <token id="21" string="to" />
            <token id="22" string="Georgia" />
          </tokens>
        </chunking>
        <chunking id="9" string="would be a flip-flop of one seat from California to Georgia" type="VP">
          <tokens>
            <token id="12" string="would" />
            <token id="13" string="be" />
            <token id="14" string="a" />
            <token id="15" string="flip-flop" />
            <token id="16" string="of" />
            <token id="17" string="one" />
            <token id="18" string="seat" />
            <token id="19" string="from" />
            <token id="20" string="California" />
            <token id="21" string="to" />
            <token id="22" string="Georgia" />
          </tokens>
        </chunking>
        <chunking id="10" string="a flip-flop of one seat from California" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="flip-flop" />
            <token id="16" string="of" />
            <token id="17" string="one" />
            <token id="18" string="seat" />
            <token id="19" string="from" />
            <token id="20" string="California" />
          </tokens>
        </chunking>
        <chunking id="11" string="William O'Hare , director of policy studies for the independent Population Reference Bureau" type="NP">
          <tokens>
            <token id="26" string="William" />
            <token id="27" string="O'Hare" />
            <token id="28" string="," />
            <token id="29" string="director" />
            <token id="30" string="of" />
            <token id="31" string="policy" />
            <token id="32" string="studies" />
            <token id="33" string="for" />
            <token id="34" string="the" />
            <token id="35" string="independent" />
            <token id="36" string="Population" />
            <token id="37" string="Reference" />
            <token id="38" string="Bureau" />
          </tokens>
        </chunking>
        <chunking id="12" string="director of policy studies for the independent Population Reference Bureau" type="NP">
          <tokens>
            <token id="29" string="director" />
            <token id="30" string="of" />
            <token id="31" string="policy" />
            <token id="32" string="studies" />
            <token id="33" string="for" />
            <token id="34" string="the" />
            <token id="35" string="independent" />
            <token id="36" string="Population" />
            <token id="37" string="Reference" />
            <token id="38" string="Bureau" />
          </tokens>
        </chunking>
        <chunking id="13" string="William O'Hare" type="NP">
          <tokens>
            <token id="26" string="William" />
            <token id="27" string="O'Hare" />
          </tokens>
        </chunking>
        <chunking id="14" string="a flip-flop" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="flip-flop" />
          </tokens>
        </chunking>
        <chunking id="15" string="Georgia" type="NP">
          <tokens>
            <token id="22" string="Georgia" />
          </tokens>
        </chunking>
        <chunking id="16" string="the only change" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="only" />
            <token id="11" string="change" />
          </tokens>
        </chunking>
        <chunking id="17" string="one seat" type="NP">
          <tokens>
            <token id="17" string="one" />
            <token id="18" string="seat" />
          </tokens>
        </chunking>
        <chunking id="18" string="their way" type="NP">
          <tokens>
            <token id="6" string="their" />
            <token id="7" string="way" />
          </tokens>
        </chunking>
        <chunking id="19" string="said" type="VP">
          <tokens>
            <token id="25" string="said" />
          </tokens>
        </chunking>
        <chunking id="20" string="one seat from California" type="NP">
          <tokens>
            <token id="17" string="one" />
            <token id="18" string="seat" />
            <token id="19" string="from" />
            <token id="20" string="California" />
          </tokens>
        </chunking>
        <chunking id="21" string="the independent Population Reference Bureau" type="NP">
          <tokens>
            <token id="34" string="the" />
            <token id="35" string="independent" />
            <token id="36" string="Population" />
            <token id="37" string="Reference" />
            <token id="38" string="Bureau" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="5">get</governor>
          <dependent id="2">If</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">sides</governor>
          <dependent id="3">both</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">get</governor>
          <dependent id="4">sides</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="15">flip-flop</governor>
          <dependent id="5">get</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="7">way</governor>
          <dependent id="6">their</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">get</governor>
          <dependent id="7">way</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">change</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">change</governor>
          <dependent id="10">only</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">flip-flop</governor>
          <dependent id="11">change</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="15">flip-flop</governor>
          <dependent id="12">would</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="15">flip-flop</governor>
          <dependent id="13">be</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">flip-flop</governor>
          <dependent id="14">a</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="25">said</governor>
          <dependent id="15">flip-flop</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">seat</governor>
          <dependent id="16">of</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="18">seat</governor>
          <dependent id="17">one</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">flip-flop</governor>
          <dependent id="18">seat</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">California</governor>
          <dependent id="19">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">seat</governor>
          <dependent id="20">California</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">Georgia</governor>
          <dependent id="21">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">flip-flop</governor>
          <dependent id="22">Georgia</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="25">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">O'Hare</governor>
          <dependent id="26">William</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">said</governor>
          <dependent id="27">O'Hare</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="27">O'Hare</governor>
          <dependent id="29">director</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">studies</governor>
          <dependent id="30">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="32">studies</governor>
          <dependent id="31">policy</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">director</governor>
          <dependent id="32">studies</dependent>
        </dependency>
        <dependency type="case">
          <governor id="38">Bureau</governor>
          <dependent id="33">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="38">Bureau</governor>
          <dependent id="34">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="38">Bureau</governor>
          <dependent id="35">independent</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="38">Bureau</governor>
          <dependent id="36">Population</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="38">Bureau</governor>
          <dependent id="37">Reference</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="32">studies</governor>
          <dependent id="38">Bureau</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="17" string="one" />
          </tokens>
        </entity>
        <entity id="2" string="California" type="LOCATION" score="0.0">
          <tokens>
            <token id="20" string="California" />
          </tokens>
        </entity>
        <entity id="3" string="Population Reference Bureau" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="36" string="Population" />
            <token id="37" string="Reference" />
            <token id="38" string="Bureau" />
          </tokens>
        </entity>
        <entity id="4" string="William O'Hare" type="PERSON" score="0.0">
          <tokens>
            <token id="26" string="William" />
            <token id="27" string="O'Hare" />
          </tokens>
        </entity>
        <entity id="5" string="independent" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="35" string="independent" />
          </tokens>
        </entity>
        <entity id="6" string="Georgia" type="LOCATION" score="0.0">
          <tokens>
            <token id="22" string="Georgia" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>O&amp;apost;Hare told a breakfast briefing for Northeast and Midwest members of Congress that he estimates their region will lose 14 House seats following the 1990 census.</content>
      <tokens>
        <token id="1" string="O'Hare" lemma="O'Hare" stem="o'hare" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="told" lemma="tell" stem="told" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="breakfast" lemma="breakfast" stem="breakfast" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="briefing" lemma="briefing" stem="brief" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Northeast" lemma="Northeast" stem="northeast" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="Midwest" lemma="Midwest" stem="midwest" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="members" lemma="member" stem="member" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="Congress" lemma="Congress" stem="congress" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="13" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="estimates" lemma="estimate" stem="estim" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="region" lemma="region" stem="region" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="lose" lemma="lose" stem="lose" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="14" lemma="14" stem="14" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="21" string="House" lemma="House" stem="hous" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="22" string="seats" lemma="seat" stem="seat" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="following" lemma="follow" stem="follow" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="1990" lemma="1990" stem="1990" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="26" string="census" lemma="census" stem="censu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP O'Hare)) (VP (VBD told) (NP (DT a) (NN breakfast) (NN briefing)) (PP (IN for) (NP (NP (NNP Northeast) (CC and) (NNP Midwest) (NNS members)) (PP (IN of) (NP (NNP Congress))))) (SBAR (IN that) (S (NP (PRP he)) (VP (VBZ estimates) (SBAR (S (NP (PRP$ their) (NN region)) (VP (MD will) (VP (VB lose) (NP (CD 14) (NNP House) (NNS seats)) (PP (VBG following) (NP (DT the) (CD 1990) (NN census))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="14 House seats" type="NP">
          <tokens>
            <token id="20" string="14" />
            <token id="21" string="House" />
            <token id="22" string="seats" />
          </tokens>
        </chunking>
        <chunking id="2" string="that he estimates their region will lose 14 House seats following the 1990 census" type="SBAR">
          <tokens>
            <token id="13" string="that" />
            <token id="14" string="he" />
            <token id="15" string="estimates" />
            <token id="16" string="their" />
            <token id="17" string="region" />
            <token id="18" string="will" />
            <token id="19" string="lose" />
            <token id="20" string="14" />
            <token id="21" string="House" />
            <token id="22" string="seats" />
            <token id="23" string="following" />
            <token id="24" string="the" />
            <token id="25" string="1990" />
            <token id="26" string="census" />
          </tokens>
        </chunking>
        <chunking id="3" string="Northeast and Midwest members" type="NP">
          <tokens>
            <token id="7" string="Northeast" />
            <token id="8" string="and" />
            <token id="9" string="Midwest" />
            <token id="10" string="members" />
          </tokens>
        </chunking>
        <chunking id="4" string="told a breakfast briefing for Northeast and Midwest members of Congress that he estimates their region will lose 14 House seats following the 1990 census" type="VP">
          <tokens>
            <token id="2" string="told" />
            <token id="3" string="a" />
            <token id="4" string="breakfast" />
            <token id="5" string="briefing" />
            <token id="6" string="for" />
            <token id="7" string="Northeast" />
            <token id="8" string="and" />
            <token id="9" string="Midwest" />
            <token id="10" string="members" />
            <token id="11" string="of" />
            <token id="12" string="Congress" />
            <token id="13" string="that" />
            <token id="14" string="he" />
            <token id="15" string="estimates" />
            <token id="16" string="their" />
            <token id="17" string="region" />
            <token id="18" string="will" />
            <token id="19" string="lose" />
            <token id="20" string="14" />
            <token id="21" string="House" />
            <token id="22" string="seats" />
            <token id="23" string="following" />
            <token id="24" string="the" />
            <token id="25" string="1990" />
            <token id="26" string="census" />
          </tokens>
        </chunking>
        <chunking id="5" string="the 1990 census" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="1990" />
            <token id="26" string="census" />
          </tokens>
        </chunking>
        <chunking id="6" string="will lose 14 House seats following the 1990 census" type="VP">
          <tokens>
            <token id="18" string="will" />
            <token id="19" string="lose" />
            <token id="20" string="14" />
            <token id="21" string="House" />
            <token id="22" string="seats" />
            <token id="23" string="following" />
            <token id="24" string="the" />
            <token id="25" string="1990" />
            <token id="26" string="census" />
          </tokens>
        </chunking>
        <chunking id="7" string="Congress" type="NP">
          <tokens>
            <token id="12" string="Congress" />
          </tokens>
        </chunking>
        <chunking id="8" string="a breakfast briefing" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="breakfast" />
            <token id="5" string="briefing" />
          </tokens>
        </chunking>
        <chunking id="9" string="their region" type="NP">
          <tokens>
            <token id="16" string="their" />
            <token id="17" string="region" />
          </tokens>
        </chunking>
        <chunking id="10" string="estimates their region will lose 14 House seats following the 1990 census" type="VP">
          <tokens>
            <token id="15" string="estimates" />
            <token id="16" string="their" />
            <token id="17" string="region" />
            <token id="18" string="will" />
            <token id="19" string="lose" />
            <token id="20" string="14" />
            <token id="21" string="House" />
            <token id="22" string="seats" />
            <token id="23" string="following" />
            <token id="24" string="the" />
            <token id="25" string="1990" />
            <token id="26" string="census" />
          </tokens>
        </chunking>
        <chunking id="11" string="their region will lose 14 House seats following the 1990 census" type="SBAR">
          <tokens>
            <token id="16" string="their" />
            <token id="17" string="region" />
            <token id="18" string="will" />
            <token id="19" string="lose" />
            <token id="20" string="14" />
            <token id="21" string="House" />
            <token id="22" string="seats" />
            <token id="23" string="following" />
            <token id="24" string="the" />
            <token id="25" string="1990" />
            <token id="26" string="census" />
          </tokens>
        </chunking>
        <chunking id="12" string="O'Hare" type="NP">
          <tokens>
            <token id="1" string="O'Hare" />
          </tokens>
        </chunking>
        <chunking id="13" string="lose 14 House seats following the 1990 census" type="VP">
          <tokens>
            <token id="19" string="lose" />
            <token id="20" string="14" />
            <token id="21" string="House" />
            <token id="22" string="seats" />
            <token id="23" string="following" />
            <token id="24" string="the" />
            <token id="25" string="1990" />
            <token id="26" string="census" />
          </tokens>
        </chunking>
        <chunking id="14" string="he" type="NP">
          <tokens>
            <token id="14" string="he" />
          </tokens>
        </chunking>
        <chunking id="15" string="Northeast and Midwest members of Congress" type="NP">
          <tokens>
            <token id="7" string="Northeast" />
            <token id="8" string="and" />
            <token id="9" string="Midwest" />
            <token id="10" string="members" />
            <token id="11" string="of" />
            <token id="12" string="Congress" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">told</governor>
          <dependent id="1">O'Hare</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">told</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">briefing</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">briefing</governor>
          <dependent id="4">breakfast</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">told</governor>
          <dependent id="5">briefing</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">members</governor>
          <dependent id="6">for</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">members</governor>
          <dependent id="7">Northeast</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">Northeast</governor>
          <dependent id="8">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">Northeast</governor>
          <dependent id="9">Midwest</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">told</governor>
          <dependent id="10">members</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">Congress</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">members</governor>
          <dependent id="12">Congress</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">estimates</governor>
          <dependent id="13">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">estimates</governor>
          <dependent id="14">he</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">told</governor>
          <dependent id="15">estimates</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="17">region</governor>
          <dependent id="16">their</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">lose</governor>
          <dependent id="17">region</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="19">lose</governor>
          <dependent id="18">will</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="15">estimates</governor>
          <dependent id="19">lose</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="22">seats</governor>
          <dependent id="20">14</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">seats</governor>
          <dependent id="21">House</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">lose</governor>
          <dependent id="22">seats</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">census</governor>
          <dependent id="23">following</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">census</governor>
          <dependent id="24">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="26">census</governor>
          <dependent id="25">1990</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">lose</governor>
          <dependent id="26">census</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="14" type="NUMBER" score="0.0">
          <tokens>
            <token id="20" string="14" />
          </tokens>
        </entity>
        <entity id="2" string="O'Hare" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="O'Hare" />
          </tokens>
        </entity>
        <entity id="3" string="House" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="21" string="House" />
          </tokens>
        </entity>
        <entity id="4" string="1990" type="DATE" score="0.0">
          <tokens>
            <token id="25" string="1990" />
          </tokens>
        </entity>
        <entity id="5" string="Congress" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="12" string="Congress" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>That would continue a trend evident over the last several decades, he noted.</content>
      <tokens>
        <token id="1" string="That" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="continue" lemma="continue" stem="continu" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="trend" lemma="trend" stem="trend" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="evident" lemma="evident" stem="evid" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="over" lemma="over" stem="over" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="9" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="10" string="several" lemma="several" stem="sever" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="11" string="decades" lemma="decade" stem="decad" pos="NNS" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="noted" lemma="note" stem="note" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (DT That)) (VP (MD would) (VP (VB continue) (S (NP (DT a) (NN trend)) (ADJP (JJ evident) (PP (IN over) (NP (DT the) (JJ last) (JJ several) (NNS decades)))))))) (, ,) (NP (PRP he)) (VP (VBD noted)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="That" type="NP">
          <tokens>
            <token id="1" string="That" />
          </tokens>
        </chunking>
        <chunking id="2" string="a trend" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="trend" />
          </tokens>
        </chunking>
        <chunking id="3" string="noted" type="VP">
          <tokens>
            <token id="14" string="noted" />
          </tokens>
        </chunking>
        <chunking id="4" string="continue a trend evident over the last several decades" type="VP">
          <tokens>
            <token id="3" string="continue" />
            <token id="4" string="a" />
            <token id="5" string="trend" />
            <token id="6" string="evident" />
            <token id="7" string="over" />
            <token id="8" string="the" />
            <token id="9" string="last" />
            <token id="10" string="several" />
            <token id="11" string="decades" />
          </tokens>
        </chunking>
        <chunking id="5" string="the last several decades" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="last" />
            <token id="10" string="several" />
            <token id="11" string="decades" />
          </tokens>
        </chunking>
        <chunking id="6" string="he" type="NP">
          <tokens>
            <token id="13" string="he" />
          </tokens>
        </chunking>
        <chunking id="7" string="would continue a trend evident over the last several decades" type="VP">
          <tokens>
            <token id="2" string="would" />
            <token id="3" string="continue" />
            <token id="4" string="a" />
            <token id="5" string="trend" />
            <token id="6" string="evident" />
            <token id="7" string="over" />
            <token id="8" string="the" />
            <token id="9" string="last" />
            <token id="10" string="several" />
            <token id="11" string="decades" />
          </tokens>
        </chunking>
        <chunking id="8" string="evident over the last several decades" type="ADJP">
          <tokens>
            <token id="6" string="evident" />
            <token id="7" string="over" />
            <token id="8" string="the" />
            <token id="9" string="last" />
            <token id="10" string="several" />
            <token id="11" string="decades" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">continue</governor>
          <dependent id="1">That</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="3">continue</governor>
          <dependent id="2">would</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="14">noted</governor>
          <dependent id="3">continue</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">trend</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">evident</governor>
          <dependent id="5">trend</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">continue</governor>
          <dependent id="6">evident</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">decades</governor>
          <dependent id="7">over</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">decades</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">decades</governor>
          <dependent id="9">last</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">decades</governor>
          <dependent id="10">several</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">evident</governor>
          <dependent id="11">decades</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">noted</governor>
          <dependent id="13">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">noted</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="the last several decades" type="DATE" score="0.0">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="last" />
            <token id="10" string="several" />
            <token id="11" string="decades" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>Using estimates of the number of illegal aliens and undercounted minorities, he said that deleting the one group and adding in the other would make little difference in the long run.</content>
      <tokens>
        <token id="1" string="Using" lemma="use" stem="using" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="estimates" lemma="estimate" stem="estim" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="number" lemma="number" stem="number" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="illegal" lemma="illegal" stem="illeg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="aliens" lemma="alien" stem="alien" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="undercounted" lemma="undercount" stem="undercount" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="minorities" lemma="minority" stem="minor" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="deleting" lemma="delete" stem="delet" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="19" string="group" lemma="group" stem="group" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="adding" lemma="add" stem="ad" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="make" lemma="make" stem="make" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="little" lemma="little" stem="littl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="difference" lemma="difference" stem="differ" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="long" lemma="long" stem="long" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="run" lemma="run" stem="run" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (VP (VBG Using) (NP (NP (NNS estimates)) (PP (IN of) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (JJ illegal) (NNS aliens))))))) (CC and) (VP (VBD undercounted) (NP (NNS minorities))))) (, ,) (NP (PRP he)) (VP (VBD said) (SBAR (IN that) (S (S (VP (VP (VBG deleting) (NP (DT the) (CD one) (NN group))) (CC and) (VP (VBG adding) (PP (IN in) (NP (DT the) (JJ other)))))) (VP (MD would) (VP (VB make) (NP (JJ little) (NN difference)) (PP (IN in) (NP (DT the) (JJ long) (NN run)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="illegal aliens" type="NP">
          <tokens>
            <token id="7" string="illegal" />
            <token id="8" string="aliens" />
          </tokens>
        </chunking>
        <chunking id="2" string="Using estimates of the number of illegal aliens" type="VP">
          <tokens>
            <token id="1" string="Using" />
            <token id="2" string="estimates" />
            <token id="3" string="of" />
            <token id="4" string="the" />
            <token id="5" string="number" />
            <token id="6" string="of" />
            <token id="7" string="illegal" />
            <token id="8" string="aliens" />
          </tokens>
        </chunking>
        <chunking id="3" string="minorities" type="NP">
          <tokens>
            <token id="11" string="minorities" />
          </tokens>
        </chunking>
        <chunking id="4" string="the one group" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="one" />
            <token id="19" string="group" />
          </tokens>
        </chunking>
        <chunking id="5" string="deleting the one group" type="VP">
          <tokens>
            <token id="16" string="deleting" />
            <token id="17" string="the" />
            <token id="18" string="one" />
            <token id="19" string="group" />
          </tokens>
        </chunking>
        <chunking id="6" string="little difference" type="NP">
          <tokens>
            <token id="27" string="little" />
            <token id="28" string="difference" />
          </tokens>
        </chunking>
        <chunking id="7" string="the long run" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="long" />
            <token id="32" string="run" />
          </tokens>
        </chunking>
        <chunking id="8" string="would make little difference in the long run" type="VP">
          <tokens>
            <token id="25" string="would" />
            <token id="26" string="make" />
            <token id="27" string="little" />
            <token id="28" string="difference" />
            <token id="29" string="in" />
            <token id="30" string="the" />
            <token id="31" string="long" />
            <token id="32" string="run" />
          </tokens>
        </chunking>
        <chunking id="9" string="the number of illegal aliens" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="number" />
            <token id="6" string="of" />
            <token id="7" string="illegal" />
            <token id="8" string="aliens" />
          </tokens>
        </chunking>
        <chunking id="10" string="said that deleting the one group and adding in the other would make little difference in the long run" type="VP">
          <tokens>
            <token id="14" string="said" />
            <token id="15" string="that" />
            <token id="16" string="deleting" />
            <token id="17" string="the" />
            <token id="18" string="one" />
            <token id="19" string="group" />
            <token id="20" string="and" />
            <token id="21" string="adding" />
            <token id="22" string="in" />
            <token id="23" string="the" />
            <token id="24" string="other" />
            <token id="25" string="would" />
            <token id="26" string="make" />
            <token id="27" string="little" />
            <token id="28" string="difference" />
            <token id="29" string="in" />
            <token id="30" string="the" />
            <token id="31" string="long" />
            <token id="32" string="run" />
          </tokens>
        </chunking>
        <chunking id="11" string="that deleting the one group and adding in the other would make little difference in the long run" type="SBAR">
          <tokens>
            <token id="15" string="that" />
            <token id="16" string="deleting" />
            <token id="17" string="the" />
            <token id="18" string="one" />
            <token id="19" string="group" />
            <token id="20" string="and" />
            <token id="21" string="adding" />
            <token id="22" string="in" />
            <token id="23" string="the" />
            <token id="24" string="other" />
            <token id="25" string="would" />
            <token id="26" string="make" />
            <token id="27" string="little" />
            <token id="28" string="difference" />
            <token id="29" string="in" />
            <token id="30" string="the" />
            <token id="31" string="long" />
            <token id="32" string="run" />
          </tokens>
        </chunking>
        <chunking id="12" string="adding in the other" type="VP">
          <tokens>
            <token id="21" string="adding" />
            <token id="22" string="in" />
            <token id="23" string="the" />
            <token id="24" string="other" />
          </tokens>
        </chunking>
        <chunking id="13" string="make little difference in the long run" type="VP">
          <tokens>
            <token id="26" string="make" />
            <token id="27" string="little" />
            <token id="28" string="difference" />
            <token id="29" string="in" />
            <token id="30" string="the" />
            <token id="31" string="long" />
            <token id="32" string="run" />
          </tokens>
        </chunking>
        <chunking id="14" string="estimates of the number of illegal aliens" type="NP">
          <tokens>
            <token id="2" string="estimates" />
            <token id="3" string="of" />
            <token id="4" string="the" />
            <token id="5" string="number" />
            <token id="6" string="of" />
            <token id="7" string="illegal" />
            <token id="8" string="aliens" />
          </tokens>
        </chunking>
        <chunking id="15" string="deleting the one group and adding in the other" type="VP">
          <tokens>
            <token id="16" string="deleting" />
            <token id="17" string="the" />
            <token id="18" string="one" />
            <token id="19" string="group" />
            <token id="20" string="and" />
            <token id="21" string="adding" />
            <token id="22" string="in" />
            <token id="23" string="the" />
            <token id="24" string="other" />
          </tokens>
        </chunking>
        <chunking id="16" string="Using estimates of the number of illegal aliens and undercounted minorities" type="VP">
          <tokens>
            <token id="1" string="Using" />
            <token id="2" string="estimates" />
            <token id="3" string="of" />
            <token id="4" string="the" />
            <token id="5" string="number" />
            <token id="6" string="of" />
            <token id="7" string="illegal" />
            <token id="8" string="aliens" />
            <token id="9" string="and" />
            <token id="10" string="undercounted" />
            <token id="11" string="minorities" />
          </tokens>
        </chunking>
        <chunking id="17" string="undercounted minorities" type="VP">
          <tokens>
            <token id="10" string="undercounted" />
            <token id="11" string="minorities" />
          </tokens>
        </chunking>
        <chunking id="18" string="the number" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="number" />
          </tokens>
        </chunking>
        <chunking id="19" string="he" type="NP">
          <tokens>
            <token id="13" string="he" />
          </tokens>
        </chunking>
        <chunking id="20" string="estimates" type="NP">
          <tokens>
            <token id="2" string="estimates" />
          </tokens>
        </chunking>
        <chunking id="21" string="the other" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="other" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advcl">
          <governor id="14">said</governor>
          <dependent id="1">Using</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="1">Using</governor>
          <dependent id="2">estimates</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">number</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">number</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">estimates</governor>
          <dependent id="5">number</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">aliens</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">aliens</governor>
          <dependent id="7">illegal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">number</governor>
          <dependent id="8">aliens</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="1">Using</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="1">Using</governor>
          <dependent id="10">undercounted</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">undercounted</governor>
          <dependent id="11">minorities</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">said</governor>
          <dependent id="13">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">said</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="26">make</governor>
          <dependent id="15">that</dependent>
        </dependency>
        <dependency type="csubj">
          <governor id="26">make</governor>
          <dependent id="16">deleting</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">group</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="19">group</governor>
          <dependent id="18">one</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">deleting</governor>
          <dependent id="19">group</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="16">deleting</governor>
          <dependent id="20">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">deleting</governor>
          <dependent id="21">adding</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">other</governor>
          <dependent id="22">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">other</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">adding</governor>
          <dependent id="24">other</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="26">make</governor>
          <dependent id="25">would</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="14">said</governor>
          <dependent id="26">make</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">difference</governor>
          <dependent id="27">little</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="26">make</governor>
          <dependent id="28">difference</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">run</governor>
          <dependent id="29">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="32">run</governor>
          <dependent id="30">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="32">run</governor>
          <dependent id="31">long</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">make</governor>
          <dependent id="32">run</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="18" string="one" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>The only change, he said, would be that California would gain five new seats instead of six, while Georgia would add two rather than just one.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="only" lemma="only" stem="onli" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="change" lemma="change" stem="chang" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="California" lemma="California" stem="california" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="12" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="gain" lemma="gain" stem="gain" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="five" lemma="five" stem="five" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="15" string="new" lemma="new" stem="new" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="seats" lemma="seat" stem="seat" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="instead" lemma="instead" stem="instead" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="six" lemma="six" stem="six" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="while" lemma="while" stem="while" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="Georgia" lemma="Georgia" stem="georgia" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="23" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="add" lemma="add" stem="add" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="26" string="rather" lemma="rather" stem="rather" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="29" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (JJ only) (NN change)) (PRN (, ,) (S (NP (PRP he)) (VP (VBD said))) (, ,)) (VP (MD would) (VP (VB be) (SBAR (IN that) (S (NP (NNP California)) (VP (MD would) (VP (VB gain) (NP (NP (CD five) (JJ new) (NNS seats)) (PP (RB instead) (IN of) (NP (CD six)))) (, ,) (SBAR (IN while) (S (NP (NNP Georgia)) (VP (MD would) (VP (VB add) (NP (NP (CD two)) (CONJP (RB rather) (IN than)) (NP (RB just) (CD one))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="six" type="NP">
          <tokens>
            <token id="19" string="six" />
          </tokens>
        </chunking>
        <chunking id="2" string="would gain five new seats instead of six , while Georgia would add two rather than just one" type="VP">
          <tokens>
            <token id="12" string="would" />
            <token id="13" string="gain" />
            <token id="14" string="five" />
            <token id="15" string="new" />
            <token id="16" string="seats" />
            <token id="17" string="instead" />
            <token id="18" string="of" />
            <token id="19" string="six" />
            <token id="20" string="," />
            <token id="21" string="while" />
            <token id="22" string="Georgia" />
            <token id="23" string="would" />
            <token id="24" string="add" />
            <token id="25" string="two" />
            <token id="26" string="rather" />
            <token id="27" string="than" />
            <token id="28" string="just" />
            <token id="29" string="one" />
          </tokens>
        </chunking>
        <chunking id="3" string="California" type="NP">
          <tokens>
            <token id="11" string="California" />
          </tokens>
        </chunking>
        <chunking id="4" string="add two rather than just one" type="VP">
          <tokens>
            <token id="24" string="add" />
            <token id="25" string="two" />
            <token id="26" string="rather" />
            <token id="27" string="than" />
            <token id="28" string="just" />
            <token id="29" string="one" />
          </tokens>
        </chunking>
        <chunking id="5" string="would add two rather than just one" type="VP">
          <tokens>
            <token id="23" string="would" />
            <token id="24" string="add" />
            <token id="25" string="two" />
            <token id="26" string="rather" />
            <token id="27" string="than" />
            <token id="28" string="just" />
            <token id="29" string="one" />
          </tokens>
        </chunking>
        <chunking id="6" string="two" type="NP">
          <tokens>
            <token id="25" string="two" />
          </tokens>
        </chunking>
        <chunking id="7" string="that California would gain five new seats instead of six , while Georgia would add two rather than just one" type="SBAR">
          <tokens>
            <token id="10" string="that" />
            <token id="11" string="California" />
            <token id="12" string="would" />
            <token id="13" string="gain" />
            <token id="14" string="five" />
            <token id="15" string="new" />
            <token id="16" string="seats" />
            <token id="17" string="instead" />
            <token id="18" string="of" />
            <token id="19" string="six" />
            <token id="20" string="," />
            <token id="21" string="while" />
            <token id="22" string="Georgia" />
            <token id="23" string="would" />
            <token id="24" string="add" />
            <token id="25" string="two" />
            <token id="26" string="rather" />
            <token id="27" string="than" />
            <token id="28" string="just" />
            <token id="29" string="one" />
          </tokens>
        </chunking>
        <chunking id="8" string="gain five new seats instead of six , while Georgia would add two rather than just one" type="VP">
          <tokens>
            <token id="13" string="gain" />
            <token id="14" string="five" />
            <token id="15" string="new" />
            <token id="16" string="seats" />
            <token id="17" string="instead" />
            <token id="18" string="of" />
            <token id="19" string="six" />
            <token id="20" string="," />
            <token id="21" string="while" />
            <token id="22" string="Georgia" />
            <token id="23" string="would" />
            <token id="24" string="add" />
            <token id="25" string="two" />
            <token id="26" string="rather" />
            <token id="27" string="than" />
            <token id="28" string="just" />
            <token id="29" string="one" />
          </tokens>
        </chunking>
        <chunking id="9" string="while Georgia would add two rather than just one" type="SBAR">
          <tokens>
            <token id="21" string="while" />
            <token id="22" string="Georgia" />
            <token id="23" string="would" />
            <token id="24" string="add" />
            <token id="25" string="two" />
            <token id="26" string="rather" />
            <token id="27" string="than" />
            <token id="28" string="just" />
            <token id="29" string="one" />
          </tokens>
        </chunking>
        <chunking id="10" string="would be that California would gain five new seats instead of six , while Georgia would add two rather than just one" type="VP">
          <tokens>
            <token id="8" string="would" />
            <token id="9" string="be" />
            <token id="10" string="that" />
            <token id="11" string="California" />
            <token id="12" string="would" />
            <token id="13" string="gain" />
            <token id="14" string="five" />
            <token id="15" string="new" />
            <token id="16" string="seats" />
            <token id="17" string="instead" />
            <token id="18" string="of" />
            <token id="19" string="six" />
            <token id="20" string="," />
            <token id="21" string="while" />
            <token id="22" string="Georgia" />
            <token id="23" string="would" />
            <token id="24" string="add" />
            <token id="25" string="two" />
            <token id="26" string="rather" />
            <token id="27" string="than" />
            <token id="28" string="just" />
            <token id="29" string="one" />
          </tokens>
        </chunking>
        <chunking id="11" string="be that California would gain five new seats instead of six , while Georgia would add two rather than just one" type="VP">
          <tokens>
            <token id="9" string="be" />
            <token id="10" string="that" />
            <token id="11" string="California" />
            <token id="12" string="would" />
            <token id="13" string="gain" />
            <token id="14" string="five" />
            <token id="15" string="new" />
            <token id="16" string="seats" />
            <token id="17" string="instead" />
            <token id="18" string="of" />
            <token id="19" string="six" />
            <token id="20" string="," />
            <token id="21" string="while" />
            <token id="22" string="Georgia" />
            <token id="23" string="would" />
            <token id="24" string="add" />
            <token id="25" string="two" />
            <token id="26" string="rather" />
            <token id="27" string="than" />
            <token id="28" string="just" />
            <token id="29" string="one" />
          </tokens>
        </chunking>
        <chunking id="12" string="just one" type="NP">
          <tokens>
            <token id="28" string="just" />
            <token id="29" string="one" />
          </tokens>
        </chunking>
        <chunking id="13" string="The only change" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="only" />
            <token id="3" string="change" />
          </tokens>
        </chunking>
        <chunking id="14" string="five new seats" type="NP">
          <tokens>
            <token id="14" string="five" />
            <token id="15" string="new" />
            <token id="16" string="seats" />
          </tokens>
        </chunking>
        <chunking id="15" string="Georgia" type="NP">
          <tokens>
            <token id="22" string="Georgia" />
          </tokens>
        </chunking>
        <chunking id="16" string="he" type="NP">
          <tokens>
            <token id="5" string="he" />
          </tokens>
        </chunking>
        <chunking id="17" string="said" type="VP">
          <tokens>
            <token id="6" string="said" />
          </tokens>
        </chunking>
        <chunking id="18" string="two rather than just one" type="NP">
          <tokens>
            <token id="25" string="two" />
            <token id="26" string="rather" />
            <token id="27" string="than" />
            <token id="28" string="just" />
            <token id="29" string="one" />
          </tokens>
        </chunking>
        <chunking id="19" string="five new seats instead of six" type="NP">
          <tokens>
            <token id="14" string="five" />
            <token id="15" string="new" />
            <token id="16" string="seats" />
            <token id="17" string="instead" />
            <token id="18" string="of" />
            <token id="19" string="six" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">change</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">change</governor>
          <dependent id="2">only</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">be</governor>
          <dependent id="3">change</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">said</governor>
          <dependent id="5">he</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="9">be</governor>
          <dependent id="6">said</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">be</governor>
          <dependent id="8">would</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">be</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">gain</governor>
          <dependent id="10">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">gain</governor>
          <dependent id="11">California</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="13">gain</governor>
          <dependent id="12">would</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="9">be</governor>
          <dependent id="13">gain</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="16">seats</governor>
          <dependent id="14">five</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">seats</governor>
          <dependent id="15">new</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">gain</governor>
          <dependent id="16">seats</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">six</governor>
          <dependent id="17">instead</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="17">instead</governor>
          <dependent id="18">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">seats</governor>
          <dependent id="19">six</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="24">add</governor>
          <dependent id="21">while</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">add</governor>
          <dependent id="22">Georgia</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="24">add</governor>
          <dependent id="23">would</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="13">gain</governor>
          <dependent id="24">add</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="24">add</governor>
          <dependent id="25">two</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="25">two</governor>
          <dependent id="26">rather</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="26">rather</governor>
          <dependent id="27">than</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="29">one</governor>
          <dependent id="28">just</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="25">two</governor>
          <dependent id="29">one</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="six" type="NUMBER" score="0.0">
          <tokens>
            <token id="19" string="six" />
          </tokens>
        </entity>
        <entity id="2" string="California" type="LOCATION" score="0.0">
          <tokens>
            <token id="11" string="California" />
          </tokens>
        </entity>
        <entity id="3" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="29" string="one" />
          </tokens>
        </entity>
        <entity id="4" string="Georgia" type="LOCATION" score="0.0">
          <tokens>
            <token id="22" string="Georgia" />
          </tokens>
        </entity>
        <entity id="5" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="25" string="two" />
          </tokens>
        </entity>
        <entity id="6" string="five" type="NUMBER" score="0.0">
          <tokens>
            <token id="14" string="five" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>``That&amp;apost;s easy to understand, since there are so many undocumented aliens in California,&amp;apost;&amp;apost; he commented.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="That" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="easy" lemma="easy" stem="easi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="understand" lemma="understand" stem="understand" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="since" lemma="since" stem="sinc" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="so" lemma="so" stem="so" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="many" lemma="many" stem="mani" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="undocumented" lemma="undocumented" stem="undocu" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="aliens" lemma="alien" stem="alien" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="California" lemma="California" stem="california" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="commented" lemma="comment" stem="comment" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (DT That)) (VP (VBZ 's) (ADJP (JJ easy) (S (VP (TO to) (VP (VB understand))))) (, ,) (SBAR (IN since) (S (NP (EX there)) (VP (VBP are) (ADVP (RB so)) (NP (NP (JJ many) (JJ undocumented) (NNS aliens)) (PP (IN in) (NP (NNP California))))))))) (, ,) ('' '') (NP (PRP he)) (VP (VBD commented)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="That" type="NP">
          <tokens>
            <token id="2" string="That" />
          </tokens>
        </chunking>
        <chunking id="2" string="since there are so many undocumented aliens in California" type="SBAR">
          <tokens>
            <token id="8" string="since" />
            <token id="9" string="there" />
            <token id="10" string="are" />
            <token id="11" string="so" />
            <token id="12" string="many" />
            <token id="13" string="undocumented" />
            <token id="14" string="aliens" />
            <token id="15" string="in" />
            <token id="16" string="California" />
          </tokens>
        </chunking>
        <chunking id="3" string="many undocumented aliens in California" type="NP">
          <tokens>
            <token id="12" string="many" />
            <token id="13" string="undocumented" />
            <token id="14" string="aliens" />
            <token id="15" string="in" />
            <token id="16" string="California" />
          </tokens>
        </chunking>
        <chunking id="4" string="California" type="NP">
          <tokens>
            <token id="16" string="California" />
          </tokens>
        </chunking>
        <chunking id="5" string="are so many undocumented aliens in California" type="VP">
          <tokens>
            <token id="10" string="are" />
            <token id="11" string="so" />
            <token id="12" string="many" />
            <token id="13" string="undocumented" />
            <token id="14" string="aliens" />
            <token id="15" string="in" />
            <token id="16" string="California" />
          </tokens>
        </chunking>
        <chunking id="6" string="understand" type="VP">
          <tokens>
            <token id="6" string="understand" />
          </tokens>
        </chunking>
        <chunking id="7" string="to understand" type="VP">
          <tokens>
            <token id="5" string="to" />
            <token id="6" string="understand" />
          </tokens>
        </chunking>
        <chunking id="8" string="there" type="NP">
          <tokens>
            <token id="9" string="there" />
          </tokens>
        </chunking>
        <chunking id="9" string="many undocumented aliens" type="NP">
          <tokens>
            <token id="12" string="many" />
            <token id="13" string="undocumented" />
            <token id="14" string="aliens" />
          </tokens>
        </chunking>
        <chunking id="10" string="easy to understand" type="ADJP">
          <tokens>
            <token id="4" string="easy" />
            <token id="5" string="to" />
            <token id="6" string="understand" />
          </tokens>
        </chunking>
        <chunking id="11" string="he" type="NP">
          <tokens>
            <token id="19" string="he" />
          </tokens>
        </chunking>
        <chunking id="12" string="'s easy to understand , since there are so many undocumented aliens in California" type="VP">
          <tokens>
            <token id="3" string="'s" />
            <token id="4" string="easy" />
            <token id="5" string="to" />
            <token id="6" string="understand" />
            <token id="7" string="," />
            <token id="8" string="since" />
            <token id="9" string="there" />
            <token id="10" string="are" />
            <token id="11" string="so" />
            <token id="12" string="many" />
            <token id="13" string="undocumented" />
            <token id="14" string="aliens" />
            <token id="15" string="in" />
            <token id="16" string="California" />
          </tokens>
        </chunking>
        <chunking id="13" string="commented" type="VP">
          <tokens>
            <token id="20" string="commented" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">easy</governor>
          <dependent id="2">That</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">easy</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="20">commented</governor>
          <dependent id="4">easy</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">understand</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">easy</governor>
          <dependent id="6">understand</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">are</governor>
          <dependent id="8">since</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="10">are</governor>
          <dependent id="9">there</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">easy</governor>
          <dependent id="10">are</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">are</governor>
          <dependent id="11">so</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">aliens</governor>
          <dependent id="12">many</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">aliens</governor>
          <dependent id="13">undocumented</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">are</governor>
          <dependent id="14">aliens</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">California</governor>
          <dependent id="15">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">aliens</governor>
          <dependent id="16">California</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">commented</governor>
          <dependent id="19">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="20">commented</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="California" type="LOCATION" score="0.0">
          <tokens>
            <token id="16" string="California" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>O&amp;apost;Hare&amp;apost;s study of potential changes in House seats _ based on 1990 projections with no adjustments _ calls for California to be the big gainer, adding six House seats, followed by Florida with a gain of four and Texas adding three.</content>
      <tokens>
        <token id="1" string="O'Hare" lemma="O'Hare" stem="o'hare" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="2" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="study" lemma="study" stem="studi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="potential" lemma="potential" stem="potenti" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="changes" lemma="change" stem="chang" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="House" lemma="House" stem="hous" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="9" string="seats" lemma="seat" stem="seat" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="_" lemma="_" stem="_" pos="VBP" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="based" lemma="base" stem="base" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="1990" lemma="1990" stem="1990" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="14" string="projections" lemma="projection" stem="project" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="adjustments" lemma="adjustment" stem="adjust" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="_" lemma="_" stem="_" pos="VBP" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="calls" lemma="call" stem="call" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="California" lemma="California" stem="california" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="22" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="big" lemma="big" stem="big" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="gainer" lemma="gainer" stem="gainer" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="adding" lemma="add" stem="ad" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="six" lemma="six" stem="six" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="30" string="House" lemma="House" stem="hous" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="31" string="seats" lemma="seat" stem="seat" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="followed" lemma="follow" stem="follow" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="Florida" lemma="Florida" stem="florida" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="36" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="gain" lemma="gain" stem="gain" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="four" lemma="four" stem="four" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="41" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="Texas" lemma="Texas" stem="texa" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="43" string="adding" lemma="add" stem="ad" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="44" string="three" lemma="three" stem="three" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="45" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NP (NNP O'Hare) (POS 's)) (NN study)) (PP (IN of) (NP (NP (JJ potential) (NNS changes)) (PP (IN in) (NP (NNP House) (NNS seats)))))) (VP (VBP _) (PP (VBN based) (PP (IN on) (NP (NP (CD 1990) (NNS projections)) (SBAR (S (S (SBAR (IN with) (S (NP (DT no) (NNS adjustments)) (VP (VBP _) (S (NP (NP (NNS calls)) (PP (IN for) (NP (NNP California)))) (VP (TO to) (VP (VB be) (NP (DT the) (JJ big) (NN gainer)))))))) (, ,) (S (VP (VBG adding) (NP (CD six) (NNP House) (NNS seats)))) (, ,) (VP (VBN followed) (PP (IN by) (NP (NNP Florida))) (PP (IN with) (NP (NP (DT a) (NN gain)) (PP (IN of) (NP (CD four))))))) (CC and) (S (NP (NNP Texas)) (VP (VBG adding) (NP (CD three)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="O'Hare 's" type="NP">
          <tokens>
            <token id="1" string="O'Hare" />
            <token id="2" string="'s" />
          </tokens>
        </chunking>
        <chunking id="2" string="House seats" type="NP">
          <tokens>
            <token id="8" string="House" />
            <token id="9" string="seats" />
          </tokens>
        </chunking>
        <chunking id="3" string="California" type="NP">
          <tokens>
            <token id="21" string="California" />
          </tokens>
        </chunking>
        <chunking id="4" string="a gain" type="NP">
          <tokens>
            <token id="37" string="a" />
            <token id="38" string="gain" />
          </tokens>
        </chunking>
        <chunking id="5" string="with no adjustments _ calls for California to be the big gainer , adding six House seats , followed by Florida with a gain of four and Texas adding three" type="SBAR">
          <tokens>
            <token id="15" string="with" />
            <token id="16" string="no" />
            <token id="17" string="adjustments" />
            <token id="18" string="_" />
            <token id="19" string="calls" />
            <token id="20" string="for" />
            <token id="21" string="California" />
            <token id="22" string="to" />
            <token id="23" string="be" />
            <token id="24" string="the" />
            <token id="25" string="big" />
            <token id="26" string="gainer" />
            <token id="27" string="," />
            <token id="28" string="adding" />
            <token id="29" string="six" />
            <token id="30" string="House" />
            <token id="31" string="seats" />
            <token id="32" string="," />
            <token id="33" string="followed" />
            <token id="34" string="by" />
            <token id="35" string="Florida" />
            <token id="36" string="with" />
            <token id="37" string="a" />
            <token id="38" string="gain" />
            <token id="39" string="of" />
            <token id="40" string="four" />
            <token id="41" string="and" />
            <token id="42" string="Texas" />
            <token id="43" string="adding" />
            <token id="44" string="three" />
          </tokens>
        </chunking>
        <chunking id="6" string="adding three" type="VP">
          <tokens>
            <token id="43" string="adding" />
            <token id="44" string="three" />
          </tokens>
        </chunking>
        <chunking id="7" string="O'Hare 's study of potential changes in House seats" type="NP">
          <tokens>
            <token id="1" string="O'Hare" />
            <token id="2" string="'s" />
            <token id="3" string="study" />
            <token id="4" string="of" />
            <token id="5" string="potential" />
            <token id="6" string="changes" />
            <token id="7" string="in" />
            <token id="8" string="House" />
            <token id="9" string="seats" />
          </tokens>
        </chunking>
        <chunking id="8" string="Florida" type="NP">
          <tokens>
            <token id="35" string="Florida" />
          </tokens>
        </chunking>
        <chunking id="9" string="no adjustments" type="NP">
          <tokens>
            <token id="16" string="no" />
            <token id="17" string="adjustments" />
          </tokens>
        </chunking>
        <chunking id="10" string="followed by Florida with a gain of four" type="VP">
          <tokens>
            <token id="33" string="followed" />
            <token id="34" string="by" />
            <token id="35" string="Florida" />
            <token id="36" string="with" />
            <token id="37" string="a" />
            <token id="38" string="gain" />
            <token id="39" string="of" />
            <token id="40" string="four" />
          </tokens>
        </chunking>
        <chunking id="11" string="calls" type="NP">
          <tokens>
            <token id="19" string="calls" />
          </tokens>
        </chunking>
        <chunking id="12" string="Texas" type="NP">
          <tokens>
            <token id="42" string="Texas" />
          </tokens>
        </chunking>
        <chunking id="13" string="potential changes" type="NP">
          <tokens>
            <token id="5" string="potential" />
            <token id="6" string="changes" />
          </tokens>
        </chunking>
        <chunking id="14" string="_ based on 1990 projections with no adjustments _ calls for California to be the big gainer , adding six House seats , followed by Florida with a gain of four and Texas adding three" type="VP">
          <tokens>
            <token id="10" string="_" />
            <token id="11" string="based" />
            <token id="12" string="on" />
            <token id="13" string="1990" />
            <token id="14" string="projections" />
            <token id="15" string="with" />
            <token id="16" string="no" />
            <token id="17" string="adjustments" />
            <token id="18" string="_" />
            <token id="19" string="calls" />
            <token id="20" string="for" />
            <token id="21" string="California" />
            <token id="22" string="to" />
            <token id="23" string="be" />
            <token id="24" string="the" />
            <token id="25" string="big" />
            <token id="26" string="gainer" />
            <token id="27" string="," />
            <token id="28" string="adding" />
            <token id="29" string="six" />
            <token id="30" string="House" />
            <token id="31" string="seats" />
            <token id="32" string="," />
            <token id="33" string="followed" />
            <token id="34" string="by" />
            <token id="35" string="Florida" />
            <token id="36" string="with" />
            <token id="37" string="a" />
            <token id="38" string="gain" />
            <token id="39" string="of" />
            <token id="40" string="four" />
            <token id="41" string="and" />
            <token id="42" string="Texas" />
            <token id="43" string="adding" />
            <token id="44" string="three" />
          </tokens>
        </chunking>
        <chunking id="15" string="with no adjustments _ calls for California to be the big gainer" type="SBAR">
          <tokens>
            <token id="15" string="with" />
            <token id="16" string="no" />
            <token id="17" string="adjustments" />
            <token id="18" string="_" />
            <token id="19" string="calls" />
            <token id="20" string="for" />
            <token id="21" string="California" />
            <token id="22" string="to" />
            <token id="23" string="be" />
            <token id="24" string="the" />
            <token id="25" string="big" />
            <token id="26" string="gainer" />
          </tokens>
        </chunking>
        <chunking id="16" string="_ calls for California to be the big gainer" type="VP">
          <tokens>
            <token id="18" string="_" />
            <token id="19" string="calls" />
            <token id="20" string="for" />
            <token id="21" string="California" />
            <token id="22" string="to" />
            <token id="23" string="be" />
            <token id="24" string="the" />
            <token id="25" string="big" />
            <token id="26" string="gainer" />
          </tokens>
        </chunking>
        <chunking id="17" string="to be the big gainer" type="VP">
          <tokens>
            <token id="22" string="to" />
            <token id="23" string="be" />
            <token id="24" string="the" />
            <token id="25" string="big" />
            <token id="26" string="gainer" />
          </tokens>
        </chunking>
        <chunking id="18" string="a gain of four" type="NP">
          <tokens>
            <token id="37" string="a" />
            <token id="38" string="gain" />
            <token id="39" string="of" />
            <token id="40" string="four" />
          </tokens>
        </chunking>
        <chunking id="19" string="potential changes in House seats" type="NP">
          <tokens>
            <token id="5" string="potential" />
            <token id="6" string="changes" />
            <token id="7" string="in" />
            <token id="8" string="House" />
            <token id="9" string="seats" />
          </tokens>
        </chunking>
        <chunking id="20" string="1990 projections with no adjustments _ calls for California to be the big gainer , adding six House seats , followed by Florida with a gain of four and Texas adding three" type="NP">
          <tokens>
            <token id="13" string="1990" />
            <token id="14" string="projections" />
            <token id="15" string="with" />
            <token id="16" string="no" />
            <token id="17" string="adjustments" />
            <token id="18" string="_" />
            <token id="19" string="calls" />
            <token id="20" string="for" />
            <token id="21" string="California" />
            <token id="22" string="to" />
            <token id="23" string="be" />
            <token id="24" string="the" />
            <token id="25" string="big" />
            <token id="26" string="gainer" />
            <token id="27" string="," />
            <token id="28" string="adding" />
            <token id="29" string="six" />
            <token id="30" string="House" />
            <token id="31" string="seats" />
            <token id="32" string="," />
            <token id="33" string="followed" />
            <token id="34" string="by" />
            <token id="35" string="Florida" />
            <token id="36" string="with" />
            <token id="37" string="a" />
            <token id="38" string="gain" />
            <token id="39" string="of" />
            <token id="40" string="four" />
            <token id="41" string="and" />
            <token id="42" string="Texas" />
            <token id="43" string="adding" />
            <token id="44" string="three" />
          </tokens>
        </chunking>
        <chunking id="21" string="adding six House seats" type="VP">
          <tokens>
            <token id="28" string="adding" />
            <token id="29" string="six" />
            <token id="30" string="House" />
            <token id="31" string="seats" />
          </tokens>
        </chunking>
        <chunking id="22" string="three" type="NP">
          <tokens>
            <token id="44" string="three" />
          </tokens>
        </chunking>
        <chunking id="23" string="1990 projections" type="NP">
          <tokens>
            <token id="13" string="1990" />
            <token id="14" string="projections" />
          </tokens>
        </chunking>
        <chunking id="24" string="be the big gainer" type="VP">
          <tokens>
            <token id="23" string="be" />
            <token id="24" string="the" />
            <token id="25" string="big" />
            <token id="26" string="gainer" />
          </tokens>
        </chunking>
        <chunking id="25" string="four" type="NP">
          <tokens>
            <token id="40" string="four" />
          </tokens>
        </chunking>
        <chunking id="26" string="O'Hare 's study" type="NP">
          <tokens>
            <token id="1" string="O'Hare" />
            <token id="2" string="'s" />
            <token id="3" string="study" />
          </tokens>
        </chunking>
        <chunking id="27" string="calls for California" type="NP">
          <tokens>
            <token id="19" string="calls" />
            <token id="20" string="for" />
            <token id="21" string="California" />
          </tokens>
        </chunking>
        <chunking id="28" string="the big gainer" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="big" />
            <token id="26" string="gainer" />
          </tokens>
        </chunking>
        <chunking id="29" string="six House seats" type="NP">
          <tokens>
            <token id="29" string="six" />
            <token id="30" string="House" />
            <token id="31" string="seats" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="3">study</governor>
          <dependent id="1">O'Hare</dependent>
        </dependency>
        <dependency type="case">
          <governor id="1">O'Hare</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">_</governor>
          <dependent id="3">study</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">changes</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">changes</governor>
          <dependent id="5">potential</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">study</governor>
          <dependent id="6">changes</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">seats</governor>
          <dependent id="7">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">seats</governor>
          <dependent id="8">House</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">changes</governor>
          <dependent id="9">seats</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">_</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">projections</governor>
          <dependent id="11">based</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="11">based</governor>
          <dependent id="12">on</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="14">projections</governor>
          <dependent id="13">1990</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="10">_</governor>
          <dependent id="14">projections</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">_</governor>
          <dependent id="15">with</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="17">adjustments</governor>
          <dependent id="16">no</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">_</governor>
          <dependent id="17">adjustments</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="33">followed</governor>
          <dependent id="18">_</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">_</governor>
          <dependent id="19">calls</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">California</governor>
          <dependent id="20">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">calls</governor>
          <dependent id="21">California</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="26">gainer</governor>
          <dependent id="22">to</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="26">gainer</governor>
          <dependent id="23">be</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">gainer</governor>
          <dependent id="24">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">gainer</governor>
          <dependent id="25">big</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="18">_</governor>
          <dependent id="26">gainer</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="33">followed</governor>
          <dependent id="28">adding</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="31">seats</governor>
          <dependent id="29">six</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">seats</governor>
          <dependent id="30">House</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="28">adding</governor>
          <dependent id="31">seats</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="14">projections</governor>
          <dependent id="33">followed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">Florida</governor>
          <dependent id="34">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="33">followed</governor>
          <dependent id="35">Florida</dependent>
        </dependency>
        <dependency type="case">
          <governor id="38">gain</governor>
          <dependent id="36">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="38">gain</governor>
          <dependent id="37">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="33">followed</governor>
          <dependent id="38">gain</dependent>
        </dependency>
        <dependency type="case">
          <governor id="40">four</governor>
          <dependent id="39">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="38">gain</governor>
          <dependent id="40">four</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="33">followed</governor>
          <dependent id="41">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="43">adding</governor>
          <dependent id="42">Texas</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="33">followed</governor>
          <dependent id="43">adding</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="43">adding</governor>
          <dependent id="44">three</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="six" type="NUMBER" score="0.0">
          <tokens>
            <token id="29" string="six" />
          </tokens>
        </entity>
        <entity id="2" string="California" type="LOCATION" score="0.0">
          <tokens>
            <token id="21" string="California" />
          </tokens>
        </entity>
        <entity id="3" string="O'Hare" type="LOCATION" score="0.0">
          <tokens>
            <token id="1" string="O'Hare" />
          </tokens>
        </entity>
        <entity id="4" string="House" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="8" string="House" />
          </tokens>
        </entity>
        <entity id="5" string="four" type="NUMBER" score="0.0">
          <tokens>
            <token id="40" string="four" />
          </tokens>
        </entity>
        <entity id="6" string="Texas" type="LOCATION" score="0.0">
          <tokens>
            <token id="42" string="Texas" />
          </tokens>
        </entity>
        <entity id="7" string="1990" type="DATE" score="0.0">
          <tokens>
            <token id="13" string="1990" />
          </tokens>
        </entity>
        <entity id="8" string="Florida" type="LOCATION" score="0.0">
          <tokens>
            <token id="35" string="Florida" />
          </tokens>
        </entity>
        <entity id="9" string="three" type="NUMBER" score="0.0">
          <tokens>
            <token id="44" string="three" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="14" has_coreference="false">
      <content>Expected to pick up one seat each are Virginia, North Carolina, Georgia, and Arizona.</content>
      <tokens>
        <token id="1" string="Expected" lemma="expect" stem="expect" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="pick" lemma="pick" stem="pick" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="6" string="seat" lemma="seat" stem="seat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="each" lemma="each" stem="each" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Virginia" lemma="Virginia" stem="virginia" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="North" lemma="North" stem="north" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="12" string="Carolina" lemma="Carolina" stem="carolina" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Georgia" lemma="Georgia" stem="georgia" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Arizona" lemma="Arizona" stem="arizona" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (VP (VBN Expected) (S (VP (TO to) (VP (VB pick) (PRT (RP up)) (NP (NP (CD one) (NN seat)) (NP (DT each))))))) (VP (VBP are)) (NP (NP (NNP Virginia)) (, ,) (NP (NP (NNP North) (NNP Carolina)) (, ,) (NP (NNP Georgia)) (, ,) (CC and) (NP (NNP Arizona)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Virginia , North Carolina , Georgia , and Arizona" type="NP">
          <tokens>
            <token id="9" string="Virginia" />
            <token id="10" string="," />
            <token id="11" string="North" />
            <token id="12" string="Carolina" />
            <token id="13" string="," />
            <token id="14" string="Georgia" />
            <token id="15" string="," />
            <token id="16" string="and" />
            <token id="17" string="Arizona" />
          </tokens>
        </chunking>
        <chunking id="2" string="Arizona" type="NP">
          <tokens>
            <token id="17" string="Arizona" />
          </tokens>
        </chunking>
        <chunking id="3" string="one seat each" type="NP">
          <tokens>
            <token id="5" string="one" />
            <token id="6" string="seat" />
            <token id="7" string="each" />
          </tokens>
        </chunking>
        <chunking id="4" string="North Carolina" type="NP">
          <tokens>
            <token id="11" string="North" />
            <token id="12" string="Carolina" />
          </tokens>
        </chunking>
        <chunking id="5" string="Expected to pick up one seat each" type="VP">
          <tokens>
            <token id="1" string="Expected" />
            <token id="2" string="to" />
            <token id="3" string="pick" />
            <token id="4" string="up" />
            <token id="5" string="one" />
            <token id="6" string="seat" />
            <token id="7" string="each" />
          </tokens>
        </chunking>
        <chunking id="6" string="to pick up one seat each" type="VP">
          <tokens>
            <token id="2" string="to" />
            <token id="3" string="pick" />
            <token id="4" string="up" />
            <token id="5" string="one" />
            <token id="6" string="seat" />
            <token id="7" string="each" />
          </tokens>
        </chunking>
        <chunking id="7" string="each" type="NP">
          <tokens>
            <token id="7" string="each" />
          </tokens>
        </chunking>
        <chunking id="8" string="pick up one seat each" type="VP">
          <tokens>
            <token id="3" string="pick" />
            <token id="4" string="up" />
            <token id="5" string="one" />
            <token id="6" string="seat" />
            <token id="7" string="each" />
          </tokens>
        </chunking>
        <chunking id="9" string="are" type="VP">
          <tokens>
            <token id="8" string="are" />
          </tokens>
        </chunking>
        <chunking id="10" string="Georgia" type="NP">
          <tokens>
            <token id="14" string="Georgia" />
          </tokens>
        </chunking>
        <chunking id="11" string="one seat" type="NP">
          <tokens>
            <token id="5" string="one" />
            <token id="6" string="seat" />
          </tokens>
        </chunking>
        <chunking id="12" string="Virginia" type="NP">
          <tokens>
            <token id="9" string="Virginia" />
          </tokens>
        </chunking>
        <chunking id="13" string="North Carolina , Georgia , and Arizona" type="NP">
          <tokens>
            <token id="11" string="North" />
            <token id="12" string="Carolina" />
            <token id="13" string="," />
            <token id="14" string="Georgia" />
            <token id="15" string="," />
            <token id="16" string="and" />
            <token id="17" string="Arizona" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="1">Expected</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="3">pick</governor>
          <dependent id="2">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="1">Expected</governor>
          <dependent id="3">pick</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="3">pick</governor>
          <dependent id="4">up</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="6">seat</governor>
          <dependent id="5">one</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">pick</governor>
          <dependent id="6">seat</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="6">seat</governor>
          <dependent id="7">each</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="1">Expected</governor>
          <dependent id="8">are</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="1">Expected</governor>
          <dependent id="9">Virginia</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Carolina</governor>
          <dependent id="11">North</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="9">Virginia</governor>
          <dependent id="12">Carolina</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">Carolina</governor>
          <dependent id="14">Georgia</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="12">Carolina</governor>
          <dependent id="16">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">Carolina</governor>
          <dependent id="17">Arizona</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Arizona" type="LOCATION" score="0.0">
          <tokens>
            <token id="17" string="Arizona" />
          </tokens>
        </entity>
        <entity id="2" string="North Carolina" type="LOCATION" score="0.0">
          <tokens>
            <token id="11" string="North" />
            <token id="12" string="Carolina" />
          </tokens>
        </entity>
        <entity id="3" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="5" string="one" />
          </tokens>
        </entity>
        <entity id="4" string="Georgia" type="LOCATION" score="0.0">
          <tokens>
            <token id="14" string="Georgia" />
          </tokens>
        </entity>
        <entity id="5" string="Virginia" type="LOCATION" score="0.0">
          <tokens>
            <token id="9" string="Virginia" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="15" has_coreference="false">
      <content>On the other hand New York would lose three seats.</content>
      <tokens>
        <token id="1" string="On" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="hand" lemma="hand" stem="hand" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="New" lemma="New" stem="new" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="6" string="York" lemma="York" stem="york" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="7" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="lose" lemma="lose" stem="lose" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="three" lemma="three" stem="three" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="10" string="seats" lemma="seat" stem="seat" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN On) (NP (DT the) (JJ other) (NN hand))) (NP (NNP New) (NNP York)) (VP (MD would) (VP (VB lose) (NP (CD three) (NNS seats)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="New York" type="NP">
          <tokens>
            <token id="5" string="New" />
            <token id="6" string="York" />
          </tokens>
        </chunking>
        <chunking id="2" string="three seats" type="NP">
          <tokens>
            <token id="9" string="three" />
            <token id="10" string="seats" />
          </tokens>
        </chunking>
        <chunking id="3" string="the other hand" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="other" />
            <token id="4" string="hand" />
          </tokens>
        </chunking>
        <chunking id="4" string="would lose three seats" type="VP">
          <tokens>
            <token id="7" string="would" />
            <token id="8" string="lose" />
            <token id="9" string="three" />
            <token id="10" string="seats" />
          </tokens>
        </chunking>
        <chunking id="5" string="lose three seats" type="VP">
          <tokens>
            <token id="8" string="lose" />
            <token id="9" string="three" />
            <token id="10" string="seats" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">hand</governor>
          <dependent id="1">On</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">hand</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">hand</governor>
          <dependent id="3">other</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">lose</governor>
          <dependent id="4">hand</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">York</governor>
          <dependent id="5">New</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">lose</governor>
          <dependent id="6">York</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">lose</governor>
          <dependent id="7">would</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">lose</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="10">seats</governor>
          <dependent id="9">three</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">lose</governor>
          <dependent id="10">seats</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="New York" type="LOCATION" score="0.0">
          <tokens>
            <token id="5" string="New" />
            <token id="6" string="York" />
          </tokens>
        </entity>
        <entity id="2" string="three" type="NUMBER" score="0.0">
          <tokens>
            <token id="9" string="three" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="16" has_coreference="false">
      <content>States losing two apiece would be Pennsylvania, Ohio, Illinois and Michigan.</content>
      <tokens>
        <token id="1" string="States" lemma="States" stem="state" pos="NNPS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="losing" lemma="lose" stem="lose" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="4" string="apiece" lemma="apiece" stem="apiec" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Pennsylvania" lemma="Pennsylvania" stem="pennsylvania" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Ohio" lemma="Ohio" stem="ohio" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Illinois" lemma="Illinois" stem="illinoi" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="12" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Michigan" lemma="Michigan" stem="michigan" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNPS States)) (VP (VBG losing) (NP (CD two)))) (ADVP (RB apiece)) (VP (MD would) (VP (VB be) (NP (NNP Pennsylvania) (, ,) (NNP Ohio) (, ,) (NNP Illinois) (CC and) (NNP Michigan)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Pennsylvania , Ohio , Illinois and Michigan" type="NP">
          <tokens>
            <token id="7" string="Pennsylvania" />
            <token id="8" string="," />
            <token id="9" string="Ohio" />
            <token id="10" string="," />
            <token id="11" string="Illinois" />
            <token id="12" string="and" />
            <token id="13" string="Michigan" />
          </tokens>
        </chunking>
        <chunking id="2" string="States" type="NP">
          <tokens>
            <token id="1" string="States" />
          </tokens>
        </chunking>
        <chunking id="3" string="losing two" type="VP">
          <tokens>
            <token id="2" string="losing" />
            <token id="3" string="two" />
          </tokens>
        </chunking>
        <chunking id="4" string="would be Pennsylvania , Ohio , Illinois and Michigan" type="VP">
          <tokens>
            <token id="5" string="would" />
            <token id="6" string="be" />
            <token id="7" string="Pennsylvania" />
            <token id="8" string="," />
            <token id="9" string="Ohio" />
            <token id="10" string="," />
            <token id="11" string="Illinois" />
            <token id="12" string="and" />
            <token id="13" string="Michigan" />
          </tokens>
        </chunking>
        <chunking id="5" string="States losing two" type="NP">
          <tokens>
            <token id="1" string="States" />
            <token id="2" string="losing" />
            <token id="3" string="two" />
          </tokens>
        </chunking>
        <chunking id="6" string="two" type="NP">
          <tokens>
            <token id="3" string="two" />
          </tokens>
        </chunking>
        <chunking id="7" string="be Pennsylvania , Ohio , Illinois and Michigan" type="VP">
          <tokens>
            <token id="6" string="be" />
            <token id="7" string="Pennsylvania" />
            <token id="8" string="," />
            <token id="9" string="Ohio" />
            <token id="10" string="," />
            <token id="11" string="Illinois" />
            <token id="12" string="and" />
            <token id="13" string="Michigan" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="7">Pennsylvania</governor>
          <dependent id="1">States</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="1">States</governor>
          <dependent id="2">losing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">losing</governor>
          <dependent id="3">two</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">Pennsylvania</governor>
          <dependent id="4">apiece</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">Pennsylvania</governor>
          <dependent id="5">would</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">Pennsylvania</governor>
          <dependent id="6">be</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">Pennsylvania</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">Pennsylvania</governor>
          <dependent id="9">Ohio</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">Pennsylvania</governor>
          <dependent id="11">Illinois</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">Pennsylvania</governor>
          <dependent id="12">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">Pennsylvania</governor>
          <dependent id="13">Michigan</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Illinois" type="LOCATION" score="0.0">
          <tokens>
            <token id="11" string="Illinois" />
          </tokens>
        </entity>
        <entity id="2" string="Michigan" type="LOCATION" score="0.0">
          <tokens>
            <token id="13" string="Michigan" />
          </tokens>
        </entity>
        <entity id="3" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="3" string="two" />
          </tokens>
        </entity>
        <entity id="4" string="Ohio" type="LOCATION" score="0.0">
          <tokens>
            <token id="9" string="Ohio" />
          </tokens>
        </entity>
        <entity id="5" string="Pennsylvania" type="LOCATION" score="0.0">
          <tokens>
            <token id="7" string="Pennsylvania" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="17" has_coreference="false">
      <content>Expected to lose one house seat are Massachusetts, Wisconsin, Iowa, Kansas, West Virginia and Montana.</content>
      <tokens>
        <token id="1" string="Expected" lemma="expect" stem="expect" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="lose" lemma="lose" stem="lose" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="5" string="house" lemma="house" stem="hous" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="seat" lemma="seat" stem="seat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Massachusetts" lemma="Massachusetts" stem="massachusett" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Wisconsin" lemma="Wisconsin" stem="wisconsin" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Iowa" lemma="Iowa" stem="iowa" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Kansas" lemma="Kansas" stem="kansa" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="West" lemma="West" stem="west" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="17" string="Virginia" lemma="Virginia" stem="virginia" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="18" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="Montana" lemma="Montana" stem="montana" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (VP (VBN Expected) (S (VP (TO to) (VP (VB lose) (NP (CD one) (NN house) (NN seat)))))) (VP (VBP are)) (NP (NP (NNP Massachusetts)) (, ,) (NP (NNP Wisconsin) (, ,) (NNP Iowa) (, ,) (NNP Kansas) (, ,) (NNP West) (NNP Virginia) (CC and) (NNP Montana))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="lose one house seat" type="VP">
          <tokens>
            <token id="3" string="lose" />
            <token id="4" string="one" />
            <token id="5" string="house" />
            <token id="6" string="seat" />
          </tokens>
        </chunking>
        <chunking id="2" string="one house seat" type="NP">
          <tokens>
            <token id="4" string="one" />
            <token id="5" string="house" />
            <token id="6" string="seat" />
          </tokens>
        </chunking>
        <chunking id="3" string="Massachusetts , Wisconsin , Iowa , Kansas , West Virginia and Montana" type="NP">
          <tokens>
            <token id="8" string="Massachusetts" />
            <token id="9" string="," />
            <token id="10" string="Wisconsin" />
            <token id="11" string="," />
            <token id="12" string="Iowa" />
            <token id="13" string="," />
            <token id="14" string="Kansas" />
            <token id="15" string="," />
            <token id="16" string="West" />
            <token id="17" string="Virginia" />
            <token id="18" string="and" />
            <token id="19" string="Montana" />
          </tokens>
        </chunking>
        <chunking id="4" string="are" type="VP">
          <tokens>
            <token id="7" string="are" />
          </tokens>
        </chunking>
        <chunking id="5" string="Expected to lose one house seat" type="VP">
          <tokens>
            <token id="1" string="Expected" />
            <token id="2" string="to" />
            <token id="3" string="lose" />
            <token id="4" string="one" />
            <token id="5" string="house" />
            <token id="6" string="seat" />
          </tokens>
        </chunking>
        <chunking id="6" string="Massachusetts" type="NP">
          <tokens>
            <token id="8" string="Massachusetts" />
          </tokens>
        </chunking>
        <chunking id="7" string="to lose one house seat" type="VP">
          <tokens>
            <token id="2" string="to" />
            <token id="3" string="lose" />
            <token id="4" string="one" />
            <token id="5" string="house" />
            <token id="6" string="seat" />
          </tokens>
        </chunking>
        <chunking id="8" string="Wisconsin , Iowa , Kansas , West Virginia and Montana" type="NP">
          <tokens>
            <token id="10" string="Wisconsin" />
            <token id="11" string="," />
            <token id="12" string="Iowa" />
            <token id="13" string="," />
            <token id="14" string="Kansas" />
            <token id="15" string="," />
            <token id="16" string="West" />
            <token id="17" string="Virginia" />
            <token id="18" string="and" />
            <token id="19" string="Montana" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="1">Expected</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="3">lose</governor>
          <dependent id="2">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="1">Expected</governor>
          <dependent id="3">lose</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="6">seat</governor>
          <dependent id="4">one</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">seat</governor>
          <dependent id="5">house</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">lose</governor>
          <dependent id="6">seat</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="1">Expected</governor>
          <dependent id="7">are</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="1">Expected</governor>
          <dependent id="8">Massachusetts</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">Virginia</governor>
          <dependent id="10">Wisconsin</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">Virginia</governor>
          <dependent id="12">Iowa</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">Virginia</governor>
          <dependent id="14">Kansas</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">Virginia</governor>
          <dependent id="16">West</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="8">Massachusetts</governor>
          <dependent id="17">Virginia</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="17">Virginia</governor>
          <dependent id="18">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">Virginia</governor>
          <dependent id="19">Montana</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="West Virginia" type="LOCATION" score="0.0">
          <tokens>
            <token id="16" string="West" />
            <token id="17" string="Virginia" />
          </tokens>
        </entity>
        <entity id="2" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="4" string="one" />
          </tokens>
        </entity>
        <entity id="3" string="Massachusetts" type="LOCATION" score="0.0">
          <tokens>
            <token id="8" string="Massachusetts" />
          </tokens>
        </entity>
        <entity id="4" string="Montana" type="LOCATION" score="0.0">
          <tokens>
            <token id="19" string="Montana" />
          </tokens>
        </entity>
        <entity id="5" string="Kansas" type="LOCATION" score="0.0">
          <tokens>
            <token id="14" string="Kansas" />
          </tokens>
        </entity>
        <entity id="6" string="Iowa" type="LOCATION" score="0.0">
          <tokens>
            <token id="12" string="Iowa" />
          </tokens>
        </entity>
        <entity id="7" string="Wisconsin" type="LOCATION" score="0.0">
          <tokens>
            <token id="10" string="Wisconsin" />
          </tokens>
        </entity>
      </entities>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="4" type="PROPER">
      <referenced ids_tokens="28-29" string="just one" id_sentence="11" />
      <mentions>
        <mention ids_tokens="23-24" string="one another" id_sentence="1" />
      </mentions>
    </coreference>
    <coreference id="5" type="PROPER">
      <referenced ids_tokens="1-2-3" string="The Census Bureau" id_sentence="2" />
      <mentions>
        <mention ids_tokens="3" string="it" id_sentence="3" />
      </mentions>
    </coreference>
    <coreference id="6" type="NOMINAL">
      <referenced ids_tokens="9-10" string="illegal aliens" id_sentence="2" />
      <mentions>
        <mention ids_tokens="8-9" string="the aliens" id_sentence="4" />
      </mentions>
    </coreference>
    <coreference id="8" type="PROPER">
      <referenced ids_tokens="24-25-26-27" string="the House of Representatives" id_sentence="4" />
      <mentions>
        <mention ids_tokens="8-9" string="the House" id_sentence="6" />
        <mention ids_tokens="9" string="House" id_sentence="6" />
        <mention ids_tokens="21" string="House" id_sentence="8" />
        <mention ids_tokens="8" string="House" id_sentence="13" />
        <mention ids_tokens="30" string="House" id_sentence="13" />
      </mentions>
    </coreference>
    <coreference id="9" type="NOMINAL">
      <referenced ids_tokens="3-4" string="other groups" id_sentence="5" />
      <mentions>
        <mention ids_tokens="6" string="their" id_sentence="7" />
      </mentions>
    </coreference>
    <coreference id="12" type="PROPER">
      <referenced ids_tokens="26-27" string="William O'Hare" id_sentence="7" />
      <mentions>
        <mention ids_tokens="1" string="O'Hare" id_sentence="8" />
        <mention ids_tokens="14" string="he" id_sentence="8" />
        <mention ids_tokens="13" string="he" id_sentence="9" />
        <mention ids_tokens="13" string="he" id_sentence="10" />
        <mention ids_tokens="5" string="he" id_sentence="11" />
        <mention ids_tokens="19" string="he" id_sentence="12" />
        <mention ids_tokens="1-2" string="O'Hare's" id_sentence="13" />
      </mentions>
    </coreference>
    <coreference id="13" type="NOMINAL">
      <referenced ids_tokens="9-10-11" string="the only change" id_sentence="7" />
      <mentions>
        <mention ids_tokens="2" string="That" id_sentence="12" />
      </mentions>
    </coreference>
    <coreference id="14" type="LIST">
      <referenced ids_tokens="7-8-9-10-11-12" string="Northeast and Midwest members of Congress" id_sentence="8" />
      <mentions>
        <mention ids_tokens="1" string="That" id_sentence="9" />
      </mentions>
    </coreference>
    <coreference id="15" type="NOMINAL">
      <referenced ids_tokens="20-21-22" string="14 House seats" id_sentence="8" />
      <mentions>
        <mention ids_tokens="8-9" string="House seats" id_sentence="13" />
      </mentions>
    </coreference>
  </coreferences>
</document>
