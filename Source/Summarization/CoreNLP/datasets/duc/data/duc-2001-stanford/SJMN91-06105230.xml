<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="SJMN91-06105230">
  <sentences>
    <sentence id="1" has_coreference="false">
      <content>Suicide or sense?</content>
      <tokens>
        <token id="1" string="Suicide" lemma="suicide" stem="suicid" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="2" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="sense" lemma="sense" stem="sens" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (FRAG (NP (NP (NN Suicide)) (CC or) (NP (NN sense))) (. ?)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Suicide or sense" type="NP">
          <tokens>
            <token id="1" string="Suicide" />
            <token id="2" string="or" />
            <token id="3" string="sense" />
          </tokens>
        </chunking>
        <chunking id="2" string="sense" type="NP">
          <tokens>
            <token id="3" string="sense" />
          </tokens>
        </chunking>
        <chunking id="3" string="Suicide" type="NP">
          <tokens>
            <token id="1" string="Suicide" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="1">Suicide</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="1">Suicide</governor>
          <dependent id="2">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="1">Suicide</governor>
          <dependent id="3">sense</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Suicide" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="1" string="Suicide" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>The answer may decide the men&amp;apost;s winner of Monday&amp;apost;s Boston Marathon.; For the women, the story line is more personal.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="answer" lemma="answer" stem="answer" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="may" lemma="may" stem="mai" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="decide" lemma="decide" stem="decid" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="men" lemma="man" stem="men" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="winner" lemma="winner" stem="winner" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="Monday" lemma="Monday" stem="mondai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="11" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="Boston" lemma="Boston" stem="boston" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="13" string="Marathon." lemma="Marathon." stem="marathon." pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="For" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="women" lemma="woman" stem="women" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="story" lemma="story" stem="stori" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="line" lemma="line" stem="line" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="personal" lemma="personal" stem="person" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (DT The) (NN answer)) (VP (MD may) (VP (VB decide) (NP (NP (NP (DT the) (NNS men) (POS 's)) (NN winner)) (PP (IN of) (NP (NP (NNP Monday) (POS 's)) (NNP Boston) (NNP Marathon.))))))) (: ;) (S (PP (IN For) (NP (DT the) (NNS women))) (, ,) (NP (DT the) (NN story) (NN line)) (VP (VBZ is) (ADJP (RBR more) (JJ personal)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the men 's" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="men" />
            <token id="7" string="'s" />
          </tokens>
        </chunking>
        <chunking id="2" string="the women" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="women" />
          </tokens>
        </chunking>
        <chunking id="3" string="The answer" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="answer" />
          </tokens>
        </chunking>
        <chunking id="4" string="the story line" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="story" />
            <token id="21" string="line" />
          </tokens>
        </chunking>
        <chunking id="5" string="Monday 's" type="NP">
          <tokens>
            <token id="10" string="Monday" />
            <token id="11" string="'s" />
          </tokens>
        </chunking>
        <chunking id="6" string="is more personal" type="VP">
          <tokens>
            <token id="22" string="is" />
            <token id="23" string="more" />
            <token id="24" string="personal" />
          </tokens>
        </chunking>
        <chunking id="7" string="more personal" type="ADJP">
          <tokens>
            <token id="23" string="more" />
            <token id="24" string="personal" />
          </tokens>
        </chunking>
        <chunking id="8" string="decide the men 's winner of Monday 's Boston Marathon." type="VP">
          <tokens>
            <token id="4" string="decide" />
            <token id="5" string="the" />
            <token id="6" string="men" />
            <token id="7" string="'s" />
            <token id="8" string="winner" />
            <token id="9" string="of" />
            <token id="10" string="Monday" />
            <token id="11" string="'s" />
            <token id="12" string="Boston" />
            <token id="13" string="Marathon." />
          </tokens>
        </chunking>
        <chunking id="9" string="the men 's winner" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="men" />
            <token id="7" string="'s" />
            <token id="8" string="winner" />
          </tokens>
        </chunking>
        <chunking id="10" string="may decide the men 's winner of Monday 's Boston Marathon." type="VP">
          <tokens>
            <token id="3" string="may" />
            <token id="4" string="decide" />
            <token id="5" string="the" />
            <token id="6" string="men" />
            <token id="7" string="'s" />
            <token id="8" string="winner" />
            <token id="9" string="of" />
            <token id="10" string="Monday" />
            <token id="11" string="'s" />
            <token id="12" string="Boston" />
            <token id="13" string="Marathon." />
          </tokens>
        </chunking>
        <chunking id="11" string="the men 's winner of Monday 's Boston Marathon." type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="men" />
            <token id="7" string="'s" />
            <token id="8" string="winner" />
            <token id="9" string="of" />
            <token id="10" string="Monday" />
            <token id="11" string="'s" />
            <token id="12" string="Boston" />
            <token id="13" string="Marathon." />
          </tokens>
        </chunking>
        <chunking id="12" string="Monday 's Boston Marathon." type="NP">
          <tokens>
            <token id="10" string="Monday" />
            <token id="11" string="'s" />
            <token id="12" string="Boston" />
            <token id="13" string="Marathon." />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">answer</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">decide</governor>
          <dependent id="2">answer</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">decide</governor>
          <dependent id="3">may</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">decide</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">men</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">winner</governor>
          <dependent id="6">men</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">men</governor>
          <dependent id="7">'s</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">decide</governor>
          <dependent id="8">winner</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Marathon.</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="13">Marathon.</governor>
          <dependent id="10">Monday</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">Monday</governor>
          <dependent id="11">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Marathon.</governor>
          <dependent id="12">Boston</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">winner</governor>
          <dependent id="13">Marathon.</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">women</governor>
          <dependent id="15">For</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">women</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">personal</governor>
          <dependent id="17">women</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">line</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">line</governor>
          <dependent id="20">story</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">personal</governor>
          <dependent id="21">line</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="24">personal</governor>
          <dependent id="22">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="24">personal</governor>
          <dependent id="23">more</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="4">decide</governor>
          <dependent id="24">personal</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Monday" type="DATE" score="0.0">
          <tokens>
            <token id="10" string="Monday" />
          </tokens>
        </entity>
        <entity id="2" string="Boston" type="LOCATION" score="0.0">
          <tokens>
            <token id="12" string="Boston" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>Can Ingrid Kristiansen and Joan Benoit Samuelson, the two fastest women&amp;apost;s marathoners in history, return to their past glory after having their second babies or is a wave of runners ready to sweep past them?</content>
      <tokens>
        <token id="1" string="Can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Ingrid" lemma="Ingrid" stem="ingrid" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="Kristiansen" lemma="Kristiansen" stem="kristiansen" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="4" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="Joan" lemma="Joan" stem="joan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="6" string="Benoit" lemma="Benoit" stem="benoit" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="7" string="Samuelson" lemma="Samuelson" stem="samuelson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="11" string="fastest" lemma="fastest" stem="fastest" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="women" lemma="woman" stem="women" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="marathoners" lemma="marathoner" stem="marathon" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="history" lemma="history" stem="histori" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="return" lemma="return" stem="return" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="past" lemma="past" stem="past" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="22" string="glory" lemma="glory" stem="glori" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="having" lemma="have" stem="have" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="second" lemma="second" stem="second" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="true" is_refers="false" />
        <token id="27" string="babies" lemma="baby" stem="babi" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="wave" lemma="wave" stem="wave" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="runners" lemma="runner" stem="runner" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="ready" lemma="ready" stem="readi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="sweep" lemma="sweep" stem="sweep" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="past" lemma="past" stem="past" pos="IN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="38" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (VP (VP (VP (NP (MD Can)) (NP (NP (NP (NNP Ingrid) (NNP Kristiansen)) (CC and) (NP (NNP Joan) (NNP Benoit) (NNP Samuelson))) (, ,) (NP (NP (DT the) (CD two) (JJS fastest)) (NP (NP (NNS women) (POS 's)) (NNS marathoners)))) (PP (IN in) (NP (NN history)))) (, ,) (NP (NP (NN return)) (PP (TO to) (NP (NP (PRP$ their) (JJ past) (NN glory)) (PP (IN after) (S (VP (VBG having) (NP (PRP$ their) (JJ second) (NNS babies))))))))) (CC or) (VP (VBZ is) (NP (NP (DT a) (NN wave)) (PP (IN of) (NP (NP (NNS runners)) (ADJP (JJ ready) (PP (TO to) (NP (NP (NN sweep)) (PP (IN past) (NP (PRP them))))))))))) (. ?)))</syntactictree>
      <chunkings>
        <chunking id="1" string="return" type="NP">
          <tokens>
            <token id="18" string="return" />
          </tokens>
        </chunking>
        <chunking id="2" string="return to their past glory after having their second babies" type="NP">
          <tokens>
            <token id="18" string="return" />
            <token id="19" string="to" />
            <token id="20" string="their" />
            <token id="21" string="past" />
            <token id="22" string="glory" />
            <token id="23" string="after" />
            <token id="24" string="having" />
            <token id="25" string="their" />
            <token id="26" string="second" />
            <token id="27" string="babies" />
          </tokens>
        </chunking>
        <chunking id="3" string="is a wave of runners ready to sweep past them" type="VP">
          <tokens>
            <token id="29" string="is" />
            <token id="30" string="a" />
            <token id="31" string="wave" />
            <token id="32" string="of" />
            <token id="33" string="runners" />
            <token id="34" string="ready" />
            <token id="35" string="to" />
            <token id="36" string="sweep" />
            <token id="37" string="past" />
            <token id="38" string="them" />
          </tokens>
        </chunking>
        <chunking id="4" string="their past glory after having their second babies" type="NP">
          <tokens>
            <token id="20" string="their" />
            <token id="21" string="past" />
            <token id="22" string="glory" />
            <token id="23" string="after" />
            <token id="24" string="having" />
            <token id="25" string="their" />
            <token id="26" string="second" />
            <token id="27" string="babies" />
          </tokens>
        </chunking>
        <chunking id="5" string="sweep" type="NP">
          <tokens>
            <token id="36" string="sweep" />
          </tokens>
        </chunking>
        <chunking id="6" string="the two fastest" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="two" />
            <token id="11" string="fastest" />
          </tokens>
        </chunking>
        <chunking id="7" string="history" type="NP">
          <tokens>
            <token id="16" string="history" />
          </tokens>
        </chunking>
        <chunking id="8" string="runners" type="NP">
          <tokens>
            <token id="33" string="runners" />
          </tokens>
        </chunking>
        <chunking id="9" string="them" type="NP">
          <tokens>
            <token id="38" string="them" />
          </tokens>
        </chunking>
        <chunking id="10" string="Can Ingrid Kristiansen and Joan Benoit Samuelson , the two fastest women 's marathoners in history" type="VP">
          <tokens>
            <token id="1" string="Can" />
            <token id="2" string="Ingrid" />
            <token id="3" string="Kristiansen" />
            <token id="4" string="and" />
            <token id="5" string="Joan" />
            <token id="6" string="Benoit" />
            <token id="7" string="Samuelson" />
            <token id="8" string="," />
            <token id="9" string="the" />
            <token id="10" string="two" />
            <token id="11" string="fastest" />
            <token id="12" string="women" />
            <token id="13" string="'s" />
            <token id="14" string="marathoners" />
            <token id="15" string="in" />
            <token id="16" string="history" />
          </tokens>
        </chunking>
        <chunking id="11" string="Can" type="NP">
          <tokens>
            <token id="1" string="Can" />
          </tokens>
        </chunking>
        <chunking id="12" string="Ingrid Kristiansen and Joan Benoit Samuelson" type="NP">
          <tokens>
            <token id="2" string="Ingrid" />
            <token id="3" string="Kristiansen" />
            <token id="4" string="and" />
            <token id="5" string="Joan" />
            <token id="6" string="Benoit" />
            <token id="7" string="Samuelson" />
          </tokens>
        </chunking>
        <chunking id="13" string="Joan Benoit Samuelson" type="NP">
          <tokens>
            <token id="5" string="Joan" />
            <token id="6" string="Benoit" />
            <token id="7" string="Samuelson" />
          </tokens>
        </chunking>
        <chunking id="14" string="women 's marathoners" type="NP">
          <tokens>
            <token id="12" string="women" />
            <token id="13" string="'s" />
            <token id="14" string="marathoners" />
          </tokens>
        </chunking>
        <chunking id="15" string="sweep past them" type="NP">
          <tokens>
            <token id="36" string="sweep" />
            <token id="37" string="past" />
            <token id="38" string="them" />
          </tokens>
        </chunking>
        <chunking id="16" string="Can Ingrid Kristiansen and Joan Benoit Samuelson , the two fastest women 's marathoners in history , return to their past glory after having their second babies or is a wave of runners ready to sweep past them" type="VP">
          <tokens>
            <token id="1" string="Can" />
            <token id="2" string="Ingrid" />
            <token id="3" string="Kristiansen" />
            <token id="4" string="and" />
            <token id="5" string="Joan" />
            <token id="6" string="Benoit" />
            <token id="7" string="Samuelson" />
            <token id="8" string="," />
            <token id="9" string="the" />
            <token id="10" string="two" />
            <token id="11" string="fastest" />
            <token id="12" string="women" />
            <token id="13" string="'s" />
            <token id="14" string="marathoners" />
            <token id="15" string="in" />
            <token id="16" string="history" />
            <token id="17" string="," />
            <token id="18" string="return" />
            <token id="19" string="to" />
            <token id="20" string="their" />
            <token id="21" string="past" />
            <token id="22" string="glory" />
            <token id="23" string="after" />
            <token id="24" string="having" />
            <token id="25" string="their" />
            <token id="26" string="second" />
            <token id="27" string="babies" />
            <token id="28" string="or" />
            <token id="29" string="is" />
            <token id="30" string="a" />
            <token id="31" string="wave" />
            <token id="32" string="of" />
            <token id="33" string="runners" />
            <token id="34" string="ready" />
            <token id="35" string="to" />
            <token id="36" string="sweep" />
            <token id="37" string="past" />
            <token id="38" string="them" />
          </tokens>
        </chunking>
        <chunking id="17" string="their past glory" type="NP">
          <tokens>
            <token id="20" string="their" />
            <token id="21" string="past" />
            <token id="22" string="glory" />
          </tokens>
        </chunking>
        <chunking id="18" string="their second babies" type="NP">
          <tokens>
            <token id="25" string="their" />
            <token id="26" string="second" />
            <token id="27" string="babies" />
          </tokens>
        </chunking>
        <chunking id="19" string="runners ready to sweep past them" type="NP">
          <tokens>
            <token id="33" string="runners" />
            <token id="34" string="ready" />
            <token id="35" string="to" />
            <token id="36" string="sweep" />
            <token id="37" string="past" />
            <token id="38" string="them" />
          </tokens>
        </chunking>
        <chunking id="20" string="women 's" type="NP">
          <tokens>
            <token id="12" string="women" />
            <token id="13" string="'s" />
          </tokens>
        </chunking>
        <chunking id="21" string="ready to sweep past them" type="ADJP">
          <tokens>
            <token id="34" string="ready" />
            <token id="35" string="to" />
            <token id="36" string="sweep" />
            <token id="37" string="past" />
            <token id="38" string="them" />
          </tokens>
        </chunking>
        <chunking id="22" string="a wave" type="NP">
          <tokens>
            <token id="30" string="a" />
            <token id="31" string="wave" />
          </tokens>
        </chunking>
        <chunking id="23" string="a wave of runners ready to sweep past them" type="NP">
          <tokens>
            <token id="30" string="a" />
            <token id="31" string="wave" />
            <token id="32" string="of" />
            <token id="33" string="runners" />
            <token id="34" string="ready" />
            <token id="35" string="to" />
            <token id="36" string="sweep" />
            <token id="37" string="past" />
            <token id="38" string="them" />
          </tokens>
        </chunking>
        <chunking id="24" string="Ingrid Kristiansen and Joan Benoit Samuelson , the two fastest women 's marathoners" type="NP">
          <tokens>
            <token id="2" string="Ingrid" />
            <token id="3" string="Kristiansen" />
            <token id="4" string="and" />
            <token id="5" string="Joan" />
            <token id="6" string="Benoit" />
            <token id="7" string="Samuelson" />
            <token id="8" string="," />
            <token id="9" string="the" />
            <token id="10" string="two" />
            <token id="11" string="fastest" />
            <token id="12" string="women" />
            <token id="13" string="'s" />
            <token id="14" string="marathoners" />
          </tokens>
        </chunking>
        <chunking id="25" string="the two fastest women 's marathoners" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="two" />
            <token id="11" string="fastest" />
            <token id="12" string="women" />
            <token id="13" string="'s" />
            <token id="14" string="marathoners" />
          </tokens>
        </chunking>
        <chunking id="26" string="Ingrid Kristiansen" type="NP">
          <tokens>
            <token id="2" string="Ingrid" />
            <token id="3" string="Kristiansen" />
          </tokens>
        </chunking>
        <chunking id="27" string="Can Ingrid Kristiansen and Joan Benoit Samuelson , the two fastest women 's marathoners in history , return to their past glory after having their second babies" type="VP">
          <tokens>
            <token id="1" string="Can" />
            <token id="2" string="Ingrid" />
            <token id="3" string="Kristiansen" />
            <token id="4" string="and" />
            <token id="5" string="Joan" />
            <token id="6" string="Benoit" />
            <token id="7" string="Samuelson" />
            <token id="8" string="," />
            <token id="9" string="the" />
            <token id="10" string="two" />
            <token id="11" string="fastest" />
            <token id="12" string="women" />
            <token id="13" string="'s" />
            <token id="14" string="marathoners" />
            <token id="15" string="in" />
            <token id="16" string="history" />
            <token id="17" string="," />
            <token id="18" string="return" />
            <token id="19" string="to" />
            <token id="20" string="their" />
            <token id="21" string="past" />
            <token id="22" string="glory" />
            <token id="23" string="after" />
            <token id="24" string="having" />
            <token id="25" string="their" />
            <token id="26" string="second" />
            <token id="27" string="babies" />
          </tokens>
        </chunking>
        <chunking id="28" string="having their second babies" type="VP">
          <tokens>
            <token id="24" string="having" />
            <token id="25" string="their" />
            <token id="26" string="second" />
            <token id="27" string="babies" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="1">Can</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Kristiansen</governor>
          <dependent id="2">Ingrid</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="1">Can</governor>
          <dependent id="3">Kristiansen</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">Kristiansen</governor>
          <dependent id="4">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Samuelson</governor>
          <dependent id="5">Joan</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Samuelson</governor>
          <dependent id="6">Benoit</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">Kristiansen</governor>
          <dependent id="7">Samuelson</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">two</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="3">Kristiansen</governor>
          <dependent id="10">two</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">two</governor>
          <dependent id="11">fastest</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="14">marathoners</governor>
          <dependent id="12">women</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">women</governor>
          <dependent id="13">'s</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="10">two</governor>
          <dependent id="14">marathoners</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">history</governor>
          <dependent id="15">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Can</governor>
          <dependent id="16">history</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="1">Can</governor>
          <dependent id="18">return</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">glory</governor>
          <dependent id="19">to</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="22">glory</governor>
          <dependent id="20">their</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">glory</governor>
          <dependent id="21">past</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">return</governor>
          <dependent id="22">glory</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="24">having</governor>
          <dependent id="23">after</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="22">glory</governor>
          <dependent id="24">having</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="27">babies</governor>
          <dependent id="25">their</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="27">babies</governor>
          <dependent id="26">second</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="24">having</governor>
          <dependent id="27">babies</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="1">Can</governor>
          <dependent id="28">or</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="31">wave</governor>
          <dependent id="29">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">wave</governor>
          <dependent id="30">a</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="1">Can</governor>
          <dependent id="31">wave</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">runners</governor>
          <dependent id="32">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">wave</governor>
          <dependent id="33">runners</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="33">runners</governor>
          <dependent id="34">ready</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">sweep</governor>
          <dependent id="35">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="34">ready</governor>
          <dependent id="36">sweep</dependent>
        </dependency>
        <dependency type="case">
          <governor id="38">them</governor>
          <dependent id="37">past</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="36">sweep</governor>
          <dependent id="38">them</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Joan Benoit Samuelson" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Joan" />
            <token id="6" string="Benoit" />
            <token id="7" string="Samuelson" />
          </tokens>
        </entity>
        <entity id="2" string="past" type="DATE" score="0.0">
          <tokens>
            <token id="21" string="past" />
          </tokens>
        </entity>
        <entity id="3" string="second" type="ORDINAL" score="0.0">
          <tokens>
            <token id="26" string="second" />
          </tokens>
        </entity>
        <entity id="4" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="10" string="two" />
          </tokens>
        </entity>
        <entity id="5" string="Ingrid Kristiansen" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Ingrid" />
            <token id="3" string="Kristiansen" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>And for the sentimentalists, there will be 83-year-old Johnny Kelley starting in his 60th Boston Marathon.</content>
      <tokens>
        <token id="1" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="sentimentalists" lemma="sentimentalist" stem="sentimentalist" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="83-year-old" lemma="83-year-old" stem="83-year-old" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="10" string="Johnny" lemma="Johnny" stem="johnni" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="11" string="Kelley" lemma="Kelley" stem="kellei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="12" string="starting" lemma="start" stem="start" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="15" string="60th" lemma="60th" stem="60th" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="true" is_refers="false" />
        <token id="16" string="Boston" lemma="Boston" stem="boston" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="17" string="Marathon" lemma="Marathon" stem="marathon" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC And) (PP (IN for) (NP (DT the) (NNS sentimentalists))) (, ,) (NP (EX there)) (VP (MD will) (VP (VB be) (NP (NP (JJ 83-year-old) (NNP Johnny) (NNP Kelley)) (VP (VBG starting) (PP (IN in) (NP (PRP$ his) (JJ 60th) (NNP Boston) (NNP Marathon))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="there" type="NP">
          <tokens>
            <token id="6" string="there" />
          </tokens>
        </chunking>
        <chunking id="2" string="be 83-year-old Johnny Kelley starting in his 60th Boston Marathon" type="VP">
          <tokens>
            <token id="8" string="be" />
            <token id="9" string="83-year-old" />
            <token id="10" string="Johnny" />
            <token id="11" string="Kelley" />
            <token id="12" string="starting" />
            <token id="13" string="in" />
            <token id="14" string="his" />
            <token id="15" string="60th" />
            <token id="16" string="Boston" />
            <token id="17" string="Marathon" />
          </tokens>
        </chunking>
        <chunking id="3" string="83-year-old Johnny Kelley" type="NP">
          <tokens>
            <token id="9" string="83-year-old" />
            <token id="10" string="Johnny" />
            <token id="11" string="Kelley" />
          </tokens>
        </chunking>
        <chunking id="4" string="the sentimentalists" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="sentimentalists" />
          </tokens>
        </chunking>
        <chunking id="5" string="83-year-old Johnny Kelley starting in his 60th Boston Marathon" type="NP">
          <tokens>
            <token id="9" string="83-year-old" />
            <token id="10" string="Johnny" />
            <token id="11" string="Kelley" />
            <token id="12" string="starting" />
            <token id="13" string="in" />
            <token id="14" string="his" />
            <token id="15" string="60th" />
            <token id="16" string="Boston" />
            <token id="17" string="Marathon" />
          </tokens>
        </chunking>
        <chunking id="6" string="his 60th Boston Marathon" type="NP">
          <tokens>
            <token id="14" string="his" />
            <token id="15" string="60th" />
            <token id="16" string="Boston" />
            <token id="17" string="Marathon" />
          </tokens>
        </chunking>
        <chunking id="7" string="starting in his 60th Boston Marathon" type="VP">
          <tokens>
            <token id="12" string="starting" />
            <token id="13" string="in" />
            <token id="14" string="his" />
            <token id="15" string="60th" />
            <token id="16" string="Boston" />
            <token id="17" string="Marathon" />
          </tokens>
        </chunking>
        <chunking id="8" string="will be 83-year-old Johnny Kelley starting in his 60th Boston Marathon" type="VP">
          <tokens>
            <token id="7" string="will" />
            <token id="8" string="be" />
            <token id="9" string="83-year-old" />
            <token id="10" string="Johnny" />
            <token id="11" string="Kelley" />
            <token id="12" string="starting" />
            <token id="13" string="in" />
            <token id="14" string="his" />
            <token id="15" string="60th" />
            <token id="16" string="Boston" />
            <token id="17" string="Marathon" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="11">Kelley</governor>
          <dependent id="1">And</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">sentimentalists</governor>
          <dependent id="2">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">sentimentalists</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">Kelley</governor>
          <dependent id="4">sentimentalists</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="11">Kelley</governor>
          <dependent id="6">there</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">Kelley</governor>
          <dependent id="7">will</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="11">Kelley</governor>
          <dependent id="8">be</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">Kelley</governor>
          <dependent id="9">83-year-old</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Kelley</governor>
          <dependent id="10">Johnny</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">Kelley</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="11">Kelley</governor>
          <dependent id="12">starting</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">Marathon</governor>
          <dependent id="13">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="17">Marathon</governor>
          <dependent id="14">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">Marathon</governor>
          <dependent id="15">60th</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">Marathon</governor>
          <dependent id="16">Boston</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">starting</governor>
          <dependent id="17">Marathon</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Boston Marathon" type="LOCATION" score="0.0">
          <tokens>
            <token id="16" string="Boston" />
            <token id="17" string="Marathon" />
          </tokens>
        </entity>
        <entity id="2" string="60th" type="ORDINAL" score="0.0">
          <tokens>
            <token id="15" string="60th" />
          </tokens>
        </entity>
        <entity id="3" string="83-year-old" type="DURATION" score="0.0">
          <tokens>
            <token id="9" string="83-year-old" />
          </tokens>
        </entity>
        <entity id="4" string="Johnny Kelley" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Johnny" />
            <token id="11" string="Kelley" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>There have only been 35 editions of this race run without him.</content>
      <tokens>
        <token id="1" string="There" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="only" lemma="only" stem="onli" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="35" lemma="35" stem="35" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="6" string="editions" lemma="edition" stem="edit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="race" lemma="race" stem="race" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="run" lemma="run" stem="run" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="without" lemma="without" stem="without" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (EX There)) (VP (VBP have) (ADVP (RB only)) (VP (VBN been) (NP (NP (CD 35) (NNS editions)) (PP (IN of) (NP (DT this) (NN race) (NN run)))) (PP (IN without) (NP (PRP him))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="have only been 35 editions of this race run without him" type="VP">
          <tokens>
            <token id="2" string="have" />
            <token id="3" string="only" />
            <token id="4" string="been" />
            <token id="5" string="35" />
            <token id="6" string="editions" />
            <token id="7" string="of" />
            <token id="8" string="this" />
            <token id="9" string="race" />
            <token id="10" string="run" />
            <token id="11" string="without" />
            <token id="12" string="him" />
          </tokens>
        </chunking>
        <chunking id="2" string="There" type="NP">
          <tokens>
            <token id="1" string="There" />
          </tokens>
        </chunking>
        <chunking id="3" string="been 35 editions of this race run without him" type="VP">
          <tokens>
            <token id="4" string="been" />
            <token id="5" string="35" />
            <token id="6" string="editions" />
            <token id="7" string="of" />
            <token id="8" string="this" />
            <token id="9" string="race" />
            <token id="10" string="run" />
            <token id="11" string="without" />
            <token id="12" string="him" />
          </tokens>
        </chunking>
        <chunking id="4" string="this race run" type="NP">
          <tokens>
            <token id="8" string="this" />
            <token id="9" string="race" />
            <token id="10" string="run" />
          </tokens>
        </chunking>
        <chunking id="5" string="35 editions" type="NP">
          <tokens>
            <token id="5" string="35" />
            <token id="6" string="editions" />
          </tokens>
        </chunking>
        <chunking id="6" string="him" type="NP">
          <tokens>
            <token id="12" string="him" />
          </tokens>
        </chunking>
        <chunking id="7" string="35 editions of this race run" type="NP">
          <tokens>
            <token id="5" string="35" />
            <token id="6" string="editions" />
            <token id="7" string="of" />
            <token id="8" string="this" />
            <token id="9" string="race" />
            <token id="10" string="run" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="expl">
          <governor id="6">editions</governor>
          <dependent id="1">There</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">editions</governor>
          <dependent id="2">have</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">editions</governor>
          <dependent id="3">only</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">editions</governor>
          <dependent id="4">been</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="6">editions</governor>
          <dependent id="5">35</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">editions</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">run</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">run</governor>
          <dependent id="8">this</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">run</governor>
          <dependent id="9">race</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">editions</governor>
          <dependent id="10">run</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">him</governor>
          <dependent id="11">without</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">editions</governor>
          <dependent id="12">him</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="35" type="NUMBER" score="0.0">
          <tokens>
            <token id="5" string="35" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="false">
      <content>The last three Boston marathons have turned into reckless speed duels.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="three" lemma="three" stem="three" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="4" string="Boston" lemma="Boston" stem="boston" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="5" string="marathons" lemma="marathon" stem="marathon" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="turned" lemma="turn" stem="turn" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="reckless" lemma="reckless" stem="reckless" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="speed" lemma="speed" stem="speed" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="duels" lemma="duel" stem="duel" pos="NNS" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (JJ last) (CD three) (NNP Boston) (NNS marathons)) (VP (VBP have) (VP (VBN turned) (PP (IN into) (NP (JJ reckless) (NN speed) (NNS duels))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="reckless speed duels" type="NP">
          <tokens>
            <token id="9" string="reckless" />
            <token id="10" string="speed" />
            <token id="11" string="duels" />
          </tokens>
        </chunking>
        <chunking id="2" string="The last three Boston marathons" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="last" />
            <token id="3" string="three" />
            <token id="4" string="Boston" />
            <token id="5" string="marathons" />
          </tokens>
        </chunking>
        <chunking id="3" string="turned into reckless speed duels" type="VP">
          <tokens>
            <token id="7" string="turned" />
            <token id="8" string="into" />
            <token id="9" string="reckless" />
            <token id="10" string="speed" />
            <token id="11" string="duels" />
          </tokens>
        </chunking>
        <chunking id="4" string="have turned into reckless speed duels" type="VP">
          <tokens>
            <token id="6" string="have" />
            <token id="7" string="turned" />
            <token id="8" string="into" />
            <token id="9" string="reckless" />
            <token id="10" string="speed" />
            <token id="11" string="duels" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="5">marathons</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">marathons</governor>
          <dependent id="2">last</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="5">marathons</governor>
          <dependent id="3">three</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">marathons</governor>
          <dependent id="4">Boston</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">turned</governor>
          <dependent id="5">marathons</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">turned</governor>
          <dependent id="6">have</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">turned</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">duels</governor>
          <dependent id="8">into</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">duels</governor>
          <dependent id="9">reckless</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">duels</governor>
          <dependent id="10">speed</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">turned</governor>
          <dependent id="11">duels</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="duels" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="11" string="duels" />
          </tokens>
        </entity>
        <entity id="2" string="three" type="NUMBER" score="0.0">
          <tokens>
            <token id="3" string="three" />
          </tokens>
        </entity>
        <entity id="3" string="Boston" type="LOCATION" score="0.0">
          <tokens>
            <token id="4" string="Boston" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>They have produced five of the top 10 times and eight of the top 15 in the race&amp;apost;s storied history.</content>
      <tokens>
        <token id="1" string="They" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="produced" lemma="produce" stem="produc" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="five" lemma="five" stem="five" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="top" lemma="top" stem="top" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="10" lemma="10" stem="10" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="9" string="times" lemma="time" stem="time" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="eight" lemma="eight" stem="eight" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="top" lemma="top" stem="top" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="15" lemma="15" stem="15" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="16" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="race" lemma="race" stem="race" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="storied" lemma="storied" stem="stori" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="history" lemma="history" stem="histori" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP They)) (VP (VBP have) (VP (VBN produced) (NP (NP (NP (CD five)) (PP (IN of) (NP (DT the) (JJ top) (CD 10) (NNS times)))) (CC and) (NP (NP (CD eight)) (PP (IN of) (NP (DT the) (JJ top) (CD 15))))) (PP (IN in) (NP (NP (DT the) (NN race) (POS 's)) (JJ storied) (NN history))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="They" type="NP">
          <tokens>
            <token id="1" string="They" />
          </tokens>
        </chunking>
        <chunking id="2" string="the race 's" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="race" />
            <token id="19" string="'s" />
          </tokens>
        </chunking>
        <chunking id="3" string="produced five of the top 10 times and eight of the top 15 in the race 's storied history" type="VP">
          <tokens>
            <token id="3" string="produced" />
            <token id="4" string="five" />
            <token id="5" string="of" />
            <token id="6" string="the" />
            <token id="7" string="top" />
            <token id="8" string="10" />
            <token id="9" string="times" />
            <token id="10" string="and" />
            <token id="11" string="eight" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="top" />
            <token id="15" string="15" />
            <token id="16" string="in" />
            <token id="17" string="the" />
            <token id="18" string="race" />
            <token id="19" string="'s" />
            <token id="20" string="storied" />
            <token id="21" string="history" />
          </tokens>
        </chunking>
        <chunking id="4" string="five of the top 10 times and eight of the top 15" type="NP">
          <tokens>
            <token id="4" string="five" />
            <token id="5" string="of" />
            <token id="6" string="the" />
            <token id="7" string="top" />
            <token id="8" string="10" />
            <token id="9" string="times" />
            <token id="10" string="and" />
            <token id="11" string="eight" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="top" />
            <token id="15" string="15" />
          </tokens>
        </chunking>
        <chunking id="5" string="eight of the top 15" type="NP">
          <tokens>
            <token id="11" string="eight" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="top" />
            <token id="15" string="15" />
          </tokens>
        </chunking>
        <chunking id="6" string="the top 10 times" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="top" />
            <token id="8" string="10" />
            <token id="9" string="times" />
          </tokens>
        </chunking>
        <chunking id="7" string="have produced five of the top 10 times and eight of the top 15 in the race 's storied history" type="VP">
          <tokens>
            <token id="2" string="have" />
            <token id="3" string="produced" />
            <token id="4" string="five" />
            <token id="5" string="of" />
            <token id="6" string="the" />
            <token id="7" string="top" />
            <token id="8" string="10" />
            <token id="9" string="times" />
            <token id="10" string="and" />
            <token id="11" string="eight" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="top" />
            <token id="15" string="15" />
            <token id="16" string="in" />
            <token id="17" string="the" />
            <token id="18" string="race" />
            <token id="19" string="'s" />
            <token id="20" string="storied" />
            <token id="21" string="history" />
          </tokens>
        </chunking>
        <chunking id="8" string="the race 's storied history" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="race" />
            <token id="19" string="'s" />
            <token id="20" string="storied" />
            <token id="21" string="history" />
          </tokens>
        </chunking>
        <chunking id="9" string="the top 15" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="top" />
            <token id="15" string="15" />
          </tokens>
        </chunking>
        <chunking id="10" string="five of the top 10 times" type="NP">
          <tokens>
            <token id="4" string="five" />
            <token id="5" string="of" />
            <token id="6" string="the" />
            <token id="7" string="top" />
            <token id="8" string="10" />
            <token id="9" string="times" />
          </tokens>
        </chunking>
        <chunking id="11" string="five" type="NP">
          <tokens>
            <token id="4" string="five" />
          </tokens>
        </chunking>
        <chunking id="12" string="eight" type="NP">
          <tokens>
            <token id="11" string="eight" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">produced</governor>
          <dependent id="1">They</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="3">produced</governor>
          <dependent id="2">have</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">produced</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">produced</governor>
          <dependent id="4">five</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">times</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">times</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">times</governor>
          <dependent id="7">top</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="9">times</governor>
          <dependent id="8">10</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">five</governor>
          <dependent id="9">times</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">five</governor>
          <dependent id="10">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">five</governor>
          <dependent id="11">eight</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">15</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">15</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">15</governor>
          <dependent id="14">top</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">eight</governor>
          <dependent id="15">15</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">history</governor>
          <dependent id="16">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">race</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="21">history</governor>
          <dependent id="18">race</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">race</governor>
          <dependent id="19">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">history</governor>
          <dependent id="20">storied</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">produced</governor>
          <dependent id="21">history</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="15" type="NUMBER" score="0.0">
          <tokens>
            <token id="15" string="15" />
          </tokens>
        </entity>
        <entity id="2" string="five" type="NUMBER" score="0.0">
          <tokens>
            <token id="4" string="five" />
          </tokens>
        </entity>
        <entity id="3" string="10" type="NUMBER" score="0.0">
          <tokens>
            <token id="8" string="10" />
          </tokens>
        </entity>
        <entity id="4" string="eight" type="NUMBER" score="0.0">
          <tokens>
            <token id="11" string="eight" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>They also have resulted in a race of attrition, with many of the early speedsters burning out completely or faltering in the late stages.</content>
      <tokens>
        <token id="1" string="They" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="resulted" lemma="result" stem="result" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="race" lemma="race" stem="race" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="attrition" lemma="attrition" stem="attrit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="many" lemma="many" stem="mani" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="early" lemma="early" stem="earli" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="speedsters" lemma="speedster" stem="speedster" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="burning" lemma="burn" stem="burn" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="completely" lemma="completely" stem="complet" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="faltering" lemma="falter" stem="falter" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="late" lemma="late" stem="late" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="stages" lemma="stage" stem="stage" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP They)) (ADVP (RB also)) (VP (VBP have) (VP (VBN resulted) (PP (IN in) (NP (NP (DT a) (NN race)) (PP (IN of) (NP (NN attrition))))) (, ,) (PP (IN with) (S (NP (NP (JJ many)) (PP (IN of) (NP (DT the) (JJ early) (NNS speedsters)))) (VP (VP (VBG burning) (PRT (RP out)) (ADVP (RB completely))) (CC or) (VP (VBG faltering) (PP (IN in) (NP (DT the) (JJ late) (NNS stages))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="They" type="NP">
          <tokens>
            <token id="1" string="They" />
          </tokens>
        </chunking>
        <chunking id="2" string="many of the early speedsters" type="NP">
          <tokens>
            <token id="12" string="many" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="early" />
            <token id="16" string="speedsters" />
          </tokens>
        </chunking>
        <chunking id="3" string="the early speedsters" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="early" />
            <token id="16" string="speedsters" />
          </tokens>
        </chunking>
        <chunking id="4" string="attrition" type="NP">
          <tokens>
            <token id="9" string="attrition" />
          </tokens>
        </chunking>
        <chunking id="5" string="a race of attrition" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="race" />
            <token id="8" string="of" />
            <token id="9" string="attrition" />
          </tokens>
        </chunking>
        <chunking id="6" string="resulted in a race of attrition , with many of the early speedsters burning out completely or faltering in the late stages" type="VP">
          <tokens>
            <token id="4" string="resulted" />
            <token id="5" string="in" />
            <token id="6" string="a" />
            <token id="7" string="race" />
            <token id="8" string="of" />
            <token id="9" string="attrition" />
            <token id="10" string="," />
            <token id="11" string="with" />
            <token id="12" string="many" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="early" />
            <token id="16" string="speedsters" />
            <token id="17" string="burning" />
            <token id="18" string="out" />
            <token id="19" string="completely" />
            <token id="20" string="or" />
            <token id="21" string="faltering" />
            <token id="22" string="in" />
            <token id="23" string="the" />
            <token id="24" string="late" />
            <token id="25" string="stages" />
          </tokens>
        </chunking>
        <chunking id="7" string="faltering in the late stages" type="VP">
          <tokens>
            <token id="21" string="faltering" />
            <token id="22" string="in" />
            <token id="23" string="the" />
            <token id="24" string="late" />
            <token id="25" string="stages" />
          </tokens>
        </chunking>
        <chunking id="8" string="many" type="NP">
          <tokens>
            <token id="12" string="many" />
          </tokens>
        </chunking>
        <chunking id="9" string="a race" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="race" />
          </tokens>
        </chunking>
        <chunking id="10" string="burning out completely or faltering in the late stages" type="VP">
          <tokens>
            <token id="17" string="burning" />
            <token id="18" string="out" />
            <token id="19" string="completely" />
            <token id="20" string="or" />
            <token id="21" string="faltering" />
            <token id="22" string="in" />
            <token id="23" string="the" />
            <token id="24" string="late" />
            <token id="25" string="stages" />
          </tokens>
        </chunking>
        <chunking id="11" string="burning out completely" type="VP">
          <tokens>
            <token id="17" string="burning" />
            <token id="18" string="out" />
            <token id="19" string="completely" />
          </tokens>
        </chunking>
        <chunking id="12" string="the late stages" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="late" />
            <token id="25" string="stages" />
          </tokens>
        </chunking>
        <chunking id="13" string="have resulted in a race of attrition , with many of the early speedsters burning out completely or faltering in the late stages" type="VP">
          <tokens>
            <token id="3" string="have" />
            <token id="4" string="resulted" />
            <token id="5" string="in" />
            <token id="6" string="a" />
            <token id="7" string="race" />
            <token id="8" string="of" />
            <token id="9" string="attrition" />
            <token id="10" string="," />
            <token id="11" string="with" />
            <token id="12" string="many" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="early" />
            <token id="16" string="speedsters" />
            <token id="17" string="burning" />
            <token id="18" string="out" />
            <token id="19" string="completely" />
            <token id="20" string="or" />
            <token id="21" string="faltering" />
            <token id="22" string="in" />
            <token id="23" string="the" />
            <token id="24" string="late" />
            <token id="25" string="stages" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">resulted</governor>
          <dependent id="1">They</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">resulted</governor>
          <dependent id="2">also</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">resulted</governor>
          <dependent id="3">have</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">resulted</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">race</governor>
          <dependent id="5">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">race</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">resulted</governor>
          <dependent id="7">race</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">attrition</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">race</governor>
          <dependent id="9">attrition</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">burning</governor>
          <dependent id="11">with</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">burning</governor>
          <dependent id="12">many</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">speedsters</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">speedsters</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">speedsters</governor>
          <dependent id="15">early</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">many</governor>
          <dependent id="16">speedsters</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">resulted</governor>
          <dependent id="17">burning</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="17">burning</governor>
          <dependent id="18">out</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="17">burning</governor>
          <dependent id="19">completely</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="17">burning</governor>
          <dependent id="20">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">burning</governor>
          <dependent id="21">faltering</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">stages</governor>
          <dependent id="22">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">stages</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">stages</governor>
          <dependent id="24">late</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">faltering</governor>
          <dependent id="25">stages</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="9" has_coreference="false">
      <content>Along the historic route that begins in Hopkinton, west of Boston, and ends in Copley Square in the Back Bay section of the city, checkpoint records have fallen at an alarming rate.</content>
      <tokens>
        <token id="1" string="Along" lemma="along" stem="along" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="historic" lemma="historic" stem="histor" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="route" lemma="route" stem="rout" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="begins" lemma="begin" stem="begin" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Hopkinton" lemma="Hopkinton" stem="hopkinton" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="west" lemma="west" stem="west" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Boston" lemma="Boston" stem="boston" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="ends" lemma="end" stem="end" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Copley" lemma="Copley" stem="coplei" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="18" string="Square" lemma="Square" stem="squar" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="19" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="Back" lemma="Back" stem="back" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="22" string="Bay" lemma="Bay" stem="bai" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="23" string="section" lemma="section" stem="section" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="city" lemma="city" stem="citi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="checkpoint" lemma="checkpoint" stem="checkpoint" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="records" lemma="record" stem="record" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="fallen" lemma="fall" stem="fallen" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="alarming" lemma="alarming" stem="alarm" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="rate" lemma="rate" stem="rate" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN Along) (NP (NP (DT the) (JJ historic) (NN route)) (SBAR (WHNP (WDT that)) (S (VP (VP (VBZ begins) (PP (IN in) (NP (NP (NNP Hopkinton)) (, ,) (NP (NP (NN west)) (PP (IN of) (NP (NNP Boston))))))) (, ,) (CC and) (VP (VBZ ends) (PP (IN in) (NP (NP (NNP Copley) (NNP Square)) (PP (IN in) (NP (NP (DT the) (NNP Back) (NNP Bay) (NN section)) (PP (IN of) (NP (DT the) (NN city))))))))))))) (, ,) (NP (NN checkpoint) (NNS records)) (VP (VBP have) (VP (VBN fallen) (PP (IN at) (NP (DT an) (ADJP (JJ alarming)) (NN rate))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="west of Boston" type="NP">
          <tokens>
            <token id="10" string="west" />
            <token id="11" string="of" />
            <token id="12" string="Boston" />
          </tokens>
        </chunking>
        <chunking id="2" string="Copley Square" type="NP">
          <tokens>
            <token id="17" string="Copley" />
            <token id="18" string="Square" />
          </tokens>
        </chunking>
        <chunking id="3" string="the city" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="city" />
          </tokens>
        </chunking>
        <chunking id="4" string="checkpoint records" type="NP">
          <tokens>
            <token id="28" string="checkpoint" />
            <token id="29" string="records" />
          </tokens>
        </chunking>
        <chunking id="5" string="alarming" type="ADJP">
          <tokens>
            <token id="34" string="alarming" />
          </tokens>
        </chunking>
        <chunking id="6" string="begins in Hopkinton , west of Boston , and ends in Copley Square in the Back Bay section of the city" type="VP">
          <tokens>
            <token id="6" string="begins" />
            <token id="7" string="in" />
            <token id="8" string="Hopkinton" />
            <token id="9" string="," />
            <token id="10" string="west" />
            <token id="11" string="of" />
            <token id="12" string="Boston" />
            <token id="13" string="," />
            <token id="14" string="and" />
            <token id="15" string="ends" />
            <token id="16" string="in" />
            <token id="17" string="Copley" />
            <token id="18" string="Square" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="Back" />
            <token id="22" string="Bay" />
            <token id="23" string="section" />
            <token id="24" string="of" />
            <token id="25" string="the" />
            <token id="26" string="city" />
          </tokens>
        </chunking>
        <chunking id="7" string="have fallen at an alarming rate" type="VP">
          <tokens>
            <token id="30" string="have" />
            <token id="31" string="fallen" />
            <token id="32" string="at" />
            <token id="33" string="an" />
            <token id="34" string="alarming" />
            <token id="35" string="rate" />
          </tokens>
        </chunking>
        <chunking id="8" string="Hopkinton" type="NP">
          <tokens>
            <token id="8" string="Hopkinton" />
          </tokens>
        </chunking>
        <chunking id="9" string="the Back Bay section of the city" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="Back" />
            <token id="22" string="Bay" />
            <token id="23" string="section" />
            <token id="24" string="of" />
            <token id="25" string="the" />
            <token id="26" string="city" />
          </tokens>
        </chunking>
        <chunking id="10" string="the historic route that begins in Hopkinton , west of Boston , and ends in Copley Square in the Back Bay section of the city" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="historic" />
            <token id="4" string="route" />
            <token id="5" string="that" />
            <token id="6" string="begins" />
            <token id="7" string="in" />
            <token id="8" string="Hopkinton" />
            <token id="9" string="," />
            <token id="10" string="west" />
            <token id="11" string="of" />
            <token id="12" string="Boston" />
            <token id="13" string="," />
            <token id="14" string="and" />
            <token id="15" string="ends" />
            <token id="16" string="in" />
            <token id="17" string="Copley" />
            <token id="18" string="Square" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="Back" />
            <token id="22" string="Bay" />
            <token id="23" string="section" />
            <token id="24" string="of" />
            <token id="25" string="the" />
            <token id="26" string="city" />
          </tokens>
        </chunking>
        <chunking id="11" string="the historic route" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="historic" />
            <token id="4" string="route" />
          </tokens>
        </chunking>
        <chunking id="12" string="begins in Hopkinton , west of Boston" type="VP">
          <tokens>
            <token id="6" string="begins" />
            <token id="7" string="in" />
            <token id="8" string="Hopkinton" />
            <token id="9" string="," />
            <token id="10" string="west" />
            <token id="11" string="of" />
            <token id="12" string="Boston" />
          </tokens>
        </chunking>
        <chunking id="13" string="Copley Square in the Back Bay section of the city" type="NP">
          <tokens>
            <token id="17" string="Copley" />
            <token id="18" string="Square" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="Back" />
            <token id="22" string="Bay" />
            <token id="23" string="section" />
            <token id="24" string="of" />
            <token id="25" string="the" />
            <token id="26" string="city" />
          </tokens>
        </chunking>
        <chunking id="14" string="ends in Copley Square in the Back Bay section of the city" type="VP">
          <tokens>
            <token id="15" string="ends" />
            <token id="16" string="in" />
            <token id="17" string="Copley" />
            <token id="18" string="Square" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="Back" />
            <token id="22" string="Bay" />
            <token id="23" string="section" />
            <token id="24" string="of" />
            <token id="25" string="the" />
            <token id="26" string="city" />
          </tokens>
        </chunking>
        <chunking id="15" string="that begins in Hopkinton , west of Boston , and ends in Copley Square in the Back Bay section of the city" type="SBAR">
          <tokens>
            <token id="5" string="that" />
            <token id="6" string="begins" />
            <token id="7" string="in" />
            <token id="8" string="Hopkinton" />
            <token id="9" string="," />
            <token id="10" string="west" />
            <token id="11" string="of" />
            <token id="12" string="Boston" />
            <token id="13" string="," />
            <token id="14" string="and" />
            <token id="15" string="ends" />
            <token id="16" string="in" />
            <token id="17" string="Copley" />
            <token id="18" string="Square" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="Back" />
            <token id="22" string="Bay" />
            <token id="23" string="section" />
            <token id="24" string="of" />
            <token id="25" string="the" />
            <token id="26" string="city" />
          </tokens>
        </chunking>
        <chunking id="16" string="west" type="NP">
          <tokens>
            <token id="10" string="west" />
          </tokens>
        </chunking>
        <chunking id="17" string="fallen at an alarming rate" type="VP">
          <tokens>
            <token id="31" string="fallen" />
            <token id="32" string="at" />
            <token id="33" string="an" />
            <token id="34" string="alarming" />
            <token id="35" string="rate" />
          </tokens>
        </chunking>
        <chunking id="18" string="an alarming rate" type="NP">
          <tokens>
            <token id="33" string="an" />
            <token id="34" string="alarming" />
            <token id="35" string="rate" />
          </tokens>
        </chunking>
        <chunking id="19" string="Hopkinton , west of Boston" type="NP">
          <tokens>
            <token id="8" string="Hopkinton" />
            <token id="9" string="," />
            <token id="10" string="west" />
            <token id="11" string="of" />
            <token id="12" string="Boston" />
          </tokens>
        </chunking>
        <chunking id="20" string="Boston" type="NP">
          <tokens>
            <token id="12" string="Boston" />
          </tokens>
        </chunking>
        <chunking id="21" string="the Back Bay section" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="Back" />
            <token id="22" string="Bay" />
            <token id="23" string="section" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">route</governor>
          <dependent id="1">Along</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">route</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">route</governor>
          <dependent id="3">historic</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">fallen</governor>
          <dependent id="4">route</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">begins</governor>
          <dependent id="5">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="4">route</governor>
          <dependent id="6">begins</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">Hopkinton</governor>
          <dependent id="7">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">begins</governor>
          <dependent id="8">Hopkinton</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="8">Hopkinton</governor>
          <dependent id="10">west</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">Boston</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">west</governor>
          <dependent id="12">Boston</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">begins</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">begins</governor>
          <dependent id="15">ends</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">Square</governor>
          <dependent id="16">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Square</governor>
          <dependent id="17">Copley</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">ends</governor>
          <dependent id="18">Square</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">section</governor>
          <dependent id="19">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">section</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">section</governor>
          <dependent id="21">Back</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">section</governor>
          <dependent id="22">Bay</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">Square</governor>
          <dependent id="23">section</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">city</governor>
          <dependent id="24">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">city</governor>
          <dependent id="25">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">section</governor>
          <dependent id="26">city</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="29">records</governor>
          <dependent id="28">checkpoint</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="31">fallen</governor>
          <dependent id="29">records</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="31">fallen</governor>
          <dependent id="30">have</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="31">fallen</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">rate</governor>
          <dependent id="32">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="35">rate</governor>
          <dependent id="33">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="35">rate</governor>
          <dependent id="34">alarming</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">fallen</governor>
          <dependent id="35">rate</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Copley Square" type="LOCATION" score="0.0">
          <tokens>
            <token id="17" string="Copley" />
            <token id="18" string="Square" />
          </tokens>
        </entity>
        <entity id="2" string="Hopkinton" type="LOCATION" score="0.0">
          <tokens>
            <token id="8" string="Hopkinton" />
          </tokens>
        </entity>
        <entity id="3" string="Back Bay" type="LOCATION" score="0.0">
          <tokens>
            <token id="21" string="Back" />
            <token id="22" string="Bay" />
          </tokens>
        </entity>
        <entity id="4" string="Boston" type="LOCATION" score="0.0">
          <tokens>
            <token id="12" string="Boston" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>For example, all 11 checkpoint records were shattered through the first 20 miles last year, either by Simon Robert Naali or Juma Ikangaa, both of Tanzania.</content>
      <tokens>
        <token id="1" string="For" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="example" lemma="example" stem="exampl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="11" lemma="11" stem="11" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="6" string="checkpoint" lemma="checkpoint" stem="checkpoint" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="records" lemma="record" stem="record" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="shattered" lemma="shatter" stem="shatter" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="13" string="20" lemma="20" stem="20" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="14" string="miles" lemma="mile" stem="mile" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="16" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="either" lemma="either" stem="either" pos="CC" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="Simon" lemma="Simon" stem="simon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="21" string="Robert" lemma="Robert" stem="robert" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="22" string="Naali" lemma="Naali" stem="naali" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="23" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="Juma" lemma="Juma" stem="juma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="25" string="Ikangaa" lemma="Ikangaa" stem="ikangaa" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="26" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="both" lemma="both" stem="both" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="Tanzania" lemma="Tanzania" stem="tanzania" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN For) (NP (NN example))) (, ,) (NP (DT all) (CD 11) (NN checkpoint) (NNS records)) (VP (VBD were) (VP (VBN shattered) (PP (PP (IN through) (NP (DT the) (JJ first) (CD 20) (NNS miles)) (NP-TMP (JJ last) (NN year))) (, ,) (CC either) (PP (IN by) (NP (NNP Simon) (NNP Robert) (NNP Naali) (CC or) (NNP Juma) (NNP Ikangaa))) (, ,) (ADVP (DT both)) (PP (IN of) (NP (NNP Tanzania)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Tanzania" type="NP">
          <tokens>
            <token id="29" string="Tanzania" />
          </tokens>
        </chunking>
        <chunking id="2" string="were shattered through the first 20 miles last year , either by Simon Robert Naali or Juma Ikangaa , both of Tanzania" type="VP">
          <tokens>
            <token id="8" string="were" />
            <token id="9" string="shattered" />
            <token id="10" string="through" />
            <token id="11" string="the" />
            <token id="12" string="first" />
            <token id="13" string="20" />
            <token id="14" string="miles" />
            <token id="15" string="last" />
            <token id="16" string="year" />
            <token id="17" string="," />
            <token id="18" string="either" />
            <token id="19" string="by" />
            <token id="20" string="Simon" />
            <token id="21" string="Robert" />
            <token id="22" string="Naali" />
            <token id="23" string="or" />
            <token id="24" string="Juma" />
            <token id="25" string="Ikangaa" />
            <token id="26" string="," />
            <token id="27" string="both" />
            <token id="28" string="of" />
            <token id="29" string="Tanzania" />
          </tokens>
        </chunking>
        <chunking id="3" string="all 11 checkpoint records" type="NP">
          <tokens>
            <token id="4" string="all" />
            <token id="5" string="11" />
            <token id="6" string="checkpoint" />
            <token id="7" string="records" />
          </tokens>
        </chunking>
        <chunking id="4" string="the first 20 miles" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="first" />
            <token id="13" string="20" />
            <token id="14" string="miles" />
          </tokens>
        </chunking>
        <chunking id="5" string="example" type="NP">
          <tokens>
            <token id="2" string="example" />
          </tokens>
        </chunking>
        <chunking id="6" string="shattered through the first 20 miles last year , either by Simon Robert Naali or Juma Ikangaa , both of Tanzania" type="VP">
          <tokens>
            <token id="9" string="shattered" />
            <token id="10" string="through" />
            <token id="11" string="the" />
            <token id="12" string="first" />
            <token id="13" string="20" />
            <token id="14" string="miles" />
            <token id="15" string="last" />
            <token id="16" string="year" />
            <token id="17" string="," />
            <token id="18" string="either" />
            <token id="19" string="by" />
            <token id="20" string="Simon" />
            <token id="21" string="Robert" />
            <token id="22" string="Naali" />
            <token id="23" string="or" />
            <token id="24" string="Juma" />
            <token id="25" string="Ikangaa" />
            <token id="26" string="," />
            <token id="27" string="both" />
            <token id="28" string="of" />
            <token id="29" string="Tanzania" />
          </tokens>
        </chunking>
        <chunking id="7" string="Simon Robert Naali or Juma Ikangaa" type="NP">
          <tokens>
            <token id="20" string="Simon" />
            <token id="21" string="Robert" />
            <token id="22" string="Naali" />
            <token id="23" string="or" />
            <token id="24" string="Juma" />
            <token id="25" string="Ikangaa" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">example</governor>
          <dependent id="1">For</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">shattered</governor>
          <dependent id="2">example</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">records</governor>
          <dependent id="4">all</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="7">records</governor>
          <dependent id="5">11</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">records</governor>
          <dependent id="6">checkpoint</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="9">shattered</governor>
          <dependent id="7">records</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="9">shattered</governor>
          <dependent id="8">were</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">shattered</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">miles</governor>
          <dependent id="10">through</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">miles</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">miles</governor>
          <dependent id="12">first</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="14">miles</governor>
          <dependent id="13">20</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">both</governor>
          <dependent id="14">miles</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">year</governor>
          <dependent id="15">last</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="14">miles</governor>
          <dependent id="16">year</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="27">both</governor>
          <dependent id="18">either</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">Naali</governor>
          <dependent id="19">by</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">Naali</governor>
          <dependent id="20">Simon</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">Naali</governor>
          <dependent id="21">Robert</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="27">both</governor>
          <dependent id="22">Naali</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="22">Naali</governor>
          <dependent id="23">or</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">Ikangaa</governor>
          <dependent id="24">Juma</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="22">Naali</governor>
          <dependent id="25">Ikangaa</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">shattered</governor>
          <dependent id="27">both</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">Tanzania</governor>
          <dependent id="28">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">both</governor>
          <dependent id="29">Tanzania</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="12" string="first" />
          </tokens>
        </entity>
        <entity id="2" string="Tanzania" type="LOCATION" score="0.0">
          <tokens>
            <token id="29" string="Tanzania" />
          </tokens>
        </entity>
        <entity id="3" string="Juma Ikangaa" type="PERSON" score="0.0">
          <tokens>
            <token id="24" string="Juma" />
            <token id="25" string="Ikangaa" />
          </tokens>
        </entity>
        <entity id="4" string="Simon Robert Naali" type="PERSON" score="0.0">
          <tokens>
            <token id="20" string="Simon" />
            <token id="21" string="Robert" />
            <token id="22" string="Naali" />
          </tokens>
        </entity>
        <entity id="5" string="20" type="NUMBER" score="0.0">
          <tokens>
            <token id="13" string="20" />
          </tokens>
        </entity>
        <entity id="6" string="last year" type="DATE" score="0.0">
          <tokens>
            <token id="15" string="last" />
            <token id="16" string="year" />
          </tokens>
        </entity>
        <entity id="7" string="11" type="NUMBER" score="0.0">
          <tokens>
            <token id="5" string="11" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="11" has_coreference="false">
      <content>Neither won.</content>
      <tokens>
        <token id="1" string="Neither" lemma="neither" stem="neither" pos="DT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="won" lemma="win" stem="won" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT Neither)) (VP (VBD won)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="won" type="VP">
          <tokens>
            <token id="2" string="won" />
          </tokens>
        </chunking>
        <chunking id="2" string="Neither" type="NP">
          <tokens>
            <token id="1" string="Neither" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">won</governor>
          <dependent id="1">Neither</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">won</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>The winner was 1988 Olympic champion Gelindo Bordin, who outsmarted the early pacesetters by running a patient, calculating race.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="winner" lemma="winner" stem="winner" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="1988" lemma="1988" stem="1988" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="5" string="Olympic" lemma="Olympic" stem="olympic" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="6" string="champion" lemma="champion" stem="champion" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="Gelindo" lemma="Gelindo" stem="gelindo" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="8" string="Bordin" lemma="Bordin" stem="bordin" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="outsmarted" lemma="outsmart" stem="outsmart" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="early" lemma="early" stem="earli" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="pacesetters" lemma="pacesetter" stem="pacesett" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="running" lemma="run" stem="run" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="patient" lemma="patient" stem="patient" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="calculating" lemma="calculate" stem="calcul" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="race" lemma="race" stem="race" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN winner)) (VP (VBD was) (NP (NP (NP (CD 1988)) (NP (NNP Olympic) (NN champion) (NNP Gelindo) (NNP Bordin))) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBD outsmarted) (NP (DT the) (JJ early) (NNS pacesetters)) (PP (IN by) (S (VP (VBG running) (NP (DT a) (NN patient))))) (, ,) (S (VP (VBG calculating) (NP (NN race))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a patient" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="patient" />
          </tokens>
        </chunking>
        <chunking id="2" string="calculating race" type="VP">
          <tokens>
            <token id="20" string="calculating" />
            <token id="21" string="race" />
          </tokens>
        </chunking>
        <chunking id="3" string="race" type="NP">
          <tokens>
            <token id="21" string="race" />
          </tokens>
        </chunking>
        <chunking id="4" string="running a patient" type="VP">
          <tokens>
            <token id="16" string="running" />
            <token id="17" string="a" />
            <token id="18" string="patient" />
          </tokens>
        </chunking>
        <chunking id="5" string="1988" type="NP">
          <tokens>
            <token id="4" string="1988" />
          </tokens>
        </chunking>
        <chunking id="6" string="Olympic champion Gelindo Bordin" type="NP">
          <tokens>
            <token id="5" string="Olympic" />
            <token id="6" string="champion" />
            <token id="7" string="Gelindo" />
            <token id="8" string="Bordin" />
          </tokens>
        </chunking>
        <chunking id="7" string="the early pacesetters" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="early" />
            <token id="14" string="pacesetters" />
          </tokens>
        </chunking>
        <chunking id="8" string="was 1988 Olympic champion Gelindo Bordin , who outsmarted the early pacesetters by running a patient , calculating race" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="1988" />
            <token id="5" string="Olympic" />
            <token id="6" string="champion" />
            <token id="7" string="Gelindo" />
            <token id="8" string="Bordin" />
            <token id="9" string="," />
            <token id="10" string="who" />
            <token id="11" string="outsmarted" />
            <token id="12" string="the" />
            <token id="13" string="early" />
            <token id="14" string="pacesetters" />
            <token id="15" string="by" />
            <token id="16" string="running" />
            <token id="17" string="a" />
            <token id="18" string="patient" />
            <token id="19" string="," />
            <token id="20" string="calculating" />
            <token id="21" string="race" />
          </tokens>
        </chunking>
        <chunking id="9" string="1988 Olympic champion Gelindo Bordin , who outsmarted the early pacesetters by running a patient , calculating race" type="NP">
          <tokens>
            <token id="4" string="1988" />
            <token id="5" string="Olympic" />
            <token id="6" string="champion" />
            <token id="7" string="Gelindo" />
            <token id="8" string="Bordin" />
            <token id="9" string="," />
            <token id="10" string="who" />
            <token id="11" string="outsmarted" />
            <token id="12" string="the" />
            <token id="13" string="early" />
            <token id="14" string="pacesetters" />
            <token id="15" string="by" />
            <token id="16" string="running" />
            <token id="17" string="a" />
            <token id="18" string="patient" />
            <token id="19" string="," />
            <token id="20" string="calculating" />
            <token id="21" string="race" />
          </tokens>
        </chunking>
        <chunking id="10" string="1988 Olympic champion Gelindo Bordin" type="NP">
          <tokens>
            <token id="4" string="1988" />
            <token id="5" string="Olympic" />
            <token id="6" string="champion" />
            <token id="7" string="Gelindo" />
            <token id="8" string="Bordin" />
          </tokens>
        </chunking>
        <chunking id="11" string="outsmarted the early pacesetters by running a patient , calculating race" type="VP">
          <tokens>
            <token id="11" string="outsmarted" />
            <token id="12" string="the" />
            <token id="13" string="early" />
            <token id="14" string="pacesetters" />
            <token id="15" string="by" />
            <token id="16" string="running" />
            <token id="17" string="a" />
            <token id="18" string="patient" />
            <token id="19" string="," />
            <token id="20" string="calculating" />
            <token id="21" string="race" />
          </tokens>
        </chunking>
        <chunking id="12" string="The winner" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="winner" />
          </tokens>
        </chunking>
        <chunking id="13" string="who outsmarted the early pacesetters by running a patient , calculating race" type="SBAR">
          <tokens>
            <token id="10" string="who" />
            <token id="11" string="outsmarted" />
            <token id="12" string="the" />
            <token id="13" string="early" />
            <token id="14" string="pacesetters" />
            <token id="15" string="by" />
            <token id="16" string="running" />
            <token id="17" string="a" />
            <token id="18" string="patient" />
            <token id="19" string="," />
            <token id="20" string="calculating" />
            <token id="21" string="race" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">winner</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">1988</governor>
          <dependent id="2">winner</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">1988</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">1988</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">Bordin</governor>
          <dependent id="5">Olympic</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">Bordin</governor>
          <dependent id="6">champion</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">Bordin</governor>
          <dependent id="7">Gelindo</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="4">1988</governor>
          <dependent id="8">Bordin</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">outsmarted</governor>
          <dependent id="10">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="4">1988</governor>
          <dependent id="11">outsmarted</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">pacesetters</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">pacesetters</governor>
          <dependent id="13">early</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">outsmarted</governor>
          <dependent id="14">pacesetters</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">running</governor>
          <dependent id="15">by</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="11">outsmarted</governor>
          <dependent id="16">running</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">patient</governor>
          <dependent id="17">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">running</governor>
          <dependent id="18">patient</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="11">outsmarted</governor>
          <dependent id="20">calculating</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">calculating</governor>
          <dependent id="21">race</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1988" type="DATE" score="0.0">
          <tokens>
            <token id="4" string="1988" />
          </tokens>
        </entity>
        <entity id="2" string="Olympic" type="MISC" score="0.0">
          <tokens>
            <token id="5" string="Olympic" />
          </tokens>
        </entity>
        <entity id="3" string="Gelindo Bordin" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Gelindo" />
            <token id="8" string="Bordin" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>Running alone about 200 meters behind a pack of six Africans, Bordin passed them all by 21 miles and went on to win in 2 hours, 8 minutes, 19 seconds, the second-fastest time in the race&amp;apost;s history, behind only the 2:07:51 by Rob de Castella in 1986.</content>
      <tokens>
        <token id="1" string="Running" lemma="run" stem="run" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="alone" lemma="alone" stem="alon" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="about" lemma="about" stem="about" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="200" lemma="200" stem="200" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="5" string="meters" lemma="meter" stem="meter" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="behind" lemma="behind" stem="behind" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="pack" lemma="pack" stem="pack" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="six" lemma="six" stem="six" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="11" string="Africans" lemma="african" stem="african" pos="NNS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Bordin" lemma="Bordin" stem="bordin" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="14" string="passed" lemma="pass" stem="pass" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="21" lemma="21" stem="21" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="19" string="miles" lemma="mile" stem="mile" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="went" lemma="go" stem="went" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="win" lemma="win" stem="win" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="2" lemma="2" stem="2" pos="CD" type="Number" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="27" string="hours" lemma="hour" stem="hour" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="28" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="8" lemma="8" stem="8" pos="CD" type="Number" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="30" string="minutes" lemma="minute" stem="minut" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="31" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="19" lemma="19" stem="19" pos="CD" type="Number" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="33" string="seconds" lemma="seconds" stem="second" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="34" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="second-fastest" lemma="second-fastest" stem="second-fastest" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="40" string="race" lemma="race" stem="race" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="41" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="42" string="history" lemma="history" stem="histori" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="43" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="behind" lemma="behind" stem="behind" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="45" string="only" lemma="only" stem="onli" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="46" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="47" string="2:07:51" lemma="2:07:51" stem="2:07:51" pos="CD" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="48" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="49" string="Rob" lemma="Rob" stem="rob" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="50" string="de" lemma="de" stem="de" pos="IN" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="51" string="Castella" lemma="Castella" stem="castella" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="52" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="53" string="1986" lemma="1986" stem="1986" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="54" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (VBG Running) (ADVP (RB alone) (NP (QP (RB about) (CD 200)) (NNS meters))) (PP (IN behind) (NP (NP (DT a) (NN pack)) (PP (IN of) (NP (CD six) (NNS Africans))))))) (, ,) (NP (NNP Bordin)) (VP (VP (VBD passed) (NP (PRP them)) (PP (DT all) (IN by) (NP (CD 21) (NNS miles)))) (CC and) (VP (VBD went) (PRT (IN on)) (S (VP (TO to) (VP (VB win) (PP (IN in) (NP (NP (CD 2) (NNS hours)) (, ,) (NP (NP (CD 8) (NNS minutes)) (, ,) (NP (CD 19) (NNS seconds)) (, ,) (NP (NP (DT the) (JJS second-fastest) (NN time)) (PP (IN in) (NP (NP (DT the) (NN race) (POS 's)) (NN history)))) (, ,) (PP (IN behind) (NP (QP (RB only) (DT the) (CD 2:07:51))))))) (PP (IN by) (NP (NP (NNP Rob) (IN de) (NNP Castella)) (PP (IN in) (NP (CD 1986)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="six Africans" type="NP">
          <tokens>
            <token id="10" string="six" />
            <token id="11" string="Africans" />
          </tokens>
        </chunking>
        <chunking id="2" string="2 hours" type="NP">
          <tokens>
            <token id="26" string="2" />
            <token id="27" string="hours" />
          </tokens>
        </chunking>
        <chunking id="3" string="8 minutes" type="NP">
          <tokens>
            <token id="29" string="8" />
            <token id="30" string="minutes" />
          </tokens>
        </chunking>
        <chunking id="4" string="the race 's" type="NP">
          <tokens>
            <token id="39" string="the" />
            <token id="40" string="race" />
            <token id="41" string="'s" />
          </tokens>
        </chunking>
        <chunking id="5" string="to win in 2 hours , 8 minutes , 19 seconds , the second-fastest time in the race 's history , behind only the 2:07:51 by Rob de Castella in 1986" type="VP">
          <tokens>
            <token id="23" string="to" />
            <token id="24" string="win" />
            <token id="25" string="in" />
            <token id="26" string="2" />
            <token id="27" string="hours" />
            <token id="28" string="," />
            <token id="29" string="8" />
            <token id="30" string="minutes" />
            <token id="31" string="," />
            <token id="32" string="19" />
            <token id="33" string="seconds" />
            <token id="34" string="," />
            <token id="35" string="the" />
            <token id="36" string="second-fastest" />
            <token id="37" string="time" />
            <token id="38" string="in" />
            <token id="39" string="the" />
            <token id="40" string="race" />
            <token id="41" string="'s" />
            <token id="42" string="history" />
            <token id="43" string="," />
            <token id="44" string="behind" />
            <token id="45" string="only" />
            <token id="46" string="the" />
            <token id="47" string="2:07:51" />
            <token id="48" string="by" />
            <token id="49" string="Rob" />
            <token id="50" string="de" />
            <token id="51" string="Castella" />
            <token id="52" string="in" />
            <token id="53" string="1986" />
          </tokens>
        </chunking>
        <chunking id="6" string="2 hours , 8 minutes , 19 seconds , the second-fastest time in the race 's history , behind only the 2:07:51" type="NP">
          <tokens>
            <token id="26" string="2" />
            <token id="27" string="hours" />
            <token id="28" string="," />
            <token id="29" string="8" />
            <token id="30" string="minutes" />
            <token id="31" string="," />
            <token id="32" string="19" />
            <token id="33" string="seconds" />
            <token id="34" string="," />
            <token id="35" string="the" />
            <token id="36" string="second-fastest" />
            <token id="37" string="time" />
            <token id="38" string="in" />
            <token id="39" string="the" />
            <token id="40" string="race" />
            <token id="41" string="'s" />
            <token id="42" string="history" />
            <token id="43" string="," />
            <token id="44" string="behind" />
            <token id="45" string="only" />
            <token id="46" string="the" />
            <token id="47" string="2:07:51" />
          </tokens>
        </chunking>
        <chunking id="7" string="them" type="NP">
          <tokens>
            <token id="15" string="them" />
          </tokens>
        </chunking>
        <chunking id="8" string="Rob de Castella in 1986" type="NP">
          <tokens>
            <token id="49" string="Rob" />
            <token id="50" string="de" />
            <token id="51" string="Castella" />
            <token id="52" string="in" />
            <token id="53" string="1986" />
          </tokens>
        </chunking>
        <chunking id="9" string="Bordin" type="NP">
          <tokens>
            <token id="13" string="Bordin" />
          </tokens>
        </chunking>
        <chunking id="10" string="1986" type="NP">
          <tokens>
            <token id="53" string="1986" />
          </tokens>
        </chunking>
        <chunking id="11" string="a pack of six Africans" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="pack" />
            <token id="9" string="of" />
            <token id="10" string="six" />
            <token id="11" string="Africans" />
          </tokens>
        </chunking>
        <chunking id="12" string="the second-fastest time" type="NP">
          <tokens>
            <token id="35" string="the" />
            <token id="36" string="second-fastest" />
            <token id="37" string="time" />
          </tokens>
        </chunking>
        <chunking id="13" string="Running alone about 200 meters behind a pack of six Africans" type="VP">
          <tokens>
            <token id="1" string="Running" />
            <token id="2" string="alone" />
            <token id="3" string="about" />
            <token id="4" string="200" />
            <token id="5" string="meters" />
            <token id="6" string="behind" />
            <token id="7" string="a" />
            <token id="8" string="pack" />
            <token id="9" string="of" />
            <token id="10" string="six" />
            <token id="11" string="Africans" />
          </tokens>
        </chunking>
        <chunking id="14" string="went on to win in 2 hours , 8 minutes , 19 seconds , the second-fastest time in the race 's history , behind only the 2:07:51 by Rob de Castella in 1986" type="VP">
          <tokens>
            <token id="21" string="went" />
            <token id="22" string="on" />
            <token id="23" string="to" />
            <token id="24" string="win" />
            <token id="25" string="in" />
            <token id="26" string="2" />
            <token id="27" string="hours" />
            <token id="28" string="," />
            <token id="29" string="8" />
            <token id="30" string="minutes" />
            <token id="31" string="," />
            <token id="32" string="19" />
            <token id="33" string="seconds" />
            <token id="34" string="," />
            <token id="35" string="the" />
            <token id="36" string="second-fastest" />
            <token id="37" string="time" />
            <token id="38" string="in" />
            <token id="39" string="the" />
            <token id="40" string="race" />
            <token id="41" string="'s" />
            <token id="42" string="history" />
            <token id="43" string="," />
            <token id="44" string="behind" />
            <token id="45" string="only" />
            <token id="46" string="the" />
            <token id="47" string="2:07:51" />
            <token id="48" string="by" />
            <token id="49" string="Rob" />
            <token id="50" string="de" />
            <token id="51" string="Castella" />
            <token id="52" string="in" />
            <token id="53" string="1986" />
          </tokens>
        </chunking>
        <chunking id="15" string="about 200 meters" type="NP">
          <tokens>
            <token id="3" string="about" />
            <token id="4" string="200" />
            <token id="5" string="meters" />
          </tokens>
        </chunking>
        <chunking id="16" string="the race 's history" type="NP">
          <tokens>
            <token id="39" string="the" />
            <token id="40" string="race" />
            <token id="41" string="'s" />
            <token id="42" string="history" />
          </tokens>
        </chunking>
        <chunking id="17" string="21 miles" type="NP">
          <tokens>
            <token id="18" string="21" />
            <token id="19" string="miles" />
          </tokens>
        </chunking>
        <chunking id="18" string="only the 2:07:51" type="NP">
          <tokens>
            <token id="45" string="only" />
            <token id="46" string="the" />
            <token id="47" string="2:07:51" />
          </tokens>
        </chunking>
        <chunking id="19" string="a pack" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="pack" />
          </tokens>
        </chunking>
        <chunking id="20" string="the second-fastest time in the race 's history" type="NP">
          <tokens>
            <token id="35" string="the" />
            <token id="36" string="second-fastest" />
            <token id="37" string="time" />
            <token id="38" string="in" />
            <token id="39" string="the" />
            <token id="40" string="race" />
            <token id="41" string="'s" />
            <token id="42" string="history" />
          </tokens>
        </chunking>
        <chunking id="21" string="passed them all by 21 miles and went on to win in 2 hours , 8 minutes , 19 seconds , the second-fastest time in the race 's history , behind only the 2:07:51 by Rob de Castella in 1986" type="VP">
          <tokens>
            <token id="14" string="passed" />
            <token id="15" string="them" />
            <token id="16" string="all" />
            <token id="17" string="by" />
            <token id="18" string="21" />
            <token id="19" string="miles" />
            <token id="20" string="and" />
            <token id="21" string="went" />
            <token id="22" string="on" />
            <token id="23" string="to" />
            <token id="24" string="win" />
            <token id="25" string="in" />
            <token id="26" string="2" />
            <token id="27" string="hours" />
            <token id="28" string="," />
            <token id="29" string="8" />
            <token id="30" string="minutes" />
            <token id="31" string="," />
            <token id="32" string="19" />
            <token id="33" string="seconds" />
            <token id="34" string="," />
            <token id="35" string="the" />
            <token id="36" string="second-fastest" />
            <token id="37" string="time" />
            <token id="38" string="in" />
            <token id="39" string="the" />
            <token id="40" string="race" />
            <token id="41" string="'s" />
            <token id="42" string="history" />
            <token id="43" string="," />
            <token id="44" string="behind" />
            <token id="45" string="only" />
            <token id="46" string="the" />
            <token id="47" string="2:07:51" />
            <token id="48" string="by" />
            <token id="49" string="Rob" />
            <token id="50" string="de" />
            <token id="51" string="Castella" />
            <token id="52" string="in" />
            <token id="53" string="1986" />
          </tokens>
        </chunking>
        <chunking id="22" string="8 minutes , 19 seconds , the second-fastest time in the race 's history , behind only the 2:07:51" type="NP">
          <tokens>
            <token id="29" string="8" />
            <token id="30" string="minutes" />
            <token id="31" string="," />
            <token id="32" string="19" />
            <token id="33" string="seconds" />
            <token id="34" string="," />
            <token id="35" string="the" />
            <token id="36" string="second-fastest" />
            <token id="37" string="time" />
            <token id="38" string="in" />
            <token id="39" string="the" />
            <token id="40" string="race" />
            <token id="41" string="'s" />
            <token id="42" string="history" />
            <token id="43" string="," />
            <token id="44" string="behind" />
            <token id="45" string="only" />
            <token id="46" string="the" />
            <token id="47" string="2:07:51" />
          </tokens>
        </chunking>
        <chunking id="23" string="win in 2 hours , 8 minutes , 19 seconds , the second-fastest time in the race 's history , behind only the 2:07:51 by Rob de Castella in 1986" type="VP">
          <tokens>
            <token id="24" string="win" />
            <token id="25" string="in" />
            <token id="26" string="2" />
            <token id="27" string="hours" />
            <token id="28" string="," />
            <token id="29" string="8" />
            <token id="30" string="minutes" />
            <token id="31" string="," />
            <token id="32" string="19" />
            <token id="33" string="seconds" />
            <token id="34" string="," />
            <token id="35" string="the" />
            <token id="36" string="second-fastest" />
            <token id="37" string="time" />
            <token id="38" string="in" />
            <token id="39" string="the" />
            <token id="40" string="race" />
            <token id="41" string="'s" />
            <token id="42" string="history" />
            <token id="43" string="," />
            <token id="44" string="behind" />
            <token id="45" string="only" />
            <token id="46" string="the" />
            <token id="47" string="2:07:51" />
            <token id="48" string="by" />
            <token id="49" string="Rob" />
            <token id="50" string="de" />
            <token id="51" string="Castella" />
            <token id="52" string="in" />
            <token id="53" string="1986" />
          </tokens>
        </chunking>
        <chunking id="24" string="passed them all by 21 miles" type="VP">
          <tokens>
            <token id="14" string="passed" />
            <token id="15" string="them" />
            <token id="16" string="all" />
            <token id="17" string="by" />
            <token id="18" string="21" />
            <token id="19" string="miles" />
          </tokens>
        </chunking>
        <chunking id="25" string="19 seconds" type="NP">
          <tokens>
            <token id="32" string="19" />
            <token id="33" string="seconds" />
          </tokens>
        </chunking>
        <chunking id="26" string="Rob de Castella" type="NP">
          <tokens>
            <token id="49" string="Rob" />
            <token id="50" string="de" />
            <token id="51" string="Castella" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advcl">
          <governor id="14">passed</governor>
          <dependent id="1">Running</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="1">Running</governor>
          <dependent id="2">alone</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">200</governor>
          <dependent id="3">about</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="5">meters</governor>
          <dependent id="4">200</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="2">alone</governor>
          <dependent id="5">meters</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">pack</governor>
          <dependent id="6">behind</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">pack</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Running</governor>
          <dependent id="8">pack</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Africans</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="11">Africans</governor>
          <dependent id="10">six</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">pack</governor>
          <dependent id="11">Africans</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">passed</governor>
          <dependent id="13">Bordin</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">passed</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">passed</governor>
          <dependent id="15">them</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="19">miles</governor>
          <dependent id="16">all</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">miles</governor>
          <dependent id="17">by</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="19">miles</governor>
          <dependent id="18">21</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">passed</governor>
          <dependent id="19">miles</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="14">passed</governor>
          <dependent id="20">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">passed</governor>
          <dependent id="21">went</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="21">went</governor>
          <dependent id="22">on</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="24">win</governor>
          <dependent id="23">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="21">went</governor>
          <dependent id="24">win</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">hours</governor>
          <dependent id="25">in</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="27">hours</governor>
          <dependent id="26">2</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">win</governor>
          <dependent id="27">hours</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="30">minutes</governor>
          <dependent id="29">8</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="27">hours</governor>
          <dependent id="30">minutes</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="33">seconds</governor>
          <dependent id="32">19</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="30">minutes</governor>
          <dependent id="33">seconds</dependent>
        </dependency>
        <dependency type="det">
          <governor id="37">time</governor>
          <dependent id="35">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="37">time</governor>
          <dependent id="36">second-fastest</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="30">minutes</governor>
          <dependent id="37">time</dependent>
        </dependency>
        <dependency type="case">
          <governor id="42">history</governor>
          <dependent id="38">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="40">race</governor>
          <dependent id="39">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="42">history</governor>
          <dependent id="40">race</dependent>
        </dependency>
        <dependency type="case">
          <governor id="40">race</governor>
          <dependent id="41">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="37">time</governor>
          <dependent id="42">history</dependent>
        </dependency>
        <dependency type="case">
          <governor id="47">2:07:51</governor>
          <dependent id="44">behind</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="47">2:07:51</governor>
          <dependent id="45">only</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="47">2:07:51</governor>
          <dependent id="46">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">minutes</governor>
          <dependent id="47">2:07:51</dependent>
        </dependency>
        <dependency type="case">
          <governor id="51">Castella</governor>
          <dependent id="48">by</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="51">Castella</governor>
          <dependent id="49">Rob</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="51">Castella</governor>
          <dependent id="50">de</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">win</governor>
          <dependent id="51">Castella</dependent>
        </dependency>
        <dependency type="case">
          <governor id="53">1986</governor>
          <dependent id="52">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="51">Castella</governor>
          <dependent id="53">1986</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="six" type="NUMBER" score="0.0">
          <tokens>
            <token id="10" string="six" />
          </tokens>
        </entity>
        <entity id="2" string="2 hours" type="DURATION" score="0.0">
          <tokens>
            <token id="26" string="2" />
            <token id="27" string="hours" />
          </tokens>
        </entity>
        <entity id="3" string="200" type="NUMBER" score="0.0">
          <tokens>
            <token id="4" string="200" />
          </tokens>
        </entity>
        <entity id="4" string="8 minutes" type="DURATION" score="0.0">
          <tokens>
            <token id="29" string="8" />
            <token id="30" string="minutes" />
          </tokens>
        </entity>
        <entity id="5" string="Bordin" type="PERSON" score="0.0">
          <tokens>
            <token id="13" string="Bordin" />
          </tokens>
        </entity>
        <entity id="6" string="1986" type="DATE" score="0.0">
          <tokens>
            <token id="53" string="1986" />
          </tokens>
        </entity>
        <entity id="7" string="Africans" type="MISC" score="0.0">
          <tokens>
            <token id="11" string="Africans" />
          </tokens>
        </entity>
        <entity id="8" string="19 seconds" type="DURATION" score="0.0">
          <tokens>
            <token id="32" string="19" />
            <token id="33" string="seconds" />
          </tokens>
        </entity>
        <entity id="9" string="2:07:51" type="TIME" score="0.0">
          <tokens>
            <token id="47" string="2:07:51" />
          </tokens>
        </entity>
        <entity id="10" string="Rob de Castella" type="PERSON" score="0.0">
          <tokens>
            <token id="49" string="Rob" />
            <token id="50" string="de" />
            <token id="51" string="Castella" />
          </tokens>
        </entity>
        <entity id="11" string="21" type="NUMBER" score="0.0">
          <tokens>
            <token id="18" string="21" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>Ikangaa finished a distant second in 2:09:52.</content>
      <tokens>
        <token id="1" string="Ikangaa" lemma="Ikangaa" stem="ikangaa" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="finished" lemma="finish" stem="finish" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="distant" lemma="distant" stem="distant" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="second" lemma="second" stem="second" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="6" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="7" string="2:09:52" lemma="2:09:52" stem="2:09:52" pos="CD" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Ikangaa)) (VP (VBD finished) (NP (DT a) (JJ distant) (JJ second)) (PP (IN in) (NP (CD 2:09:52)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Ikangaa" type="NP">
          <tokens>
            <token id="1" string="Ikangaa" />
          </tokens>
        </chunking>
        <chunking id="2" string="a distant second" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="distant" />
            <token id="5" string="second" />
          </tokens>
        </chunking>
        <chunking id="3" string="2:09:52" type="NP">
          <tokens>
            <token id="7" string="2:09:52" />
          </tokens>
        </chunking>
        <chunking id="4" string="finished a distant second in 2:09:52" type="VP">
          <tokens>
            <token id="2" string="finished" />
            <token id="3" string="a" />
            <token id="4" string="distant" />
            <token id="5" string="second" />
            <token id="6" string="in" />
            <token id="7" string="2:09:52" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">finished</governor>
          <dependent id="1">Ikangaa</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">finished</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">second</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">second</governor>
          <dependent id="4">distant</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">finished</governor>
          <dependent id="5">second</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">2:09:52</governor>
          <dependent id="6">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">finished</governor>
          <dependent id="7">2:09:52</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ikangaa" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Ikangaa" />
          </tokens>
        </entity>
        <entity id="2" string="second in 2:09:52" type="DATE" score="0.0">
          <tokens>
            <token id="5" string="second" />
            <token id="6" string="in" />
            <token id="7" string="2:09:52" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>It was his third consecutive runner-up finish in Boston.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="third" lemma="third" stem="third" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="true" is_refers="true" />
        <token id="5" string="consecutive" lemma="consecutive" stem="consecut" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="runner-up" lemma="runner-up" stem="runner-up" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="finish" lemma="finish" stem="finish" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="Boston" lemma="Boston" stem="boston" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP It)) (VP (VBD was) (NP (NP (PRP$ his) (JJ third) (JJ consecutive) (NN runner-up) (NN finish)) (PP (IN in) (NP (NNP Boston))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="his third consecutive runner-up finish in Boston" type="NP">
          <tokens>
            <token id="3" string="his" />
            <token id="4" string="third" />
            <token id="5" string="consecutive" />
            <token id="6" string="runner-up" />
            <token id="7" string="finish" />
            <token id="8" string="in" />
            <token id="9" string="Boston" />
          </tokens>
        </chunking>
        <chunking id="2" string="his third consecutive runner-up finish" type="NP">
          <tokens>
            <token id="3" string="his" />
            <token id="4" string="third" />
            <token id="5" string="consecutive" />
            <token id="6" string="runner-up" />
            <token id="7" string="finish" />
          </tokens>
        </chunking>
        <chunking id="3" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="4" string="was his third consecutive runner-up finish in Boston" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="his" />
            <token id="4" string="third" />
            <token id="5" string="consecutive" />
            <token id="6" string="runner-up" />
            <token id="7" string="finish" />
            <token id="8" string="in" />
            <token id="9" string="Boston" />
          </tokens>
        </chunking>
        <chunking id="5" string="Boston" type="NP">
          <tokens>
            <token id="9" string="Boston" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="7">finish</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">finish</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="7">finish</governor>
          <dependent id="3">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">finish</governor>
          <dependent id="4">third</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">finish</governor>
          <dependent id="5">consecutive</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">finish</governor>
          <dependent id="6">runner-up</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">finish</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Boston</governor>
          <dependent id="8">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">finish</governor>
          <dependent id="9">Boston</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="third" type="ORDINAL" score="0.0">
          <tokens>
            <token id="4" string="third" />
          </tokens>
        </entity>
        <entity id="2" string="Boston" type="LOCATION" score="0.0">
          <tokens>
            <token id="9" string="Boston" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>Ikangaa is back again, along with several other formidable Africans.</content>
      <tokens>
        <token id="1" string="Ikangaa" lemma="Ikangaa" stem="ikangaa" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="back" lemma="back" stem="back" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="again" lemma="again" stem="again" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="along" lemma="along" stem="along" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="several" lemma="several" stem="sever" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="formidable" lemma="formidable" stem="formid" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="Africans" lemma="african" stem="african" pos="NNS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Ikangaa)) (VP (VBZ is) (ADVP (RB back) (RB again)) (, ,) (ADVP (IN along) (PP (IN with) (NP (JJ several) (JJ other) (JJ formidable) (NNS Africans))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Ikangaa" type="NP">
          <tokens>
            <token id="1" string="Ikangaa" />
          </tokens>
        </chunking>
        <chunking id="2" string="several other formidable Africans" type="NP">
          <tokens>
            <token id="8" string="several" />
            <token id="9" string="other" />
            <token id="10" string="formidable" />
            <token id="11" string="Africans" />
          </tokens>
        </chunking>
        <chunking id="3" string="is back again , along with several other formidable Africans" type="VP">
          <tokens>
            <token id="2" string="is" />
            <token id="3" string="back" />
            <token id="4" string="again" />
            <token id="5" string="," />
            <token id="6" string="along" />
            <token id="7" string="with" />
            <token id="8" string="several" />
            <token id="9" string="other" />
            <token id="10" string="formidable" />
            <token id="11" string="Africans" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">is</governor>
          <dependent id="1">Ikangaa</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">again</governor>
          <dependent id="3">back</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="2">is</governor>
          <dependent id="4">again</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="2">is</governor>
          <dependent id="6">along</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Africans</governor>
          <dependent id="7">with</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">Africans</governor>
          <dependent id="8">several</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">Africans</governor>
          <dependent id="9">other</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">Africans</governor>
          <dependent id="10">formidable</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">along</governor>
          <dependent id="11">Africans</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ikangaa" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Ikangaa" />
          </tokens>
        </entity>
        <entity id="2" string="Africans" type="MISC" score="0.0">
          <tokens>
            <token id="11" string="Africans" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="17" has_coreference="true">
      <content>They include Ibrahim Hussein of Kenya, the 1988 winner in 2:08:43, the third-fastest time in Boston and one second ahead of Ikangaa; Abebe Mekonnen of Ethiopia, the 1989 champion in 2:09:06, Boston&amp;apost;s eighth-best time; Douglas Wakiihuri of Kenya, the 1987 world champion and 1988 Olympic silver medalist who is making his Boston debut; and Naali, the third-place finisher in the 1990 Commonwealth Games.</content>
      <tokens>
        <token id="1" string="They" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="include" lemma="include" stem="includ" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Ibrahim" lemma="Ibrahim" stem="ibrahim" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="4" string="Hussein" lemma="Hussein" stem="hussein" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="Kenya" lemma="Kenya" stem="kenya" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="1988" lemma="1988" stem="1988" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="10" string="winner" lemma="winner" stem="winner" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="2:08:43" lemma="2:08:43" stem="2:08:43" pos="CD" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="third-fastest" lemma="third-fastest" stem="third-fastest" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Boston" lemma="Boston" stem="boston" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="19" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="21" string="second" lemma="second" stem="second" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="22" string="ahead" lemma="ahead" stem="ahead" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="Ikangaa" lemma="Ikangaa" stem="ikangaa" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="25" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="Abebe" lemma="Abebe" stem="abebe" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="27" string="Mekonnen" lemma="Mekonnen" stem="mekonnen" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="28" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="Ethiopia" lemma="Ethiopia" stem="ethiopia" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="30" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="1989" lemma="1989" stem="1989" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="33" string="champion" lemma="champion" stem="champion" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="2:09:06" lemma="2:09:06" stem="2:09:06" pos="CD" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="36" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="Boston" lemma="Boston" stem="boston" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="38" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="39" string="eighth-best" lemma="eighth-best" stem="eighth-best" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="Douglas" lemma="Douglas" stem="dougla" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="43" string="Wakiihuri" lemma="Wakiihuri" stem="wakiihuri" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="44" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="Kenya" lemma="Kenya" stem="kenya" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="46" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="47" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="48" string="1987" lemma="1987" stem="1987" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="49" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="50" string="champion" lemma="champion" stem="champion" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="51" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="52" string="1988" lemma="1988" stem="1988" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="53" string="Olympic" lemma="Olympic" stem="olympic" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="54" string="silver" lemma="silver" stem="silver" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="55" string="medalist" lemma="medalist" stem="medalist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="56" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="57" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="58" string="making" lemma="make" stem="make" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="59" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="60" string="Boston" lemma="Boston" stem="boston" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="61" string="debut" lemma="debut" stem="debut" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="62" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="63" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="64" string="Naali" lemma="Naali" stem="naali" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="65" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="66" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="67" string="third-place" lemma="third-place" stem="third-plac" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="68" string="finisher" lemma="finisher" stem="finish" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="69" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="70" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="71" string="1990" lemma="1990" stem="1990" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="72" string="Commonwealth" lemma="Commonwealth" stem="commonwealth" pos="NNP" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="73" string="Games" lemma="Games" stem="game" pos="NNPS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="74" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP They)) (VP (VBP include) (NP (NP (NP (NNP Ibrahim) (NNP Hussein)) (PP (IN of) (NP (NNP Kenya)))) (, ,) (NP (NP (DT the) (CD 1988) (NN winner)) (PP (IN in) (NP (NP (CD 2:08:43)) (, ,) (NP (NP (DT the) (JJS third-fastest) (NN time)) (PP (IN in) (NP (NNP Boston)))) (CC and) (NP (NP (NP (CD one)) (ADJP (JJ second)) (ADVP (RB ahead)) (PP (IN of) (NP (NNP Ikangaa)))) (: ;) (NP (NP (NNP Abebe) (NNP Mekonnen)) (PP (IN of) (NP (NNP Ethiopia))) (, ,) (NP (NP (DT the) (CD 1989) (NN champion)) (PP (IN in) (NP (CD 2:09:06)))) (, ,) (NP (NP (NNP Boston) (POS 's)) (JJS eighth-best) (NN time))) (: ;) (NP (NP (NNP Douglas) (NNP Wakiihuri)) (PP (IN of) (NP (NP (NNP Kenya)) (, ,) (NP (DT the) (CD 1987) (NN world) (NN champion)) (CC and) (NP (CD 1988) (NNP Olympic) (NN silver) (NN medalist)))))))) (SBAR (WHNP (WP who)) (S (VP (VBZ is) (VP (VBG making) (NP (PRP$ his) (NNP Boston) (NN debut))))))) (: ;) (CC and) (NP (NP (NNP Naali)) (, ,) (NP (NP (DT the) (JJ third-place) (NN finisher)) (PP (IN in) (NP (DT the) (CD 1990) (NNP Commonwealth) (NNPS Games))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="They" type="NP">
          <tokens>
            <token id="1" string="They" />
          </tokens>
        </chunking>
        <chunking id="2" string="2:09:06" type="NP">
          <tokens>
            <token id="35" string="2:09:06" />
          </tokens>
        </chunking>
        <chunking id="3" string="one" type="NP">
          <tokens>
            <token id="20" string="one" />
          </tokens>
        </chunking>
        <chunking id="4" string="Abebe Mekonnen" type="NP">
          <tokens>
            <token id="26" string="Abebe" />
            <token id="27" string="Mekonnen" />
          </tokens>
        </chunking>
        <chunking id="5" string="the third-fastest time" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="third-fastest" />
            <token id="16" string="time" />
          </tokens>
        </chunking>
        <chunking id="6" string="the 1988 winner in 2:08:43 , the third-fastest time in Boston and one second ahead of Ikangaa ; Abebe Mekonnen of Ethiopia , the 1989 champion in 2:09:06 , Boston 's eighth-best time ; Douglas Wakiihuri of Kenya , the 1987 world champion and 1988 Olympic silver medalist who is making his Boston debut" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="1988" />
            <token id="10" string="winner" />
            <token id="11" string="in" />
            <token id="12" string="2:08:43" />
            <token id="13" string="," />
            <token id="14" string="the" />
            <token id="15" string="third-fastest" />
            <token id="16" string="time" />
            <token id="17" string="in" />
            <token id="18" string="Boston" />
            <token id="19" string="and" />
            <token id="20" string="one" />
            <token id="21" string="second" />
            <token id="22" string="ahead" />
            <token id="23" string="of" />
            <token id="24" string="Ikangaa" />
            <token id="25" string=";" />
            <token id="26" string="Abebe" />
            <token id="27" string="Mekonnen" />
            <token id="28" string="of" />
            <token id="29" string="Ethiopia" />
            <token id="30" string="," />
            <token id="31" string="the" />
            <token id="32" string="1989" />
            <token id="33" string="champion" />
            <token id="34" string="in" />
            <token id="35" string="2:09:06" />
            <token id="36" string="," />
            <token id="37" string="Boston" />
            <token id="38" string="'s" />
            <token id="39" string="eighth-best" />
            <token id="40" string="time" />
            <token id="41" string=";" />
            <token id="42" string="Douglas" />
            <token id="43" string="Wakiihuri" />
            <token id="44" string="of" />
            <token id="45" string="Kenya" />
            <token id="46" string="," />
            <token id="47" string="the" />
            <token id="48" string="1987" />
            <token id="49" string="world" />
            <token id="50" string="champion" />
            <token id="51" string="and" />
            <token id="52" string="1988" />
            <token id="53" string="Olympic" />
            <token id="54" string="silver" />
            <token id="55" string="medalist" />
            <token id="56" string="who" />
            <token id="57" string="is" />
            <token id="58" string="making" />
            <token id="59" string="his" />
            <token id="60" string="Boston" />
            <token id="61" string="debut" />
          </tokens>
        </chunking>
        <chunking id="7" string="Kenya" type="NP">
          <tokens>
            <token id="6" string="Kenya" />
          </tokens>
        </chunking>
        <chunking id="8" string="who is making his Boston debut" type="SBAR">
          <tokens>
            <token id="56" string="who" />
            <token id="57" string="is" />
            <token id="58" string="making" />
            <token id="59" string="his" />
            <token id="60" string="Boston" />
            <token id="61" string="debut" />
          </tokens>
        </chunking>
        <chunking id="9" string="the third-place finisher" type="NP">
          <tokens>
            <token id="66" string="the" />
            <token id="67" string="third-place" />
            <token id="68" string="finisher" />
          </tokens>
        </chunking>
        <chunking id="10" string="Ibrahim Hussein of Kenya" type="NP">
          <tokens>
            <token id="3" string="Ibrahim" />
            <token id="4" string="Hussein" />
            <token id="5" string="of" />
            <token id="6" string="Kenya" />
          </tokens>
        </chunking>
        <chunking id="11" string="his Boston debut" type="NP">
          <tokens>
            <token id="59" string="his" />
            <token id="60" string="Boston" />
            <token id="61" string="debut" />
          </tokens>
        </chunking>
        <chunking id="12" string="one second ahead of Ikangaa ; Abebe Mekonnen of Ethiopia , the 1989 champion in 2:09:06 , Boston 's eighth-best time ; Douglas Wakiihuri of Kenya , the 1987 world champion and 1988 Olympic silver medalist" type="NP">
          <tokens>
            <token id="20" string="one" />
            <token id="21" string="second" />
            <token id="22" string="ahead" />
            <token id="23" string="of" />
            <token id="24" string="Ikangaa" />
            <token id="25" string=";" />
            <token id="26" string="Abebe" />
            <token id="27" string="Mekonnen" />
            <token id="28" string="of" />
            <token id="29" string="Ethiopia" />
            <token id="30" string="," />
            <token id="31" string="the" />
            <token id="32" string="1989" />
            <token id="33" string="champion" />
            <token id="34" string="in" />
            <token id="35" string="2:09:06" />
            <token id="36" string="," />
            <token id="37" string="Boston" />
            <token id="38" string="'s" />
            <token id="39" string="eighth-best" />
            <token id="40" string="time" />
            <token id="41" string=";" />
            <token id="42" string="Douglas" />
            <token id="43" string="Wakiihuri" />
            <token id="44" string="of" />
            <token id="45" string="Kenya" />
            <token id="46" string="," />
            <token id="47" string="the" />
            <token id="48" string="1987" />
            <token id="49" string="world" />
            <token id="50" string="champion" />
            <token id="51" string="and" />
            <token id="52" string="1988" />
            <token id="53" string="Olympic" />
            <token id="54" string="silver" />
            <token id="55" string="medalist" />
          </tokens>
        </chunking>
        <chunking id="13" string="Ikangaa" type="NP">
          <tokens>
            <token id="24" string="Ikangaa" />
          </tokens>
        </chunking>
        <chunking id="14" string="Ibrahim Hussein of Kenya , the 1988 winner in 2:08:43 , the third-fastest time in Boston and one second ahead of Ikangaa ; Abebe Mekonnen of Ethiopia , the 1989 champion in 2:09:06 , Boston 's eighth-best time ; Douglas Wakiihuri of Kenya , the 1987 world champion and 1988 Olympic silver medalist who is making his Boston debut ; and Naali , the third-place finisher in the 1990 Commonwealth Games" type="NP">
          <tokens>
            <token id="3" string="Ibrahim" />
            <token id="4" string="Hussein" />
            <token id="5" string="of" />
            <token id="6" string="Kenya" />
            <token id="7" string="," />
            <token id="8" string="the" />
            <token id="9" string="1988" />
            <token id="10" string="winner" />
            <token id="11" string="in" />
            <token id="12" string="2:08:43" />
            <token id="13" string="," />
            <token id="14" string="the" />
            <token id="15" string="third-fastest" />
            <token id="16" string="time" />
            <token id="17" string="in" />
            <token id="18" string="Boston" />
            <token id="19" string="and" />
            <token id="20" string="one" />
            <token id="21" string="second" />
            <token id="22" string="ahead" />
            <token id="23" string="of" />
            <token id="24" string="Ikangaa" />
            <token id="25" string=";" />
            <token id="26" string="Abebe" />
            <token id="27" string="Mekonnen" />
            <token id="28" string="of" />
            <token id="29" string="Ethiopia" />
            <token id="30" string="," />
            <token id="31" string="the" />
            <token id="32" string="1989" />
            <token id="33" string="champion" />
            <token id="34" string="in" />
            <token id="35" string="2:09:06" />
            <token id="36" string="," />
            <token id="37" string="Boston" />
            <token id="38" string="'s" />
            <token id="39" string="eighth-best" />
            <token id="40" string="time" />
            <token id="41" string=";" />
            <token id="42" string="Douglas" />
            <token id="43" string="Wakiihuri" />
            <token id="44" string="of" />
            <token id="45" string="Kenya" />
            <token id="46" string="," />
            <token id="47" string="the" />
            <token id="48" string="1987" />
            <token id="49" string="world" />
            <token id="50" string="champion" />
            <token id="51" string="and" />
            <token id="52" string="1988" />
            <token id="53" string="Olympic" />
            <token id="54" string="silver" />
            <token id="55" string="medalist" />
            <token id="56" string="who" />
            <token id="57" string="is" />
            <token id="58" string="making" />
            <token id="59" string="his" />
            <token id="60" string="Boston" />
            <token id="61" string="debut" />
            <token id="62" string=";" />
            <token id="63" string="and" />
            <token id="64" string="Naali" />
            <token id="65" string="," />
            <token id="66" string="the" />
            <token id="67" string="third-place" />
            <token id="68" string="finisher" />
            <token id="69" string="in" />
            <token id="70" string="the" />
            <token id="71" string="1990" />
            <token id="72" string="Commonwealth" />
            <token id="73" string="Games" />
          </tokens>
        </chunking>
        <chunking id="15" string="Boston 's eighth-best time" type="NP">
          <tokens>
            <token id="37" string="Boston" />
            <token id="38" string="'s" />
            <token id="39" string="eighth-best" />
            <token id="40" string="time" />
          </tokens>
        </chunking>
        <chunking id="16" string="one second ahead of Ikangaa" type="NP">
          <tokens>
            <token id="20" string="one" />
            <token id="21" string="second" />
            <token id="22" string="ahead" />
            <token id="23" string="of" />
            <token id="24" string="Ikangaa" />
          </tokens>
        </chunking>
        <chunking id="17" string="the 1989 champion" type="NP">
          <tokens>
            <token id="31" string="the" />
            <token id="32" string="1989" />
            <token id="33" string="champion" />
          </tokens>
        </chunking>
        <chunking id="18" string="Ethiopia" type="NP">
          <tokens>
            <token id="29" string="Ethiopia" />
          </tokens>
        </chunking>
        <chunking id="19" string="the 1989 champion in 2:09:06" type="NP">
          <tokens>
            <token id="31" string="the" />
            <token id="32" string="1989" />
            <token id="33" string="champion" />
            <token id="34" string="in" />
            <token id="35" string="2:09:06" />
          </tokens>
        </chunking>
        <chunking id="20" string="Douglas Wakiihuri of Kenya , the 1987 world champion and 1988 Olympic silver medalist" type="NP">
          <tokens>
            <token id="42" string="Douglas" />
            <token id="43" string="Wakiihuri" />
            <token id="44" string="of" />
            <token id="45" string="Kenya" />
            <token id="46" string="," />
            <token id="47" string="the" />
            <token id="48" string="1987" />
            <token id="49" string="world" />
            <token id="50" string="champion" />
            <token id="51" string="and" />
            <token id="52" string="1988" />
            <token id="53" string="Olympic" />
            <token id="54" string="silver" />
            <token id="55" string="medalist" />
          </tokens>
        </chunking>
        <chunking id="21" string="is making his Boston debut" type="VP">
          <tokens>
            <token id="57" string="is" />
            <token id="58" string="making" />
            <token id="59" string="his" />
            <token id="60" string="Boston" />
            <token id="61" string="debut" />
          </tokens>
        </chunking>
        <chunking id="22" string="Kenya , the 1987 world champion and 1988 Olympic silver medalist" type="NP">
          <tokens>
            <token id="45" string="Kenya" />
            <token id="46" string="," />
            <token id="47" string="the" />
            <token id="48" string="1987" />
            <token id="49" string="world" />
            <token id="50" string="champion" />
            <token id="51" string="and" />
            <token id="52" string="1988" />
            <token id="53" string="Olympic" />
            <token id="54" string="silver" />
            <token id="55" string="medalist" />
          </tokens>
        </chunking>
        <chunking id="23" string="Ibrahim Hussein" type="NP">
          <tokens>
            <token id="3" string="Ibrahim" />
            <token id="4" string="Hussein" />
          </tokens>
        </chunking>
        <chunking id="24" string="2:08:43" type="NP">
          <tokens>
            <token id="12" string="2:08:43" />
          </tokens>
        </chunking>
        <chunking id="25" string="second" type="ADJP">
          <tokens>
            <token id="21" string="second" />
          </tokens>
        </chunking>
        <chunking id="26" string="Boston 's" type="NP">
          <tokens>
            <token id="37" string="Boston" />
            <token id="38" string="'s" />
          </tokens>
        </chunking>
        <chunking id="27" string="Abebe Mekonnen of Ethiopia , the 1989 champion in 2:09:06 , Boston 's eighth-best time" type="NP">
          <tokens>
            <token id="26" string="Abebe" />
            <token id="27" string="Mekonnen" />
            <token id="28" string="of" />
            <token id="29" string="Ethiopia" />
            <token id="30" string="," />
            <token id="31" string="the" />
            <token id="32" string="1989" />
            <token id="33" string="champion" />
            <token id="34" string="in" />
            <token id="35" string="2:09:06" />
            <token id="36" string="," />
            <token id="37" string="Boston" />
            <token id="38" string="'s" />
            <token id="39" string="eighth-best" />
            <token id="40" string="time" />
          </tokens>
        </chunking>
        <chunking id="28" string="the third-place finisher in the 1990 Commonwealth Games" type="NP">
          <tokens>
            <token id="66" string="the" />
            <token id="67" string="third-place" />
            <token id="68" string="finisher" />
            <token id="69" string="in" />
            <token id="70" string="the" />
            <token id="71" string="1990" />
            <token id="72" string="Commonwealth" />
            <token id="73" string="Games" />
          </tokens>
        </chunking>
        <chunking id="29" string="1988 Olympic silver medalist" type="NP">
          <tokens>
            <token id="52" string="1988" />
            <token id="53" string="Olympic" />
            <token id="54" string="silver" />
            <token id="55" string="medalist" />
          </tokens>
        </chunking>
        <chunking id="30" string="Naali" type="NP">
          <tokens>
            <token id="64" string="Naali" />
          </tokens>
        </chunking>
        <chunking id="31" string="Douglas Wakiihuri" type="NP">
          <tokens>
            <token id="42" string="Douglas" />
            <token id="43" string="Wakiihuri" />
          </tokens>
        </chunking>
        <chunking id="32" string="Naali , the third-place finisher in the 1990 Commonwealth Games" type="NP">
          <tokens>
            <token id="64" string="Naali" />
            <token id="65" string="," />
            <token id="66" string="the" />
            <token id="67" string="third-place" />
            <token id="68" string="finisher" />
            <token id="69" string="in" />
            <token id="70" string="the" />
            <token id="71" string="1990" />
            <token id="72" string="Commonwealth" />
            <token id="73" string="Games" />
          </tokens>
        </chunking>
        <chunking id="33" string="2:08:43 , the third-fastest time in Boston and one second ahead of Ikangaa ; Abebe Mekonnen of Ethiopia , the 1989 champion in 2:09:06 , Boston 's eighth-best time ; Douglas Wakiihuri of Kenya , the 1987 world champion and 1988 Olympic silver medalist" type="NP">
          <tokens>
            <token id="12" string="2:08:43" />
            <token id="13" string="," />
            <token id="14" string="the" />
            <token id="15" string="third-fastest" />
            <token id="16" string="time" />
            <token id="17" string="in" />
            <token id="18" string="Boston" />
            <token id="19" string="and" />
            <token id="20" string="one" />
            <token id="21" string="second" />
            <token id="22" string="ahead" />
            <token id="23" string="of" />
            <token id="24" string="Ikangaa" />
            <token id="25" string=";" />
            <token id="26" string="Abebe" />
            <token id="27" string="Mekonnen" />
            <token id="28" string="of" />
            <token id="29" string="Ethiopia" />
            <token id="30" string="," />
            <token id="31" string="the" />
            <token id="32" string="1989" />
            <token id="33" string="champion" />
            <token id="34" string="in" />
            <token id="35" string="2:09:06" />
            <token id="36" string="," />
            <token id="37" string="Boston" />
            <token id="38" string="'s" />
            <token id="39" string="eighth-best" />
            <token id="40" string="time" />
            <token id="41" string=";" />
            <token id="42" string="Douglas" />
            <token id="43" string="Wakiihuri" />
            <token id="44" string="of" />
            <token id="45" string="Kenya" />
            <token id="46" string="," />
            <token id="47" string="the" />
            <token id="48" string="1987" />
            <token id="49" string="world" />
            <token id="50" string="champion" />
            <token id="51" string="and" />
            <token id="52" string="1988" />
            <token id="53" string="Olympic" />
            <token id="54" string="silver" />
            <token id="55" string="medalist" />
          </tokens>
        </chunking>
        <chunking id="34" string="the third-fastest time in Boston" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="third-fastest" />
            <token id="16" string="time" />
            <token id="17" string="in" />
            <token id="18" string="Boston" />
          </tokens>
        </chunking>
        <chunking id="35" string="include Ibrahim Hussein of Kenya , the 1988 winner in 2:08:43 , the third-fastest time in Boston and one second ahead of Ikangaa ; Abebe Mekonnen of Ethiopia , the 1989 champion in 2:09:06 , Boston 's eighth-best time ; Douglas Wakiihuri of Kenya , the 1987 world champion and 1988 Olympic silver medalist who is making his Boston debut ; and Naali , the third-place finisher in the 1990 Commonwealth Games" type="VP">
          <tokens>
            <token id="2" string="include" />
            <token id="3" string="Ibrahim" />
            <token id="4" string="Hussein" />
            <token id="5" string="of" />
            <token id="6" string="Kenya" />
            <token id="7" string="," />
            <token id="8" string="the" />
            <token id="9" string="1988" />
            <token id="10" string="winner" />
            <token id="11" string="in" />
            <token id="12" string="2:08:43" />
            <token id="13" string="," />
            <token id="14" string="the" />
            <token id="15" string="third-fastest" />
            <token id="16" string="time" />
            <token id="17" string="in" />
            <token id="18" string="Boston" />
            <token id="19" string="and" />
            <token id="20" string="one" />
            <token id="21" string="second" />
            <token id="22" string="ahead" />
            <token id="23" string="of" />
            <token id="24" string="Ikangaa" />
            <token id="25" string=";" />
            <token id="26" string="Abebe" />
            <token id="27" string="Mekonnen" />
            <token id="28" string="of" />
            <token id="29" string="Ethiopia" />
            <token id="30" string="," />
            <token id="31" string="the" />
            <token id="32" string="1989" />
            <token id="33" string="champion" />
            <token id="34" string="in" />
            <token id="35" string="2:09:06" />
            <token id="36" string="," />
            <token id="37" string="Boston" />
            <token id="38" string="'s" />
            <token id="39" string="eighth-best" />
            <token id="40" string="time" />
            <token id="41" string=";" />
            <token id="42" string="Douglas" />
            <token id="43" string="Wakiihuri" />
            <token id="44" string="of" />
            <token id="45" string="Kenya" />
            <token id="46" string="," />
            <token id="47" string="the" />
            <token id="48" string="1987" />
            <token id="49" string="world" />
            <token id="50" string="champion" />
            <token id="51" string="and" />
            <token id="52" string="1988" />
            <token id="53" string="Olympic" />
            <token id="54" string="silver" />
            <token id="55" string="medalist" />
            <token id="56" string="who" />
            <token id="57" string="is" />
            <token id="58" string="making" />
            <token id="59" string="his" />
            <token id="60" string="Boston" />
            <token id="61" string="debut" />
            <token id="62" string=";" />
            <token id="63" string="and" />
            <token id="64" string="Naali" />
            <token id="65" string="," />
            <token id="66" string="the" />
            <token id="67" string="third-place" />
            <token id="68" string="finisher" />
            <token id="69" string="in" />
            <token id="70" string="the" />
            <token id="71" string="1990" />
            <token id="72" string="Commonwealth" />
            <token id="73" string="Games" />
          </tokens>
        </chunking>
        <chunking id="36" string="the 1987 world champion" type="NP">
          <tokens>
            <token id="47" string="the" />
            <token id="48" string="1987" />
            <token id="49" string="world" />
            <token id="50" string="champion" />
          </tokens>
        </chunking>
        <chunking id="37" string="the 1988 winner" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="1988" />
            <token id="10" string="winner" />
          </tokens>
        </chunking>
        <chunking id="38" string="making his Boston debut" type="VP">
          <tokens>
            <token id="58" string="making" />
            <token id="59" string="his" />
            <token id="60" string="Boston" />
            <token id="61" string="debut" />
          </tokens>
        </chunking>
        <chunking id="39" string="Boston" type="NP">
          <tokens>
            <token id="18" string="Boston" />
          </tokens>
        </chunking>
        <chunking id="40" string="the 1990 Commonwealth Games" type="NP">
          <tokens>
            <token id="70" string="the" />
            <token id="71" string="1990" />
            <token id="72" string="Commonwealth" />
            <token id="73" string="Games" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">include</governor>
          <dependent id="1">They</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">include</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">Hussein</governor>
          <dependent id="3">Ibrahim</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">include</governor>
          <dependent id="4">Hussein</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">Kenya</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">Hussein</governor>
          <dependent id="6">Kenya</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">winner</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="10">winner</governor>
          <dependent id="9">1988</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">Hussein</governor>
          <dependent id="10">winner</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">2:08:43</governor>
          <dependent id="11">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">winner</governor>
          <dependent id="12">2:08:43</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">time</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">time</governor>
          <dependent id="15">third-fastest</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">2:08:43</governor>
          <dependent id="16">time</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">Boston</governor>
          <dependent id="17">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">time</governor>
          <dependent id="18">Boston</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="12">2:08:43</governor>
          <dependent id="19">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">2:08:43</governor>
          <dependent id="20">one</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">one</governor>
          <dependent id="21">second</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="20">one</governor>
          <dependent id="22">ahead</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">Ikangaa</governor>
          <dependent id="23">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">one</governor>
          <dependent id="24">Ikangaa</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">Mekonnen</governor>
          <dependent id="26">Abebe</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="20">one</governor>
          <dependent id="27">Mekonnen</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">Ethiopia</governor>
          <dependent id="28">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">Mekonnen</governor>
          <dependent id="29">Ethiopia</dependent>
        </dependency>
        <dependency type="det">
          <governor id="33">champion</governor>
          <dependent id="31">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="33">champion</governor>
          <dependent id="32">1989</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="27">Mekonnen</governor>
          <dependent id="33">champion</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">2:09:06</governor>
          <dependent id="34">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="33">champion</governor>
          <dependent id="35">2:09:06</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="40">time</governor>
          <dependent id="37">Boston</dependent>
        </dependency>
        <dependency type="case">
          <governor id="37">Boston</governor>
          <dependent id="38">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="40">time</governor>
          <dependent id="39">eighth-best</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="27">Mekonnen</governor>
          <dependent id="40">time</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="43">Wakiihuri</governor>
          <dependent id="42">Douglas</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="20">one</governor>
          <dependent id="43">Wakiihuri</dependent>
        </dependency>
        <dependency type="case">
          <governor id="45">Kenya</governor>
          <dependent id="44">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="43">Wakiihuri</governor>
          <dependent id="45">Kenya</dependent>
        </dependency>
        <dependency type="det">
          <governor id="50">champion</governor>
          <dependent id="47">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="50">champion</governor>
          <dependent id="48">1987</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="50">champion</governor>
          <dependent id="49">world</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="45">Kenya</governor>
          <dependent id="50">champion</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="45">Kenya</governor>
          <dependent id="51">and</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="55">medalist</governor>
          <dependent id="52">1988</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="55">medalist</governor>
          <dependent id="53">Olympic</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="55">medalist</governor>
          <dependent id="54">silver</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="45">Kenya</governor>
          <dependent id="55">medalist</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="58">making</governor>
          <dependent id="56">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="58">making</governor>
          <dependent id="57">is</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="10">winner</governor>
          <dependent id="58">making</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="61">debut</governor>
          <dependent id="59">his</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="61">debut</governor>
          <dependent id="60">Boston</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="58">making</governor>
          <dependent id="61">debut</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">Hussein</governor>
          <dependent id="63">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">Hussein</governor>
          <dependent id="64">Naali</dependent>
        </dependency>
        <dependency type="det">
          <governor id="68">finisher</governor>
          <dependent id="66">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="68">finisher</governor>
          <dependent id="67">third-place</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="64">Naali</governor>
          <dependent id="68">finisher</dependent>
        </dependency>
        <dependency type="case">
          <governor id="73">Games</governor>
          <dependent id="69">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="73">Games</governor>
          <dependent id="70">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="73">Games</governor>
          <dependent id="71">1990</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="73">Games</governor>
          <dependent id="72">Commonwealth</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="68">finisher</governor>
          <dependent id="73">Games</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="2:09:06" type="TIME" score="0.0">
          <tokens>
            <token id="35" string="2:09:06" />
          </tokens>
        </entity>
        <entity id="2" string="Ibrahim Hussein" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Ibrahim" />
            <token id="4" string="Hussein" />
          </tokens>
        </entity>
        <entity id="3" string="Abebe Mekonnen" type="PERSON" score="0.0">
          <tokens>
            <token id="26" string="Abebe" />
            <token id="27" string="Mekonnen" />
          </tokens>
        </entity>
        <entity id="4" string="2:08:43" type="TIME" score="0.0">
          <tokens>
            <token id="12" string="2:08:43" />
          </tokens>
        </entity>
        <entity id="5" string="1990" type="DATE" score="0.0">
          <tokens>
            <token id="71" string="1990" />
          </tokens>
        </entity>
        <entity id="6" string="Kenya" type="LOCATION" score="0.0">
          <tokens>
            <token id="6" string="Kenya" />
          </tokens>
        </entity>
        <entity id="7" string="Olympic" type="MISC" score="0.0">
          <tokens>
            <token id="53" string="Olympic" />
          </tokens>
        </entity>
        <entity id="8" string="1988" type="DATE" score="0.0">
          <tokens>
            <token id="9" string="1988" />
          </tokens>
        </entity>
        <entity id="9" string="Ikangaa" type="PERSON" score="0.0">
          <tokens>
            <token id="24" string="Ikangaa" />
          </tokens>
        </entity>
        <entity id="10" string="1987" type="DATE" score="0.0">
          <tokens>
            <token id="48" string="1987" />
          </tokens>
        </entity>
        <entity id="11" string="Naali" type="PERSON" score="0.0">
          <tokens>
            <token id="64" string="Naali" />
          </tokens>
        </entity>
        <entity id="12" string="Douglas Wakiihuri" type="PERSON" score="0.0">
          <tokens>
            <token id="42" string="Douglas" />
            <token id="43" string="Wakiihuri" />
          </tokens>
        </entity>
        <entity id="13" string="one second" type="DURATION" score="0.0">
          <tokens>
            <token id="20" string="one" />
            <token id="21" string="second" />
          </tokens>
        </entity>
        <entity id="14" string="Commonwealth" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="72" string="Commonwealth" />
          </tokens>
        </entity>
        <entity id="15" string="Boston" type="LOCATION" score="0.0">
          <tokens>
            <token id="18" string="Boston" />
          </tokens>
        </entity>
        <entity id="16" string="Ethiopia" type="LOCATION" score="0.0">
          <tokens>
            <token id="29" string="Ethiopia" />
          </tokens>
        </entity>
        <entity id="17" string="1989" type="DATE" score="0.0">
          <tokens>
            <token id="32" string="1989" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="18" has_coreference="true">
      <content>Among those chasing them will be John Treacy, the 1984 Olympic silver medalist and the third-place finisher in Boston in 1988 and 1989; Geoff Smith, the Boston winner in 1984-85; Ed Eyestone, the top-ranked U.S. marathoner; Salvador Garcia, the runner-up to Wakiihuri in last year&amp;apost;s New York City Marathon; and Rolando Vera, who finished third in his marathon debut in Boston in 1990.</content>
      <tokens>
        <token id="1" string="Among" lemma="among" stem="among" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="those" lemma="those" stem="those" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="chasing" lemma="chase" stem="chase" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="8" string="Treacy" lemma="Treacy" stem="treaci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="1984" lemma="1984" stem="1984" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="12" string="Olympic" lemma="Olympic" stem="olympic" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="13" string="silver" lemma="silver" stem="silver" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="medalist" lemma="medalist" stem="medalist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="third-place" lemma="third-place" stem="third-plac" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="finisher" lemma="finisher" stem="finish" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="Boston" lemma="Boston" stem="boston" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="21" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="1988" lemma="1988" stem="1988" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="23" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="1989" lemma="1989" stem="1989" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="25" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="Geoff" lemma="Geoff" stem="geoff" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="27" string="Smith" lemma="Smith" stem="smith" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="28" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="Boston" lemma="Boston" stem="boston" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="31" string="winner" lemma="winner" stem="winner" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="1984-85" lemma="1984-85" stem="1984-85" pos="CD" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="34" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="Ed" lemma="Ed" stem="ed" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="36" string="Eyestone" lemma="Eyestone" stem="eyeston" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="37" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="top-ranked" lemma="top-ranked" stem="top-rank" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="U.S." lemma="U.S." stem="u.s." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="41" string="marathoner" lemma="marathoner" stem="marathon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="Salvador" lemma="Salvador" stem="salvador" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="44" string="Garcia" lemma="Garcia" stem="garcia" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="45" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="46" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="47" string="runner-up" lemma="runner-up" stem="runner-up" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="48" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="49" string="Wakiihuri" lemma="Wakiihuri" stem="wakiihuri" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="50" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="51" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="true" />
        <token id="52" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="true" />
        <token id="53" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="54" string="New" lemma="New" stem="new" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="55" string="York" lemma="York" stem="york" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="56" string="City" lemma="City" stem="citi" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="57" string="Marathon" lemma="Marathon" stem="marathon" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="58" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="59" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="60" string="Rolando" lemma="Rolando" stem="rolando" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="61" string="Vera" lemma="Vera" stem="vera" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="62" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="63" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="64" string="finished" lemma="finish" stem="finish" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="65" string="third" lemma="third" stem="third" pos="RB" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="66" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="67" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="68" string="marathon" lemma="marathon" stem="marathon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="69" string="debut" lemma="debut" stem="debut" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="70" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="71" string="Boston" lemma="Boston" stem="boston" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="72" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="73" string="1990" lemma="1990" stem="1990" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="74" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN Among) (S (NP (DT those)) (VP (VBG chasing)))) (NP (PRP them)) (VP (MD will) (VP (VB be) (NP (NP (NNP John) (NNP Treacy)) (, ,) (NP (DT the) (CD 1984) (NNP Olympic) (NN silver) (NN medalist)) (CC and) (NP (NP (DT the) (JJ third-place) (NN finisher)) (PP (IN in) (NP (NP (NP (NP (NNP Boston)) (PP (IN in) (NP (CD 1988) (CC and) (CD 1989)))) (: ;) (NP (NP (NNP Geoff) (NNP Smith)) (, ,) (NP (NP (DT the) (NNP Boston) (NN winner)) (PP (IN in) (NP (CD 1984-85))))) (: ;) (NP (NP (NNP Ed) (NNP Eyestone)) (, ,) (NP (DT the) (JJ top-ranked) (NNP U.S.) (NN marathoner))) (: ;) (NP (NP (NNP Salvador) (NNP Garcia)) (, ,) (NP (NP (DT the) (NN runner-up)) (PP (TO to) (NP (NP (NNP Wakiihuri)) (PP (IN in) (NP (NP (JJ last) (NN year) (POS 's)) (NNP New) (NNP York) (NNP City) (NNP Marathon))))))) (: ;) (CC and) (NP (NNP Rolando) (NNP Vera))) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBD finished) (ADVP (RB third) (PP (IN in) (NP (PRP$ his) (NN marathon) (NN debut)))) (PP (IN in) (NP (NNP Boston))) (PP (IN in) (NP (CD 1990)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the Boston winner in 1984-85" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="Boston" />
            <token id="31" string="winner" />
            <token id="32" string="in" />
            <token id="33" string="1984-85" />
          </tokens>
        </chunking>
        <chunking id="2" string="Boston in 1988 and 1989 ; Geoff Smith , the Boston winner in 1984-85 ; Ed Eyestone , the top-ranked U.S. marathoner ; Salvador Garcia , the runner-up to Wakiihuri in last year 's New York City Marathon ; and Rolando Vera" type="NP">
          <tokens>
            <token id="20" string="Boston" />
            <token id="21" string="in" />
            <token id="22" string="1988" />
            <token id="23" string="and" />
            <token id="24" string="1989" />
            <token id="25" string=";" />
            <token id="26" string="Geoff" />
            <token id="27" string="Smith" />
            <token id="28" string="," />
            <token id="29" string="the" />
            <token id="30" string="Boston" />
            <token id="31" string="winner" />
            <token id="32" string="in" />
            <token id="33" string="1984-85" />
            <token id="34" string=";" />
            <token id="35" string="Ed" />
            <token id="36" string="Eyestone" />
            <token id="37" string="," />
            <token id="38" string="the" />
            <token id="39" string="top-ranked" />
            <token id="40" string="U.S." />
            <token id="41" string="marathoner" />
            <token id="42" string=";" />
            <token id="43" string="Salvador" />
            <token id="44" string="Garcia" />
            <token id="45" string="," />
            <token id="46" string="the" />
            <token id="47" string="runner-up" />
            <token id="48" string="to" />
            <token id="49" string="Wakiihuri" />
            <token id="50" string="in" />
            <token id="51" string="last" />
            <token id="52" string="year" />
            <token id="53" string="'s" />
            <token id="54" string="New" />
            <token id="55" string="York" />
            <token id="56" string="City" />
            <token id="57" string="Marathon" />
            <token id="58" string=";" />
            <token id="59" string="and" />
            <token id="60" string="Rolando" />
            <token id="61" string="Vera" />
          </tokens>
        </chunking>
        <chunking id="3" string="chasing" type="VP">
          <tokens>
            <token id="3" string="chasing" />
          </tokens>
        </chunking>
        <chunking id="4" string="1990" type="NP">
          <tokens>
            <token id="73" string="1990" />
          </tokens>
        </chunking>
        <chunking id="5" string="finished third in his marathon debut in Boston in 1990" type="VP">
          <tokens>
            <token id="64" string="finished" />
            <token id="65" string="third" />
            <token id="66" string="in" />
            <token id="67" string="his" />
            <token id="68" string="marathon" />
            <token id="69" string="debut" />
            <token id="70" string="in" />
            <token id="71" string="Boston" />
            <token id="72" string="in" />
            <token id="73" string="1990" />
          </tokens>
        </chunking>
        <chunking id="6" string="them" type="NP">
          <tokens>
            <token id="4" string="them" />
          </tokens>
        </chunking>
        <chunking id="7" string="the third-place finisher" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="third-place" />
            <token id="18" string="finisher" />
          </tokens>
        </chunking>
        <chunking id="8" string="the top-ranked U.S. marathoner" type="NP">
          <tokens>
            <token id="38" string="the" />
            <token id="39" string="top-ranked" />
            <token id="40" string="U.S." />
            <token id="41" string="marathoner" />
          </tokens>
        </chunking>
        <chunking id="9" string="the Boston winner" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="Boston" />
            <token id="31" string="winner" />
          </tokens>
        </chunking>
        <chunking id="10" string="Geoff Smith , the Boston winner in 1984-85" type="NP">
          <tokens>
            <token id="26" string="Geoff" />
            <token id="27" string="Smith" />
            <token id="28" string="," />
            <token id="29" string="the" />
            <token id="30" string="Boston" />
            <token id="31" string="winner" />
            <token id="32" string="in" />
            <token id="33" string="1984-85" />
          </tokens>
        </chunking>
        <chunking id="11" string="Ed Eyestone" type="NP">
          <tokens>
            <token id="35" string="Ed" />
            <token id="36" string="Eyestone" />
          </tokens>
        </chunking>
        <chunking id="12" string="Wakiihuri in last year 's New York City Marathon" type="NP">
          <tokens>
            <token id="49" string="Wakiihuri" />
            <token id="50" string="in" />
            <token id="51" string="last" />
            <token id="52" string="year" />
            <token id="53" string="'s" />
            <token id="54" string="New" />
            <token id="55" string="York" />
            <token id="56" string="City" />
            <token id="57" string="Marathon" />
          </tokens>
        </chunking>
        <chunking id="13" string="Salvador Garcia" type="NP">
          <tokens>
            <token id="43" string="Salvador" />
            <token id="44" string="Garcia" />
          </tokens>
        </chunking>
        <chunking id="14" string="the 1984 Olympic silver medalist" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="1984" />
            <token id="12" string="Olympic" />
            <token id="13" string="silver" />
            <token id="14" string="medalist" />
          </tokens>
        </chunking>
        <chunking id="15" string="will be John Treacy , the 1984 Olympic silver medalist and the third-place finisher in Boston in 1988 and 1989 ; Geoff Smith , the Boston winner in 1984-85 ; Ed Eyestone , the top-ranked U.S. marathoner ; Salvador Garcia , the runner-up to Wakiihuri in last year 's New York City Marathon ; and Rolando Vera , who finished third in his marathon debut in Boston in 1990" type="VP">
          <tokens>
            <token id="5" string="will" />
            <token id="6" string="be" />
            <token id="7" string="John" />
            <token id="8" string="Treacy" />
            <token id="9" string="," />
            <token id="10" string="the" />
            <token id="11" string="1984" />
            <token id="12" string="Olympic" />
            <token id="13" string="silver" />
            <token id="14" string="medalist" />
            <token id="15" string="and" />
            <token id="16" string="the" />
            <token id="17" string="third-place" />
            <token id="18" string="finisher" />
            <token id="19" string="in" />
            <token id="20" string="Boston" />
            <token id="21" string="in" />
            <token id="22" string="1988" />
            <token id="23" string="and" />
            <token id="24" string="1989" />
            <token id="25" string=";" />
            <token id="26" string="Geoff" />
            <token id="27" string="Smith" />
            <token id="28" string="," />
            <token id="29" string="the" />
            <token id="30" string="Boston" />
            <token id="31" string="winner" />
            <token id="32" string="in" />
            <token id="33" string="1984-85" />
            <token id="34" string=";" />
            <token id="35" string="Ed" />
            <token id="36" string="Eyestone" />
            <token id="37" string="," />
            <token id="38" string="the" />
            <token id="39" string="top-ranked" />
            <token id="40" string="U.S." />
            <token id="41" string="marathoner" />
            <token id="42" string=";" />
            <token id="43" string="Salvador" />
            <token id="44" string="Garcia" />
            <token id="45" string="," />
            <token id="46" string="the" />
            <token id="47" string="runner-up" />
            <token id="48" string="to" />
            <token id="49" string="Wakiihuri" />
            <token id="50" string="in" />
            <token id="51" string="last" />
            <token id="52" string="year" />
            <token id="53" string="'s" />
            <token id="54" string="New" />
            <token id="55" string="York" />
            <token id="56" string="City" />
            <token id="57" string="Marathon" />
            <token id="58" string=";" />
            <token id="59" string="and" />
            <token id="60" string="Rolando" />
            <token id="61" string="Vera" />
            <token id="62" string="," />
            <token id="63" string="who" />
            <token id="64" string="finished" />
            <token id="65" string="third" />
            <token id="66" string="in" />
            <token id="67" string="his" />
            <token id="68" string="marathon" />
            <token id="69" string="debut" />
            <token id="70" string="in" />
            <token id="71" string="Boston" />
            <token id="72" string="in" />
            <token id="73" string="1990" />
          </tokens>
        </chunking>
        <chunking id="16" string="1984-85" type="NP">
          <tokens>
            <token id="33" string="1984-85" />
          </tokens>
        </chunking>
        <chunking id="17" string="his marathon debut" type="NP">
          <tokens>
            <token id="67" string="his" />
            <token id="68" string="marathon" />
            <token id="69" string="debut" />
          </tokens>
        </chunking>
        <chunking id="18" string="the third-place finisher in Boston in 1988 and 1989 ; Geoff Smith , the Boston winner in 1984-85 ; Ed Eyestone , the top-ranked U.S. marathoner ; Salvador Garcia , the runner-up to Wakiihuri in last year 's New York City Marathon ; and Rolando Vera , who finished third in his marathon debut in Boston in 1990" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="third-place" />
            <token id="18" string="finisher" />
            <token id="19" string="in" />
            <token id="20" string="Boston" />
            <token id="21" string="in" />
            <token id="22" string="1988" />
            <token id="23" string="and" />
            <token id="24" string="1989" />
            <token id="25" string=";" />
            <token id="26" string="Geoff" />
            <token id="27" string="Smith" />
            <token id="28" string="," />
            <token id="29" string="the" />
            <token id="30" string="Boston" />
            <token id="31" string="winner" />
            <token id="32" string="in" />
            <token id="33" string="1984-85" />
            <token id="34" string=";" />
            <token id="35" string="Ed" />
            <token id="36" string="Eyestone" />
            <token id="37" string="," />
            <token id="38" string="the" />
            <token id="39" string="top-ranked" />
            <token id="40" string="U.S." />
            <token id="41" string="marathoner" />
            <token id="42" string=";" />
            <token id="43" string="Salvador" />
            <token id="44" string="Garcia" />
            <token id="45" string="," />
            <token id="46" string="the" />
            <token id="47" string="runner-up" />
            <token id="48" string="to" />
            <token id="49" string="Wakiihuri" />
            <token id="50" string="in" />
            <token id="51" string="last" />
            <token id="52" string="year" />
            <token id="53" string="'s" />
            <token id="54" string="New" />
            <token id="55" string="York" />
            <token id="56" string="City" />
            <token id="57" string="Marathon" />
            <token id="58" string=";" />
            <token id="59" string="and" />
            <token id="60" string="Rolando" />
            <token id="61" string="Vera" />
            <token id="62" string="," />
            <token id="63" string="who" />
            <token id="64" string="finished" />
            <token id="65" string="third" />
            <token id="66" string="in" />
            <token id="67" string="his" />
            <token id="68" string="marathon" />
            <token id="69" string="debut" />
            <token id="70" string="in" />
            <token id="71" string="Boston" />
            <token id="72" string="in" />
            <token id="73" string="1990" />
          </tokens>
        </chunking>
        <chunking id="19" string="the runner-up to Wakiihuri in last year 's New York City Marathon" type="NP">
          <tokens>
            <token id="46" string="the" />
            <token id="47" string="runner-up" />
            <token id="48" string="to" />
            <token id="49" string="Wakiihuri" />
            <token id="50" string="in" />
            <token id="51" string="last" />
            <token id="52" string="year" />
            <token id="53" string="'s" />
            <token id="54" string="New" />
            <token id="55" string="York" />
            <token id="56" string="City" />
            <token id="57" string="Marathon" />
          </tokens>
        </chunking>
        <chunking id="20" string="1988 and 1989" type="NP">
          <tokens>
            <token id="22" string="1988" />
            <token id="23" string="and" />
            <token id="24" string="1989" />
          </tokens>
        </chunking>
        <chunking id="21" string="be John Treacy , the 1984 Olympic silver medalist and the third-place finisher in Boston in 1988 and 1989 ; Geoff Smith , the Boston winner in 1984-85 ; Ed Eyestone , the top-ranked U.S. marathoner ; Salvador Garcia , the runner-up to Wakiihuri in last year 's New York City Marathon ; and Rolando Vera , who finished third in his marathon debut in Boston in 1990" type="VP">
          <tokens>
            <token id="6" string="be" />
            <token id="7" string="John" />
            <token id="8" string="Treacy" />
            <token id="9" string="," />
            <token id="10" string="the" />
            <token id="11" string="1984" />
            <token id="12" string="Olympic" />
            <token id="13" string="silver" />
            <token id="14" string="medalist" />
            <token id="15" string="and" />
            <token id="16" string="the" />
            <token id="17" string="third-place" />
            <token id="18" string="finisher" />
            <token id="19" string="in" />
            <token id="20" string="Boston" />
            <token id="21" string="in" />
            <token id="22" string="1988" />
            <token id="23" string="and" />
            <token id="24" string="1989" />
            <token id="25" string=";" />
            <token id="26" string="Geoff" />
            <token id="27" string="Smith" />
            <token id="28" string="," />
            <token id="29" string="the" />
            <token id="30" string="Boston" />
            <token id="31" string="winner" />
            <token id="32" string="in" />
            <token id="33" string="1984-85" />
            <token id="34" string=";" />
            <token id="35" string="Ed" />
            <token id="36" string="Eyestone" />
            <token id="37" string="," />
            <token id="38" string="the" />
            <token id="39" string="top-ranked" />
            <token id="40" string="U.S." />
            <token id="41" string="marathoner" />
            <token id="42" string=";" />
            <token id="43" string="Salvador" />
            <token id="44" string="Garcia" />
            <token id="45" string="," />
            <token id="46" string="the" />
            <token id="47" string="runner-up" />
            <token id="48" string="to" />
            <token id="49" string="Wakiihuri" />
            <token id="50" string="in" />
            <token id="51" string="last" />
            <token id="52" string="year" />
            <token id="53" string="'s" />
            <token id="54" string="New" />
            <token id="55" string="York" />
            <token id="56" string="City" />
            <token id="57" string="Marathon" />
            <token id="58" string=";" />
            <token id="59" string="and" />
            <token id="60" string="Rolando" />
            <token id="61" string="Vera" />
            <token id="62" string="," />
            <token id="63" string="who" />
            <token id="64" string="finished" />
            <token id="65" string="third" />
            <token id="66" string="in" />
            <token id="67" string="his" />
            <token id="68" string="marathon" />
            <token id="69" string="debut" />
            <token id="70" string="in" />
            <token id="71" string="Boston" />
            <token id="72" string="in" />
            <token id="73" string="1990" />
          </tokens>
        </chunking>
        <chunking id="22" string="John Treacy , the 1984 Olympic silver medalist and the third-place finisher in Boston in 1988 and 1989 ; Geoff Smith , the Boston winner in 1984-85 ; Ed Eyestone , the top-ranked U.S. marathoner ; Salvador Garcia , the runner-up to Wakiihuri in last year 's New York City Marathon ; and Rolando Vera , who finished third in his marathon debut in Boston in 1990" type="NP">
          <tokens>
            <token id="7" string="John" />
            <token id="8" string="Treacy" />
            <token id="9" string="," />
            <token id="10" string="the" />
            <token id="11" string="1984" />
            <token id="12" string="Olympic" />
            <token id="13" string="silver" />
            <token id="14" string="medalist" />
            <token id="15" string="and" />
            <token id="16" string="the" />
            <token id="17" string="third-place" />
            <token id="18" string="finisher" />
            <token id="19" string="in" />
            <token id="20" string="Boston" />
            <token id="21" string="in" />
            <token id="22" string="1988" />
            <token id="23" string="and" />
            <token id="24" string="1989" />
            <token id="25" string=";" />
            <token id="26" string="Geoff" />
            <token id="27" string="Smith" />
            <token id="28" string="," />
            <token id="29" string="the" />
            <token id="30" string="Boston" />
            <token id="31" string="winner" />
            <token id="32" string="in" />
            <token id="33" string="1984-85" />
            <token id="34" string=";" />
            <token id="35" string="Ed" />
            <token id="36" string="Eyestone" />
            <token id="37" string="," />
            <token id="38" string="the" />
            <token id="39" string="top-ranked" />
            <token id="40" string="U.S." />
            <token id="41" string="marathoner" />
            <token id="42" string=";" />
            <token id="43" string="Salvador" />
            <token id="44" string="Garcia" />
            <token id="45" string="," />
            <token id="46" string="the" />
            <token id="47" string="runner-up" />
            <token id="48" string="to" />
            <token id="49" string="Wakiihuri" />
            <token id="50" string="in" />
            <token id="51" string="last" />
            <token id="52" string="year" />
            <token id="53" string="'s" />
            <token id="54" string="New" />
            <token id="55" string="York" />
            <token id="56" string="City" />
            <token id="57" string="Marathon" />
            <token id="58" string=";" />
            <token id="59" string="and" />
            <token id="60" string="Rolando" />
            <token id="61" string="Vera" />
            <token id="62" string="," />
            <token id="63" string="who" />
            <token id="64" string="finished" />
            <token id="65" string="third" />
            <token id="66" string="in" />
            <token id="67" string="his" />
            <token id="68" string="marathon" />
            <token id="69" string="debut" />
            <token id="70" string="in" />
            <token id="71" string="Boston" />
            <token id="72" string="in" />
            <token id="73" string="1990" />
          </tokens>
        </chunking>
        <chunking id="23" string="Boston in 1988 and 1989 ; Geoff Smith , the Boston winner in 1984-85 ; Ed Eyestone , the top-ranked U.S. marathoner ; Salvador Garcia , the runner-up to Wakiihuri in last year 's New York City Marathon ; and Rolando Vera , who finished third in his marathon debut in Boston in 1990" type="NP">
          <tokens>
            <token id="20" string="Boston" />
            <token id="21" string="in" />
            <token id="22" string="1988" />
            <token id="23" string="and" />
            <token id="24" string="1989" />
            <token id="25" string=";" />
            <token id="26" string="Geoff" />
            <token id="27" string="Smith" />
            <token id="28" string="," />
            <token id="29" string="the" />
            <token id="30" string="Boston" />
            <token id="31" string="winner" />
            <token id="32" string="in" />
            <token id="33" string="1984-85" />
            <token id="34" string=";" />
            <token id="35" string="Ed" />
            <token id="36" string="Eyestone" />
            <token id="37" string="," />
            <token id="38" string="the" />
            <token id="39" string="top-ranked" />
            <token id="40" string="U.S." />
            <token id="41" string="marathoner" />
            <token id="42" string=";" />
            <token id="43" string="Salvador" />
            <token id="44" string="Garcia" />
            <token id="45" string="," />
            <token id="46" string="the" />
            <token id="47" string="runner-up" />
            <token id="48" string="to" />
            <token id="49" string="Wakiihuri" />
            <token id="50" string="in" />
            <token id="51" string="last" />
            <token id="52" string="year" />
            <token id="53" string="'s" />
            <token id="54" string="New" />
            <token id="55" string="York" />
            <token id="56" string="City" />
            <token id="57" string="Marathon" />
            <token id="58" string=";" />
            <token id="59" string="and" />
            <token id="60" string="Rolando" />
            <token id="61" string="Vera" />
            <token id="62" string="," />
            <token id="63" string="who" />
            <token id="64" string="finished" />
            <token id="65" string="third" />
            <token id="66" string="in" />
            <token id="67" string="his" />
            <token id="68" string="marathon" />
            <token id="69" string="debut" />
            <token id="70" string="in" />
            <token id="71" string="Boston" />
            <token id="72" string="in" />
            <token id="73" string="1990" />
          </tokens>
        </chunking>
        <chunking id="24" string="Wakiihuri" type="NP">
          <tokens>
            <token id="49" string="Wakiihuri" />
          </tokens>
        </chunking>
        <chunking id="25" string="last year 's" type="NP">
          <tokens>
            <token id="51" string="last" />
            <token id="52" string="year" />
            <token id="53" string="'s" />
          </tokens>
        </chunking>
        <chunking id="26" string="John Treacy" type="NP">
          <tokens>
            <token id="7" string="John" />
            <token id="8" string="Treacy" />
          </tokens>
        </chunking>
        <chunking id="27" string="the runner-up" type="NP">
          <tokens>
            <token id="46" string="the" />
            <token id="47" string="runner-up" />
          </tokens>
        </chunking>
        <chunking id="28" string="Geoff Smith" type="NP">
          <tokens>
            <token id="26" string="Geoff" />
            <token id="27" string="Smith" />
          </tokens>
        </chunking>
        <chunking id="29" string="Rolando Vera" type="NP">
          <tokens>
            <token id="60" string="Rolando" />
            <token id="61" string="Vera" />
          </tokens>
        </chunking>
        <chunking id="30" string="Boston in 1988 and 1989" type="NP">
          <tokens>
            <token id="20" string="Boston" />
            <token id="21" string="in" />
            <token id="22" string="1988" />
            <token id="23" string="and" />
            <token id="24" string="1989" />
          </tokens>
        </chunking>
        <chunking id="31" string="Ed Eyestone , the top-ranked U.S. marathoner" type="NP">
          <tokens>
            <token id="35" string="Ed" />
            <token id="36" string="Eyestone" />
            <token id="37" string="," />
            <token id="38" string="the" />
            <token id="39" string="top-ranked" />
            <token id="40" string="U.S." />
            <token id="41" string="marathoner" />
          </tokens>
        </chunking>
        <chunking id="32" string="last year 's New York City Marathon" type="NP">
          <tokens>
            <token id="51" string="last" />
            <token id="52" string="year" />
            <token id="53" string="'s" />
            <token id="54" string="New" />
            <token id="55" string="York" />
            <token id="56" string="City" />
            <token id="57" string="Marathon" />
          </tokens>
        </chunking>
        <chunking id="33" string="Salvador Garcia , the runner-up to Wakiihuri in last year 's New York City Marathon" type="NP">
          <tokens>
            <token id="43" string="Salvador" />
            <token id="44" string="Garcia" />
            <token id="45" string="," />
            <token id="46" string="the" />
            <token id="47" string="runner-up" />
            <token id="48" string="to" />
            <token id="49" string="Wakiihuri" />
            <token id="50" string="in" />
            <token id="51" string="last" />
            <token id="52" string="year" />
            <token id="53" string="'s" />
            <token id="54" string="New" />
            <token id="55" string="York" />
            <token id="56" string="City" />
            <token id="57" string="Marathon" />
          </tokens>
        </chunking>
        <chunking id="34" string="who finished third in his marathon debut in Boston in 1990" type="SBAR">
          <tokens>
            <token id="63" string="who" />
            <token id="64" string="finished" />
            <token id="65" string="third" />
            <token id="66" string="in" />
            <token id="67" string="his" />
            <token id="68" string="marathon" />
            <token id="69" string="debut" />
            <token id="70" string="in" />
            <token id="71" string="Boston" />
            <token id="72" string="in" />
            <token id="73" string="1990" />
          </tokens>
        </chunking>
        <chunking id="35" string="Boston" type="NP">
          <tokens>
            <token id="20" string="Boston" />
          </tokens>
        </chunking>
        <chunking id="36" string="those" type="NP">
          <tokens>
            <token id="2" string="those" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="3">chasing</governor>
          <dependent id="1">Among</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">chasing</governor>
          <dependent id="2">those</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="8">Treacy</governor>
          <dependent id="3">chasing</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">Treacy</governor>
          <dependent id="4">them</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">Treacy</governor>
          <dependent id="5">will</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="8">Treacy</governor>
          <dependent id="6">be</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">Treacy</governor>
          <dependent id="7">John</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">Treacy</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">medalist</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="14">medalist</governor>
          <dependent id="11">1984</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">medalist</governor>
          <dependent id="12">Olympic</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">medalist</governor>
          <dependent id="13">silver</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">Treacy</governor>
          <dependent id="14">medalist</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">Treacy</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">finisher</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">finisher</governor>
          <dependent id="17">third-place</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">Treacy</governor>
          <dependent id="18">finisher</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">Boston</governor>
          <dependent id="19">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">finisher</governor>
          <dependent id="20">Boston</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">1988</governor>
          <dependent id="21">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">Boston</governor>
          <dependent id="22">1988</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="22">1988</governor>
          <dependent id="23">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="22">1988</governor>
          <dependent id="24">1989</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">Smith</governor>
          <dependent id="26">Geoff</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="20">Boston</governor>
          <dependent id="27">Smith</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">winner</governor>
          <dependent id="29">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">winner</governor>
          <dependent id="30">Boston</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="27">Smith</governor>
          <dependent id="31">winner</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">1984-85</governor>
          <dependent id="32">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">winner</governor>
          <dependent id="33">1984-85</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="36">Eyestone</governor>
          <dependent id="35">Ed</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="20">Boston</governor>
          <dependent id="36">Eyestone</dependent>
        </dependency>
        <dependency type="det">
          <governor id="41">marathoner</governor>
          <dependent id="38">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="41">marathoner</governor>
          <dependent id="39">top-ranked</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="41">marathoner</governor>
          <dependent id="40">U.S.</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="36">Eyestone</governor>
          <dependent id="41">marathoner</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="44">Garcia</governor>
          <dependent id="43">Salvador</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="20">Boston</governor>
          <dependent id="44">Garcia</dependent>
        </dependency>
        <dependency type="det">
          <governor id="47">runner-up</governor>
          <dependent id="46">the</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="44">Garcia</governor>
          <dependent id="47">runner-up</dependent>
        </dependency>
        <dependency type="case">
          <governor id="49">Wakiihuri</governor>
          <dependent id="48">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="47">runner-up</governor>
          <dependent id="49">Wakiihuri</dependent>
        </dependency>
        <dependency type="case">
          <governor id="57">Marathon</governor>
          <dependent id="50">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="52">year</governor>
          <dependent id="51">last</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="57">Marathon</governor>
          <dependent id="52">year</dependent>
        </dependency>
        <dependency type="case">
          <governor id="52">year</governor>
          <dependent id="53">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="57">Marathon</governor>
          <dependent id="54">New</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="57">Marathon</governor>
          <dependent id="55">York</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="57">Marathon</governor>
          <dependent id="56">City</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="49">Wakiihuri</governor>
          <dependent id="57">Marathon</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="20">Boston</governor>
          <dependent id="59">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="61">Vera</governor>
          <dependent id="60">Rolando</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="20">Boston</governor>
          <dependent id="61">Vera</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="64">finished</governor>
          <dependent id="63">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="20">Boston</governor>
          <dependent id="64">finished</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="64">finished</governor>
          <dependent id="65">third</dependent>
        </dependency>
        <dependency type="case">
          <governor id="69">debut</governor>
          <dependent id="66">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="69">debut</governor>
          <dependent id="67">his</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="69">debut</governor>
          <dependent id="68">marathon</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="65">third</governor>
          <dependent id="69">debut</dependent>
        </dependency>
        <dependency type="case">
          <governor id="71">Boston</governor>
          <dependent id="70">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="64">finished</governor>
          <dependent id="71">Boston</dependent>
        </dependency>
        <dependency type="case">
          <governor id="73">1990</governor>
          <dependent id="72">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="64">finished</governor>
          <dependent id="73">1990</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="New York City Marathon" type="LOCATION" score="0.0">
          <tokens>
            <token id="54" string="New" />
            <token id="55" string="York" />
            <token id="56" string="City" />
            <token id="57" string="Marathon" />
          </tokens>
        </entity>
        <entity id="2" string="1984-85" type="DATE" score="0.0">
          <tokens>
            <token id="33" string="1984-85" />
          </tokens>
        </entity>
        <entity id="3" string="1990" type="DATE" score="0.0">
          <tokens>
            <token id="73" string="1990" />
          </tokens>
        </entity>
        <entity id="4" string="Olympic" type="MISC" score="0.0">
          <tokens>
            <token id="12" string="Olympic" />
          </tokens>
        </entity>
        <entity id="5" string="last year" type="DATE" score="0.0">
          <tokens>
            <token id="51" string="last" />
            <token id="52" string="year" />
          </tokens>
        </entity>
        <entity id="6" string="1988" type="DATE" score="0.0">
          <tokens>
            <token id="22" string="1988" />
          </tokens>
        </entity>
        <entity id="7" string="Wakiihuri" type="PERSON" score="0.0">
          <tokens>
            <token id="49" string="Wakiihuri" />
          </tokens>
        </entity>
        <entity id="8" string="John Treacy" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="John" />
            <token id="8" string="Treacy" />
          </tokens>
        </entity>
        <entity id="9" string="1984" type="DATE" score="0.0">
          <tokens>
            <token id="11" string="1984" />
          </tokens>
        </entity>
        <entity id="10" string="U.S." type="LOCATION" score="0.0">
          <tokens>
            <token id="40" string="U.S." />
          </tokens>
        </entity>
        <entity id="11" string="Geoff Smith" type="PERSON" score="0.0">
          <tokens>
            <token id="26" string="Geoff" />
            <token id="27" string="Smith" />
          </tokens>
        </entity>
        <entity id="12" string="third" type="ORDINAL" score="0.0">
          <tokens>
            <token id="65" string="third" />
          </tokens>
        </entity>
        <entity id="13" string="Rolando Vera" type="PERSON" score="0.0">
          <tokens>
            <token id="60" string="Rolando" />
            <token id="61" string="Vera" />
          </tokens>
        </entity>
        <entity id="14" string="Ed Eyestone" type="PERSON" score="0.0">
          <tokens>
            <token id="35" string="Ed" />
            <token id="36" string="Eyestone" />
          </tokens>
        </entity>
        <entity id="15" string="Boston" type="LOCATION" score="0.0">
          <tokens>
            <token id="20" string="Boston" />
          </tokens>
        </entity>
        <entity id="16" string="1989" type="DATE" score="0.0">
          <tokens>
            <token id="24" string="1989" />
          </tokens>
        </entity>
        <entity id="17" string="Salvador Garcia" type="PERSON" score="0.0">
          <tokens>
            <token id="43" string="Salvador" />
            <token id="44" string="Garcia" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="19" has_coreference="true">
      <content>The women&amp;apost;s division also is filled with many respectable entrants.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="women" lemma="woman" stem="women" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="division" lemma="division" stem="divis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="filled" lemma="fill" stem="fill" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="many" lemma="many" stem="mani" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="respectable" lemma="respectable" stem="respect" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="entrants" lemma="entrant" stem="entrant" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (NNS women) (POS 's)) (NN division)) (ADVP (RB also)) (VP (VBZ is) (VP (VBN filled) (PP (IN with) (NP (JJ many) (JJ respectable) (NNS entrants))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="is filled with many respectable entrants" type="VP">
          <tokens>
            <token id="6" string="is" />
            <token id="7" string="filled" />
            <token id="8" string="with" />
            <token id="9" string="many" />
            <token id="10" string="respectable" />
            <token id="11" string="entrants" />
          </tokens>
        </chunking>
        <chunking id="2" string="filled with many respectable entrants" type="VP">
          <tokens>
            <token id="7" string="filled" />
            <token id="8" string="with" />
            <token id="9" string="many" />
            <token id="10" string="respectable" />
            <token id="11" string="entrants" />
          </tokens>
        </chunking>
        <chunking id="3" string="The women 's division" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="women" />
            <token id="3" string="'s" />
            <token id="4" string="division" />
          </tokens>
        </chunking>
        <chunking id="4" string="The women 's" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="women" />
            <token id="3" string="'s" />
          </tokens>
        </chunking>
        <chunking id="5" string="many respectable entrants" type="NP">
          <tokens>
            <token id="9" string="many" />
            <token id="10" string="respectable" />
            <token id="11" string="entrants" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">women</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">division</governor>
          <dependent id="2">women</dependent>
        </dependency>
        <dependency type="case">
          <governor id="2">women</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="7">filled</governor>
          <dependent id="4">division</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">filled</governor>
          <dependent id="5">also</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="7">filled</governor>
          <dependent id="6">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">filled</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">entrants</governor>
          <dependent id="8">with</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">entrants</governor>
          <dependent id="9">many</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">entrants</governor>
          <dependent id="10">respectable</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">filled</governor>
          <dependent id="11">entrants</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="20" has_coreference="true">
      <content>Foremost among them are Kristiansen, the 35-year-old Norwegian who holds the world record of 2:21:06 and won in Boston in 1986 and 1989, and Samuelson, 33, the U.S.-record holder at 2:21:21, 1984 Olympic gold medalist and Boston champion in 1979 and 1983.</content>
      <tokens>
        <token id="1" string="Foremost" lemma="foremost" stem="foremost" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="among" lemma="among" stem="among" pos="IN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="4" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Kristiansen" lemma="Kristiansen" stem="kristiansen" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="35-year-old" lemma="35-year-old" stem="35-year-old" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="9" string="Norwegian" lemma="norwegian" stem="norwegian" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="10" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="holds" lemma="hold" stem="hold" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="record" lemma="record" stem="record" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="2:21:06" lemma="2:21:06" stem="2:21:06" pos="CD" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="17" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="won" lemma="win" stem="won" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="Boston" lemma="Boston" stem="boston" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="21" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="1986" lemma="1986" stem="1986" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="23" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="1989" lemma="1989" stem="1989" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="25" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="Samuelson" lemma="Samuelson" stem="samuelson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="28" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="33" lemma="33" stem="33" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="30" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="U.S.-record" lemma="u.s.-record" stem="u.s.-record" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="33" string="holder" lemma="holder" stem="holder" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="2:21:21" lemma="2:21:21" stem="2:21:21" pos="CD" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="36" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="37" string="1984" lemma="1984" stem="1984" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="38" string="Olympic" lemma="Olympic" stem="olympic" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="39" string="gold" lemma="gold" stem="gold" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="medalist" lemma="medalist" stem="medalist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="Boston" lemma="Boston" stem="boston" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="43" string="champion" lemma="champion" stem="champion" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="44" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="1979" lemma="1979" stem="1979" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="46" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="47" string="1983" lemma="1983" stem="1983" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="48" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (JJ Foremost)) (PP (IN among) (NP (PRP them)))) (VP (VBP are) (NP (NP (NNP Kristiansen)) (, ,) (NP (NP (DT the) (JJ 35-year-old) (JJ Norwegian)) (SBAR (WHNP (WP who)) (S (VP (VP (VBZ holds) (NP (NP (DT the) (NN world) (NN record)) (PP (IN of) (NP (CD 2:21:06))))) (CC and) (VP (VBD won) (PP (IN in) (NP (NP (NP (NNP Boston)) (PP (IN in) (NP (CD 1986) (CC and) (CD 1989)))) (, ,) (CC and) (NP (NP (NNP Samuelson)) (, ,) (NP (CD 33)) (, ,) (NP (NP (DT the) (JJ U.S.-record) (NN holder)) (PP (IN at) (NP (CD 2:21:21)))) (, ,) (NP (NP (CD 1984) (NNP Olympic) (NN gold) (NN medalist)) (CC and) (NP (NNP Boston) (NN champion)))))) (PP (IN in) (NP (CD 1979) (CC and) (CD 1983)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="who holds the world record of 2:21:06 and won in Boston in 1986 and 1989 , and Samuelson , 33 , the U.S.-record holder at 2:21:21 , 1984 Olympic gold medalist and Boston champion in 1979 and 1983" type="SBAR">
          <tokens>
            <token id="10" string="who" />
            <token id="11" string="holds" />
            <token id="12" string="the" />
            <token id="13" string="world" />
            <token id="14" string="record" />
            <token id="15" string="of" />
            <token id="16" string="2:21:06" />
            <token id="17" string="and" />
            <token id="18" string="won" />
            <token id="19" string="in" />
            <token id="20" string="Boston" />
            <token id="21" string="in" />
            <token id="22" string="1986" />
            <token id="23" string="and" />
            <token id="24" string="1989" />
            <token id="25" string="," />
            <token id="26" string="and" />
            <token id="27" string="Samuelson" />
            <token id="28" string="," />
            <token id="29" string="33" />
            <token id="30" string="," />
            <token id="31" string="the" />
            <token id="32" string="U.S.-record" />
            <token id="33" string="holder" />
            <token id="34" string="at" />
            <token id="35" string="2:21:21" />
            <token id="36" string="," />
            <token id="37" string="1984" />
            <token id="38" string="Olympic" />
            <token id="39" string="gold" />
            <token id="40" string="medalist" />
            <token id="41" string="and" />
            <token id="42" string="Boston" />
            <token id="43" string="champion" />
            <token id="44" string="in" />
            <token id="45" string="1979" />
            <token id="46" string="and" />
            <token id="47" string="1983" />
          </tokens>
        </chunking>
        <chunking id="2" string="Samuelson , 33 , the U.S.-record holder at 2:21:21 , 1984 Olympic gold medalist and Boston champion" type="NP">
          <tokens>
            <token id="27" string="Samuelson" />
            <token id="28" string="," />
            <token id="29" string="33" />
            <token id="30" string="," />
            <token id="31" string="the" />
            <token id="32" string="U.S.-record" />
            <token id="33" string="holder" />
            <token id="34" string="at" />
            <token id="35" string="2:21:21" />
            <token id="36" string="," />
            <token id="37" string="1984" />
            <token id="38" string="Olympic" />
            <token id="39" string="gold" />
            <token id="40" string="medalist" />
            <token id="41" string="and" />
            <token id="42" string="Boston" />
            <token id="43" string="champion" />
          </tokens>
        </chunking>
        <chunking id="3" string="the 35-year-old Norwegian" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="35-year-old" />
            <token id="9" string="Norwegian" />
          </tokens>
        </chunking>
        <chunking id="4" string="the U.S.-record holder at 2:21:21" type="NP">
          <tokens>
            <token id="31" string="the" />
            <token id="32" string="U.S.-record" />
            <token id="33" string="holder" />
            <token id="34" string="at" />
            <token id="35" string="2:21:21" />
          </tokens>
        </chunking>
        <chunking id="5" string="them" type="NP">
          <tokens>
            <token id="3" string="them" />
          </tokens>
        </chunking>
        <chunking id="6" string="Foremost" type="NP">
          <tokens>
            <token id="1" string="Foremost" />
          </tokens>
        </chunking>
        <chunking id="7" string="holds the world record of 2:21:06 and won in Boston in 1986 and 1989 , and Samuelson , 33 , the U.S.-record holder at 2:21:21 , 1984 Olympic gold medalist and Boston champion in 1979 and 1983" type="VP">
          <tokens>
            <token id="11" string="holds" />
            <token id="12" string="the" />
            <token id="13" string="world" />
            <token id="14" string="record" />
            <token id="15" string="of" />
            <token id="16" string="2:21:06" />
            <token id="17" string="and" />
            <token id="18" string="won" />
            <token id="19" string="in" />
            <token id="20" string="Boston" />
            <token id="21" string="in" />
            <token id="22" string="1986" />
            <token id="23" string="and" />
            <token id="24" string="1989" />
            <token id="25" string="," />
            <token id="26" string="and" />
            <token id="27" string="Samuelson" />
            <token id="28" string="," />
            <token id="29" string="33" />
            <token id="30" string="," />
            <token id="31" string="the" />
            <token id="32" string="U.S.-record" />
            <token id="33" string="holder" />
            <token id="34" string="at" />
            <token id="35" string="2:21:21" />
            <token id="36" string="," />
            <token id="37" string="1984" />
            <token id="38" string="Olympic" />
            <token id="39" string="gold" />
            <token id="40" string="medalist" />
            <token id="41" string="and" />
            <token id="42" string="Boston" />
            <token id="43" string="champion" />
            <token id="44" string="in" />
            <token id="45" string="1979" />
            <token id="46" string="and" />
            <token id="47" string="1983" />
          </tokens>
        </chunking>
        <chunking id="8" string="Foremost among them" type="NP">
          <tokens>
            <token id="1" string="Foremost" />
            <token id="2" string="among" />
            <token id="3" string="them" />
          </tokens>
        </chunking>
        <chunking id="9" string="1986 and 1989" type="NP">
          <tokens>
            <token id="22" string="1986" />
            <token id="23" string="and" />
            <token id="24" string="1989" />
          </tokens>
        </chunking>
        <chunking id="10" string="holds the world record of 2:21:06" type="VP">
          <tokens>
            <token id="11" string="holds" />
            <token id="12" string="the" />
            <token id="13" string="world" />
            <token id="14" string="record" />
            <token id="15" string="of" />
            <token id="16" string="2:21:06" />
          </tokens>
        </chunking>
        <chunking id="11" string="Kristiansen , the 35-year-old Norwegian who holds the world record of 2:21:06 and won in Boston in 1986 and 1989 , and Samuelson , 33 , the U.S.-record holder at 2:21:21 , 1984 Olympic gold medalist and Boston champion in 1979 and 1983" type="NP">
          <tokens>
            <token id="5" string="Kristiansen" />
            <token id="6" string="," />
            <token id="7" string="the" />
            <token id="8" string="35-year-old" />
            <token id="9" string="Norwegian" />
            <token id="10" string="who" />
            <token id="11" string="holds" />
            <token id="12" string="the" />
            <token id="13" string="world" />
            <token id="14" string="record" />
            <token id="15" string="of" />
            <token id="16" string="2:21:06" />
            <token id="17" string="and" />
            <token id="18" string="won" />
            <token id="19" string="in" />
            <token id="20" string="Boston" />
            <token id="21" string="in" />
            <token id="22" string="1986" />
            <token id="23" string="and" />
            <token id="24" string="1989" />
            <token id="25" string="," />
            <token id="26" string="and" />
            <token id="27" string="Samuelson" />
            <token id="28" string="," />
            <token id="29" string="33" />
            <token id="30" string="," />
            <token id="31" string="the" />
            <token id="32" string="U.S.-record" />
            <token id="33" string="holder" />
            <token id="34" string="at" />
            <token id="35" string="2:21:21" />
            <token id="36" string="," />
            <token id="37" string="1984" />
            <token id="38" string="Olympic" />
            <token id="39" string="gold" />
            <token id="40" string="medalist" />
            <token id="41" string="and" />
            <token id="42" string="Boston" />
            <token id="43" string="champion" />
            <token id="44" string="in" />
            <token id="45" string="1979" />
            <token id="46" string="and" />
            <token id="47" string="1983" />
          </tokens>
        </chunking>
        <chunking id="12" string="the 35-year-old Norwegian who holds the world record of 2:21:06 and won in Boston in 1986 and 1989 , and Samuelson , 33 , the U.S.-record holder at 2:21:21 , 1984 Olympic gold medalist and Boston champion in 1979 and 1983" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="35-year-old" />
            <token id="9" string="Norwegian" />
            <token id="10" string="who" />
            <token id="11" string="holds" />
            <token id="12" string="the" />
            <token id="13" string="world" />
            <token id="14" string="record" />
            <token id="15" string="of" />
            <token id="16" string="2:21:06" />
            <token id="17" string="and" />
            <token id="18" string="won" />
            <token id="19" string="in" />
            <token id="20" string="Boston" />
            <token id="21" string="in" />
            <token id="22" string="1986" />
            <token id="23" string="and" />
            <token id="24" string="1989" />
            <token id="25" string="," />
            <token id="26" string="and" />
            <token id="27" string="Samuelson" />
            <token id="28" string="," />
            <token id="29" string="33" />
            <token id="30" string="," />
            <token id="31" string="the" />
            <token id="32" string="U.S.-record" />
            <token id="33" string="holder" />
            <token id="34" string="at" />
            <token id="35" string="2:21:21" />
            <token id="36" string="," />
            <token id="37" string="1984" />
            <token id="38" string="Olympic" />
            <token id="39" string="gold" />
            <token id="40" string="medalist" />
            <token id="41" string="and" />
            <token id="42" string="Boston" />
            <token id="43" string="champion" />
            <token id="44" string="in" />
            <token id="45" string="1979" />
            <token id="46" string="and" />
            <token id="47" string="1983" />
          </tokens>
        </chunking>
        <chunking id="13" string="1984 Olympic gold medalist" type="NP">
          <tokens>
            <token id="37" string="1984" />
            <token id="38" string="Olympic" />
            <token id="39" string="gold" />
            <token id="40" string="medalist" />
          </tokens>
        </chunking>
        <chunking id="14" string="Samuelson" type="NP">
          <tokens>
            <token id="27" string="Samuelson" />
          </tokens>
        </chunking>
        <chunking id="15" string="Boston in 1986 and 1989" type="NP">
          <tokens>
            <token id="20" string="Boston" />
            <token id="21" string="in" />
            <token id="22" string="1986" />
            <token id="23" string="and" />
            <token id="24" string="1989" />
          </tokens>
        </chunking>
        <chunking id="16" string="Boston champion" type="NP">
          <tokens>
            <token id="42" string="Boston" />
            <token id="43" string="champion" />
          </tokens>
        </chunking>
        <chunking id="17" string="1979 and 1983" type="NP">
          <tokens>
            <token id="45" string="1979" />
            <token id="46" string="and" />
            <token id="47" string="1983" />
          </tokens>
        </chunking>
        <chunking id="18" string="the world record of 2:21:06" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="world" />
            <token id="14" string="record" />
            <token id="15" string="of" />
            <token id="16" string="2:21:06" />
          </tokens>
        </chunking>
        <chunking id="19" string="2:21:06" type="NP">
          <tokens>
            <token id="16" string="2:21:06" />
          </tokens>
        </chunking>
        <chunking id="20" string="the U.S.-record holder" type="NP">
          <tokens>
            <token id="31" string="the" />
            <token id="32" string="U.S.-record" />
            <token id="33" string="holder" />
          </tokens>
        </chunking>
        <chunking id="21" string="won in Boston in 1986 and 1989 , and Samuelson , 33 , the U.S.-record holder at 2:21:21 , 1984 Olympic gold medalist and Boston champion in 1979 and 1983" type="VP">
          <tokens>
            <token id="18" string="won" />
            <token id="19" string="in" />
            <token id="20" string="Boston" />
            <token id="21" string="in" />
            <token id="22" string="1986" />
            <token id="23" string="and" />
            <token id="24" string="1989" />
            <token id="25" string="," />
            <token id="26" string="and" />
            <token id="27" string="Samuelson" />
            <token id="28" string="," />
            <token id="29" string="33" />
            <token id="30" string="," />
            <token id="31" string="the" />
            <token id="32" string="U.S.-record" />
            <token id="33" string="holder" />
            <token id="34" string="at" />
            <token id="35" string="2:21:21" />
            <token id="36" string="," />
            <token id="37" string="1984" />
            <token id="38" string="Olympic" />
            <token id="39" string="gold" />
            <token id="40" string="medalist" />
            <token id="41" string="and" />
            <token id="42" string="Boston" />
            <token id="43" string="champion" />
            <token id="44" string="in" />
            <token id="45" string="1979" />
            <token id="46" string="and" />
            <token id="47" string="1983" />
          </tokens>
        </chunking>
        <chunking id="22" string="1984 Olympic gold medalist and Boston champion" type="NP">
          <tokens>
            <token id="37" string="1984" />
            <token id="38" string="Olympic" />
            <token id="39" string="gold" />
            <token id="40" string="medalist" />
            <token id="41" string="and" />
            <token id="42" string="Boston" />
            <token id="43" string="champion" />
          </tokens>
        </chunking>
        <chunking id="23" string="2:21:21" type="NP">
          <tokens>
            <token id="35" string="2:21:21" />
          </tokens>
        </chunking>
        <chunking id="24" string="Boston in 1986 and 1989 , and Samuelson , 33 , the U.S.-record holder at 2:21:21 , 1984 Olympic gold medalist and Boston champion" type="NP">
          <tokens>
            <token id="20" string="Boston" />
            <token id="21" string="in" />
            <token id="22" string="1986" />
            <token id="23" string="and" />
            <token id="24" string="1989" />
            <token id="25" string="," />
            <token id="26" string="and" />
            <token id="27" string="Samuelson" />
            <token id="28" string="," />
            <token id="29" string="33" />
            <token id="30" string="," />
            <token id="31" string="the" />
            <token id="32" string="U.S.-record" />
            <token id="33" string="holder" />
            <token id="34" string="at" />
            <token id="35" string="2:21:21" />
            <token id="36" string="," />
            <token id="37" string="1984" />
            <token id="38" string="Olympic" />
            <token id="39" string="gold" />
            <token id="40" string="medalist" />
            <token id="41" string="and" />
            <token id="42" string="Boston" />
            <token id="43" string="champion" />
          </tokens>
        </chunking>
        <chunking id="25" string="the world record" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="world" />
            <token id="14" string="record" />
          </tokens>
        </chunking>
        <chunking id="26" string="Boston" type="NP">
          <tokens>
            <token id="20" string="Boston" />
          </tokens>
        </chunking>
        <chunking id="27" string="are Kristiansen , the 35-year-old Norwegian who holds the world record of 2:21:06 and won in Boston in 1986 and 1989 , and Samuelson , 33 , the U.S.-record holder at 2:21:21 , 1984 Olympic gold medalist and Boston champion in 1979 and 1983" type="VP">
          <tokens>
            <token id="4" string="are" />
            <token id="5" string="Kristiansen" />
            <token id="6" string="," />
            <token id="7" string="the" />
            <token id="8" string="35-year-old" />
            <token id="9" string="Norwegian" />
            <token id="10" string="who" />
            <token id="11" string="holds" />
            <token id="12" string="the" />
            <token id="13" string="world" />
            <token id="14" string="record" />
            <token id="15" string="of" />
            <token id="16" string="2:21:06" />
            <token id="17" string="and" />
            <token id="18" string="won" />
            <token id="19" string="in" />
            <token id="20" string="Boston" />
            <token id="21" string="in" />
            <token id="22" string="1986" />
            <token id="23" string="and" />
            <token id="24" string="1989" />
            <token id="25" string="," />
            <token id="26" string="and" />
            <token id="27" string="Samuelson" />
            <token id="28" string="," />
            <token id="29" string="33" />
            <token id="30" string="," />
            <token id="31" string="the" />
            <token id="32" string="U.S.-record" />
            <token id="33" string="holder" />
            <token id="34" string="at" />
            <token id="35" string="2:21:21" />
            <token id="36" string="," />
            <token id="37" string="1984" />
            <token id="38" string="Olympic" />
            <token id="39" string="gold" />
            <token id="40" string="medalist" />
            <token id="41" string="and" />
            <token id="42" string="Boston" />
            <token id="43" string="champion" />
            <token id="44" string="in" />
            <token id="45" string="1979" />
            <token id="46" string="and" />
            <token id="47" string="1983" />
          </tokens>
        </chunking>
        <chunking id="28" string="Kristiansen" type="NP">
          <tokens>
            <token id="5" string="Kristiansen" />
          </tokens>
        </chunking>
        <chunking id="29" string="33" type="NP">
          <tokens>
            <token id="29" string="33" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">Kristiansen</governor>
          <dependent id="1">Foremost</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">them</governor>
          <dependent id="2">among</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Foremost</governor>
          <dependent id="3">them</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">Kristiansen</governor>
          <dependent id="4">are</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">Kristiansen</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">Norwegian</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">Norwegian</governor>
          <dependent id="8">35-year-old</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="5">Kristiansen</governor>
          <dependent id="9">Norwegian</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">holds</governor>
          <dependent id="10">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="9">Norwegian</governor>
          <dependent id="11">holds</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">record</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">record</governor>
          <dependent id="13">world</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">holds</governor>
          <dependent id="14">record</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">2:21:06</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">record</governor>
          <dependent id="16">2:21:06</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="11">holds</governor>
          <dependent id="17">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">holds</governor>
          <dependent id="18">won</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">Boston</governor>
          <dependent id="19">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">won</governor>
          <dependent id="20">Boston</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">1986</governor>
          <dependent id="21">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">Boston</governor>
          <dependent id="22">1986</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="22">1986</governor>
          <dependent id="23">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="22">1986</governor>
          <dependent id="24">1989</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="20">Boston</governor>
          <dependent id="26">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="20">Boston</governor>
          <dependent id="27">Samuelson</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="27">Samuelson</governor>
          <dependent id="29">33</dependent>
        </dependency>
        <dependency type="det">
          <governor id="33">holder</governor>
          <dependent id="31">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="33">holder</governor>
          <dependent id="32">U.S.-record</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="27">Samuelson</governor>
          <dependent id="33">holder</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">2:21:21</governor>
          <dependent id="34">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="33">holder</governor>
          <dependent id="35">2:21:21</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="40">medalist</governor>
          <dependent id="37">1984</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="40">medalist</governor>
          <dependent id="38">Olympic</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="40">medalist</governor>
          <dependent id="39">gold</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="27">Samuelson</governor>
          <dependent id="40">medalist</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="40">medalist</governor>
          <dependent id="41">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="43">champion</governor>
          <dependent id="42">Boston</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="40">medalist</governor>
          <dependent id="43">champion</dependent>
        </dependency>
        <dependency type="case">
          <governor id="45">1979</governor>
          <dependent id="44">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">won</governor>
          <dependent id="45">1979</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="45">1979</governor>
          <dependent id="46">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="45">1979</governor>
          <dependent id="47">1983</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="2:21:21 ," type="TIME" score="0.0">
          <tokens>
            <token id="35" string="2:21:21" />
            <token id="36" string="," />
          </tokens>
        </entity>
        <entity id="2" string="Samuelson" type="PERSON" score="0.0">
          <tokens>
            <token id="27" string="Samuelson" />
          </tokens>
        </entity>
        <entity id="3" string="Olympic" type="MISC" score="0.0">
          <tokens>
            <token id="38" string="Olympic" />
          </tokens>
        </entity>
        <entity id="4" string="U.S.-record" type="MISC" score="0.0">
          <tokens>
            <token id="32" string="U.S.-record" />
          </tokens>
        </entity>
        <entity id="5" string="35-year-old" type="DURATION" score="0.0">
          <tokens>
            <token id="8" string="35-year-old" />
          </tokens>
        </entity>
        <entity id="6" string="2:21:06" type="TIME" score="0.0">
          <tokens>
            <token id="16" string="2:21:06" />
          </tokens>
        </entity>
        <entity id="7" string="1986" type="DATE" score="0.0">
          <tokens>
            <token id="22" string="1986" />
          </tokens>
        </entity>
        <entity id="8" string="1984" type="DATE" score="0.0">
          <tokens>
            <token id="37" string="1984" />
          </tokens>
        </entity>
        <entity id="9" string="1983" type="DATE" score="0.0">
          <tokens>
            <token id="47" string="1983" />
          </tokens>
        </entity>
        <entity id="10" string="Norwegian" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="9" string="Norwegian" />
          </tokens>
        </entity>
        <entity id="11" string="Boston" type="LOCATION" score="0.0">
          <tokens>
            <token id="20" string="Boston" />
          </tokens>
        </entity>
        <entity id="12" string="1979" type="DATE" score="0.0">
          <tokens>
            <token id="45" string="1979" />
          </tokens>
        </entity>
        <entity id="13" string="Kristiansen" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Kristiansen" />
          </tokens>
        </entity>
        <entity id="14" string="1989" type="DATE" score="0.0">
          <tokens>
            <token id="24" string="1989" />
          </tokens>
        </entity>
        <entity id="15" string="33" type="NUMBER" score="0.0">
          <tokens>
            <token id="29" string="33" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="21" has_coreference="true">
      <content>Challenging them will be Uta Pippig, Wanda Panfil and Kim Jones.</content>
      <tokens>
        <token id="1" string="Challenging" lemma="challenge" stem="challeng" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Uta" lemma="Uta" stem="uta" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="6" string="Pippig" lemma="Pippig" stem="pippig" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Wanda" lemma="Wanda" stem="wanda" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="9" string="Panfil" lemma="Panfil" stem="panfil" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="10" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Kim" lemma="Kim" stem="kim" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="12" string="Jones" lemma="Jones" stem="jone" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (VBG Challenging) (NP (PRP them)))) (VP (MD will) (VP (VB be) (NP (NP (NNP Uta) (NNP Pippig)) (, ,) (NP (NNP Wanda) (NNP Panfil)) (CC and) (NP (NNP Kim) (NNP Jones))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="be Uta Pippig , Wanda Panfil and Kim Jones" type="VP">
          <tokens>
            <token id="4" string="be" />
            <token id="5" string="Uta" />
            <token id="6" string="Pippig" />
            <token id="7" string="," />
            <token id="8" string="Wanda" />
            <token id="9" string="Panfil" />
            <token id="10" string="and" />
            <token id="11" string="Kim" />
            <token id="12" string="Jones" />
          </tokens>
        </chunking>
        <chunking id="2" string="Challenging them" type="VP">
          <tokens>
            <token id="1" string="Challenging" />
            <token id="2" string="them" />
          </tokens>
        </chunking>
        <chunking id="3" string="will be Uta Pippig , Wanda Panfil and Kim Jones" type="VP">
          <tokens>
            <token id="3" string="will" />
            <token id="4" string="be" />
            <token id="5" string="Uta" />
            <token id="6" string="Pippig" />
            <token id="7" string="," />
            <token id="8" string="Wanda" />
            <token id="9" string="Panfil" />
            <token id="10" string="and" />
            <token id="11" string="Kim" />
            <token id="12" string="Jones" />
          </tokens>
        </chunking>
        <chunking id="4" string="Wanda Panfil" type="NP">
          <tokens>
            <token id="8" string="Wanda" />
            <token id="9" string="Panfil" />
          </tokens>
        </chunking>
        <chunking id="5" string="Kim Jones" type="NP">
          <tokens>
            <token id="11" string="Kim" />
            <token id="12" string="Jones" />
          </tokens>
        </chunking>
        <chunking id="6" string="Uta Pippig" type="NP">
          <tokens>
            <token id="5" string="Uta" />
            <token id="6" string="Pippig" />
          </tokens>
        </chunking>
        <chunking id="7" string="them" type="NP">
          <tokens>
            <token id="2" string="them" />
          </tokens>
        </chunking>
        <chunking id="8" string="Uta Pippig , Wanda Panfil and Kim Jones" type="NP">
          <tokens>
            <token id="5" string="Uta" />
            <token id="6" string="Pippig" />
            <token id="7" string="," />
            <token id="8" string="Wanda" />
            <token id="9" string="Panfil" />
            <token id="10" string="and" />
            <token id="11" string="Kim" />
            <token id="12" string="Jones" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="csubj">
          <governor id="6">Pippig</governor>
          <dependent id="1">Challenging</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="1">Challenging</governor>
          <dependent id="2">them</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">Pippig</governor>
          <dependent id="3">will</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">Pippig</governor>
          <dependent id="4">be</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Pippig</governor>
          <dependent id="5">Uta</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">Pippig</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Panfil</governor>
          <dependent id="8">Wanda</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">Pippig</governor>
          <dependent id="9">Panfil</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">Pippig</governor>
          <dependent id="10">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Jones</governor>
          <dependent id="11">Kim</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">Pippig</governor>
          <dependent id="12">Jones</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Wanda Panfil" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Wanda" />
            <token id="9" string="Panfil" />
          </tokens>
        </entity>
        <entity id="2" string="Kim Jones" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Kim" />
            <token id="12" string="Jones" />
          </tokens>
        </entity>
        <entity id="3" string="Uta Pippig" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Uta" />
            <token id="6" string="Pippig" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="22" has_coreference="true">
      <content>Pippig finished second in Boston last year in a career-best 2:28:03.</content>
      <tokens>
        <token id="1" string="Pippig" lemma="Pippig" stem="pippig" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="finished" lemma="finish" stem="finish" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="second" lemma="second" stem="second" pos="RB" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="4" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Boston" lemma="Boston" stem="boston" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="6" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="7" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="8" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="career-best" lemma="career-best" stem="career-best" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="2:28:03" lemma="2:28:03" stem="2:28:03" pos="CD" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Pippig)) (VP (VBD finished) (ADVP (RB second) (PP (IN in) (NP (NNP Boston)) (NP-TMP (JJ last) (NN year)))) (PP (IN in) (NP (DT a) (JJ career-best) (CD 2:28:03)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="finished second in Boston last year in a career-best 2:28:03" type="VP">
          <tokens>
            <token id="2" string="finished" />
            <token id="3" string="second" />
            <token id="4" string="in" />
            <token id="5" string="Boston" />
            <token id="6" string="last" />
            <token id="7" string="year" />
            <token id="8" string="in" />
            <token id="9" string="a" />
            <token id="10" string="career-best" />
            <token id="11" string="2:28:03" />
          </tokens>
        </chunking>
        <chunking id="2" string="a career-best 2:28:03" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="career-best" />
            <token id="11" string="2:28:03" />
          </tokens>
        </chunking>
        <chunking id="3" string="Pippig" type="NP">
          <tokens>
            <token id="1" string="Pippig" />
          </tokens>
        </chunking>
        <chunking id="4" string="Boston" type="NP">
          <tokens>
            <token id="5" string="Boston" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">finished</governor>
          <dependent id="1">Pippig</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">finished</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="2">finished</governor>
          <dependent id="3">second</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">Boston</governor>
          <dependent id="4">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">second</governor>
          <dependent id="5">Boston</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">year</governor>
          <dependent id="6">last</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="5">Boston</governor>
          <dependent id="7">year</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">2:28:03</governor>
          <dependent id="8">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">2:28:03</governor>
          <dependent id="9">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">2:28:03</governor>
          <dependent id="10">career-best</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">finished</governor>
          <dependent id="11">2:28:03</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="2:28:03" type="TIME" score="0.0">
          <tokens>
            <token id="11" string="2:28:03" />
          </tokens>
        </entity>
        <entity id="2" string="second" type="ORDINAL" score="0.0">
          <tokens>
            <token id="3" string="second" />
          </tokens>
        </entity>
        <entity id="3" string="Pippig" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Pippig" />
          </tokens>
        </entity>
        <entity id="4" string="last year" type="DATE" score="0.0">
          <tokens>
            <token id="6" string="last" />
            <token id="7" string="year" />
          </tokens>
        </entity>
        <entity id="5" string="Boston" type="LOCATION" score="0.0">
          <tokens>
            <token id="5" string="Boston" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="23" has_coreference="true">
      <content>Panfil won the London Marathon in 2:26:31, her personal best, and won the New York City Marathon in 1990.</content>
      <tokens>
        <token id="1" string="Panfil" lemma="Panfil" stem="panfil" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="won" lemma="win" stem="won" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="London" lemma="London" stem="london" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="5" string="Marathon" lemma="Marathon" stem="marathon" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="2:26:31" lemma="2:26:31" stem="2:26:31" pos="CD" type="Word" isStopWord="false" ner="TIME" is_referenced="true" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="personal" lemma="personal" stem="person" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="best" lemma="best" stem="best" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="won" lemma="win" stem="won" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="New" lemma="New" stem="new" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="17" string="York" lemma="York" stem="york" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="18" string="City" lemma="City" stem="citi" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="19" string="Marathon" lemma="Marathon" stem="marathon" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="20" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="1990" lemma="1990" stem="1990" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Panfil)) (VP (VP (VBD won) (NP (DT the) (NNP London) (NNP Marathon)) (PP (IN in) (NP (NP (CD 2:26:31)) (, ,) (NP (NP (PRP$ her) (JJ personal)) (NP (JJS best)))))) (, ,) (CC and) (VP (VBD won) (NP (DT the) (NNP New) (NNP York) (NNP City) (NNP Marathon)) (PP (IN in) (NP (CD 1990))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="2:26:31" type="NP">
          <tokens>
            <token id="7" string="2:26:31" />
          </tokens>
        </chunking>
        <chunking id="2" string="won the New York City Marathon in 1990" type="VP">
          <tokens>
            <token id="14" string="won" />
            <token id="15" string="the" />
            <token id="16" string="New" />
            <token id="17" string="York" />
            <token id="18" string="City" />
            <token id="19" string="Marathon" />
            <token id="20" string="in" />
            <token id="21" string="1990" />
          </tokens>
        </chunking>
        <chunking id="3" string="won the London Marathon in 2:26:31 , her personal best" type="VP">
          <tokens>
            <token id="2" string="won" />
            <token id="3" string="the" />
            <token id="4" string="London" />
            <token id="5" string="Marathon" />
            <token id="6" string="in" />
            <token id="7" string="2:26:31" />
            <token id="8" string="," />
            <token id="9" string="her" />
            <token id="10" string="personal" />
            <token id="11" string="best" />
          </tokens>
        </chunking>
        <chunking id="4" string="the London Marathon" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="London" />
            <token id="5" string="Marathon" />
          </tokens>
        </chunking>
        <chunking id="5" string="Panfil" type="NP">
          <tokens>
            <token id="1" string="Panfil" />
          </tokens>
        </chunking>
        <chunking id="6" string="her personal" type="NP">
          <tokens>
            <token id="9" string="her" />
            <token id="10" string="personal" />
          </tokens>
        </chunking>
        <chunking id="7" string="1990" type="NP">
          <tokens>
            <token id="21" string="1990" />
          </tokens>
        </chunking>
        <chunking id="8" string="her personal best" type="NP">
          <tokens>
            <token id="9" string="her" />
            <token id="10" string="personal" />
            <token id="11" string="best" />
          </tokens>
        </chunking>
        <chunking id="9" string="the New York City Marathon" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="New" />
            <token id="17" string="York" />
            <token id="18" string="City" />
            <token id="19" string="Marathon" />
          </tokens>
        </chunking>
        <chunking id="10" string="won the London Marathon in 2:26:31 , her personal best , and won the New York City Marathon in 1990" type="VP">
          <tokens>
            <token id="2" string="won" />
            <token id="3" string="the" />
            <token id="4" string="London" />
            <token id="5" string="Marathon" />
            <token id="6" string="in" />
            <token id="7" string="2:26:31" />
            <token id="8" string="," />
            <token id="9" string="her" />
            <token id="10" string="personal" />
            <token id="11" string="best" />
            <token id="12" string="," />
            <token id="13" string="and" />
            <token id="14" string="won" />
            <token id="15" string="the" />
            <token id="16" string="New" />
            <token id="17" string="York" />
            <token id="18" string="City" />
            <token id="19" string="Marathon" />
            <token id="20" string="in" />
            <token id="21" string="1990" />
          </tokens>
        </chunking>
        <chunking id="11" string="best" type="NP">
          <tokens>
            <token id="11" string="best" />
          </tokens>
        </chunking>
        <chunking id="12" string="2:26:31 , her personal best" type="NP">
          <tokens>
            <token id="7" string="2:26:31" />
            <token id="8" string="," />
            <token id="9" string="her" />
            <token id="10" string="personal" />
            <token id="11" string="best" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">won</governor>
          <dependent id="1">Panfil</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">won</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">Marathon</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Marathon</governor>
          <dependent id="4">London</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">won</governor>
          <dependent id="5">Marathon</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">2:26:31</governor>
          <dependent id="6">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">won</governor>
          <dependent id="7">2:26:31</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="10">personal</governor>
          <dependent id="9">her</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="7">2:26:31</governor>
          <dependent id="10">personal</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="10">personal</governor>
          <dependent id="11">best</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">won</governor>
          <dependent id="13">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">won</governor>
          <dependent id="14">won</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">Marathon</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">Marathon</governor>
          <dependent id="16">New</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">Marathon</governor>
          <dependent id="17">York</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">Marathon</governor>
          <dependent id="18">City</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">won</governor>
          <dependent id="19">Marathon</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">1990</governor>
          <dependent id="20">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">won</governor>
          <dependent id="21">1990</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="2:26:31" type="TIME" score="0.0">
          <tokens>
            <token id="7" string="2:26:31" />
          </tokens>
        </entity>
        <entity id="2" string="New York City Marathon" type="LOCATION" score="0.0">
          <tokens>
            <token id="16" string="New" />
            <token id="17" string="York" />
            <token id="18" string="City" />
            <token id="19" string="Marathon" />
          </tokens>
        </entity>
        <entity id="3" string="Panfil" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Panfil" />
          </tokens>
        </entity>
        <entity id="4" string="London" type="LOCATION" score="0.0">
          <tokens>
            <token id="4" string="London" />
          </tokens>
        </entity>
        <entity id="5" string="1990" type="DATE" score="0.0">
          <tokens>
            <token id="21" string="1990" />
          </tokens>
        </entity>
      </entities>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="1" type="PROPER">
      <referenced ids_tokens="12" string="Boston" id_sentence="2" />
      <mentions>
        <mention ids_tokens="37-38" string="Boston's" id_sentence="17" />
      </mentions>
    </coreference>
    <coreference id="2" type="NOMINAL">
      <referenced ids_tokens="5-6-7-8-9-10-11-12-13" string="the men 's winner of Monday 's Boston Marathon." id_sentence="2" />
      <mentions>
        <mention ids_tokens="1-2" string="The winner" id_sentence="12" />
      </mentions>
    </coreference>
    <coreference id="3" type="NOMINAL">
      <referenced ids_tokens="16-17" string="the women" id_sentence="2" />
      <mentions>
        <mention ids_tokens="12-13" string="women's" id_sentence="3" />
        <mention ids_tokens="1-3" string="The women's" id_sentence="19" />
        <mention ids_tokens="3" string="them" id_sentence="20" />
      </mentions>
    </coreference>
    <coreference id="4" type="PROPER">
      <referenced ids_tokens="2-3" string="Ingrid Kristiansen" id_sentence="3" />
      <mentions>
        <mention ids_tokens="14" string="his" id_sentence="4" />
        <mention ids_tokens="5" string="Kristiansen" id_sentence="20" />
      </mentions>
    </coreference>
    <coreference id="5" type="PROPER">
      <referenced ids_tokens="5-6-7" string="Joan Benoit Samuelson" id_sentence="3" />
      <mentions>
        <mention ids_tokens="27" string="Samuelson" id_sentence="20" />
      </mentions>
    </coreference>
    <coreference id="8" type="NOMINAL">
      <referenced ids_tokens="3-4" string="the sentimentalists" id_sentence="4" />
      <mentions>
        <mention ids_tokens="1" string="They" id_sentence="7" />
        <mention ids_tokens="1" string="They" id_sentence="8" />
      </mentions>
    </coreference>
    <coreference id="9" type="PROPER">
      <referenced ids_tokens="9-10-11-12-13-14-15-16-17" string="83-year-old Johnny Kelley starting in his 60th Boston Marathon" id_sentence="4" />
      <mentions>
        <mention ids_tokens="12" string="him" id_sentence="5" />
      </mentions>
    </coreference>
    <coreference id="10" type="NOMINAL">
      <referenced ids_tokens="17-18-19-20-21" string="the race 's storied history" id_sentence="7" />
      <mentions>
        <mention ids_tokens="39-42" string="the race's history" id_sentence="13" />
      </mentions>
    </coreference>
    <coreference id="13" type="PROPER">
      <referenced ids_tokens="20-21-22" string="Simon Robert Naali" id_sentence="10" />
      <mentions>
        <mention ids_tokens="64" string="Naali" id_sentence="17" />
      </mentions>
    </coreference>
    <coreference id="14" type="PROPER">
      <referenced ids_tokens="24-25" string="Juma Ikangaa" id_sentence="10" />
      <mentions>
        <mention ids_tokens="1" string="Ikangaa" id_sentence="14" />
        <mention ids_tokens="3" string="his" id_sentence="15" />
        <mention ids_tokens="1" string="Ikangaa" id_sentence="16" />
        <mention ids_tokens="24" string="Ikangaa" id_sentence="17" />
      </mentions>
    </coreference>
    <coreference id="15" type="PROPER">
      <referenced ids_tokens="15-16" string="last year" id_sentence="10" />
      <mentions>
        <mention ids_tokens="51-53" string="last year's" id_sentence="18" />
      </mentions>
    </coreference>
    <coreference id="17" type="PROPER">
      <referenced ids_tokens="7-8" string="Gelindo Bordin" id_sentence="12" />
      <mentions>
        <mention ids_tokens="13" string="Bordin" id_sentence="13" />
      </mentions>
    </coreference>
    <coreference id="18" type="NOMINAL">
      <referenced ids_tokens="12-13-14" string="the early pacesetters" id_sentence="12" />
      <mentions>
        <mention ids_tokens="15" string="them" id_sentence="13" />
      </mentions>
    </coreference>
    <coreference id="19" type="PROPER">
      <referenced ids_tokens="3-4-5" string="a distant second" id_sentence="14" />
      <mentions>
        <mention ids_tokens="1" string="It" id_sentence="15" />
        <mention ids_tokens="3-9" string="his third consecutive runner-up finish in Boston" id_sentence="15" />
      </mentions>
    </coreference>
    <coreference id="25" type="PROPER">
      <referenced ids_tokens="51-52-53-54-55-56-57" string="last year 's New York City Marathon" id_sentence="18" />
      <mentions>
        <mention ids_tokens="15-19" string="the New York City Marathon" id_sentence="23" />
      </mentions>
    </coreference>
    <coreference id="27" type="NOMINAL">
      <referenced ids_tokens="1-2-3" string="Foremost among them" id_sentence="20" />
      <mentions>
        <mention ids_tokens="2" string="them" id_sentence="21" />
      </mentions>
    </coreference>
    <coreference id="28" type="PROPER">
      <referenced ids_tokens="5-6" string="Uta Pippig" id_sentence="21" />
      <mentions>
        <mention ids_tokens="1" string="Pippig" id_sentence="22" />
      </mentions>
    </coreference>
    <coreference id="29" type="PROPER">
      <referenced ids_tokens="8-9" string="Wanda Panfil" id_sentence="21" />
      <mentions>
        <mention ids_tokens="1" string="Panfil" id_sentence="23" />
        <mention ids_tokens="9" string="her" id_sentence="23" />
      </mentions>
    </coreference>
  </coreferences>
</document>
