<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="AP900313-0191">
  <sentences>
    <sentence id="1" has_coreference="false">
      <content>From a helicopter, the wave-washed beach looks as if the worst oil spill in U.S. history had never touched it.</content>
      <tokens>
        <token id="1" string="From" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="helicopter" lemma="helicopter" stem="helicopt" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="wave-washed" lemma="wave-washed" stem="wave-wash" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="beach" lemma="beach" stem="beach" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="looks" lemma="look" stem="look" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="worst" lemma="worst" stem="worst" pos="JJS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="oil" lemma="oil" stem="oil" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="spill" lemma="spill" stem="spill" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="U.S." lemma="U.S." stem="u.s." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="17" string="history" lemma="history" stem="histori" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="touched" lemma="touch" stem="touch" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN From) (NP (DT a) (NN helicopter))) (, ,) (NP (DT the) (JJ wave-washed) (NN beach)) (VP (VBZ looks) (SBAR (IN as) (IN if) (S (NP (NP (DT the) (JJS worst) (NN oil) (NN spill)) (PP (IN in) (NP (NNP U.S.) (NN history)))) (VP (VBD had) (ADVP (RB never)) (VP (VBN touched) (NP (PRP it))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the wave-washed beach" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="wave-washed" />
            <token id="7" string="beach" />
          </tokens>
        </chunking>
        <chunking id="2" string="U.S. history" type="NP">
          <tokens>
            <token id="16" string="U.S." />
            <token id="17" string="history" />
          </tokens>
        </chunking>
        <chunking id="3" string="looks as if the worst oil spill in U.S. history had never touched it" type="VP">
          <tokens>
            <token id="8" string="looks" />
            <token id="9" string="as" />
            <token id="10" string="if" />
            <token id="11" string="the" />
            <token id="12" string="worst" />
            <token id="13" string="oil" />
            <token id="14" string="spill" />
            <token id="15" string="in" />
            <token id="16" string="U.S." />
            <token id="17" string="history" />
            <token id="18" string="had" />
            <token id="19" string="never" />
            <token id="20" string="touched" />
            <token id="21" string="it" />
          </tokens>
        </chunking>
        <chunking id="4" string="as if the worst oil spill in U.S. history had never touched it" type="SBAR">
          <tokens>
            <token id="9" string="as" />
            <token id="10" string="if" />
            <token id="11" string="the" />
            <token id="12" string="worst" />
            <token id="13" string="oil" />
            <token id="14" string="spill" />
            <token id="15" string="in" />
            <token id="16" string="U.S." />
            <token id="17" string="history" />
            <token id="18" string="had" />
            <token id="19" string="never" />
            <token id="20" string="touched" />
            <token id="21" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="the worst oil spill in U.S. history" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="worst" />
            <token id="13" string="oil" />
            <token id="14" string="spill" />
            <token id="15" string="in" />
            <token id="16" string="U.S." />
            <token id="17" string="history" />
          </tokens>
        </chunking>
        <chunking id="6" string="touched it" type="VP">
          <tokens>
            <token id="20" string="touched" />
            <token id="21" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="the worst oil spill" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="worst" />
            <token id="13" string="oil" />
            <token id="14" string="spill" />
          </tokens>
        </chunking>
        <chunking id="8" string="it" type="NP">
          <tokens>
            <token id="21" string="it" />
          </tokens>
        </chunking>
        <chunking id="9" string="had never touched it" type="VP">
          <tokens>
            <token id="18" string="had" />
            <token id="19" string="never" />
            <token id="20" string="touched" />
            <token id="21" string="it" />
          </tokens>
        </chunking>
        <chunking id="10" string="a helicopter" type="NP">
          <tokens>
            <token id="2" string="a" />
            <token id="3" string="helicopter" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">helicopter</governor>
          <dependent id="1">From</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">helicopter</governor>
          <dependent id="2">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">looks</governor>
          <dependent id="3">helicopter</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">beach</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">beach</governor>
          <dependent id="6">wave-washed</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">looks</governor>
          <dependent id="7">beach</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">looks</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="20">touched</governor>
          <dependent id="9">as</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="9">as</governor>
          <dependent id="10">if</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">spill</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">spill</governor>
          <dependent id="12">worst</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">spill</governor>
          <dependent id="13">oil</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">touched</governor>
          <dependent id="14">spill</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">history</governor>
          <dependent id="15">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">history</governor>
          <dependent id="16">U.S.</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">spill</governor>
          <dependent id="17">history</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="20">touched</governor>
          <dependent id="18">had</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="20">touched</governor>
          <dependent id="19">never</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="8">looks</governor>
          <dependent id="20">touched</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">touched</governor>
          <dependent id="21">it</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="U.S." type="LOCATION" score="0.0">
          <tokens>
            <token id="16" string="U.S." />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="false">
      <content>Silvery sticks of driftwood poke through a deep blanket of snow, and smooth gray pebbles roll in the surf under the gaze of a bald eagle perched in a shoreside spruce.</content>
      <tokens>
        <token id="1" string="Silvery" lemma="silvery" stem="silveri" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="sticks" lemma="stick" stem="stick" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="driftwood" lemma="driftwood" stem="driftwood" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="poke" lemma="poke" stem="poke" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="deep" lemma="deep" stem="deep" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="blanket" lemma="blanket" stem="blanket" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="snow" lemma="snow" stem="snow" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="smooth" lemma="smooth" stem="smooth" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="gray" lemma="gray" stem="grai" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="pebbles" lemma="pebble" stem="pebbl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="roll" lemma="roll" stem="roll" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="surf" lemma="surf" stem="surf" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="under" lemma="under" stem="under" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="gaze" lemma="gaze" stem="gaze" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="bald" lemma="bald" stem="bald" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="eagle" lemma="eagle" stem="eagl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="perched" lemma="perch" stem="perch" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="shoreside" lemma="shoreside" stem="shoresid" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="spruce" lemma="spruce" stem="spruce" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NP (JJ Silvery) (NNS sticks)) (PP (IN of) (NP (NN driftwood) (NN poke))) (UCP (PP (IN through) (NP (NP (DT a) (JJ deep) (NN blanket)) (PP (IN of) (NP (NN snow))))) (, ,) (CC and) (S (VP (VB smooth) (SBAR (S (NP (JJ gray) (NNS pebbles)) (VP (VBP roll) (SBAR (IN in) (S (NP (DT the) (NN surf)) (VP (ADVP (IN under) (DT the)) (VBP gaze))))))))))) (PP (IN of) (NP (NP (DT a) (JJ bald) (NN eagle)) (VP (VBN perched) (PP (IN in) (NP (DT a) (JJ shoreside))))))) (VP (VBP spruce)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="perched in a shoreside" type="VP">
          <tokens>
            <token id="28" string="perched" />
            <token id="29" string="in" />
            <token id="30" string="a" />
            <token id="31" string="shoreside" />
          </tokens>
        </chunking>
        <chunking id="2" string="driftwood poke" type="NP">
          <tokens>
            <token id="4" string="driftwood" />
            <token id="5" string="poke" />
          </tokens>
        </chunking>
        <chunking id="3" string="the surf" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="surf" />
          </tokens>
        </chunking>
        <chunking id="4" string="gray pebbles roll in the surf under the gaze" type="SBAR">
          <tokens>
            <token id="15" string="gray" />
            <token id="16" string="pebbles" />
            <token id="17" string="roll" />
            <token id="18" string="in" />
            <token id="19" string="the" />
            <token id="20" string="surf" />
            <token id="21" string="under" />
            <token id="22" string="the" />
            <token id="23" string="gaze" />
          </tokens>
        </chunking>
        <chunking id="5" string="Silvery sticks" type="NP">
          <tokens>
            <token id="1" string="Silvery" />
            <token id="2" string="sticks" />
          </tokens>
        </chunking>
        <chunking id="6" string="a deep blanket of snow" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="deep" />
            <token id="9" string="blanket" />
            <token id="10" string="of" />
            <token id="11" string="snow" />
          </tokens>
        </chunking>
        <chunking id="7" string="Silvery sticks of driftwood poke through a deep blanket of snow , and smooth gray pebbles roll in the surf under the gaze of a bald eagle perched in a shoreside" type="NP">
          <tokens>
            <token id="1" string="Silvery" />
            <token id="2" string="sticks" />
            <token id="3" string="of" />
            <token id="4" string="driftwood" />
            <token id="5" string="poke" />
            <token id="6" string="through" />
            <token id="7" string="a" />
            <token id="8" string="deep" />
            <token id="9" string="blanket" />
            <token id="10" string="of" />
            <token id="11" string="snow" />
            <token id="12" string="," />
            <token id="13" string="and" />
            <token id="14" string="smooth" />
            <token id="15" string="gray" />
            <token id="16" string="pebbles" />
            <token id="17" string="roll" />
            <token id="18" string="in" />
            <token id="19" string="the" />
            <token id="20" string="surf" />
            <token id="21" string="under" />
            <token id="22" string="the" />
            <token id="23" string="gaze" />
            <token id="24" string="of" />
            <token id="25" string="a" />
            <token id="26" string="bald" />
            <token id="27" string="eagle" />
            <token id="28" string="perched" />
            <token id="29" string="in" />
            <token id="30" string="a" />
            <token id="31" string="shoreside" />
          </tokens>
        </chunking>
        <chunking id="8" string="a shoreside" type="NP">
          <tokens>
            <token id="30" string="a" />
            <token id="31" string="shoreside" />
          </tokens>
        </chunking>
        <chunking id="9" string="roll in the surf under the gaze" type="VP">
          <tokens>
            <token id="17" string="roll" />
            <token id="18" string="in" />
            <token id="19" string="the" />
            <token id="20" string="surf" />
            <token id="21" string="under" />
            <token id="22" string="the" />
            <token id="23" string="gaze" />
          </tokens>
        </chunking>
        <chunking id="10" string="gray pebbles" type="NP">
          <tokens>
            <token id="15" string="gray" />
            <token id="16" string="pebbles" />
          </tokens>
        </chunking>
        <chunking id="11" string="a bald eagle" type="NP">
          <tokens>
            <token id="25" string="a" />
            <token id="26" string="bald" />
            <token id="27" string="eagle" />
          </tokens>
        </chunking>
        <chunking id="12" string="under the gaze" type="VP">
          <tokens>
            <token id="21" string="under" />
            <token id="22" string="the" />
            <token id="23" string="gaze" />
          </tokens>
        </chunking>
        <chunking id="13" string="snow" type="NP">
          <tokens>
            <token id="11" string="snow" />
          </tokens>
        </chunking>
        <chunking id="14" string="Silvery sticks of driftwood poke through a deep blanket of snow , and smooth gray pebbles roll in the surf under the gaze" type="NP">
          <tokens>
            <token id="1" string="Silvery" />
            <token id="2" string="sticks" />
            <token id="3" string="of" />
            <token id="4" string="driftwood" />
            <token id="5" string="poke" />
            <token id="6" string="through" />
            <token id="7" string="a" />
            <token id="8" string="deep" />
            <token id="9" string="blanket" />
            <token id="10" string="of" />
            <token id="11" string="snow" />
            <token id="12" string="," />
            <token id="13" string="and" />
            <token id="14" string="smooth" />
            <token id="15" string="gray" />
            <token id="16" string="pebbles" />
            <token id="17" string="roll" />
            <token id="18" string="in" />
            <token id="19" string="the" />
            <token id="20" string="surf" />
            <token id="21" string="under" />
            <token id="22" string="the" />
            <token id="23" string="gaze" />
          </tokens>
        </chunking>
        <chunking id="15" string="a bald eagle perched in a shoreside" type="NP">
          <tokens>
            <token id="25" string="a" />
            <token id="26" string="bald" />
            <token id="27" string="eagle" />
            <token id="28" string="perched" />
            <token id="29" string="in" />
            <token id="30" string="a" />
            <token id="31" string="shoreside" />
          </tokens>
        </chunking>
        <chunking id="16" string="a deep blanket" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="deep" />
            <token id="9" string="blanket" />
          </tokens>
        </chunking>
        <chunking id="17" string="spruce" type="VP">
          <tokens>
            <token id="32" string="spruce" />
          </tokens>
        </chunking>
        <chunking id="18" string="smooth gray pebbles roll in the surf under the gaze" type="VP">
          <tokens>
            <token id="14" string="smooth" />
            <token id="15" string="gray" />
            <token id="16" string="pebbles" />
            <token id="17" string="roll" />
            <token id="18" string="in" />
            <token id="19" string="the" />
            <token id="20" string="surf" />
            <token id="21" string="under" />
            <token id="22" string="the" />
            <token id="23" string="gaze" />
          </tokens>
        </chunking>
        <chunking id="19" string="in the surf under the gaze" type="SBAR">
          <tokens>
            <token id="18" string="in" />
            <token id="19" string="the" />
            <token id="20" string="surf" />
            <token id="21" string="under" />
            <token id="22" string="the" />
            <token id="23" string="gaze" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="2">sticks</governor>
          <dependent id="1">Silvery</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="32">spruce</governor>
          <dependent id="2">sticks</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">poke</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">poke</governor>
          <dependent id="4">driftwood</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">sticks</governor>
          <dependent id="5">poke</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">blanket</governor>
          <dependent id="6">through</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">blanket</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">blanket</governor>
          <dependent id="8">deep</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">sticks</governor>
          <dependent id="9">blanket</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">snow</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">blanket</governor>
          <dependent id="11">snow</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">blanket</governor>
          <dependent id="13">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">blanket</governor>
          <dependent id="14">smooth</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">pebbles</governor>
          <dependent id="15">gray</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">roll</governor>
          <dependent id="16">pebbles</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="14">smooth</governor>
          <dependent id="17">roll</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="23">gaze</governor>
          <dependent id="18">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">surf</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">gaze</governor>
          <dependent id="20">surf</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">the</governor>
          <dependent id="21">under</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="23">gaze</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="17">roll</governor>
          <dependent id="23">gaze</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">eagle</governor>
          <dependent id="24">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">eagle</governor>
          <dependent id="25">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="27">eagle</governor>
          <dependent id="26">bald</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">sticks</governor>
          <dependent id="27">eagle</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="27">eagle</governor>
          <dependent id="28">perched</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">shoreside</governor>
          <dependent id="29">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">shoreside</governor>
          <dependent id="30">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">perched</governor>
          <dependent id="31">shoreside</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="32">spruce</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>But the view doesn&amp;apost;t impress Joe Bridgman of the Alaska Department of Environmental Conservation.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="view" lemma="view" stem="view" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="does" lemma="do" stem="doe" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="impress" lemma="impress" stem="impress" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="Joe" lemma="Joe" stem="joe" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="8" string="Bridgman" lemma="Bridgman" stem="bridgman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="Alaska" lemma="Alaska" stem="alaska" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="12" string="Department" lemma="Department" stem="depart" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="14" string="Environmental" lemma="Environmental" stem="environment" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="15" string="Conservation" lemma="Conservation" stem="conserv" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (DT the) (NN view)) (VP (VBZ does) (RB n't) (VP (VB impress) (NP (NP (NNP Joe) (NNP Bridgman)) (PP (IN of) (NP (NP (DT the) (NNP Alaska) (NNP Department)) (PP (IN of) (NP (NNP Environmental) (NNP Conservation)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="does n't impress Joe Bridgman of the Alaska Department of Environmental Conservation" type="VP">
          <tokens>
            <token id="4" string="does" />
            <token id="5" string="n't" />
            <token id="6" string="impress" />
            <token id="7" string="Joe" />
            <token id="8" string="Bridgman" />
            <token id="9" string="of" />
            <token id="10" string="the" />
            <token id="11" string="Alaska" />
            <token id="12" string="Department" />
            <token id="13" string="of" />
            <token id="14" string="Environmental" />
            <token id="15" string="Conservation" />
          </tokens>
        </chunking>
        <chunking id="2" string="Joe Bridgman" type="NP">
          <tokens>
            <token id="7" string="Joe" />
            <token id="8" string="Bridgman" />
          </tokens>
        </chunking>
        <chunking id="3" string="the Alaska Department of Environmental Conservation" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="Alaska" />
            <token id="12" string="Department" />
            <token id="13" string="of" />
            <token id="14" string="Environmental" />
            <token id="15" string="Conservation" />
          </tokens>
        </chunking>
        <chunking id="4" string="the Alaska Department" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="Alaska" />
            <token id="12" string="Department" />
          </tokens>
        </chunking>
        <chunking id="5" string="Environmental Conservation" type="NP">
          <tokens>
            <token id="14" string="Environmental" />
            <token id="15" string="Conservation" />
          </tokens>
        </chunking>
        <chunking id="6" string="Joe Bridgman of the Alaska Department of Environmental Conservation" type="NP">
          <tokens>
            <token id="7" string="Joe" />
            <token id="8" string="Bridgman" />
            <token id="9" string="of" />
            <token id="10" string="the" />
            <token id="11" string="Alaska" />
            <token id="12" string="Department" />
            <token id="13" string="of" />
            <token id="14" string="Environmental" />
            <token id="15" string="Conservation" />
          </tokens>
        </chunking>
        <chunking id="7" string="the view" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="view" />
          </tokens>
        </chunking>
        <chunking id="8" string="impress Joe Bridgman of the Alaska Department of Environmental Conservation" type="VP">
          <tokens>
            <token id="6" string="impress" />
            <token id="7" string="Joe" />
            <token id="8" string="Bridgman" />
            <token id="9" string="of" />
            <token id="10" string="the" />
            <token id="11" string="Alaska" />
            <token id="12" string="Department" />
            <token id="13" string="of" />
            <token id="14" string="Environmental" />
            <token id="15" string="Conservation" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="6">impress</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">view</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">impress</governor>
          <dependent id="3">view</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">impress</governor>
          <dependent id="4">does</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="6">impress</governor>
          <dependent id="5">n't</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">impress</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">Bridgman</governor>
          <dependent id="7">Joe</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">impress</governor>
          <dependent id="8">Bridgman</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">Department</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">Department</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Department</governor>
          <dependent id="11">Alaska</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">Bridgman</governor>
          <dependent id="12">Department</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">Conservation</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Conservation</governor>
          <dependent id="14">Environmental</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">Department</governor>
          <dependent id="15">Conservation</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Joe Bridgman" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Joe" />
            <token id="8" string="Bridgman" />
          </tokens>
        </entity>
        <entity id="2" string="Alaska Department of Environmental Conservation" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="11" string="Alaska" />
            <token id="12" string="Department" />
            <token id="13" string="of" />
            <token id="14" string="Environmental" />
            <token id="15" string="Conservation" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>Dashing out as the chopper lands, he digs into the cobble beach and quickly finds what he knew he would.</content>
      <tokens>
        <token id="1" string="Dashing" lemma="dash" stem="dash" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="chopper" lemma="chopper" stem="chopper" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="lands" lemma="land" stem="land" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="digs" lemma="dig" stem="dig" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="cobble" lemma="cobble" stem="cobbl" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="beach" lemma="beach" stem="beach" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="quickly" lemma="quickly" stem="quickli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="finds" lemma="find" stem="find" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="knew" lemma="know" stem="knew" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (VBG Dashing) (PRT (RP out)) (PP (IN as) (NP (DT the) (NN chopper) (NNS lands))))) (, ,) (NP (PRP he)) (VP (VP (VBZ digs) (PP (IN into) (NP (DT the) (JJ cobble) (NN beach)))) (CC and) (VP (ADVP (RB quickly)) (VBZ finds) (SBAR (WHNP (WP what)) (S (NP (PRP he)) (VP (VBD knew) (SBAR (S (NP (PRP he)) (VP (MD would))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the chopper lands" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="chopper" />
            <token id="6" string="lands" />
          </tokens>
        </chunking>
        <chunking id="2" string="would" type="VP">
          <tokens>
            <token id="21" string="would" />
          </tokens>
        </chunking>
        <chunking id="3" string="digs into the cobble beach and quickly finds what he knew he would" type="VP">
          <tokens>
            <token id="9" string="digs" />
            <token id="10" string="into" />
            <token id="11" string="the" />
            <token id="12" string="cobble" />
            <token id="13" string="beach" />
            <token id="14" string="and" />
            <token id="15" string="quickly" />
            <token id="16" string="finds" />
            <token id="17" string="what" />
            <token id="18" string="he" />
            <token id="19" string="knew" />
            <token id="20" string="he" />
            <token id="21" string="would" />
          </tokens>
        </chunking>
        <chunking id="4" string="he would" type="SBAR">
          <tokens>
            <token id="20" string="he" />
            <token id="21" string="would" />
          </tokens>
        </chunking>
        <chunking id="5" string="the cobble beach" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="cobble" />
            <token id="13" string="beach" />
          </tokens>
        </chunking>
        <chunking id="6" string="he" type="NP">
          <tokens>
            <token id="8" string="he" />
          </tokens>
        </chunking>
        <chunking id="7" string="quickly finds what he knew he would" type="VP">
          <tokens>
            <token id="15" string="quickly" />
            <token id="16" string="finds" />
            <token id="17" string="what" />
            <token id="18" string="he" />
            <token id="19" string="knew" />
            <token id="20" string="he" />
            <token id="21" string="would" />
          </tokens>
        </chunking>
        <chunking id="8" string="knew he would" type="VP">
          <tokens>
            <token id="19" string="knew" />
            <token id="20" string="he" />
            <token id="21" string="would" />
          </tokens>
        </chunking>
        <chunking id="9" string="what he knew he would" type="SBAR">
          <tokens>
            <token id="17" string="what" />
            <token id="18" string="he" />
            <token id="19" string="knew" />
            <token id="20" string="he" />
            <token id="21" string="would" />
          </tokens>
        </chunking>
        <chunking id="10" string="Dashing out as the chopper lands" type="VP">
          <tokens>
            <token id="1" string="Dashing" />
            <token id="2" string="out" />
            <token id="3" string="as" />
            <token id="4" string="the" />
            <token id="5" string="chopper" />
            <token id="6" string="lands" />
          </tokens>
        </chunking>
        <chunking id="11" string="digs into the cobble beach" type="VP">
          <tokens>
            <token id="9" string="digs" />
            <token id="10" string="into" />
            <token id="11" string="the" />
            <token id="12" string="cobble" />
            <token id="13" string="beach" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advcl">
          <governor id="9">digs</governor>
          <dependent id="1">Dashing</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="1">Dashing</governor>
          <dependent id="2">out</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">lands</governor>
          <dependent id="3">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">lands</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">lands</governor>
          <dependent id="5">chopper</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Dashing</governor>
          <dependent id="6">lands</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">digs</governor>
          <dependent id="8">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">digs</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">beach</governor>
          <dependent id="10">into</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">beach</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">beach</governor>
          <dependent id="12">cobble</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">digs</governor>
          <dependent id="13">beach</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">digs</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">finds</governor>
          <dependent id="15">quickly</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">digs</governor>
          <dependent id="16">finds</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">knew</governor>
          <dependent id="17">what</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">knew</governor>
          <dependent id="18">he</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="16">finds</governor>
          <dependent id="19">knew</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">would</governor>
          <dependent id="20">he</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="19">knew</governor>
          <dependent id="21">would</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>``Oil,&amp;apost;&amp;apost; he says.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Oil" lemma="oil" stem="oil" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (FRAG (NP (NN Oil))) (, ,) ('' '') (NP (PRP he)) (VP (VBZ says)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Oil" type="NP">
          <tokens>
            <token id="2" string="Oil" />
          </tokens>
        </chunking>
        <chunking id="2" string="says" type="VP">
          <tokens>
            <token id="6" string="says" />
          </tokens>
        </chunking>
        <chunking id="3" string="he" type="NP">
          <tokens>
            <token id="5" string="he" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="dep">
          <governor id="6">says</governor>
          <dependent id="2">Oil</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">says</governor>
          <dependent id="5">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">says</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>``Smell it?&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Smell" lemma="smell" stem="smell" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (VP (VB Smell) (NP (PRP it))) (. ?) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="Smell it" type="VP">
          <tokens>
            <token id="2" string="Smell" />
            <token id="3" string="it" />
          </tokens>
        </chunking>
        <chunking id="2" string="it" type="NP">
          <tokens>
            <token id="3" string="it" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">Smell</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">Smell</governor>
          <dependent id="3">it</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>The pungent odor of petroleum wafts through the air as the hole turns black with crude oil, an oozing remnant of the 10.8 million gallons spilled into Prince William Sound last March 24 by the tanker Exxon Valdez.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="pungent" lemma="pungent" stem="pungent" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="odor" lemma="odor" stem="odor" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="petroleum" lemma="petroleum" stem="petroleum" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="wafts" lemma="waft" stem="waft" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="air" lemma="air" stem="air" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="hole" lemma="hole" stem="hole" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="turns" lemma="turn" stem="turn" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="black" lemma="black" stem="black" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="crude" lemma="crude" stem="crude" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="oil" lemma="oil" stem="oil" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="oozing" lemma="ooze" stem="ooz" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="remnant" lemma="remnant" stem="remnant" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="10.8" lemma="10.8" stem="10.8" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="25" string="million" lemma="million" stem="million" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="26" string="gallons" lemma="gallon" stem="gallon" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="spilled" lemma="spill" stem="spill" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="Prince" lemma="Prince" stem="princ" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="30" string="William" lemma="William" stem="william" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="31" string="Sound" lemma="Sound" stem="sound" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="32" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="33" string="March" lemma="March" stem="march" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="34" string="24" lemma="24" stem="24" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="35" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="tanker" lemma="tanker" stem="tanker" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="Exxon" lemma="Exxon" stem="exxon" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="39" string="Valdez" lemma="Valdez" stem="valdez" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="40" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (S (NP (NP (DT The) (ADJP (JJ pungent)) (NN odor)) (PP (IN of) (NP (NN petroleum)))) (VP (VBZ wafts) (PP (IN through) (NP (DT the) (NN air))) (SBAR (IN as) (S (NP (DT the) (NN hole)) (VP (VBZ turns) (ADJP (JJ black) (PP (IN with) (NP (NP (JJ crude) (NN oil)) (, ,) (NP (NP (DT an) (VBG oozing) (NN remnant)) (PP (IN of) (NP (DT the) (QP (CD 10.8) (CD million)) (NNS gallons)))))))))))) (VP (VBD spilled) (PP (IN into) (NP (NNP Prince) (NNP William) (NNP Sound))) (NP-TMP (JJ last) (NNP March) (CD 24)) (PP (IN by) (NP (DT the) (NN tanker)))) (NP (NNP Exxon) (NNP Valdez)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="wafts through the air as the hole turns black with crude oil , an oozing remnant of the 10.8 million gallons" type="VP">
          <tokens>
            <token id="6" string="wafts" />
            <token id="7" string="through" />
            <token id="8" string="the" />
            <token id="9" string="air" />
            <token id="10" string="as" />
            <token id="11" string="the" />
            <token id="12" string="hole" />
            <token id="13" string="turns" />
            <token id="14" string="black" />
            <token id="15" string="with" />
            <token id="16" string="crude" />
            <token id="17" string="oil" />
            <token id="18" string="," />
            <token id="19" string="an" />
            <token id="20" string="oozing" />
            <token id="21" string="remnant" />
            <token id="22" string="of" />
            <token id="23" string="the" />
            <token id="24" string="10.8" />
            <token id="25" string="million" />
            <token id="26" string="gallons" />
          </tokens>
        </chunking>
        <chunking id="2" string="crude oil" type="NP">
          <tokens>
            <token id="16" string="crude" />
            <token id="17" string="oil" />
          </tokens>
        </chunking>
        <chunking id="3" string="the 10.8 million gallons" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="10.8" />
            <token id="25" string="million" />
            <token id="26" string="gallons" />
          </tokens>
        </chunking>
        <chunking id="4" string="Prince William Sound" type="NP">
          <tokens>
            <token id="29" string="Prince" />
            <token id="30" string="William" />
            <token id="31" string="Sound" />
          </tokens>
        </chunking>
        <chunking id="5" string="an oozing remnant of the 10.8 million gallons" type="NP">
          <tokens>
            <token id="19" string="an" />
            <token id="20" string="oozing" />
            <token id="21" string="remnant" />
            <token id="22" string="of" />
            <token id="23" string="the" />
            <token id="24" string="10.8" />
            <token id="25" string="million" />
            <token id="26" string="gallons" />
          </tokens>
        </chunking>
        <chunking id="6" string="The pungent odor of petroleum" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="pungent" />
            <token id="3" string="odor" />
            <token id="4" string="of" />
            <token id="5" string="petroleum" />
          </tokens>
        </chunking>
        <chunking id="7" string="black with crude oil , an oozing remnant of the 10.8 million gallons" type="ADJP">
          <tokens>
            <token id="14" string="black" />
            <token id="15" string="with" />
            <token id="16" string="crude" />
            <token id="17" string="oil" />
            <token id="18" string="," />
            <token id="19" string="an" />
            <token id="20" string="oozing" />
            <token id="21" string="remnant" />
            <token id="22" string="of" />
            <token id="23" string="the" />
            <token id="24" string="10.8" />
            <token id="25" string="million" />
            <token id="26" string="gallons" />
          </tokens>
        </chunking>
        <chunking id="8" string="the tanker" type="NP">
          <tokens>
            <token id="36" string="the" />
            <token id="37" string="tanker" />
          </tokens>
        </chunking>
        <chunking id="9" string="as the hole turns black with crude oil , an oozing remnant of the 10.8 million gallons" type="SBAR">
          <tokens>
            <token id="10" string="as" />
            <token id="11" string="the" />
            <token id="12" string="hole" />
            <token id="13" string="turns" />
            <token id="14" string="black" />
            <token id="15" string="with" />
            <token id="16" string="crude" />
            <token id="17" string="oil" />
            <token id="18" string="," />
            <token id="19" string="an" />
            <token id="20" string="oozing" />
            <token id="21" string="remnant" />
            <token id="22" string="of" />
            <token id="23" string="the" />
            <token id="24" string="10.8" />
            <token id="25" string="million" />
            <token id="26" string="gallons" />
          </tokens>
        </chunking>
        <chunking id="10" string="the air" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="air" />
          </tokens>
        </chunking>
        <chunking id="11" string="crude oil , an oozing remnant of the 10.8 million gallons" type="NP">
          <tokens>
            <token id="16" string="crude" />
            <token id="17" string="oil" />
            <token id="18" string="," />
            <token id="19" string="an" />
            <token id="20" string="oozing" />
            <token id="21" string="remnant" />
            <token id="22" string="of" />
            <token id="23" string="the" />
            <token id="24" string="10.8" />
            <token id="25" string="million" />
            <token id="26" string="gallons" />
          </tokens>
        </chunking>
        <chunking id="12" string="Exxon Valdez" type="NP">
          <tokens>
            <token id="38" string="Exxon" />
            <token id="39" string="Valdez" />
          </tokens>
        </chunking>
        <chunking id="13" string="pungent" type="ADJP">
          <tokens>
            <token id="2" string="pungent" />
          </tokens>
        </chunking>
        <chunking id="14" string="the hole" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="hole" />
          </tokens>
        </chunking>
        <chunking id="15" string="an oozing remnant" type="NP">
          <tokens>
            <token id="19" string="an" />
            <token id="20" string="oozing" />
            <token id="21" string="remnant" />
          </tokens>
        </chunking>
        <chunking id="16" string="spilled into Prince William Sound last March 24 by the tanker" type="VP">
          <tokens>
            <token id="27" string="spilled" />
            <token id="28" string="into" />
            <token id="29" string="Prince" />
            <token id="30" string="William" />
            <token id="31" string="Sound" />
            <token id="32" string="last" />
            <token id="33" string="March" />
            <token id="34" string="24" />
            <token id="35" string="by" />
            <token id="36" string="the" />
            <token id="37" string="tanker" />
          </tokens>
        </chunking>
        <chunking id="17" string="The pungent odor" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="pungent" />
            <token id="3" string="odor" />
          </tokens>
        </chunking>
        <chunking id="18" string="petroleum" type="NP">
          <tokens>
            <token id="5" string="petroleum" />
          </tokens>
        </chunking>
        <chunking id="19" string="turns black with crude oil , an oozing remnant of the 10.8 million gallons" type="VP">
          <tokens>
            <token id="13" string="turns" />
            <token id="14" string="black" />
            <token id="15" string="with" />
            <token id="16" string="crude" />
            <token id="17" string="oil" />
            <token id="18" string="," />
            <token id="19" string="an" />
            <token id="20" string="oozing" />
            <token id="21" string="remnant" />
            <token id="22" string="of" />
            <token id="23" string="the" />
            <token id="24" string="10.8" />
            <token id="25" string="million" />
            <token id="26" string="gallons" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">odor</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">odor</governor>
          <dependent id="2">pungent</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">wafts</governor>
          <dependent id="3">odor</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">petroleum</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">odor</governor>
          <dependent id="5">petroleum</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="27">spilled</governor>
          <dependent id="6">wafts</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">air</governor>
          <dependent id="7">through</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">air</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">wafts</governor>
          <dependent id="9">air</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">turns</governor>
          <dependent id="10">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">hole</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">turns</governor>
          <dependent id="12">hole</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="6">wafts</governor>
          <dependent id="13">turns</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="13">turns</governor>
          <dependent id="14">black</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">oil</governor>
          <dependent id="15">with</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">oil</governor>
          <dependent id="16">crude</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">black</governor>
          <dependent id="17">oil</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">remnant</governor>
          <dependent id="19">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">remnant</governor>
          <dependent id="20">oozing</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="17">oil</governor>
          <dependent id="21">remnant</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">gallons</governor>
          <dependent id="22">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">gallons</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">million</governor>
          <dependent id="24">10.8</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="26">gallons</governor>
          <dependent id="25">million</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">remnant</governor>
          <dependent id="26">gallons</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="27">spilled</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">Sound</governor>
          <dependent id="28">into</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">Sound</governor>
          <dependent id="29">Prince</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">Sound</governor>
          <dependent id="30">William</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">spilled</governor>
          <dependent id="31">Sound</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="33">March</governor>
          <dependent id="32">last</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="27">spilled</governor>
          <dependent id="33">March</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="33">March</governor>
          <dependent id="34">24</dependent>
        </dependency>
        <dependency type="case">
          <governor id="37">tanker</governor>
          <dependent id="35">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="37">tanker</governor>
          <dependent id="36">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">spilled</governor>
          <dependent id="37">tanker</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="39">Valdez</governor>
          <dependent id="38">Exxon</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">spilled</governor>
          <dependent id="39">Valdez</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="last March 24" type="DATE" score="0.0">
          <tokens>
            <token id="32" string="last" />
            <token id="33" string="March" />
            <token id="34" string="24" />
          </tokens>
        </entity>
        <entity id="2" string="Prince William Sound" type="LOCATION" score="0.0">
          <tokens>
            <token id="29" string="Prince" />
            <token id="30" string="William" />
            <token id="31" string="Sound" />
          </tokens>
        </entity>
        <entity id="3" string="10.8 million" type="NUMBER" score="0.0">
          <tokens>
            <token id="24" string="10.8" />
            <token id="25" string="million" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>Bridgman scoops up a shovelful of gravel, lugs it to the water&amp;apost;s edge and dumps it in.</content>
      <tokens>
        <token id="1" string="Bridgman" lemma="Bridgman" stem="bridgman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="scoops" lemma="scoop" stem="scoop" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="shovelful" lemma="shovelful" stem="shovel" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="gravel" lemma="gravel" stem="gravel" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="lugs" lemma="lug" stem="lug" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="11" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="water" lemma="water" stem="water" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="edge" lemma="edge" stem="edg" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="dumps" lemma="dump" stem="dump" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Bridgman)) (VP (VP (VBZ scoops) (PRT (RP up)) (NP (NP (DT a) (NN shovelful)) (PP (IN of) (NP (NP (NN gravel)) (, ,) (NP (NP (NNS lugs)) (VP (NP (PRP it)) (PP (TO to) (NP (NP (DT the) (NN water) (POS 's)) (NN edge))))))))) (CC and) (VP (VBZ dumps) (NP (PRP it)) (PP (IN in)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the water 's edge" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="water" />
            <token id="14" string="'s" />
            <token id="15" string="edge" />
          </tokens>
        </chunking>
        <chunking id="2" string="a shovelful" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="shovelful" />
          </tokens>
        </chunking>
        <chunking id="3" string="lugs" type="NP">
          <tokens>
            <token id="9" string="lugs" />
          </tokens>
        </chunking>
        <chunking id="4" string="it" type="NP">
          <tokens>
            <token id="10" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="dumps it in" type="VP">
          <tokens>
            <token id="17" string="dumps" />
            <token id="18" string="it" />
            <token id="19" string="in" />
          </tokens>
        </chunking>
        <chunking id="6" string="the water 's" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="water" />
            <token id="14" string="'s" />
          </tokens>
        </chunking>
        <chunking id="7" string="Bridgman" type="NP">
          <tokens>
            <token id="1" string="Bridgman" />
          </tokens>
        </chunking>
        <chunking id="8" string="gravel" type="NP">
          <tokens>
            <token id="7" string="gravel" />
          </tokens>
        </chunking>
        <chunking id="9" string="it to the water 's edge" type="VP">
          <tokens>
            <token id="10" string="it" />
            <token id="11" string="to" />
            <token id="12" string="the" />
            <token id="13" string="water" />
            <token id="14" string="'s" />
            <token id="15" string="edge" />
          </tokens>
        </chunking>
        <chunking id="10" string="a shovelful of gravel , lugs it to the water 's edge" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="shovelful" />
            <token id="6" string="of" />
            <token id="7" string="gravel" />
            <token id="8" string="," />
            <token id="9" string="lugs" />
            <token id="10" string="it" />
            <token id="11" string="to" />
            <token id="12" string="the" />
            <token id="13" string="water" />
            <token id="14" string="'s" />
            <token id="15" string="edge" />
          </tokens>
        </chunking>
        <chunking id="11" string="lugs it to the water 's edge" type="NP">
          <tokens>
            <token id="9" string="lugs" />
            <token id="10" string="it" />
            <token id="11" string="to" />
            <token id="12" string="the" />
            <token id="13" string="water" />
            <token id="14" string="'s" />
            <token id="15" string="edge" />
          </tokens>
        </chunking>
        <chunking id="12" string="scoops up a shovelful of gravel , lugs it to the water 's edge" type="VP">
          <tokens>
            <token id="2" string="scoops" />
            <token id="3" string="up" />
            <token id="4" string="a" />
            <token id="5" string="shovelful" />
            <token id="6" string="of" />
            <token id="7" string="gravel" />
            <token id="8" string="," />
            <token id="9" string="lugs" />
            <token id="10" string="it" />
            <token id="11" string="to" />
            <token id="12" string="the" />
            <token id="13" string="water" />
            <token id="14" string="'s" />
            <token id="15" string="edge" />
          </tokens>
        </chunking>
        <chunking id="13" string="gravel , lugs it to the water 's edge" type="NP">
          <tokens>
            <token id="7" string="gravel" />
            <token id="8" string="," />
            <token id="9" string="lugs" />
            <token id="10" string="it" />
            <token id="11" string="to" />
            <token id="12" string="the" />
            <token id="13" string="water" />
            <token id="14" string="'s" />
            <token id="15" string="edge" />
          </tokens>
        </chunking>
        <chunking id="14" string="scoops up a shovelful of gravel , lugs it to the water 's edge and dumps it in" type="VP">
          <tokens>
            <token id="2" string="scoops" />
            <token id="3" string="up" />
            <token id="4" string="a" />
            <token id="5" string="shovelful" />
            <token id="6" string="of" />
            <token id="7" string="gravel" />
            <token id="8" string="," />
            <token id="9" string="lugs" />
            <token id="10" string="it" />
            <token id="11" string="to" />
            <token id="12" string="the" />
            <token id="13" string="water" />
            <token id="14" string="'s" />
            <token id="15" string="edge" />
            <token id="16" string="and" />
            <token id="17" string="dumps" />
            <token id="18" string="it" />
            <token id="19" string="in" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">scoops</governor>
          <dependent id="1">Bridgman</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">scoops</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="2">scoops</governor>
          <dependent id="3">up</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">shovelful</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">scoops</governor>
          <dependent id="5">shovelful</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">gravel</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">shovelful</governor>
          <dependent id="7">gravel</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="7">gravel</governor>
          <dependent id="9">lugs</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="9">lugs</governor>
          <dependent id="10">it</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">edge</governor>
          <dependent id="11">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">water</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="15">edge</governor>
          <dependent id="13">water</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">water</governor>
          <dependent id="14">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">it</governor>
          <dependent id="15">edge</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">scoops</governor>
          <dependent id="16">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">scoops</governor>
          <dependent id="17">dumps</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">dumps</governor>
          <dependent id="18">it</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">dumps</governor>
          <dependent id="19">in</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Bridgman" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Bridgman" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>A rainbow sheen of oil spreads across the water.</content>
      <tokens>
        <token id="1" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="rainbow" lemma="rainbow" stem="rainbow" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="sheen" lemma="sheen" stem="sheen" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="oil" lemma="oil" stem="oil" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="spreads" lemma="spread" stem="spread" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="across" lemma="across" stem="across" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="water" lemma="water" stem="water" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (NP (NP (DT A) (NN rainbow) (NN sheen)) (PP (IN of) (NP (NN oil) (NNS spreads))) (PP (IN across) (NP (DT the) (NN water))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the water" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="water" />
          </tokens>
        </chunking>
        <chunking id="2" string="A rainbow sheen of oil spreads across the water ." type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="rainbow" />
            <token id="3" string="sheen" />
            <token id="4" string="of" />
            <token id="5" string="oil" />
            <token id="6" string="spreads" />
            <token id="7" string="across" />
            <token id="8" string="the" />
            <token id="9" string="water" />
            <token id="10" string="." />
          </tokens>
        </chunking>
        <chunking id="3" string="A rainbow sheen" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="rainbow" />
            <token id="3" string="sheen" />
          </tokens>
        </chunking>
        <chunking id="4" string="oil spreads" type="NP">
          <tokens>
            <token id="5" string="oil" />
            <token id="6" string="spreads" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">sheen</governor>
          <dependent id="1">A</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">sheen</governor>
          <dependent id="2">rainbow</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">sheen</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">spreads</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">spreads</governor>
          <dependent id="5">oil</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">sheen</governor>
          <dependent id="6">spreads</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">water</governor>
          <dependent id="7">across</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">water</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">sheen</governor>
          <dependent id="9">water</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>``Hundreds of gallons of oil are locked up under this beach,&amp;apost;&amp;apost; he says.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Hundreds" lemma="hundred" stem="hundr" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="gallons" lemma="gallon" stem="gallon" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="oil" lemma="oil" stem="oil" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="locked" lemma="lock" stem="lock" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="under" lemma="under" stem="under" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="beach" lemma="beach" stem="beach" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (NP (NNS Hundreds)) (PP (IN of) (NP (NP (NNS gallons)) (PP (IN of) (NP (NN oil)))))) (VP (VBP are) (VP (VBN locked) (PRT (RP up)) (PP (IN under) (NP (DT this) (NN beach)))))) (, ,) ('' '') (NP (PRP he)) (VP (VBZ says)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="oil" type="NP">
          <tokens>
            <token id="6" string="oil" />
          </tokens>
        </chunking>
        <chunking id="2" string="says" type="VP">
          <tokens>
            <token id="16" string="says" />
          </tokens>
        </chunking>
        <chunking id="3" string="locked up under this beach" type="VP">
          <tokens>
            <token id="8" string="locked" />
            <token id="9" string="up" />
            <token id="10" string="under" />
            <token id="11" string="this" />
            <token id="12" string="beach" />
          </tokens>
        </chunking>
        <chunking id="4" string="Hundreds of gallons of oil" type="NP">
          <tokens>
            <token id="2" string="Hundreds" />
            <token id="3" string="of" />
            <token id="4" string="gallons" />
            <token id="5" string="of" />
            <token id="6" string="oil" />
          </tokens>
        </chunking>
        <chunking id="5" string="gallons" type="NP">
          <tokens>
            <token id="4" string="gallons" />
          </tokens>
        </chunking>
        <chunking id="6" string="gallons of oil" type="NP">
          <tokens>
            <token id="4" string="gallons" />
            <token id="5" string="of" />
            <token id="6" string="oil" />
          </tokens>
        </chunking>
        <chunking id="7" string="this beach" type="NP">
          <tokens>
            <token id="11" string="this" />
            <token id="12" string="beach" />
          </tokens>
        </chunking>
        <chunking id="8" string="are locked up under this beach" type="VP">
          <tokens>
            <token id="7" string="are" />
            <token id="8" string="locked" />
            <token id="9" string="up" />
            <token id="10" string="under" />
            <token id="11" string="this" />
            <token id="12" string="beach" />
          </tokens>
        </chunking>
        <chunking id="9" string="he" type="NP">
          <tokens>
            <token id="15" string="he" />
          </tokens>
        </chunking>
        <chunking id="10" string="Hundreds" type="NP">
          <tokens>
            <token id="2" string="Hundreds" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="8">locked</governor>
          <dependent id="2">Hundreds</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">gallons</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">Hundreds</governor>
          <dependent id="4">gallons</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">oil</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">gallons</governor>
          <dependent id="6">oil</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="8">locked</governor>
          <dependent id="7">are</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="16">says</governor>
          <dependent id="8">locked</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="8">locked</governor>
          <dependent id="9">up</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">beach</governor>
          <dependent id="10">under</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">beach</governor>
          <dependent id="11">this</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">locked</governor>
          <dependent id="12">beach</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">says</governor>
          <dependent id="15">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="16">says</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="11" has_coreference="false">
      <content>``And this isn&amp;apost;t isolated.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="isolated" lemma="isolate" stem="isol" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (CC And) (NP (DT this)) (VP (VBZ is) (RB n't) (ADJP (VBN isolated))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="is n't isolated" type="VP">
          <tokens>
            <token id="4" string="is" />
            <token id="5" string="n't" />
            <token id="6" string="isolated" />
          </tokens>
        </chunking>
        <chunking id="2" string="isolated" type="ADJP">
          <tokens>
            <token id="6" string="isolated" />
          </tokens>
        </chunking>
        <chunking id="3" string="this" type="NP">
          <tokens>
            <token id="3" string="this" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="6">isolated</governor>
          <dependent id="2">And</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="6">isolated</governor>
          <dependent id="3">this</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="6">isolated</governor>
          <dependent id="4">is</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="6">isolated</governor>
          <dependent id="5">n't</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">isolated</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>There are hundreds of beaches all over the sound that are still oiled, and the oil is slowly bleeding out.</content>
      <tokens>
        <token id="1" string="There" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="hundreds" lemma="hundred" stem="hundr" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="beaches" lemma="beach" stem="beach" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="over" lemma="over" stem="over" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="sound" lemma="sound" stem="sound" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="still" lemma="still" stem="still" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="oiled" lemma="oil" stem="oil" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="oil" lemma="oil" stem="oil" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="slowly" lemma="slowly" stem="slowli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="bleeding" lemma="bleed" stem="bleed" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (EX There)) (VP (VBP are) (NP (NP (NNS hundreds)) (PP (IN of) (NP (NP (NNS beaches)) (PP (ADVP (DT all)) (IN over) (NP (NP (DT the) (NN sound)) (SBAR (WHNP (WDT that)) (S (VP (VBP are) (ADVP (RB still)) (VP (VBN oiled)))))))))))) (, ,) (CC and) (S (NP (DT the) (NN oil)) (VP (VBZ is) (ADVP (RB slowly)) (VP (VBG bleeding) (PRT (RP out))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the sound that are still oiled" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="sound" />
            <token id="10" string="that" />
            <token id="11" string="are" />
            <token id="12" string="still" />
            <token id="13" string="oiled" />
          </tokens>
        </chunking>
        <chunking id="2" string="that are still oiled" type="SBAR">
          <tokens>
            <token id="10" string="that" />
            <token id="11" string="are" />
            <token id="12" string="still" />
            <token id="13" string="oiled" />
          </tokens>
        </chunking>
        <chunking id="3" string="are still oiled" type="VP">
          <tokens>
            <token id="11" string="are" />
            <token id="12" string="still" />
            <token id="13" string="oiled" />
          </tokens>
        </chunking>
        <chunking id="4" string="the oil" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="oil" />
          </tokens>
        </chunking>
        <chunking id="5" string="the sound" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="sound" />
          </tokens>
        </chunking>
        <chunking id="6" string="beaches" type="NP">
          <tokens>
            <token id="5" string="beaches" />
          </tokens>
        </chunking>
        <chunking id="7" string="There" type="NP">
          <tokens>
            <token id="1" string="There" />
          </tokens>
        </chunking>
        <chunking id="8" string="hundreds of beaches all over the sound that are still oiled" type="NP">
          <tokens>
            <token id="3" string="hundreds" />
            <token id="4" string="of" />
            <token id="5" string="beaches" />
            <token id="6" string="all" />
            <token id="7" string="over" />
            <token id="8" string="the" />
            <token id="9" string="sound" />
            <token id="10" string="that" />
            <token id="11" string="are" />
            <token id="12" string="still" />
            <token id="13" string="oiled" />
          </tokens>
        </chunking>
        <chunking id="9" string="are hundreds of beaches all over the sound that are still oiled" type="VP">
          <tokens>
            <token id="2" string="are" />
            <token id="3" string="hundreds" />
            <token id="4" string="of" />
            <token id="5" string="beaches" />
            <token id="6" string="all" />
            <token id="7" string="over" />
            <token id="8" string="the" />
            <token id="9" string="sound" />
            <token id="10" string="that" />
            <token id="11" string="are" />
            <token id="12" string="still" />
            <token id="13" string="oiled" />
          </tokens>
        </chunking>
        <chunking id="10" string="is slowly bleeding out" type="VP">
          <tokens>
            <token id="18" string="is" />
            <token id="19" string="slowly" />
            <token id="20" string="bleeding" />
            <token id="21" string="out" />
          </tokens>
        </chunking>
        <chunking id="11" string="beaches all over the sound that are still oiled" type="NP">
          <tokens>
            <token id="5" string="beaches" />
            <token id="6" string="all" />
            <token id="7" string="over" />
            <token id="8" string="the" />
            <token id="9" string="sound" />
            <token id="10" string="that" />
            <token id="11" string="are" />
            <token id="12" string="still" />
            <token id="13" string="oiled" />
          </tokens>
        </chunking>
        <chunking id="12" string="hundreds" type="NP">
          <tokens>
            <token id="3" string="hundreds" />
          </tokens>
        </chunking>
        <chunking id="13" string="oiled" type="VP">
          <tokens>
            <token id="13" string="oiled" />
          </tokens>
        </chunking>
        <chunking id="14" string="bleeding out" type="VP">
          <tokens>
            <token id="20" string="bleeding" />
            <token id="21" string="out" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="expl">
          <governor id="2">are</governor>
          <dependent id="1">There</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">are</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="2">are</governor>
          <dependent id="3">hundreds</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">beaches</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">hundreds</governor>
          <dependent id="5">beaches</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">sound</governor>
          <dependent id="6">all</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">sound</governor>
          <dependent id="7">over</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">sound</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">beaches</governor>
          <dependent id="9">sound</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="13">oiled</governor>
          <dependent id="10">that</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="13">oiled</governor>
          <dependent id="11">are</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">oiled</governor>
          <dependent id="12">still</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="9">sound</governor>
          <dependent id="13">oiled</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">are</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">oil</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">bleeding</governor>
          <dependent id="17">oil</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="20">bleeding</governor>
          <dependent id="18">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="20">bleeding</governor>
          <dependent id="19">slowly</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">are</governor>
          <dependent id="20">bleeding</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="20">bleeding</governor>
          <dependent id="21">out</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="13" has_coreference="false">
      <content>``The beaches can look beautiful at the surface, but you can dig down, in this case just a few inches below the surface, and find lots of oil.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="beaches" lemma="beach" stem="beach" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="look" lemma="look" stem="look" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="beautiful" lemma="beautiful" stem="beauti" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="surface" lemma="surface" stem="surfac" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="dig" lemma="dig" stem="dig" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="down" lemma="down" stem="down" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="few" lemma="few" stem="few" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="inches" lemma="inch" stem="inch" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="below" lemma="below" stem="below" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="surface" lemma="surface" stem="surfac" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="find" lemma="find" stem="find" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="lots" lemma="lot" stem="lot" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="oil" lemma="oil" stem="oil" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (DT The) (NNS beaches)) (VP (MD can) (VP (VB look) (ADJP (JJ beautiful)) (PP (IN at) (NP (DT the) (NN surface)))))) (, ,) (CC but) (S (NP (PRP you)) (VP (MD can) (VP (VP (VB dig) (ADVP (RB down))) (, ,) (VP (PP (IN in) (NP (DT this) (NN case))) (ADVP (RB just) (NP (DT a) (JJ few) (NNS inches)) (PP (IN below) (NP (DT the) (NN surface))))) (, ,) (CC and) (VP (VB find) (NP (NP (NNS lots)) (PP (IN of) (NP (NN oil)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="The beaches" type="NP">
          <tokens>
            <token id="2" string="The" />
            <token id="3" string="beaches" />
          </tokens>
        </chunking>
        <chunking id="2" string="dig down" type="VP">
          <tokens>
            <token id="14" string="dig" />
            <token id="15" string="down" />
          </tokens>
        </chunking>
        <chunking id="3" string="this case" type="NP">
          <tokens>
            <token id="18" string="this" />
            <token id="19" string="case" />
          </tokens>
        </chunking>
        <chunking id="4" string="look beautiful at the surface" type="VP">
          <tokens>
            <token id="5" string="look" />
            <token id="6" string="beautiful" />
            <token id="7" string="at" />
            <token id="8" string="the" />
            <token id="9" string="surface" />
          </tokens>
        </chunking>
        <chunking id="5" string="can look beautiful at the surface" type="VP">
          <tokens>
            <token id="4" string="can" />
            <token id="5" string="look" />
            <token id="6" string="beautiful" />
            <token id="7" string="at" />
            <token id="8" string="the" />
            <token id="9" string="surface" />
          </tokens>
        </chunking>
        <chunking id="6" string="beautiful" type="ADJP">
          <tokens>
            <token id="6" string="beautiful" />
          </tokens>
        </chunking>
        <chunking id="7" string="oil" type="NP">
          <tokens>
            <token id="32" string="oil" />
          </tokens>
        </chunking>
        <chunking id="8" string="dig down , in this case just a few inches below the surface , and find lots of oil" type="VP">
          <tokens>
            <token id="14" string="dig" />
            <token id="15" string="down" />
            <token id="16" string="," />
            <token id="17" string="in" />
            <token id="18" string="this" />
            <token id="19" string="case" />
            <token id="20" string="just" />
            <token id="21" string="a" />
            <token id="22" string="few" />
            <token id="23" string="inches" />
            <token id="24" string="below" />
            <token id="25" string="the" />
            <token id="26" string="surface" />
            <token id="27" string="," />
            <token id="28" string="and" />
            <token id="29" string="find" />
            <token id="30" string="lots" />
            <token id="31" string="of" />
            <token id="32" string="oil" />
          </tokens>
        </chunking>
        <chunking id="9" string="lots" type="NP">
          <tokens>
            <token id="30" string="lots" />
          </tokens>
        </chunking>
        <chunking id="10" string="in this case just a few inches below the surface" type="VP">
          <tokens>
            <token id="17" string="in" />
            <token id="18" string="this" />
            <token id="19" string="case" />
            <token id="20" string="just" />
            <token id="21" string="a" />
            <token id="22" string="few" />
            <token id="23" string="inches" />
            <token id="24" string="below" />
            <token id="25" string="the" />
            <token id="26" string="surface" />
          </tokens>
        </chunking>
        <chunking id="11" string="find lots of oil" type="VP">
          <tokens>
            <token id="29" string="find" />
            <token id="30" string="lots" />
            <token id="31" string="of" />
            <token id="32" string="oil" />
          </tokens>
        </chunking>
        <chunking id="12" string="the surface" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="surface" />
          </tokens>
        </chunking>
        <chunking id="13" string="can dig down , in this case just a few inches below the surface , and find lots of oil" type="VP">
          <tokens>
            <token id="13" string="can" />
            <token id="14" string="dig" />
            <token id="15" string="down" />
            <token id="16" string="," />
            <token id="17" string="in" />
            <token id="18" string="this" />
            <token id="19" string="case" />
            <token id="20" string="just" />
            <token id="21" string="a" />
            <token id="22" string="few" />
            <token id="23" string="inches" />
            <token id="24" string="below" />
            <token id="25" string="the" />
            <token id="26" string="surface" />
            <token id="27" string="," />
            <token id="28" string="and" />
            <token id="29" string="find" />
            <token id="30" string="lots" />
            <token id="31" string="of" />
            <token id="32" string="oil" />
          </tokens>
        </chunking>
        <chunking id="14" string="a few inches" type="NP">
          <tokens>
            <token id="21" string="a" />
            <token id="22" string="few" />
            <token id="23" string="inches" />
          </tokens>
        </chunking>
        <chunking id="15" string="lots of oil" type="NP">
          <tokens>
            <token id="30" string="lots" />
            <token id="31" string="of" />
            <token id="32" string="oil" />
          </tokens>
        </chunking>
        <chunking id="16" string="you" type="NP">
          <tokens>
            <token id="12" string="you" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">beaches</governor>
          <dependent id="2">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">look</governor>
          <dependent id="3">beaches</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">look</governor>
          <dependent id="4">can</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">look</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">look</governor>
          <dependent id="6">beautiful</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">surface</governor>
          <dependent id="7">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">surface</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">look</governor>
          <dependent id="9">surface</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">look</governor>
          <dependent id="11">but</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">dig</governor>
          <dependent id="12">you</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="14">dig</governor>
          <dependent id="13">can</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">look</governor>
          <dependent id="14">dig</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">dig</governor>
          <dependent id="15">down</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">case</governor>
          <dependent id="17">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">case</governor>
          <dependent id="18">this</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">dig</governor>
          <dependent id="19">case</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="19">case</governor>
          <dependent id="20">just</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">inches</governor>
          <dependent id="21">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">inches</governor>
          <dependent id="22">few</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="20">just</governor>
          <dependent id="23">inches</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">surface</governor>
          <dependent id="24">below</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">surface</governor>
          <dependent id="25">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">just</governor>
          <dependent id="26">surface</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="14">dig</governor>
          <dependent id="28">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">dig</governor>
          <dependent id="29">find</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="29">find</governor>
          <dependent id="30">lots</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">oil</governor>
          <dependent id="31">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">lots</governor>
          <dependent id="32">oil</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="14" has_coreference="false">
      <content>Now, is that a threat or isn&amp;apost;t it?&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="Now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="threat" lemma="threat" stem="threat" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (ADVP (RB Now)) (, ,) (VP (VP (VBZ is) (ADVP (IN that) (NP (DT a) (NN threat)))) (CC or) (VP (VBZ is) (RB n't))) (NP (PRP it)) (. ?) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="a threat" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="threat" />
          </tokens>
        </chunking>
        <chunking id="2" string="is that a threat" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="that" />
            <token id="5" string="a" />
            <token id="6" string="threat" />
          </tokens>
        </chunking>
        <chunking id="3" string="is that a threat or is n't" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="that" />
            <token id="5" string="a" />
            <token id="6" string="threat" />
            <token id="7" string="or" />
            <token id="8" string="is" />
            <token id="9" string="n't" />
          </tokens>
        </chunking>
        <chunking id="4" string="is n't" type="VP">
          <tokens>
            <token id="8" string="is" />
            <token id="9" string="n't" />
          </tokens>
        </chunking>
        <chunking id="5" string="it" type="NP">
          <tokens>
            <token id="10" string="it" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="3">is</governor>
          <dependent id="1">Now</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">threat</governor>
          <dependent id="4">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">threat</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">is</governor>
          <dependent id="6">threat</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">is</governor>
          <dependent id="7">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">is</governor>
          <dependent id="8">is</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="8">is</governor>
          <dependent id="9">n't</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">is</governor>
          <dependent id="10">it</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Now" type="DATE" score="0.0">
          <tokens>
            <token id="1" string="Now" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>A year after the wreck of the Exxon Valdez, the question clings like the oil under this Perry Island beach.</content>
      <tokens>
        <token id="1" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="2" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="3" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="wreck" lemma="wreck" stem="wreck" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="Exxon" lemma="Exxon" stem="exxon" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="Valdez" lemma="Valdez" stem="valdez" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="question" lemma="question" stem="question" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="clings" lemma="cling" stem="cling" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="oil" lemma="oil" stem="oil" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="under" lemma="under" stem="under" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="Perry" lemma="Perry" stem="perri" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="20" string="Island" lemma="Island" stem="island" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="21" string="beach" lemma="beach" stem="beach" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (NP (DT A) (NN year)) (IN after) (NP (NP (DT the) (NN wreck)) (PP (IN of) (NP (DT the) (NNP Exxon) (NNP Valdez))))) (, ,) (NP (DT the) (NN question)) (VP (VBZ clings) (PP (IN like) (NP (NP (DT the) (NN oil)) (PP (IN under) (NP (DT this) (NNP Perry) (NNP Island) (NN beach)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the question" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="question" />
          </tokens>
        </chunking>
        <chunking id="2" string="this Perry Island beach" type="NP">
          <tokens>
            <token id="18" string="this" />
            <token id="19" string="Perry" />
            <token id="20" string="Island" />
            <token id="21" string="beach" />
          </tokens>
        </chunking>
        <chunking id="3" string="the wreck of the Exxon Valdez" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="wreck" />
            <token id="6" string="of" />
            <token id="7" string="the" />
            <token id="8" string="Exxon" />
            <token id="9" string="Valdez" />
          </tokens>
        </chunking>
        <chunking id="4" string="the oil under this Perry Island beach" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="oil" />
            <token id="17" string="under" />
            <token id="18" string="this" />
            <token id="19" string="Perry" />
            <token id="20" string="Island" />
            <token id="21" string="beach" />
          </tokens>
        </chunking>
        <chunking id="5" string="the oil" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="oil" />
          </tokens>
        </chunking>
        <chunking id="6" string="the Exxon Valdez" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="Exxon" />
            <token id="9" string="Valdez" />
          </tokens>
        </chunking>
        <chunking id="7" string="A year" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="year" />
          </tokens>
        </chunking>
        <chunking id="8" string="the wreck" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="wreck" />
          </tokens>
        </chunking>
        <chunking id="9" string="clings like the oil under this Perry Island beach" type="VP">
          <tokens>
            <token id="13" string="clings" />
            <token id="14" string="like" />
            <token id="15" string="the" />
            <token id="16" string="oil" />
            <token id="17" string="under" />
            <token id="18" string="this" />
            <token id="19" string="Perry" />
            <token id="20" string="Island" />
            <token id="21" string="beach" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">year</governor>
          <dependent id="1">A</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">clings</governor>
          <dependent id="2">year</dependent>
        </dependency>
        <dependency type="case">
          <governor id="2">year</governor>
          <dependent id="3">after</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">wreck</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="2">year</governor>
          <dependent id="5">wreck</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Valdez</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">Valdez</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Valdez</governor>
          <dependent id="8">Exxon</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">wreck</governor>
          <dependent id="9">Valdez</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">question</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">clings</governor>
          <dependent id="12">question</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">clings</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">oil</governor>
          <dependent id="14">like</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">oil</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">clings</governor>
          <dependent id="16">oil</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">beach</governor>
          <dependent id="17">under</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">beach</governor>
          <dependent id="18">this</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">beach</governor>
          <dependent id="19">Perry</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">beach</governor>
          <dependent id="20">Island</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">oil</governor>
          <dependent id="21">beach</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Perry Island" type="LOCATION" score="0.0">
          <tokens>
            <token id="19" string="Perry" />
            <token id="20" string="Island" />
          </tokens>
        </entity>
        <entity id="2" string="A year" type="DURATION" score="0.0">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="year" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="16" has_coreference="false">
      <content>Certainly, the worst is over; thousands of dead birds no longer wash up on shorelines as they did last summer.</content>
      <tokens>
        <token id="1" string="Certainly" lemma="certainly" stem="certainli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="worst" lemma="worst" stem="worst" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="over" lemma="over" stem="over" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="thousands" lemma="thousand" stem="thousand" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="dead" lemma="dead" stem="dead" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="birds" lemma="bird" stem="bird" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="no" lemma="no" stem="no" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="longer" lemma="longer" stem="longer" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="wash" lemma="wash" stem="wash" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="shorelines" lemma="shoreline" stem="shorelin" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="22" string="summer" lemma="summer" stem="summer" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (ADVP (RB Certainly)) (, ,) (NP (DT the) (JJS worst)) (VP (VBZ is) (ADJP (IN over)))) (: ;) (S (NP (NP (NNS thousands)) (PP (IN of) (NP (JJ dead) (NNS birds)))) (VP (ADVP (RB no) (RB longer)) (VB wash) (PRT (RP up)) (PP (IN on) (NP (NNS shorelines))) (SBAR (IN as) (S (NP (PRP they)) (VP (VBD did) (NP-TMP (JJ last) (NN summer))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="shorelines" type="NP">
          <tokens>
            <token id="17" string="shorelines" />
          </tokens>
        </chunking>
        <chunking id="2" string="they" type="NP">
          <tokens>
            <token id="19" string="they" />
          </tokens>
        </chunking>
        <chunking id="3" string="thousands of dead birds" type="NP">
          <tokens>
            <token id="8" string="thousands" />
            <token id="9" string="of" />
            <token id="10" string="dead" />
            <token id="11" string="birds" />
          </tokens>
        </chunking>
        <chunking id="4" string="the worst" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="worst" />
          </tokens>
        </chunking>
        <chunking id="5" string="as they did last summer" type="SBAR">
          <tokens>
            <token id="18" string="as" />
            <token id="19" string="they" />
            <token id="20" string="did" />
            <token id="21" string="last" />
            <token id="22" string="summer" />
          </tokens>
        </chunking>
        <chunking id="6" string="over" type="ADJP">
          <tokens>
            <token id="6" string="over" />
          </tokens>
        </chunking>
        <chunking id="7" string="did last summer" type="VP">
          <tokens>
            <token id="20" string="did" />
            <token id="21" string="last" />
            <token id="22" string="summer" />
          </tokens>
        </chunking>
        <chunking id="8" string="is over" type="VP">
          <tokens>
            <token id="5" string="is" />
            <token id="6" string="over" />
          </tokens>
        </chunking>
        <chunking id="9" string="thousands" type="NP">
          <tokens>
            <token id="8" string="thousands" />
          </tokens>
        </chunking>
        <chunking id="10" string="no longer wash up on shorelines as they did last summer" type="VP">
          <tokens>
            <token id="12" string="no" />
            <token id="13" string="longer" />
            <token id="14" string="wash" />
            <token id="15" string="up" />
            <token id="16" string="on" />
            <token id="17" string="shorelines" />
            <token id="18" string="as" />
            <token id="19" string="they" />
            <token id="20" string="did" />
            <token id="21" string="last" />
            <token id="22" string="summer" />
          </tokens>
        </chunking>
        <chunking id="11" string="dead birds" type="NP">
          <tokens>
            <token id="10" string="dead" />
            <token id="11" string="birds" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="6">over</governor>
          <dependent id="1">Certainly</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">worst</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">over</governor>
          <dependent id="4">worst</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">over</governor>
          <dependent id="5">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">over</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">wash</governor>
          <dependent id="8">thousands</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">birds</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">birds</governor>
          <dependent id="10">dead</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">thousands</governor>
          <dependent id="11">birds</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="13">longer</governor>
          <dependent id="12">no</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">wash</governor>
          <dependent id="13">longer</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="6">over</governor>
          <dependent id="14">wash</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="14">wash</governor>
          <dependent id="15">up</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">shorelines</governor>
          <dependent id="16">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">wash</governor>
          <dependent id="17">shorelines</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="20">did</governor>
          <dependent id="18">as</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">did</governor>
          <dependent id="19">they</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="14">wash</governor>
          <dependent id="20">did</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">summer</governor>
          <dependent id="21">last</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="20">did</governor>
          <dependent id="22">summer</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="last summer" type="DATE" score="0.0">
          <tokens>
            <token id="21" string="last" />
            <token id="22" string="summer" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="17" has_coreference="true">
      <content>But assessing the continuing damage wrought by the nation&amp;apost;s most extensive _ and expensive _ oil spill has just begun.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="assessing" lemma="assess" stem="assess" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="continuing" lemma="continue" stem="continu" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="damage" lemma="damage" stem="damag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="wrought" lemma="work" stem="wrought" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="nation" lemma="nation" stem="nation" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="most" lemma="most" stem="most" pos="RBS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="extensive" lemma="extensive" stem="extens" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="_" lemma="_" stem="_" pos="NN" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="expensive" lemma="expensive" stem="expens" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="_" lemma="_" stem="_" pos="NN" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="oil" lemma="oil" stem="oil" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="spill" lemma="spill" stem="spill" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="begun" lemma="begin" stem="begun" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (S (VP (VBG assessing) (NP (NP (DT the) (VBG continuing) (NN damage)) (VP (VBN wrought) (PP (IN by) (NP (NP (NP (DT the) (NN nation) (POS 's)) (ADJP (RBS most) (JJ extensive)) (NN _)) (CC and) (NP (JJ expensive) (NN _) (NN oil) (NN spill)))))))) (VP (VBZ has) (ADVP (RB just)) (VP (VBN begun))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="assessing the continuing damage wrought by the nation 's most extensive _ and expensive _ oil spill" type="VP">
          <tokens>
            <token id="2" string="assessing" />
            <token id="3" string="the" />
            <token id="4" string="continuing" />
            <token id="5" string="damage" />
            <token id="6" string="wrought" />
            <token id="7" string="by" />
            <token id="8" string="the" />
            <token id="9" string="nation" />
            <token id="10" string="'s" />
            <token id="11" string="most" />
            <token id="12" string="extensive" />
            <token id="13" string="_" />
            <token id="14" string="and" />
            <token id="15" string="expensive" />
            <token id="16" string="_" />
            <token id="17" string="oil" />
            <token id="18" string="spill" />
          </tokens>
        </chunking>
        <chunking id="2" string="the nation 's most extensive _ and expensive _ oil spill" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="nation" />
            <token id="10" string="'s" />
            <token id="11" string="most" />
            <token id="12" string="extensive" />
            <token id="13" string="_" />
            <token id="14" string="and" />
            <token id="15" string="expensive" />
            <token id="16" string="_" />
            <token id="17" string="oil" />
            <token id="18" string="spill" />
          </tokens>
        </chunking>
        <chunking id="3" string="has just begun" type="VP">
          <tokens>
            <token id="19" string="has" />
            <token id="20" string="just" />
            <token id="21" string="begun" />
          </tokens>
        </chunking>
        <chunking id="4" string="the continuing damage" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="continuing" />
            <token id="5" string="damage" />
          </tokens>
        </chunking>
        <chunking id="5" string="the nation 's most extensive _" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="nation" />
            <token id="10" string="'s" />
            <token id="11" string="most" />
            <token id="12" string="extensive" />
            <token id="13" string="_" />
          </tokens>
        </chunking>
        <chunking id="6" string="the continuing damage wrought by the nation 's most extensive _ and expensive _ oil spill" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="continuing" />
            <token id="5" string="damage" />
            <token id="6" string="wrought" />
            <token id="7" string="by" />
            <token id="8" string="the" />
            <token id="9" string="nation" />
            <token id="10" string="'s" />
            <token id="11" string="most" />
            <token id="12" string="extensive" />
            <token id="13" string="_" />
            <token id="14" string="and" />
            <token id="15" string="expensive" />
            <token id="16" string="_" />
            <token id="17" string="oil" />
            <token id="18" string="spill" />
          </tokens>
        </chunking>
        <chunking id="7" string="begun" type="VP">
          <tokens>
            <token id="21" string="begun" />
          </tokens>
        </chunking>
        <chunking id="8" string="wrought by the nation 's most extensive _ and expensive _ oil spill" type="VP">
          <tokens>
            <token id="6" string="wrought" />
            <token id="7" string="by" />
            <token id="8" string="the" />
            <token id="9" string="nation" />
            <token id="10" string="'s" />
            <token id="11" string="most" />
            <token id="12" string="extensive" />
            <token id="13" string="_" />
            <token id="14" string="and" />
            <token id="15" string="expensive" />
            <token id="16" string="_" />
            <token id="17" string="oil" />
            <token id="18" string="spill" />
          </tokens>
        </chunking>
        <chunking id="9" string="most extensive" type="ADJP">
          <tokens>
            <token id="11" string="most" />
            <token id="12" string="extensive" />
          </tokens>
        </chunking>
        <chunking id="10" string="expensive _ oil spill" type="NP">
          <tokens>
            <token id="15" string="expensive" />
            <token id="16" string="_" />
            <token id="17" string="oil" />
            <token id="18" string="spill" />
          </tokens>
        </chunking>
        <chunking id="11" string="the nation 's" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="nation" />
            <token id="10" string="'s" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="21">begun</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="csubj">
          <governor id="21">begun</governor>
          <dependent id="2">assessing</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">damage</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">damage</governor>
          <dependent id="4">continuing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">assessing</governor>
          <dependent id="5">damage</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="5">damage</governor>
          <dependent id="6">wrought</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">_</governor>
          <dependent id="7">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">nation</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="13">_</governor>
          <dependent id="9">nation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">nation</governor>
          <dependent id="10">'s</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">extensive</governor>
          <dependent id="11">most</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">_</governor>
          <dependent id="12">extensive</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">wrought</governor>
          <dependent id="13">_</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">_</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">spill</governor>
          <dependent id="15">expensive</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">spill</governor>
          <dependent id="16">_</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">spill</governor>
          <dependent id="17">oil</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">_</governor>
          <dependent id="18">spill</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="21">begun</governor>
          <dependent id="19">has</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="21">begun</governor>
          <dependent id="20">just</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="21">begun</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="18" has_coreference="true">
      <content>As a growing slick of lawyers haggles over who is to blame, Exxon Corp. and government agencies debate how to clean up what&amp;apost;s left and scientists track wildlife populations&amp;apost; first steps on the long road to recovery.</content>
      <tokens>
        <token id="1" string="As" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="growing" lemma="grow" stem="grow" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="slick" lemma="slick" stem="slick" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="lawyers" lemma="lawyer" stem="lawyer" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="haggles" lemma="haggle" stem="haggl" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="over" lemma="over" stem="over" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="blame" lemma="blame" stem="blame" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Exxon" lemma="Exxon" stem="exxon" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="15" string="Corp." lemma="Corp." stem="corp." pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="16" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="government" lemma="government" stem="govern" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="agencies" lemma="agency" stem="agenc" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="debate" lemma="debate" stem="debat" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="how" lemma="how" stem="how" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="clean" lemma="clean" stem="clean" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="left" lemma="leave" stem="left" pos="VBN" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="true" is_refers="false" />
        <token id="27" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="scientists" lemma="scientist" stem="scientist" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="29" string="track" lemma="track" stem="track" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="wildlife" lemma="wildlife" stem="wildlif" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="31" string="populations" lemma="population" stem="popul" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="32" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="33" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="34" string="steps" lemma="step" stem="step" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="long" lemma="long" stem="long" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="road" lemma="road" stem="road" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="recovery" lemma="recovery" stem="recoveri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN As) (S (NP (NP (DT a) (VBG growing) (NN slick)) (PP (IN of) (NP (NNS lawyers)))) (VP (VBZ haggles) (PP (IN over) (SBAR (WHNP (WP who)) (S (VP (VBZ is) (S (VP (TO to) (VP (VB blame))))))))))) (, ,) (S (NP (NP (NNP Exxon) (NNP Corp.)) (CC and) (NP (NN government) (NNS agencies))) (VP (VB debate) (SBAR (WHADVP (WRB how)) (S (VP (TO to) (VP (VB clean) (PRT (RP up)) (SBAR (WHNP (WP what)) (S (VP (VBZ 's) (VP (VBN left))))))))))) (CC and) (S (NP (NNS scientists)) (VP (VBP track) (NP (NP (NP (NN wildlife) (NNS populations) (POS ')) (JJ first) (NNS steps)) (PP (IN on) (NP (DT the) (JJ long) (NN road)))) (PP (TO to) (NP (NN recovery))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="what 's left" type="SBAR">
          <tokens>
            <token id="24" string="what" />
            <token id="25" string="'s" />
            <token id="26" string="left" />
          </tokens>
        </chunking>
        <chunking id="2" string="track wildlife populations ' first steps on the long road to recovery" type="VP">
          <tokens>
            <token id="29" string="track" />
            <token id="30" string="wildlife" />
            <token id="31" string="populations" />
            <token id="32" string="'" />
            <token id="33" string="first" />
            <token id="34" string="steps" />
            <token id="35" string="on" />
            <token id="36" string="the" />
            <token id="37" string="long" />
            <token id="38" string="road" />
            <token id="39" string="to" />
            <token id="40" string="recovery" />
          </tokens>
        </chunking>
        <chunking id="3" string="wildlife populations '" type="NP">
          <tokens>
            <token id="30" string="wildlife" />
            <token id="31" string="populations" />
            <token id="32" string="'" />
          </tokens>
        </chunking>
        <chunking id="4" string="As a growing slick of lawyers haggles over who is to blame" type="SBAR">
          <tokens>
            <token id="1" string="As" />
            <token id="2" string="a" />
            <token id="3" string="growing" />
            <token id="4" string="slick" />
            <token id="5" string="of" />
            <token id="6" string="lawyers" />
            <token id="7" string="haggles" />
            <token id="8" string="over" />
            <token id="9" string="who" />
            <token id="10" string="is" />
            <token id="11" string="to" />
            <token id="12" string="blame" />
          </tokens>
        </chunking>
        <chunking id="5" string="haggles over who is to blame" type="VP">
          <tokens>
            <token id="7" string="haggles" />
            <token id="8" string="over" />
            <token id="9" string="who" />
            <token id="10" string="is" />
            <token id="11" string="to" />
            <token id="12" string="blame" />
          </tokens>
        </chunking>
        <chunking id="6" string="debate how to clean up what 's left" type="VP">
          <tokens>
            <token id="19" string="debate" />
            <token id="20" string="how" />
            <token id="21" string="to" />
            <token id="22" string="clean" />
            <token id="23" string="up" />
            <token id="24" string="what" />
            <token id="25" string="'s" />
            <token id="26" string="left" />
          </tokens>
        </chunking>
        <chunking id="7" string="a growing slick of lawyers" type="NP">
          <tokens>
            <token id="2" string="a" />
            <token id="3" string="growing" />
            <token id="4" string="slick" />
            <token id="5" string="of" />
            <token id="6" string="lawyers" />
          </tokens>
        </chunking>
        <chunking id="8" string="wildlife populations ' first steps" type="NP">
          <tokens>
            <token id="30" string="wildlife" />
            <token id="31" string="populations" />
            <token id="32" string="'" />
            <token id="33" string="first" />
            <token id="34" string="steps" />
          </tokens>
        </chunking>
        <chunking id="9" string="a growing slick" type="NP">
          <tokens>
            <token id="2" string="a" />
            <token id="3" string="growing" />
            <token id="4" string="slick" />
          </tokens>
        </chunking>
        <chunking id="10" string="left" type="VP">
          <tokens>
            <token id="26" string="left" />
          </tokens>
        </chunking>
        <chunking id="11" string="scientists" type="NP">
          <tokens>
            <token id="28" string="scientists" />
          </tokens>
        </chunking>
        <chunking id="12" string="how to clean up what 's left" type="SBAR">
          <tokens>
            <token id="20" string="how" />
            <token id="21" string="to" />
            <token id="22" string="clean" />
            <token id="23" string="up" />
            <token id="24" string="what" />
            <token id="25" string="'s" />
            <token id="26" string="left" />
          </tokens>
        </chunking>
        <chunking id="13" string="clean up what 's left" type="VP">
          <tokens>
            <token id="22" string="clean" />
            <token id="23" string="up" />
            <token id="24" string="what" />
            <token id="25" string="'s" />
            <token id="26" string="left" />
          </tokens>
        </chunking>
        <chunking id="14" string="blame" type="VP">
          <tokens>
            <token id="12" string="blame" />
          </tokens>
        </chunking>
        <chunking id="15" string="'s left" type="VP">
          <tokens>
            <token id="25" string="'s" />
            <token id="26" string="left" />
          </tokens>
        </chunking>
        <chunking id="16" string="lawyers" type="NP">
          <tokens>
            <token id="6" string="lawyers" />
          </tokens>
        </chunking>
        <chunking id="17" string="to clean up what 's left" type="VP">
          <tokens>
            <token id="21" string="to" />
            <token id="22" string="clean" />
            <token id="23" string="up" />
            <token id="24" string="what" />
            <token id="25" string="'s" />
            <token id="26" string="left" />
          </tokens>
        </chunking>
        <chunking id="18" string="to blame" type="VP">
          <tokens>
            <token id="11" string="to" />
            <token id="12" string="blame" />
          </tokens>
        </chunking>
        <chunking id="19" string="Exxon Corp. and government agencies" type="NP">
          <tokens>
            <token id="14" string="Exxon" />
            <token id="15" string="Corp." />
            <token id="16" string="and" />
            <token id="17" string="government" />
            <token id="18" string="agencies" />
          </tokens>
        </chunking>
        <chunking id="20" string="the long road" type="NP">
          <tokens>
            <token id="36" string="the" />
            <token id="37" string="long" />
            <token id="38" string="road" />
          </tokens>
        </chunking>
        <chunking id="21" string="wildlife populations ' first steps on the long road" type="NP">
          <tokens>
            <token id="30" string="wildlife" />
            <token id="31" string="populations" />
            <token id="32" string="'" />
            <token id="33" string="first" />
            <token id="34" string="steps" />
            <token id="35" string="on" />
            <token id="36" string="the" />
            <token id="37" string="long" />
            <token id="38" string="road" />
          </tokens>
        </chunking>
        <chunking id="22" string="recovery" type="NP">
          <tokens>
            <token id="40" string="recovery" />
          </tokens>
        </chunking>
        <chunking id="23" string="how" type="WHADVP">
          <tokens>
            <token id="20" string="how" />
          </tokens>
        </chunking>
        <chunking id="24" string="Exxon Corp." type="NP">
          <tokens>
            <token id="14" string="Exxon" />
            <token id="15" string="Corp." />
          </tokens>
        </chunking>
        <chunking id="25" string="is to blame" type="VP">
          <tokens>
            <token id="10" string="is" />
            <token id="11" string="to" />
            <token id="12" string="blame" />
          </tokens>
        </chunking>
        <chunking id="26" string="who is to blame" type="SBAR">
          <tokens>
            <token id="9" string="who" />
            <token id="10" string="is" />
            <token id="11" string="to" />
            <token id="12" string="blame" />
          </tokens>
        </chunking>
        <chunking id="27" string="government agencies" type="NP">
          <tokens>
            <token id="17" string="government" />
            <token id="18" string="agencies" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="7">haggles</governor>
          <dependent id="1">As</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">slick</governor>
          <dependent id="2">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">slick</governor>
          <dependent id="3">growing</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">haggles</governor>
          <dependent id="4">slick</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">lawyers</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">slick</governor>
          <dependent id="6">lawyers</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="19">debate</governor>
          <dependent id="7">haggles</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">is</governor>
          <dependent id="8">over</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">is</governor>
          <dependent id="9">who</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="7">haggles</governor>
          <dependent id="10">is</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">blame</governor>
          <dependent id="11">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="10">is</governor>
          <dependent id="12">blame</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Corp.</governor>
          <dependent id="14">Exxon</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">debate</governor>
          <dependent id="15">Corp.</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="15">Corp.</governor>
          <dependent id="16">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">agencies</governor>
          <dependent id="17">government</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="15">Corp.</governor>
          <dependent id="18">agencies</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="19">debate</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="22">clean</governor>
          <dependent id="20">how</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">clean</governor>
          <dependent id="21">to</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="19">debate</governor>
          <dependent id="22">clean</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="22">clean</governor>
          <dependent id="23">up</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="26">left</governor>
          <dependent id="24">what</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="26">left</governor>
          <dependent id="25">'s</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="22">clean</governor>
          <dependent id="26">left</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="19">debate</governor>
          <dependent id="27">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">track</governor>
          <dependent id="28">scientists</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="19">debate</governor>
          <dependent id="29">track</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">populations</governor>
          <dependent id="30">wildlife</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="34">steps</governor>
          <dependent id="31">populations</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">populations</governor>
          <dependent id="32">'</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="34">steps</governor>
          <dependent id="33">first</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="29">track</governor>
          <dependent id="34">steps</dependent>
        </dependency>
        <dependency type="case">
          <governor id="38">road</governor>
          <dependent id="35">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="38">road</governor>
          <dependent id="36">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="38">road</governor>
          <dependent id="37">long</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="34">steps</governor>
          <dependent id="38">road</dependent>
        </dependency>
        <dependency type="case">
          <governor id="40">recovery</governor>
          <dependent id="39">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">track</governor>
          <dependent id="40">recovery</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="33" string="first" />
          </tokens>
        </entity>
        <entity id="2" string="Exxon Corp." type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="14" string="Exxon" />
            <token id="15" string="Corp." />
          </tokens>
        </entity>
        <entity id="3" string="left" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="26" string="left" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="19" has_coreference="false">
      <content>Any hope of a quick solution faded last summer as oil from the Exxon Valdez spread across 1,100 miles of Alaska&amp;apost;s wild southern coast.</content>
      <tokens>
        <token id="1" string="Any" lemma="any" stem="any" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="hope" lemma="hope" stem="hope" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="quick" lemma="quick" stem="quick" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="solution" lemma="solution" stem="solut" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="faded" lemma="fade" stem="fade" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="9" string="summer" lemma="summer" stem="summer" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="10" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="oil" lemma="oil" stem="oil" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Exxon" lemma="Exxon" stem="exxon" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="Valdez" lemma="Valdez" stem="valdez" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="spread" lemma="spread" stem="spread" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="across" lemma="across" stem="across" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="1,100" lemma="1,100" stem="1,100" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="19" string="miles" lemma="mile" stem="mile" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="Alaska" lemma="Alaska" stem="alaska" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="22" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="wild" lemma="wild" stem="wild" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="southern" lemma="southern" stem="southern" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="coast" lemma="coast" stem="coast" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT Any) (NN hope)) (PP (IN of) (NP (DT a) (JJ quick) (NN solution)))) (VP (VBN faded) (NP-TMP (JJ last) (NN summer)) (PP (IN as) (NP (NN oil))) (PP (IN from) (NP (NP (DT the) (NNP Exxon) (NNP Valdez) (NN spread)) (PP (IN across) (NP (NP (CD 1,100) (NNS miles)) (PP (IN of) (NP (NP (NNP Alaska) (POS 's)) (JJ wild) (JJ southern) (NN coast)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="oil" type="NP">
          <tokens>
            <token id="11" string="oil" />
          </tokens>
        </chunking>
        <chunking id="2" string="Alaska 's" type="NP">
          <tokens>
            <token id="21" string="Alaska" />
            <token id="22" string="'s" />
          </tokens>
        </chunking>
        <chunking id="3" string="Any hope of a quick solution" type="NP">
          <tokens>
            <token id="1" string="Any" />
            <token id="2" string="hope" />
            <token id="3" string="of" />
            <token id="4" string="a" />
            <token id="5" string="quick" />
            <token id="6" string="solution" />
          </tokens>
        </chunking>
        <chunking id="4" string="Any hope" type="NP">
          <tokens>
            <token id="1" string="Any" />
            <token id="2" string="hope" />
          </tokens>
        </chunking>
        <chunking id="5" string="Alaska 's wild southern coast" type="NP">
          <tokens>
            <token id="21" string="Alaska" />
            <token id="22" string="'s" />
            <token id="23" string="wild" />
            <token id="24" string="southern" />
            <token id="25" string="coast" />
          </tokens>
        </chunking>
        <chunking id="6" string="faded last summer as oil from the Exxon Valdez spread across 1,100 miles of Alaska 's wild southern coast" type="VP">
          <tokens>
            <token id="7" string="faded" />
            <token id="8" string="last" />
            <token id="9" string="summer" />
            <token id="10" string="as" />
            <token id="11" string="oil" />
            <token id="12" string="from" />
            <token id="13" string="the" />
            <token id="14" string="Exxon" />
            <token id="15" string="Valdez" />
            <token id="16" string="spread" />
            <token id="17" string="across" />
            <token id="18" string="1,100" />
            <token id="19" string="miles" />
            <token id="20" string="of" />
            <token id="21" string="Alaska" />
            <token id="22" string="'s" />
            <token id="23" string="wild" />
            <token id="24" string="southern" />
            <token id="25" string="coast" />
          </tokens>
        </chunking>
        <chunking id="7" string="the Exxon Valdez spread across 1,100 miles of Alaska 's wild southern coast" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="Exxon" />
            <token id="15" string="Valdez" />
            <token id="16" string="spread" />
            <token id="17" string="across" />
            <token id="18" string="1,100" />
            <token id="19" string="miles" />
            <token id="20" string="of" />
            <token id="21" string="Alaska" />
            <token id="22" string="'s" />
            <token id="23" string="wild" />
            <token id="24" string="southern" />
            <token id="25" string="coast" />
          </tokens>
        </chunking>
        <chunking id="8" string="the Exxon Valdez spread" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="Exxon" />
            <token id="15" string="Valdez" />
            <token id="16" string="spread" />
          </tokens>
        </chunking>
        <chunking id="9" string="1,100 miles" type="NP">
          <tokens>
            <token id="18" string="1,100" />
            <token id="19" string="miles" />
          </tokens>
        </chunking>
        <chunking id="10" string="1,100 miles of Alaska 's wild southern coast" type="NP">
          <tokens>
            <token id="18" string="1,100" />
            <token id="19" string="miles" />
            <token id="20" string="of" />
            <token id="21" string="Alaska" />
            <token id="22" string="'s" />
            <token id="23" string="wild" />
            <token id="24" string="southern" />
            <token id="25" string="coast" />
          </tokens>
        </chunking>
        <chunking id="11" string="a quick solution" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="quick" />
            <token id="6" string="solution" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">hope</governor>
          <dependent id="1">Any</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">faded</governor>
          <dependent id="2">hope</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">solution</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">solution</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">solution</governor>
          <dependent id="5">quick</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">hope</governor>
          <dependent id="6">solution</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">faded</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">summer</governor>
          <dependent id="8">last</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="7">faded</governor>
          <dependent id="9">summer</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">oil</governor>
          <dependent id="10">as</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">faded</governor>
          <dependent id="11">oil</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">spread</governor>
          <dependent id="12">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">spread</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">spread</governor>
          <dependent id="14">Exxon</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">spread</governor>
          <dependent id="15">Valdez</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">faded</governor>
          <dependent id="16">spread</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">miles</governor>
          <dependent id="17">across</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="19">miles</governor>
          <dependent id="18">1,100</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">spread</governor>
          <dependent id="19">miles</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">coast</governor>
          <dependent id="20">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="25">coast</governor>
          <dependent id="21">Alaska</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">Alaska</governor>
          <dependent id="22">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">coast</governor>
          <dependent id="23">wild</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">coast</governor>
          <dependent id="24">southern</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">miles</governor>
          <dependent id="25">coast</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1,100" type="NUMBER" score="0.0">
          <tokens>
            <token id="18" string="1,100" />
          </tokens>
        </entity>
        <entity id="2" string="last summer" type="DATE" score="0.0">
          <tokens>
            <token id="8" string="last" />
            <token id="9" string="summer" />
          </tokens>
        </entity>
        <entity id="3" string="Alaska" type="LOCATION" score="0.0">
          <tokens>
            <token id="21" string="Alaska" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="20" has_coreference="true">
      <content>A cleanup army of 12,000 workers polished rocks by hand, blasted beaches with hot water and sprayed fertilizer to promote the growth of oil-eating microbes.</content>
      <tokens>
        <token id="1" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="cleanup" lemma="cleanup" stem="cleanup" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="army" lemma="army" stem="armi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="12,000" lemma="12,000" stem="12,000" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="6" string="workers" lemma="worker" stem="worker" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="polished" lemma="polished" stem="polish" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="rocks" lemma="rock" stem="rock" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="hand" lemma="hand" stem="hand" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="blasted" lemma="blast" stem="blast" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="beaches" lemma="beach" stem="beach" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="hot" lemma="hot" stem="hot" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="water" lemma="water" stem="water" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="sprayed" lemma="spray" stem="sprai" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="fertilizer" lemma="fertilizer" stem="fertil" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="promote" lemma="promote" stem="promot" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="growth" lemma="growth" stem="growth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="oil-eating" lemma="oil-eating" stem="oil-eat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="microbes" lemma="microbe" stem="microb" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT A) (NN cleanup) (NN army)) (PP (IN of) (NP (ADJP (NP (CD 12,000) (NNS workers)) (JJ polished)) (NNS rocks)))) (VP (VP (PP (IN by) (NP (NN hand))) (, ,) (VBD blasted) (NP (NP (NNS beaches)) (PP (IN with) (NP (JJ hot) (NN water))))) (CC and) (VP (VBD sprayed) (NP (NN fertilizer)) (S (VP (TO to) (VP (VB promote) (NP (NP (DT the) (NN growth)) (PP (IN of) (NP (NN oil-eating) (NNS microbes))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="promote the growth of oil-eating microbes" type="VP">
          <tokens>
            <token id="21" string="promote" />
            <token id="22" string="the" />
            <token id="23" string="growth" />
            <token id="24" string="of" />
            <token id="25" string="oil-eating" />
            <token id="26" string="microbes" />
          </tokens>
        </chunking>
        <chunking id="2" string="12,000 workers polished rocks" type="NP">
          <tokens>
            <token id="5" string="12,000" />
            <token id="6" string="workers" />
            <token id="7" string="polished" />
            <token id="8" string="rocks" />
          </tokens>
        </chunking>
        <chunking id="3" string="12,000 workers" type="NP">
          <tokens>
            <token id="5" string="12,000" />
            <token id="6" string="workers" />
          </tokens>
        </chunking>
        <chunking id="4" string="the growth" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="growth" />
          </tokens>
        </chunking>
        <chunking id="5" string="A cleanup army" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="cleanup" />
            <token id="3" string="army" />
          </tokens>
        </chunking>
        <chunking id="6" string="the growth of oil-eating microbes" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="growth" />
            <token id="24" string="of" />
            <token id="25" string="oil-eating" />
            <token id="26" string="microbes" />
          </tokens>
        </chunking>
        <chunking id="7" string="to promote the growth of oil-eating microbes" type="VP">
          <tokens>
            <token id="20" string="to" />
            <token id="21" string="promote" />
            <token id="22" string="the" />
            <token id="23" string="growth" />
            <token id="24" string="of" />
            <token id="25" string="oil-eating" />
            <token id="26" string="microbes" />
          </tokens>
        </chunking>
        <chunking id="8" string="A cleanup army of 12,000 workers polished rocks" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="cleanup" />
            <token id="3" string="army" />
            <token id="4" string="of" />
            <token id="5" string="12,000" />
            <token id="6" string="workers" />
            <token id="7" string="polished" />
            <token id="8" string="rocks" />
          </tokens>
        </chunking>
        <chunking id="9" string="sprayed fertilizer to promote the growth of oil-eating microbes" type="VP">
          <tokens>
            <token id="18" string="sprayed" />
            <token id="19" string="fertilizer" />
            <token id="20" string="to" />
            <token id="21" string="promote" />
            <token id="22" string="the" />
            <token id="23" string="growth" />
            <token id="24" string="of" />
            <token id="25" string="oil-eating" />
            <token id="26" string="microbes" />
          </tokens>
        </chunking>
        <chunking id="10" string="fertilizer" type="NP">
          <tokens>
            <token id="19" string="fertilizer" />
          </tokens>
        </chunking>
        <chunking id="11" string="12,000 workers polished" type="ADJP">
          <tokens>
            <token id="5" string="12,000" />
            <token id="6" string="workers" />
            <token id="7" string="polished" />
          </tokens>
        </chunking>
        <chunking id="12" string="beaches" type="NP">
          <tokens>
            <token id="13" string="beaches" />
          </tokens>
        </chunking>
        <chunking id="13" string="by hand , blasted beaches with hot water" type="VP">
          <tokens>
            <token id="9" string="by" />
            <token id="10" string="hand" />
            <token id="11" string="," />
            <token id="12" string="blasted" />
            <token id="13" string="beaches" />
            <token id="14" string="with" />
            <token id="15" string="hot" />
            <token id="16" string="water" />
          </tokens>
        </chunking>
        <chunking id="14" string="oil-eating microbes" type="NP">
          <tokens>
            <token id="25" string="oil-eating" />
            <token id="26" string="microbes" />
          </tokens>
        </chunking>
        <chunking id="15" string="by hand , blasted beaches with hot water and sprayed fertilizer to promote the growth of oil-eating microbes" type="VP">
          <tokens>
            <token id="9" string="by" />
            <token id="10" string="hand" />
            <token id="11" string="," />
            <token id="12" string="blasted" />
            <token id="13" string="beaches" />
            <token id="14" string="with" />
            <token id="15" string="hot" />
            <token id="16" string="water" />
            <token id="17" string="and" />
            <token id="18" string="sprayed" />
            <token id="19" string="fertilizer" />
            <token id="20" string="to" />
            <token id="21" string="promote" />
            <token id="22" string="the" />
            <token id="23" string="growth" />
            <token id="24" string="of" />
            <token id="25" string="oil-eating" />
            <token id="26" string="microbes" />
          </tokens>
        </chunking>
        <chunking id="16" string="beaches with hot water" type="NP">
          <tokens>
            <token id="13" string="beaches" />
            <token id="14" string="with" />
            <token id="15" string="hot" />
            <token id="16" string="water" />
          </tokens>
        </chunking>
        <chunking id="17" string="hot water" type="NP">
          <tokens>
            <token id="15" string="hot" />
            <token id="16" string="water" />
          </tokens>
        </chunking>
        <chunking id="18" string="hand" type="NP">
          <tokens>
            <token id="10" string="hand" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">army</governor>
          <dependent id="1">A</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">army</governor>
          <dependent id="2">cleanup</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">blasted</governor>
          <dependent id="3">army</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">rocks</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="6">workers</governor>
          <dependent id="5">12,000</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="7">polished</governor>
          <dependent id="6">workers</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">rocks</governor>
          <dependent id="7">polished</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">army</governor>
          <dependent id="8">rocks</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">hand</governor>
          <dependent id="9">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">blasted</governor>
          <dependent id="10">hand</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">blasted</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">blasted</governor>
          <dependent id="13">beaches</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">water</governor>
          <dependent id="14">with</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">water</governor>
          <dependent id="15">hot</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">beaches</governor>
          <dependent id="16">water</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="12">blasted</governor>
          <dependent id="17">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">blasted</governor>
          <dependent id="18">sprayed</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">sprayed</governor>
          <dependent id="19">fertilizer</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="21">promote</governor>
          <dependent id="20">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="18">sprayed</governor>
          <dependent id="21">promote</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">growth</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">promote</governor>
          <dependent id="23">growth</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">microbes</governor>
          <dependent id="24">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">microbes</governor>
          <dependent id="25">oil-eating</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">growth</governor>
          <dependent id="26">microbes</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="12,000" type="NUMBER" score="0.0">
          <tokens>
            <token id="5" string="12,000" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="21" has_coreference="true">
      <content>But when Exxon suspended its $2 billion cleanup in mid-September, it had recovered only 5 percent to 9 percent of the oil spilled, state officials estimate.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Exxon" lemma="Exxon" stem="exxon" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="4" string="suspended" lemma="suspend" stem="suspend" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="7" string="2" lemma="2" stem="2" pos="CD" type="Number" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="8" string="billion" lemma="billion" stem="billion" pos="CD" type="Word" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="9" string="cleanup" lemma="cleanup" stem="cleanup" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="mid-September" lemma="mid-September" stem="mid-septemb" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="recovered" lemma="recover" stem="recov" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="only" lemma="only" stem="onli" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="5" lemma="5" stem="5" pos="CD" type="Number" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="18" string="percent" lemma="percent" stem="percent" pos="NN" type="Word" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="19" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="9" lemma="9" stem="9" pos="CD" type="Number" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="21" string="percent" lemma="percent" stem="percent" pos="NN" type="Word" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="22" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="oil" lemma="oil" stem="oil" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="spilled" lemma="spill" stem="spill" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="state" lemma="state" stem="state" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="28" string="officials" lemma="official" stem="offici" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="29" string="estimate" lemma="estimate" stem="estim" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (SBAR (WHADVP (WRB when)) (S (NP (NNP Exxon)) (VP (VBD suspended) (NP (PRP$ its) (ADJP (QP ($ $) (CD 2) (CD billion))) (NN cleanup)) (PP (IN in) (NP (NNP mid-September)))))) (PRN (, ,) (S (NP (PRP it)) (VP (VBD had) (VP (VBN recovered) (NP (RB only) (CD 5) (NN percent)) (PP (TO to) (NP (NP (CD 9) (NN percent)) (PP (IN of) (NP (NP (DT the) (NN oil)) (VP (VBD spilled))))))))) (, ,)) (NP (NN state) (NNS officials)) (VP (VBP estimate)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="had recovered only 5 percent to 9 percent of the oil spilled" type="VP">
          <tokens>
            <token id="14" string="had" />
            <token id="15" string="recovered" />
            <token id="16" string="only" />
            <token id="17" string="5" />
            <token id="18" string="percent" />
            <token id="19" string="to" />
            <token id="20" string="9" />
            <token id="21" string="percent" />
            <token id="22" string="of" />
            <token id="23" string="the" />
            <token id="24" string="oil" />
            <token id="25" string="spilled" />
          </tokens>
        </chunking>
        <chunking id="2" string="Exxon" type="NP">
          <tokens>
            <token id="3" string="Exxon" />
          </tokens>
        </chunking>
        <chunking id="3" string="the oil" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="oil" />
          </tokens>
        </chunking>
        <chunking id="4" string="it" type="NP">
          <tokens>
            <token id="13" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="its $ 2 billion cleanup" type="NP">
          <tokens>
            <token id="5" string="its" />
            <token id="6" string="$" />
            <token id="7" string="2" />
            <token id="8" string="billion" />
            <token id="9" string="cleanup" />
          </tokens>
        </chunking>
        <chunking id="6" string="only 5 percent" type="NP">
          <tokens>
            <token id="16" string="only" />
            <token id="17" string="5" />
            <token id="18" string="percent" />
          </tokens>
        </chunking>
        <chunking id="7" string="when" type="WHADVP">
          <tokens>
            <token id="2" string="when" />
          </tokens>
        </chunking>
        <chunking id="8" string="when Exxon suspended its $ 2 billion cleanup in mid-September" type="SBAR">
          <tokens>
            <token id="2" string="when" />
            <token id="3" string="Exxon" />
            <token id="4" string="suspended" />
            <token id="5" string="its" />
            <token id="6" string="$" />
            <token id="7" string="2" />
            <token id="8" string="billion" />
            <token id="9" string="cleanup" />
            <token id="10" string="in" />
            <token id="11" string="mid-September" />
          </tokens>
        </chunking>
        <chunking id="9" string="spilled" type="VP">
          <tokens>
            <token id="25" string="spilled" />
          </tokens>
        </chunking>
        <chunking id="10" string="mid-September" type="NP">
          <tokens>
            <token id="11" string="mid-September" />
          </tokens>
        </chunking>
        <chunking id="11" string="9 percent of the oil spilled" type="NP">
          <tokens>
            <token id="20" string="9" />
            <token id="21" string="percent" />
            <token id="22" string="of" />
            <token id="23" string="the" />
            <token id="24" string="oil" />
            <token id="25" string="spilled" />
          </tokens>
        </chunking>
        <chunking id="12" string="the oil spilled" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="oil" />
            <token id="25" string="spilled" />
          </tokens>
        </chunking>
        <chunking id="13" string="recovered only 5 percent to 9 percent of the oil spilled" type="VP">
          <tokens>
            <token id="15" string="recovered" />
            <token id="16" string="only" />
            <token id="17" string="5" />
            <token id="18" string="percent" />
            <token id="19" string="to" />
            <token id="20" string="9" />
            <token id="21" string="percent" />
            <token id="22" string="of" />
            <token id="23" string="the" />
            <token id="24" string="oil" />
            <token id="25" string="spilled" />
          </tokens>
        </chunking>
        <chunking id="14" string="state officials" type="NP">
          <tokens>
            <token id="27" string="state" />
            <token id="28" string="officials" />
          </tokens>
        </chunking>
        <chunking id="15" string="9 percent" type="NP">
          <tokens>
            <token id="20" string="9" />
            <token id="21" string="percent" />
          </tokens>
        </chunking>
        <chunking id="16" string="estimate" type="VP">
          <tokens>
            <token id="29" string="estimate" />
          </tokens>
        </chunking>
        <chunking id="17" string="$ 2 billion" type="ADJP">
          <tokens>
            <token id="6" string="$" />
            <token id="7" string="2" />
            <token id="8" string="billion" />
          </tokens>
        </chunking>
        <chunking id="18" string="suspended its $ 2 billion cleanup in mid-September" type="VP">
          <tokens>
            <token id="4" string="suspended" />
            <token id="5" string="its" />
            <token id="6" string="$" />
            <token id="7" string="2" />
            <token id="8" string="billion" />
            <token id="9" string="cleanup" />
            <token id="10" string="in" />
            <token id="11" string="mid-September" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="29">estimate</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">suspended</governor>
          <dependent id="2">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">suspended</governor>
          <dependent id="3">Exxon</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="29">estimate</governor>
          <dependent id="4">suspended</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="9">cleanup</governor>
          <dependent id="5">its</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">cleanup</governor>
          <dependent id="6">$</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">billion</governor>
          <dependent id="7">2</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="6">$</governor>
          <dependent id="8">billion</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">suspended</governor>
          <dependent id="9">cleanup</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">mid-September</governor>
          <dependent id="10">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">suspended</governor>
          <dependent id="11">mid-September</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">recovered</governor>
          <dependent id="13">it</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="15">recovered</governor>
          <dependent id="14">had</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="29">estimate</governor>
          <dependent id="15">recovered</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">percent</governor>
          <dependent id="16">only</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="18">percent</governor>
          <dependent id="17">5</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">recovered</governor>
          <dependent id="18">percent</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">percent</governor>
          <dependent id="19">to</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="21">percent</governor>
          <dependent id="20">9</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">recovered</governor>
          <dependent id="21">percent</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">oil</governor>
          <dependent id="22">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">oil</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">percent</governor>
          <dependent id="24">oil</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="24">oil</governor>
          <dependent id="25">spilled</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">officials</governor>
          <dependent id="27">state</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">estimate</governor>
          <dependent id="28">officials</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="29">estimate</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="mid-September" type="DATE" score="0.0">
          <tokens>
            <token id="11" string="mid-September" />
          </tokens>
        </entity>
        <entity id="2" string="5 percent" type="PERCENT" score="0.0">
          <tokens>
            <token id="17" string="5" />
            <token id="18" string="percent" />
          </tokens>
        </entity>
        <entity id="3" string="Exxon" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="3" string="Exxon" />
          </tokens>
        </entity>
        <entity id="4" string="9 percent" type="PERCENT" score="0.0">
          <tokens>
            <token id="20" string="9" />
            <token id="21" string="percent" />
          </tokens>
        </entity>
        <entity id="5" string="$ 2 billion" type="MONEY" score="0.0">
          <tokens>
            <token id="6" string="$" />
            <token id="7" string="2" />
            <token id="8" string="billion" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="22" has_coreference="false">
      <content>About 20 percent to 40 percent is believed to have evaporated.</content>
      <tokens>
        <token id="1" string="About" lemma="about" stem="about" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="20" lemma="20" stem="20" pos="CD" type="Number" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="3" string="percent" lemma="percent" stem="percent" pos="NN" type="Word" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="40" lemma="40" stem="40" pos="CD" type="Number" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="6" string="percent" lemma="percent" stem="percent" pos="NN" type="Word" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="7" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="believed" lemma="believe" stem="believ" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="evaporated" lemma="evaporate" stem="evapor" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (QP (RB About) (CD 20)) (NN percent)) (PP (TO to) (NP (CD 40) (NN percent)))) (VP (VBZ is) (VP (VBN believed) (S (VP (TO to) (VP (VB have) (VP (VBN evaporated))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="believed to have evaporated" type="VP">
          <tokens>
            <token id="8" string="believed" />
            <token id="9" string="to" />
            <token id="10" string="have" />
            <token id="11" string="evaporated" />
          </tokens>
        </chunking>
        <chunking id="2" string="About 20 percent" type="NP">
          <tokens>
            <token id="1" string="About" />
            <token id="2" string="20" />
            <token id="3" string="percent" />
          </tokens>
        </chunking>
        <chunking id="3" string="have evaporated" type="VP">
          <tokens>
            <token id="10" string="have" />
            <token id="11" string="evaporated" />
          </tokens>
        </chunking>
        <chunking id="4" string="About 20 percent to 40 percent" type="NP">
          <tokens>
            <token id="1" string="About" />
            <token id="2" string="20" />
            <token id="3" string="percent" />
            <token id="4" string="to" />
            <token id="5" string="40" />
            <token id="6" string="percent" />
          </tokens>
        </chunking>
        <chunking id="5" string="evaporated" type="VP">
          <tokens>
            <token id="11" string="evaporated" />
          </tokens>
        </chunking>
        <chunking id="6" string="40 percent" type="NP">
          <tokens>
            <token id="5" string="40" />
            <token id="6" string="percent" />
          </tokens>
        </chunking>
        <chunking id="7" string="to have evaporated" type="VP">
          <tokens>
            <token id="9" string="to" />
            <token id="10" string="have" />
            <token id="11" string="evaporated" />
          </tokens>
        </chunking>
        <chunking id="8" string="is believed to have evaporated" type="VP">
          <tokens>
            <token id="7" string="is" />
            <token id="8" string="believed" />
            <token id="9" string="to" />
            <token id="10" string="have" />
            <token id="11" string="evaporated" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="2">20</governor>
          <dependent id="1">About</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="3">percent</governor>
          <dependent id="2">20</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="8">believed</governor>
          <dependent id="3">percent</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">percent</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="6">percent</governor>
          <dependent id="5">40</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">percent</governor>
          <dependent id="6">percent</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="8">believed</governor>
          <dependent id="7">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">believed</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">evaporated</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">evaporated</governor>
          <dependent id="10">have</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="8">believed</governor>
          <dependent id="11">evaporated</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="20 percent" type="PERCENT" score="0.0">
          <tokens>
            <token id="2" string="20" />
            <token id="3" string="percent" />
          </tokens>
        </entity>
        <entity id="2" string="40 percent" type="PERCENT" score="0.0">
          <tokens>
            <token id="5" string="40" />
            <token id="6" string="percent" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="23" has_coreference="true">
      <content>That leaves 50 percent to 75 percent of the oil in the water, on the ocean bottom or on beaches.</content>
      <tokens>
        <token id="1" string="That" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="leaves" lemma="leave" stem="leav" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="50" lemma="50" stem="50" pos="CD" type="Number" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="4" string="percent" lemma="percent" stem="percent" pos="NN" type="Word" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="75" lemma="75" stem="75" pos="CD" type="Number" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="7" string="percent" lemma="percent" stem="percent" pos="NN" type="Word" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="oil" lemma="oil" stem="oil" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="water" lemma="water" stem="water" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="ocean" lemma="ocean" stem="ocean" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="bottom" lemma="bottom" stem="bottom" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="beaches" lemma="beach" stem="beach" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT That)) (VP (VBZ leaves) (NP (NP (CD 50) (NN percent)) (PP (PP (TO to) (NP (NP (CD 75) (NN percent)) (PP (IN of) (NP (NP (DT the) (NN oil)) (PP (IN in) (NP (DT the) (NN water))))))) (, ,) (PP (IN on) (NP (DT the) (NN ocean) (NN bottom))) (CC or) (PP (IN on) (NP (NNS beaches)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the water" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="water" />
          </tokens>
        </chunking>
        <chunking id="2" string="That" type="NP">
          <tokens>
            <token id="1" string="That" />
          </tokens>
        </chunking>
        <chunking id="3" string="leaves 50 percent to 75 percent of the oil in the water , on the ocean bottom or on beaches" type="VP">
          <tokens>
            <token id="2" string="leaves" />
            <token id="3" string="50" />
            <token id="4" string="percent" />
            <token id="5" string="to" />
            <token id="6" string="75" />
            <token id="7" string="percent" />
            <token id="8" string="of" />
            <token id="9" string="the" />
            <token id="10" string="oil" />
            <token id="11" string="in" />
            <token id="12" string="the" />
            <token id="13" string="water" />
            <token id="14" string="," />
            <token id="15" string="on" />
            <token id="16" string="the" />
            <token id="17" string="ocean" />
            <token id="18" string="bottom" />
            <token id="19" string="or" />
            <token id="20" string="on" />
            <token id="21" string="beaches" />
          </tokens>
        </chunking>
        <chunking id="4" string="beaches" type="NP">
          <tokens>
            <token id="21" string="beaches" />
          </tokens>
        </chunking>
        <chunking id="5" string="75 percent" type="NP">
          <tokens>
            <token id="6" string="75" />
            <token id="7" string="percent" />
          </tokens>
        </chunking>
        <chunking id="6" string="the oil in the water" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="oil" />
            <token id="11" string="in" />
            <token id="12" string="the" />
            <token id="13" string="water" />
          </tokens>
        </chunking>
        <chunking id="7" string="50 percent to 75 percent of the oil in the water , on the ocean bottom or on beaches" type="NP">
          <tokens>
            <token id="3" string="50" />
            <token id="4" string="percent" />
            <token id="5" string="to" />
            <token id="6" string="75" />
            <token id="7" string="percent" />
            <token id="8" string="of" />
            <token id="9" string="the" />
            <token id="10" string="oil" />
            <token id="11" string="in" />
            <token id="12" string="the" />
            <token id="13" string="water" />
            <token id="14" string="," />
            <token id="15" string="on" />
            <token id="16" string="the" />
            <token id="17" string="ocean" />
            <token id="18" string="bottom" />
            <token id="19" string="or" />
            <token id="20" string="on" />
            <token id="21" string="beaches" />
          </tokens>
        </chunking>
        <chunking id="8" string="50 percent" type="NP">
          <tokens>
            <token id="3" string="50" />
            <token id="4" string="percent" />
          </tokens>
        </chunking>
        <chunking id="9" string="the oil" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="oil" />
          </tokens>
        </chunking>
        <chunking id="10" string="the ocean bottom" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="ocean" />
            <token id="18" string="bottom" />
          </tokens>
        </chunking>
        <chunking id="11" string="75 percent of the oil in the water" type="NP">
          <tokens>
            <token id="6" string="75" />
            <token id="7" string="percent" />
            <token id="8" string="of" />
            <token id="9" string="the" />
            <token id="10" string="oil" />
            <token id="11" string="in" />
            <token id="12" string="the" />
            <token id="13" string="water" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">leaves</governor>
          <dependent id="1">That</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">leaves</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="4">percent</governor>
          <dependent id="3">50</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">leaves</governor>
          <dependent id="4">percent</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">percent</governor>
          <dependent id="4">percent</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">percent</governor>
          <dependent id="4">percent</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">percent</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="7">percent</governor>
          <dependent id="6">75</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">percent</governor>
          <dependent id="7">percent</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">oil</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">oil</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">percent</governor>
          <dependent id="10">oil</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">water</governor>
          <dependent id="11">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">water</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">oil</governor>
          <dependent id="13">water</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">bottom</governor>
          <dependent id="15">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">bottom</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">bottom</governor>
          <dependent id="17">ocean</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">percent</governor>
          <dependent id="18">bottom</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">percent</governor>
          <dependent id="19">or</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">beaches</governor>
          <dependent id="20">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">percent</governor>
          <dependent id="21">beaches</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="75 percent" type="PERCENT" score="0.0">
          <tokens>
            <token id="6" string="75" />
            <token id="7" string="percent" />
          </tokens>
        </entity>
        <entity id="2" string="50 percent" type="PERCENT" score="0.0">
          <tokens>
            <token id="3" string="50" />
            <token id="4" string="percent" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="24" has_coreference="false">
      <content>Some was soaked up by unwilling sponges: the seabirds, eagles and sea otters whose carcasses now lie frozen in five vans in an Anchorage storage yard, awaiting their day as physical evidence in court.</content>
      <tokens>
        <token id="1" string="Some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="soaked" lemma="soak" stem="soak" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="unwilling" lemma="unwilling" stem="unwil" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="sponges" lemma="sponge" stem="spong" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="seabirds" lemma="seabird" stem="seabird" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="eagles" lemma="eagle" stem="eagl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="sea" lemma="sea" stem="sea" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="otters" lemma="otter" stem="otter" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="whose" lemma="whose" stem="whose" pos="WP$" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="carcasses" lemma="carcass" stem="carcass" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="19" string="lie" lemma="lie" stem="lie" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="frozen" lemma="freeze" stem="frozen" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="five" lemma="five" stem="five" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="23" string="vans" lemma="van" stem="van" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="Anchorage" lemma="Anchorage" stem="anchorag" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="27" string="storage" lemma="storage" stem="storag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="yard" lemma="yard" stem="yard" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="awaiting" lemma="await" stem="await" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="day" lemma="day" stem="dai" pos="NN" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="33" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="physical" lemma="physical" stem="physic" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="evidence" lemma="evidence" stem="evid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="court" lemma="court" stem="court" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT Some)) (VP (VBD was) (VP (VBN soaked) (PRT (RP up)) (PP (IN by) (NP (NP (ADJP (JJ unwilling)) (NNS sponges)) (: :) (NP (NP (DT the) (NNS seabirds) (, ,) (NNS eagles) (CC and) (NN sea) (NNS otters)) (SBAR (WP$ whose) (S (NP (NNS carcasses)) (ADVP (RB now)) (VP (VBP lie) (S (VP (VBN frozen) (PP (IN in) (NP (CD five) (NNS vans))) (PP (IN in) (NP (DT an) (NNP Anchorage) (NN storage) (NN yard))) (, ,) (S (VP (VBG awaiting) (NP (PRP$ their) (NN day)) (PP (IN as) (NP (NP (JJ physical) (NN evidence)) (PP (IN in) (NP (NN court))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="their day" type="NP">
          <tokens>
            <token id="31" string="their" />
            <token id="32" string="day" />
          </tokens>
        </chunking>
        <chunking id="2" string="physical evidence" type="NP">
          <tokens>
            <token id="34" string="physical" />
            <token id="35" string="evidence" />
          </tokens>
        </chunking>
        <chunking id="3" string="awaiting their day as physical evidence in court" type="VP">
          <tokens>
            <token id="30" string="awaiting" />
            <token id="31" string="their" />
            <token id="32" string="day" />
            <token id="33" string="as" />
            <token id="34" string="physical" />
            <token id="35" string="evidence" />
            <token id="36" string="in" />
            <token id="37" string="court" />
          </tokens>
        </chunking>
        <chunking id="4" string="whose carcasses now lie frozen in five vans in an Anchorage storage yard , awaiting their day as physical evidence in court" type="SBAR">
          <tokens>
            <token id="16" string="whose" />
            <token id="17" string="carcasses" />
            <token id="18" string="now" />
            <token id="19" string="lie" />
            <token id="20" string="frozen" />
            <token id="21" string="in" />
            <token id="22" string="five" />
            <token id="23" string="vans" />
            <token id="24" string="in" />
            <token id="25" string="an" />
            <token id="26" string="Anchorage" />
            <token id="27" string="storage" />
            <token id="28" string="yard" />
            <token id="29" string="," />
            <token id="30" string="awaiting" />
            <token id="31" string="their" />
            <token id="32" string="day" />
            <token id="33" string="as" />
            <token id="34" string="physical" />
            <token id="35" string="evidence" />
            <token id="36" string="in" />
            <token id="37" string="court" />
          </tokens>
        </chunking>
        <chunking id="5" string="an Anchorage storage yard" type="NP">
          <tokens>
            <token id="25" string="an" />
            <token id="26" string="Anchorage" />
            <token id="27" string="storage" />
            <token id="28" string="yard" />
          </tokens>
        </chunking>
        <chunking id="6" string="unwilling" type="ADJP">
          <tokens>
            <token id="6" string="unwilling" />
          </tokens>
        </chunking>
        <chunking id="7" string="lie frozen in five vans in an Anchorage storage yard , awaiting their day as physical evidence in court" type="VP">
          <tokens>
            <token id="19" string="lie" />
            <token id="20" string="frozen" />
            <token id="21" string="in" />
            <token id="22" string="five" />
            <token id="23" string="vans" />
            <token id="24" string="in" />
            <token id="25" string="an" />
            <token id="26" string="Anchorage" />
            <token id="27" string="storage" />
            <token id="28" string="yard" />
            <token id="29" string="," />
            <token id="30" string="awaiting" />
            <token id="31" string="their" />
            <token id="32" string="day" />
            <token id="33" string="as" />
            <token id="34" string="physical" />
            <token id="35" string="evidence" />
            <token id="36" string="in" />
            <token id="37" string="court" />
          </tokens>
        </chunking>
        <chunking id="8" string="unwilling sponges" type="NP">
          <tokens>
            <token id="6" string="unwilling" />
            <token id="7" string="sponges" />
          </tokens>
        </chunking>
        <chunking id="9" string="the seabirds , eagles and sea otters whose carcasses now lie frozen in five vans in an Anchorage storage yard , awaiting their day as physical evidence in court" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="seabirds" />
            <token id="11" string="," />
            <token id="12" string="eagles" />
            <token id="13" string="and" />
            <token id="14" string="sea" />
            <token id="15" string="otters" />
            <token id="16" string="whose" />
            <token id="17" string="carcasses" />
            <token id="18" string="now" />
            <token id="19" string="lie" />
            <token id="20" string="frozen" />
            <token id="21" string="in" />
            <token id="22" string="five" />
            <token id="23" string="vans" />
            <token id="24" string="in" />
            <token id="25" string="an" />
            <token id="26" string="Anchorage" />
            <token id="27" string="storage" />
            <token id="28" string="yard" />
            <token id="29" string="," />
            <token id="30" string="awaiting" />
            <token id="31" string="their" />
            <token id="32" string="day" />
            <token id="33" string="as" />
            <token id="34" string="physical" />
            <token id="35" string="evidence" />
            <token id="36" string="in" />
            <token id="37" string="court" />
          </tokens>
        </chunking>
        <chunking id="10" string="court" type="NP">
          <tokens>
            <token id="37" string="court" />
          </tokens>
        </chunking>
        <chunking id="11" string="five vans" type="NP">
          <tokens>
            <token id="22" string="five" />
            <token id="23" string="vans" />
          </tokens>
        </chunking>
        <chunking id="12" string="carcasses" type="NP">
          <tokens>
            <token id="17" string="carcasses" />
          </tokens>
        </chunking>
        <chunking id="13" string="frozen in five vans in an Anchorage storage yard , awaiting their day as physical evidence in court" type="VP">
          <tokens>
            <token id="20" string="frozen" />
            <token id="21" string="in" />
            <token id="22" string="five" />
            <token id="23" string="vans" />
            <token id="24" string="in" />
            <token id="25" string="an" />
            <token id="26" string="Anchorage" />
            <token id="27" string="storage" />
            <token id="28" string="yard" />
            <token id="29" string="," />
            <token id="30" string="awaiting" />
            <token id="31" string="their" />
            <token id="32" string="day" />
            <token id="33" string="as" />
            <token id="34" string="physical" />
            <token id="35" string="evidence" />
            <token id="36" string="in" />
            <token id="37" string="court" />
          </tokens>
        </chunking>
        <chunking id="14" string="Some" type="NP">
          <tokens>
            <token id="1" string="Some" />
          </tokens>
        </chunking>
        <chunking id="15" string="soaked up by unwilling sponges : the seabirds , eagles and sea otters whose carcasses now lie frozen in five vans in an Anchorage storage yard , awaiting their day as physical evidence in court" type="VP">
          <tokens>
            <token id="3" string="soaked" />
            <token id="4" string="up" />
            <token id="5" string="by" />
            <token id="6" string="unwilling" />
            <token id="7" string="sponges" />
            <token id="8" string=":" />
            <token id="9" string="the" />
            <token id="10" string="seabirds" />
            <token id="11" string="," />
            <token id="12" string="eagles" />
            <token id="13" string="and" />
            <token id="14" string="sea" />
            <token id="15" string="otters" />
            <token id="16" string="whose" />
            <token id="17" string="carcasses" />
            <token id="18" string="now" />
            <token id="19" string="lie" />
            <token id="20" string="frozen" />
            <token id="21" string="in" />
            <token id="22" string="five" />
            <token id="23" string="vans" />
            <token id="24" string="in" />
            <token id="25" string="an" />
            <token id="26" string="Anchorage" />
            <token id="27" string="storage" />
            <token id="28" string="yard" />
            <token id="29" string="," />
            <token id="30" string="awaiting" />
            <token id="31" string="their" />
            <token id="32" string="day" />
            <token id="33" string="as" />
            <token id="34" string="physical" />
            <token id="35" string="evidence" />
            <token id="36" string="in" />
            <token id="37" string="court" />
          </tokens>
        </chunking>
        <chunking id="16" string="unwilling sponges : the seabirds , eagles and sea otters whose carcasses now lie frozen in five vans in an Anchorage storage yard , awaiting their day as physical evidence in court" type="NP">
          <tokens>
            <token id="6" string="unwilling" />
            <token id="7" string="sponges" />
            <token id="8" string=":" />
            <token id="9" string="the" />
            <token id="10" string="seabirds" />
            <token id="11" string="," />
            <token id="12" string="eagles" />
            <token id="13" string="and" />
            <token id="14" string="sea" />
            <token id="15" string="otters" />
            <token id="16" string="whose" />
            <token id="17" string="carcasses" />
            <token id="18" string="now" />
            <token id="19" string="lie" />
            <token id="20" string="frozen" />
            <token id="21" string="in" />
            <token id="22" string="five" />
            <token id="23" string="vans" />
            <token id="24" string="in" />
            <token id="25" string="an" />
            <token id="26" string="Anchorage" />
            <token id="27" string="storage" />
            <token id="28" string="yard" />
            <token id="29" string="," />
            <token id="30" string="awaiting" />
            <token id="31" string="their" />
            <token id="32" string="day" />
            <token id="33" string="as" />
            <token id="34" string="physical" />
            <token id="35" string="evidence" />
            <token id="36" string="in" />
            <token id="37" string="court" />
          </tokens>
        </chunking>
        <chunking id="17" string="the seabirds , eagles and sea otters" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="seabirds" />
            <token id="11" string="," />
            <token id="12" string="eagles" />
            <token id="13" string="and" />
            <token id="14" string="sea" />
            <token id="15" string="otters" />
          </tokens>
        </chunking>
        <chunking id="18" string="physical evidence in court" type="NP">
          <tokens>
            <token id="34" string="physical" />
            <token id="35" string="evidence" />
            <token id="36" string="in" />
            <token id="37" string="court" />
          </tokens>
        </chunking>
        <chunking id="19" string="was soaked up by unwilling sponges : the seabirds , eagles and sea otters whose carcasses now lie frozen in five vans in an Anchorage storage yard , awaiting their day as physical evidence in court" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="soaked" />
            <token id="4" string="up" />
            <token id="5" string="by" />
            <token id="6" string="unwilling" />
            <token id="7" string="sponges" />
            <token id="8" string=":" />
            <token id="9" string="the" />
            <token id="10" string="seabirds" />
            <token id="11" string="," />
            <token id="12" string="eagles" />
            <token id="13" string="and" />
            <token id="14" string="sea" />
            <token id="15" string="otters" />
            <token id="16" string="whose" />
            <token id="17" string="carcasses" />
            <token id="18" string="now" />
            <token id="19" string="lie" />
            <token id="20" string="frozen" />
            <token id="21" string="in" />
            <token id="22" string="five" />
            <token id="23" string="vans" />
            <token id="24" string="in" />
            <token id="25" string="an" />
            <token id="26" string="Anchorage" />
            <token id="27" string="storage" />
            <token id="28" string="yard" />
            <token id="29" string="," />
            <token id="30" string="awaiting" />
            <token id="31" string="their" />
            <token id="32" string="day" />
            <token id="33" string="as" />
            <token id="34" string="physical" />
            <token id="35" string="evidence" />
            <token id="36" string="in" />
            <token id="37" string="court" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="3">soaked</governor>
          <dependent id="1">Some</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="3">soaked</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">soaked</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="3">soaked</governor>
          <dependent id="4">up</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">sponges</governor>
          <dependent id="5">by</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">sponges</governor>
          <dependent id="6">unwilling</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">soaked</governor>
          <dependent id="7">sponges</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">eagles</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">eagles</governor>
          <dependent id="10">seabirds</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="7">sponges</governor>
          <dependent id="12">eagles</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="12">eagles</governor>
          <dependent id="13">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">otters</governor>
          <dependent id="14">sea</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">eagles</governor>
          <dependent id="15">otters</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="19">lie</governor>
          <dependent id="16">whose</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">lie</governor>
          <dependent id="17">carcasses</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="19">lie</governor>
          <dependent id="18">now</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="12">eagles</governor>
          <dependent id="19">lie</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="19">lie</governor>
          <dependent id="20">frozen</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">vans</governor>
          <dependent id="21">in</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="23">vans</governor>
          <dependent id="22">five</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">frozen</governor>
          <dependent id="23">vans</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">yard</governor>
          <dependent id="24">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">yard</governor>
          <dependent id="25">an</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">yard</governor>
          <dependent id="26">Anchorage</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">yard</governor>
          <dependent id="27">storage</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">frozen</governor>
          <dependent id="28">yard</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="20">frozen</governor>
          <dependent id="30">awaiting</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="32">day</governor>
          <dependent id="31">their</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="30">awaiting</governor>
          <dependent id="32">day</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">evidence</governor>
          <dependent id="33">as</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="35">evidence</governor>
          <dependent id="34">physical</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">awaiting</governor>
          <dependent id="35">evidence</dependent>
        </dependency>
        <dependency type="case">
          <governor id="37">court</governor>
          <dependent id="36">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="35">evidence</governor>
          <dependent id="37">court</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="now" type="DATE" score="0.0">
          <tokens>
            <token id="18" string="now" />
          </tokens>
        </entity>
        <entity id="2" string="Anchorage" type="LOCATION" score="0.0">
          <tokens>
            <token id="26" string="Anchorage" />
          </tokens>
        </entity>
        <entity id="3" string="day" type="DURATION" score="0.0">
          <tokens>
            <token id="32" string="day" />
          </tokens>
        </entity>
        <entity id="4" string="five" type="NUMBER" score="0.0">
          <tokens>
            <token id="22" string="five" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="25" has_coreference="true">
      <content>Workers found more than 1,000 dead otters, a sizable chunk of the spill area&amp;apost;s total population of 15,000 to 22,000.</content>
      <tokens>
        <token id="1" string="Workers" lemma="worker" stem="worker" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="2" string="found" lemma="find" stem="found" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="more" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="1,000" lemma="1,000" stem="1,000" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="6" string="dead" lemma="dead" stem="dead" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="otters" lemma="otter" stem="otter" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="sizable" lemma="sizable" stem="sizabl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="chunk" lemma="chunk" stem="chunk" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="spill" lemma="spill" stem="spill" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="area" lemma="area" stem="area" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="total" lemma="total" stem="total" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="population" lemma="population" stem="popul" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="15,000" lemma="15,000" stem="15,000" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="21" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="22,000" lemma="22,000" stem="22,000" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNS Workers)) (VP (VBD found) (NP (NP (QP (JJR more) (IN than) (CD 1,000)) (JJ dead) (NNS otters)) (, ,) (NP (NP (DT a) (JJ sizable) (NN chunk)) (PP (IN of) (NP (NP (NP (DT the) (NN spill) (NN area) (POS 's)) (JJ total) (NN population)) (PP (IN of) (NP (QP (CD 15,000) (TO to) (CD 22,000))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the spill area 's total population" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="spill" />
            <token id="15" string="area" />
            <token id="16" string="'s" />
            <token id="17" string="total" />
            <token id="18" string="population" />
          </tokens>
        </chunking>
        <chunking id="2" string="more than 1,000 dead otters , a sizable chunk of the spill area 's total population of 15,000 to 22,000" type="NP">
          <tokens>
            <token id="3" string="more" />
            <token id="4" string="than" />
            <token id="5" string="1,000" />
            <token id="6" string="dead" />
            <token id="7" string="otters" />
            <token id="8" string="," />
            <token id="9" string="a" />
            <token id="10" string="sizable" />
            <token id="11" string="chunk" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="spill" />
            <token id="15" string="area" />
            <token id="16" string="'s" />
            <token id="17" string="total" />
            <token id="18" string="population" />
            <token id="19" string="of" />
            <token id="20" string="15,000" />
            <token id="21" string="to" />
            <token id="22" string="22,000" />
          </tokens>
        </chunking>
        <chunking id="3" string="a sizable chunk of the spill area 's total population of 15,000 to 22,000" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="sizable" />
            <token id="11" string="chunk" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="spill" />
            <token id="15" string="area" />
            <token id="16" string="'s" />
            <token id="17" string="total" />
            <token id="18" string="population" />
            <token id="19" string="of" />
            <token id="20" string="15,000" />
            <token id="21" string="to" />
            <token id="22" string="22,000" />
          </tokens>
        </chunking>
        <chunking id="4" string="Workers" type="NP">
          <tokens>
            <token id="1" string="Workers" />
          </tokens>
        </chunking>
        <chunking id="5" string="the spill area 's total population of 15,000 to 22,000" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="spill" />
            <token id="15" string="area" />
            <token id="16" string="'s" />
            <token id="17" string="total" />
            <token id="18" string="population" />
            <token id="19" string="of" />
            <token id="20" string="15,000" />
            <token id="21" string="to" />
            <token id="22" string="22,000" />
          </tokens>
        </chunking>
        <chunking id="6" string="more than 1,000 dead otters" type="NP">
          <tokens>
            <token id="3" string="more" />
            <token id="4" string="than" />
            <token id="5" string="1,000" />
            <token id="6" string="dead" />
            <token id="7" string="otters" />
          </tokens>
        </chunking>
        <chunking id="7" string="a sizable chunk" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="sizable" />
            <token id="11" string="chunk" />
          </tokens>
        </chunking>
        <chunking id="8" string="15,000 to 22,000" type="NP">
          <tokens>
            <token id="20" string="15,000" />
            <token id="21" string="to" />
            <token id="22" string="22,000" />
          </tokens>
        </chunking>
        <chunking id="9" string="the spill area 's" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="spill" />
            <token id="15" string="area" />
            <token id="16" string="'s" />
          </tokens>
        </chunking>
        <chunking id="10" string="found more than 1,000 dead otters , a sizable chunk of the spill area 's total population of 15,000 to 22,000" type="VP">
          <tokens>
            <token id="2" string="found" />
            <token id="3" string="more" />
            <token id="4" string="than" />
            <token id="5" string="1,000" />
            <token id="6" string="dead" />
            <token id="7" string="otters" />
            <token id="8" string="," />
            <token id="9" string="a" />
            <token id="10" string="sizable" />
            <token id="11" string="chunk" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="spill" />
            <token id="15" string="area" />
            <token id="16" string="'s" />
            <token id="17" string="total" />
            <token id="18" string="population" />
            <token id="19" string="of" />
            <token id="20" string="15,000" />
            <token id="21" string="to" />
            <token id="22" string="22,000" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">found</governor>
          <dependent id="1">Workers</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">found</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">1,000</governor>
          <dependent id="3">more</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="3">more</governor>
          <dependent id="4">than</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="7">otters</governor>
          <dependent id="5">1,000</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">otters</governor>
          <dependent id="6">dead</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">found</governor>
          <dependent id="7">otters</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">chunk</governor>
          <dependent id="9">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">chunk</governor>
          <dependent id="10">sizable</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="7">otters</governor>
          <dependent id="11">chunk</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">population</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">area</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">area</governor>
          <dependent id="14">spill</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="18">population</governor>
          <dependent id="15">area</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">area</governor>
          <dependent id="16">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">population</governor>
          <dependent id="17">total</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">chunk</governor>
          <dependent id="18">population</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">22,000</governor>
          <dependent id="19">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">22,000</governor>
          <dependent id="20">15,000</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="22">22,000</governor>
          <dependent id="21">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">population</governor>
          <dependent id="22">22,000</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1,000" type="NUMBER" score="0.0">
          <tokens>
            <token id="5" string="1,000" />
          </tokens>
        </entity>
        <entity id="2" string="22,000" type="NUMBER" score="0.0">
          <tokens>
            <token id="22" string="22,000" />
          </tokens>
        </entity>
        <entity id="3" string="15,000" type="NUMBER" score="0.0">
          <tokens>
            <token id="20" string="15,000" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="26" has_coreference="true">
      <content>Many of Prince William Sound&amp;apost;s 3,000 bald eagles also suffered; at least 151 died, most poisoned by scavenging the oily remains of some of the 34,400 dead seabirds recovered.</content>
      <tokens>
        <token id="1" string="Many" lemma="many" stem="mani" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Prince" lemma="Prince" stem="princ" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="false" is_refers="true" />
        <token id="4" string="William" lemma="William" stem="william" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="5" string="Sound" lemma="Sound" stem="sound" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="6" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="3,000" lemma="3,000" stem="3,000" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="8" string="bald" lemma="bald" stem="bald" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="eagles" lemma="eagle" stem="eagl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="suffered" lemma="suffer" stem="suffer" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="least" lemma="least" stem="least" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="151" lemma="151" stem="151" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="16" string="died" lemma="die" stem="di" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="most" lemma="most" stem="most" pos="JJS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="poisoned" lemma="poison" stem="poison" pos="VBN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="20" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="scavenging" lemma="scavenging" stem="scaveng" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="oily" lemma="oily" stem="oili" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="remains" lemma="remain" stem="remain" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="34,400" lemma="34,400" stem="34,400" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="30" string="dead" lemma="dead" stem="dead" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="seabirds" lemma="seabird" stem="seabird" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="recovered" lemma="recover" stem="recov" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (JJ Many)) (PP (IN of) (NP (NP (NNP Prince) (NNP William) (NNP Sound) (POS 's)) (CD 3,000) (JJ bald) (NNS eagles)))) (ADVP (RB also)) (VP (VBD suffered))) (: ;) (S (NP (QP (IN at) (JJS least) (CD 151))) (VP (VBD died))) (, ,) (S (NP (NP (JJS most)) (VP (VBN poisoned) (PP (IN by) (NP (NP (NN scavenging)) (SBAR (S (NP (DT the) (NN oily)) (VP (VBZ remains) (PP (IN of) (NP (NP (DT some)) (PP (IN of) (NP (DT the) (CD 34,400) (JJ dead) (NNS seabirds)))))))))))) (VP (VBD recovered))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="some" type="NP">
          <tokens>
            <token id="26" string="some" />
          </tokens>
        </chunking>
        <chunking id="2" string="at least 151" type="NP">
          <tokens>
            <token id="13" string="at" />
            <token id="14" string="least" />
            <token id="15" string="151" />
          </tokens>
        </chunking>
        <chunking id="3" string="most poisoned by scavenging the oily remains of some of the 34,400 dead seabirds" type="NP">
          <tokens>
            <token id="18" string="most" />
            <token id="19" string="poisoned" />
            <token id="20" string="by" />
            <token id="21" string="scavenging" />
            <token id="22" string="the" />
            <token id="23" string="oily" />
            <token id="24" string="remains" />
            <token id="25" string="of" />
            <token id="26" string="some" />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="34,400" />
            <token id="30" string="dead" />
            <token id="31" string="seabirds" />
          </tokens>
        </chunking>
        <chunking id="4" string="Prince William Sound 's" type="NP">
          <tokens>
            <token id="3" string="Prince" />
            <token id="4" string="William" />
            <token id="5" string="Sound" />
            <token id="6" string="'s" />
          </tokens>
        </chunking>
        <chunking id="5" string="some of the 34,400 dead seabirds" type="NP">
          <tokens>
            <token id="26" string="some" />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="34,400" />
            <token id="30" string="dead" />
            <token id="31" string="seabirds" />
          </tokens>
        </chunking>
        <chunking id="6" string="died" type="VP">
          <tokens>
            <token id="16" string="died" />
          </tokens>
        </chunking>
        <chunking id="7" string="scavenging the oily remains of some of the 34,400 dead seabirds" type="NP">
          <tokens>
            <token id="21" string="scavenging" />
            <token id="22" string="the" />
            <token id="23" string="oily" />
            <token id="24" string="remains" />
            <token id="25" string="of" />
            <token id="26" string="some" />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="34,400" />
            <token id="30" string="dead" />
            <token id="31" string="seabirds" />
          </tokens>
        </chunking>
        <chunking id="8" string="poisoned by scavenging the oily remains of some of the 34,400 dead seabirds" type="VP">
          <tokens>
            <token id="19" string="poisoned" />
            <token id="20" string="by" />
            <token id="21" string="scavenging" />
            <token id="22" string="the" />
            <token id="23" string="oily" />
            <token id="24" string="remains" />
            <token id="25" string="of" />
            <token id="26" string="some" />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="34,400" />
            <token id="30" string="dead" />
            <token id="31" string="seabirds" />
          </tokens>
        </chunking>
        <chunking id="9" string="most" type="NP">
          <tokens>
            <token id="18" string="most" />
          </tokens>
        </chunking>
        <chunking id="10" string="the oily remains of some of the 34,400 dead seabirds" type="SBAR">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="oily" />
            <token id="24" string="remains" />
            <token id="25" string="of" />
            <token id="26" string="some" />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="34,400" />
            <token id="30" string="dead" />
            <token id="31" string="seabirds" />
          </tokens>
        </chunking>
        <chunking id="11" string="remains of some of the 34,400 dead seabirds" type="VP">
          <tokens>
            <token id="24" string="remains" />
            <token id="25" string="of" />
            <token id="26" string="some" />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="34,400" />
            <token id="30" string="dead" />
            <token id="31" string="seabirds" />
          </tokens>
        </chunking>
        <chunking id="12" string="recovered" type="VP">
          <tokens>
            <token id="32" string="recovered" />
          </tokens>
        </chunking>
        <chunking id="13" string="the oily" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="oily" />
          </tokens>
        </chunking>
        <chunking id="14" string="Many of Prince William Sound 's 3,000 bald eagles" type="NP">
          <tokens>
            <token id="1" string="Many" />
            <token id="2" string="of" />
            <token id="3" string="Prince" />
            <token id="4" string="William" />
            <token id="5" string="Sound" />
            <token id="6" string="'s" />
            <token id="7" string="3,000" />
            <token id="8" string="bald" />
            <token id="9" string="eagles" />
          </tokens>
        </chunking>
        <chunking id="15" string="suffered" type="VP">
          <tokens>
            <token id="11" string="suffered" />
          </tokens>
        </chunking>
        <chunking id="16" string="scavenging" type="NP">
          <tokens>
            <token id="21" string="scavenging" />
          </tokens>
        </chunking>
        <chunking id="17" string="Many" type="NP">
          <tokens>
            <token id="1" string="Many" />
          </tokens>
        </chunking>
        <chunking id="18" string="Prince William Sound 's 3,000 bald eagles" type="NP">
          <tokens>
            <token id="3" string="Prince" />
            <token id="4" string="William" />
            <token id="5" string="Sound" />
            <token id="6" string="'s" />
            <token id="7" string="3,000" />
            <token id="8" string="bald" />
            <token id="9" string="eagles" />
          </tokens>
        </chunking>
        <chunking id="19" string="the 34,400 dead seabirds" type="NP">
          <tokens>
            <token id="28" string="the" />
            <token id="29" string="34,400" />
            <token id="30" string="dead" />
            <token id="31" string="seabirds" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="11">suffered</governor>
          <dependent id="1">Many</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">eagles</governor>
          <dependent id="2">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Sound</governor>
          <dependent id="3">Prince</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Sound</governor>
          <dependent id="4">William</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="9">eagles</governor>
          <dependent id="5">Sound</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">Sound</governor>
          <dependent id="6">'s</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="9">eagles</governor>
          <dependent id="7">3,000</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">eagles</governor>
          <dependent id="8">bald</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Many</governor>
          <dependent id="9">eagles</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">suffered</governor>
          <dependent id="10">also</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">suffered</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">least</governor>
          <dependent id="13">at</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="15">151</governor>
          <dependent id="14">least</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">died</governor>
          <dependent id="15">151</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="11">suffered</governor>
          <dependent id="16">died</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="32">recovered</governor>
          <dependent id="18">most</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="18">most</governor>
          <dependent id="19">poisoned</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">scavenging</governor>
          <dependent id="20">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">poisoned</governor>
          <dependent id="21">scavenging</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">oily</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">remains</governor>
          <dependent id="23">oily</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="21">scavenging</governor>
          <dependent id="24">remains</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">some</governor>
          <dependent id="25">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">remains</governor>
          <dependent id="26">some</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">seabirds</governor>
          <dependent id="27">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">seabirds</governor>
          <dependent id="28">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="31">seabirds</governor>
          <dependent id="29">34,400</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="31">seabirds</governor>
          <dependent id="30">dead</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">some</governor>
          <dependent id="31">seabirds</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="11">suffered</governor>
          <dependent id="32">recovered</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="34,400" type="NUMBER" score="0.0">
          <tokens>
            <token id="29" string="34,400" />
          </tokens>
        </entity>
        <entity id="2" string="Prince" type="TITLE" score="0.0">
          <tokens>
            <token id="3" string="Prince" />
          </tokens>
        </entity>
        <entity id="3" string="3,000" type="NUMBER" score="0.0">
          <tokens>
            <token id="7" string="3,000" />
          </tokens>
        </entity>
        <entity id="4" string="William Sound" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="William" />
            <token id="5" string="Sound" />
          </tokens>
        </entity>
        <entity id="5" string="poisoned" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="19" string="poisoned" />
          </tokens>
        </entity>
        <entity id="6" string="151" type="NUMBER" score="0.0">
          <tokens>
            <token id="15" string="151" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="27" has_coreference="true">
      <content>Those numbers alone make the Valdez spill the most lethal ever, but scientists say the actual death count is much higher, estimating that up to 90 percent of the seabirds caught in oil sank from sight or drifted out to sea.</content>
      <tokens>
        <token id="1" string="Those" lemma="those" stem="those" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="numbers" lemma="number" stem="number" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="alone" lemma="alone" stem="alon" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="make" lemma="make" stem="make" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="Valdez" lemma="Valdez" stem="valdez" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="spill" lemma="spill" stem="spill" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="most" lemma="most" stem="most" pos="RBS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="lethal" lemma="lethal" stem="lethal" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="ever" lemma="ever" stem="ever" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="scientists" lemma="scientist" stem="scientist" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="say" lemma="say" stem="sai" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="actual" lemma="actual" stem="actual" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="death" lemma="death" stem="death" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="count" lemma="count" stem="count" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="much" lemma="much" stem="much" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="higher" lemma="higher" stem="higher" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="estimating" lemma="estimate" stem="estim" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="up" lemma="up" stem="up" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="90" lemma="90" stem="90" pos="CD" type="Number" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="29" string="percent" lemma="percent" stem="percent" pos="NN" type="Word" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="30" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="seabirds" lemma="seabird" stem="seabird" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="caught" lemma="catch" stem="caught" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="oil" lemma="oil" stem="oil" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="sank" lemma="sink" stem="sank" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="sight" lemma="sight" stem="sight" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="drifted" lemma="drift" stem="drift" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="sea" lemma="sea" stem="sea" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="44" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (DT Those) (NNS numbers)) (ADVP (RB alone)) (VP (VBP make) (S (NP (DT the) (NNP Valdez) (NN spill)) (NP (NP (DT the) (ADJP (RBS most) (JJ lethal))) (ADVP (RB ever)))))) (, ,) (CC but) (S (NP (NNS scientists)) (VP (VBP say) (SBAR (S (NP (DT the) (JJ actual) (NN death) (NN count)) (VP (VP (VBZ is) (ADJP (RB much) (JJR higher)) (, ,) (S (VP (VBG estimating) (SBAR (IN that) (S (NP (NP (QP (IN up) (TO to) (CD 90)) (NN percent)) (PP (IN of) (NP (NP (DT the) (NNS seabirds)) (VP (VBN caught) (PP (IN in) (NP (NN oil))))))) (VP (VBD sank) (PP (IN from) (NP (NN sight))))))))) (CC or) (VP (VBD drifted) (PRT (RP out)) (PP (TO to) (NP (NN sea))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="up to 90 percent of the seabirds caught in oil" type="NP">
          <tokens>
            <token id="26" string="up" />
            <token id="27" string="to" />
            <token id="28" string="90" />
            <token id="29" string="percent" />
            <token id="30" string="of" />
            <token id="31" string="the" />
            <token id="32" string="seabirds" />
            <token id="33" string="caught" />
            <token id="34" string="in" />
            <token id="35" string="oil" />
          </tokens>
        </chunking>
        <chunking id="2" string="the most lethal ever" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="most" />
            <token id="10" string="lethal" />
            <token id="11" string="ever" />
          </tokens>
        </chunking>
        <chunking id="3" string="make the Valdez spill the most lethal ever" type="VP">
          <tokens>
            <token id="4" string="make" />
            <token id="5" string="the" />
            <token id="6" string="Valdez" />
            <token id="7" string="spill" />
            <token id="8" string="the" />
            <token id="9" string="most" />
            <token id="10" string="lethal" />
            <token id="11" string="ever" />
          </tokens>
        </chunking>
        <chunking id="4" string="the most lethal" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="most" />
            <token id="10" string="lethal" />
          </tokens>
        </chunking>
        <chunking id="5" string="Those numbers" type="NP">
          <tokens>
            <token id="1" string="Those" />
            <token id="2" string="numbers" />
          </tokens>
        </chunking>
        <chunking id="6" string="the seabirds" type="NP">
          <tokens>
            <token id="31" string="the" />
            <token id="32" string="seabirds" />
          </tokens>
        </chunking>
        <chunking id="7" string="the actual death count is much higher , estimating that up to 90 percent of the seabirds caught in oil sank from sight or drifted out to sea" type="SBAR">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="actual" />
            <token id="18" string="death" />
            <token id="19" string="count" />
            <token id="20" string="is" />
            <token id="21" string="much" />
            <token id="22" string="higher" />
            <token id="23" string="," />
            <token id="24" string="estimating" />
            <token id="25" string="that" />
            <token id="26" string="up" />
            <token id="27" string="to" />
            <token id="28" string="90" />
            <token id="29" string="percent" />
            <token id="30" string="of" />
            <token id="31" string="the" />
            <token id="32" string="seabirds" />
            <token id="33" string="caught" />
            <token id="34" string="in" />
            <token id="35" string="oil" />
            <token id="36" string="sank" />
            <token id="37" string="from" />
            <token id="38" string="sight" />
            <token id="39" string="or" />
            <token id="40" string="drifted" />
            <token id="41" string="out" />
            <token id="42" string="to" />
            <token id="43" string="sea" />
          </tokens>
        </chunking>
        <chunking id="8" string="scientists" type="NP">
          <tokens>
            <token id="14" string="scientists" />
          </tokens>
        </chunking>
        <chunking id="9" string="that up to 90 percent of the seabirds caught in oil sank from sight" type="SBAR">
          <tokens>
            <token id="25" string="that" />
            <token id="26" string="up" />
            <token id="27" string="to" />
            <token id="28" string="90" />
            <token id="29" string="percent" />
            <token id="30" string="of" />
            <token id="31" string="the" />
            <token id="32" string="seabirds" />
            <token id="33" string="caught" />
            <token id="34" string="in" />
            <token id="35" string="oil" />
            <token id="36" string="sank" />
            <token id="37" string="from" />
            <token id="38" string="sight" />
          </tokens>
        </chunking>
        <chunking id="10" string="up to 90 percent" type="NP">
          <tokens>
            <token id="26" string="up" />
            <token id="27" string="to" />
            <token id="28" string="90" />
            <token id="29" string="percent" />
          </tokens>
        </chunking>
        <chunking id="11" string="is much higher , estimating that up to 90 percent of the seabirds caught in oil sank from sight or drifted out to sea" type="VP">
          <tokens>
            <token id="20" string="is" />
            <token id="21" string="much" />
            <token id="22" string="higher" />
            <token id="23" string="," />
            <token id="24" string="estimating" />
            <token id="25" string="that" />
            <token id="26" string="up" />
            <token id="27" string="to" />
            <token id="28" string="90" />
            <token id="29" string="percent" />
            <token id="30" string="of" />
            <token id="31" string="the" />
            <token id="32" string="seabirds" />
            <token id="33" string="caught" />
            <token id="34" string="in" />
            <token id="35" string="oil" />
            <token id="36" string="sank" />
            <token id="37" string="from" />
            <token id="38" string="sight" />
            <token id="39" string="or" />
            <token id="40" string="drifted" />
            <token id="41" string="out" />
            <token id="42" string="to" />
            <token id="43" string="sea" />
          </tokens>
        </chunking>
        <chunking id="12" string="the seabirds caught in oil" type="NP">
          <tokens>
            <token id="31" string="the" />
            <token id="32" string="seabirds" />
            <token id="33" string="caught" />
            <token id="34" string="in" />
            <token id="35" string="oil" />
          </tokens>
        </chunking>
        <chunking id="13" string="most lethal" type="ADJP">
          <tokens>
            <token id="9" string="most" />
            <token id="10" string="lethal" />
          </tokens>
        </chunking>
        <chunking id="14" string="estimating that up to 90 percent of the seabirds caught in oil sank from sight" type="VP">
          <tokens>
            <token id="24" string="estimating" />
            <token id="25" string="that" />
            <token id="26" string="up" />
            <token id="27" string="to" />
            <token id="28" string="90" />
            <token id="29" string="percent" />
            <token id="30" string="of" />
            <token id="31" string="the" />
            <token id="32" string="seabirds" />
            <token id="33" string="caught" />
            <token id="34" string="in" />
            <token id="35" string="oil" />
            <token id="36" string="sank" />
            <token id="37" string="from" />
            <token id="38" string="sight" />
          </tokens>
        </chunking>
        <chunking id="15" string="say the actual death count is much higher , estimating that up to 90 percent of the seabirds caught in oil sank from sight or drifted out to sea" type="VP">
          <tokens>
            <token id="15" string="say" />
            <token id="16" string="the" />
            <token id="17" string="actual" />
            <token id="18" string="death" />
            <token id="19" string="count" />
            <token id="20" string="is" />
            <token id="21" string="much" />
            <token id="22" string="higher" />
            <token id="23" string="," />
            <token id="24" string="estimating" />
            <token id="25" string="that" />
            <token id="26" string="up" />
            <token id="27" string="to" />
            <token id="28" string="90" />
            <token id="29" string="percent" />
            <token id="30" string="of" />
            <token id="31" string="the" />
            <token id="32" string="seabirds" />
            <token id="33" string="caught" />
            <token id="34" string="in" />
            <token id="35" string="oil" />
            <token id="36" string="sank" />
            <token id="37" string="from" />
            <token id="38" string="sight" />
            <token id="39" string="or" />
            <token id="40" string="drifted" />
            <token id="41" string="out" />
            <token id="42" string="to" />
            <token id="43" string="sea" />
          </tokens>
        </chunking>
        <chunking id="16" string="drifted out to sea" type="VP">
          <tokens>
            <token id="40" string="drifted" />
            <token id="41" string="out" />
            <token id="42" string="to" />
            <token id="43" string="sea" />
          </tokens>
        </chunking>
        <chunking id="17" string="the Valdez spill" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="Valdez" />
            <token id="7" string="spill" />
          </tokens>
        </chunking>
        <chunking id="18" string="caught in oil" type="VP">
          <tokens>
            <token id="33" string="caught" />
            <token id="34" string="in" />
            <token id="35" string="oil" />
          </tokens>
        </chunking>
        <chunking id="19" string="sea" type="NP">
          <tokens>
            <token id="43" string="sea" />
          </tokens>
        </chunking>
        <chunking id="20" string="is much higher , estimating that up to 90 percent of the seabirds caught in oil sank from sight" type="VP">
          <tokens>
            <token id="20" string="is" />
            <token id="21" string="much" />
            <token id="22" string="higher" />
            <token id="23" string="," />
            <token id="24" string="estimating" />
            <token id="25" string="that" />
            <token id="26" string="up" />
            <token id="27" string="to" />
            <token id="28" string="90" />
            <token id="29" string="percent" />
            <token id="30" string="of" />
            <token id="31" string="the" />
            <token id="32" string="seabirds" />
            <token id="33" string="caught" />
            <token id="34" string="in" />
            <token id="35" string="oil" />
            <token id="36" string="sank" />
            <token id="37" string="from" />
            <token id="38" string="sight" />
          </tokens>
        </chunking>
        <chunking id="21" string="oil" type="NP">
          <tokens>
            <token id="35" string="oil" />
          </tokens>
        </chunking>
        <chunking id="22" string="the actual death count" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="actual" />
            <token id="18" string="death" />
            <token id="19" string="count" />
          </tokens>
        </chunking>
        <chunking id="23" string="much higher" type="ADJP">
          <tokens>
            <token id="21" string="much" />
            <token id="22" string="higher" />
          </tokens>
        </chunking>
        <chunking id="24" string="sight" type="NP">
          <tokens>
            <token id="38" string="sight" />
          </tokens>
        </chunking>
        <chunking id="25" string="sank from sight" type="VP">
          <tokens>
            <token id="36" string="sank" />
            <token id="37" string="from" />
            <token id="38" string="sight" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">numbers</governor>
          <dependent id="1">Those</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">make</governor>
          <dependent id="2">numbers</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">make</governor>
          <dependent id="3">alone</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">make</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">spill</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">spill</governor>
          <dependent id="6">Valdez</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">lethal</governor>
          <dependent id="7">spill</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">lethal</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">lethal</governor>
          <dependent id="9">most</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">make</governor>
          <dependent id="10">lethal</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">lethal</governor>
          <dependent id="11">ever</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">make</governor>
          <dependent id="13">but</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">say</governor>
          <dependent id="14">scientists</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">make</governor>
          <dependent id="15">say</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">count</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">count</governor>
          <dependent id="17">actual</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">count</governor>
          <dependent id="18">death</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">higher</governor>
          <dependent id="19">count</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="22">higher</governor>
          <dependent id="20">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="22">higher</governor>
          <dependent id="21">much</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="15">say</governor>
          <dependent id="22">higher</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="22">higher</governor>
          <dependent id="24">estimating</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="36">sank</governor>
          <dependent id="25">that</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="28">90</governor>
          <dependent id="26">up</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="26">up</governor>
          <dependent id="27">to</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="29">percent</governor>
          <dependent id="28">90</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="36">sank</governor>
          <dependent id="29">percent</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">seabirds</governor>
          <dependent id="30">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="32">seabirds</governor>
          <dependent id="31">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">percent</governor>
          <dependent id="32">seabirds</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="32">seabirds</governor>
          <dependent id="33">caught</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">oil</governor>
          <dependent id="34">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="33">caught</governor>
          <dependent id="35">oil</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="24">estimating</governor>
          <dependent id="36">sank</dependent>
        </dependency>
        <dependency type="case">
          <governor id="38">sight</governor>
          <dependent id="37">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="36">sank</governor>
          <dependent id="38">sight</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="22">higher</governor>
          <dependent id="39">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="22">higher</governor>
          <dependent id="40">drifted</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="40">drifted</governor>
          <dependent id="41">out</dependent>
        </dependency>
        <dependency type="case">
          <governor id="43">sea</governor>
          <dependent id="42">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="40">drifted</governor>
          <dependent id="43">sea</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="90 percent" type="PERCENT" score="0.0">
          <tokens>
            <token id="28" string="90" />
            <token id="29" string="percent" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="28" has_coreference="true">
      <content>Exxon notes the spill did not wipe out any species and says surviving animals and birds will rebuild populations.</content>
      <tokens>
        <token id="1" string="Exxon" lemma="Exxon" stem="exxon" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="2" string="notes" lemma="note" stem="note" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="spill" lemma="spill" stem="spill" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="wipe" lemma="wipe" stem="wipe" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="any" lemma="any" stem="ani" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="species" lemma="species" stem="speci" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="surviving" lemma="survive" stem="surviv" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="animals" lemma="animal" stem="anim" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="birds" lemma="bird" stem="bird" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="rebuild" lemma="rebuild" stem="rebuild" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="populations" lemma="population" stem="popul" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NNP Exxon)) (VP (VBZ notes) (SBAR (S (NP (DT the) (NN spill)) (VP (VP (VBD did) (RB not) (VP (VB wipe) (PRT (RP out)) (NP (DT any) (NNS species)))) (CC and) (VP (VBZ says) (NP (VBG surviving) (NNS animals)))))))) (CC and) (S (NP (NNS birds)) (VP (MD will) (VP (VB rebuild) (NP (NNS populations))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="did not wipe out any species and says surviving animals" type="VP">
          <tokens>
            <token id="5" string="did" />
            <token id="6" string="not" />
            <token id="7" string="wipe" />
            <token id="8" string="out" />
            <token id="9" string="any" />
            <token id="10" string="species" />
            <token id="11" string="and" />
            <token id="12" string="says" />
            <token id="13" string="surviving" />
            <token id="14" string="animals" />
          </tokens>
        </chunking>
        <chunking id="2" string="says surviving animals" type="VP">
          <tokens>
            <token id="12" string="says" />
            <token id="13" string="surviving" />
            <token id="14" string="animals" />
          </tokens>
        </chunking>
        <chunking id="3" string="Exxon" type="NP">
          <tokens>
            <token id="1" string="Exxon" />
          </tokens>
        </chunking>
        <chunking id="4" string="the spill" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="spill" />
          </tokens>
        </chunking>
        <chunking id="5" string="rebuild populations" type="VP">
          <tokens>
            <token id="18" string="rebuild" />
            <token id="19" string="populations" />
          </tokens>
        </chunking>
        <chunking id="6" string="birds" type="NP">
          <tokens>
            <token id="16" string="birds" />
          </tokens>
        </chunking>
        <chunking id="7" string="the spill did not wipe out any species and says surviving animals" type="SBAR">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="spill" />
            <token id="5" string="did" />
            <token id="6" string="not" />
            <token id="7" string="wipe" />
            <token id="8" string="out" />
            <token id="9" string="any" />
            <token id="10" string="species" />
            <token id="11" string="and" />
            <token id="12" string="says" />
            <token id="13" string="surviving" />
            <token id="14" string="animals" />
          </tokens>
        </chunking>
        <chunking id="8" string="did not wipe out any species" type="VP">
          <tokens>
            <token id="5" string="did" />
            <token id="6" string="not" />
            <token id="7" string="wipe" />
            <token id="8" string="out" />
            <token id="9" string="any" />
            <token id="10" string="species" />
          </tokens>
        </chunking>
        <chunking id="9" string="notes the spill did not wipe out any species and says surviving animals" type="VP">
          <tokens>
            <token id="2" string="notes" />
            <token id="3" string="the" />
            <token id="4" string="spill" />
            <token id="5" string="did" />
            <token id="6" string="not" />
            <token id="7" string="wipe" />
            <token id="8" string="out" />
            <token id="9" string="any" />
            <token id="10" string="species" />
            <token id="11" string="and" />
            <token id="12" string="says" />
            <token id="13" string="surviving" />
            <token id="14" string="animals" />
          </tokens>
        </chunking>
        <chunking id="10" string="will rebuild populations" type="VP">
          <tokens>
            <token id="17" string="will" />
            <token id="18" string="rebuild" />
            <token id="19" string="populations" />
          </tokens>
        </chunking>
        <chunking id="11" string="any species" type="NP">
          <tokens>
            <token id="9" string="any" />
            <token id="10" string="species" />
          </tokens>
        </chunking>
        <chunking id="12" string="surviving animals" type="NP">
          <tokens>
            <token id="13" string="surviving" />
            <token id="14" string="animals" />
          </tokens>
        </chunking>
        <chunking id="13" string="wipe out any species" type="VP">
          <tokens>
            <token id="7" string="wipe" />
            <token id="8" string="out" />
            <token id="9" string="any" />
            <token id="10" string="species" />
          </tokens>
        </chunking>
        <chunking id="14" string="populations" type="NP">
          <tokens>
            <token id="19" string="populations" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">notes</governor>
          <dependent id="1">Exxon</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">notes</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">spill</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">wipe</governor>
          <dependent id="4">spill</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">wipe</governor>
          <dependent id="5">did</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="7">wipe</governor>
          <dependent id="6">not</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">notes</governor>
          <dependent id="7">wipe</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="7">wipe</governor>
          <dependent id="8">out</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">species</governor>
          <dependent id="9">any</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">wipe</governor>
          <dependent id="10">species</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">wipe</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">wipe</governor>
          <dependent id="12">says</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">animals</governor>
          <dependent id="13">surviving</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">says</governor>
          <dependent id="14">animals</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">notes</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">rebuild</governor>
          <dependent id="16">birds</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="18">rebuild</governor>
          <dependent id="17">will</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">notes</governor>
          <dependent id="18">rebuild</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">rebuild</governor>
          <dependent id="19">populations</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Exxon" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="1" string="Exxon" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="29" has_coreference="true">
      <content>But that may take up to 70 years for some hard-hit seabird colonies, U.S. Fish and Wildlife Service researchers say.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="may" lemma="may" stem="mai" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="take" lemma="take" stem="take" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="7" string="70" lemma="70" stem="70" pos="CD" type="Number" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="8" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="9" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="hard-hit" lemma="hard-hit" stem="hard-hit" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="seabird" lemma="seabird" stem="seabird" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="colonies" lemma="colony" stem="coloni" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="U.S." lemma="U.S." stem="u.s." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="16" string="Fish" lemma="fish" stem="fish" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Wildlife" lemma="Wildlife" stem="wildlif" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="19" string="Service" lemma="Service" stem="servic" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="20" string="researchers" lemma="researcher" stem="research" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="say" lemma="say" stem="sai" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (S (NP (DT that)) (VP (MD may) (VP (VB take) (PRT (RP up)) (PP (TO to) (NP (NP (CD 70) (NNS years)) (PP (IN for) (NP (NP (DT some) (JJ hard-hit) (NN seabird) (NNS colonies)) (, ,) (NP (NNP U.S.) (NN Fish))))))))) (CC and) (S (NP (NNP Wildlife) (NNP Service) (NNS researchers)) (VP (VBP say))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="that" type="NP">
          <tokens>
            <token id="2" string="that" />
          </tokens>
        </chunking>
        <chunking id="2" string="70 years" type="NP">
          <tokens>
            <token id="7" string="70" />
            <token id="8" string="years" />
          </tokens>
        </chunking>
        <chunking id="3" string="take up to 70 years for some hard-hit seabird colonies , U.S. Fish" type="VP">
          <tokens>
            <token id="4" string="take" />
            <token id="5" string="up" />
            <token id="6" string="to" />
            <token id="7" string="70" />
            <token id="8" string="years" />
            <token id="9" string="for" />
            <token id="10" string="some" />
            <token id="11" string="hard-hit" />
            <token id="12" string="seabird" />
            <token id="13" string="colonies" />
            <token id="14" string="," />
            <token id="15" string="U.S." />
            <token id="16" string="Fish" />
          </tokens>
        </chunking>
        <chunking id="4" string="some hard-hit seabird colonies , U.S. Fish" type="NP">
          <tokens>
            <token id="10" string="some" />
            <token id="11" string="hard-hit" />
            <token id="12" string="seabird" />
            <token id="13" string="colonies" />
            <token id="14" string="," />
            <token id="15" string="U.S." />
            <token id="16" string="Fish" />
          </tokens>
        </chunking>
        <chunking id="5" string="may take up to 70 years for some hard-hit seabird colonies , U.S. Fish" type="VP">
          <tokens>
            <token id="3" string="may" />
            <token id="4" string="take" />
            <token id="5" string="up" />
            <token id="6" string="to" />
            <token id="7" string="70" />
            <token id="8" string="years" />
            <token id="9" string="for" />
            <token id="10" string="some" />
            <token id="11" string="hard-hit" />
            <token id="12" string="seabird" />
            <token id="13" string="colonies" />
            <token id="14" string="," />
            <token id="15" string="U.S." />
            <token id="16" string="Fish" />
          </tokens>
        </chunking>
        <chunking id="6" string="U.S. Fish" type="NP">
          <tokens>
            <token id="15" string="U.S." />
            <token id="16" string="Fish" />
          </tokens>
        </chunking>
        <chunking id="7" string="say" type="VP">
          <tokens>
            <token id="21" string="say" />
          </tokens>
        </chunking>
        <chunking id="8" string="70 years for some hard-hit seabird colonies , U.S. Fish" type="NP">
          <tokens>
            <token id="7" string="70" />
            <token id="8" string="years" />
            <token id="9" string="for" />
            <token id="10" string="some" />
            <token id="11" string="hard-hit" />
            <token id="12" string="seabird" />
            <token id="13" string="colonies" />
            <token id="14" string="," />
            <token id="15" string="U.S." />
            <token id="16" string="Fish" />
          </tokens>
        </chunking>
        <chunking id="9" string="some hard-hit seabird colonies" type="NP">
          <tokens>
            <token id="10" string="some" />
            <token id="11" string="hard-hit" />
            <token id="12" string="seabird" />
            <token id="13" string="colonies" />
          </tokens>
        </chunking>
        <chunking id="10" string="Wildlife Service researchers" type="NP">
          <tokens>
            <token id="18" string="Wildlife" />
            <token id="19" string="Service" />
            <token id="20" string="researchers" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="4">take</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">take</governor>
          <dependent id="2">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">take</governor>
          <dependent id="3">may</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">take</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="4">take</governor>
          <dependent id="5">up</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">years</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="8">years</governor>
          <dependent id="7">70</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">take</governor>
          <dependent id="8">years</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">colonies</governor>
          <dependent id="9">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">colonies</governor>
          <dependent id="10">some</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">colonies</governor>
          <dependent id="11">hard-hit</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">colonies</governor>
          <dependent id="12">seabird</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">years</governor>
          <dependent id="13">colonies</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Fish</governor>
          <dependent id="15">U.S.</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="13">colonies</governor>
          <dependent id="16">Fish</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">take</governor>
          <dependent id="17">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">researchers</governor>
          <dependent id="18">Wildlife</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">researchers</governor>
          <dependent id="19">Service</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">say</governor>
          <dependent id="20">researchers</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">take</governor>
          <dependent id="21">say</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="up to 70 years" type="DURATION" score="0.0">
          <tokens>
            <token id="5" string="up" />
            <token id="6" string="to" />
            <token id="7" string="70" />
            <token id="8" string="years" />
          </tokens>
        </entity>
        <entity id="2" string="U.S." type="LOCATION" score="0.0">
          <tokens>
            <token id="15" string="U.S." />
          </tokens>
        </entity>
        <entity id="3" string="Wildlife Service" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="18" string="Wildlife" />
            <token id="19" string="Service" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="30" has_coreference="true">
      <content>``We never claimed that the spill put any animal on the endangered species list, but that&amp;apost;s missing the point,&amp;apost;&amp;apost; said Fish and Wildlife spokesman Bruce Batten.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="We" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="claimed" lemma="claim" stem="claim" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="spill" lemma="spill" stem="spill" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="put" lemma="put" stem="put" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="any" lemma="any" stem="ani" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="animal" lemma="animal" stem="anim" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="endangered" lemma="endanger" stem="endang" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="species" lemma="species" stem="speci" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="list" lemma="list" stem="list" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="missing" lemma="miss" stem="miss" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="point" lemma="point" stem="point" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="Fish" lemma="fish" stem="fish" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="Wildlife" lemma="Wildlife" stem="wildlif" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="spokesman" lemma="spokesman" stem="spokesman" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="Bruce" lemma="Bruce" stem="bruce" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="31" string="Batten" lemma="Batten" stem="batten" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (S (NP (PRP We)) (ADVP (RB never)) (VP (VBD claimed) (SBAR (IN that) (S (NP (DT the) (NN spill)) (VP (VBD put) (NP (NP (DT any) (NN animal)) (PP (IN on) (NP (DT the) (VBN endangered) (NNS species) (NN list))))))))) (, ,) (CC but) (S (NP (DT that)) (VP (VBZ 's) (VP (VBG missing) (NP (DT the) (NN point)))))) (, ,) ('' '') (VP (VBD said) (NP (NN Fish) (CC and) (NNP Wildlife) (NN spokesman))) (NP (NNP Bruce) (NNP Batten)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the endangered species list" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="endangered" />
            <token id="14" string="species" />
            <token id="15" string="list" />
          </tokens>
        </chunking>
        <chunking id="2" string="said Fish and Wildlife spokesman" type="VP">
          <tokens>
            <token id="25" string="said" />
            <token id="26" string="Fish" />
            <token id="27" string="and" />
            <token id="28" string="Wildlife" />
            <token id="29" string="spokesman" />
          </tokens>
        </chunking>
        <chunking id="3" string="Fish and Wildlife spokesman" type="NP">
          <tokens>
            <token id="26" string="Fish" />
            <token id="27" string="and" />
            <token id="28" string="Wildlife" />
            <token id="29" string="spokesman" />
          </tokens>
        </chunking>
        <chunking id="4" string="'s missing the point" type="VP">
          <tokens>
            <token id="19" string="'s" />
            <token id="20" string="missing" />
            <token id="21" string="the" />
            <token id="22" string="point" />
          </tokens>
        </chunking>
        <chunking id="5" string="the spill" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="spill" />
          </tokens>
        </chunking>
        <chunking id="6" string="the point" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="point" />
          </tokens>
        </chunking>
        <chunking id="7" string="We" type="NP">
          <tokens>
            <token id="2" string="We" />
          </tokens>
        </chunking>
        <chunking id="8" string="missing the point" type="VP">
          <tokens>
            <token id="20" string="missing" />
            <token id="21" string="the" />
            <token id="22" string="point" />
          </tokens>
        </chunking>
        <chunking id="9" string="that" type="NP">
          <tokens>
            <token id="18" string="that" />
          </tokens>
        </chunking>
        <chunking id="10" string="claimed that the spill put any animal on the endangered species list" type="VP">
          <tokens>
            <token id="4" string="claimed" />
            <token id="5" string="that" />
            <token id="6" string="the" />
            <token id="7" string="spill" />
            <token id="8" string="put" />
            <token id="9" string="any" />
            <token id="10" string="animal" />
            <token id="11" string="on" />
            <token id="12" string="the" />
            <token id="13" string="endangered" />
            <token id="14" string="species" />
            <token id="15" string="list" />
          </tokens>
        </chunking>
        <chunking id="11" string="that the spill put any animal on the endangered species list" type="SBAR">
          <tokens>
            <token id="5" string="that" />
            <token id="6" string="the" />
            <token id="7" string="spill" />
            <token id="8" string="put" />
            <token id="9" string="any" />
            <token id="10" string="animal" />
            <token id="11" string="on" />
            <token id="12" string="the" />
            <token id="13" string="endangered" />
            <token id="14" string="species" />
            <token id="15" string="list" />
          </tokens>
        </chunking>
        <chunking id="12" string="Bruce Batten" type="NP">
          <tokens>
            <token id="30" string="Bruce" />
            <token id="31" string="Batten" />
          </tokens>
        </chunking>
        <chunking id="13" string="put any animal on the endangered species list" type="VP">
          <tokens>
            <token id="8" string="put" />
            <token id="9" string="any" />
            <token id="10" string="animal" />
            <token id="11" string="on" />
            <token id="12" string="the" />
            <token id="13" string="endangered" />
            <token id="14" string="species" />
            <token id="15" string="list" />
          </tokens>
        </chunking>
        <chunking id="14" string="any animal on the endangered species list" type="NP">
          <tokens>
            <token id="9" string="any" />
            <token id="10" string="animal" />
            <token id="11" string="on" />
            <token id="12" string="the" />
            <token id="13" string="endangered" />
            <token id="14" string="species" />
            <token id="15" string="list" />
          </tokens>
        </chunking>
        <chunking id="15" string="any animal" type="NP">
          <tokens>
            <token id="9" string="any" />
            <token id="10" string="animal" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">claimed</governor>
          <dependent id="2">We</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="4">claimed</governor>
          <dependent id="3">never</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="25">said</governor>
          <dependent id="4">claimed</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">put</governor>
          <dependent id="5">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">spill</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">put</governor>
          <dependent id="7">spill</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">claimed</governor>
          <dependent id="8">put</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">animal</governor>
          <dependent id="9">any</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">put</governor>
          <dependent id="10">animal</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">list</governor>
          <dependent id="11">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">list</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">list</governor>
          <dependent id="13">endangered</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">list</governor>
          <dependent id="14">species</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">animal</governor>
          <dependent id="15">list</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">claimed</governor>
          <dependent id="17">but</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">missing</governor>
          <dependent id="18">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="20">missing</governor>
          <dependent id="19">'s</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">claimed</governor>
          <dependent id="20">missing</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">point</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">missing</governor>
          <dependent id="22">point</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="25">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="29">spokesman</governor>
          <dependent id="26">Fish</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="26">Fish</governor>
          <dependent id="27">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="26">Fish</governor>
          <dependent id="28">Wildlife</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="25">said</governor>
          <dependent id="29">spokesman</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">Batten</governor>
          <dependent id="30">Bruce</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">said</governor>
          <dependent id="31">Batten</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Bruce Batten" type="PERSON" score="0.0">
          <tokens>
            <token id="30" string="Bruce" />
            <token id="31" string="Batten" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="31" has_coreference="true">
      <content>``It&amp;apost;s still the greatest human-caused wildlife disaster that this agency knows about.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="still" lemma="still" stem="still" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="greatest" lemma="greatest" stem="greatest" pos="JJS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="human-caused" lemma="human-caused" stem="human-caus" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="wildlife" lemma="wildlife" stem="wildlif" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="disaster" lemma="disaster" stem="disast" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="true" is_refers="false" />
        <token id="10" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="agency" lemma="agency" stem="agenc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="knows" lemma="know" stem="know" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="about" lemma="about" stem="about" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP It)) (VP (VBZ 's) (ADVP (RB still)) (NP (DT the) (JJS greatest) (JJ human-caused) (NN wildlife) (NN disaster)) (SBAR (IN that) (S (NP (DT this) (NN agency)) (VP (VBZ knows) (ADVP (RB about)))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="the greatest human-caused wildlife disaster" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="greatest" />
            <token id="7" string="human-caused" />
            <token id="8" string="wildlife" />
            <token id="9" string="disaster" />
          </tokens>
        </chunking>
        <chunking id="2" string="that this agency knows about" type="SBAR">
          <tokens>
            <token id="10" string="that" />
            <token id="11" string="this" />
            <token id="12" string="agency" />
            <token id="13" string="knows" />
            <token id="14" string="about" />
          </tokens>
        </chunking>
        <chunking id="3" string="It" type="NP">
          <tokens>
            <token id="2" string="It" />
          </tokens>
        </chunking>
        <chunking id="4" string="this agency" type="NP">
          <tokens>
            <token id="11" string="this" />
            <token id="12" string="agency" />
          </tokens>
        </chunking>
        <chunking id="5" string="knows about" type="VP">
          <tokens>
            <token id="13" string="knows" />
            <token id="14" string="about" />
          </tokens>
        </chunking>
        <chunking id="6" string="'s still the greatest human-caused wildlife disaster that this agency knows about" type="VP">
          <tokens>
            <token id="3" string="'s" />
            <token id="4" string="still" />
            <token id="5" string="the" />
            <token id="6" string="greatest" />
            <token id="7" string="human-caused" />
            <token id="8" string="wildlife" />
            <token id="9" string="disaster" />
            <token id="10" string="that" />
            <token id="11" string="this" />
            <token id="12" string="agency" />
            <token id="13" string="knows" />
            <token id="14" string="about" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="9">disaster</governor>
          <dependent id="2">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="9">disaster</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">disaster</governor>
          <dependent id="4">still</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">disaster</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">disaster</governor>
          <dependent id="6">greatest</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">disaster</governor>
          <dependent id="7">human-caused</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">disaster</governor>
          <dependent id="8">wildlife</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">disaster</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">knows</governor>
          <dependent id="10">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">agency</governor>
          <dependent id="11">this</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">knows</governor>
          <dependent id="12">agency</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="9">disaster</governor>
          <dependent id="13">knows</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">knows</governor>
          <dependent id="14">about</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="disaster" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="9" string="disaster" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="32" has_coreference="true">
      <content>Oily carcasses were an obvious measure of the spill&amp;apost;s impact, but victims also included less visible members of the ecosystem, such as young salmon and tiny intertidal creatures.</content>
      <tokens>
        <token id="1" string="Oily" lemma="oily" stem="oili" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="carcasses" lemma="carcass" stem="carcass" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="obvious" lemma="obvious" stem="obviou" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="measure" lemma="measure" stem="measur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="spill" lemma="spill" stem="spill" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="impact" lemma="impact" stem="impact" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="victims" lemma="victim" stem="victim" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="included" lemma="include" stem="includ" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="less" lemma="less" stem="less" pos="RBR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="visible" lemma="visible" stem="visibl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="members" lemma="member" stem="member" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="ecosystem" lemma="ecosystem" stem="ecosystem" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="such" lemma="such" stem="such" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="young" lemma="young" stem="young" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="salmon" lemma="salmon" stem="salmon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="tiny" lemma="tiny" stem="tini" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="intertidal" lemma="intertidal" stem="intertid" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="creatures" lemma="creature" stem="creatur" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (ADVP (RB Oily)) (NP (NNS carcasses)) (VP (VBD were) (NP (NP (DT an) (JJ obvious) (NN measure)) (PP (IN of) (NP (NP (DT the) (NN spill) (POS 's)) (NN impact)))))) (, ,) (CC but) (S (NP (NNS victims)) (ADVP (RB also)) (VP (VBD included) (NP (NP (ADJP (RBR less) (JJ visible)) (NNS members)) (PP (IN of) (NP (DT the) (NN ecosystem))) (, ,) (PP (JJ such) (IN as) (NP (NP (JJ young) (NN salmon)) (CC and) (NP (JJ tiny) (JJ intertidal) (NNS creatures))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="less visible members" type="NP">
          <tokens>
            <token id="17" string="less" />
            <token id="18" string="visible" />
            <token id="19" string="members" />
          </tokens>
        </chunking>
        <chunking id="2" string="tiny intertidal creatures" type="NP">
          <tokens>
            <token id="29" string="tiny" />
            <token id="30" string="intertidal" />
            <token id="31" string="creatures" />
          </tokens>
        </chunking>
        <chunking id="3" string="an obvious measure" type="NP">
          <tokens>
            <token id="4" string="an" />
            <token id="5" string="obvious" />
            <token id="6" string="measure" />
          </tokens>
        </chunking>
        <chunking id="4" string="less visible members of the ecosystem , such as young salmon and tiny intertidal creatures" type="NP">
          <tokens>
            <token id="17" string="less" />
            <token id="18" string="visible" />
            <token id="19" string="members" />
            <token id="20" string="of" />
            <token id="21" string="the" />
            <token id="22" string="ecosystem" />
            <token id="23" string="," />
            <token id="24" string="such" />
            <token id="25" string="as" />
            <token id="26" string="young" />
            <token id="27" string="salmon" />
            <token id="28" string="and" />
            <token id="29" string="tiny" />
            <token id="30" string="intertidal" />
            <token id="31" string="creatures" />
          </tokens>
        </chunking>
        <chunking id="5" string="the ecosystem" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="ecosystem" />
          </tokens>
        </chunking>
        <chunking id="6" string="the spill 's" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="spill" />
            <token id="10" string="'s" />
          </tokens>
        </chunking>
        <chunking id="7" string="an obvious measure of the spill 's impact" type="NP">
          <tokens>
            <token id="4" string="an" />
            <token id="5" string="obvious" />
            <token id="6" string="measure" />
            <token id="7" string="of" />
            <token id="8" string="the" />
            <token id="9" string="spill" />
            <token id="10" string="'s" />
            <token id="11" string="impact" />
          </tokens>
        </chunking>
        <chunking id="8" string="the spill 's impact" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="spill" />
            <token id="10" string="'s" />
            <token id="11" string="impact" />
          </tokens>
        </chunking>
        <chunking id="9" string="carcasses" type="NP">
          <tokens>
            <token id="2" string="carcasses" />
          </tokens>
        </chunking>
        <chunking id="10" string="were an obvious measure of the spill 's impact" type="VP">
          <tokens>
            <token id="3" string="were" />
            <token id="4" string="an" />
            <token id="5" string="obvious" />
            <token id="6" string="measure" />
            <token id="7" string="of" />
            <token id="8" string="the" />
            <token id="9" string="spill" />
            <token id="10" string="'s" />
            <token id="11" string="impact" />
          </tokens>
        </chunking>
        <chunking id="11" string="less visible" type="ADJP">
          <tokens>
            <token id="17" string="less" />
            <token id="18" string="visible" />
          </tokens>
        </chunking>
        <chunking id="12" string="young salmon" type="NP">
          <tokens>
            <token id="26" string="young" />
            <token id="27" string="salmon" />
          </tokens>
        </chunking>
        <chunking id="13" string="included less visible members of the ecosystem , such as young salmon and tiny intertidal creatures" type="VP">
          <tokens>
            <token id="16" string="included" />
            <token id="17" string="less" />
            <token id="18" string="visible" />
            <token id="19" string="members" />
            <token id="20" string="of" />
            <token id="21" string="the" />
            <token id="22" string="ecosystem" />
            <token id="23" string="," />
            <token id="24" string="such" />
            <token id="25" string="as" />
            <token id="26" string="young" />
            <token id="27" string="salmon" />
            <token id="28" string="and" />
            <token id="29" string="tiny" />
            <token id="30" string="intertidal" />
            <token id="31" string="creatures" />
          </tokens>
        </chunking>
        <chunking id="14" string="young salmon and tiny intertidal creatures" type="NP">
          <tokens>
            <token id="26" string="young" />
            <token id="27" string="salmon" />
            <token id="28" string="and" />
            <token id="29" string="tiny" />
            <token id="30" string="intertidal" />
            <token id="31" string="creatures" />
          </tokens>
        </chunking>
        <chunking id="15" string="victims" type="NP">
          <tokens>
            <token id="14" string="victims" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="6">measure</governor>
          <dependent id="1">Oily</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">measure</governor>
          <dependent id="2">carcasses</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">measure</governor>
          <dependent id="3">were</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">measure</governor>
          <dependent id="4">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">measure</governor>
          <dependent id="5">obvious</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">measure</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">impact</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">spill</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">impact</governor>
          <dependent id="9">spill</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">spill</governor>
          <dependent id="10">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">measure</governor>
          <dependent id="11">impact</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">measure</governor>
          <dependent id="13">but</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">included</governor>
          <dependent id="14">victims</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">included</governor>
          <dependent id="15">also</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">measure</governor>
          <dependent id="16">included</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">visible</governor>
          <dependent id="17">less</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">members</governor>
          <dependent id="18">visible</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">included</governor>
          <dependent id="19">members</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">ecosystem</governor>
          <dependent id="20">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">ecosystem</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">members</governor>
          <dependent id="22">ecosystem</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">salmon</governor>
          <dependent id="24">such</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="24">such</governor>
          <dependent id="25">as</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="27">salmon</governor>
          <dependent id="26">young</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">members</governor>
          <dependent id="27">salmon</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="27">salmon</governor>
          <dependent id="28">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="31">creatures</governor>
          <dependent id="29">tiny</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="31">creatures</governor>
          <dependent id="30">intertidal</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="27">salmon</governor>
          <dependent id="31">creatures</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="33" has_coreference="true">
      <content>Assessment studies for these populations are not finished, and even preliminary findings are hard to come by _ researchers have been told by lawyers to save their findings for court, where it seems nearly everyone involved in the spill is headed.</content>
      <tokens>
        <token id="1" string="Assessment" lemma="Assessment" stem="assessment" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="studies" lemma="study" stem="studi" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="these" lemma="these" stem="these" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="populations" lemma="population" stem="popul" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="finished" lemma="finish" stem="finish" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="preliminary" lemma="preliminary" stem="preliminari" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="findings" lemma="finding" stem="find" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="hard" lemma="hard" stem="hard" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="come" lemma="come" stem="come" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="_" lemma="_" stem="_" pos="CD" type="Symbol" isStopWord="true" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="20" string="researchers" lemma="researcher" stem="research" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="told" lemma="tell" stem="told" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="lawyers" lemma="lawyer" stem="lawyer" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="save" lemma="save" stem="save" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="findings" lemma="finding" stem="find" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="court" lemma="court" stem="court" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="where" lemma="where" stem="where" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="seems" lemma="seem" stem="seem" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="nearly" lemma="nearly" stem="nearli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="everyone" lemma="everyone" stem="everyon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="involved" lemma="involve" stem="involv" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="41" string="spill" lemma="spill" stem="spill" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="42" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="headed" lemma="head" stem="head" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="44" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (NNP Assessment) (NNS studies)) (PP (IN for) (NP (DT these) (NNS populations)))) (VP (VBP are) (RB not) (ADJP (VBN finished)))) (, ,) (CC and) (S (SBAR (RB even) (S (NP (JJ preliminary) (NNS findings)) (VP (VBP are) (ADJP (JJ hard) (S (VP (TO to) (VP (VB come) (PP (IN by) (NP (CD _) (NNS researchers)))))))))) (VP (VBP have) (VP (VBN been) (VP (VBN told) (PP (IN by) (NP (NNS lawyers))) (S (VP (TO to) (VP (VB save) (NP (PRP$ their) (NNS findings)) (PP (IN for) (NP (NP (NN court)) (, ,) (SBAR (WHADVP (WRB where)) (S (NP (PRP it)) (VP (VBZ seems) (SBAR (S (NP (NP (RB nearly) (NN everyone)) (VP (VBN involved) (PP (IN in) (NP (DT the) (NN spill))))) (VP (VBZ is) (VP (VBN headed))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="have been told by lawyers to save their findings for court , where it seems nearly everyone involved in the spill is headed" type="VP">
          <tokens>
            <token id="21" string="have" />
            <token id="22" string="been" />
            <token id="23" string="told" />
            <token id="24" string="by" />
            <token id="25" string="lawyers" />
            <token id="26" string="to" />
            <token id="27" string="save" />
            <token id="28" string="their" />
            <token id="29" string="findings" />
            <token id="30" string="for" />
            <token id="31" string="court" />
            <token id="32" string="," />
            <token id="33" string="where" />
            <token id="34" string="it" />
            <token id="35" string="seems" />
            <token id="36" string="nearly" />
            <token id="37" string="everyone" />
            <token id="38" string="involved" />
            <token id="39" string="in" />
            <token id="40" string="the" />
            <token id="41" string="spill" />
            <token id="42" string="is" />
            <token id="43" string="headed" />
          </tokens>
        </chunking>
        <chunking id="2" string="are not finished" type="VP">
          <tokens>
            <token id="6" string="are" />
            <token id="7" string="not" />
            <token id="8" string="finished" />
          </tokens>
        </chunking>
        <chunking id="3" string="their findings" type="NP">
          <tokens>
            <token id="28" string="their" />
            <token id="29" string="findings" />
          </tokens>
        </chunking>
        <chunking id="4" string="nearly everyone involved in the spill" type="NP">
          <tokens>
            <token id="36" string="nearly" />
            <token id="37" string="everyone" />
            <token id="38" string="involved" />
            <token id="39" string="in" />
            <token id="40" string="the" />
            <token id="41" string="spill" />
          </tokens>
        </chunking>
        <chunking id="5" string="nearly everyone" type="NP">
          <tokens>
            <token id="36" string="nearly" />
            <token id="37" string="everyone" />
          </tokens>
        </chunking>
        <chunking id="6" string="these populations" type="NP">
          <tokens>
            <token id="4" string="these" />
            <token id="5" string="populations" />
          </tokens>
        </chunking>
        <chunking id="7" string="Assessment studies" type="NP">
          <tokens>
            <token id="1" string="Assessment" />
            <token id="2" string="studies" />
          </tokens>
        </chunking>
        <chunking id="8" string="finished" type="ADJP">
          <tokens>
            <token id="8" string="finished" />
          </tokens>
        </chunking>
        <chunking id="9" string="to come by _ researchers" type="VP">
          <tokens>
            <token id="16" string="to" />
            <token id="17" string="come" />
            <token id="18" string="by" />
            <token id="19" string="_" />
            <token id="20" string="researchers" />
          </tokens>
        </chunking>
        <chunking id="10" string="it" type="NP">
          <tokens>
            <token id="34" string="it" />
          </tokens>
        </chunking>
        <chunking id="11" string="involved in the spill" type="VP">
          <tokens>
            <token id="38" string="involved" />
            <token id="39" string="in" />
            <token id="40" string="the" />
            <token id="41" string="spill" />
          </tokens>
        </chunking>
        <chunking id="12" string="come by _ researchers" type="VP">
          <tokens>
            <token id="17" string="come" />
            <token id="18" string="by" />
            <token id="19" string="_" />
            <token id="20" string="researchers" />
          </tokens>
        </chunking>
        <chunking id="13" string="court" type="NP">
          <tokens>
            <token id="31" string="court" />
          </tokens>
        </chunking>
        <chunking id="14" string="nearly everyone involved in the spill is headed" type="SBAR">
          <tokens>
            <token id="36" string="nearly" />
            <token id="37" string="everyone" />
            <token id="38" string="involved" />
            <token id="39" string="in" />
            <token id="40" string="the" />
            <token id="41" string="spill" />
            <token id="42" string="is" />
            <token id="43" string="headed" />
          </tokens>
        </chunking>
        <chunking id="15" string="are hard to come by _ researchers" type="VP">
          <tokens>
            <token id="14" string="are" />
            <token id="15" string="hard" />
            <token id="16" string="to" />
            <token id="17" string="come" />
            <token id="18" string="by" />
            <token id="19" string="_" />
            <token id="20" string="researchers" />
          </tokens>
        </chunking>
        <chunking id="16" string="even preliminary findings are hard to come by _ researchers" type="SBAR">
          <tokens>
            <token id="11" string="even" />
            <token id="12" string="preliminary" />
            <token id="13" string="findings" />
            <token id="14" string="are" />
            <token id="15" string="hard" />
            <token id="16" string="to" />
            <token id="17" string="come" />
            <token id="18" string="by" />
            <token id="19" string="_" />
            <token id="20" string="researchers" />
          </tokens>
        </chunking>
        <chunking id="17" string="told by lawyers to save their findings for court , where it seems nearly everyone involved in the spill is headed" type="VP">
          <tokens>
            <token id="23" string="told" />
            <token id="24" string="by" />
            <token id="25" string="lawyers" />
            <token id="26" string="to" />
            <token id="27" string="save" />
            <token id="28" string="their" />
            <token id="29" string="findings" />
            <token id="30" string="for" />
            <token id="31" string="court" />
            <token id="32" string="," />
            <token id="33" string="where" />
            <token id="34" string="it" />
            <token id="35" string="seems" />
            <token id="36" string="nearly" />
            <token id="37" string="everyone" />
            <token id="38" string="involved" />
            <token id="39" string="in" />
            <token id="40" string="the" />
            <token id="41" string="spill" />
            <token id="42" string="is" />
            <token id="43" string="headed" />
          </tokens>
        </chunking>
        <chunking id="18" string="to save their findings for court , where it seems nearly everyone involved in the spill is headed" type="VP">
          <tokens>
            <token id="26" string="to" />
            <token id="27" string="save" />
            <token id="28" string="their" />
            <token id="29" string="findings" />
            <token id="30" string="for" />
            <token id="31" string="court" />
            <token id="32" string="," />
            <token id="33" string="where" />
            <token id="34" string="it" />
            <token id="35" string="seems" />
            <token id="36" string="nearly" />
            <token id="37" string="everyone" />
            <token id="38" string="involved" />
            <token id="39" string="in" />
            <token id="40" string="the" />
            <token id="41" string="spill" />
            <token id="42" string="is" />
            <token id="43" string="headed" />
          </tokens>
        </chunking>
        <chunking id="19" string="been told by lawyers to save their findings for court , where it seems nearly everyone involved in the spill is headed" type="VP">
          <tokens>
            <token id="22" string="been" />
            <token id="23" string="told" />
            <token id="24" string="by" />
            <token id="25" string="lawyers" />
            <token id="26" string="to" />
            <token id="27" string="save" />
            <token id="28" string="their" />
            <token id="29" string="findings" />
            <token id="30" string="for" />
            <token id="31" string="court" />
            <token id="32" string="," />
            <token id="33" string="where" />
            <token id="34" string="it" />
            <token id="35" string="seems" />
            <token id="36" string="nearly" />
            <token id="37" string="everyone" />
            <token id="38" string="involved" />
            <token id="39" string="in" />
            <token id="40" string="the" />
            <token id="41" string="spill" />
            <token id="42" string="is" />
            <token id="43" string="headed" />
          </tokens>
        </chunking>
        <chunking id="20" string="is headed" type="VP">
          <tokens>
            <token id="42" string="is" />
            <token id="43" string="headed" />
          </tokens>
        </chunking>
        <chunking id="21" string="hard to come by _ researchers" type="ADJP">
          <tokens>
            <token id="15" string="hard" />
            <token id="16" string="to" />
            <token id="17" string="come" />
            <token id="18" string="by" />
            <token id="19" string="_" />
            <token id="20" string="researchers" />
          </tokens>
        </chunking>
        <chunking id="22" string="lawyers" type="NP">
          <tokens>
            <token id="25" string="lawyers" />
          </tokens>
        </chunking>
        <chunking id="23" string="where it seems nearly everyone involved in the spill is headed" type="SBAR">
          <tokens>
            <token id="33" string="where" />
            <token id="34" string="it" />
            <token id="35" string="seems" />
            <token id="36" string="nearly" />
            <token id="37" string="everyone" />
            <token id="38" string="involved" />
            <token id="39" string="in" />
            <token id="40" string="the" />
            <token id="41" string="spill" />
            <token id="42" string="is" />
            <token id="43" string="headed" />
          </tokens>
        </chunking>
        <chunking id="24" string="Assessment studies for these populations" type="NP">
          <tokens>
            <token id="1" string="Assessment" />
            <token id="2" string="studies" />
            <token id="3" string="for" />
            <token id="4" string="these" />
            <token id="5" string="populations" />
          </tokens>
        </chunking>
        <chunking id="25" string="the spill" type="NP">
          <tokens>
            <token id="40" string="the" />
            <token id="41" string="spill" />
          </tokens>
        </chunking>
        <chunking id="26" string="headed" type="VP">
          <tokens>
            <token id="43" string="headed" />
          </tokens>
        </chunking>
        <chunking id="27" string="_ researchers" type="NP">
          <tokens>
            <token id="19" string="_" />
            <token id="20" string="researchers" />
          </tokens>
        </chunking>
        <chunking id="28" string="preliminary findings" type="NP">
          <tokens>
            <token id="12" string="preliminary" />
            <token id="13" string="findings" />
          </tokens>
        </chunking>
        <chunking id="29" string="save their findings for court , where it seems nearly everyone involved in the spill is headed" type="VP">
          <tokens>
            <token id="27" string="save" />
            <token id="28" string="their" />
            <token id="29" string="findings" />
            <token id="30" string="for" />
            <token id="31" string="court" />
            <token id="32" string="," />
            <token id="33" string="where" />
            <token id="34" string="it" />
            <token id="35" string="seems" />
            <token id="36" string="nearly" />
            <token id="37" string="everyone" />
            <token id="38" string="involved" />
            <token id="39" string="in" />
            <token id="40" string="the" />
            <token id="41" string="spill" />
            <token id="42" string="is" />
            <token id="43" string="headed" />
          </tokens>
        </chunking>
        <chunking id="30" string="seems nearly everyone involved in the spill is headed" type="VP">
          <tokens>
            <token id="35" string="seems" />
            <token id="36" string="nearly" />
            <token id="37" string="everyone" />
            <token id="38" string="involved" />
            <token id="39" string="in" />
            <token id="40" string="the" />
            <token id="41" string="spill" />
            <token id="42" string="is" />
            <token id="43" string="headed" />
          </tokens>
        </chunking>
        <chunking id="31" string="court , where it seems nearly everyone involved in the spill is headed" type="NP">
          <tokens>
            <token id="31" string="court" />
            <token id="32" string="," />
            <token id="33" string="where" />
            <token id="34" string="it" />
            <token id="35" string="seems" />
            <token id="36" string="nearly" />
            <token id="37" string="everyone" />
            <token id="38" string="involved" />
            <token id="39" string="in" />
            <token id="40" string="the" />
            <token id="41" string="spill" />
            <token id="42" string="is" />
            <token id="43" string="headed" />
          </tokens>
        </chunking>
        <chunking id="32" string="where" type="WHADVP">
          <tokens>
            <token id="33" string="where" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">studies</governor>
          <dependent id="1">Assessment</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="8">finished</governor>
          <dependent id="2">studies</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">populations</governor>
          <dependent id="3">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">populations</governor>
          <dependent id="4">these</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">studies</governor>
          <dependent id="5">populations</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="8">finished</governor>
          <dependent id="6">are</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="8">finished</governor>
          <dependent id="7">not</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">finished</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">finished</governor>
          <dependent id="10">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">hard</governor>
          <dependent id="11">even</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">findings</governor>
          <dependent id="12">preliminary</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">hard</governor>
          <dependent id="13">findings</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="15">hard</governor>
          <dependent id="14">are</dependent>
        </dependency>
        <dependency type="csubjpass">
          <governor id="23">told</governor>
          <dependent id="15">hard</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">come</governor>
          <dependent id="16">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="15">hard</governor>
          <dependent id="17">come</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">researchers</governor>
          <dependent id="18">by</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="20">researchers</governor>
          <dependent id="19">_</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">come</governor>
          <dependent id="20">researchers</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="23">told</governor>
          <dependent id="21">have</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="23">told</governor>
          <dependent id="22">been</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">finished</governor>
          <dependent id="23">told</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">lawyers</governor>
          <dependent id="24">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">told</governor>
          <dependent id="25">lawyers</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="27">save</governor>
          <dependent id="26">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="23">told</governor>
          <dependent id="27">save</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="29">findings</governor>
          <dependent id="28">their</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="27">save</governor>
          <dependent id="29">findings</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">court</governor>
          <dependent id="30">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">save</governor>
          <dependent id="31">court</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="35">seems</governor>
          <dependent id="33">where</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="35">seems</governor>
          <dependent id="34">it</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="31">court</governor>
          <dependent id="35">seems</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="37">everyone</governor>
          <dependent id="36">nearly</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="43">headed</governor>
          <dependent id="37">everyone</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="37">everyone</governor>
          <dependent id="38">involved</dependent>
        </dependency>
        <dependency type="case">
          <governor id="41">spill</governor>
          <dependent id="39">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="41">spill</governor>
          <dependent id="40">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="38">involved</governor>
          <dependent id="41">spill</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="43">headed</governor>
          <dependent id="42">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="35">seems</governor>
          <dependent id="43">headed</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="_" type="NUMBER" score="0.0">
          <tokens>
            <token id="19" string="_" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="34" has_coreference="true">
      <content>Capt. Joseph Hazelwood, skipper of the Exxon Valdez, is on trial this month in Anchorage on charges including criminal mischief and drunken driving of his vessel, and a federal grand jury recently issued criminal indictments against Exxon, starting a case that could take years to finish.</content>
      <tokens>
        <token id="1" string="Capt." lemma="Capt." stem="capt." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="Joseph" lemma="Joseph" stem="joseph" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="Hazelwood" lemma="Hazelwood" stem="hazelwood" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="skipper" lemma="skipper" stem="skipper" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Exxon" lemma="Exxon" stem="exxon" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="Valdez" lemma="Valdez" stem="valdez" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="trial" lemma="trial" stem="trial" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="15" string="month" lemma="month" stem="month" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="16" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Anchorage" lemma="Anchorage" stem="anchorag" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="18" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="charges" lemma="charge" stem="charg" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="including" lemma="include" stem="includ" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="criminal" lemma="criminal" stem="crimin" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="mischief" lemma="mischief" stem="mischief" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="drunken" lemma="drunken" stem="drunken" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="driving" lemma="driving" stem="drive" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="vessel" lemma="vessel" stem="vessel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="federal" lemma="federal" stem="feder" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="grand" lemma="grand" stem="grand" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="jury" lemma="jury" stem="juri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="recently" lemma="recently" stem="recent" pos="RB" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="36" string="issued" lemma="issue" stem="issu" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="criminal" lemma="criminal" stem="crimin" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="indictments" lemma="indictment" stem="indict" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="Exxon" lemma="Exxon" stem="exxon" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="41" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="starting" lemma="start" stem="start" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="45" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="46" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="47" string="take" lemma="take" stem="take" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="48" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="true" />
        <token id="49" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="50" string="finish" lemma="finish" stem="finish" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="51" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (NNP Capt.) (NNP Joseph) (NNP Hazelwood)) (, ,) (NP (NP (NN skipper)) (PP (IN of) (NP (DT the) (NNP Exxon) (NNP Valdez)))) (, ,)) (VP (VBZ is) (PP (IN on) (NP (NP (NN trial)) (NP-TMP (DT this) (NN month)) (PP (IN in) (NP (NNP Anchorage))) (PP (IN on) (NP (NP (NNS charges)) (PP (VBG including) (NP (NP (JJ criminal) (NN mischief) (CC and) (JJ drunken) (NN driving)) (PP (IN of) (NP (PRP$ his) (NN vessel))))))))))) (, ,) (CC and) (S (NP (DT a) (JJ federal) (JJ grand) (NN jury)) (ADVP (RB recently)) (VP (VBD issued) (NP (JJ criminal) (NNS indictments)) (PP (IN against) (NP (NNP Exxon))) (, ,) (S (VP (VBG starting) (NP (NP (DT a) (NN case)) (SBAR (WHNP (WDT that)) (S (VP (MD could) (VP (VB take) (S (NP (NNS years)) (VP (TO to) (VP (VB finish))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="to finish" type="VP">
          <tokens>
            <token id="49" string="to" />
            <token id="50" string="finish" />
          </tokens>
        </chunking>
        <chunking id="2" string="that could take years to finish" type="SBAR">
          <tokens>
            <token id="45" string="that" />
            <token id="46" string="could" />
            <token id="47" string="take" />
            <token id="48" string="years" />
            <token id="49" string="to" />
            <token id="50" string="finish" />
          </tokens>
        </chunking>
        <chunking id="3" string="Exxon" type="NP">
          <tokens>
            <token id="40" string="Exxon" />
          </tokens>
        </chunking>
        <chunking id="4" string="trial this month in Anchorage on charges including criminal mischief and drunken driving of his vessel" type="NP">
          <tokens>
            <token id="13" string="trial" />
            <token id="14" string="this" />
            <token id="15" string="month" />
            <token id="16" string="in" />
            <token id="17" string="Anchorage" />
            <token id="18" string="on" />
            <token id="19" string="charges" />
            <token id="20" string="including" />
            <token id="21" string="criminal" />
            <token id="22" string="mischief" />
            <token id="23" string="and" />
            <token id="24" string="drunken" />
            <token id="25" string="driving" />
            <token id="26" string="of" />
            <token id="27" string="his" />
            <token id="28" string="vessel" />
          </tokens>
        </chunking>
        <chunking id="5" string="is on trial this month in Anchorage on charges including criminal mischief and drunken driving of his vessel" type="VP">
          <tokens>
            <token id="11" string="is" />
            <token id="12" string="on" />
            <token id="13" string="trial" />
            <token id="14" string="this" />
            <token id="15" string="month" />
            <token id="16" string="in" />
            <token id="17" string="Anchorage" />
            <token id="18" string="on" />
            <token id="19" string="charges" />
            <token id="20" string="including" />
            <token id="21" string="criminal" />
            <token id="22" string="mischief" />
            <token id="23" string="and" />
            <token id="24" string="drunken" />
            <token id="25" string="driving" />
            <token id="26" string="of" />
            <token id="27" string="his" />
            <token id="28" string="vessel" />
          </tokens>
        </chunking>
        <chunking id="6" string="Capt. Joseph Hazelwood , skipper of the Exxon Valdez ," type="NP">
          <tokens>
            <token id="1" string="Capt." />
            <token id="2" string="Joseph" />
            <token id="3" string="Hazelwood" />
            <token id="4" string="," />
            <token id="5" string="skipper" />
            <token id="6" string="of" />
            <token id="7" string="the" />
            <token id="8" string="Exxon" />
            <token id="9" string="Valdez" />
            <token id="10" string="," />
          </tokens>
        </chunking>
        <chunking id="7" string="skipper of the Exxon Valdez" type="NP">
          <tokens>
            <token id="5" string="skipper" />
            <token id="6" string="of" />
            <token id="7" string="the" />
            <token id="8" string="Exxon" />
            <token id="9" string="Valdez" />
          </tokens>
        </chunking>
        <chunking id="8" string="charges including criminal mischief and drunken driving of his vessel" type="NP">
          <tokens>
            <token id="19" string="charges" />
            <token id="20" string="including" />
            <token id="21" string="criminal" />
            <token id="22" string="mischief" />
            <token id="23" string="and" />
            <token id="24" string="drunken" />
            <token id="25" string="driving" />
            <token id="26" string="of" />
            <token id="27" string="his" />
            <token id="28" string="vessel" />
          </tokens>
        </chunking>
        <chunking id="9" string="Capt. Joseph Hazelwood" type="NP">
          <tokens>
            <token id="1" string="Capt." />
            <token id="2" string="Joseph" />
            <token id="3" string="Hazelwood" />
          </tokens>
        </chunking>
        <chunking id="10" string="charges" type="NP">
          <tokens>
            <token id="19" string="charges" />
          </tokens>
        </chunking>
        <chunking id="11" string="his vessel" type="NP">
          <tokens>
            <token id="27" string="his" />
            <token id="28" string="vessel" />
          </tokens>
        </chunking>
        <chunking id="12" string="a federal grand jury" type="NP">
          <tokens>
            <token id="31" string="a" />
            <token id="32" string="federal" />
            <token id="33" string="grand" />
            <token id="34" string="jury" />
          </tokens>
        </chunking>
        <chunking id="13" string="a case" type="NP">
          <tokens>
            <token id="43" string="a" />
            <token id="44" string="case" />
          </tokens>
        </chunking>
        <chunking id="14" string="Anchorage" type="NP">
          <tokens>
            <token id="17" string="Anchorage" />
          </tokens>
        </chunking>
        <chunking id="15" string="criminal mischief and drunken driving" type="NP">
          <tokens>
            <token id="21" string="criminal" />
            <token id="22" string="mischief" />
            <token id="23" string="and" />
            <token id="24" string="drunken" />
            <token id="25" string="driving" />
          </tokens>
        </chunking>
        <chunking id="16" string="criminal indictments" type="NP">
          <tokens>
            <token id="37" string="criminal" />
            <token id="38" string="indictments" />
          </tokens>
        </chunking>
        <chunking id="17" string="take years to finish" type="VP">
          <tokens>
            <token id="47" string="take" />
            <token id="48" string="years" />
            <token id="49" string="to" />
            <token id="50" string="finish" />
          </tokens>
        </chunking>
        <chunking id="18" string="skipper" type="NP">
          <tokens>
            <token id="5" string="skipper" />
          </tokens>
        </chunking>
        <chunking id="19" string="could take years to finish" type="VP">
          <tokens>
            <token id="46" string="could" />
            <token id="47" string="take" />
            <token id="48" string="years" />
            <token id="49" string="to" />
            <token id="50" string="finish" />
          </tokens>
        </chunking>
        <chunking id="20" string="issued criminal indictments against Exxon , starting a case that could take years to finish" type="VP">
          <tokens>
            <token id="36" string="issued" />
            <token id="37" string="criminal" />
            <token id="38" string="indictments" />
            <token id="39" string="against" />
            <token id="40" string="Exxon" />
            <token id="41" string="," />
            <token id="42" string="starting" />
            <token id="43" string="a" />
            <token id="44" string="case" />
            <token id="45" string="that" />
            <token id="46" string="could" />
            <token id="47" string="take" />
            <token id="48" string="years" />
            <token id="49" string="to" />
            <token id="50" string="finish" />
          </tokens>
        </chunking>
        <chunking id="21" string="starting a case that could take years to finish" type="VP">
          <tokens>
            <token id="42" string="starting" />
            <token id="43" string="a" />
            <token id="44" string="case" />
            <token id="45" string="that" />
            <token id="46" string="could" />
            <token id="47" string="take" />
            <token id="48" string="years" />
            <token id="49" string="to" />
            <token id="50" string="finish" />
          </tokens>
        </chunking>
        <chunking id="22" string="trial" type="NP">
          <tokens>
            <token id="13" string="trial" />
          </tokens>
        </chunking>
        <chunking id="23" string="years" type="NP">
          <tokens>
            <token id="48" string="years" />
          </tokens>
        </chunking>
        <chunking id="24" string="a case that could take years to finish" type="NP">
          <tokens>
            <token id="43" string="a" />
            <token id="44" string="case" />
            <token id="45" string="that" />
            <token id="46" string="could" />
            <token id="47" string="take" />
            <token id="48" string="years" />
            <token id="49" string="to" />
            <token id="50" string="finish" />
          </tokens>
        </chunking>
        <chunking id="25" string="finish" type="VP">
          <tokens>
            <token id="50" string="finish" />
          </tokens>
        </chunking>
        <chunking id="26" string="the Exxon Valdez" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="Exxon" />
            <token id="9" string="Valdez" />
          </tokens>
        </chunking>
        <chunking id="27" string="criminal mischief and drunken driving of his vessel" type="NP">
          <tokens>
            <token id="21" string="criminal" />
            <token id="22" string="mischief" />
            <token id="23" string="and" />
            <token id="24" string="drunken" />
            <token id="25" string="driving" />
            <token id="26" string="of" />
            <token id="27" string="his" />
            <token id="28" string="vessel" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">Hazelwood</governor>
          <dependent id="1">Capt.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Hazelwood</governor>
          <dependent id="2">Joseph</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">trial</governor>
          <dependent id="3">Hazelwood</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="3">Hazelwood</governor>
          <dependent id="5">skipper</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Valdez</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">Valdez</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Valdez</governor>
          <dependent id="8">Exxon</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">skipper</governor>
          <dependent id="9">Valdez</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="13">trial</governor>
          <dependent id="11">is</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">trial</governor>
          <dependent id="12">on</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">trial</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">month</governor>
          <dependent id="14">this</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="13">trial</governor>
          <dependent id="15">month</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">Anchorage</governor>
          <dependent id="16">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">trial</governor>
          <dependent id="17">Anchorage</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">charges</governor>
          <dependent id="18">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">trial</governor>
          <dependent id="19">charges</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">mischief</governor>
          <dependent id="20">including</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">mischief</governor>
          <dependent id="21">criminal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">charges</governor>
          <dependent id="22">mischief</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="22">mischief</governor>
          <dependent id="23">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">driving</governor>
          <dependent id="24">drunken</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="22">mischief</governor>
          <dependent id="25">driving</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">vessel</governor>
          <dependent id="26">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="28">vessel</governor>
          <dependent id="27">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">mischief</governor>
          <dependent id="28">vessel</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">trial</governor>
          <dependent id="30">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="34">jury</governor>
          <dependent id="31">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="34">jury</governor>
          <dependent id="32">federal</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="34">jury</governor>
          <dependent id="33">grand</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="36">issued</governor>
          <dependent id="34">jury</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="36">issued</governor>
          <dependent id="35">recently</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">trial</governor>
          <dependent id="36">issued</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="38">indictments</governor>
          <dependent id="37">criminal</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="36">issued</governor>
          <dependent id="38">indictments</dependent>
        </dependency>
        <dependency type="case">
          <governor id="40">Exxon</governor>
          <dependent id="39">against</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="36">issued</governor>
          <dependent id="40">Exxon</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="36">issued</governor>
          <dependent id="42">starting</dependent>
        </dependency>
        <dependency type="det">
          <governor id="44">case</governor>
          <dependent id="43">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="42">starting</governor>
          <dependent id="44">case</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="47">take</governor>
          <dependent id="45">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="47">take</governor>
          <dependent id="46">could</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="44">case</governor>
          <dependent id="47">take</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="47">take</governor>
          <dependent id="48">years</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="50">finish</governor>
          <dependent id="49">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="47">take</governor>
          <dependent id="50">finish</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="this month" type="DATE" score="0.0">
          <tokens>
            <token id="14" string="this" />
            <token id="15" string="month" />
          </tokens>
        </entity>
        <entity id="2" string="Exxon" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="40" string="Exxon" />
          </tokens>
        </entity>
        <entity id="3" string="recently" type="DATE" score="0.0">
          <tokens>
            <token id="35" string="recently" />
          </tokens>
        </entity>
        <entity id="4" string="Anchorage" type="LOCATION" score="0.0">
          <tokens>
            <token id="17" string="Anchorage" />
          </tokens>
        </entity>
        <entity id="5" string="years" type="DURATION" score="0.0">
          <tokens>
            <token id="48" string="years" />
          </tokens>
        </entity>
        <entity id="6" string="Joseph Hazelwood" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Joseph" />
            <token id="3" string="Hazelwood" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="35" has_coreference="false">
      <content>Exxon already faces more than 150 civil lawsuits.</content>
      <tokens>
        <token id="1" string="Exxon" lemma="Exxon" stem="exxon" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="2" string="already" lemma="already" stem="alreadi" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="faces" lemma="face" stem="face" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="more" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="150" lemma="150" stem="150" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="7" string="civil" lemma="civil" stem="civil" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="lawsuits" lemma="lawsuit" stem="lawsuit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Exxon)) (ADVP (RB already)) (VP (VBZ faces) (NP (QP (JJR more) (IN than) (CD 150)) (JJ civil) (NNS lawsuits))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Exxon" type="NP">
          <tokens>
            <token id="1" string="Exxon" />
          </tokens>
        </chunking>
        <chunking id="2" string="faces more than 150 civil lawsuits" type="VP">
          <tokens>
            <token id="3" string="faces" />
            <token id="4" string="more" />
            <token id="5" string="than" />
            <token id="6" string="150" />
            <token id="7" string="civil" />
            <token id="8" string="lawsuits" />
          </tokens>
        </chunking>
        <chunking id="3" string="more than 150 civil lawsuits" type="NP">
          <tokens>
            <token id="4" string="more" />
            <token id="5" string="than" />
            <token id="6" string="150" />
            <token id="7" string="civil" />
            <token id="8" string="lawsuits" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">faces</governor>
          <dependent id="1">Exxon</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">faces</governor>
          <dependent id="2">already</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">faces</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">150</governor>
          <dependent id="4">more</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="4">more</governor>
          <dependent id="5">than</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="8">lawsuits</governor>
          <dependent id="6">150</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">lawsuits</governor>
          <dependent id="7">civil</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">faces</governor>
          <dependent id="8">lawsuits</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Exxon" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="1" string="Exxon" />
          </tokens>
        </entity>
        <entity id="2" string="150" type="NUMBER" score="0.0">
          <tokens>
            <token id="6" string="150" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="36" has_coreference="false">
      <content>Fishermen sued because of lost seasons.</content>
      <tokens>
        <token id="1" string="Fishermen" lemma="fisherman" stem="fishermen" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="sued" lemma="sue" stem="su" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="lost" lemma="lost" stem="lost" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="seasons" lemma="season" stem="season" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNS Fishermen)) (VP (VBD sued) (PP (IN because) (PP (IN of) (NP (JJ lost) (NNS seasons))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="lost seasons" type="NP">
          <tokens>
            <token id="5" string="lost" />
            <token id="6" string="seasons" />
          </tokens>
        </chunking>
        <chunking id="2" string="sued because of lost seasons" type="VP">
          <tokens>
            <token id="2" string="sued" />
            <token id="3" string="because" />
            <token id="4" string="of" />
            <token id="5" string="lost" />
            <token id="6" string="seasons" />
          </tokens>
        </chunking>
        <chunking id="3" string="Fishermen" type="NP">
          <tokens>
            <token id="1" string="Fishermen" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">sued</governor>
          <dependent id="1">Fishermen</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">sued</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">seasons</governor>
          <dependent id="3">because</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">seasons</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">seasons</governor>
          <dependent id="5">lost</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">sued</governor>
          <dependent id="6">seasons</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="37" has_coreference="false">
      <content>Tour-boat operators sued because fewer people wanted to cruise an oiled sound.</content>
      <tokens>
        <token id="1" string="Tour-boat" lemma="tour-boat" stem="tour-boat" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="operators" lemma="operator" stem="oper" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="sued" lemma="sue" stem="su" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="fewer" lemma="fewer" stem="fewer" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="wanted" lemma="want" stem="want" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="cruise" lemma="cruise" stem="cruis" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="oiled" lemma="oil" stem="oil" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="sound" lemma="sound" stem="sound" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (JJ Tour-boat) (NNS operators)) (VP (VBD sued) (SBAR (IN because) (S (NP (JJR fewer) (NNS people)) (VP (VBD wanted) (S (VP (TO to) (VP (VB cruise) (NP (NP (DT an)) (VP (VBN oiled) (NP (NN sound))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="sued because fewer people wanted to cruise an oiled sound" type="VP">
          <tokens>
            <token id="3" string="sued" />
            <token id="4" string="because" />
            <token id="5" string="fewer" />
            <token id="6" string="people" />
            <token id="7" string="wanted" />
            <token id="8" string="to" />
            <token id="9" string="cruise" />
            <token id="10" string="an" />
            <token id="11" string="oiled" />
            <token id="12" string="sound" />
          </tokens>
        </chunking>
        <chunking id="2" string="an oiled sound" type="NP">
          <tokens>
            <token id="10" string="an" />
            <token id="11" string="oiled" />
            <token id="12" string="sound" />
          </tokens>
        </chunking>
        <chunking id="3" string="Tour-boat operators" type="NP">
          <tokens>
            <token id="1" string="Tour-boat" />
            <token id="2" string="operators" />
          </tokens>
        </chunking>
        <chunking id="4" string="wanted to cruise an oiled sound" type="VP">
          <tokens>
            <token id="7" string="wanted" />
            <token id="8" string="to" />
            <token id="9" string="cruise" />
            <token id="10" string="an" />
            <token id="11" string="oiled" />
            <token id="12" string="sound" />
          </tokens>
        </chunking>
        <chunking id="5" string="cruise an oiled sound" type="VP">
          <tokens>
            <token id="9" string="cruise" />
            <token id="10" string="an" />
            <token id="11" string="oiled" />
            <token id="12" string="sound" />
          </tokens>
        </chunking>
        <chunking id="6" string="sound" type="NP">
          <tokens>
            <token id="12" string="sound" />
          </tokens>
        </chunking>
        <chunking id="7" string="fewer people" type="NP">
          <tokens>
            <token id="5" string="fewer" />
            <token id="6" string="people" />
          </tokens>
        </chunking>
        <chunking id="8" string="an" type="NP">
          <tokens>
            <token id="10" string="an" />
          </tokens>
        </chunking>
        <chunking id="9" string="to cruise an oiled sound" type="VP">
          <tokens>
            <token id="8" string="to" />
            <token id="9" string="cruise" />
            <token id="10" string="an" />
            <token id="11" string="oiled" />
            <token id="12" string="sound" />
          </tokens>
        </chunking>
        <chunking id="10" string="because fewer people wanted to cruise an oiled sound" type="SBAR">
          <tokens>
            <token id="4" string="because" />
            <token id="5" string="fewer" />
            <token id="6" string="people" />
            <token id="7" string="wanted" />
            <token id="8" string="to" />
            <token id="9" string="cruise" />
            <token id="10" string="an" />
            <token id="11" string="oiled" />
            <token id="12" string="sound" />
          </tokens>
        </chunking>
        <chunking id="11" string="oiled sound" type="VP">
          <tokens>
            <token id="11" string="oiled" />
            <token id="12" string="sound" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="2">operators</governor>
          <dependent id="1">Tour-boat</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">sued</governor>
          <dependent id="2">operators</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">sued</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">wanted</governor>
          <dependent id="4">because</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">people</governor>
          <dependent id="5">fewer</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">wanted</governor>
          <dependent id="6">people</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">sued</governor>
          <dependent id="7">wanted</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">cruise</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="7">wanted</governor>
          <dependent id="9">cruise</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">cruise</governor>
          <dependent id="10">an</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="10">an</governor>
          <dependent id="11">oiled</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">oiled</governor>
          <dependent id="12">sound</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="38" has_coreference="true">
      <content>The state sued, claiming the company was negligent in responding to the spill, only to be countersued by Exxon, which claimed state officials hindered the use of chemical dispersants that could have broken up large quantities of oil early on.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="state" lemma="state" stem="state" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="sued" lemma="sue" stem="su" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="claiming" lemma="claim" stem="claim" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="company" lemma="company" stem="compani" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="negligent" lemma="negligent" stem="neglig" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="responding" lemma="respond" stem="respond" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="spill" lemma="spill" stem="spill" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="only" lemma="only" stem="onli" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="countersued" lemma="countersue" stem="countersu" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="Exxon" lemma="Exxon" stem="exxon" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="claimed" lemma="claim" stem="claim" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="25" string="state" lemma="state" stem="state" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="26" string="officials" lemma="official" stem="offici" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="27" string="hindered" lemma="hinder" stem="hinder" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="28" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="29" string="use" lemma="use" stem="us" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="30" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="31" string="chemical" lemma="chemical" stem="chemic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="32" string="dispersants" lemma="dispersant" stem="dispers" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="33" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="34" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="35" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="36" string="broken" lemma="break" stem="broken" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="37" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="38" string="large" lemma="large" stem="larg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="39" string="quantities" lemma="quantity" stem="quantiti" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="40" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="41" string="oil" lemma="oil" stem="oil" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="42" string="early" lemma="early" stem="earli" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="43" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="44" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN state)) (VP (VBD sued) (, ,) (S (VP (VBG claiming) (SBAR (S (NP (DT the) (NN company)) (VP (VBD was) (ADJP (JJ negligent) (PP (IN in) (S (VP (VBG responding) (PP (TO to) (NP (DT the) (NN spill))) (, ,) (ADVP (RB only)) (S (VP (TO to) (VP (VB be) (VP (VBN countersued) (PP (IN by) (NP (NP (NNP Exxon)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBD claimed) (SBAR (S (NP (NN state) (NNS officials)) (VP (VBD hindered) (NP (NP (DT the) (NN use)) (PP (IN of) (NP (NN chemical) (NNS dispersants))) (SBAR (WHNP (WDT that)) (S (VP (MD could) (VP (VB have) (VP (VBN broken) (PRT (RP up)) (NP (NP (JJ large) (NNS quantities)) (PP (IN of) (NP (NN oil) (JJ early)))) (PP (IN on)))))))))))))))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="could have broken up large quantities of oil early on" type="VP">
          <tokens>
            <token id="34" string="could" />
            <token id="35" string="have" />
            <token id="36" string="broken" />
            <token id="37" string="up" />
            <token id="38" string="large" />
            <token id="39" string="quantities" />
            <token id="40" string="of" />
            <token id="41" string="oil" />
            <token id="42" string="early" />
            <token id="43" string="on" />
          </tokens>
        </chunking>
        <chunking id="2" string="the use of chemical dispersants that could have broken up large quantities of oil early on" type="NP">
          <tokens>
            <token id="28" string="the" />
            <token id="29" string="use" />
            <token id="30" string="of" />
            <token id="31" string="chemical" />
            <token id="32" string="dispersants" />
            <token id="33" string="that" />
            <token id="34" string="could" />
            <token id="35" string="have" />
            <token id="36" string="broken" />
            <token id="37" string="up" />
            <token id="38" string="large" />
            <token id="39" string="quantities" />
            <token id="40" string="of" />
            <token id="41" string="oil" />
            <token id="42" string="early" />
            <token id="43" string="on" />
          </tokens>
        </chunking>
        <chunking id="3" string="Exxon" type="NP">
          <tokens>
            <token id="21" string="Exxon" />
          </tokens>
        </chunking>
        <chunking id="4" string="hindered the use of chemical dispersants that could have broken up large quantities of oil early on" type="VP">
          <tokens>
            <token id="27" string="hindered" />
            <token id="28" string="the" />
            <token id="29" string="use" />
            <token id="30" string="of" />
            <token id="31" string="chemical" />
            <token id="32" string="dispersants" />
            <token id="33" string="that" />
            <token id="34" string="could" />
            <token id="35" string="have" />
            <token id="36" string="broken" />
            <token id="37" string="up" />
            <token id="38" string="large" />
            <token id="39" string="quantities" />
            <token id="40" string="of" />
            <token id="41" string="oil" />
            <token id="42" string="early" />
            <token id="43" string="on" />
          </tokens>
        </chunking>
        <chunking id="5" string="The state" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="state" />
          </tokens>
        </chunking>
        <chunking id="6" string="have broken up large quantities of oil early on" type="VP">
          <tokens>
            <token id="35" string="have" />
            <token id="36" string="broken" />
            <token id="37" string="up" />
            <token id="38" string="large" />
            <token id="39" string="quantities" />
            <token id="40" string="of" />
            <token id="41" string="oil" />
            <token id="42" string="early" />
            <token id="43" string="on" />
          </tokens>
        </chunking>
        <chunking id="7" string="to be countersued by Exxon , which claimed state officials hindered the use of chemical dispersants that could have broken up large quantities of oil early on" type="VP">
          <tokens>
            <token id="17" string="to" />
            <token id="18" string="be" />
            <token id="19" string="countersued" />
            <token id="20" string="by" />
            <token id="21" string="Exxon" />
            <token id="22" string="," />
            <token id="23" string="which" />
            <token id="24" string="claimed" />
            <token id="25" string="state" />
            <token id="26" string="officials" />
            <token id="27" string="hindered" />
            <token id="28" string="the" />
            <token id="29" string="use" />
            <token id="30" string="of" />
            <token id="31" string="chemical" />
            <token id="32" string="dispersants" />
            <token id="33" string="that" />
            <token id="34" string="could" />
            <token id="35" string="have" />
            <token id="36" string="broken" />
            <token id="37" string="up" />
            <token id="38" string="large" />
            <token id="39" string="quantities" />
            <token id="40" string="of" />
            <token id="41" string="oil" />
            <token id="42" string="early" />
            <token id="43" string="on" />
          </tokens>
        </chunking>
        <chunking id="8" string="be countersued by Exxon , which claimed state officials hindered the use of chemical dispersants that could have broken up large quantities of oil early on" type="VP">
          <tokens>
            <token id="18" string="be" />
            <token id="19" string="countersued" />
            <token id="20" string="by" />
            <token id="21" string="Exxon" />
            <token id="22" string="," />
            <token id="23" string="which" />
            <token id="24" string="claimed" />
            <token id="25" string="state" />
            <token id="26" string="officials" />
            <token id="27" string="hindered" />
            <token id="28" string="the" />
            <token id="29" string="use" />
            <token id="30" string="of" />
            <token id="31" string="chemical" />
            <token id="32" string="dispersants" />
            <token id="33" string="that" />
            <token id="34" string="could" />
            <token id="35" string="have" />
            <token id="36" string="broken" />
            <token id="37" string="up" />
            <token id="38" string="large" />
            <token id="39" string="quantities" />
            <token id="40" string="of" />
            <token id="41" string="oil" />
            <token id="42" string="early" />
            <token id="43" string="on" />
          </tokens>
        </chunking>
        <chunking id="9" string="countersued by Exxon , which claimed state officials hindered the use of chemical dispersants that could have broken up large quantities of oil early on" type="VP">
          <tokens>
            <token id="19" string="countersued" />
            <token id="20" string="by" />
            <token id="21" string="Exxon" />
            <token id="22" string="," />
            <token id="23" string="which" />
            <token id="24" string="claimed" />
            <token id="25" string="state" />
            <token id="26" string="officials" />
            <token id="27" string="hindered" />
            <token id="28" string="the" />
            <token id="29" string="use" />
            <token id="30" string="of" />
            <token id="31" string="chemical" />
            <token id="32" string="dispersants" />
            <token id="33" string="that" />
            <token id="34" string="could" />
            <token id="35" string="have" />
            <token id="36" string="broken" />
            <token id="37" string="up" />
            <token id="38" string="large" />
            <token id="39" string="quantities" />
            <token id="40" string="of" />
            <token id="41" string="oil" />
            <token id="42" string="early" />
            <token id="43" string="on" />
          </tokens>
        </chunking>
        <chunking id="10" string="sued , claiming the company was negligent in responding to the spill , only to be countersued by Exxon , which claimed state officials hindered the use of chemical dispersants that could have broken up large quantities of oil early on" type="VP">
          <tokens>
            <token id="3" string="sued" />
            <token id="4" string="," />
            <token id="5" string="claiming" />
            <token id="6" string="the" />
            <token id="7" string="company" />
            <token id="8" string="was" />
            <token id="9" string="negligent" />
            <token id="10" string="in" />
            <token id="11" string="responding" />
            <token id="12" string="to" />
            <token id="13" string="the" />
            <token id="14" string="spill" />
            <token id="15" string="," />
            <token id="16" string="only" />
            <token id="17" string="to" />
            <token id="18" string="be" />
            <token id="19" string="countersued" />
            <token id="20" string="by" />
            <token id="21" string="Exxon" />
            <token id="22" string="," />
            <token id="23" string="which" />
            <token id="24" string="claimed" />
            <token id="25" string="state" />
            <token id="26" string="officials" />
            <token id="27" string="hindered" />
            <token id="28" string="the" />
            <token id="29" string="use" />
            <token id="30" string="of" />
            <token id="31" string="chemical" />
            <token id="32" string="dispersants" />
            <token id="33" string="that" />
            <token id="34" string="could" />
            <token id="35" string="have" />
            <token id="36" string="broken" />
            <token id="37" string="up" />
            <token id="38" string="large" />
            <token id="39" string="quantities" />
            <token id="40" string="of" />
            <token id="41" string="oil" />
            <token id="42" string="early" />
            <token id="43" string="on" />
          </tokens>
        </chunking>
        <chunking id="11" string="was negligent in responding to the spill , only to be countersued by Exxon , which claimed state officials hindered the use of chemical dispersants that could have broken up large quantities of oil early on" type="VP">
          <tokens>
            <token id="8" string="was" />
            <token id="9" string="negligent" />
            <token id="10" string="in" />
            <token id="11" string="responding" />
            <token id="12" string="to" />
            <token id="13" string="the" />
            <token id="14" string="spill" />
            <token id="15" string="," />
            <token id="16" string="only" />
            <token id="17" string="to" />
            <token id="18" string="be" />
            <token id="19" string="countersued" />
            <token id="20" string="by" />
            <token id="21" string="Exxon" />
            <token id="22" string="," />
            <token id="23" string="which" />
            <token id="24" string="claimed" />
            <token id="25" string="state" />
            <token id="26" string="officials" />
            <token id="27" string="hindered" />
            <token id="28" string="the" />
            <token id="29" string="use" />
            <token id="30" string="of" />
            <token id="31" string="chemical" />
            <token id="32" string="dispersants" />
            <token id="33" string="that" />
            <token id="34" string="could" />
            <token id="35" string="have" />
            <token id="36" string="broken" />
            <token id="37" string="up" />
            <token id="38" string="large" />
            <token id="39" string="quantities" />
            <token id="40" string="of" />
            <token id="41" string="oil" />
            <token id="42" string="early" />
            <token id="43" string="on" />
          </tokens>
        </chunking>
        <chunking id="12" string="claimed state officials hindered the use of chemical dispersants that could have broken up large quantities of oil early on" type="VP">
          <tokens>
            <token id="24" string="claimed" />
            <token id="25" string="state" />
            <token id="26" string="officials" />
            <token id="27" string="hindered" />
            <token id="28" string="the" />
            <token id="29" string="use" />
            <token id="30" string="of" />
            <token id="31" string="chemical" />
            <token id="32" string="dispersants" />
            <token id="33" string="that" />
            <token id="34" string="could" />
            <token id="35" string="have" />
            <token id="36" string="broken" />
            <token id="37" string="up" />
            <token id="38" string="large" />
            <token id="39" string="quantities" />
            <token id="40" string="of" />
            <token id="41" string="oil" />
            <token id="42" string="early" />
            <token id="43" string="on" />
          </tokens>
        </chunking>
        <chunking id="13" string="state officials hindered the use of chemical dispersants that could have broken up large quantities of oil early on" type="SBAR">
          <tokens>
            <token id="25" string="state" />
            <token id="26" string="officials" />
            <token id="27" string="hindered" />
            <token id="28" string="the" />
            <token id="29" string="use" />
            <token id="30" string="of" />
            <token id="31" string="chemical" />
            <token id="32" string="dispersants" />
            <token id="33" string="that" />
            <token id="34" string="could" />
            <token id="35" string="have" />
            <token id="36" string="broken" />
            <token id="37" string="up" />
            <token id="38" string="large" />
            <token id="39" string="quantities" />
            <token id="40" string="of" />
            <token id="41" string="oil" />
            <token id="42" string="early" />
            <token id="43" string="on" />
          </tokens>
        </chunking>
        <chunking id="14" string="claiming the company was negligent in responding to the spill , only to be countersued by Exxon , which claimed state officials hindered the use of chemical dispersants that could have broken up large quantities of oil early on" type="VP">
          <tokens>
            <token id="5" string="claiming" />
            <token id="6" string="the" />
            <token id="7" string="company" />
            <token id="8" string="was" />
            <token id="9" string="negligent" />
            <token id="10" string="in" />
            <token id="11" string="responding" />
            <token id="12" string="to" />
            <token id="13" string="the" />
            <token id="14" string="spill" />
            <token id="15" string="," />
            <token id="16" string="only" />
            <token id="17" string="to" />
            <token id="18" string="be" />
            <token id="19" string="countersued" />
            <token id="20" string="by" />
            <token id="21" string="Exxon" />
            <token id="22" string="," />
            <token id="23" string="which" />
            <token id="24" string="claimed" />
            <token id="25" string="state" />
            <token id="26" string="officials" />
            <token id="27" string="hindered" />
            <token id="28" string="the" />
            <token id="29" string="use" />
            <token id="30" string="of" />
            <token id="31" string="chemical" />
            <token id="32" string="dispersants" />
            <token id="33" string="that" />
            <token id="34" string="could" />
            <token id="35" string="have" />
            <token id="36" string="broken" />
            <token id="37" string="up" />
            <token id="38" string="large" />
            <token id="39" string="quantities" />
            <token id="40" string="of" />
            <token id="41" string="oil" />
            <token id="42" string="early" />
            <token id="43" string="on" />
          </tokens>
        </chunking>
        <chunking id="15" string="the use" type="NP">
          <tokens>
            <token id="28" string="the" />
            <token id="29" string="use" />
          </tokens>
        </chunking>
        <chunking id="16" string="Exxon , which claimed state officials hindered the use of chemical dispersants that could have broken up large quantities of oil early on" type="NP">
          <tokens>
            <token id="21" string="Exxon" />
            <token id="22" string="," />
            <token id="23" string="which" />
            <token id="24" string="claimed" />
            <token id="25" string="state" />
            <token id="26" string="officials" />
            <token id="27" string="hindered" />
            <token id="28" string="the" />
            <token id="29" string="use" />
            <token id="30" string="of" />
            <token id="31" string="chemical" />
            <token id="32" string="dispersants" />
            <token id="33" string="that" />
            <token id="34" string="could" />
            <token id="35" string="have" />
            <token id="36" string="broken" />
            <token id="37" string="up" />
            <token id="38" string="large" />
            <token id="39" string="quantities" />
            <token id="40" string="of" />
            <token id="41" string="oil" />
            <token id="42" string="early" />
            <token id="43" string="on" />
          </tokens>
        </chunking>
        <chunking id="17" string="the spill" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="spill" />
          </tokens>
        </chunking>
        <chunking id="18" string="which claimed state officials hindered the use of chemical dispersants that could have broken up large quantities of oil early on" type="SBAR">
          <tokens>
            <token id="23" string="which" />
            <token id="24" string="claimed" />
            <token id="25" string="state" />
            <token id="26" string="officials" />
            <token id="27" string="hindered" />
            <token id="28" string="the" />
            <token id="29" string="use" />
            <token id="30" string="of" />
            <token id="31" string="chemical" />
            <token id="32" string="dispersants" />
            <token id="33" string="that" />
            <token id="34" string="could" />
            <token id="35" string="have" />
            <token id="36" string="broken" />
            <token id="37" string="up" />
            <token id="38" string="large" />
            <token id="39" string="quantities" />
            <token id="40" string="of" />
            <token id="41" string="oil" />
            <token id="42" string="early" />
            <token id="43" string="on" />
          </tokens>
        </chunking>
        <chunking id="19" string="the company" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="company" />
          </tokens>
        </chunking>
        <chunking id="20" string="large quantities of oil early" type="NP">
          <tokens>
            <token id="38" string="large" />
            <token id="39" string="quantities" />
            <token id="40" string="of" />
            <token id="41" string="oil" />
            <token id="42" string="early" />
          </tokens>
        </chunking>
        <chunking id="21" string="the company was negligent in responding to the spill , only to be countersued by Exxon , which claimed state officials hindered the use of chemical dispersants that could have broken up large quantities of oil early on" type="SBAR">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="company" />
            <token id="8" string="was" />
            <token id="9" string="negligent" />
            <token id="10" string="in" />
            <token id="11" string="responding" />
            <token id="12" string="to" />
            <token id="13" string="the" />
            <token id="14" string="spill" />
            <token id="15" string="," />
            <token id="16" string="only" />
            <token id="17" string="to" />
            <token id="18" string="be" />
            <token id="19" string="countersued" />
            <token id="20" string="by" />
            <token id="21" string="Exxon" />
            <token id="22" string="," />
            <token id="23" string="which" />
            <token id="24" string="claimed" />
            <token id="25" string="state" />
            <token id="26" string="officials" />
            <token id="27" string="hindered" />
            <token id="28" string="the" />
            <token id="29" string="use" />
            <token id="30" string="of" />
            <token id="31" string="chemical" />
            <token id="32" string="dispersants" />
            <token id="33" string="that" />
            <token id="34" string="could" />
            <token id="35" string="have" />
            <token id="36" string="broken" />
            <token id="37" string="up" />
            <token id="38" string="large" />
            <token id="39" string="quantities" />
            <token id="40" string="of" />
            <token id="41" string="oil" />
            <token id="42" string="early" />
            <token id="43" string="on" />
          </tokens>
        </chunking>
        <chunking id="22" string="negligent in responding to the spill , only to be countersued by Exxon , which claimed state officials hindered the use of chemical dispersants that could have broken up large quantities of oil early on" type="ADJP">
          <tokens>
            <token id="9" string="negligent" />
            <token id="10" string="in" />
            <token id="11" string="responding" />
            <token id="12" string="to" />
            <token id="13" string="the" />
            <token id="14" string="spill" />
            <token id="15" string="," />
            <token id="16" string="only" />
            <token id="17" string="to" />
            <token id="18" string="be" />
            <token id="19" string="countersued" />
            <token id="20" string="by" />
            <token id="21" string="Exxon" />
            <token id="22" string="," />
            <token id="23" string="which" />
            <token id="24" string="claimed" />
            <token id="25" string="state" />
            <token id="26" string="officials" />
            <token id="27" string="hindered" />
            <token id="28" string="the" />
            <token id="29" string="use" />
            <token id="30" string="of" />
            <token id="31" string="chemical" />
            <token id="32" string="dispersants" />
            <token id="33" string="that" />
            <token id="34" string="could" />
            <token id="35" string="have" />
            <token id="36" string="broken" />
            <token id="37" string="up" />
            <token id="38" string="large" />
            <token id="39" string="quantities" />
            <token id="40" string="of" />
            <token id="41" string="oil" />
            <token id="42" string="early" />
            <token id="43" string="on" />
          </tokens>
        </chunking>
        <chunking id="23" string="responding to the spill , only to be countersued by Exxon , which claimed state officials hindered the use of chemical dispersants that could have broken up large quantities of oil early on" type="VP">
          <tokens>
            <token id="11" string="responding" />
            <token id="12" string="to" />
            <token id="13" string="the" />
            <token id="14" string="spill" />
            <token id="15" string="," />
            <token id="16" string="only" />
            <token id="17" string="to" />
            <token id="18" string="be" />
            <token id="19" string="countersued" />
            <token id="20" string="by" />
            <token id="21" string="Exxon" />
            <token id="22" string="," />
            <token id="23" string="which" />
            <token id="24" string="claimed" />
            <token id="25" string="state" />
            <token id="26" string="officials" />
            <token id="27" string="hindered" />
            <token id="28" string="the" />
            <token id="29" string="use" />
            <token id="30" string="of" />
            <token id="31" string="chemical" />
            <token id="32" string="dispersants" />
            <token id="33" string="that" />
            <token id="34" string="could" />
            <token id="35" string="have" />
            <token id="36" string="broken" />
            <token id="37" string="up" />
            <token id="38" string="large" />
            <token id="39" string="quantities" />
            <token id="40" string="of" />
            <token id="41" string="oil" />
            <token id="42" string="early" />
            <token id="43" string="on" />
          </tokens>
        </chunking>
        <chunking id="24" string="oil early" type="NP">
          <tokens>
            <token id="41" string="oil" />
            <token id="42" string="early" />
          </tokens>
        </chunking>
        <chunking id="25" string="state officials" type="NP">
          <tokens>
            <token id="25" string="state" />
            <token id="26" string="officials" />
          </tokens>
        </chunking>
        <chunking id="26" string="chemical dispersants" type="NP">
          <tokens>
            <token id="31" string="chemical" />
            <token id="32" string="dispersants" />
          </tokens>
        </chunking>
        <chunking id="27" string="that could have broken up large quantities of oil early on" type="SBAR">
          <tokens>
            <token id="33" string="that" />
            <token id="34" string="could" />
            <token id="35" string="have" />
            <token id="36" string="broken" />
            <token id="37" string="up" />
            <token id="38" string="large" />
            <token id="39" string="quantities" />
            <token id="40" string="of" />
            <token id="41" string="oil" />
            <token id="42" string="early" />
            <token id="43" string="on" />
          </tokens>
        </chunking>
        <chunking id="28" string="broken up large quantities of oil early on" type="VP">
          <tokens>
            <token id="36" string="broken" />
            <token id="37" string="up" />
            <token id="38" string="large" />
            <token id="39" string="quantities" />
            <token id="40" string="of" />
            <token id="41" string="oil" />
            <token id="42" string="early" />
            <token id="43" string="on" />
          </tokens>
        </chunking>
        <chunking id="29" string="large quantities" type="NP">
          <tokens>
            <token id="38" string="large" />
            <token id="39" string="quantities" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">state</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">sued</governor>
          <dependent id="2">state</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">sued</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">sued</governor>
          <dependent id="5">claiming</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">company</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">negligent</governor>
          <dependent id="7">company</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="9">negligent</governor>
          <dependent id="8">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">claiming</governor>
          <dependent id="9">negligent</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">responding</governor>
          <dependent id="10">in</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="9">negligent</governor>
          <dependent id="11">responding</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">spill</governor>
          <dependent id="12">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">spill</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">responding</governor>
          <dependent id="14">spill</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="19">countersued</governor>
          <dependent id="16">only</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">countersued</governor>
          <dependent id="17">to</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="19">countersued</governor>
          <dependent id="18">be</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="11">responding</governor>
          <dependent id="19">countersued</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">Exxon</governor>
          <dependent id="20">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">countersued</governor>
          <dependent id="21">Exxon</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">claimed</governor>
          <dependent id="23">which</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="21">Exxon</governor>
          <dependent id="24">claimed</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">officials</governor>
          <dependent id="25">state</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">hindered</governor>
          <dependent id="26">officials</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="24">claimed</governor>
          <dependent id="27">hindered</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">use</governor>
          <dependent id="28">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="27">hindered</governor>
          <dependent id="29">use</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">dispersants</governor>
          <dependent id="30">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="32">dispersants</governor>
          <dependent id="31">chemical</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">use</governor>
          <dependent id="32">dispersants</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="36">broken</governor>
          <dependent id="33">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="36">broken</governor>
          <dependent id="34">could</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="36">broken</governor>
          <dependent id="35">have</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="29">use</governor>
          <dependent id="36">broken</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="36">broken</governor>
          <dependent id="37">up</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="39">quantities</governor>
          <dependent id="38">large</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="36">broken</governor>
          <dependent id="39">quantities</dependent>
        </dependency>
        <dependency type="case">
          <governor id="41">oil</governor>
          <dependent id="40">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="39">quantities</governor>
          <dependent id="41">oil</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="41">oil</governor>
          <dependent id="42">early</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="36">broken</governor>
          <dependent id="43">on</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Exxon" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="21" string="Exxon" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="39" has_coreference="true">
      <content>Information about the spill is filtered through this litigious atmosphere, making much of it suspect.</content>
      <tokens>
        <token id="1" string="Information" lemma="information" stem="informat" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="4" string="spill" lemma="spill" stem="spill" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="5" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="filtered" lemma="filter" stem="filter" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="litigious" lemma="litigious" stem="litigi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="atmosphere" lemma="atmosphere" stem="atmospher" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="making" lemma="make" stem="make" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="much" lemma="much" stem="much" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="suspect" lemma="suspect" stem="suspect" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NN Information)) (PP (IN about) (NP (DT the) (NN spill)))) (VP (VBZ is) (VP (VBN filtered) (PP (IN through) (NP (DT this) (JJ litigious) (NN atmosphere))) (, ,) (S (VP (VBG making) (S (NP (NP (JJ much)) (PP (IN of) (NP (PRP it)))) (VP (VB suspect))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="this litigious atmosphere" type="NP">
          <tokens>
            <token id="8" string="this" />
            <token id="9" string="litigious" />
            <token id="10" string="atmosphere" />
          </tokens>
        </chunking>
        <chunking id="2" string="the spill" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="spill" />
          </tokens>
        </chunking>
        <chunking id="3" string="making much of it suspect" type="VP">
          <tokens>
            <token id="12" string="making" />
            <token id="13" string="much" />
            <token id="14" string="of" />
            <token id="15" string="it" />
            <token id="16" string="suspect" />
          </tokens>
        </chunking>
        <chunking id="4" string="it" type="NP">
          <tokens>
            <token id="15" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="suspect" type="VP">
          <tokens>
            <token id="16" string="suspect" />
          </tokens>
        </chunking>
        <chunking id="6" string="Information" type="NP">
          <tokens>
            <token id="1" string="Information" />
          </tokens>
        </chunking>
        <chunking id="7" string="filtered through this litigious atmosphere , making much of it suspect" type="VP">
          <tokens>
            <token id="6" string="filtered" />
            <token id="7" string="through" />
            <token id="8" string="this" />
            <token id="9" string="litigious" />
            <token id="10" string="atmosphere" />
            <token id="11" string="," />
            <token id="12" string="making" />
            <token id="13" string="much" />
            <token id="14" string="of" />
            <token id="15" string="it" />
            <token id="16" string="suspect" />
          </tokens>
        </chunking>
        <chunking id="8" string="Information about the spill" type="NP">
          <tokens>
            <token id="1" string="Information" />
            <token id="2" string="about" />
            <token id="3" string="the" />
            <token id="4" string="spill" />
          </tokens>
        </chunking>
        <chunking id="9" string="is filtered through this litigious atmosphere , making much of it suspect" type="VP">
          <tokens>
            <token id="5" string="is" />
            <token id="6" string="filtered" />
            <token id="7" string="through" />
            <token id="8" string="this" />
            <token id="9" string="litigious" />
            <token id="10" string="atmosphere" />
            <token id="11" string="," />
            <token id="12" string="making" />
            <token id="13" string="much" />
            <token id="14" string="of" />
            <token id="15" string="it" />
            <token id="16" string="suspect" />
          </tokens>
        </chunking>
        <chunking id="10" string="much of it" type="NP">
          <tokens>
            <token id="13" string="much" />
            <token id="14" string="of" />
            <token id="15" string="it" />
          </tokens>
        </chunking>
        <chunking id="11" string="much" type="NP">
          <tokens>
            <token id="13" string="much" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="6">filtered</governor>
          <dependent id="1">Information</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">spill</governor>
          <dependent id="2">about</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">spill</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Information</governor>
          <dependent id="4">spill</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="6">filtered</governor>
          <dependent id="5">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">filtered</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">atmosphere</governor>
          <dependent id="7">through</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">atmosphere</governor>
          <dependent id="8">this</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">atmosphere</governor>
          <dependent id="9">litigious</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">filtered</governor>
          <dependent id="10">atmosphere</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">filtered</governor>
          <dependent id="12">making</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">suspect</governor>
          <dependent id="13">much</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">it</governor>
          <dependent id="14">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">much</governor>
          <dependent id="15">it</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="12">making</governor>
          <dependent id="16">suspect</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="40" has_coreference="true">
      <content>Exxon distributes before-and-after pictures of cleaned beaches; Bridgman and other state officials, accusing Exxon of ``myth-making,&amp;apost;&amp;apost; eagerly make room for journalists on flights to oiled beaches.</content>
      <tokens>
        <token id="1" string="Exxon" lemma="Exxon" stem="exxon" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="2" string="distributes" lemma="distribute" stem="distribut" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="before-and-after" lemma="before-and-after" stem="before-and-aft" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="pictures" lemma="picture" stem="pictur" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="cleaned" lemma="clean" stem="clean" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="beaches" lemma="beach" stem="beach" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Bridgman" lemma="Bridgman" stem="bridgman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="10" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="state" lemma="state" stem="state" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="officials" lemma="official" stem="offici" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="accusing" lemma="accuse" stem="accus" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="Exxon" lemma="Exxon" stem="exxon" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="17" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="myth-making" lemma="myth-making" stem="myth-mak" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="eagerly" lemma="eagerly" stem="eagerli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="make" lemma="make" stem="make" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="room" lemma="room" stem="room" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="journalists" lemma="journalist" stem="journalist" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="flights" lemma="flight" stem="flight" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="oiled" lemma="oiled" stem="oil" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="beaches" lemma="beach" stem="beach" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Exxon)) (VP (VBZ distributes) (NP (NP (NP (JJ before-and-after) (NNS pictures)) (PP (IN of) (NP (VBN cleaned) (NNS beaches)))) (: ;) (NP (NP (NNP Bridgman)) (CC and) (NP (JJ other) (NN state) (NNS officials)))) (, ,) (S (VP (VBG accusing) (NP (NP (NNP Exxon)) (PP (IN of) (`` ``) (ADJP (JJ myth-making)))))) (, ,) ('' '') (S (VP (ADVP (RB eagerly)) (VB make) (NP (NP (NN room)) (PP (IN for) (NP (NP (NNS journalists)) (PP (IN on) (NP (NP (NNS flights)) (PP (TO to) (NP (JJ oiled) (NNS beaches))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="myth-making" type="ADJP">
          <tokens>
            <token id="19" string="myth-making" />
          </tokens>
        </chunking>
        <chunking id="2" string="oiled beaches" type="NP">
          <tokens>
            <token id="30" string="oiled" />
            <token id="31" string="beaches" />
          </tokens>
        </chunking>
        <chunking id="3" string="Exxon" type="NP">
          <tokens>
            <token id="1" string="Exxon" />
          </tokens>
        </chunking>
        <chunking id="4" string="journalists on flights to oiled beaches" type="NP">
          <tokens>
            <token id="26" string="journalists" />
            <token id="27" string="on" />
            <token id="28" string="flights" />
            <token id="29" string="to" />
            <token id="30" string="oiled" />
            <token id="31" string="beaches" />
          </tokens>
        </chunking>
        <chunking id="5" string="Bridgman and other state officials" type="NP">
          <tokens>
            <token id="9" string="Bridgman" />
            <token id="10" string="and" />
            <token id="11" string="other" />
            <token id="12" string="state" />
            <token id="13" string="officials" />
          </tokens>
        </chunking>
        <chunking id="6" string="Exxon of `` myth-making" type="NP">
          <tokens>
            <token id="16" string="Exxon" />
            <token id="17" string="of" />
            <token id="18" string="``" />
            <token id="19" string="myth-making" />
          </tokens>
        </chunking>
        <chunking id="7" string="accusing Exxon of `` myth-making" type="VP">
          <tokens>
            <token id="15" string="accusing" />
            <token id="16" string="Exxon" />
            <token id="17" string="of" />
            <token id="18" string="``" />
            <token id="19" string="myth-making" />
          </tokens>
        </chunking>
        <chunking id="8" string="Bridgman" type="NP">
          <tokens>
            <token id="9" string="Bridgman" />
          </tokens>
        </chunking>
        <chunking id="9" string="room" type="NP">
          <tokens>
            <token id="24" string="room" />
          </tokens>
        </chunking>
        <chunking id="10" string="journalists" type="NP">
          <tokens>
            <token id="26" string="journalists" />
          </tokens>
        </chunking>
        <chunking id="11" string="distributes before-and-after pictures of cleaned beaches ; Bridgman and other state officials , accusing Exxon of `` myth-making , '' eagerly make room for journalists on flights to oiled beaches" type="VP">
          <tokens>
            <token id="2" string="distributes" />
            <token id="3" string="before-and-after" />
            <token id="4" string="pictures" />
            <token id="5" string="of" />
            <token id="6" string="cleaned" />
            <token id="7" string="beaches" />
            <token id="8" string=";" />
            <token id="9" string="Bridgman" />
            <token id="10" string="and" />
            <token id="11" string="other" />
            <token id="12" string="state" />
            <token id="13" string="officials" />
            <token id="14" string="," />
            <token id="15" string="accusing" />
            <token id="16" string="Exxon" />
            <token id="17" string="of" />
            <token id="18" string="``" />
            <token id="19" string="myth-making" />
            <token id="20" string="," />
            <token id="21" string="''" />
            <token id="22" string="eagerly" />
            <token id="23" string="make" />
            <token id="24" string="room" />
            <token id="25" string="for" />
            <token id="26" string="journalists" />
            <token id="27" string="on" />
            <token id="28" string="flights" />
            <token id="29" string="to" />
            <token id="30" string="oiled" />
            <token id="31" string="beaches" />
          </tokens>
        </chunking>
        <chunking id="12" string="before-and-after pictures of cleaned beaches" type="NP">
          <tokens>
            <token id="3" string="before-and-after" />
            <token id="4" string="pictures" />
            <token id="5" string="of" />
            <token id="6" string="cleaned" />
            <token id="7" string="beaches" />
          </tokens>
        </chunking>
        <chunking id="13" string="other state officials" type="NP">
          <tokens>
            <token id="11" string="other" />
            <token id="12" string="state" />
            <token id="13" string="officials" />
          </tokens>
        </chunking>
        <chunking id="14" string="before-and-after pictures" type="NP">
          <tokens>
            <token id="3" string="before-and-after" />
            <token id="4" string="pictures" />
          </tokens>
        </chunking>
        <chunking id="15" string="cleaned beaches" type="NP">
          <tokens>
            <token id="6" string="cleaned" />
            <token id="7" string="beaches" />
          </tokens>
        </chunking>
        <chunking id="16" string="eagerly make room for journalists on flights to oiled beaches" type="VP">
          <tokens>
            <token id="22" string="eagerly" />
            <token id="23" string="make" />
            <token id="24" string="room" />
            <token id="25" string="for" />
            <token id="26" string="journalists" />
            <token id="27" string="on" />
            <token id="28" string="flights" />
            <token id="29" string="to" />
            <token id="30" string="oiled" />
            <token id="31" string="beaches" />
          </tokens>
        </chunking>
        <chunking id="17" string="flights to oiled beaches" type="NP">
          <tokens>
            <token id="28" string="flights" />
            <token id="29" string="to" />
            <token id="30" string="oiled" />
            <token id="31" string="beaches" />
          </tokens>
        </chunking>
        <chunking id="18" string="before-and-after pictures of cleaned beaches ; Bridgman and other state officials" type="NP">
          <tokens>
            <token id="3" string="before-and-after" />
            <token id="4" string="pictures" />
            <token id="5" string="of" />
            <token id="6" string="cleaned" />
            <token id="7" string="beaches" />
            <token id="8" string=";" />
            <token id="9" string="Bridgman" />
            <token id="10" string="and" />
            <token id="11" string="other" />
            <token id="12" string="state" />
            <token id="13" string="officials" />
          </tokens>
        </chunking>
        <chunking id="19" string="flights" type="NP">
          <tokens>
            <token id="28" string="flights" />
          </tokens>
        </chunking>
        <chunking id="20" string="room for journalists on flights to oiled beaches" type="NP">
          <tokens>
            <token id="24" string="room" />
            <token id="25" string="for" />
            <token id="26" string="journalists" />
            <token id="27" string="on" />
            <token id="28" string="flights" />
            <token id="29" string="to" />
            <token id="30" string="oiled" />
            <token id="31" string="beaches" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">distributes</governor>
          <dependent id="1">Exxon</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">distributes</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">pictures</governor>
          <dependent id="3">before-and-after</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">distributes</governor>
          <dependent id="4">pictures</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">beaches</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">beaches</governor>
          <dependent id="6">cleaned</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">pictures</governor>
          <dependent id="7">beaches</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="4">pictures</governor>
          <dependent id="9">Bridgman</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">Bridgman</governor>
          <dependent id="10">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">officials</governor>
          <dependent id="11">other</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">officials</governor>
          <dependent id="12">state</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">Bridgman</governor>
          <dependent id="13">officials</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="2">distributes</governor>
          <dependent id="15">accusing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">accusing</governor>
          <dependent id="16">Exxon</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">myth-making</governor>
          <dependent id="17">of</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="16">Exxon</governor>
          <dependent id="19">myth-making</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="23">make</governor>
          <dependent id="22">eagerly</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="2">distributes</governor>
          <dependent id="23">make</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="23">make</governor>
          <dependent id="24">room</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">journalists</governor>
          <dependent id="25">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">room</governor>
          <dependent id="26">journalists</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">flights</governor>
          <dependent id="27">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">journalists</governor>
          <dependent id="28">flights</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">beaches</governor>
          <dependent id="29">to</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="31">beaches</governor>
          <dependent id="30">oiled</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">flights</governor>
          <dependent id="31">beaches</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Exxon" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="1" string="Exxon" />
          </tokens>
        </entity>
        <entity id="2" string="Bridgman" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="Bridgman" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="41" has_coreference="false">
      <content>State officials cite an October survey that showed 117 miles of shoreline remained moderately or heavily oiled, with oil more than two feet deep in some spots.</content>
      <tokens>
        <token id="1" string="State" lemma="state" stem="state" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="officials" lemma="official" stem="offici" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="cite" lemma="cite" stem="cite" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="October" lemma="October" stem="october" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="6" string="survey" lemma="survey" stem="survei" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="showed" lemma="show" stem="show" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="117" lemma="117" stem="117" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="10" string="miles" lemma="mile" stem="mile" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="shoreline" lemma="shoreline" stem="shorelin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="remained" lemma="remain" stem="remain" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="moderately" lemma="moderately" stem="moder" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="heavily" lemma="heavily" stem="heavili" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="oiled" lemma="oil" stem="oil" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="oil" lemma="oil" stem="oil" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="24" string="feet" lemma="foot" stem="feet" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="deep" lemma="deep" stem="deep" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="spots" lemma="spot" stem="spot" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NN State) (NNS officials)) (VP (VBP cite) (NP (NP (DT an) (NNP October) (NN survey)) (SBAR (WHNP (WDT that)) (S (VP (VBD showed) (SBAR (S (NP (NP (CD 117) (NNS miles)) (PP (IN of) (NP (NN shoreline)))) (VP (VBD remained) (VP (ADVP (RB moderately) (CC or) (RB heavily)) (VBN oiled) (, ,) (PP (IN with) (NP (NP (NN oil)) (ADJP (NP (QP (RBR more) (IN than) (CD two)) (NNS feet)) (JJ deep)) (PP (IN in) (NP (DT some) (NNS spots)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="117 miles" type="NP">
          <tokens>
            <token id="9" string="117" />
            <token id="10" string="miles" />
          </tokens>
        </chunking>
        <chunking id="2" string="117 miles of shoreline" type="NP">
          <tokens>
            <token id="9" string="117" />
            <token id="10" string="miles" />
            <token id="11" string="of" />
            <token id="12" string="shoreline" />
          </tokens>
        </chunking>
        <chunking id="3" string="an October survey" type="NP">
          <tokens>
            <token id="4" string="an" />
            <token id="5" string="October" />
            <token id="6" string="survey" />
          </tokens>
        </chunking>
        <chunking id="4" string="oil more than two feet deep in some spots" type="NP">
          <tokens>
            <token id="20" string="oil" />
            <token id="21" string="more" />
            <token id="22" string="than" />
            <token id="23" string="two" />
            <token id="24" string="feet" />
            <token id="25" string="deep" />
            <token id="26" string="in" />
            <token id="27" string="some" />
            <token id="28" string="spots" />
          </tokens>
        </chunking>
        <chunking id="5" string="some spots" type="NP">
          <tokens>
            <token id="27" string="some" />
            <token id="28" string="spots" />
          </tokens>
        </chunking>
        <chunking id="6" string="117 miles of shoreline remained moderately or heavily oiled , with oil more than two feet deep in some spots" type="SBAR">
          <tokens>
            <token id="9" string="117" />
            <token id="10" string="miles" />
            <token id="11" string="of" />
            <token id="12" string="shoreline" />
            <token id="13" string="remained" />
            <token id="14" string="moderately" />
            <token id="15" string="or" />
            <token id="16" string="heavily" />
            <token id="17" string="oiled" />
            <token id="18" string="," />
            <token id="19" string="with" />
            <token id="20" string="oil" />
            <token id="21" string="more" />
            <token id="22" string="than" />
            <token id="23" string="two" />
            <token id="24" string="feet" />
            <token id="25" string="deep" />
            <token id="26" string="in" />
            <token id="27" string="some" />
            <token id="28" string="spots" />
          </tokens>
        </chunking>
        <chunking id="7" string="more than two feet" type="NP">
          <tokens>
            <token id="21" string="more" />
            <token id="22" string="than" />
            <token id="23" string="two" />
            <token id="24" string="feet" />
          </tokens>
        </chunking>
        <chunking id="8" string="more than two feet deep" type="ADJP">
          <tokens>
            <token id="21" string="more" />
            <token id="22" string="than" />
            <token id="23" string="two" />
            <token id="24" string="feet" />
            <token id="25" string="deep" />
          </tokens>
        </chunking>
        <chunking id="9" string="remained moderately or heavily oiled , with oil more than two feet deep in some spots" type="VP">
          <tokens>
            <token id="13" string="remained" />
            <token id="14" string="moderately" />
            <token id="15" string="or" />
            <token id="16" string="heavily" />
            <token id="17" string="oiled" />
            <token id="18" string="," />
            <token id="19" string="with" />
            <token id="20" string="oil" />
            <token id="21" string="more" />
            <token id="22" string="than" />
            <token id="23" string="two" />
            <token id="24" string="feet" />
            <token id="25" string="deep" />
            <token id="26" string="in" />
            <token id="27" string="some" />
            <token id="28" string="spots" />
          </tokens>
        </chunking>
        <chunking id="10" string="moderately or heavily oiled , with oil more than two feet deep in some spots" type="VP">
          <tokens>
            <token id="14" string="moderately" />
            <token id="15" string="or" />
            <token id="16" string="heavily" />
            <token id="17" string="oiled" />
            <token id="18" string="," />
            <token id="19" string="with" />
            <token id="20" string="oil" />
            <token id="21" string="more" />
            <token id="22" string="than" />
            <token id="23" string="two" />
            <token id="24" string="feet" />
            <token id="25" string="deep" />
            <token id="26" string="in" />
            <token id="27" string="some" />
            <token id="28" string="spots" />
          </tokens>
        </chunking>
        <chunking id="11" string="oil" type="NP">
          <tokens>
            <token id="20" string="oil" />
          </tokens>
        </chunking>
        <chunking id="12" string="shoreline" type="NP">
          <tokens>
            <token id="12" string="shoreline" />
          </tokens>
        </chunking>
        <chunking id="13" string="State officials" type="NP">
          <tokens>
            <token id="1" string="State" />
            <token id="2" string="officials" />
          </tokens>
        </chunking>
        <chunking id="14" string="an October survey that showed 117 miles of shoreline remained moderately or heavily oiled , with oil more than two feet deep in some spots" type="NP">
          <tokens>
            <token id="4" string="an" />
            <token id="5" string="October" />
            <token id="6" string="survey" />
            <token id="7" string="that" />
            <token id="8" string="showed" />
            <token id="9" string="117" />
            <token id="10" string="miles" />
            <token id="11" string="of" />
            <token id="12" string="shoreline" />
            <token id="13" string="remained" />
            <token id="14" string="moderately" />
            <token id="15" string="or" />
            <token id="16" string="heavily" />
            <token id="17" string="oiled" />
            <token id="18" string="," />
            <token id="19" string="with" />
            <token id="20" string="oil" />
            <token id="21" string="more" />
            <token id="22" string="than" />
            <token id="23" string="two" />
            <token id="24" string="feet" />
            <token id="25" string="deep" />
            <token id="26" string="in" />
            <token id="27" string="some" />
            <token id="28" string="spots" />
          </tokens>
        </chunking>
        <chunking id="15" string="showed 117 miles of shoreline remained moderately or heavily oiled , with oil more than two feet deep in some spots" type="VP">
          <tokens>
            <token id="8" string="showed" />
            <token id="9" string="117" />
            <token id="10" string="miles" />
            <token id="11" string="of" />
            <token id="12" string="shoreline" />
            <token id="13" string="remained" />
            <token id="14" string="moderately" />
            <token id="15" string="or" />
            <token id="16" string="heavily" />
            <token id="17" string="oiled" />
            <token id="18" string="," />
            <token id="19" string="with" />
            <token id="20" string="oil" />
            <token id="21" string="more" />
            <token id="22" string="than" />
            <token id="23" string="two" />
            <token id="24" string="feet" />
            <token id="25" string="deep" />
            <token id="26" string="in" />
            <token id="27" string="some" />
            <token id="28" string="spots" />
          </tokens>
        </chunking>
        <chunking id="16" string="cite an October survey that showed 117 miles of shoreline remained moderately or heavily oiled , with oil more than two feet deep in some spots" type="VP">
          <tokens>
            <token id="3" string="cite" />
            <token id="4" string="an" />
            <token id="5" string="October" />
            <token id="6" string="survey" />
            <token id="7" string="that" />
            <token id="8" string="showed" />
            <token id="9" string="117" />
            <token id="10" string="miles" />
            <token id="11" string="of" />
            <token id="12" string="shoreline" />
            <token id="13" string="remained" />
            <token id="14" string="moderately" />
            <token id="15" string="or" />
            <token id="16" string="heavily" />
            <token id="17" string="oiled" />
            <token id="18" string="," />
            <token id="19" string="with" />
            <token id="20" string="oil" />
            <token id="21" string="more" />
            <token id="22" string="than" />
            <token id="23" string="two" />
            <token id="24" string="feet" />
            <token id="25" string="deep" />
            <token id="26" string="in" />
            <token id="27" string="some" />
            <token id="28" string="spots" />
          </tokens>
        </chunking>
        <chunking id="17" string="that showed 117 miles of shoreline remained moderately or heavily oiled , with oil more than two feet deep in some spots" type="SBAR">
          <tokens>
            <token id="7" string="that" />
            <token id="8" string="showed" />
            <token id="9" string="117" />
            <token id="10" string="miles" />
            <token id="11" string="of" />
            <token id="12" string="shoreline" />
            <token id="13" string="remained" />
            <token id="14" string="moderately" />
            <token id="15" string="or" />
            <token id="16" string="heavily" />
            <token id="17" string="oiled" />
            <token id="18" string="," />
            <token id="19" string="with" />
            <token id="20" string="oil" />
            <token id="21" string="more" />
            <token id="22" string="than" />
            <token id="23" string="two" />
            <token id="24" string="feet" />
            <token id="25" string="deep" />
            <token id="26" string="in" />
            <token id="27" string="some" />
            <token id="28" string="spots" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">officials</governor>
          <dependent id="1">State</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">cite</governor>
          <dependent id="2">officials</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">cite</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">survey</governor>
          <dependent id="4">an</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">survey</governor>
          <dependent id="5">October</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">cite</governor>
          <dependent id="6">survey</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">showed</governor>
          <dependent id="7">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="6">survey</governor>
          <dependent id="8">showed</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="10">miles</governor>
          <dependent id="9">117</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">remained</governor>
          <dependent id="10">miles</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">shoreline</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">miles</governor>
          <dependent id="12">shoreline</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="8">showed</governor>
          <dependent id="13">remained</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="17">oiled</governor>
          <dependent id="14">moderately</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="14">moderately</governor>
          <dependent id="15">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">moderately</governor>
          <dependent id="16">heavily</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="13">remained</governor>
          <dependent id="17">oiled</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">oil</governor>
          <dependent id="19">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">oiled</governor>
          <dependent id="20">oil</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="23">two</governor>
          <dependent id="21">more</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="21">more</governor>
          <dependent id="22">than</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="24">feet</governor>
          <dependent id="23">two</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="25">deep</governor>
          <dependent id="24">feet</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">oil</governor>
          <dependent id="25">deep</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">spots</governor>
          <dependent id="26">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">spots</governor>
          <dependent id="27">some</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">oil</governor>
          <dependent id="28">spots</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="117" type="NUMBER" score="0.0">
          <tokens>
            <token id="9" string="117" />
          </tokens>
        </entity>
        <entity id="2" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="23" string="two" />
          </tokens>
        </entity>
        <entity id="3" string="October" type="DATE" score="0.0">
          <tokens>
            <token id="5" string="October" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="42" has_coreference="true">
      <content>They say observers flying over the sound still report 15 to 20 oil sheens bleeding off beaches daily.</content>
      <tokens>
        <token id="1" string="They" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="say" lemma="say" stem="sai" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="observers" lemma="observer" stem="observ" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="flying" lemma="fly" stem="fly" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="over" lemma="over" stem="over" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="sound" lemma="sound" stem="sound" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="still" lemma="still" stem="still" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="report" lemma="report" stem="report" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="15" lemma="15" stem="15" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="11" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="20" lemma="20" stem="20" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="13" string="oil" lemma="oil" stem="oil" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="sheens" lemma="sheen" stem="sheen" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="bleeding" lemma="bleed" stem="bleed" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="off" lemma="off" stem="off" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="beaches" lemma="beach" stem="beach" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="18" string="daily" lemma="daily" stem="daili" pos="RB" type="Word" isStopWord="false" ner="SET" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP They)) (VP (VBP say) (SBAR (S (NP (NP (NNS observers)) (VP (VBG flying) (PP (IN over) (NP (DT the) (NN sound))))) (VP (ADVP (RB still)) (VBP report) (NP (QP (CD 15) (TO to) (CD 20)) (NN oil) (NNS sheens)) (S (VP (VBG bleeding) (PRT (RP off)) (NP (NNS beaches)) (ADVP (RB daily)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="They" type="NP">
          <tokens>
            <token id="1" string="They" />
          </tokens>
        </chunking>
        <chunking id="2" string="bleeding off beaches daily" type="VP">
          <tokens>
            <token id="15" string="bleeding" />
            <token id="16" string="off" />
            <token id="17" string="beaches" />
            <token id="18" string="daily" />
          </tokens>
        </chunking>
        <chunking id="3" string="beaches" type="NP">
          <tokens>
            <token id="17" string="beaches" />
          </tokens>
        </chunking>
        <chunking id="4" string="15 to 20 oil sheens" type="NP">
          <tokens>
            <token id="10" string="15" />
            <token id="11" string="to" />
            <token id="12" string="20" />
            <token id="13" string="oil" />
            <token id="14" string="sheens" />
          </tokens>
        </chunking>
        <chunking id="5" string="say observers flying over the sound still report 15 to 20 oil sheens bleeding off beaches daily" type="VP">
          <tokens>
            <token id="2" string="say" />
            <token id="3" string="observers" />
            <token id="4" string="flying" />
            <token id="5" string="over" />
            <token id="6" string="the" />
            <token id="7" string="sound" />
            <token id="8" string="still" />
            <token id="9" string="report" />
            <token id="10" string="15" />
            <token id="11" string="to" />
            <token id="12" string="20" />
            <token id="13" string="oil" />
            <token id="14" string="sheens" />
            <token id="15" string="bleeding" />
            <token id="16" string="off" />
            <token id="17" string="beaches" />
            <token id="18" string="daily" />
          </tokens>
        </chunking>
        <chunking id="6" string="flying over the sound" type="VP">
          <tokens>
            <token id="4" string="flying" />
            <token id="5" string="over" />
            <token id="6" string="the" />
            <token id="7" string="sound" />
          </tokens>
        </chunking>
        <chunking id="7" string="observers flying over the sound still report 15 to 20 oil sheens bleeding off beaches daily" type="SBAR">
          <tokens>
            <token id="3" string="observers" />
            <token id="4" string="flying" />
            <token id="5" string="over" />
            <token id="6" string="the" />
            <token id="7" string="sound" />
            <token id="8" string="still" />
            <token id="9" string="report" />
            <token id="10" string="15" />
            <token id="11" string="to" />
            <token id="12" string="20" />
            <token id="13" string="oil" />
            <token id="14" string="sheens" />
            <token id="15" string="bleeding" />
            <token id="16" string="off" />
            <token id="17" string="beaches" />
            <token id="18" string="daily" />
          </tokens>
        </chunking>
        <chunking id="8" string="still report 15 to 20 oil sheens bleeding off beaches daily" type="VP">
          <tokens>
            <token id="8" string="still" />
            <token id="9" string="report" />
            <token id="10" string="15" />
            <token id="11" string="to" />
            <token id="12" string="20" />
            <token id="13" string="oil" />
            <token id="14" string="sheens" />
            <token id="15" string="bleeding" />
            <token id="16" string="off" />
            <token id="17" string="beaches" />
            <token id="18" string="daily" />
          </tokens>
        </chunking>
        <chunking id="9" string="observers flying over the sound" type="NP">
          <tokens>
            <token id="3" string="observers" />
            <token id="4" string="flying" />
            <token id="5" string="over" />
            <token id="6" string="the" />
            <token id="7" string="sound" />
          </tokens>
        </chunking>
        <chunking id="10" string="the sound" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="sound" />
          </tokens>
        </chunking>
        <chunking id="11" string="observers" type="NP">
          <tokens>
            <token id="3" string="observers" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">say</governor>
          <dependent id="1">They</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">say</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">report</governor>
          <dependent id="3">observers</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="3">observers</governor>
          <dependent id="4">flying</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">sound</governor>
          <dependent id="5">over</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">sound</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">flying</governor>
          <dependent id="7">sound</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">report</governor>
          <dependent id="8">still</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">say</governor>
          <dependent id="9">report</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">20</governor>
          <dependent id="10">15</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="12">20</governor>
          <dependent id="11">to</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="14">sheens</governor>
          <dependent id="12">20</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">sheens</governor>
          <dependent id="13">oil</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">report</governor>
          <dependent id="14">sheens</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="9">report</governor>
          <dependent id="15">bleeding</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="15">bleeding</governor>
          <dependent id="16">off</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">bleeding</governor>
          <dependent id="17">beaches</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">bleeding</governor>
          <dependent id="18">daily</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="15" type="NUMBER" score="0.0">
          <tokens>
            <token id="10" string="15" />
          </tokens>
        </entity>
        <entity id="2" string="daily" type="SET" score="0.0">
          <tokens>
            <token id="18" string="daily" />
          </tokens>
        </entity>
        <entity id="3" string="20" type="NUMBER" score="0.0">
          <tokens>
            <token id="12" string="20" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="43" has_coreference="false">
      <content>Exxon officials, meanwhile, say their winter monitoring of 64 sites shows wind and waves have scoured away, on average, more than half the surface oil left in September, and up to 80 percent of the buried oil.</content>
      <tokens>
        <token id="1" string="Exxon" lemma="Exxon" stem="exxon" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="2" string="officials" lemma="official" stem="offici" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="meanwhile" lemma="meanwhile" stem="meanwhil" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="say" lemma="say" stem="sai" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="winter" lemma="winter" stem="winter" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="9" string="monitoring" lemma="monitoring" stem="monitor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="64" lemma="64" stem="64" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="12" string="sites" lemma="site" stem="site" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="shows" lemma="show" stem="show" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="wind" lemma="wind" stem="wind" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="waves" lemma="wave" stem="wave" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="scoured" lemma="scour" stem="scour" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="away" lemma="away" stem="awai" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="average" lemma="average" stem="averag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="more" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="half" lemma="half" stem="half" pos="PDT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="surface" lemma="surface" stem="surfac" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="oil" lemma="oil" stem="oil" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="left" lemma="leave" stem="left" pos="VBD" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="31" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="September" lemma="September" stem="septemb" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="33" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="up" lemma="up" stem="up" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="80" lemma="80" stem="80" pos="CD" type="Number" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="38" string="percent" lemma="percent" stem="percent" pos="NN" type="Word" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="39" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="buried" lemma="bury" stem="buri" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="oil" lemma="oil" stem="oil" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Exxon) (NNS officials)) (, ,) (ADVP (RB meanwhile)) (, ,) (VP (VBP say) (SBAR (S (NP (NP (PRP$ their) (NN winter) (NN monitoring)) (PP (IN of) (NP (CD 64) (NNS sites)))) (VP (VBZ shows) (SBAR (S (NP (NN wind) (CC and) (NNS waves)) (VP (VBP have) (VP (VBN scoured) (ADVP (RB away)) (, ,) (PP (PP (IN on) (NP (NP (NN average)) (, ,) (NP (NP (QP (JJR more) (IN than) (PDT half))) (SBAR (S (NP (DT the) (NN surface) (NN oil)) (VP (VBD left) (PP (IN in) (NP (NNP September))))))) (, ,))) (CC and) (PP (ADVP (RB up)) (TO to) (NP (NP (CD 80) (NN percent)) (PP (IN of) (NP (DT the) (VBN buried) (NN oil)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="their winter monitoring" type="NP">
          <tokens>
            <token id="7" string="their" />
            <token id="8" string="winter" />
            <token id="9" string="monitoring" />
          </tokens>
        </chunking>
        <chunking id="2" string="average" type="NP">
          <tokens>
            <token id="22" string="average" />
          </tokens>
        </chunking>
        <chunking id="3" string="the buried oil" type="NP">
          <tokens>
            <token id="40" string="the" />
            <token id="41" string="buried" />
            <token id="42" string="oil" />
          </tokens>
        </chunking>
        <chunking id="4" string="wind and waves have scoured away , on average , more than half the surface oil left in September , and up to 80 percent of the buried oil" type="SBAR">
          <tokens>
            <token id="14" string="wind" />
            <token id="15" string="and" />
            <token id="16" string="waves" />
            <token id="17" string="have" />
            <token id="18" string="scoured" />
            <token id="19" string="away" />
            <token id="20" string="," />
            <token id="21" string="on" />
            <token id="22" string="average" />
            <token id="23" string="," />
            <token id="24" string="more" />
            <token id="25" string="than" />
            <token id="26" string="half" />
            <token id="27" string="the" />
            <token id="28" string="surface" />
            <token id="29" string="oil" />
            <token id="30" string="left" />
            <token id="31" string="in" />
            <token id="32" string="September" />
            <token id="33" string="," />
            <token id="34" string="and" />
            <token id="35" string="up" />
            <token id="36" string="to" />
            <token id="37" string="80" />
            <token id="38" string="percent" />
            <token id="39" string="of" />
            <token id="40" string="the" />
            <token id="41" string="buried" />
            <token id="42" string="oil" />
          </tokens>
        </chunking>
        <chunking id="5" string="more than half" type="NP">
          <tokens>
            <token id="24" string="more" />
            <token id="25" string="than" />
            <token id="26" string="half" />
          </tokens>
        </chunking>
        <chunking id="6" string="Exxon officials" type="NP">
          <tokens>
            <token id="1" string="Exxon" />
            <token id="2" string="officials" />
          </tokens>
        </chunking>
        <chunking id="7" string="September" type="NP">
          <tokens>
            <token id="32" string="September" />
          </tokens>
        </chunking>
        <chunking id="8" string="left in September" type="VP">
          <tokens>
            <token id="30" string="left" />
            <token id="31" string="in" />
            <token id="32" string="September" />
          </tokens>
        </chunking>
        <chunking id="9" string="have scoured away , on average , more than half the surface oil left in September , and up to 80 percent of the buried oil" type="VP">
          <tokens>
            <token id="17" string="have" />
            <token id="18" string="scoured" />
            <token id="19" string="away" />
            <token id="20" string="," />
            <token id="21" string="on" />
            <token id="22" string="average" />
            <token id="23" string="," />
            <token id="24" string="more" />
            <token id="25" string="than" />
            <token id="26" string="half" />
            <token id="27" string="the" />
            <token id="28" string="surface" />
            <token id="29" string="oil" />
            <token id="30" string="left" />
            <token id="31" string="in" />
            <token id="32" string="September" />
            <token id="33" string="," />
            <token id="34" string="and" />
            <token id="35" string="up" />
            <token id="36" string="to" />
            <token id="37" string="80" />
            <token id="38" string="percent" />
            <token id="39" string="of" />
            <token id="40" string="the" />
            <token id="41" string="buried" />
            <token id="42" string="oil" />
          </tokens>
        </chunking>
        <chunking id="10" string="their winter monitoring of 64 sites shows wind and waves have scoured away , on average , more than half the surface oil left in September , and up to 80 percent of the buried oil" type="SBAR">
          <tokens>
            <token id="7" string="their" />
            <token id="8" string="winter" />
            <token id="9" string="monitoring" />
            <token id="10" string="of" />
            <token id="11" string="64" />
            <token id="12" string="sites" />
            <token id="13" string="shows" />
            <token id="14" string="wind" />
            <token id="15" string="and" />
            <token id="16" string="waves" />
            <token id="17" string="have" />
            <token id="18" string="scoured" />
            <token id="19" string="away" />
            <token id="20" string="," />
            <token id="21" string="on" />
            <token id="22" string="average" />
            <token id="23" string="," />
            <token id="24" string="more" />
            <token id="25" string="than" />
            <token id="26" string="half" />
            <token id="27" string="the" />
            <token id="28" string="surface" />
            <token id="29" string="oil" />
            <token id="30" string="left" />
            <token id="31" string="in" />
            <token id="32" string="September" />
            <token id="33" string="," />
            <token id="34" string="and" />
            <token id="35" string="up" />
            <token id="36" string="to" />
            <token id="37" string="80" />
            <token id="38" string="percent" />
            <token id="39" string="of" />
            <token id="40" string="the" />
            <token id="41" string="buried" />
            <token id="42" string="oil" />
          </tokens>
        </chunking>
        <chunking id="11" string="their winter monitoring of 64 sites" type="NP">
          <tokens>
            <token id="7" string="their" />
            <token id="8" string="winter" />
            <token id="9" string="monitoring" />
            <token id="10" string="of" />
            <token id="11" string="64" />
            <token id="12" string="sites" />
          </tokens>
        </chunking>
        <chunking id="12" string="64 sites" type="NP">
          <tokens>
            <token id="11" string="64" />
            <token id="12" string="sites" />
          </tokens>
        </chunking>
        <chunking id="13" string="80 percent" type="NP">
          <tokens>
            <token id="37" string="80" />
            <token id="38" string="percent" />
          </tokens>
        </chunking>
        <chunking id="14" string="the surface oil left in September" type="SBAR">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="surface" />
            <token id="29" string="oil" />
            <token id="30" string="left" />
            <token id="31" string="in" />
            <token id="32" string="September" />
          </tokens>
        </chunking>
        <chunking id="15" string="average , more than half the surface oil left in September ," type="NP">
          <tokens>
            <token id="22" string="average" />
            <token id="23" string="," />
            <token id="24" string="more" />
            <token id="25" string="than" />
            <token id="26" string="half" />
            <token id="27" string="the" />
            <token id="28" string="surface" />
            <token id="29" string="oil" />
            <token id="30" string="left" />
            <token id="31" string="in" />
            <token id="32" string="September" />
            <token id="33" string="," />
          </tokens>
        </chunking>
        <chunking id="16" string="say their winter monitoring of 64 sites shows wind and waves have scoured away , on average , more than half the surface oil left in September , and up to 80 percent of the buried oil" type="VP">
          <tokens>
            <token id="6" string="say" />
            <token id="7" string="their" />
            <token id="8" string="winter" />
            <token id="9" string="monitoring" />
            <token id="10" string="of" />
            <token id="11" string="64" />
            <token id="12" string="sites" />
            <token id="13" string="shows" />
            <token id="14" string="wind" />
            <token id="15" string="and" />
            <token id="16" string="waves" />
            <token id="17" string="have" />
            <token id="18" string="scoured" />
            <token id="19" string="away" />
            <token id="20" string="," />
            <token id="21" string="on" />
            <token id="22" string="average" />
            <token id="23" string="," />
            <token id="24" string="more" />
            <token id="25" string="than" />
            <token id="26" string="half" />
            <token id="27" string="the" />
            <token id="28" string="surface" />
            <token id="29" string="oil" />
            <token id="30" string="left" />
            <token id="31" string="in" />
            <token id="32" string="September" />
            <token id="33" string="," />
            <token id="34" string="and" />
            <token id="35" string="up" />
            <token id="36" string="to" />
            <token id="37" string="80" />
            <token id="38" string="percent" />
            <token id="39" string="of" />
            <token id="40" string="the" />
            <token id="41" string="buried" />
            <token id="42" string="oil" />
          </tokens>
        </chunking>
        <chunking id="17" string="the surface oil" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="surface" />
            <token id="29" string="oil" />
          </tokens>
        </chunking>
        <chunking id="18" string="wind and waves" type="NP">
          <tokens>
            <token id="14" string="wind" />
            <token id="15" string="and" />
            <token id="16" string="waves" />
          </tokens>
        </chunking>
        <chunking id="19" string="more than half the surface oil left in September" type="NP">
          <tokens>
            <token id="24" string="more" />
            <token id="25" string="than" />
            <token id="26" string="half" />
            <token id="27" string="the" />
            <token id="28" string="surface" />
            <token id="29" string="oil" />
            <token id="30" string="left" />
            <token id="31" string="in" />
            <token id="32" string="September" />
          </tokens>
        </chunking>
        <chunking id="20" string="80 percent of the buried oil" type="NP">
          <tokens>
            <token id="37" string="80" />
            <token id="38" string="percent" />
            <token id="39" string="of" />
            <token id="40" string="the" />
            <token id="41" string="buried" />
            <token id="42" string="oil" />
          </tokens>
        </chunking>
        <chunking id="21" string="shows wind and waves have scoured away , on average , more than half the surface oil left in September , and up to 80 percent of the buried oil" type="VP">
          <tokens>
            <token id="13" string="shows" />
            <token id="14" string="wind" />
            <token id="15" string="and" />
            <token id="16" string="waves" />
            <token id="17" string="have" />
            <token id="18" string="scoured" />
            <token id="19" string="away" />
            <token id="20" string="," />
            <token id="21" string="on" />
            <token id="22" string="average" />
            <token id="23" string="," />
            <token id="24" string="more" />
            <token id="25" string="than" />
            <token id="26" string="half" />
            <token id="27" string="the" />
            <token id="28" string="surface" />
            <token id="29" string="oil" />
            <token id="30" string="left" />
            <token id="31" string="in" />
            <token id="32" string="September" />
            <token id="33" string="," />
            <token id="34" string="and" />
            <token id="35" string="up" />
            <token id="36" string="to" />
            <token id="37" string="80" />
            <token id="38" string="percent" />
            <token id="39" string="of" />
            <token id="40" string="the" />
            <token id="41" string="buried" />
            <token id="42" string="oil" />
          </tokens>
        </chunking>
        <chunking id="22" string="scoured away , on average , more than half the surface oil left in September , and up to 80 percent of the buried oil" type="VP">
          <tokens>
            <token id="18" string="scoured" />
            <token id="19" string="away" />
            <token id="20" string="," />
            <token id="21" string="on" />
            <token id="22" string="average" />
            <token id="23" string="," />
            <token id="24" string="more" />
            <token id="25" string="than" />
            <token id="26" string="half" />
            <token id="27" string="the" />
            <token id="28" string="surface" />
            <token id="29" string="oil" />
            <token id="30" string="left" />
            <token id="31" string="in" />
            <token id="32" string="September" />
            <token id="33" string="," />
            <token id="34" string="and" />
            <token id="35" string="up" />
            <token id="36" string="to" />
            <token id="37" string="80" />
            <token id="38" string="percent" />
            <token id="39" string="of" />
            <token id="40" string="the" />
            <token id="41" string="buried" />
            <token id="42" string="oil" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">officials</governor>
          <dependent id="1">Exxon</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">say</governor>
          <dependent id="2">officials</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">say</governor>
          <dependent id="4">meanwhile</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">say</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="9">monitoring</governor>
          <dependent id="7">their</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">monitoring</governor>
          <dependent id="8">winter</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">shows</governor>
          <dependent id="9">monitoring</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">sites</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="12">sites</governor>
          <dependent id="11">64</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">monitoring</governor>
          <dependent id="12">sites</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">say</governor>
          <dependent id="13">shows</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">scoured</governor>
          <dependent id="14">wind</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="14">wind</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">wind</governor>
          <dependent id="16">waves</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="18">scoured</governor>
          <dependent id="17">have</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="13">shows</governor>
          <dependent id="18">scoured</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="18">scoured</governor>
          <dependent id="18">scoured</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">scoured</governor>
          <dependent id="19">away</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">average</governor>
          <dependent id="21">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">scoured</governor>
          <dependent id="22">average</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="26">half</governor>
          <dependent id="24">more</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="24">more</governor>
          <dependent id="25">than</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="22">average</governor>
          <dependent id="26">half</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">oil</governor>
          <dependent id="27">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="29">oil</governor>
          <dependent id="28">surface</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="30">left</governor>
          <dependent id="29">oil</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="26">half</governor>
          <dependent id="30">left</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">September</governor>
          <dependent id="31">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">left</governor>
          <dependent id="32">September</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="18">scoured</governor>
          <dependent id="34">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="38">percent</governor>
          <dependent id="35">up</dependent>
        </dependency>
        <dependency type="case">
          <governor id="38">percent</governor>
          <dependent id="36">to</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="38">percent</governor>
          <dependent id="37">80</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">scoured</governor>
          <dependent id="38">percent</dependent>
        </dependency>
        <dependency type="case">
          <governor id="42">oil</governor>
          <dependent id="39">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="42">oil</governor>
          <dependent id="40">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="42">oil</governor>
          <dependent id="41">buried</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="38">percent</governor>
          <dependent id="42">oil</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="left" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="30" string="left" />
          </tokens>
        </entity>
        <entity id="2" string="September" type="DATE" score="0.0">
          <tokens>
            <token id="32" string="September" />
          </tokens>
        </entity>
        <entity id="3" string="Exxon" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="1" string="Exxon" />
          </tokens>
        </entity>
        <entity id="4" string="winter" type="DATE" score="0.0">
          <tokens>
            <token id="8" string="winter" />
          </tokens>
        </entity>
        <entity id="5" string="64" type="NUMBER" score="0.0">
          <tokens>
            <token id="11" string="64" />
          </tokens>
        </entity>
        <entity id="6" string="80 percent" type="PERCENT" score="0.0">
          <tokens>
            <token id="37" string="80" />
            <token id="38" string="percent" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="44" has_coreference="false">
      <content>``From a layman&amp;apost;s point of view, what&amp;apost;s left out there is really insignificant,&amp;apost;&amp;apost; said Exxon scientist Andy Teal.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="From" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="layman" lemma="layman" stem="layman" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="point" lemma="point" stem="point" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="view" lemma="view" stem="view" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="left" lemma="leave" stem="left" pos="VBN" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="13" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="really" lemma="really" stem="realli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="insignificant" lemma="insignificant" stem="insignific" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="Exxon" lemma="Exxon" stem="exxon" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="22" string="scientist" lemma="scientist" stem="scientist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="Andy" lemma="Andy" stem="andy" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="24" string="Teal" lemma="Teal" stem="teal" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (PP (IN From) (NP (NP (NP (DT a) (NN layman) (POS 's)) (NN point)) (PP (IN of) (NP (NN view))) (, ,) (SBAR (WHNP (WP what)) (S (VP (VBZ 's) (VP (VBN left) (PRT (RP out)))))))) (NP (EX there)) (VP (VBZ is) (ADJP (RB really) (JJ insignificant)))) (, ,) ('' '') (VP (VBD said)) (NP (NNP Exxon) (NN scientist) (NNP Andy) (NNP Teal)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="'s left out" type="VP">
          <tokens>
            <token id="11" string="'s" />
            <token id="12" string="left" />
            <token id="13" string="out" />
          </tokens>
        </chunking>
        <chunking id="2" string="there" type="NP">
          <tokens>
            <token id="14" string="there" />
          </tokens>
        </chunking>
        <chunking id="3" string="left out" type="VP">
          <tokens>
            <token id="12" string="left" />
            <token id="13" string="out" />
          </tokens>
        </chunking>
        <chunking id="4" string="a layman 's point of view , what 's left out" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="layman" />
            <token id="5" string="'s" />
            <token id="6" string="point" />
            <token id="7" string="of" />
            <token id="8" string="view" />
            <token id="9" string="," />
            <token id="10" string="what" />
            <token id="11" string="'s" />
            <token id="12" string="left" />
            <token id="13" string="out" />
          </tokens>
        </chunking>
        <chunking id="5" string="view" type="NP">
          <tokens>
            <token id="8" string="view" />
          </tokens>
        </chunking>
        <chunking id="6" string="a layman 's" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="layman" />
            <token id="5" string="'s" />
          </tokens>
        </chunking>
        <chunking id="7" string="really insignificant" type="ADJP">
          <tokens>
            <token id="16" string="really" />
            <token id="17" string="insignificant" />
          </tokens>
        </chunking>
        <chunking id="8" string="Exxon scientist Andy Teal" type="NP">
          <tokens>
            <token id="21" string="Exxon" />
            <token id="22" string="scientist" />
            <token id="23" string="Andy" />
            <token id="24" string="Teal" />
          </tokens>
        </chunking>
        <chunking id="9" string="is really insignificant" type="VP">
          <tokens>
            <token id="15" string="is" />
            <token id="16" string="really" />
            <token id="17" string="insignificant" />
          </tokens>
        </chunking>
        <chunking id="10" string="a layman 's point" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="layman" />
            <token id="5" string="'s" />
            <token id="6" string="point" />
          </tokens>
        </chunking>
        <chunking id="11" string="what 's left out" type="SBAR">
          <tokens>
            <token id="10" string="what" />
            <token id="11" string="'s" />
            <token id="12" string="left" />
            <token id="13" string="out" />
          </tokens>
        </chunking>
        <chunking id="12" string="said" type="VP">
          <tokens>
            <token id="20" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="6">point</governor>
          <dependent id="2">From</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">layman</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="6">point</governor>
          <dependent id="4">layman</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">layman</governor>
          <dependent id="5">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">is</governor>
          <dependent id="6">point</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">view</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">point</governor>
          <dependent id="8">view</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="12">left</governor>
          <dependent id="10">what</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="12">left</governor>
          <dependent id="11">'s</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="6">point</governor>
          <dependent id="12">left</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="12">left</governor>
          <dependent id="13">out</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="15">is</governor>
          <dependent id="14">there</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="20">said</governor>
          <dependent id="15">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="17">insignificant</governor>
          <dependent id="16">really</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="15">is</governor>
          <dependent id="17">insignificant</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="20">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">Teal</governor>
          <dependent id="21">Exxon</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">Teal</governor>
          <dependent id="22">scientist</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">Teal</governor>
          <dependent id="23">Andy</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">said</governor>
          <dependent id="24">Teal</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="left" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="12" string="left" />
          </tokens>
        </entity>
        <entity id="2" string="Exxon" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="21" string="Exxon" />
          </tokens>
        </entity>
        <entity id="3" string="Andy Teal" type="PERSON" score="0.0">
          <tokens>
            <token id="23" string="Andy" />
            <token id="24" string="Teal" />
          </tokens>
        </entity>
      </entities>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="2" type="PROPER">
      <referenced ids_tokens="7-8-9-10-11-12-13-14-15" string="Joe Bridgman of the Alaska Department of Environmental Conservation" id_sentence="3" />
      <mentions>
        <mention ids_tokens="8" string="he" id_sentence="4" />
        <mention ids_tokens="18" string="he" id_sentence="4" />
        <mention ids_tokens="20" string="he" id_sentence="4" />
        <mention ids_tokens="5" string="he" id_sentence="5" />
        <mention ids_tokens="1" string="Bridgman" id_sentence="8" />
        <mention ids_tokens="15" string="he" id_sentence="10" />
        <mention ids_tokens="9" string="Bridgman" id_sentence="40" />
      </mentions>
    </coreference>
    <coreference id="3" type="NOMINAL">
      <referenced ids_tokens="11-12-13" string="the cobble beach" id_sentence="4" />
      <mentions>
        <mention ids_tokens="3" string="it" id_sentence="6" />
        <mention ids_tokens="11-12" string="this beach" id_sentence="10" />
      </mentions>
    </coreference>
    <coreference id="4" type="PROPER">
      <referenced ids_tokens="29-30-31" string="Prince William Sound" id_sentence="7" />
      <mentions>
        <mention ids_tokens="3-6" string="Prince William Sound's" id_sentence="26" />
      </mentions>
    </coreference>
    <coreference id="5" type="NOMINAL">
      <referenced ids_tokens="1-2-3-4-5" string="The pungent odor of petroleum" id_sentence="7" />
      <mentions>
        <mention ids_tokens="10" string="it" id_sentence="8" />
      </mentions>
    </coreference>
    <coreference id="6" type="PROPER">
      <referenced ids_tokens="7-8-9" string="the Exxon Valdez" id_sentence="15" />
      <mentions>
        <mention ids_tokens="38-39" string="Exxon Valdez" id_sentence="7" />
      </mentions>
    </coreference>
    <coreference id="8" type="NOMINAL">
      <referenced ids_tokens="12-13-14" string="the water 's" id_sentence="8" />
      <mentions>
        <mention ids_tokens="8-9" string="the water" id_sentence="9" />
        <mention ids_tokens="12-13" string="the water" id_sentence="23" />
      </mentions>
    </coreference>
    <coreference id="9" type="NOMINAL">
      <referenced ids_tokens="8-9-10-11-12-13" string="the sound that are still oiled" id_sentence="12" />
      <mentions>
        <mention ids_tokens="6-7" string="the sound" id_sentence="42" />
      </mentions>
    </coreference>
    <coreference id="14" type="PROPER">
      <referenced ids_tokens="19" string="_" id_sentence="33" />
      <mentions>
        <mention ids_tokens="8-13" string="the nation's most extensive _" id_sentence="17" />
      </mentions>
    </coreference>
    <coreference id="18" type="NOMINAL">
      <referenced ids_tokens="30-31-32" string="wildlife populations '" id_sentence="18" />
      <mentions>
        <mention ids_tokens="19" string="populations" id_sentence="28" />
        <mention ids_tokens="4-5" string="these populations" id_sentence="33" />
      </mentions>
    </coreference>
    <coreference id="19" type="NOMINAL">
      <referenced ids_tokens="5-6" string="12,000 workers" id_sentence="20" />
      <mentions>
        <mention ids_tokens="1" string="Workers" id_sentence="25" />
      </mentions>
    </coreference>
    <coreference id="20" type="NOMINAL">
      <referenced ids_tokens="13-14-15-16" string="beaches with hot water" id_sentence="20" />
      <mentions>
        <mention ids_tokens="21" string="beaches" id_sentence="23" />
        <mention ids_tokens="17" string="beaches" id_sentence="42" />
      </mentions>
    </coreference>
    <coreference id="21" type="PROPER">
      <referenced ids_tokens="3" string="Exxon" id_sentence="21" />
      <mentions>
        <mention ids_tokens="1" string="That" id_sentence="23" />
        <mention ids_tokens="2" string="that" id_sentence="29" />
        <mention ids_tokens="21-43" string="Exxon , which claimed state officials hindered the use of chemical dispersants that could have broken up large quantities of oil early on" id_sentence="38" />
      </mentions>
    </coreference>
    <coreference id="22" type="NOMINAL">
      <referenced ids_tokens="27-28" string="state officials" id_sentence="21" />
      <mentions>
        <mention ids_tokens="1" string="They" id_sentence="42" />
      </mentions>
    </coreference>
    <coreference id="26" type="PROPER">
      <referenced ids_tokens="5-6-7-8-9" string="the greatest human-caused wildlife disaster" id_sentence="31" />
      <mentions>
        <mention ids_tokens="5-7" string="the Valdez spill" id_sentence="27" />
        <mention ids_tokens="3-4" string="the spill" id_sentence="28" />
        <mention ids_tokens="6-7" string="the spill" id_sentence="30" />
        <mention ids_tokens="8-10" string="the spill's" id_sentence="32" />
        <mention ids_tokens="40-41" string="the spill" id_sentence="33" />
        <mention ids_tokens="13-14" string="the spill" id_sentence="38" />
        <mention ids_tokens="3-4" string="the spill" id_sentence="39" />
      </mentions>
    </coreference>
    <coreference id="27" type="PROPER">
      <referenced ids_tokens="7-8-9-10-11-12-13-14-15-16" string="70 years for some hard-hit seabird colonies , U.S. Fish" id_sentence="29" />
      <mentions>
        <mention ids_tokens="48" string="years" id_sentence="34" />
      </mentions>
    </coreference>
    <coreference id="28" type="NOMINAL">
      <referenced ids_tokens="18-19-20" string="Wildlife Service researchers" id_sentence="29" />
      <mentions>
        <mention ids_tokens="2" string="We" id_sentence="30" />
      </mentions>
    </coreference>
  </coreferences>
</document>
