<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="LA041889-0039">
  <sentences>
    <sentence id="1" has_coreference="false">
      <content>Out of the horn of Africa has emerged the most devastating and dominant group of marathon runners the world has seen.</content>
      <tokens>
        <token id="1" string="Out" lemma="out" stem="out" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="horn" lemma="horn" stem="horn" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Africa" lemma="Africa" stem="africa" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="7" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="emerged" lemma="emerge" stem="emerg" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="most" lemma="most" stem="most" pos="RBS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="devastating" lemma="devastating" stem="devast" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="dominant" lemma="dominant" stem="domin" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="group" lemma="group" stem="group" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="marathon" lemma="marathon" stem="marathon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="runners" lemma="runner" stem="runner" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="seen" lemma="see" stem="seen" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (IN Out)) (PP (IN of) (NP (NP (DT the) (NN horn)) (PP (IN of) (NP (NNP Africa)))))) (VP (VBZ has) (VP (VBN emerged) (NP (NP (DT the) (ADJP (RBS most) (JJ devastating) (CC and) (JJ dominant)) (NN group)) (PP (IN of) (NP (NN marathon) (NNS runners))))))) (NP (DT the) (NN world)) (VP (VBZ has) (VP (VBN seen))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the horn of Africa" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="horn" />
            <token id="5" string="of" />
            <token id="6" string="Africa" />
          </tokens>
        </chunking>
        <chunking id="2" string="Africa" type="NP">
          <tokens>
            <token id="6" string="Africa" />
          </tokens>
        </chunking>
        <chunking id="3" string="emerged the most devastating and dominant group of marathon runners" type="VP">
          <tokens>
            <token id="8" string="emerged" />
            <token id="9" string="the" />
            <token id="10" string="most" />
            <token id="11" string="devastating" />
            <token id="12" string="and" />
            <token id="13" string="dominant" />
            <token id="14" string="group" />
            <token id="15" string="of" />
            <token id="16" string="marathon" />
            <token id="17" string="runners" />
          </tokens>
        </chunking>
        <chunking id="4" string="Out of the horn of Africa" type="NP">
          <tokens>
            <token id="1" string="Out" />
            <token id="2" string="of" />
            <token id="3" string="the" />
            <token id="4" string="horn" />
            <token id="5" string="of" />
            <token id="6" string="Africa" />
          </tokens>
        </chunking>
        <chunking id="5" string="has emerged the most devastating and dominant group of marathon runners" type="VP">
          <tokens>
            <token id="7" string="has" />
            <token id="8" string="emerged" />
            <token id="9" string="the" />
            <token id="10" string="most" />
            <token id="11" string="devastating" />
            <token id="12" string="and" />
            <token id="13" string="dominant" />
            <token id="14" string="group" />
            <token id="15" string="of" />
            <token id="16" string="marathon" />
            <token id="17" string="runners" />
          </tokens>
        </chunking>
        <chunking id="6" string="Out" type="NP">
          <tokens>
            <token id="1" string="Out" />
          </tokens>
        </chunking>
        <chunking id="7" string="the horn" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="horn" />
          </tokens>
        </chunking>
        <chunking id="8" string="the world" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="world" />
          </tokens>
        </chunking>
        <chunking id="9" string="has seen" type="VP">
          <tokens>
            <token id="20" string="has" />
            <token id="21" string="seen" />
          </tokens>
        </chunking>
        <chunking id="10" string="seen" type="VP">
          <tokens>
            <token id="21" string="seen" />
          </tokens>
        </chunking>
        <chunking id="11" string="the most devastating and dominant group" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="most" />
            <token id="11" string="devastating" />
            <token id="12" string="and" />
            <token id="13" string="dominant" />
            <token id="14" string="group" />
          </tokens>
        </chunking>
        <chunking id="12" string="most devastating and dominant" type="ADJP">
          <tokens>
            <token id="10" string="most" />
            <token id="11" string="devastating" />
            <token id="12" string="and" />
            <token id="13" string="dominant" />
          </tokens>
        </chunking>
        <chunking id="13" string="the most devastating and dominant group of marathon runners" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="most" />
            <token id="11" string="devastating" />
            <token id="12" string="and" />
            <token id="13" string="dominant" />
            <token id="14" string="group" />
            <token id="15" string="of" />
            <token id="16" string="marathon" />
            <token id="17" string="runners" />
          </tokens>
        </chunking>
        <chunking id="14" string="marathon runners" type="NP">
          <tokens>
            <token id="16" string="marathon" />
            <token id="17" string="runners" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">horn</governor>
          <dependent id="1">Out</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="1">Out</governor>
          <dependent id="2">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">horn</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">emerged</governor>
          <dependent id="4">horn</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">Africa</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">horn</governor>
          <dependent id="6">Africa</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">emerged</governor>
          <dependent id="7">has</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="21">seen</governor>
          <dependent id="8">emerged</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">group</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">devastating</governor>
          <dependent id="10">most</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">group</governor>
          <dependent id="11">devastating</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="11">devastating</governor>
          <dependent id="12">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">devastating</governor>
          <dependent id="13">dominant</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">emerged</governor>
          <dependent id="14">group</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">runners</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">runners</governor>
          <dependent id="16">marathon</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">group</governor>
          <dependent id="17">runners</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">world</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">seen</governor>
          <dependent id="19">world</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="21">seen</governor>
          <dependent id="20">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="21">seen</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Africa" type="LOCATION" score="0.0">
          <tokens>
            <token id="6" string="Africa" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>Or at least since the last time Ethiopia ventured from its athletic isolation and won three consecutive Olympic gold medals, putting its indelible stamp on the marathon.</content>
      <tokens>
        <token id="1" string="Or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="least" lemma="least" stem="least" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="since" lemma="since" stem="sinc" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="Ethiopia" lemma="Ethiopia" stem="ethiopia" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="9" string="ventured" lemma="venture" stem="ventur" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="athletic" lemma="athletic" stem="athlet" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="isolation" lemma="isolation" stem="isol" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="won" lemma="win" stem="won" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="three" lemma="three" stem="three" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="17" string="consecutive" lemma="consecutive" stem="consecut" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="Olympic" lemma="Olympic" stem="olympic" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="true" />
        <token id="19" string="gold" lemma="gold" stem="gold" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="medals" lemma="medal" stem="medal" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="putting" lemma="put" stem="put" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="indelible" lemma="indelible" stem="indel" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="stamp" lemma="stamp" stem="stamp" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="28" string="marathon" lemma="marathon" stem="marathon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC Or) (PP (ADVP (IN at) (JJS least)) (IN since) (NP (DT the) (JJ last) (NN time))) (NP (NNP Ethiopia)) (VP (VP (VBD ventured) (PP (IN from) (NP (PRP$ its) (JJ athletic) (NN isolation)))) (CC and) (VP (VBD won) (NP (CD three) (JJ consecutive) (NNP Olympic) (NN gold) (NNS medals))) (, ,) (S (VP (VBG putting) (NP (PRP$ its) (JJ indelible) (NN stamp)) (PP (IN on) (NP (DT the) (NN marathon)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="ventured from its athletic isolation" type="VP">
          <tokens>
            <token id="9" string="ventured" />
            <token id="10" string="from" />
            <token id="11" string="its" />
            <token id="12" string="athletic" />
            <token id="13" string="isolation" />
          </tokens>
        </chunking>
        <chunking id="2" string="ventured from its athletic isolation and won three consecutive Olympic gold medals , putting its indelible stamp on the marathon" type="VP">
          <tokens>
            <token id="9" string="ventured" />
            <token id="10" string="from" />
            <token id="11" string="its" />
            <token id="12" string="athletic" />
            <token id="13" string="isolation" />
            <token id="14" string="and" />
            <token id="15" string="won" />
            <token id="16" string="three" />
            <token id="17" string="consecutive" />
            <token id="18" string="Olympic" />
            <token id="19" string="gold" />
            <token id="20" string="medals" />
            <token id="21" string="," />
            <token id="22" string="putting" />
            <token id="23" string="its" />
            <token id="24" string="indelible" />
            <token id="25" string="stamp" />
            <token id="26" string="on" />
            <token id="27" string="the" />
            <token id="28" string="marathon" />
          </tokens>
        </chunking>
        <chunking id="3" string="the marathon" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="marathon" />
          </tokens>
        </chunking>
        <chunking id="4" string="three consecutive Olympic gold medals" type="NP">
          <tokens>
            <token id="16" string="three" />
            <token id="17" string="consecutive" />
            <token id="18" string="Olympic" />
            <token id="19" string="gold" />
            <token id="20" string="medals" />
          </tokens>
        </chunking>
        <chunking id="5" string="won three consecutive Olympic gold medals" type="VP">
          <tokens>
            <token id="15" string="won" />
            <token id="16" string="three" />
            <token id="17" string="consecutive" />
            <token id="18" string="Olympic" />
            <token id="19" string="gold" />
            <token id="20" string="medals" />
          </tokens>
        </chunking>
        <chunking id="6" string="the last time" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="last" />
            <token id="7" string="time" />
          </tokens>
        </chunking>
        <chunking id="7" string="putting its indelible stamp on the marathon" type="VP">
          <tokens>
            <token id="22" string="putting" />
            <token id="23" string="its" />
            <token id="24" string="indelible" />
            <token id="25" string="stamp" />
            <token id="26" string="on" />
            <token id="27" string="the" />
            <token id="28" string="marathon" />
          </tokens>
        </chunking>
        <chunking id="8" string="its indelible stamp" type="NP">
          <tokens>
            <token id="23" string="its" />
            <token id="24" string="indelible" />
            <token id="25" string="stamp" />
          </tokens>
        </chunking>
        <chunking id="9" string="its athletic isolation" type="NP">
          <tokens>
            <token id="11" string="its" />
            <token id="12" string="athletic" />
            <token id="13" string="isolation" />
          </tokens>
        </chunking>
        <chunking id="10" string="Ethiopia" type="NP">
          <tokens>
            <token id="8" string="Ethiopia" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="9">ventured</governor>
          <dependent id="1">Or</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">time</governor>
          <dependent id="2">at</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="2">at</governor>
          <dependent id="3">least</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">time</governor>
          <dependent id="4">since</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">time</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">time</governor>
          <dependent id="6">last</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">ventured</governor>
          <dependent id="7">time</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">ventured</governor>
          <dependent id="8">Ethiopia</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">ventured</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">isolation</governor>
          <dependent id="10">from</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="13">isolation</governor>
          <dependent id="11">its</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">isolation</governor>
          <dependent id="12">athletic</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">ventured</governor>
          <dependent id="13">isolation</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">ventured</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">ventured</governor>
          <dependent id="15">won</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="20">medals</governor>
          <dependent id="16">three</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">medals</governor>
          <dependent id="17">consecutive</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">medals</governor>
          <dependent id="18">Olympic</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">medals</governor>
          <dependent id="19">gold</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">won</governor>
          <dependent id="20">medals</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="9">ventured</governor>
          <dependent id="22">putting</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="25">stamp</governor>
          <dependent id="23">its</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">stamp</governor>
          <dependent id="24">indelible</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">putting</governor>
          <dependent id="25">stamp</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">marathon</governor>
          <dependent id="26">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">marathon</governor>
          <dependent id="27">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">putting</governor>
          <dependent id="28">marathon</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Olympic" type="MISC" score="0.0">
          <tokens>
            <token id="18" string="Olympic" />
          </tokens>
        </entity>
        <entity id="2" string="three" type="NUMBER" score="0.0">
          <tokens>
            <token id="16" string="three" />
          </tokens>
        </entity>
        <entity id="3" string="Ethiopia" type="LOCATION" score="0.0">
          <tokens>
            <token id="8" string="Ethiopia" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>It appears to be happening again, a generation after Abebe Bikila ran barefoot through the darkened streets of Rome in 1960 to win the first of his two Olympic golds.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="appears" lemma="appear" stem="appear" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="happening" lemma="happen" stem="happen" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="again" lemma="again" stem="again" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="generation" lemma="generation" stem="gener" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Abebe" lemma="Abebe" stem="abebe" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="12" string="Bikila" lemma="Bikila" stem="bikila" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="13" string="ran" lemma="run" stem="ran" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="barefoot" lemma="barefoot" stem="barefoot" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="darkened" lemma="darkened" stem="darken" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="streets" lemma="street" stem="street" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="Rome" lemma="Rome" stem="rome" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="21" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="1960" lemma="1960" stem="1960" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="23" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="win" lemma="win" stem="win" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="26" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="true" is_refers="false" />
        <token id="27" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="28" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="29" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="30" string="Olympic" lemma="Olympic" stem="olympic" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="true" />
        <token id="31" string="golds" lemma="gold" stem="gold" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP It)) (VP (VBZ appears) (S (VP (TO to) (VP (VB be) (VP (VBG happening) (ADVP (RB again)))))))) (, ,) (NP (NP (DT a) (NN generation)) (PP (IN after) (NP (NNP Abebe) (NNP Bikila)))) (VP (VBD ran) (NP (NN barefoot)) (PP (IN through) (NP (NP (DT the) (JJ darkened) (NNS streets)) (PP (IN of) (NP (NP (NNP Rome)) (PP (IN in) (NP (CD 1960))))))) (S (VP (TO to) (VP (VB win) (NP (NP (DT the) (JJ first)) (PP (IN of) (NP (PRP$ his) (CD two) (NNP Olympic) (NNS golds)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="appears to be happening again" type="VP">
          <tokens>
            <token id="2" string="appears" />
            <token id="3" string="to" />
            <token id="4" string="be" />
            <token id="5" string="happening" />
            <token id="6" string="again" />
          </tokens>
        </chunking>
        <chunking id="2" string="win the first of his two Olympic golds" type="VP">
          <tokens>
            <token id="24" string="win" />
            <token id="25" string="the" />
            <token id="26" string="first" />
            <token id="27" string="of" />
            <token id="28" string="his" />
            <token id="29" string="two" />
            <token id="30" string="Olympic" />
            <token id="31" string="golds" />
          </tokens>
        </chunking>
        <chunking id="3" string="a generation after Abebe Bikila" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="generation" />
            <token id="10" string="after" />
            <token id="11" string="Abebe" />
            <token id="12" string="Bikila" />
          </tokens>
        </chunking>
        <chunking id="4" string="the darkened streets of Rome in 1960" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="darkened" />
            <token id="18" string="streets" />
            <token id="19" string="of" />
            <token id="20" string="Rome" />
            <token id="21" string="in" />
            <token id="22" string="1960" />
          </tokens>
        </chunking>
        <chunking id="5" string="ran barefoot through the darkened streets of Rome in 1960 to win the first of his two Olympic golds" type="VP">
          <tokens>
            <token id="13" string="ran" />
            <token id="14" string="barefoot" />
            <token id="15" string="through" />
            <token id="16" string="the" />
            <token id="17" string="darkened" />
            <token id="18" string="streets" />
            <token id="19" string="of" />
            <token id="20" string="Rome" />
            <token id="21" string="in" />
            <token id="22" string="1960" />
            <token id="23" string="to" />
            <token id="24" string="win" />
            <token id="25" string="the" />
            <token id="26" string="first" />
            <token id="27" string="of" />
            <token id="28" string="his" />
            <token id="29" string="two" />
            <token id="30" string="Olympic" />
            <token id="31" string="golds" />
          </tokens>
        </chunking>
        <chunking id="6" string="to win the first of his two Olympic golds" type="VP">
          <tokens>
            <token id="23" string="to" />
            <token id="24" string="win" />
            <token id="25" string="the" />
            <token id="26" string="first" />
            <token id="27" string="of" />
            <token id="28" string="his" />
            <token id="29" string="two" />
            <token id="30" string="Olympic" />
            <token id="31" string="golds" />
          </tokens>
        </chunking>
        <chunking id="7" string="happening again" type="VP">
          <tokens>
            <token id="5" string="happening" />
            <token id="6" string="again" />
          </tokens>
        </chunking>
        <chunking id="8" string="a generation" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="generation" />
          </tokens>
        </chunking>
        <chunking id="9" string="barefoot" type="NP">
          <tokens>
            <token id="14" string="barefoot" />
          </tokens>
        </chunking>
        <chunking id="10" string="Rome in 1960" type="NP">
          <tokens>
            <token id="20" string="Rome" />
            <token id="21" string="in" />
            <token id="22" string="1960" />
          </tokens>
        </chunking>
        <chunking id="11" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="12" string="be happening again" type="VP">
          <tokens>
            <token id="4" string="be" />
            <token id="5" string="happening" />
            <token id="6" string="again" />
          </tokens>
        </chunking>
        <chunking id="13" string="Rome" type="NP">
          <tokens>
            <token id="20" string="Rome" />
          </tokens>
        </chunking>
        <chunking id="14" string="his two Olympic golds" type="NP">
          <tokens>
            <token id="28" string="his" />
            <token id="29" string="two" />
            <token id="30" string="Olympic" />
            <token id="31" string="golds" />
          </tokens>
        </chunking>
        <chunking id="15" string="1960" type="NP">
          <tokens>
            <token id="22" string="1960" />
          </tokens>
        </chunking>
        <chunking id="16" string="Abebe Bikila" type="NP">
          <tokens>
            <token id="11" string="Abebe" />
            <token id="12" string="Bikila" />
          </tokens>
        </chunking>
        <chunking id="17" string="the darkened streets" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="darkened" />
            <token id="18" string="streets" />
          </tokens>
        </chunking>
        <chunking id="18" string="the first" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="first" />
          </tokens>
        </chunking>
        <chunking id="19" string="the first of his two Olympic golds" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="first" />
            <token id="27" string="of" />
            <token id="28" string="his" />
            <token id="29" string="two" />
            <token id="30" string="Olympic" />
            <token id="31" string="golds" />
          </tokens>
        </chunking>
        <chunking id="20" string="to be happening again" type="VP">
          <tokens>
            <token id="3" string="to" />
            <token id="4" string="be" />
            <token id="5" string="happening" />
            <token id="6" string="again" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">appears</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="13">ran</governor>
          <dependent id="2">appears</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">happening</governor>
          <dependent id="3">to</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">happening</governor>
          <dependent id="4">be</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="2">appears</governor>
          <dependent id="5">happening</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">happening</governor>
          <dependent id="6">again</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">generation</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">ran</governor>
          <dependent id="9">generation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">Bikila</governor>
          <dependent id="10">after</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Bikila</governor>
          <dependent id="11">Abebe</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">generation</governor>
          <dependent id="12">Bikila</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">ran</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">ran</governor>
          <dependent id="14">barefoot</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">streets</governor>
          <dependent id="15">through</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">streets</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">streets</governor>
          <dependent id="17">darkened</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">ran</governor>
          <dependent id="18">streets</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">Rome</governor>
          <dependent id="19">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">streets</governor>
          <dependent id="20">Rome</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">1960</governor>
          <dependent id="21">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">Rome</governor>
          <dependent id="22">1960</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="24">win</governor>
          <dependent id="23">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="13">ran</governor>
          <dependent id="24">win</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">first</governor>
          <dependent id="25">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="24">win</governor>
          <dependent id="26">first</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">golds</governor>
          <dependent id="27">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="31">golds</governor>
          <dependent id="28">his</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="31">golds</governor>
          <dependent id="29">two</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">golds</governor>
          <dependent id="30">Olympic</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">first</governor>
          <dependent id="31">golds</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="26" string="first" />
          </tokens>
        </entity>
        <entity id="2" string="Rome" type="LOCATION" score="0.0">
          <tokens>
            <token id="20" string="Rome" />
          </tokens>
        </entity>
        <entity id="3" string="1960" type="DATE" score="0.0">
          <tokens>
            <token id="22" string="1960" />
          </tokens>
        </entity>
        <entity id="4" string="Abebe Bikila" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Abebe" />
            <token id="12" string="Bikila" />
          </tokens>
        </entity>
        <entity id="5" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="29" string="two" />
          </tokens>
        </entity>
        <entity id="6" string="Olympic" type="MISC" score="0.0">
          <tokens>
            <token id="30" string="Olympic" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>Now it is Abebe Mekonnen, who was born the year Bikila won the 1964 Olympic Marathon in Tokyo and a nation named its baby boys after its hero.</content>
      <tokens>
        <token id="1" string="Now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="2" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Abebe" lemma="Abebe" stem="abebe" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="5" string="Mekonnen" lemma="Mekonnen" stem="mekonnen" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="born" lemma="bear" stem="born" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="11" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="12" string="Bikila" lemma="Bikila" stem="bikila" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="13" string="won" lemma="win" stem="won" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="1964" lemma="1964" stem="1964" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="16" string="Olympic" lemma="Olympic" stem="olympic" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="17" string="Marathon" lemma="Marathon" stem="marathon" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="18" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="Tokyo" lemma="Tokyo" stem="tokyo" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="20" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="nation" lemma="nation" stem="nation" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="named" lemma="name" stem="name" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="baby" lemma="baby" stem="babi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="boys" lemma="boy" stem="boi" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="hero" lemma="hero" stem="hero" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (ADVP (RB Now)) (NP (PRP it)) (VP (VBZ is) (NP (NP (NNP Abebe) (NNP Mekonnen)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBD was) (VP (VBN born) (NP-TMP (DT the) (NN year))))))))) (PRN (NP (NNP Bikila)) (VP (VBD won) (NP (DT the) (CD 1964) (NNP Olympic) (NNP Marathon)) (PP (IN in) (NP (NNP Tokyo))))) (CC and) (S (NP (DT a) (NN nation)) (VP (VBD named) (NP (PRP$ its) (NN baby) (NNS boys)) (PP (IN after) (NP (PRP$ its) (NN hero))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="is Abebe Mekonnen , who was born the year" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="Abebe" />
            <token id="5" string="Mekonnen" />
            <token id="6" string="," />
            <token id="7" string="who" />
            <token id="8" string="was" />
            <token id="9" string="born" />
            <token id="10" string="the" />
            <token id="11" string="year" />
          </tokens>
        </chunking>
        <chunking id="2" string="Bikila" type="NP">
          <tokens>
            <token id="12" string="Bikila" />
          </tokens>
        </chunking>
        <chunking id="3" string="its baby boys" type="NP">
          <tokens>
            <token id="24" string="its" />
            <token id="25" string="baby" />
            <token id="26" string="boys" />
          </tokens>
        </chunking>
        <chunking id="4" string="the 1964 Olympic Marathon" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="1964" />
            <token id="16" string="Olympic" />
            <token id="17" string="Marathon" />
          </tokens>
        </chunking>
        <chunking id="5" string="Abebe Mekonnen" type="NP">
          <tokens>
            <token id="4" string="Abebe" />
            <token id="5" string="Mekonnen" />
          </tokens>
        </chunking>
        <chunking id="6" string="was born the year" type="VP">
          <tokens>
            <token id="8" string="was" />
            <token id="9" string="born" />
            <token id="10" string="the" />
            <token id="11" string="year" />
          </tokens>
        </chunking>
        <chunking id="7" string="named its baby boys after its hero" type="VP">
          <tokens>
            <token id="23" string="named" />
            <token id="24" string="its" />
            <token id="25" string="baby" />
            <token id="26" string="boys" />
            <token id="27" string="after" />
            <token id="28" string="its" />
            <token id="29" string="hero" />
          </tokens>
        </chunking>
        <chunking id="8" string="won the 1964 Olympic Marathon in Tokyo" type="VP">
          <tokens>
            <token id="13" string="won" />
            <token id="14" string="the" />
            <token id="15" string="1964" />
            <token id="16" string="Olympic" />
            <token id="17" string="Marathon" />
            <token id="18" string="in" />
            <token id="19" string="Tokyo" />
          </tokens>
        </chunking>
        <chunking id="9" string="it" type="NP">
          <tokens>
            <token id="2" string="it" />
          </tokens>
        </chunking>
        <chunking id="10" string="who was born the year" type="SBAR">
          <tokens>
            <token id="7" string="who" />
            <token id="8" string="was" />
            <token id="9" string="born" />
            <token id="10" string="the" />
            <token id="11" string="year" />
          </tokens>
        </chunking>
        <chunking id="11" string="born the year" type="VP">
          <tokens>
            <token id="9" string="born" />
            <token id="10" string="the" />
            <token id="11" string="year" />
          </tokens>
        </chunking>
        <chunking id="12" string="its hero" type="NP">
          <tokens>
            <token id="28" string="its" />
            <token id="29" string="hero" />
          </tokens>
        </chunking>
        <chunking id="13" string="Abebe Mekonnen , who was born the year" type="NP">
          <tokens>
            <token id="4" string="Abebe" />
            <token id="5" string="Mekonnen" />
            <token id="6" string="," />
            <token id="7" string="who" />
            <token id="8" string="was" />
            <token id="9" string="born" />
            <token id="10" string="the" />
            <token id="11" string="year" />
          </tokens>
        </chunking>
        <chunking id="14" string="Tokyo" type="NP">
          <tokens>
            <token id="19" string="Tokyo" />
          </tokens>
        </chunking>
        <chunking id="15" string="a nation" type="NP">
          <tokens>
            <token id="21" string="a" />
            <token id="22" string="nation" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="5">Mekonnen</governor>
          <dependent id="1">Now</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">Mekonnen</governor>
          <dependent id="2">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">Mekonnen</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Mekonnen</governor>
          <dependent id="4">Abebe</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">Mekonnen</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="9">born</governor>
          <dependent id="7">who</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="9">born</governor>
          <dependent id="8">was</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="5">Mekonnen</governor>
          <dependent id="9">born</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">year</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="9">born</governor>
          <dependent id="11">year</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">won</governor>
          <dependent id="12">Bikila</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="5">Mekonnen</governor>
          <dependent id="13">won</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">Marathon</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="17">Marathon</governor>
          <dependent id="15">1964</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">Marathon</governor>
          <dependent id="16">Olympic</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">won</governor>
          <dependent id="17">Marathon</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">Tokyo</governor>
          <dependent id="18">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">won</governor>
          <dependent id="19">Tokyo</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">Mekonnen</governor>
          <dependent id="20">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">nation</governor>
          <dependent id="21">a</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">named</governor>
          <dependent id="22">nation</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">Mekonnen</governor>
          <dependent id="23">named</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="26">boys</governor>
          <dependent id="24">its</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">boys</governor>
          <dependent id="25">baby</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="23">named</governor>
          <dependent id="26">boys</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">hero</governor>
          <dependent id="27">after</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="29">hero</governor>
          <dependent id="28">its</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">named</governor>
          <dependent id="29">hero</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Bikila" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Bikila" />
          </tokens>
        </entity>
        <entity id="2" string="1964" type="DATE" score="0.0">
          <tokens>
            <token id="15" string="1964" />
          </tokens>
        </entity>
        <entity id="3" string="Now" type="DATE" score="0.0">
          <tokens>
            <token id="1" string="Now" />
          </tokens>
        </entity>
        <entity id="4" string="Abebe Mekonnen" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Abebe" />
            <token id="5" string="Mekonnen" />
          </tokens>
        </entity>
        <entity id="5" string="Olympic Marathon" type="MISC" score="0.0">
          <tokens>
            <token id="16" string="Olympic" />
            <token id="17" string="Marathon" />
          </tokens>
        </entity>
        <entity id="6" string="Tokyo" type="LOCATION" score="0.0">
          <tokens>
            <token id="19" string="Tokyo" />
          </tokens>
        </entity>
        <entity id="7" string="the year" type="DATE" score="0.0">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="year" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>Mekonnen, a police lieutenant from Addis Ababa, made a furious rush with a mile to go, passing Juma Ikangaa of Tanzania and winning Monday&amp;apost;s Boston Marathon in 2 hours 9 minutes 6 seconds.</content>
      <tokens>
        <token id="1" string="Mekonnen" lemma="Mekonnen" stem="mekonnen" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="lieutenant" lemma="lieutenant" stem="lieuten" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="Addis" lemma="Addis" stem="addi" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="8" string="Ababa" lemma="Ababa" stem="ababa" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="made" lemma="make" stem="made" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="furious" lemma="furious" stem="furiou" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="rush" lemma="rush" stem="rush" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="mile" lemma="mile" stem="mile" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="go" lemma="go" stem="go" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="passing" lemma="pass" stem="pass" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="Juma" lemma="Juma" stem="juma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="22" string="Ikangaa" lemma="Ikangaa" stem="ikangaa" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="23" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="24" string="Tanzania" lemma="Tanzania" stem="tanzania" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="25" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="winning" lemma="win" stem="win" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="Monday" lemma="Monday" stem="mondai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="28" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="29" string="Boston" lemma="Boston" stem="boston" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="30" string="Marathon" lemma="Marathon" stem="marathon" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="31" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="32" string="2" lemma="2" stem="2" pos="CD" type="Number" isStopWord="false" ner="TIME" is_referenced="true" is_refers="false" />
        <token id="33" string="hours" lemma="hour" stem="hour" pos="NNS" type="Word" isStopWord="false" ner="TIME" is_referenced="true" is_refers="false" />
        <token id="34" string="9" lemma="9" stem="9" pos="CD" type="Number" isStopWord="false" ner="TIME" is_referenced="true" is_refers="false" />
        <token id="35" string="minutes" lemma="minute" stem="minut" pos="NNS" type="Word" isStopWord="false" ner="TIME" is_referenced="true" is_refers="false" />
        <token id="36" string="6" lemma="6" stem="6" pos="CD" type="Number" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="37" string="seconds" lemma="seconds" stem="second" pos="NNS" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="38" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Mekonnen)) (, ,) (NP (NP (DT a) (NN police) (NN lieutenant)) (PP (IN from) (NP (NNP Addis) (NNP Ababa)))) (, ,)) (VP (VBD made) (NP (DT a) (JJ furious) (NN rush)) (PP (IN with) (NP (DT a) (NN mile))) (S (VP (TO to) (VP (VB go)))) (, ,) (S (VP (VP (VBG passing) (NP (NP (NNP Juma) (NNP Ikangaa)) (PP (IN of) (NP (NNP Tanzania))))) (CC and) (VP (VBG winning) (NP (NP (NP (NNP Monday) (POS 's)) (NNP Boston) (NNP Marathon)) (PP (IN in) (NP (NP (CD 2) (NNS hours)) (NP-TMP (CD 9) (NNS minutes)))))) (NP (CD 6) (NNS seconds))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a furious rush" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="furious" />
            <token id="13" string="rush" />
          </tokens>
        </chunking>
        <chunking id="2" string="2 hours" type="NP">
          <tokens>
            <token id="32" string="2" />
            <token id="33" string="hours" />
          </tokens>
        </chunking>
        <chunking id="3" string="passing Juma Ikangaa of Tanzania and winning Monday 's Boston Marathon in 2 hours 9 minutes 6 seconds" type="VP">
          <tokens>
            <token id="20" string="passing" />
            <token id="21" string="Juma" />
            <token id="22" string="Ikangaa" />
            <token id="23" string="of" />
            <token id="24" string="Tanzania" />
            <token id="25" string="and" />
            <token id="26" string="winning" />
            <token id="27" string="Monday" />
            <token id="28" string="'s" />
            <token id="29" string="Boston" />
            <token id="30" string="Marathon" />
            <token id="31" string="in" />
            <token id="32" string="2" />
            <token id="33" string="hours" />
            <token id="34" string="9" />
            <token id="35" string="minutes" />
            <token id="36" string="6" />
            <token id="37" string="seconds" />
          </tokens>
        </chunking>
        <chunking id="4" string="2 hours 9 minutes" type="NP">
          <tokens>
            <token id="32" string="2" />
            <token id="33" string="hours" />
            <token id="34" string="9" />
            <token id="35" string="minutes" />
          </tokens>
        </chunking>
        <chunking id="5" string="Monday 's" type="NP">
          <tokens>
            <token id="27" string="Monday" />
            <token id="28" string="'s" />
          </tokens>
        </chunking>
        <chunking id="6" string="Tanzania" type="NP">
          <tokens>
            <token id="24" string="Tanzania" />
          </tokens>
        </chunking>
        <chunking id="7" string="Mekonnen , a police lieutenant from Addis Ababa ," type="NP">
          <tokens>
            <token id="1" string="Mekonnen" />
            <token id="2" string="," />
            <token id="3" string="a" />
            <token id="4" string="police" />
            <token id="5" string="lieutenant" />
            <token id="6" string="from" />
            <token id="7" string="Addis" />
            <token id="8" string="Ababa" />
            <token id="9" string="," />
          </tokens>
        </chunking>
        <chunking id="8" string="go" type="VP">
          <tokens>
            <token id="18" string="go" />
          </tokens>
        </chunking>
        <chunking id="9" string="Monday 's Boston Marathon" type="NP">
          <tokens>
            <token id="27" string="Monday" />
            <token id="28" string="'s" />
            <token id="29" string="Boston" />
            <token id="30" string="Marathon" />
          </tokens>
        </chunking>
        <chunking id="10" string="Juma Ikangaa of Tanzania" type="NP">
          <tokens>
            <token id="21" string="Juma" />
            <token id="22" string="Ikangaa" />
            <token id="23" string="of" />
            <token id="24" string="Tanzania" />
          </tokens>
        </chunking>
        <chunking id="11" string="Addis Ababa" type="NP">
          <tokens>
            <token id="7" string="Addis" />
            <token id="8" string="Ababa" />
          </tokens>
        </chunking>
        <chunking id="12" string="passing Juma Ikangaa of Tanzania" type="VP">
          <tokens>
            <token id="20" string="passing" />
            <token id="21" string="Juma" />
            <token id="22" string="Ikangaa" />
            <token id="23" string="of" />
            <token id="24" string="Tanzania" />
          </tokens>
        </chunking>
        <chunking id="13" string="a mile" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="mile" />
          </tokens>
        </chunking>
        <chunking id="14" string="Mekonnen" type="NP">
          <tokens>
            <token id="1" string="Mekonnen" />
          </tokens>
        </chunking>
        <chunking id="15" string="a police lieutenant from Addis Ababa" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="police" />
            <token id="5" string="lieutenant" />
            <token id="6" string="from" />
            <token id="7" string="Addis" />
            <token id="8" string="Ababa" />
          </tokens>
        </chunking>
        <chunking id="16" string="made a furious rush with a mile to go , passing Juma Ikangaa of Tanzania and winning Monday 's Boston Marathon in 2 hours 9 minutes 6 seconds" type="VP">
          <tokens>
            <token id="10" string="made" />
            <token id="11" string="a" />
            <token id="12" string="furious" />
            <token id="13" string="rush" />
            <token id="14" string="with" />
            <token id="15" string="a" />
            <token id="16" string="mile" />
            <token id="17" string="to" />
            <token id="18" string="go" />
            <token id="19" string="," />
            <token id="20" string="passing" />
            <token id="21" string="Juma" />
            <token id="22" string="Ikangaa" />
            <token id="23" string="of" />
            <token id="24" string="Tanzania" />
            <token id="25" string="and" />
            <token id="26" string="winning" />
            <token id="27" string="Monday" />
            <token id="28" string="'s" />
            <token id="29" string="Boston" />
            <token id="30" string="Marathon" />
            <token id="31" string="in" />
            <token id="32" string="2" />
            <token id="33" string="hours" />
            <token id="34" string="9" />
            <token id="35" string="minutes" />
            <token id="36" string="6" />
            <token id="37" string="seconds" />
          </tokens>
        </chunking>
        <chunking id="17" string="Juma Ikangaa" type="NP">
          <tokens>
            <token id="21" string="Juma" />
            <token id="22" string="Ikangaa" />
          </tokens>
        </chunking>
        <chunking id="18" string="6 seconds" type="NP">
          <tokens>
            <token id="36" string="6" />
            <token id="37" string="seconds" />
          </tokens>
        </chunking>
        <chunking id="19" string="a police lieutenant" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="police" />
            <token id="5" string="lieutenant" />
          </tokens>
        </chunking>
        <chunking id="20" string="to go" type="VP">
          <tokens>
            <token id="17" string="to" />
            <token id="18" string="go" />
          </tokens>
        </chunking>
        <chunking id="21" string="Monday 's Boston Marathon in 2 hours 9 minutes" type="NP">
          <tokens>
            <token id="27" string="Monday" />
            <token id="28" string="'s" />
            <token id="29" string="Boston" />
            <token id="30" string="Marathon" />
            <token id="31" string="in" />
            <token id="32" string="2" />
            <token id="33" string="hours" />
            <token id="34" string="9" />
            <token id="35" string="minutes" />
          </tokens>
        </chunking>
        <chunking id="22" string="winning Monday 's Boston Marathon in 2 hours 9 minutes" type="VP">
          <tokens>
            <token id="26" string="winning" />
            <token id="27" string="Monday" />
            <token id="28" string="'s" />
            <token id="29" string="Boston" />
            <token id="30" string="Marathon" />
            <token id="31" string="in" />
            <token id="32" string="2" />
            <token id="33" string="hours" />
            <token id="34" string="9" />
            <token id="35" string="minutes" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="10">made</governor>
          <dependent id="1">Mekonnen</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">lieutenant</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">lieutenant</governor>
          <dependent id="4">police</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="1">Mekonnen</governor>
          <dependent id="5">lieutenant</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">Ababa</governor>
          <dependent id="6">from</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">Ababa</governor>
          <dependent id="7">Addis</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">lieutenant</governor>
          <dependent id="8">Ababa</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">made</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">rush</governor>
          <dependent id="11">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">rush</governor>
          <dependent id="12">furious</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">made</governor>
          <dependent id="13">rush</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">mile</governor>
          <dependent id="14">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">mile</governor>
          <dependent id="15">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">made</governor>
          <dependent id="16">mile</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">go</governor>
          <dependent id="17">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="10">made</governor>
          <dependent id="18">go</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="10">made</governor>
          <dependent id="20">passing</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">Ikangaa</governor>
          <dependent id="21">Juma</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">passing</governor>
          <dependent id="22">Ikangaa</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">Tanzania</governor>
          <dependent id="23">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">Ikangaa</governor>
          <dependent id="24">Tanzania</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="20">passing</governor>
          <dependent id="25">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="20">passing</governor>
          <dependent id="26">winning</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="30">Marathon</governor>
          <dependent id="27">Monday</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">Monday</governor>
          <dependent id="28">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="30">Marathon</governor>
          <dependent id="29">Boston</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="26">winning</governor>
          <dependent id="30">Marathon</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">hours</governor>
          <dependent id="31">in</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="33">hours</governor>
          <dependent id="32">2</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">Marathon</governor>
          <dependent id="33">hours</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="35">minutes</governor>
          <dependent id="34">9</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="33">hours</governor>
          <dependent id="35">minutes</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="37">seconds</governor>
          <dependent id="36">6</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">passing</governor>
          <dependent id="37">seconds</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Boston Marathon" type="LOCATION" score="0.0">
          <tokens>
            <token id="29" string="Boston" />
            <token id="30" string="Marathon" />
          </tokens>
        </entity>
        <entity id="2" string="Mekonnen" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Mekonnen" />
          </tokens>
        </entity>
        <entity id="3" string="2 hours 9 minutes 6 seconds" type="TIME" score="0.0">
          <tokens>
            <token id="32" string="2" />
            <token id="33" string="hours" />
            <token id="34" string="9" />
            <token id="35" string="minutes" />
            <token id="36" string="6" />
            <token id="37" string="seconds" />
          </tokens>
        </entity>
        <entity id="4" string="Tanzania" type="LOCATION" score="0.0">
          <tokens>
            <token id="24" string="Tanzania" />
          </tokens>
        </entity>
        <entity id="5" string="Juma Ikangaa" type="PERSON" score="0.0">
          <tokens>
            <token id="21" string="Juma" />
            <token id="22" string="Ikangaa" />
          </tokens>
        </entity>
        <entity id="6" string="Addis Ababa" type="LOCATION" score="0.0">
          <tokens>
            <token id="7" string="Addis" />
            <token id="8" string="Ababa" />
          </tokens>
        </entity>
        <entity id="7" string="Monday" type="DATE" score="0.0">
          <tokens>
            <token id="27" string="Monday" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>Ikangaa was second in 2:09:56.</content>
      <tokens>
        <token id="1" string="Ikangaa" lemma="Ikangaa" stem="ikangaa" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="second" lemma="second" stem="second" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="4" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="5" string="2:09:56" lemma="2:09:56" stem="2:09:56" pos="CD" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Ikangaa)) (VP (VBD was) (ADJP (JJ second) (PP (IN in) (NP (CD 2:09:56))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Ikangaa" type="NP">
          <tokens>
            <token id="1" string="Ikangaa" />
          </tokens>
        </chunking>
        <chunking id="2" string="was second in 2:09:56" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="second" />
            <token id="4" string="in" />
            <token id="5" string="2:09:56" />
          </tokens>
        </chunking>
        <chunking id="3" string="2:09:56" type="NP">
          <tokens>
            <token id="5" string="2:09:56" />
          </tokens>
        </chunking>
        <chunking id="4" string="second in 2:09:56" type="ADJP">
          <tokens>
            <token id="3" string="second" />
            <token id="4" string="in" />
            <token id="5" string="2:09:56" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">second</governor>
          <dependent id="1">Ikangaa</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="3">second</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">second</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">2:09:56</governor>
          <dependent id="4">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">second</governor>
          <dependent id="5">2:09:56</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ikangaa" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Ikangaa" />
          </tokens>
        </entity>
        <entity id="2" string="second in 2:09:56" type="DATE" score="0.0">
          <tokens>
            <token id="3" string="second" />
            <token id="4" string="in" />
            <token id="5" string="2:09:56" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>It was only the second time an African has won here.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="only" lemma="only" stem="onli" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="second" lemma="second" stem="second" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="true" is_refers="false" />
        <token id="6" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="African" lemma="African" stem="african" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="9" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="won" lemma="win" stem="won" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="here" lemma="here" stem="here" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP It)) (VP (VBD was) (NP (NP (RB only) (DT the) (JJ second) (NN time)) (SBAR (S (NP (DT an) (NNP African)) (VP (VBZ has) (VP (VBN won) (ADVP (RB here)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="only the second time an African has won here" type="NP">
          <tokens>
            <token id="3" string="only" />
            <token id="4" string="the" />
            <token id="5" string="second" />
            <token id="6" string="time" />
            <token id="7" string="an" />
            <token id="8" string="African" />
            <token id="9" string="has" />
            <token id="10" string="won" />
            <token id="11" string="here" />
          </tokens>
        </chunking>
        <chunking id="2" string="was only the second time an African has won here" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="only" />
            <token id="4" string="the" />
            <token id="5" string="second" />
            <token id="6" string="time" />
            <token id="7" string="an" />
            <token id="8" string="African" />
            <token id="9" string="has" />
            <token id="10" string="won" />
            <token id="11" string="here" />
          </tokens>
        </chunking>
        <chunking id="3" string="won here" type="VP">
          <tokens>
            <token id="10" string="won" />
            <token id="11" string="here" />
          </tokens>
        </chunking>
        <chunking id="4" string="an African has won here" type="SBAR">
          <tokens>
            <token id="7" string="an" />
            <token id="8" string="African" />
            <token id="9" string="has" />
            <token id="10" string="won" />
            <token id="11" string="here" />
          </tokens>
        </chunking>
        <chunking id="5" string="has won here" type="VP">
          <tokens>
            <token id="9" string="has" />
            <token id="10" string="won" />
            <token id="11" string="here" />
          </tokens>
        </chunking>
        <chunking id="6" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="7" string="only the second time" type="NP">
          <tokens>
            <token id="3" string="only" />
            <token id="4" string="the" />
            <token id="5" string="second" />
            <token id="6" string="time" />
          </tokens>
        </chunking>
        <chunking id="8" string="an African" type="NP">
          <tokens>
            <token id="7" string="an" />
            <token id="8" string="African" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="6">time</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">time</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">time</governor>
          <dependent id="3">only</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">time</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">time</governor>
          <dependent id="5">second</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">time</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">African</governor>
          <dependent id="7">an</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">won</governor>
          <dependent id="8">African</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="10">won</governor>
          <dependent id="9">has</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="6">time</governor>
          <dependent id="10">won</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">won</governor>
          <dependent id="11">here</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="second" type="ORDINAL" score="0.0">
          <tokens>
            <token id="5" string="second" />
          </tokens>
        </entity>
        <entity id="2" string="African" type="MISC" score="0.0">
          <tokens>
            <token id="8" string="African" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>Ingrid Kristiansen of Norway easily won the women&amp;apost;s race in 2:24:33 after abandoning her attempt to break 2:20.</content>
      <tokens>
        <token id="1" string="Ingrid" lemma="Ingrid" stem="ingrid" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="Kristiansen" lemma="Kristiansen" stem="kristiansen" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="Norway" lemma="Norway" stem="norwai" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="5" string="easily" lemma="easily" stem="easili" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="won" lemma="win" stem="won" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="women" lemma="woman" stem="women" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="race" lemma="race" stem="race" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="2:24:33" lemma="2:24:33" stem="2:24:33" pos="CD" type="Word" isStopWord="false" ner="TIME" is_referenced="true" is_refers="false" />
        <token id="13" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="abandoning" lemma="abandon" stem="abandon" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="attempt" lemma="attempt" stem="attempt" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="break" lemma="break" stem="break" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="2:20" lemma="2:20" stem="2:20" pos="CD" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Ingrid) (NNP Kristiansen)) (PP (IN of) (NP (NNP Norway)))) (ADVP (RB easily)) (VP (VBD won) (NP (NP (NP (DT the) (NNS women) (POS 's)) (NN race)) (PP (IN in) (NP (CD 2:24:33)))) (PP (IN after) (S (VP (VBG abandoning) (NP (PRP$ her) (NN attempt) (S (VP (TO to) (VP (VB break) (NP (CD 2:20)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="abandoning her attempt to break 2:20" type="VP">
          <tokens>
            <token id="14" string="abandoning" />
            <token id="15" string="her" />
            <token id="16" string="attempt" />
            <token id="17" string="to" />
            <token id="18" string="break" />
            <token id="19" string="2:20" />
          </tokens>
        </chunking>
        <chunking id="2" string="2:24:33" type="NP">
          <tokens>
            <token id="12" string="2:24:33" />
          </tokens>
        </chunking>
        <chunking id="3" string="the women 's" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="women" />
            <token id="9" string="'s" />
          </tokens>
        </chunking>
        <chunking id="4" string="the women 's race" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="women" />
            <token id="9" string="'s" />
            <token id="10" string="race" />
          </tokens>
        </chunking>
        <chunking id="5" string="2:20" type="NP">
          <tokens>
            <token id="19" string="2:20" />
          </tokens>
        </chunking>
        <chunking id="6" string="Norway" type="NP">
          <tokens>
            <token id="4" string="Norway" />
          </tokens>
        </chunking>
        <chunking id="7" string="Ingrid Kristiansen of Norway" type="NP">
          <tokens>
            <token id="1" string="Ingrid" />
            <token id="2" string="Kristiansen" />
            <token id="3" string="of" />
            <token id="4" string="Norway" />
          </tokens>
        </chunking>
        <chunking id="8" string="the women 's race in 2:24:33" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="women" />
            <token id="9" string="'s" />
            <token id="10" string="race" />
            <token id="11" string="in" />
            <token id="12" string="2:24:33" />
          </tokens>
        </chunking>
        <chunking id="9" string="her attempt to break 2:20" type="NP">
          <tokens>
            <token id="15" string="her" />
            <token id="16" string="attempt" />
            <token id="17" string="to" />
            <token id="18" string="break" />
            <token id="19" string="2:20" />
          </tokens>
        </chunking>
        <chunking id="10" string="Ingrid Kristiansen" type="NP">
          <tokens>
            <token id="1" string="Ingrid" />
            <token id="2" string="Kristiansen" />
          </tokens>
        </chunking>
        <chunking id="11" string="won the women 's race in 2:24:33 after abandoning her attempt to break 2:20" type="VP">
          <tokens>
            <token id="6" string="won" />
            <token id="7" string="the" />
            <token id="8" string="women" />
            <token id="9" string="'s" />
            <token id="10" string="race" />
            <token id="11" string="in" />
            <token id="12" string="2:24:33" />
            <token id="13" string="after" />
            <token id="14" string="abandoning" />
            <token id="15" string="her" />
            <token id="16" string="attempt" />
            <token id="17" string="to" />
            <token id="18" string="break" />
            <token id="19" string="2:20" />
          </tokens>
        </chunking>
        <chunking id="12" string="break 2:20" type="VP">
          <tokens>
            <token id="18" string="break" />
            <token id="19" string="2:20" />
          </tokens>
        </chunking>
        <chunking id="13" string="to break 2:20" type="VP">
          <tokens>
            <token id="17" string="to" />
            <token id="18" string="break" />
            <token id="19" string="2:20" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Kristiansen</governor>
          <dependent id="1">Ingrid</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">won</governor>
          <dependent id="2">Kristiansen</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">Norway</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">Kristiansen</governor>
          <dependent id="4">Norway</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">won</governor>
          <dependent id="5">easily</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">won</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">women</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="10">race</governor>
          <dependent id="8">women</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">women</governor>
          <dependent id="9">'s</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">won</governor>
          <dependent id="10">race</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">2:24:33</governor>
          <dependent id="11">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">race</governor>
          <dependent id="12">2:24:33</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">abandoning</governor>
          <dependent id="13">after</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="6">won</governor>
          <dependent id="14">abandoning</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="16">attempt</governor>
          <dependent id="15">her</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">abandoning</governor>
          <dependent id="16">attempt</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">break</governor>
          <dependent id="17">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="16">attempt</governor>
          <dependent id="18">break</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">break</governor>
          <dependent id="19">2:20</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="2:20" type="TIME" score="0.0">
          <tokens>
            <token id="19" string="2:20" />
          </tokens>
        </entity>
        <entity id="2" string="Norway" type="LOCATION" score="0.0">
          <tokens>
            <token id="4" string="Norway" />
          </tokens>
        </entity>
        <entity id="3" string="2:24:33" type="TIME" score="0.0">
          <tokens>
            <token id="12" string="2:24:33" />
          </tokens>
        </entity>
        <entity id="4" string="Ingrid Kristiansen" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Ingrid" />
            <token id="2" string="Kristiansen" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>Kristiansen, the women&amp;apost;s marathon world record-holder, started fast but slowed markedly on a hot day.</content>
      <tokens>
        <token id="1" string="Kristiansen" lemma="Kristiansen" stem="kristiansen" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="women" lemma="woman" stem="women" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="marathon" lemma="marathon" stem="marathon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="record-holder" lemma="record-holder" stem="record-hold" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="started" lemma="start" stem="start" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="fast" lemma="fast" stem="fast" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="slowed" lemma="slow" stem="slow" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="markedly" lemma="markedly" stem="markedli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="hot" lemma="hot" stem="hot" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="day" lemma="day" stem="dai" pos="NN" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Kristiansen)) (, ,) (NP (NP (DT the) (NNS women) (POS 's)) (NN marathon) (NN world) (NN record-holder)) (, ,)) (VP (VP (VBD started) (ADVP (RB fast))) (CC but) (VP (VBD slowed) (ADVP (RB markedly) (PP (IN on) (NP-TMP (DT a) (JJ hot) (NN day)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="slowed markedly on a hot day" type="VP">
          <tokens>
            <token id="13" string="slowed" />
            <token id="14" string="markedly" />
            <token id="15" string="on" />
            <token id="16" string="a" />
            <token id="17" string="hot" />
            <token id="18" string="day" />
          </tokens>
        </chunking>
        <chunking id="2" string="Kristiansen , the women 's marathon world record-holder ," type="NP">
          <tokens>
            <token id="1" string="Kristiansen" />
            <token id="2" string="," />
            <token id="3" string="the" />
            <token id="4" string="women" />
            <token id="5" string="'s" />
            <token id="6" string="marathon" />
            <token id="7" string="world" />
            <token id="8" string="record-holder" />
            <token id="9" string="," />
          </tokens>
        </chunking>
        <chunking id="3" string="started fast" type="VP">
          <tokens>
            <token id="10" string="started" />
            <token id="11" string="fast" />
          </tokens>
        </chunking>
        <chunking id="4" string="the women 's" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="women" />
            <token id="5" string="'s" />
          </tokens>
        </chunking>
        <chunking id="5" string="the women 's marathon world record-holder" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="women" />
            <token id="5" string="'s" />
            <token id="6" string="marathon" />
            <token id="7" string="world" />
            <token id="8" string="record-holder" />
          </tokens>
        </chunking>
        <chunking id="6" string="started fast but slowed markedly on a hot day" type="VP">
          <tokens>
            <token id="10" string="started" />
            <token id="11" string="fast" />
            <token id="12" string="but" />
            <token id="13" string="slowed" />
            <token id="14" string="markedly" />
            <token id="15" string="on" />
            <token id="16" string="a" />
            <token id="17" string="hot" />
            <token id="18" string="day" />
          </tokens>
        </chunking>
        <chunking id="7" string="Kristiansen" type="NP">
          <tokens>
            <token id="1" string="Kristiansen" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="10">started</governor>
          <dependent id="1">Kristiansen</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">women</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">record-holder</governor>
          <dependent id="4">women</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">women</governor>
          <dependent id="5">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">record-holder</governor>
          <dependent id="6">marathon</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">record-holder</governor>
          <dependent id="7">world</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="1">Kristiansen</governor>
          <dependent id="8">record-holder</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">started</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">started</governor>
          <dependent id="11">fast</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">started</governor>
          <dependent id="12">but</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">started</governor>
          <dependent id="13">slowed</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">slowed</governor>
          <dependent id="14">markedly</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">day</governor>
          <dependent id="15">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">day</governor>
          <dependent id="16">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">day</governor>
          <dependent id="17">hot</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">markedly</governor>
          <dependent id="18">day</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="day" type="DURATION" score="0.0">
          <tokens>
            <token id="18" string="day" />
          </tokens>
        </entity>
        <entity id="2" string="Kristiansen" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Kristiansen" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>With temperatures in the high 60s during the Patriot&amp;apost;s Day race, it was about 20 degrees warmer than it was Sunday and all of last week.</content>
      <tokens>
        <token id="1" string="With" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="temperatures" lemma="temperature" stem="temperatur" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="high" lemma="high" stem="high" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="60s" lemma="60" stem="60" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="during" lemma="during" stem="dure" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="Patriot" lemma="patriot" stem="patriot" pos="NN" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="10" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="11" string="Day" lemma="day" stem="dai" pos="NN" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="12" string="race" lemma="race" stem="race" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="about" lemma="about" stem="about" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="20" lemma="20" stem="20" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="18" string="degrees" lemma="degree" stem="degre" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="warmer" lemma="warmer" stem="warmer" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="Sunday" lemma="Sunday" stem="sundai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="24" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="28" string="week" lemma="week" stem="week" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN With) (NP (NP (NNS temperatures)) (PP (IN in) (NP (NP (DT the) (JJ high) (NNS 60s)) (PP (IN during) (NP (NP (DT the) (NN Patriot) (POS 's)) (NN Day) (NN race))))))) (, ,) (NP (PRP it)) (VP (VBD was) (ADJP (ADJP (NP (QP (RB about) (CD 20)) (NNS degrees)) (JJR warmer)) (SBAR (IN than) (S (NP (PRP it)) (VP (VBD was) (NP (NP (NNP Sunday)) (CC and) (NP (NP (DT all)) (PP (IN of) (NP (JJ last) (NN week)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="all" type="NP">
          <tokens>
            <token id="25" string="all" />
          </tokens>
        </chunking>
        <chunking id="2" string="about 20 degrees warmer than it was Sunday and all of last week" type="ADJP">
          <tokens>
            <token id="16" string="about" />
            <token id="17" string="20" />
            <token id="18" string="degrees" />
            <token id="19" string="warmer" />
            <token id="20" string="than" />
            <token id="21" string="it" />
            <token id="22" string="was" />
            <token id="23" string="Sunday" />
            <token id="24" string="and" />
            <token id="25" string="all" />
            <token id="26" string="of" />
            <token id="27" string="last" />
            <token id="28" string="week" />
          </tokens>
        </chunking>
        <chunking id="3" string="temperatures in the high 60s during the Patriot 's Day race" type="NP">
          <tokens>
            <token id="2" string="temperatures" />
            <token id="3" string="in" />
            <token id="4" string="the" />
            <token id="5" string="high" />
            <token id="6" string="60s" />
            <token id="7" string="during" />
            <token id="8" string="the" />
            <token id="9" string="Patriot" />
            <token id="10" string="'s" />
            <token id="11" string="Day" />
            <token id="12" string="race" />
          </tokens>
        </chunking>
        <chunking id="4" string="Sunday" type="NP">
          <tokens>
            <token id="23" string="Sunday" />
          </tokens>
        </chunking>
        <chunking id="5" string="the high 60s" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="high" />
            <token id="6" string="60s" />
          </tokens>
        </chunking>
        <chunking id="6" string="the Patriot 's Day race" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="Patriot" />
            <token id="10" string="'s" />
            <token id="11" string="Day" />
            <token id="12" string="race" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="14" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="about 20 degrees warmer" type="ADJP">
          <tokens>
            <token id="16" string="about" />
            <token id="17" string="20" />
            <token id="18" string="degrees" />
            <token id="19" string="warmer" />
          </tokens>
        </chunking>
        <chunking id="9" string="the Patriot 's" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="Patriot" />
            <token id="10" string="'s" />
          </tokens>
        </chunking>
        <chunking id="10" string="was Sunday and all of last week" type="VP">
          <tokens>
            <token id="22" string="was" />
            <token id="23" string="Sunday" />
            <token id="24" string="and" />
            <token id="25" string="all" />
            <token id="26" string="of" />
            <token id="27" string="last" />
            <token id="28" string="week" />
          </tokens>
        </chunking>
        <chunking id="11" string="Sunday and all of last week" type="NP">
          <tokens>
            <token id="23" string="Sunday" />
            <token id="24" string="and" />
            <token id="25" string="all" />
            <token id="26" string="of" />
            <token id="27" string="last" />
            <token id="28" string="week" />
          </tokens>
        </chunking>
        <chunking id="12" string="than it was Sunday and all of last week" type="SBAR">
          <tokens>
            <token id="20" string="than" />
            <token id="21" string="it" />
            <token id="22" string="was" />
            <token id="23" string="Sunday" />
            <token id="24" string="and" />
            <token id="25" string="all" />
            <token id="26" string="of" />
            <token id="27" string="last" />
            <token id="28" string="week" />
          </tokens>
        </chunking>
        <chunking id="13" string="was about 20 degrees warmer than it was Sunday and all of last week" type="VP">
          <tokens>
            <token id="15" string="was" />
            <token id="16" string="about" />
            <token id="17" string="20" />
            <token id="18" string="degrees" />
            <token id="19" string="warmer" />
            <token id="20" string="than" />
            <token id="21" string="it" />
            <token id="22" string="was" />
            <token id="23" string="Sunday" />
            <token id="24" string="and" />
            <token id="25" string="all" />
            <token id="26" string="of" />
            <token id="27" string="last" />
            <token id="28" string="week" />
          </tokens>
        </chunking>
        <chunking id="14" string="temperatures" type="NP">
          <tokens>
            <token id="2" string="temperatures" />
          </tokens>
        </chunking>
        <chunking id="15" string="all of last week" type="NP">
          <tokens>
            <token id="25" string="all" />
            <token id="26" string="of" />
            <token id="27" string="last" />
            <token id="28" string="week" />
          </tokens>
        </chunking>
        <chunking id="16" string="about 20 degrees" type="NP">
          <tokens>
            <token id="16" string="about" />
            <token id="17" string="20" />
            <token id="18" string="degrees" />
          </tokens>
        </chunking>
        <chunking id="17" string="last week" type="NP">
          <tokens>
            <token id="27" string="last" />
            <token id="28" string="week" />
          </tokens>
        </chunking>
        <chunking id="18" string="the high 60s during the Patriot 's Day race" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="high" />
            <token id="6" string="60s" />
            <token id="7" string="during" />
            <token id="8" string="the" />
            <token id="9" string="Patriot" />
            <token id="10" string="'s" />
            <token id="11" string="Day" />
            <token id="12" string="race" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">temperatures</governor>
          <dependent id="1">With</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">warmer</governor>
          <dependent id="2">temperatures</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">60s</governor>
          <dependent id="3">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">60s</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">60s</governor>
          <dependent id="5">high</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">temperatures</governor>
          <dependent id="6">60s</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">race</governor>
          <dependent id="7">during</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">Patriot</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="12">race</governor>
          <dependent id="9">Patriot</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Patriot</governor>
          <dependent id="10">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">race</governor>
          <dependent id="11">Day</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">60s</governor>
          <dependent id="12">race</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">warmer</governor>
          <dependent id="14">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="19">warmer</governor>
          <dependent id="15">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="17">20</governor>
          <dependent id="16">about</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="18">degrees</governor>
          <dependent id="17">20</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="19">warmer</governor>
          <dependent id="18">degrees</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="19">warmer</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="23">Sunday</governor>
          <dependent id="20">than</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">Sunday</governor>
          <dependent id="21">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="23">Sunday</governor>
          <dependent id="22">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="19">warmer</governor>
          <dependent id="23">Sunday</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="23">Sunday</governor>
          <dependent id="24">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="23">Sunday</governor>
          <dependent id="25">all</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">week</governor>
          <dependent id="26">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">week</governor>
          <dependent id="27">last</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">all</governor>
          <dependent id="28">week</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Patriot 's" type="MISC" score="0.0">
          <tokens>
            <token id="9" string="Patriot" />
            <token id="10" string="'s" />
          </tokens>
        </entity>
        <entity id="2" string="last week" type="DATE" score="0.0">
          <tokens>
            <token id="27" string="last" />
            <token id="28" string="week" />
          </tokens>
        </entity>
        <entity id="3" string="Sunday" type="DATE" score="0.0">
          <tokens>
            <token id="23" string="Sunday" />
          </tokens>
        </entity>
        <entity id="4" string="Day" type="DURATION" score="0.0">
          <tokens>
            <token id="11" string="Day" />
          </tokens>
        </entity>
        <entity id="5" string="20" type="NUMBER" score="0.0">
          <tokens>
            <token id="17" string="20" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>Still, Kristiansen finished 26th overall, believed to be the highest finish for a woman in this race.</content>
      <tokens>
        <token id="1" string="Still" lemma="still" stem="still" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Kristiansen" lemma="Kristiansen" stem="kristiansen" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="4" string="finished" lemma="finish" stem="finish" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="26th" lemma="26th" stem="26th" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="6" string="overall" lemma="overall" stem="overal" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="believed" lemma="believe" stem="believ" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="highest" lemma="highest" stem="highest" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="finish" lemma="finish" stem="finish" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="woman" lemma="woman" stem="woman" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="race" lemma="race" stem="race" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Still)) (, ,) (NP (NNP Kristiansen)) (VP (VBD finished) (NP (NP (JJ 26th) (JJ overall)) (, ,) (VP (VBN believed) (S (VP (TO to) (VP (VB be) (NP (NP (DT the) (JJS highest) (NN finish)) (PP (IN for) (NP (NP (DT a) (NN woman)) (PP (IN in) (NP (DT this) (NN race)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="26th overall , believed to be the highest finish for a woman in this race" type="NP">
          <tokens>
            <token id="5" string="26th" />
            <token id="6" string="overall" />
            <token id="7" string="," />
            <token id="8" string="believed" />
            <token id="9" string="to" />
            <token id="10" string="be" />
            <token id="11" string="the" />
            <token id="12" string="highest" />
            <token id="13" string="finish" />
            <token id="14" string="for" />
            <token id="15" string="a" />
            <token id="16" string="woman" />
            <token id="17" string="in" />
            <token id="18" string="this" />
            <token id="19" string="race" />
          </tokens>
        </chunking>
        <chunking id="2" string="to be the highest finish for a woman in this race" type="VP">
          <tokens>
            <token id="9" string="to" />
            <token id="10" string="be" />
            <token id="11" string="the" />
            <token id="12" string="highest" />
            <token id="13" string="finish" />
            <token id="14" string="for" />
            <token id="15" string="a" />
            <token id="16" string="woman" />
            <token id="17" string="in" />
            <token id="18" string="this" />
            <token id="19" string="race" />
          </tokens>
        </chunking>
        <chunking id="3" string="the highest finish for a woman in this race" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="highest" />
            <token id="13" string="finish" />
            <token id="14" string="for" />
            <token id="15" string="a" />
            <token id="16" string="woman" />
            <token id="17" string="in" />
            <token id="18" string="this" />
            <token id="19" string="race" />
          </tokens>
        </chunking>
        <chunking id="4" string="this race" type="NP">
          <tokens>
            <token id="18" string="this" />
            <token id="19" string="race" />
          </tokens>
        </chunking>
        <chunking id="5" string="a woman in this race" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="woman" />
            <token id="17" string="in" />
            <token id="18" string="this" />
            <token id="19" string="race" />
          </tokens>
        </chunking>
        <chunking id="6" string="believed to be the highest finish for a woman in this race" type="VP">
          <tokens>
            <token id="8" string="believed" />
            <token id="9" string="to" />
            <token id="10" string="be" />
            <token id="11" string="the" />
            <token id="12" string="highest" />
            <token id="13" string="finish" />
            <token id="14" string="for" />
            <token id="15" string="a" />
            <token id="16" string="woman" />
            <token id="17" string="in" />
            <token id="18" string="this" />
            <token id="19" string="race" />
          </tokens>
        </chunking>
        <chunking id="7" string="finished 26th overall , believed to be the highest finish for a woman in this race" type="VP">
          <tokens>
            <token id="4" string="finished" />
            <token id="5" string="26th" />
            <token id="6" string="overall" />
            <token id="7" string="," />
            <token id="8" string="believed" />
            <token id="9" string="to" />
            <token id="10" string="be" />
            <token id="11" string="the" />
            <token id="12" string="highest" />
            <token id="13" string="finish" />
            <token id="14" string="for" />
            <token id="15" string="a" />
            <token id="16" string="woman" />
            <token id="17" string="in" />
            <token id="18" string="this" />
            <token id="19" string="race" />
          </tokens>
        </chunking>
        <chunking id="8" string="26th overall" type="NP">
          <tokens>
            <token id="5" string="26th" />
            <token id="6" string="overall" />
          </tokens>
        </chunking>
        <chunking id="9" string="a woman" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="woman" />
          </tokens>
        </chunking>
        <chunking id="10" string="be the highest finish for a woman in this race" type="VP">
          <tokens>
            <token id="10" string="be" />
            <token id="11" string="the" />
            <token id="12" string="highest" />
            <token id="13" string="finish" />
            <token id="14" string="for" />
            <token id="15" string="a" />
            <token id="16" string="woman" />
            <token id="17" string="in" />
            <token id="18" string="this" />
            <token id="19" string="race" />
          </tokens>
        </chunking>
        <chunking id="11" string="the highest finish" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="highest" />
            <token id="13" string="finish" />
          </tokens>
        </chunking>
        <chunking id="12" string="Kristiansen" type="NP">
          <tokens>
            <token id="3" string="Kristiansen" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="4">finished</governor>
          <dependent id="1">Still</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">finished</governor>
          <dependent id="3">Kristiansen</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">finished</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">overall</governor>
          <dependent id="5">26th</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">finished</governor>
          <dependent id="6">overall</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="6">overall</governor>
          <dependent id="8">believed</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">finish</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="13">finish</governor>
          <dependent id="10">be</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">finish</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">finish</governor>
          <dependent id="12">highest</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="8">believed</governor>
          <dependent id="13">finish</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">woman</governor>
          <dependent id="14">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">woman</governor>
          <dependent id="15">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">finish</governor>
          <dependent id="16">woman</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">race</governor>
          <dependent id="17">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">race</governor>
          <dependent id="18">this</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">woman</governor>
          <dependent id="19">race</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="26th" type="ORDINAL" score="0.0">
          <tokens>
            <token id="5" string="26th" />
          </tokens>
        </entity>
        <entity id="2" string="Kristiansen" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Kristiansen" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>Joan Benoit Samuelson, who set a world record on this course in 1983, was beset with physical problems that altered her stride at 11 miles, and she finished ninth among the women in 2:37:52.</content>
      <tokens>
        <token id="1" string="Joan" lemma="Joan" stem="joan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="Benoit" lemma="Benoit" stem="benoit" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="Samuelson" lemma="Samuelson" stem="samuelson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="set" lemma="set" stem="set" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="record" lemma="record" stem="record" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="course" lemma="course" stem="cours" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="1983" lemma="1983" stem="1983" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="beset" lemma="beset" stem="beset" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="physical" lemma="physical" stem="physic" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="problems" lemma="problem" stem="problem" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="altered" lemma="alter" stem="alter" pos="VBD" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="her" lemma="she" stem="her" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="24" string="stride" lemma="stride" stem="stride" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="25" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="26" string="11" lemma="11" stem="11" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="true" />
        <token id="27" string="miles" lemma="mile" stem="mile" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="28" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="finished" lemma="finish" stem="finish" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="ninth" lemma="ninth" stem="ninth" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="33" string="among" lemma="among" stem="among" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="35" string="women" lemma="woman" stem="women" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="36" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="2:37:52" lemma="2:37:52" stem="2:37:52" pos="CD" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="38" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (NNP Joan) (NNP Benoit) (NNP Samuelson)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBD set) (NP (DT a) (NN world) (NN record)) (PP (IN on) (NP (DT this) (NN course))) (PP (IN in) (NP (CD 1983)))))) (, ,)) (VP (VBD was) (VP (VBN beset) (PP (IN with) (NP (NP (JJ physical) (NNS problems)) (SBAR (WHNP (WDT that)) (S (VP (VBD altered) (S (NP (PRP her)) (NP (NP (NN stride)) (PP (IN at) (NP (CD 11) (NNS miles))))))))))))) (, ,) (CC and) (S (NP (PRP she)) (VP (VBD finished) (NP (JJ ninth)) (PP (IN among) (NP (DT the) (NNS women))) (PP (IN in) (NP (CD 2:37:52))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the women" type="NP">
          <tokens>
            <token id="34" string="the" />
            <token id="35" string="women" />
          </tokens>
        </chunking>
        <chunking id="2" string="a world record" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="world" />
            <token id="9" string="record" />
          </tokens>
        </chunking>
        <chunking id="3" string="Joan Benoit Samuelson , who set a world record on this course in 1983 ," type="NP">
          <tokens>
            <token id="1" string="Joan" />
            <token id="2" string="Benoit" />
            <token id="3" string="Samuelson" />
            <token id="4" string="," />
            <token id="5" string="who" />
            <token id="6" string="set" />
            <token id="7" string="a" />
            <token id="8" string="world" />
            <token id="9" string="record" />
            <token id="10" string="on" />
            <token id="11" string="this" />
            <token id="12" string="course" />
            <token id="13" string="in" />
            <token id="14" string="1983" />
            <token id="15" string="," />
          </tokens>
        </chunking>
        <chunking id="4" string="who set a world record on this course in 1983" type="SBAR">
          <tokens>
            <token id="5" string="who" />
            <token id="6" string="set" />
            <token id="7" string="a" />
            <token id="8" string="world" />
            <token id="9" string="record" />
            <token id="10" string="on" />
            <token id="11" string="this" />
            <token id="12" string="course" />
            <token id="13" string="in" />
            <token id="14" string="1983" />
          </tokens>
        </chunking>
        <chunking id="5" string="this course" type="NP">
          <tokens>
            <token id="11" string="this" />
            <token id="12" string="course" />
          </tokens>
        </chunking>
        <chunking id="6" string="set a world record on this course in 1983" type="VP">
          <tokens>
            <token id="6" string="set" />
            <token id="7" string="a" />
            <token id="8" string="world" />
            <token id="9" string="record" />
            <token id="10" string="on" />
            <token id="11" string="this" />
            <token id="12" string="course" />
            <token id="13" string="in" />
            <token id="14" string="1983" />
          </tokens>
        </chunking>
        <chunking id="7" string="physical problems that altered her stride at 11 miles" type="NP">
          <tokens>
            <token id="19" string="physical" />
            <token id="20" string="problems" />
            <token id="21" string="that" />
            <token id="22" string="altered" />
            <token id="23" string="her" />
            <token id="24" string="stride" />
            <token id="25" string="at" />
            <token id="26" string="11" />
            <token id="27" string="miles" />
          </tokens>
        </chunking>
        <chunking id="8" string="11 miles" type="NP">
          <tokens>
            <token id="26" string="11" />
            <token id="27" string="miles" />
          </tokens>
        </chunking>
        <chunking id="9" string="was beset with physical problems that altered her stride at 11 miles" type="VP">
          <tokens>
            <token id="16" string="was" />
            <token id="17" string="beset" />
            <token id="18" string="with" />
            <token id="19" string="physical" />
            <token id="20" string="problems" />
            <token id="21" string="that" />
            <token id="22" string="altered" />
            <token id="23" string="her" />
            <token id="24" string="stride" />
            <token id="25" string="at" />
            <token id="26" string="11" />
            <token id="27" string="miles" />
          </tokens>
        </chunking>
        <chunking id="10" string="physical problems" type="NP">
          <tokens>
            <token id="19" string="physical" />
            <token id="20" string="problems" />
          </tokens>
        </chunking>
        <chunking id="11" string="altered her stride at 11 miles" type="VP">
          <tokens>
            <token id="22" string="altered" />
            <token id="23" string="her" />
            <token id="24" string="stride" />
            <token id="25" string="at" />
            <token id="26" string="11" />
            <token id="27" string="miles" />
          </tokens>
        </chunking>
        <chunking id="12" string="stride" type="NP">
          <tokens>
            <token id="24" string="stride" />
          </tokens>
        </chunking>
        <chunking id="13" string="she" type="NP">
          <tokens>
            <token id="30" string="she" />
          </tokens>
        </chunking>
        <chunking id="14" string="Joan Benoit Samuelson" type="NP">
          <tokens>
            <token id="1" string="Joan" />
            <token id="2" string="Benoit" />
            <token id="3" string="Samuelson" />
          </tokens>
        </chunking>
        <chunking id="15" string="stride at 11 miles" type="NP">
          <tokens>
            <token id="24" string="stride" />
            <token id="25" string="at" />
            <token id="26" string="11" />
            <token id="27" string="miles" />
          </tokens>
        </chunking>
        <chunking id="16" string="2:37:52" type="NP">
          <tokens>
            <token id="37" string="2:37:52" />
          </tokens>
        </chunking>
        <chunking id="17" string="1983" type="NP">
          <tokens>
            <token id="14" string="1983" />
          </tokens>
        </chunking>
        <chunking id="18" string="that altered her stride at 11 miles" type="SBAR">
          <tokens>
            <token id="21" string="that" />
            <token id="22" string="altered" />
            <token id="23" string="her" />
            <token id="24" string="stride" />
            <token id="25" string="at" />
            <token id="26" string="11" />
            <token id="27" string="miles" />
          </tokens>
        </chunking>
        <chunking id="19" string="her" type="NP">
          <tokens>
            <token id="23" string="her" />
          </tokens>
        </chunking>
        <chunking id="20" string="ninth" type="NP">
          <tokens>
            <token id="32" string="ninth" />
          </tokens>
        </chunking>
        <chunking id="21" string="beset with physical problems that altered her stride at 11 miles" type="VP">
          <tokens>
            <token id="17" string="beset" />
            <token id="18" string="with" />
            <token id="19" string="physical" />
            <token id="20" string="problems" />
            <token id="21" string="that" />
            <token id="22" string="altered" />
            <token id="23" string="her" />
            <token id="24" string="stride" />
            <token id="25" string="at" />
            <token id="26" string="11" />
            <token id="27" string="miles" />
          </tokens>
        </chunking>
        <chunking id="22" string="finished ninth among the women in 2:37:52" type="VP">
          <tokens>
            <token id="31" string="finished" />
            <token id="32" string="ninth" />
            <token id="33" string="among" />
            <token id="34" string="the" />
            <token id="35" string="women" />
            <token id="36" string="in" />
            <token id="37" string="2:37:52" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">Samuelson</governor>
          <dependent id="1">Joan</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Samuelson</governor>
          <dependent id="2">Benoit</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="17">beset</governor>
          <dependent id="3">Samuelson</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">set</governor>
          <dependent id="5">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="3">Samuelson</governor>
          <dependent id="6">set</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">record</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">record</governor>
          <dependent id="8">world</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">set</governor>
          <dependent id="9">record</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">course</governor>
          <dependent id="10">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">course</governor>
          <dependent id="11">this</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">set</governor>
          <dependent id="12">course</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">1983</governor>
          <dependent id="13">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">set</governor>
          <dependent id="14">1983</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="17">beset</governor>
          <dependent id="16">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="17">beset</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">problems</governor>
          <dependent id="18">with</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">problems</governor>
          <dependent id="19">physical</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">beset</governor>
          <dependent id="20">problems</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">altered</governor>
          <dependent id="21">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="20">problems</governor>
          <dependent id="22">altered</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">stride</governor>
          <dependent id="23">her</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="22">altered</governor>
          <dependent id="24">stride</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">miles</governor>
          <dependent id="25">at</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="27">miles</governor>
          <dependent id="26">11</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">stride</governor>
          <dependent id="27">miles</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="17">beset</governor>
          <dependent id="29">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="31">finished</governor>
          <dependent id="30">she</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">beset</governor>
          <dependent id="31">finished</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="31">finished</governor>
          <dependent id="32">ninth</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">women</governor>
          <dependent id="33">among</dependent>
        </dependency>
        <dependency type="det">
          <governor id="35">women</governor>
          <dependent id="34">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">finished</governor>
          <dependent id="35">women</dependent>
        </dependency>
        <dependency type="case">
          <governor id="37">2:37:52</governor>
          <dependent id="36">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">finished</governor>
          <dependent id="37">2:37:52</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Joan Benoit Samuelson" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Joan" />
            <token id="2" string="Benoit" />
            <token id="3" string="Samuelson" />
          </tokens>
        </entity>
        <entity id="2" string="2:37:52" type="TIME" score="0.0">
          <tokens>
            <token id="37" string="2:37:52" />
          </tokens>
        </entity>
        <entity id="3" string="1983" type="DATE" score="0.0">
          <tokens>
            <token id="14" string="1983" />
          </tokens>
        </entity>
        <entity id="4" string="ninth" type="ORDINAL" score="0.0">
          <tokens>
            <token id="32" string="ninth" />
          </tokens>
        </entity>
        <entity id="5" string="11" type="NUMBER" score="0.0">
          <tokens>
            <token id="26" string="11" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>It was the worst marathon performance of her career.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="worst" lemma="worst" stem="worst" pos="JJS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="marathon" lemma="marathon" stem="marathon" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="performance" lemma="performance" stem="perform" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="9" string="career" lemma="career" stem="career" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP It)) (VP (VBD was) (NP (NP (DT the) (JJS worst) (NN marathon) (NN performance)) (PP (IN of) (NP (PRP$ her) (NN career))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the worst marathon performance" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="worst" />
            <token id="5" string="marathon" />
            <token id="6" string="performance" />
          </tokens>
        </chunking>
        <chunking id="2" string="her career" type="NP">
          <tokens>
            <token id="8" string="her" />
            <token id="9" string="career" />
          </tokens>
        </chunking>
        <chunking id="3" string="was the worst marathon performance of her career" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="the" />
            <token id="4" string="worst" />
            <token id="5" string="marathon" />
            <token id="6" string="performance" />
            <token id="7" string="of" />
            <token id="8" string="her" />
            <token id="9" string="career" />
          </tokens>
        </chunking>
        <chunking id="4" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="5" string="the worst marathon performance of her career" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="worst" />
            <token id="5" string="marathon" />
            <token id="6" string="performance" />
            <token id="7" string="of" />
            <token id="8" string="her" />
            <token id="9" string="career" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="6">performance</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">performance</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">performance</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">performance</governor>
          <dependent id="4">worst</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">performance</governor>
          <dependent id="5">marathon</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">performance</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">career</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="9">career</governor>
          <dependent id="8">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">performance</governor>
          <dependent id="9">career</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>It also was the first time Kristiansen had beaten Samuelson in a marathon.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="true" />
        <token id="6" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="Kristiansen" lemma="Kristiansen" stem="kristiansen" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="8" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="beaten" lemma="beat" stem="beaten" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="Samuelson" lemma="Samuelson" stem="samuelson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="11" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="marathon" lemma="marathon" stem="marathon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP It)) (ADVP (RB also)) (VP (VBD was) (NP (NP (DT the) (JJ first) (NN time)) (SBAR (S (NP (NNP Kristiansen)) (VP (VBD had) (VP (VBN beaten) (NP (NP (NNP Samuelson)) (PP (IN in) (NP (DT a) (NN marathon)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the first time Kristiansen had beaten Samuelson in a marathon" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="first" />
            <token id="6" string="time" />
            <token id="7" string="Kristiansen" />
            <token id="8" string="had" />
            <token id="9" string="beaten" />
            <token id="10" string="Samuelson" />
            <token id="11" string="in" />
            <token id="12" string="a" />
            <token id="13" string="marathon" />
          </tokens>
        </chunking>
        <chunking id="2" string="was the first time Kristiansen had beaten Samuelson in a marathon" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="the" />
            <token id="5" string="first" />
            <token id="6" string="time" />
            <token id="7" string="Kristiansen" />
            <token id="8" string="had" />
            <token id="9" string="beaten" />
            <token id="10" string="Samuelson" />
            <token id="11" string="in" />
            <token id="12" string="a" />
            <token id="13" string="marathon" />
          </tokens>
        </chunking>
        <chunking id="3" string="the first time" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="first" />
            <token id="6" string="time" />
          </tokens>
        </chunking>
        <chunking id="4" string="Kristiansen had beaten Samuelson in a marathon" type="SBAR">
          <tokens>
            <token id="7" string="Kristiansen" />
            <token id="8" string="had" />
            <token id="9" string="beaten" />
            <token id="10" string="Samuelson" />
            <token id="11" string="in" />
            <token id="12" string="a" />
            <token id="13" string="marathon" />
          </tokens>
        </chunking>
        <chunking id="5" string="Samuelson in a marathon" type="NP">
          <tokens>
            <token id="10" string="Samuelson" />
            <token id="11" string="in" />
            <token id="12" string="a" />
            <token id="13" string="marathon" />
          </tokens>
        </chunking>
        <chunking id="6" string="beaten Samuelson in a marathon" type="VP">
          <tokens>
            <token id="9" string="beaten" />
            <token id="10" string="Samuelson" />
            <token id="11" string="in" />
            <token id="12" string="a" />
            <token id="13" string="marathon" />
          </tokens>
        </chunking>
        <chunking id="7" string="had beaten Samuelson in a marathon" type="VP">
          <tokens>
            <token id="8" string="had" />
            <token id="9" string="beaten" />
            <token id="10" string="Samuelson" />
            <token id="11" string="in" />
            <token id="12" string="a" />
            <token id="13" string="marathon" />
          </tokens>
        </chunking>
        <chunking id="8" string="Samuelson" type="NP">
          <tokens>
            <token id="10" string="Samuelson" />
          </tokens>
        </chunking>
        <chunking id="9" string="a marathon" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="marathon" />
          </tokens>
        </chunking>
        <chunking id="10" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="11" string="Kristiansen" type="NP">
          <tokens>
            <token id="7" string="Kristiansen" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="6">time</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">time</governor>
          <dependent id="2">also</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">time</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">time</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">time</governor>
          <dependent id="5">first</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">time</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">beaten</governor>
          <dependent id="7">Kristiansen</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">beaten</governor>
          <dependent id="8">had</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="6">time</governor>
          <dependent id="9">beaten</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">beaten</governor>
          <dependent id="10">Samuelson</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">marathon</governor>
          <dependent id="11">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">marathon</governor>
          <dependent id="12">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">Samuelson</governor>
          <dependent id="13">marathon</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="5" string="first" />
          </tokens>
        </entity>
        <entity id="2" string="Samuelson" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Samuelson" />
          </tokens>
        </entity>
        <entity id="3" string="Kristiansen" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Kristiansen" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>In an emotional news conference afterward, Samuelson, who won the first women&amp;apost;s Olympic marathon in 1984 at Los Angeles, tearfully conceded that she might have run her last marathon for some time.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="emotional" lemma="emotional" stem="emot" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="news" lemma="news" stem="new" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="conference" lemma="conference" stem="confer" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="afterward" lemma="afterward" stem="afterward" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Samuelson" lemma="Samuelson" stem="samuelson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="won" lemma="win" stem="won" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="true" />
        <token id="14" string="women" lemma="woman" stem="women" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="Olympic" lemma="Olympic" stem="olympic" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="true" />
        <token id="17" string="marathon" lemma="marathon" stem="marathon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="1984" lemma="1984" stem="1984" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="20" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="Los" lemma="Los" stem="lo" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="22" string="Angeles" lemma="Angeles" stem="angele" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="tearfully" lemma="tearfully" stem="tearfulli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="conceded" lemma="concede" stem="conced" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="28" string="might" lemma="might" stem="might" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="run" lemma="run" stem="run" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="32" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="marathon" lemma="marathon" stem="marathon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (ADVP (NP (DT an) (JJ emotional) (NN news) (NN conference)) (RB afterward))) (, ,) (NP (NP (NNP Samuelson)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBD won) (NP (NP (DT the) (JJ first) (NNS women) (POS 's)) (NNP Olympic) (NN marathon)) (PP (IN in) (NP (CD 1984))) (PP (IN at) (NP (NNP Los) (NNP Angeles)))))) (, ,)) (ADVP (RB tearfully)) (VP (VBD conceded) (SBAR (IN that) (S (NP (PRP she)) (VP (MD might) (VP (VB have) (VP (VBN run) (NP (PRP$ her) (JJ last) (NN marathon)) (PP (IN for) (NP (DT some) (NN time))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="might have run her last marathon for some time" type="VP">
          <tokens>
            <token id="28" string="might" />
            <token id="29" string="have" />
            <token id="30" string="run" />
            <token id="31" string="her" />
            <token id="32" string="last" />
            <token id="33" string="marathon" />
            <token id="34" string="for" />
            <token id="35" string="some" />
            <token id="36" string="time" />
          </tokens>
        </chunking>
        <chunking id="2" string="some time" type="NP">
          <tokens>
            <token id="35" string="some" />
            <token id="36" string="time" />
          </tokens>
        </chunking>
        <chunking id="3" string="her last marathon" type="NP">
          <tokens>
            <token id="31" string="her" />
            <token id="32" string="last" />
            <token id="33" string="marathon" />
          </tokens>
        </chunking>
        <chunking id="4" string="Samuelson" type="NP">
          <tokens>
            <token id="8" string="Samuelson" />
          </tokens>
        </chunking>
        <chunking id="5" string="the first women 's Olympic marathon" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="first" />
            <token id="14" string="women" />
            <token id="15" string="'s" />
            <token id="16" string="Olympic" />
            <token id="17" string="marathon" />
          </tokens>
        </chunking>
        <chunking id="6" string="Samuelson , who won the first women 's Olympic marathon in 1984 at Los Angeles ," type="NP">
          <tokens>
            <token id="8" string="Samuelson" />
            <token id="9" string="," />
            <token id="10" string="who" />
            <token id="11" string="won" />
            <token id="12" string="the" />
            <token id="13" string="first" />
            <token id="14" string="women" />
            <token id="15" string="'s" />
            <token id="16" string="Olympic" />
            <token id="17" string="marathon" />
            <token id="18" string="in" />
            <token id="19" string="1984" />
            <token id="20" string="at" />
            <token id="21" string="Los" />
            <token id="22" string="Angeles" />
            <token id="23" string="," />
          </tokens>
        </chunking>
        <chunking id="7" string="the first women 's" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="first" />
            <token id="14" string="women" />
            <token id="15" string="'s" />
          </tokens>
        </chunking>
        <chunking id="8" string="she" type="NP">
          <tokens>
            <token id="27" string="she" />
          </tokens>
        </chunking>
        <chunking id="9" string="have run her last marathon for some time" type="VP">
          <tokens>
            <token id="29" string="have" />
            <token id="30" string="run" />
            <token id="31" string="her" />
            <token id="32" string="last" />
            <token id="33" string="marathon" />
            <token id="34" string="for" />
            <token id="35" string="some" />
            <token id="36" string="time" />
          </tokens>
        </chunking>
        <chunking id="10" string="run her last marathon for some time" type="VP">
          <tokens>
            <token id="30" string="run" />
            <token id="31" string="her" />
            <token id="32" string="last" />
            <token id="33" string="marathon" />
            <token id="34" string="for" />
            <token id="35" string="some" />
            <token id="36" string="time" />
          </tokens>
        </chunking>
        <chunking id="11" string="conceded that she might have run her last marathon for some time" type="VP">
          <tokens>
            <token id="25" string="conceded" />
            <token id="26" string="that" />
            <token id="27" string="she" />
            <token id="28" string="might" />
            <token id="29" string="have" />
            <token id="30" string="run" />
            <token id="31" string="her" />
            <token id="32" string="last" />
            <token id="33" string="marathon" />
            <token id="34" string="for" />
            <token id="35" string="some" />
            <token id="36" string="time" />
          </tokens>
        </chunking>
        <chunking id="12" string="1984" type="NP">
          <tokens>
            <token id="19" string="1984" />
          </tokens>
        </chunking>
        <chunking id="13" string="that she might have run her last marathon for some time" type="SBAR">
          <tokens>
            <token id="26" string="that" />
            <token id="27" string="she" />
            <token id="28" string="might" />
            <token id="29" string="have" />
            <token id="30" string="run" />
            <token id="31" string="her" />
            <token id="32" string="last" />
            <token id="33" string="marathon" />
            <token id="34" string="for" />
            <token id="35" string="some" />
            <token id="36" string="time" />
          </tokens>
        </chunking>
        <chunking id="14" string="an emotional news conference" type="NP">
          <tokens>
            <token id="2" string="an" />
            <token id="3" string="emotional" />
            <token id="4" string="news" />
            <token id="5" string="conference" />
          </tokens>
        </chunking>
        <chunking id="15" string="Los Angeles" type="NP">
          <tokens>
            <token id="21" string="Los" />
            <token id="22" string="Angeles" />
          </tokens>
        </chunking>
        <chunking id="16" string="who won the first women 's Olympic marathon in 1984 at Los Angeles" type="SBAR">
          <tokens>
            <token id="10" string="who" />
            <token id="11" string="won" />
            <token id="12" string="the" />
            <token id="13" string="first" />
            <token id="14" string="women" />
            <token id="15" string="'s" />
            <token id="16" string="Olympic" />
            <token id="17" string="marathon" />
            <token id="18" string="in" />
            <token id="19" string="1984" />
            <token id="20" string="at" />
            <token id="21" string="Los" />
            <token id="22" string="Angeles" />
          </tokens>
        </chunking>
        <chunking id="17" string="won the first women 's Olympic marathon in 1984 at Los Angeles" type="VP">
          <tokens>
            <token id="11" string="won" />
            <token id="12" string="the" />
            <token id="13" string="first" />
            <token id="14" string="women" />
            <token id="15" string="'s" />
            <token id="16" string="Olympic" />
            <token id="17" string="marathon" />
            <token id="18" string="in" />
            <token id="19" string="1984" />
            <token id="20" string="at" />
            <token id="21" string="Los" />
            <token id="22" string="Angeles" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="6">afterward</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">conference</governor>
          <dependent id="2">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">conference</governor>
          <dependent id="3">emotional</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">conference</governor>
          <dependent id="4">news</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="6">afterward</governor>
          <dependent id="5">conference</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="25">conceded</governor>
          <dependent id="6">afterward</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">conceded</governor>
          <dependent id="8">Samuelson</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">won</governor>
          <dependent id="10">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="8">Samuelson</governor>
          <dependent id="11">won</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">women</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">women</governor>
          <dependent id="13">first</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="17">marathon</governor>
          <dependent id="14">women</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">women</governor>
          <dependent id="15">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">marathon</governor>
          <dependent id="16">Olympic</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">won</governor>
          <dependent id="17">marathon</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">1984</governor>
          <dependent id="18">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">won</governor>
          <dependent id="19">1984</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">Angeles</governor>
          <dependent id="20">at</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">Angeles</governor>
          <dependent id="21">Los</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">won</governor>
          <dependent id="22">Angeles</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="25">conceded</governor>
          <dependent id="24">tearfully</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="25">conceded</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="30">run</governor>
          <dependent id="26">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="30">run</governor>
          <dependent id="27">she</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="30">run</governor>
          <dependent id="28">might</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="30">run</governor>
          <dependent id="29">have</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="25">conceded</governor>
          <dependent id="30">run</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="33">marathon</governor>
          <dependent id="31">her</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="33">marathon</governor>
          <dependent id="32">last</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="30">run</governor>
          <dependent id="33">marathon</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">time</governor>
          <dependent id="34">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="36">time</governor>
          <dependent id="35">some</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">run</governor>
          <dependent id="36">time</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="13" string="first" />
          </tokens>
        </entity>
        <entity id="2" string="1984" type="DATE" score="0.0">
          <tokens>
            <token id="19" string="1984" />
          </tokens>
        </entity>
        <entity id="3" string="Samuelson" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Samuelson" />
          </tokens>
        </entity>
        <entity id="4" string="Los Angeles" type="LOCATION" score="0.0">
          <tokens>
            <token id="21" string="Los" />
            <token id="22" string="Angeles" />
          </tokens>
        </entity>
        <entity id="5" string="Olympic" type="MISC" score="0.0">
          <tokens>
            <token id="16" string="Olympic" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>But the story of Monday&amp;apost;s 93rd Boston race was Mekonnen and his nation of 42 million, which has reemerged as a force to be reckoned with in marathon running.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="story" lemma="story" stem="stori" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Monday" lemma="Monday" stem="mondai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="6" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="93rd" lemma="93rd" stem="93rd" pos="JJ" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="8" string="Boston" lemma="Boston" stem="boston" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="9" string="race" lemma="race" stem="race" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Mekonnen" lemma="Mekonnen" stem="mekonnen" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="12" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="nation" lemma="nation" stem="nation" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="42" lemma="42" stem="42" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="17" string="million" lemma="million" stem="million" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="reemerged" lemma="reemerge" stem="reemerg" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="force" lemma="force" stem="forc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="reckoned" lemma="reckon" stem="reckon" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="marathon" lemma="marathon" stem="marathon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="running" lemma="running" stem="run" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (NP (DT the) (NN story)) (PP (IN of) (NP (NP (NNP Monday) (POS 's)) (JJ 93rd) (NNP Boston) (NN race)))) (VP (VBD was) (NP (NP (NNP Mekonnen)) (CC and) (NP (NP (PRP$ his) (NN nation)) (PP (IN of) (NP (NP (QP (CD 42) (CD million))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ has) (VP (VBN reemerged) (PP (IN as) (NP (DT a) (NN force))) (S (VP (TO to) (VP (VB be) (VP (VBN reckoned) (PP (IN with) (PP (IN in) (NP (NN marathon) (NN running))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Monday 's 93rd Boston race" type="NP">
          <tokens>
            <token id="5" string="Monday" />
            <token id="6" string="'s" />
            <token id="7" string="93rd" />
            <token id="8" string="Boston" />
            <token id="9" string="race" />
          </tokens>
        </chunking>
        <chunking id="2" string="his nation of 42 million , which has reemerged as a force to be reckoned with in marathon running" type="NP">
          <tokens>
            <token id="13" string="his" />
            <token id="14" string="nation" />
            <token id="15" string="of" />
            <token id="16" string="42" />
            <token id="17" string="million" />
            <token id="18" string="," />
            <token id="19" string="which" />
            <token id="20" string="has" />
            <token id="21" string="reemerged" />
            <token id="22" string="as" />
            <token id="23" string="a" />
            <token id="24" string="force" />
            <token id="25" string="to" />
            <token id="26" string="be" />
            <token id="27" string="reckoned" />
            <token id="28" string="with" />
            <token id="29" string="in" />
            <token id="30" string="marathon" />
            <token id="31" string="running" />
          </tokens>
        </chunking>
        <chunking id="3" string="a force" type="NP">
          <tokens>
            <token id="23" string="a" />
            <token id="24" string="force" />
          </tokens>
        </chunking>
        <chunking id="4" string="Monday 's" type="NP">
          <tokens>
            <token id="5" string="Monday" />
            <token id="6" string="'s" />
          </tokens>
        </chunking>
        <chunking id="5" string="Mekonnen and his nation of 42 million , which has reemerged as a force to be reckoned with in marathon running" type="NP">
          <tokens>
            <token id="11" string="Mekonnen" />
            <token id="12" string="and" />
            <token id="13" string="his" />
            <token id="14" string="nation" />
            <token id="15" string="of" />
            <token id="16" string="42" />
            <token id="17" string="million" />
            <token id="18" string="," />
            <token id="19" string="which" />
            <token id="20" string="has" />
            <token id="21" string="reemerged" />
            <token id="22" string="as" />
            <token id="23" string="a" />
            <token id="24" string="force" />
            <token id="25" string="to" />
            <token id="26" string="be" />
            <token id="27" string="reckoned" />
            <token id="28" string="with" />
            <token id="29" string="in" />
            <token id="30" string="marathon" />
            <token id="31" string="running" />
          </tokens>
        </chunking>
        <chunking id="6" string="the story of Monday 's 93rd Boston race" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="story" />
            <token id="4" string="of" />
            <token id="5" string="Monday" />
            <token id="6" string="'s" />
            <token id="7" string="93rd" />
            <token id="8" string="Boston" />
            <token id="9" string="race" />
          </tokens>
        </chunking>
        <chunking id="7" string="reemerged as a force to be reckoned with in marathon running" type="VP">
          <tokens>
            <token id="21" string="reemerged" />
            <token id="22" string="as" />
            <token id="23" string="a" />
            <token id="24" string="force" />
            <token id="25" string="to" />
            <token id="26" string="be" />
            <token id="27" string="reckoned" />
            <token id="28" string="with" />
            <token id="29" string="in" />
            <token id="30" string="marathon" />
            <token id="31" string="running" />
          </tokens>
        </chunking>
        <chunking id="8" string="42 million , which has reemerged as a force to be reckoned with in marathon running" type="NP">
          <tokens>
            <token id="16" string="42" />
            <token id="17" string="million" />
            <token id="18" string="," />
            <token id="19" string="which" />
            <token id="20" string="has" />
            <token id="21" string="reemerged" />
            <token id="22" string="as" />
            <token id="23" string="a" />
            <token id="24" string="force" />
            <token id="25" string="to" />
            <token id="26" string="be" />
            <token id="27" string="reckoned" />
            <token id="28" string="with" />
            <token id="29" string="in" />
            <token id="30" string="marathon" />
            <token id="31" string="running" />
          </tokens>
        </chunking>
        <chunking id="9" string="be reckoned with in marathon running" type="VP">
          <tokens>
            <token id="26" string="be" />
            <token id="27" string="reckoned" />
            <token id="28" string="with" />
            <token id="29" string="in" />
            <token id="30" string="marathon" />
            <token id="31" string="running" />
          </tokens>
        </chunking>
        <chunking id="10" string="his nation" type="NP">
          <tokens>
            <token id="13" string="his" />
            <token id="14" string="nation" />
          </tokens>
        </chunking>
        <chunking id="11" string="42 million" type="NP">
          <tokens>
            <token id="16" string="42" />
            <token id="17" string="million" />
          </tokens>
        </chunking>
        <chunking id="12" string="the story" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="story" />
          </tokens>
        </chunking>
        <chunking id="13" string="Mekonnen" type="NP">
          <tokens>
            <token id="11" string="Mekonnen" />
          </tokens>
        </chunking>
        <chunking id="14" string="has reemerged as a force to be reckoned with in marathon running" type="VP">
          <tokens>
            <token id="20" string="has" />
            <token id="21" string="reemerged" />
            <token id="22" string="as" />
            <token id="23" string="a" />
            <token id="24" string="force" />
            <token id="25" string="to" />
            <token id="26" string="be" />
            <token id="27" string="reckoned" />
            <token id="28" string="with" />
            <token id="29" string="in" />
            <token id="30" string="marathon" />
            <token id="31" string="running" />
          </tokens>
        </chunking>
        <chunking id="15" string="was Mekonnen and his nation of 42 million , which has reemerged as a force to be reckoned with in marathon running" type="VP">
          <tokens>
            <token id="10" string="was" />
            <token id="11" string="Mekonnen" />
            <token id="12" string="and" />
            <token id="13" string="his" />
            <token id="14" string="nation" />
            <token id="15" string="of" />
            <token id="16" string="42" />
            <token id="17" string="million" />
            <token id="18" string="," />
            <token id="19" string="which" />
            <token id="20" string="has" />
            <token id="21" string="reemerged" />
            <token id="22" string="as" />
            <token id="23" string="a" />
            <token id="24" string="force" />
            <token id="25" string="to" />
            <token id="26" string="be" />
            <token id="27" string="reckoned" />
            <token id="28" string="with" />
            <token id="29" string="in" />
            <token id="30" string="marathon" />
            <token id="31" string="running" />
          </tokens>
        </chunking>
        <chunking id="16" string="to be reckoned with in marathon running" type="VP">
          <tokens>
            <token id="25" string="to" />
            <token id="26" string="be" />
            <token id="27" string="reckoned" />
            <token id="28" string="with" />
            <token id="29" string="in" />
            <token id="30" string="marathon" />
            <token id="31" string="running" />
          </tokens>
        </chunking>
        <chunking id="17" string="marathon running" type="NP">
          <tokens>
            <token id="30" string="marathon" />
            <token id="31" string="running" />
          </tokens>
        </chunking>
        <chunking id="18" string="reckoned with in marathon running" type="VP">
          <tokens>
            <token id="27" string="reckoned" />
            <token id="28" string="with" />
            <token id="29" string="in" />
            <token id="30" string="marathon" />
            <token id="31" string="running" />
          </tokens>
        </chunking>
        <chunking id="19" string="which has reemerged as a force to be reckoned with in marathon running" type="SBAR">
          <tokens>
            <token id="19" string="which" />
            <token id="20" string="has" />
            <token id="21" string="reemerged" />
            <token id="22" string="as" />
            <token id="23" string="a" />
            <token id="24" string="force" />
            <token id="25" string="to" />
            <token id="26" string="be" />
            <token id="27" string="reckoned" />
            <token id="28" string="with" />
            <token id="29" string="in" />
            <token id="30" string="marathon" />
            <token id="31" string="running" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="11">Mekonnen</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">story</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">Mekonnen</governor>
          <dependent id="3">story</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">race</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="9">race</governor>
          <dependent id="5">Monday</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">Monday</governor>
          <dependent id="6">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">race</governor>
          <dependent id="7">93rd</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">race</governor>
          <dependent id="8">Boston</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">story</governor>
          <dependent id="9">race</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="11">Mekonnen</governor>
          <dependent id="10">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">Mekonnen</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="11">Mekonnen</governor>
          <dependent id="12">and</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="14">nation</governor>
          <dependent id="13">his</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">Mekonnen</governor>
          <dependent id="14">nation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">million</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">million</governor>
          <dependent id="16">42</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">nation</governor>
          <dependent id="17">million</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">reemerged</governor>
          <dependent id="19">which</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="21">reemerged</governor>
          <dependent id="20">has</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="17">million</governor>
          <dependent id="21">reemerged</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">force</governor>
          <dependent id="22">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">force</governor>
          <dependent id="23">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">reemerged</governor>
          <dependent id="24">force</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="27">reckoned</governor>
          <dependent id="25">to</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="27">reckoned</governor>
          <dependent id="26">be</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="21">reemerged</governor>
          <dependent id="27">reckoned</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">running</governor>
          <dependent id="28">with</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">running</governor>
          <dependent id="29">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">running</governor>
          <dependent id="30">marathon</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">reckoned</governor>
          <dependent id="31">running</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Mekonnen" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Mekonnen" />
          </tokens>
        </entity>
        <entity id="2" string="93rd Boston" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="7" string="93rd" />
            <token id="8" string="Boston" />
          </tokens>
        </entity>
        <entity id="3" string="Monday" type="DATE" score="0.0">
          <tokens>
            <token id="5" string="Monday" />
          </tokens>
        </entity>
        <entity id="4" string="42 million" type="NUMBER" score="0.0">
          <tokens>
            <token id="16" string="42" />
            <token id="17" string="million" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="17" has_coreference="false">
      <content>In two days, Ethiopian runners have won three major marathons.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="3" string="days" lemma="day" stem="dai" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Ethiopian" lemma="ethiopian" stem="ethiopian" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="6" string="runners" lemma="runner" stem="runner" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="won" lemma="win" stem="won" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="three" lemma="three" stem="three" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="10" string="major" lemma="major" stem="major" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="marathons" lemma="marathon" stem="marathon" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (CD two) (NNS days))) (, ,) (NP (JJ Ethiopian) (NNS runners)) (VP (VBP have) (VP (VBN won) (NP (CD three) (JJ major) (NNS marathons)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="two days" type="NP">
          <tokens>
            <token id="2" string="two" />
            <token id="3" string="days" />
          </tokens>
        </chunking>
        <chunking id="2" string="won three major marathons" type="VP">
          <tokens>
            <token id="8" string="won" />
            <token id="9" string="three" />
            <token id="10" string="major" />
            <token id="11" string="marathons" />
          </tokens>
        </chunking>
        <chunking id="3" string="Ethiopian runners" type="NP">
          <tokens>
            <token id="5" string="Ethiopian" />
            <token id="6" string="runners" />
          </tokens>
        </chunking>
        <chunking id="4" string="have won three major marathons" type="VP">
          <tokens>
            <token id="7" string="have" />
            <token id="8" string="won" />
            <token id="9" string="three" />
            <token id="10" string="major" />
            <token id="11" string="marathons" />
          </tokens>
        </chunking>
        <chunking id="5" string="three major marathons" type="NP">
          <tokens>
            <token id="9" string="three" />
            <token id="10" string="major" />
            <token id="11" string="marathons" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">days</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="3">days</governor>
          <dependent id="2">two</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">won</governor>
          <dependent id="3">days</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">runners</governor>
          <dependent id="5">Ethiopian</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">won</governor>
          <dependent id="6">runners</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">won</governor>
          <dependent id="7">have</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">won</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="11">marathons</governor>
          <dependent id="9">three</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">marathons</governor>
          <dependent id="10">major</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">won</governor>
          <dependent id="11">marathons</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="two days" type="DURATION" score="0.0">
          <tokens>
            <token id="2" string="two" />
            <token id="3" string="days" />
          </tokens>
        </entity>
        <entity id="2" string="Ethiopian" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="5" string="Ethiopian" />
          </tokens>
        </entity>
        <entity id="3" string="three" type="NUMBER" score="0.0">
          <tokens>
            <token id="9" string="three" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="18" has_coreference="true">
      <content>In Rotterdam on Sunday, Belayneh Dinsamo won in 2:08:39.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Rotterdam" lemma="Rotterdam" stem="rotterdam" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="3" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Sunday" lemma="Sunday" stem="sundai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Belayneh" lemma="Belayneh" stem="belayneh" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="7" string="Dinsamo" lemma="Dinsamo" stem="dinsamo" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="8" string="won" lemma="win" stem="won" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="2:08:39" lemma="2:08:39" stem="2:08:39" pos="CD" type="Word" isStopWord="false" ner="TIME" is_referenced="true" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (NP (NNP Rotterdam)) (PP (IN on) (NP (NNP Sunday))))) (, ,) (NP (NNP Belayneh) (NNP Dinsamo)) (VP (VBD won) (PP (IN in) (NP (CD 2:08:39)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="2:08:39" type="NP">
          <tokens>
            <token id="10" string="2:08:39" />
          </tokens>
        </chunking>
        <chunking id="2" string="Rotterdam" type="NP">
          <tokens>
            <token id="2" string="Rotterdam" />
          </tokens>
        </chunking>
        <chunking id="3" string="Rotterdam on Sunday" type="NP">
          <tokens>
            <token id="2" string="Rotterdam" />
            <token id="3" string="on" />
            <token id="4" string="Sunday" />
          </tokens>
        </chunking>
        <chunking id="4" string="Sunday" type="NP">
          <tokens>
            <token id="4" string="Sunday" />
          </tokens>
        </chunking>
        <chunking id="5" string="Belayneh Dinsamo" type="NP">
          <tokens>
            <token id="6" string="Belayneh" />
            <token id="7" string="Dinsamo" />
          </tokens>
        </chunking>
        <chunking id="6" string="won in 2:08:39" type="VP">
          <tokens>
            <token id="8" string="won" />
            <token id="9" string="in" />
            <token id="10" string="2:08:39" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">Rotterdam</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">won</governor>
          <dependent id="2">Rotterdam</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">Sunday</governor>
          <dependent id="3">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">Rotterdam</governor>
          <dependent id="4">Sunday</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Dinsamo</governor>
          <dependent id="6">Belayneh</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">won</governor>
          <dependent id="7">Dinsamo</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">won</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">2:08:39</governor>
          <dependent id="9">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">won</governor>
          <dependent id="10">2:08:39</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="2:08:39" type="TIME" score="0.0">
          <tokens>
            <token id="10" string="2:08:39" />
          </tokens>
        </entity>
        <entity id="2" string="Rotterdam" type="LOCATION" score="0.0">
          <tokens>
            <token id="2" string="Rotterdam" />
          </tokens>
        </entity>
        <entity id="3" string="Sunday" type="DATE" score="0.0">
          <tokens>
            <token id="4" string="Sunday" />
          </tokens>
        </entity>
        <entity id="4" string="Belayneh Dinsamo" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="6" string="Belayneh" />
            <token id="7" string="Dinsamo" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="19" has_coreference="true">
      <content>Dinsamo holds the world record of 2:06:50, set last year on the same course.</content>
      <tokens>
        <token id="1" string="Dinsamo" lemma="Dinsamo" stem="dinsamo" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="holds" lemma="hold" stem="hold" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="record" lemma="record" stem="record" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="2:06:50" lemma="2:06:50" stem="2:06:50" pos="CD" type="Word" isStopWord="false" ner="TIME" is_referenced="true" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="set" lemma="set" stem="set" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="true" />
        <token id="11" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="true" />
        <token id="12" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="same" lemma="same" stem="same" pos="JJ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="course" lemma="course" stem="cours" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Dinsamo)) (VP (VBZ holds) (NP (NP (DT the) (NN world) (NN record)) (PP (IN of) (NP (CD 2:06:50))) (, ,) (VP (VBN set) (NP-TMP (JJ last) (NN year)) (PP (IN on) (NP (DT the) (JJ same) (NN course)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Dinsamo" type="NP">
          <tokens>
            <token id="1" string="Dinsamo" />
          </tokens>
        </chunking>
        <chunking id="2" string="set last year on the same course" type="VP">
          <tokens>
            <token id="9" string="set" />
            <token id="10" string="last" />
            <token id="11" string="year" />
            <token id="12" string="on" />
            <token id="13" string="the" />
            <token id="14" string="same" />
            <token id="15" string="course" />
          </tokens>
        </chunking>
        <chunking id="3" string="the same course" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="same" />
            <token id="15" string="course" />
          </tokens>
        </chunking>
        <chunking id="4" string="2:06:50" type="NP">
          <tokens>
            <token id="7" string="2:06:50" />
          </tokens>
        </chunking>
        <chunking id="5" string="holds the world record of 2:06:50 , set last year on the same course" type="VP">
          <tokens>
            <token id="2" string="holds" />
            <token id="3" string="the" />
            <token id="4" string="world" />
            <token id="5" string="record" />
            <token id="6" string="of" />
            <token id="7" string="2:06:50" />
            <token id="8" string="," />
            <token id="9" string="set" />
            <token id="10" string="last" />
            <token id="11" string="year" />
            <token id="12" string="on" />
            <token id="13" string="the" />
            <token id="14" string="same" />
            <token id="15" string="course" />
          </tokens>
        </chunking>
        <chunking id="6" string="the world record" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="world" />
            <token id="5" string="record" />
          </tokens>
        </chunking>
        <chunking id="7" string="the world record of 2:06:50 , set last year on the same course" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="world" />
            <token id="5" string="record" />
            <token id="6" string="of" />
            <token id="7" string="2:06:50" />
            <token id="8" string="," />
            <token id="9" string="set" />
            <token id="10" string="last" />
            <token id="11" string="year" />
            <token id="12" string="on" />
            <token id="13" string="the" />
            <token id="14" string="same" />
            <token id="15" string="course" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">holds</governor>
          <dependent id="1">Dinsamo</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">holds</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">record</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">record</governor>
          <dependent id="4">world</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">holds</governor>
          <dependent id="5">record</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">2:06:50</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">record</governor>
          <dependent id="7">2:06:50</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="5">record</governor>
          <dependent id="9">set</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">year</governor>
          <dependent id="10">last</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="9">set</governor>
          <dependent id="11">year</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">course</governor>
          <dependent id="12">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">course</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">course</governor>
          <dependent id="14">same</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">set</governor>
          <dependent id="15">course</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Dinsamo" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Dinsamo" />
          </tokens>
        </entity>
        <entity id="2" string="2:06:50" type="TIME" score="0.0">
          <tokens>
            <token id="7" string="2:06:50" />
          </tokens>
        </entity>
        <entity id="3" string="last year" type="DATE" score="0.0">
          <tokens>
            <token id="10" string="last" />
            <token id="11" string="year" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="20" has_coreference="true">
      <content>Also on Sunday, in the World Cup Marathon at Milan, Ethiopians finished 1-2.</content>
      <tokens>
        <token id="1" string="Also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Sunday" lemma="Sunday" stem="sundai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="World" lemma="World" stem="world" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="8" string="Cup" lemma="Cup" stem="cup" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="9" string="Marathon" lemma="Marathon" stem="marathon" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="10" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="Milan" lemma="Milan" stem="milan" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Ethiopians" lemma="Ethiopians" stem="ethiopian" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="14" string="finished" lemma="finish" stem="finish" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="1-2" lemma="1-2" stem="1-2" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (ADVP (RB Also)) (IN on) (NP (NNP Sunday))) (, ,) (PP (IN in) (NP (NP (DT the) (NNP World) (NNP Cup) (NNP Marathon)) (PP (IN at) (NP (NNP Milan))))) (, ,) (NP (NNPS Ethiopians)) (VP (VBD finished) (NP (CD 1-2))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the World Cup Marathon" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="World" />
            <token id="8" string="Cup" />
            <token id="9" string="Marathon" />
          </tokens>
        </chunking>
        <chunking id="2" string="Milan" type="NP">
          <tokens>
            <token id="11" string="Milan" />
          </tokens>
        </chunking>
        <chunking id="3" string="1-2" type="NP">
          <tokens>
            <token id="15" string="1-2" />
          </tokens>
        </chunking>
        <chunking id="4" string="Ethiopians" type="NP">
          <tokens>
            <token id="13" string="Ethiopians" />
          </tokens>
        </chunking>
        <chunking id="5" string="Sunday" type="NP">
          <tokens>
            <token id="3" string="Sunday" />
          </tokens>
        </chunking>
        <chunking id="6" string="finished 1-2" type="VP">
          <tokens>
            <token id="14" string="finished" />
            <token id="15" string="1-2" />
          </tokens>
        </chunking>
        <chunking id="7" string="the World Cup Marathon at Milan" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="World" />
            <token id="8" string="Cup" />
            <token id="9" string="Marathon" />
            <token id="10" string="at" />
            <token id="11" string="Milan" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="3">Sunday</governor>
          <dependent id="1">Also</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">Sunday</governor>
          <dependent id="2">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">finished</governor>
          <dependent id="3">Sunday</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Marathon</governor>
          <dependent id="5">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">Marathon</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Marathon</governor>
          <dependent id="7">World</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Marathon</governor>
          <dependent id="8">Cup</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">finished</governor>
          <dependent id="9">Marathon</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Milan</governor>
          <dependent id="10">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">Marathon</governor>
          <dependent id="11">Milan</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">finished</governor>
          <dependent id="13">Ethiopians</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">finished</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">finished</governor>
          <dependent id="15">1-2</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="World Cup Marathon" type="MISC" score="0.0">
          <tokens>
            <token id="7" string="World" />
            <token id="8" string="Cup" />
            <token id="9" string="Marathon" />
          </tokens>
        </entity>
        <entity id="2" string="Milan" type="LOCATION" score="0.0">
          <tokens>
            <token id="11" string="Milan" />
          </tokens>
        </entity>
        <entity id="3" string="1-2" type="NUMBER" score="0.0">
          <tokens>
            <token id="15" string="1-2" />
          </tokens>
        </entity>
        <entity id="4" string="Ethiopians" type="MISC" score="0.0">
          <tokens>
            <token id="13" string="Ethiopians" />
          </tokens>
        </entity>
        <entity id="5" string="Sunday" type="DATE" score="0.0">
          <tokens>
            <token id="3" string="Sunday" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="21" has_coreference="true">
      <content>Keleke Metaferia won in 2:10:28, and Dereje Nedi was second in 2:10:36.</content>
      <tokens>
        <token id="1" string="Keleke" lemma="Keleke" stem="kelek" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="Metaferia" lemma="Metaferia" stem="metaferia" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="won" lemma="win" stem="won" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="2:10:28" lemma="2:10:28" stem="2:10:28" pos="CD" type="Word" isStopWord="false" ner="TIME" is_referenced="true" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Dereje" lemma="Dereje" stem="derej" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="9" string="Nedi" lemma="Nedi" stem="nedi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="10" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="second" lemma="second" stem="second" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="12" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="13" string="2:10:36" lemma="2:10:36" stem="2:10:36" pos="CD" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NNP Keleke) (NNP Metaferia)) (VP (VBD won) (PP (IN in) (NP (CD 2:10:28))))) (, ,) (CC and) (S (NP (NNP Dereje) (NNP Nedi)) (VP (VBD was) (ADJP (JJ second) (PP (IN in) (NP (CD 2:10:36)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="2:10:28" type="NP">
          <tokens>
            <token id="5" string="2:10:28" />
          </tokens>
        </chunking>
        <chunking id="2" string="Dereje Nedi" type="NP">
          <tokens>
            <token id="8" string="Dereje" />
            <token id="9" string="Nedi" />
          </tokens>
        </chunking>
        <chunking id="3" string="Keleke Metaferia" type="NP">
          <tokens>
            <token id="1" string="Keleke" />
            <token id="2" string="Metaferia" />
          </tokens>
        </chunking>
        <chunking id="4" string="second in 2:10:36" type="ADJP">
          <tokens>
            <token id="11" string="second" />
            <token id="12" string="in" />
            <token id="13" string="2:10:36" />
          </tokens>
        </chunking>
        <chunking id="5" string="2:10:36" type="NP">
          <tokens>
            <token id="13" string="2:10:36" />
          </tokens>
        </chunking>
        <chunking id="6" string="won in 2:10:28" type="VP">
          <tokens>
            <token id="3" string="won" />
            <token id="4" string="in" />
            <token id="5" string="2:10:28" />
          </tokens>
        </chunking>
        <chunking id="7" string="was second in 2:10:36" type="VP">
          <tokens>
            <token id="10" string="was" />
            <token id="11" string="second" />
            <token id="12" string="in" />
            <token id="13" string="2:10:36" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Metaferia</governor>
          <dependent id="1">Keleke</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">won</governor>
          <dependent id="2">Metaferia</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">won</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">2:10:28</governor>
          <dependent id="4">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">won</governor>
          <dependent id="5">2:10:28</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">won</governor>
          <dependent id="7">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Nedi</governor>
          <dependent id="8">Dereje</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">second</governor>
          <dependent id="9">Nedi</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="11">second</governor>
          <dependent id="10">was</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">won</governor>
          <dependent id="11">second</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">2:10:36</governor>
          <dependent id="12">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">second</governor>
          <dependent id="13">2:10:36</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="2:10:28" type="TIME" score="0.0">
          <tokens>
            <token id="5" string="2:10:28" />
          </tokens>
        </entity>
        <entity id="2" string="Dereje Nedi" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Dereje" />
            <token id="9" string="Nedi" />
          </tokens>
        </entity>
        <entity id="3" string="Keleke Metaferia" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Keleke" />
            <token id="2" string="Metaferia" />
          </tokens>
        </entity>
        <entity id="4" string="second in 2:10:36" type="DATE" score="0.0">
          <tokens>
            <token id="11" string="second" />
            <token id="12" string="in" />
            <token id="13" string="2:10:36" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="22" has_coreference="true">
      <content>Ethiopia beat Italy for the World Cup team title with a second-string team.</content>
      <tokens>
        <token id="1" string="Ethiopia" lemma="Ethiopia" stem="ethiopia" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="2" string="beat" lemma="beat" stem="beat" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Italy" lemma="Italy" stem="itali" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="4" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="World" lemma="World" stem="world" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="true" />
        <token id="7" string="Cup" lemma="Cup" stem="cup" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="true" />
        <token id="8" string="team" lemma="team" stem="team" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="title" lemma="title" stem="titl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="second-string" lemma="second-string" stem="second-str" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="team" lemma="team" stem="team" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Ethiopia)) (VP (VBD beat) (NP (NNP Italy)) (PP (IN for) (NP (DT the) (NNP World) (NNP Cup) (NN team) (NN title))) (PP (IN with) (NP (DT a) (JJ second-string) (NN team)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="beat Italy for the World Cup team title with a second-string team" type="VP">
          <tokens>
            <token id="2" string="beat" />
            <token id="3" string="Italy" />
            <token id="4" string="for" />
            <token id="5" string="the" />
            <token id="6" string="World" />
            <token id="7" string="Cup" />
            <token id="8" string="team" />
            <token id="9" string="title" />
            <token id="10" string="with" />
            <token id="11" string="a" />
            <token id="12" string="second-string" />
            <token id="13" string="team" />
          </tokens>
        </chunking>
        <chunking id="2" string="the World Cup team title" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="World" />
            <token id="7" string="Cup" />
            <token id="8" string="team" />
            <token id="9" string="title" />
          </tokens>
        </chunking>
        <chunking id="3" string="Italy" type="NP">
          <tokens>
            <token id="3" string="Italy" />
          </tokens>
        </chunking>
        <chunking id="4" string="Ethiopia" type="NP">
          <tokens>
            <token id="1" string="Ethiopia" />
          </tokens>
        </chunking>
        <chunking id="5" string="a second-string team" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="second-string" />
            <token id="13" string="team" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">beat</governor>
          <dependent id="1">Ethiopia</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">beat</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">beat</governor>
          <dependent id="3">Italy</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">title</governor>
          <dependent id="4">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">title</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">title</governor>
          <dependent id="6">World</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">title</governor>
          <dependent id="7">Cup</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">title</governor>
          <dependent id="8">team</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">beat</governor>
          <dependent id="9">title</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">team</governor>
          <dependent id="10">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">team</governor>
          <dependent id="11">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">team</governor>
          <dependent id="12">second-string</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">beat</governor>
          <dependent id="13">team</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Italy" type="LOCATION" score="0.0">
          <tokens>
            <token id="3" string="Italy" />
          </tokens>
        </entity>
        <entity id="2" string="World Cup" type="MISC" score="0.0">
          <tokens>
            <token id="6" string="World" />
            <token id="7" string="Cup" />
          </tokens>
        </entity>
        <entity id="3" string="Ethiopia" type="LOCATION" score="0.0">
          <tokens>
            <token id="1" string="Ethiopia" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="23" has_coreference="false">
      <content>Nearly a dozen Ethiopian runners have been deployed around the world in this hectic two-week period of spring marathons.</content>
      <tokens>
        <token id="1" string="Nearly" lemma="nearly" stem="nearli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="dozen" lemma="dozen" stem="dozen" pos="NN" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="4" string="Ethiopian" lemma="ethiopian" stem="ethiopian" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="5" string="runners" lemma="runner" stem="runner" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="deployed" lemma="deploy" stem="deploi" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="around" lemma="around" stem="around" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="hectic" lemma="hectic" stem="hectic" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="two-week" lemma="two-week" stem="two-week" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="16" string="period" lemma="period" stem="period" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="spring" lemma="spring" stem="spring" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="19" string="marathons" lemma="marathon" stem="marathon" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (QP (RB Nearly) (DT a) (NN dozen)) (JJ Ethiopian) (NNS runners)) (VP (VBP have) (VP (VBN been) (VP (VBN deployed) (PP (IN around) (NP (NP (DT the) (NN world)) (PP (IN in) (NP (NP (DT this) (JJ hectic) (JJ two-week) (NN period)) (PP (IN of) (NP (NN spring) (NNS marathons)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="this hectic two-week period" type="NP">
          <tokens>
            <token id="13" string="this" />
            <token id="14" string="hectic" />
            <token id="15" string="two-week" />
            <token id="16" string="period" />
          </tokens>
        </chunking>
        <chunking id="2" string="this hectic two-week period of spring marathons" type="NP">
          <tokens>
            <token id="13" string="this" />
            <token id="14" string="hectic" />
            <token id="15" string="two-week" />
            <token id="16" string="period" />
            <token id="17" string="of" />
            <token id="18" string="spring" />
            <token id="19" string="marathons" />
          </tokens>
        </chunking>
        <chunking id="3" string="Nearly a dozen Ethiopian runners" type="NP">
          <tokens>
            <token id="1" string="Nearly" />
            <token id="2" string="a" />
            <token id="3" string="dozen" />
            <token id="4" string="Ethiopian" />
            <token id="5" string="runners" />
          </tokens>
        </chunking>
        <chunking id="4" string="have been deployed around the world in this hectic two-week period of spring marathons" type="VP">
          <tokens>
            <token id="6" string="have" />
            <token id="7" string="been" />
            <token id="8" string="deployed" />
            <token id="9" string="around" />
            <token id="10" string="the" />
            <token id="11" string="world" />
            <token id="12" string="in" />
            <token id="13" string="this" />
            <token id="14" string="hectic" />
            <token id="15" string="two-week" />
            <token id="16" string="period" />
            <token id="17" string="of" />
            <token id="18" string="spring" />
            <token id="19" string="marathons" />
          </tokens>
        </chunking>
        <chunking id="5" string="been deployed around the world in this hectic two-week period of spring marathons" type="VP">
          <tokens>
            <token id="7" string="been" />
            <token id="8" string="deployed" />
            <token id="9" string="around" />
            <token id="10" string="the" />
            <token id="11" string="world" />
            <token id="12" string="in" />
            <token id="13" string="this" />
            <token id="14" string="hectic" />
            <token id="15" string="two-week" />
            <token id="16" string="period" />
            <token id="17" string="of" />
            <token id="18" string="spring" />
            <token id="19" string="marathons" />
          </tokens>
        </chunking>
        <chunking id="6" string="deployed around the world in this hectic two-week period of spring marathons" type="VP">
          <tokens>
            <token id="8" string="deployed" />
            <token id="9" string="around" />
            <token id="10" string="the" />
            <token id="11" string="world" />
            <token id="12" string="in" />
            <token id="13" string="this" />
            <token id="14" string="hectic" />
            <token id="15" string="two-week" />
            <token id="16" string="period" />
            <token id="17" string="of" />
            <token id="18" string="spring" />
            <token id="19" string="marathons" />
          </tokens>
        </chunking>
        <chunking id="7" string="spring marathons" type="NP">
          <tokens>
            <token id="18" string="spring" />
            <token id="19" string="marathons" />
          </tokens>
        </chunking>
        <chunking id="8" string="the world in this hectic two-week period of spring marathons" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="world" />
            <token id="12" string="in" />
            <token id="13" string="this" />
            <token id="14" string="hectic" />
            <token id="15" string="two-week" />
            <token id="16" string="period" />
            <token id="17" string="of" />
            <token id="18" string="spring" />
            <token id="19" string="marathons" />
          </tokens>
        </chunking>
        <chunking id="9" string="the world" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="world" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="3">dozen</governor>
          <dependent id="1">Nearly</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">dozen</governor>
          <dependent id="2">a</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="5">runners</governor>
          <dependent id="3">dozen</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">runners</governor>
          <dependent id="4">Ethiopian</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="8">deployed</governor>
          <dependent id="5">runners</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">deployed</governor>
          <dependent id="6">have</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="8">deployed</governor>
          <dependent id="7">been</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">deployed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">world</governor>
          <dependent id="9">around</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">world</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">deployed</governor>
          <dependent id="11">world</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">period</governor>
          <dependent id="12">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">period</governor>
          <dependent id="13">this</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">period</governor>
          <dependent id="14">hectic</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">period</governor>
          <dependent id="15">two-week</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">world</governor>
          <dependent id="16">period</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">marathons</governor>
          <dependent id="17">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">marathons</governor>
          <dependent id="18">spring</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">period</governor>
          <dependent id="19">marathons</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="spring" type="DATE" score="0.0">
          <tokens>
            <token id="18" string="spring" />
          </tokens>
        </entity>
        <entity id="2" string="dozen" type="NUMBER" score="0.0">
          <tokens>
            <token id="3" string="dozen" />
          </tokens>
        </entity>
        <entity id="3" string="Ethiopian" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="4" string="Ethiopian" />
          </tokens>
        </entity>
        <entity id="4" string="two-week" type="DURATION" score="0.0">
          <tokens>
            <token id="15" string="two-week" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="24" has_coreference="true">
      <content>Two other Ethiopians were in Monday&amp;apost;s Boston race, placing ninth and 18th.</content>
      <tokens>
        <token id="1" string="Two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="2" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Ethiopians" lemma="Ethiopians" stem="ethiopian" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="4" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Monday" lemma="Monday" stem="mondai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="7" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="Boston" lemma="Boston" stem="boston" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="9" string="race" lemma="race" stem="race" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="placing" lemma="place" stem="place" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="ninth" lemma="ninth" stem="ninth" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="13" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="14" string="18th" lemma="18th" stem="18th" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (CD Two)) (NP (JJ other) (NNPS Ethiopians))) (VP (VBD were) (PP (IN in) (NP (NP (NNP Monday) (POS 's)) (NNP Boston) (NN race))) (, ,) (S (VP (VBG placing) (NP (NP (JJ ninth)) (CC and) (NP (JJ 18th)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Monday 's Boston race" type="NP">
          <tokens>
            <token id="6" string="Monday" />
            <token id="7" string="'s" />
            <token id="8" string="Boston" />
            <token id="9" string="race" />
          </tokens>
        </chunking>
        <chunking id="2" string="Monday 's" type="NP">
          <tokens>
            <token id="6" string="Monday" />
            <token id="7" string="'s" />
          </tokens>
        </chunking>
        <chunking id="3" string="were in Monday 's Boston race , placing ninth and 18th" type="VP">
          <tokens>
            <token id="4" string="were" />
            <token id="5" string="in" />
            <token id="6" string="Monday" />
            <token id="7" string="'s" />
            <token id="8" string="Boston" />
            <token id="9" string="race" />
            <token id="10" string="," />
            <token id="11" string="placing" />
            <token id="12" string="ninth" />
            <token id="13" string="and" />
            <token id="14" string="18th" />
          </tokens>
        </chunking>
        <chunking id="4" string="other Ethiopians" type="NP">
          <tokens>
            <token id="2" string="other" />
            <token id="3" string="Ethiopians" />
          </tokens>
        </chunking>
        <chunking id="5" string="ninth" type="NP">
          <tokens>
            <token id="12" string="ninth" />
          </tokens>
        </chunking>
        <chunking id="6" string="Two" type="NP">
          <tokens>
            <token id="1" string="Two" />
          </tokens>
        </chunking>
        <chunking id="7" string="placing ninth and 18th" type="VP">
          <tokens>
            <token id="11" string="placing" />
            <token id="12" string="ninth" />
            <token id="13" string="and" />
            <token id="14" string="18th" />
          </tokens>
        </chunking>
        <chunking id="8" string="18th" type="NP">
          <tokens>
            <token id="14" string="18th" />
          </tokens>
        </chunking>
        <chunking id="9" string="Two other Ethiopians" type="NP">
          <tokens>
            <token id="1" string="Two" />
            <token id="2" string="other" />
            <token id="3" string="Ethiopians" />
          </tokens>
        </chunking>
        <chunking id="10" string="ninth and 18th" type="NP">
          <tokens>
            <token id="12" string="ninth" />
            <token id="13" string="and" />
            <token id="14" string="18th" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="9">race</governor>
          <dependent id="1">Two</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">Ethiopians</governor>
          <dependent id="2">other</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="1">Two</governor>
          <dependent id="3">Ethiopians</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="9">race</governor>
          <dependent id="4">were</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">race</governor>
          <dependent id="5">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="9">race</governor>
          <dependent id="6">Monday</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">Monday</governor>
          <dependent id="7">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">race</governor>
          <dependent id="8">Boston</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">race</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="9">race</governor>
          <dependent id="11">placing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">placing</governor>
          <dependent id="12">ninth</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="12">ninth</governor>
          <dependent id="13">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">ninth</governor>
          <dependent id="14">18th</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ethiopians" type="MISC" score="0.0">
          <tokens>
            <token id="3" string="Ethiopians" />
          </tokens>
        </entity>
        <entity id="2" string="Two" type="NUMBER" score="0.0">
          <tokens>
            <token id="1" string="Two" />
          </tokens>
        </entity>
        <entity id="3" string="Monday" type="DATE" score="0.0">
          <tokens>
            <token id="6" string="Monday" />
          </tokens>
        </entity>
        <entity id="4" string="Boston" type="LOCATION" score="0.0">
          <tokens>
            <token id="8" string="Boston" />
          </tokens>
        </entity>
        <entity id="5" string="ninth and 18th" type="ORDINAL" score="0.0">
          <tokens>
            <token id="12" string="ninth" />
            <token id="13" string="and" />
            <token id="14" string="18th" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="25" has_coreference="true">
      <content>And still another, Wodajo Bulti, who has run 2:08:44, is one of the favorites in the London Marathon next Sunday.</content>
      <tokens>
        <token id="1" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="still" lemma="still" stem="still" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="another" lemma="another" stem="anoth" pos="DT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Wodajo" lemma="Wodajo" stem="wodajo" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="6" string="Bulti" lemma="Bulti" stem="bulti" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="run" lemma="run" stem="run" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="2:08:44" lemma="2:08:44" stem="2:08:44" pos="CD" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="favorites" lemma="favorite" stem="favorit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="London" lemma="London" stem="london" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="21" string="Marathon" lemma="Marathon" stem="marathon" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="22" string="next" lemma="next" stem="next" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="23" string="Sunday" lemma="Sunday" stem="sundai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC And) (NP (NP (RB still) (DT another)) (, ,) (NP (NNP Wodajo) (NNP Bulti)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBZ has) (VP (VBN run) (NP (CD 2:08:44)))))) (, ,)) (VP (VBZ is) (NP (NP (CD one)) (PP (IN of) (NP (NP (DT the) (NNS favorites)) (PP (IN in) (NP (DT the) (NNP London) (NNP Marathon))) (NP-TMP (JJ next) (NNP Sunday)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="one" type="NP">
          <tokens>
            <token id="14" string="one" />
          </tokens>
        </chunking>
        <chunking id="2" string="the London Marathon" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="London" />
            <token id="21" string="Marathon" />
          </tokens>
        </chunking>
        <chunking id="3" string="still another" type="NP">
          <tokens>
            <token id="2" string="still" />
            <token id="3" string="another" />
          </tokens>
        </chunking>
        <chunking id="4" string="2:08:44" type="NP">
          <tokens>
            <token id="11" string="2:08:44" />
          </tokens>
        </chunking>
        <chunking id="5" string="Wodajo Bulti" type="NP">
          <tokens>
            <token id="5" string="Wodajo" />
            <token id="6" string="Bulti" />
          </tokens>
        </chunking>
        <chunking id="6" string="has run 2:08:44" type="VP">
          <tokens>
            <token id="9" string="has" />
            <token id="10" string="run" />
            <token id="11" string="2:08:44" />
          </tokens>
        </chunking>
        <chunking id="7" string="the favorites" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="favorites" />
          </tokens>
        </chunking>
        <chunking id="8" string="still another , Wodajo Bulti , who has run 2:08:44 ," type="NP">
          <tokens>
            <token id="2" string="still" />
            <token id="3" string="another" />
            <token id="4" string="," />
            <token id="5" string="Wodajo" />
            <token id="6" string="Bulti" />
            <token id="7" string="," />
            <token id="8" string="who" />
            <token id="9" string="has" />
            <token id="10" string="run" />
            <token id="11" string="2:08:44" />
            <token id="12" string="," />
          </tokens>
        </chunking>
        <chunking id="9" string="who has run 2:08:44" type="SBAR">
          <tokens>
            <token id="8" string="who" />
            <token id="9" string="has" />
            <token id="10" string="run" />
            <token id="11" string="2:08:44" />
          </tokens>
        </chunking>
        <chunking id="10" string="run 2:08:44" type="VP">
          <tokens>
            <token id="10" string="run" />
            <token id="11" string="2:08:44" />
          </tokens>
        </chunking>
        <chunking id="11" string="is one of the favorites in the London Marathon next Sunday" type="VP">
          <tokens>
            <token id="13" string="is" />
            <token id="14" string="one" />
            <token id="15" string="of" />
            <token id="16" string="the" />
            <token id="17" string="favorites" />
            <token id="18" string="in" />
            <token id="19" string="the" />
            <token id="20" string="London" />
            <token id="21" string="Marathon" />
            <token id="22" string="next" />
            <token id="23" string="Sunday" />
          </tokens>
        </chunking>
        <chunking id="12" string="the favorites in the London Marathon next Sunday" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="favorites" />
            <token id="18" string="in" />
            <token id="19" string="the" />
            <token id="20" string="London" />
            <token id="21" string="Marathon" />
            <token id="22" string="next" />
            <token id="23" string="Sunday" />
          </tokens>
        </chunking>
        <chunking id="13" string="one of the favorites in the London Marathon next Sunday" type="NP">
          <tokens>
            <token id="14" string="one" />
            <token id="15" string="of" />
            <token id="16" string="the" />
            <token id="17" string="favorites" />
            <token id="18" string="in" />
            <token id="19" string="the" />
            <token id="20" string="London" />
            <token id="21" string="Marathon" />
            <token id="22" string="next" />
            <token id="23" string="Sunday" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="14">one</governor>
          <dependent id="1">And</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">another</governor>
          <dependent id="2">still</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">one</governor>
          <dependent id="3">another</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Bulti</governor>
          <dependent id="5">Wodajo</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="3">another</governor>
          <dependent id="6">Bulti</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">run</governor>
          <dependent id="8">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="10">run</governor>
          <dependent id="9">has</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="3">another</governor>
          <dependent id="10">run</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">run</governor>
          <dependent id="11">2:08:44</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="14">one</governor>
          <dependent id="13">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">one</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">favorites</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">favorites</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">one</governor>
          <dependent id="17">favorites</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">Marathon</governor>
          <dependent id="18">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">Marathon</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">Marathon</governor>
          <dependent id="20">London</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">favorites</governor>
          <dependent id="21">Marathon</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">Sunday</governor>
          <dependent id="22">next</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="17">favorites</governor>
          <dependent id="23">Sunday</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="14" string="one" />
          </tokens>
        </entity>
        <entity id="2" string="next Sunday" type="DATE" score="0.0">
          <tokens>
            <token id="22" string="next" />
            <token id="23" string="Sunday" />
          </tokens>
        </entity>
        <entity id="3" string="2:08:44" type="TIME" score="0.0">
          <tokens>
            <token id="11" string="2:08:44" />
          </tokens>
        </entity>
        <entity id="4" string="Wodajo Bulti" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Wodajo" />
            <token id="6" string="Bulti" />
          </tokens>
        </entity>
        <entity id="5" string="London Marathon" type="LOCATION" score="0.0">
          <tokens>
            <token id="20" string="London" />
            <token id="21" string="Marathon" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="26" has_coreference="true">
      <content>Ethiopia&amp;apost;s legacy to the world in the last decade has been one of drought, famine and ethnic civil war.</content>
      <tokens>
        <token id="1" string="Ethiopia" lemma="Ethiopia" stem="ethiopia" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="2" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="legacy" lemma="legacy" stem="legaci" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="9" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="10" string="decade" lemma="decade" stem="decad" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="11" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="14" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="drought" lemma="drought" stem="drought" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="famine" lemma="famine" stem="famin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="ethnic" lemma="ethnic" stem="ethnic" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="civil" lemma="civil" stem="civil" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="war" lemma="war" stem="war" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NP (NNP Ethiopia) (POS 's)) (NN legacy)) (PP (TO to) (NP (NP (DT the) (NN world)) (PP (IN in) (NP (DT the) (JJ last) (NN decade)))))) (VP (VBZ has) (VP (VBN been) (NP (NP (CD one)) (PP (IN of) (NP (NP (NN drought)) (, ,) (NP (NN famine)) (CC and) (NP (JJ ethnic) (JJ civil) (NN war))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="drought , famine and ethnic civil war" type="NP">
          <tokens>
            <token id="15" string="drought" />
            <token id="16" string="," />
            <token id="17" string="famine" />
            <token id="18" string="and" />
            <token id="19" string="ethnic" />
            <token id="20" string="civil" />
            <token id="21" string="war" />
          </tokens>
        </chunking>
        <chunking id="2" string="Ethiopia 's legacy to the world in the last decade" type="NP">
          <tokens>
            <token id="1" string="Ethiopia" />
            <token id="2" string="'s" />
            <token id="3" string="legacy" />
            <token id="4" string="to" />
            <token id="5" string="the" />
            <token id="6" string="world" />
            <token id="7" string="in" />
            <token id="8" string="the" />
            <token id="9" string="last" />
            <token id="10" string="decade" />
          </tokens>
        </chunking>
        <chunking id="3" string="Ethiopia 's legacy" type="NP">
          <tokens>
            <token id="1" string="Ethiopia" />
            <token id="2" string="'s" />
            <token id="3" string="legacy" />
          </tokens>
        </chunking>
        <chunking id="4" string="one" type="NP">
          <tokens>
            <token id="13" string="one" />
          </tokens>
        </chunking>
        <chunking id="5" string="the world in the last decade" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="world" />
            <token id="7" string="in" />
            <token id="8" string="the" />
            <token id="9" string="last" />
            <token id="10" string="decade" />
          </tokens>
        </chunking>
        <chunking id="6" string="the world" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="world" />
          </tokens>
        </chunking>
        <chunking id="7" string="been one of drought , famine and ethnic civil war" type="VP">
          <tokens>
            <token id="12" string="been" />
            <token id="13" string="one" />
            <token id="14" string="of" />
            <token id="15" string="drought" />
            <token id="16" string="," />
            <token id="17" string="famine" />
            <token id="18" string="and" />
            <token id="19" string="ethnic" />
            <token id="20" string="civil" />
            <token id="21" string="war" />
          </tokens>
        </chunking>
        <chunking id="8" string="the last decade" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="last" />
            <token id="10" string="decade" />
          </tokens>
        </chunking>
        <chunking id="9" string="one of drought , famine and ethnic civil war" type="NP">
          <tokens>
            <token id="13" string="one" />
            <token id="14" string="of" />
            <token id="15" string="drought" />
            <token id="16" string="," />
            <token id="17" string="famine" />
            <token id="18" string="and" />
            <token id="19" string="ethnic" />
            <token id="20" string="civil" />
            <token id="21" string="war" />
          </tokens>
        </chunking>
        <chunking id="10" string="drought" type="NP">
          <tokens>
            <token id="15" string="drought" />
          </tokens>
        </chunking>
        <chunking id="11" string="famine" type="NP">
          <tokens>
            <token id="17" string="famine" />
          </tokens>
        </chunking>
        <chunking id="12" string="ethnic civil war" type="NP">
          <tokens>
            <token id="19" string="ethnic" />
            <token id="20" string="civil" />
            <token id="21" string="war" />
          </tokens>
        </chunking>
        <chunking id="13" string="has been one of drought , famine and ethnic civil war" type="VP">
          <tokens>
            <token id="11" string="has" />
            <token id="12" string="been" />
            <token id="13" string="one" />
            <token id="14" string="of" />
            <token id="15" string="drought" />
            <token id="16" string="," />
            <token id="17" string="famine" />
            <token id="18" string="and" />
            <token id="19" string="ethnic" />
            <token id="20" string="civil" />
            <token id="21" string="war" />
          </tokens>
        </chunking>
        <chunking id="14" string="Ethiopia 's" type="NP">
          <tokens>
            <token id="1" string="Ethiopia" />
            <token id="2" string="'s" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="3">legacy</governor>
          <dependent id="1">Ethiopia</dependent>
        </dependency>
        <dependency type="case">
          <governor id="1">Ethiopia</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">one</governor>
          <dependent id="3">legacy</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">world</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">world</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">legacy</governor>
          <dependent id="6">world</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">decade</governor>
          <dependent id="7">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">decade</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">decade</governor>
          <dependent id="9">last</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">world</governor>
          <dependent id="10">decade</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="13">one</governor>
          <dependent id="11">has</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="13">one</governor>
          <dependent id="12">been</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">one</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">drought</governor>
          <dependent id="14">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">one</governor>
          <dependent id="15">drought</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="15">drought</governor>
          <dependent id="17">famine</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="15">drought</governor>
          <dependent id="18">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">war</governor>
          <dependent id="19">ethnic</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">war</governor>
          <dependent id="20">civil</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="15">drought</governor>
          <dependent id="21">war</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="the last decade" type="DATE" score="0.0">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="last" />
            <token id="10" string="decade" />
          </tokens>
        </entity>
        <entity id="2" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="13" string="one" />
          </tokens>
        </entity>
        <entity id="3" string="war" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="21" string="war" />
          </tokens>
        </entity>
        <entity id="4" string="Ethiopia" type="LOCATION" score="0.0">
          <tokens>
            <token id="1" string="Ethiopia" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="27" has_coreference="true">
      <content>More than 1 million people died in 1984-85 during a drought-caused famine.</content>
      <tokens>
        <token id="1" string="More" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="1" lemma="1" stem="1" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="4" string="million" lemma="million" stem="million" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="5" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="died" lemma="die" stem="di" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="1984-85" lemma="1984-85" stem="1984-85" pos="CD" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="9" string="during" lemma="during" stem="dure" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="drought-caused" lemma="drought-caused" stem="drought-caus" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="famine" lemma="famine" stem="famin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (QP (JJR More) (IN than) (CD 1) (CD million)) (NNS people)) (VP (VBD died) (PP (IN in) (NP (CD 1984-85))) (PP (IN during) (NP (DT a) (JJ drought-caused) (NN famine)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a drought-caused famine" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="drought-caused" />
            <token id="12" string="famine" />
          </tokens>
        </chunking>
        <chunking id="2" string="1984-85" type="NP">
          <tokens>
            <token id="8" string="1984-85" />
          </tokens>
        </chunking>
        <chunking id="3" string="died in 1984-85 during a drought-caused famine" type="VP">
          <tokens>
            <token id="6" string="died" />
            <token id="7" string="in" />
            <token id="8" string="1984-85" />
            <token id="9" string="during" />
            <token id="10" string="a" />
            <token id="11" string="drought-caused" />
            <token id="12" string="famine" />
          </tokens>
        </chunking>
        <chunking id="4" string="More than 1 million people" type="NP">
          <tokens>
            <token id="1" string="More" />
            <token id="2" string="than" />
            <token id="3" string="1" />
            <token id="4" string="million" />
            <token id="5" string="people" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="4">million</governor>
          <dependent id="1">More</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="1">More</governor>
          <dependent id="2">than</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">million</governor>
          <dependent id="3">1</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="5">people</governor>
          <dependent id="4">million</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">died</governor>
          <dependent id="5">people</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">died</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">1984-85</governor>
          <dependent id="7">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">died</governor>
          <dependent id="8">1984-85</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">famine</governor>
          <dependent id="9">during</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">famine</governor>
          <dependent id="10">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">famine</governor>
          <dependent id="11">drought-caused</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">died</governor>
          <dependent id="12">famine</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1984-85" type="DATE" score="0.0">
          <tokens>
            <token id="8" string="1984-85" />
          </tokens>
        </entity>
        <entity id="2" string="1 million" type="NUMBER" score="0.0">
          <tokens>
            <token id="3" string="1" />
            <token id="4" string="million" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="28" has_coreference="false">
      <content>The plight of Ethiopians caught the imagination of the world and inspired rock musicians and others to organize benefit concerts.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="plight" lemma="plight" stem="plight" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Ethiopians" lemma="Ethiopians" stem="ethiopian" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="5" string="caught" lemma="catch" stem="caught" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="imagination" lemma="imagination" stem="imagin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="inspired" lemma="inspire" stem="inspir" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="rock" lemma="rock" stem="rock" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="musicians" lemma="musician" stem="musician" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="others" lemma="other" stem="other" pos="NNS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="organize" lemma="organize" stem="organ" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="benefit" lemma="benefit" stem="benefit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="concerts" lemma="concert" stem="concert" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (NN plight)) (PP (IN of) (NP (NNPS Ethiopians)))) (VP (VP (VBD caught) (NP (NP (DT the) (NN imagination)) (PP (IN of) (NP (DT the) (NN world))))) (CC and) (VP (VBD inspired) (NP (NN rock) (NNS musicians) (CC and) (NNS others)) (S (VP (TO to) (VP (VB organize) (NP (NN benefit) (NNS concerts))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the imagination of the world" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="imagination" />
            <token id="8" string="of" />
            <token id="9" string="the" />
            <token id="10" string="world" />
          </tokens>
        </chunking>
        <chunking id="2" string="the imagination" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="imagination" />
          </tokens>
        </chunking>
        <chunking id="3" string="benefit concerts" type="NP">
          <tokens>
            <token id="19" string="benefit" />
            <token id="20" string="concerts" />
          </tokens>
        </chunking>
        <chunking id="4" string="caught the imagination of the world" type="VP">
          <tokens>
            <token id="5" string="caught" />
            <token id="6" string="the" />
            <token id="7" string="imagination" />
            <token id="8" string="of" />
            <token id="9" string="the" />
            <token id="10" string="world" />
          </tokens>
        </chunking>
        <chunking id="5" string="the world" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="world" />
          </tokens>
        </chunking>
        <chunking id="6" string="inspired rock musicians and others to organize benefit concerts" type="VP">
          <tokens>
            <token id="12" string="inspired" />
            <token id="13" string="rock" />
            <token id="14" string="musicians" />
            <token id="15" string="and" />
            <token id="16" string="others" />
            <token id="17" string="to" />
            <token id="18" string="organize" />
            <token id="19" string="benefit" />
            <token id="20" string="concerts" />
          </tokens>
        </chunking>
        <chunking id="7" string="The plight" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="plight" />
          </tokens>
        </chunking>
        <chunking id="8" string="The plight of Ethiopians" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="plight" />
            <token id="3" string="of" />
            <token id="4" string="Ethiopians" />
          </tokens>
        </chunking>
        <chunking id="9" string="Ethiopians" type="NP">
          <tokens>
            <token id="4" string="Ethiopians" />
          </tokens>
        </chunking>
        <chunking id="10" string="rock musicians and others" type="NP">
          <tokens>
            <token id="13" string="rock" />
            <token id="14" string="musicians" />
            <token id="15" string="and" />
            <token id="16" string="others" />
          </tokens>
        </chunking>
        <chunking id="11" string="organize benefit concerts" type="VP">
          <tokens>
            <token id="18" string="organize" />
            <token id="19" string="benefit" />
            <token id="20" string="concerts" />
          </tokens>
        </chunking>
        <chunking id="12" string="caught the imagination of the world and inspired rock musicians and others to organize benefit concerts" type="VP">
          <tokens>
            <token id="5" string="caught" />
            <token id="6" string="the" />
            <token id="7" string="imagination" />
            <token id="8" string="of" />
            <token id="9" string="the" />
            <token id="10" string="world" />
            <token id="11" string="and" />
            <token id="12" string="inspired" />
            <token id="13" string="rock" />
            <token id="14" string="musicians" />
            <token id="15" string="and" />
            <token id="16" string="others" />
            <token id="17" string="to" />
            <token id="18" string="organize" />
            <token id="19" string="benefit" />
            <token id="20" string="concerts" />
          </tokens>
        </chunking>
        <chunking id="13" string="to organize benefit concerts" type="VP">
          <tokens>
            <token id="17" string="to" />
            <token id="18" string="organize" />
            <token id="19" string="benefit" />
            <token id="20" string="concerts" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">plight</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">caught</governor>
          <dependent id="2">plight</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">Ethiopians</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">plight</governor>
          <dependent id="4">Ethiopians</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">caught</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">imagination</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">caught</governor>
          <dependent id="7">imagination</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">world</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">world</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">imagination</governor>
          <dependent id="10">world</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">caught</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">caught</governor>
          <dependent id="12">inspired</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">musicians</governor>
          <dependent id="13">rock</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">inspired</governor>
          <dependent id="14">musicians</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="14">musicians</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">musicians</governor>
          <dependent id="16">others</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">organize</governor>
          <dependent id="17">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="12">inspired</governor>
          <dependent id="18">organize</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">concerts</governor>
          <dependent id="19">benefit</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">organize</governor>
          <dependent id="20">concerts</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ethiopians" type="MISC" score="0.0">
          <tokens>
            <token id="4" string="Ethiopians" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="29" has_coreference="true">
      <content>Because of internal disturbances, however, little of that aid ever reached the needy.</content>
      <tokens>
        <token id="1" string="Because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="internal" lemma="internal" stem="intern" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="disturbances" lemma="disturbance" stem="disturb" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="however" lemma="however" stem="howev" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="little" lemma="little" stem="littl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="aid" lemma="aid" stem="aid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="ever" lemma="ever" stem="ever" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="reached" lemma="reach" stem="reach" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="needy" lemma="needy" stem="needi" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN Because) (PP (IN of) (NP (JJ internal) (NNS disturbances)))) (, ,) (ADVP (RB however)) (, ,) (NP (NP (JJ little)) (PP (IN of) (NP (DT that) (NN aid)))) (ADVP (RB ever)) (VP (VBD reached) (NP (DT the) (JJ needy))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="internal disturbances" type="NP">
          <tokens>
            <token id="3" string="internal" />
            <token id="4" string="disturbances" />
          </tokens>
        </chunking>
        <chunking id="2" string="little of that aid" type="NP">
          <tokens>
            <token id="8" string="little" />
            <token id="9" string="of" />
            <token id="10" string="that" />
            <token id="11" string="aid" />
          </tokens>
        </chunking>
        <chunking id="3" string="the needy" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="needy" />
          </tokens>
        </chunking>
        <chunking id="4" string="that aid" type="NP">
          <tokens>
            <token id="10" string="that" />
            <token id="11" string="aid" />
          </tokens>
        </chunking>
        <chunking id="5" string="little" type="NP">
          <tokens>
            <token id="8" string="little" />
          </tokens>
        </chunking>
        <chunking id="6" string="reached the needy" type="VP">
          <tokens>
            <token id="13" string="reached" />
            <token id="14" string="the" />
            <token id="15" string="needy" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">disturbances</governor>
          <dependent id="1">Because</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">disturbances</governor>
          <dependent id="2">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">disturbances</governor>
          <dependent id="3">internal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">reached</governor>
          <dependent id="4">disturbances</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">reached</governor>
          <dependent id="6">however</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">reached</governor>
          <dependent id="8">little</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">aid</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">aid</governor>
          <dependent id="10">that</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">little</governor>
          <dependent id="11">aid</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">reached</governor>
          <dependent id="12">ever</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">reached</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">needy</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">reached</governor>
          <dependent id="15">needy</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="30" has_coreference="true">
      <content>Politically pro-Soviet, Ethiopia&amp;apost;s Marxist government ordered boycotts of the Olympic Games in 1976, 1984 and 1988.</content>
      <tokens>
        <token id="1" string="Politically" lemma="politically" stem="polit" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="pro-Soviet" lemma="pro-soviet" stem="pro-soviet" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Ethiopia" lemma="Ethiopia" stem="ethiopia" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="5" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="Marxist" lemma="marxist" stem="marxist" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="7" string="government" lemma="government" stem="govern" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="ordered" lemma="order" stem="order" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="boycotts" lemma="boycott" stem="boycott" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="Olympic" lemma="Olympic" stem="olympic" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="13" string="Games" lemma="Games" stem="game" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="14" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="1976" lemma="1976" stem="1976" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="1984" lemma="1984" stem="1984" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="18" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="1988" lemma="1988" stem="1988" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (ADVP (RB Politically)) (ADJP (JJ pro-Soviet))) (, ,) (NP (NP (NNP Ethiopia) (POS 's)) (JJ Marxist) (NN government)) (VP (VBD ordered) (NP (NP (NNS boycotts)) (PP (IN of) (NP (DT the) (NNP Olympic) (NNPS Games)))) (PP (IN in) (NP (CD 1976) (, ,) (CD 1984) (CC and) (CD 1988)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="ordered boycotts of the Olympic Games in 1976 , 1984 and 1988" type="VP">
          <tokens>
            <token id="8" string="ordered" />
            <token id="9" string="boycotts" />
            <token id="10" string="of" />
            <token id="11" string="the" />
            <token id="12" string="Olympic" />
            <token id="13" string="Games" />
            <token id="14" string="in" />
            <token id="15" string="1976" />
            <token id="16" string="," />
            <token id="17" string="1984" />
            <token id="18" string="and" />
            <token id="19" string="1988" />
          </tokens>
        </chunking>
        <chunking id="2" string="boycotts" type="NP">
          <tokens>
            <token id="9" string="boycotts" />
          </tokens>
        </chunking>
        <chunking id="3" string="the Olympic Games" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="Olympic" />
            <token id="13" string="Games" />
          </tokens>
        </chunking>
        <chunking id="4" string="pro-Soviet" type="ADJP">
          <tokens>
            <token id="2" string="pro-Soviet" />
          </tokens>
        </chunking>
        <chunking id="5" string="Ethiopia 's" type="NP">
          <tokens>
            <token id="4" string="Ethiopia" />
            <token id="5" string="'s" />
          </tokens>
        </chunking>
        <chunking id="6" string="Ethiopia 's Marxist government" type="NP">
          <tokens>
            <token id="4" string="Ethiopia" />
            <token id="5" string="'s" />
            <token id="6" string="Marxist" />
            <token id="7" string="government" />
          </tokens>
        </chunking>
        <chunking id="7" string="1976 , 1984 and 1988" type="NP">
          <tokens>
            <token id="15" string="1976" />
            <token id="16" string="," />
            <token id="17" string="1984" />
            <token id="18" string="and" />
            <token id="19" string="1988" />
          </tokens>
        </chunking>
        <chunking id="8" string="boycotts of the Olympic Games" type="NP">
          <tokens>
            <token id="9" string="boycotts" />
            <token id="10" string="of" />
            <token id="11" string="the" />
            <token id="12" string="Olympic" />
            <token id="13" string="Games" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="2">pro-Soviet</governor>
          <dependent id="1">Politically</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="8">ordered</governor>
          <dependent id="2">pro-Soviet</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="7">government</governor>
          <dependent id="4">Ethiopia</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">Ethiopia</governor>
          <dependent id="5">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">government</governor>
          <dependent id="6">Marxist</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">ordered</governor>
          <dependent id="7">government</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">ordered</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">ordered</governor>
          <dependent id="9">boycotts</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Games</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">Games</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Games</governor>
          <dependent id="12">Olympic</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">boycotts</governor>
          <dependent id="13">Games</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">1976</governor>
          <dependent id="14">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">ordered</governor>
          <dependent id="15">1976</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="15">1976</governor>
          <dependent id="17">1984</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="15">1976</governor>
          <dependent id="18">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="15">1976</governor>
          <dependent id="19">1988</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1988" type="DATE" score="0.0">
          <tokens>
            <token id="19" string="1988" />
          </tokens>
        </entity>
        <entity id="2" string="1976" type="DATE" score="0.0">
          <tokens>
            <token id="15" string="1976" />
          </tokens>
        </entity>
        <entity id="3" string="1984" type="DATE" score="0.0">
          <tokens>
            <token id="17" string="1984" />
          </tokens>
        </entity>
        <entity id="4" string="pro-Soviet" type="MISC" score="0.0">
          <tokens>
            <token id="2" string="pro-Soviet" />
          </tokens>
        </entity>
        <entity id="5" string="Marxist" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="6" string="Marxist" />
          </tokens>
        </entity>
        <entity id="6" string="Olympic Games" type="MISC" score="0.0">
          <tokens>
            <token id="12" string="Olympic" />
            <token id="13" string="Games" />
          </tokens>
        </entity>
        <entity id="7" string="Ethiopia" type="LOCATION" score="0.0">
          <tokens>
            <token id="4" string="Ethiopia" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="31" has_coreference="true">
      <content>Had they not boycotted, at least three Ethiopian runners would have been among the favorites in the men&amp;apost;s marathon at Seoul.</content>
      <tokens>
        <token id="1" string="Had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="boycotted" lemma="boycott" stem="boycot" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="least" lemma="least" stem="least" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="three" lemma="three" stem="three" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="9" string="Ethiopian" lemma="ethiopian" stem="ethiopian" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="10" string="runners" lemma="runner" stem="runner" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="among" lemma="among" stem="among" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="favorites" lemma="favorite" stem="favorit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="men" lemma="man" stem="men" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="marathon" lemma="marathon" stem="marathon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="Seoul" lemma="Seoul" stem="seoul" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SINV (VBD Had) (NP (PRP they)) (RB not) (VP (VBD boycotted))) (, ,) (S (NP (QP (IN at) (JJS least) (CD three)) (JJ Ethiopian) (NNS runners)) (VP (MD would) (VP (VB have) (VP (VBN been) (PP (IN among) (NP (NP (DT the) (NNS favorites)) (PP (IN in) (NP (NP (DT the) (NNS men) (POS 's)) (NN marathon))))) (PP (IN at) (NP (NNP Seoul))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the men 's" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="men" />
            <token id="20" string="'s" />
          </tokens>
        </chunking>
        <chunking id="2" string="they" type="NP">
          <tokens>
            <token id="2" string="they" />
          </tokens>
        </chunking>
        <chunking id="3" string="have been among the favorites in the men 's marathon at Seoul" type="VP">
          <tokens>
            <token id="12" string="have" />
            <token id="13" string="been" />
            <token id="14" string="among" />
            <token id="15" string="the" />
            <token id="16" string="favorites" />
            <token id="17" string="in" />
            <token id="18" string="the" />
            <token id="19" string="men" />
            <token id="20" string="'s" />
            <token id="21" string="marathon" />
            <token id="22" string="at" />
            <token id="23" string="Seoul" />
          </tokens>
        </chunking>
        <chunking id="4" string="Seoul" type="NP">
          <tokens>
            <token id="23" string="Seoul" />
          </tokens>
        </chunking>
        <chunking id="5" string="the favorites in the men 's marathon" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="favorites" />
            <token id="17" string="in" />
            <token id="18" string="the" />
            <token id="19" string="men" />
            <token id="20" string="'s" />
            <token id="21" string="marathon" />
          </tokens>
        </chunking>
        <chunking id="6" string="been among the favorites in the men 's marathon at Seoul" type="VP">
          <tokens>
            <token id="13" string="been" />
            <token id="14" string="among" />
            <token id="15" string="the" />
            <token id="16" string="favorites" />
            <token id="17" string="in" />
            <token id="18" string="the" />
            <token id="19" string="men" />
            <token id="20" string="'s" />
            <token id="21" string="marathon" />
            <token id="22" string="at" />
            <token id="23" string="Seoul" />
          </tokens>
        </chunking>
        <chunking id="7" string="the men 's marathon" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="men" />
            <token id="20" string="'s" />
            <token id="21" string="marathon" />
          </tokens>
        </chunking>
        <chunking id="8" string="at least three Ethiopian runners" type="NP">
          <tokens>
            <token id="6" string="at" />
            <token id="7" string="least" />
            <token id="8" string="three" />
            <token id="9" string="Ethiopian" />
            <token id="10" string="runners" />
          </tokens>
        </chunking>
        <chunking id="9" string="the favorites" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="favorites" />
          </tokens>
        </chunking>
        <chunking id="10" string="would have been among the favorites in the men 's marathon at Seoul" type="VP">
          <tokens>
            <token id="11" string="would" />
            <token id="12" string="have" />
            <token id="13" string="been" />
            <token id="14" string="among" />
            <token id="15" string="the" />
            <token id="16" string="favorites" />
            <token id="17" string="in" />
            <token id="18" string="the" />
            <token id="19" string="men" />
            <token id="20" string="'s" />
            <token id="21" string="marathon" />
            <token id="22" string="at" />
            <token id="23" string="Seoul" />
          </tokens>
        </chunking>
        <chunking id="11" string="boycotted" type="VP">
          <tokens>
            <token id="4" string="boycotted" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="aux">
          <governor id="4">boycotted</governor>
          <dependent id="1">Had</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">boycotted</governor>
          <dependent id="2">they</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="4">boycotted</governor>
          <dependent id="3">not</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="16">favorites</governor>
          <dependent id="4">boycotted</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">least</governor>
          <dependent id="6">at</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="8">three</governor>
          <dependent id="7">least</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="10">runners</governor>
          <dependent id="8">three</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">runners</governor>
          <dependent id="9">Ethiopian</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">favorites</governor>
          <dependent id="10">runners</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">favorites</governor>
          <dependent id="11">would</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">favorites</governor>
          <dependent id="12">have</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="16">favorites</governor>
          <dependent id="13">been</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">favorites</governor>
          <dependent id="14">among</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">favorites</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="16">favorites</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">marathon</governor>
          <dependent id="17">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">men</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="21">marathon</governor>
          <dependent id="19">men</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">men</governor>
          <dependent id="20">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">favorites</governor>
          <dependent id="21">marathon</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">Seoul</governor>
          <dependent id="22">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">favorites</governor>
          <dependent id="23">Seoul</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Seoul" type="LOCATION" score="0.0">
          <tokens>
            <token id="23" string="Seoul" />
          </tokens>
        </entity>
        <entity id="2" string="Ethiopian" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="9" string="Ethiopian" />
          </tokens>
        </entity>
        <entity id="3" string="three" type="NUMBER" score="0.0">
          <tokens>
            <token id="8" string="three" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="32" has_coreference="true">
      <content>Despite its erratic participation, however, Ethiopia has a proud Olympic heritage, dating to 1956.</content>
      <tokens>
        <token id="1" string="Despite" lemma="despite" stem="despit" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="erratic" lemma="erratic" stem="errat" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="participation" lemma="participation" stem="particip" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="however" lemma="however" stem="howev" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Ethiopia" lemma="Ethiopia" stem="ethiopia" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="9" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="proud" lemma="proud" stem="proud" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="Olympic" lemma="Olympic" stem="olympic" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="true" />
        <token id="13" string="heritage" lemma="heritage" stem="heritag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="dating" lemma="date" stem="date" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="1956" lemma="1956" stem="1956" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN Despite) (NP (PRP$ its) (JJ erratic) (NN participation))) (, ,) (ADVP (RB however)) (, ,) (NP (NNP Ethiopia)) (VP (VBZ has) (NP (NP (DT a) (JJ proud) (NNP Olympic) (NN heritage)) (, ,) (VP (VBG dating) (PP (TO to) (NP (CD 1956)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="dating to 1956" type="VP">
          <tokens>
            <token id="15" string="dating" />
            <token id="16" string="to" />
            <token id="17" string="1956" />
          </tokens>
        </chunking>
        <chunking id="2" string="has a proud Olympic heritage , dating to 1956" type="VP">
          <tokens>
            <token id="9" string="has" />
            <token id="10" string="a" />
            <token id="11" string="proud" />
            <token id="12" string="Olympic" />
            <token id="13" string="heritage" />
            <token id="14" string="," />
            <token id="15" string="dating" />
            <token id="16" string="to" />
            <token id="17" string="1956" />
          </tokens>
        </chunking>
        <chunking id="3" string="a proud Olympic heritage" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="proud" />
            <token id="12" string="Olympic" />
            <token id="13" string="heritage" />
          </tokens>
        </chunking>
        <chunking id="4" string="a proud Olympic heritage , dating to 1956" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="proud" />
            <token id="12" string="Olympic" />
            <token id="13" string="heritage" />
            <token id="14" string="," />
            <token id="15" string="dating" />
            <token id="16" string="to" />
            <token id="17" string="1956" />
          </tokens>
        </chunking>
        <chunking id="5" string="its erratic participation" type="NP">
          <tokens>
            <token id="2" string="its" />
            <token id="3" string="erratic" />
            <token id="4" string="participation" />
          </tokens>
        </chunking>
        <chunking id="6" string="Ethiopia" type="NP">
          <tokens>
            <token id="8" string="Ethiopia" />
          </tokens>
        </chunking>
        <chunking id="7" string="1956" type="NP">
          <tokens>
            <token id="17" string="1956" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">participation</governor>
          <dependent id="1">Despite</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">participation</governor>
          <dependent id="2">its</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">participation</governor>
          <dependent id="3">erratic</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">has</governor>
          <dependent id="4">participation</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">has</governor>
          <dependent id="6">however</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">has</governor>
          <dependent id="8">Ethiopia</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">has</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">heritage</governor>
          <dependent id="10">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">heritage</governor>
          <dependent id="11">proud</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">heritage</governor>
          <dependent id="12">Olympic</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">has</governor>
          <dependent id="13">heritage</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="13">heritage</governor>
          <dependent id="15">dating</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">1956</governor>
          <dependent id="16">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">dating</governor>
          <dependent id="17">1956</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Olympic" type="MISC" score="0.0">
          <tokens>
            <token id="12" string="Olympic" />
          </tokens>
        </entity>
        <entity id="2" string="Ethiopia" type="LOCATION" score="0.0">
          <tokens>
            <token id="8" string="Ethiopia" />
          </tokens>
        </entity>
        <entity id="3" string="1956" type="DATE" score="0.0">
          <tokens>
            <token id="17" string="1956" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="33" has_coreference="true">
      <content>One of the marathon&amp;apost;s most enduring figures was Bikila, who won the marathon gold medal in 1960 and 1964.</content>
      <tokens>
        <token id="1" string="One" lemma="one" stem="one" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="2" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="marathon" lemma="marathon" stem="marathon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="most" lemma="most" stem="most" pos="RBS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="enduring" lemma="enduring" stem="endur" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="figures" lemma="figure" stem="figur" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Bikila" lemma="Bikila" stem="bikila" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="won" lemma="win" stem="won" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="marathon" lemma="marathon" stem="marathon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="gold" lemma="gold" stem="gold" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="medal" lemma="medal" stem="medal" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="18" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="1960" lemma="1960" stem="1960" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="20" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="1964" lemma="1964" stem="1964" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (CD One)) (PP (IN of) (NP (NP (DT the) (NN marathon) (POS 's)) (ADJP (RBS most) (JJ enduring)) (NNS figures)))) (VP (VBD was) (NP (NP (NNP Bikila)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBD won) (NP (DT the) (NN marathon) (NN gold) (NN medal)) (PP (IN in) (NP (CD 1960) (CC and) (CD 1964)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Bikila" type="NP">
          <tokens>
            <token id="10" string="Bikila" />
          </tokens>
        </chunking>
        <chunking id="2" string="the marathon 's" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="marathon" />
            <token id="5" string="'s" />
          </tokens>
        </chunking>
        <chunking id="3" string="was Bikila , who won the marathon gold medal in 1960 and 1964" type="VP">
          <tokens>
            <token id="9" string="was" />
            <token id="10" string="Bikila" />
            <token id="11" string="," />
            <token id="12" string="who" />
            <token id="13" string="won" />
            <token id="14" string="the" />
            <token id="15" string="marathon" />
            <token id="16" string="gold" />
            <token id="17" string="medal" />
            <token id="18" string="in" />
            <token id="19" string="1960" />
            <token id="20" string="and" />
            <token id="21" string="1964" />
          </tokens>
        </chunking>
        <chunking id="4" string="One of the marathon 's most enduring figures" type="NP">
          <tokens>
            <token id="1" string="One" />
            <token id="2" string="of" />
            <token id="3" string="the" />
            <token id="4" string="marathon" />
            <token id="5" string="'s" />
            <token id="6" string="most" />
            <token id="7" string="enduring" />
            <token id="8" string="figures" />
          </tokens>
        </chunking>
        <chunking id="5" string="One" type="NP">
          <tokens>
            <token id="1" string="One" />
          </tokens>
        </chunking>
        <chunking id="6" string="Bikila , who won the marathon gold medal in 1960 and 1964" type="NP">
          <tokens>
            <token id="10" string="Bikila" />
            <token id="11" string="," />
            <token id="12" string="who" />
            <token id="13" string="won" />
            <token id="14" string="the" />
            <token id="15" string="marathon" />
            <token id="16" string="gold" />
            <token id="17" string="medal" />
            <token id="18" string="in" />
            <token id="19" string="1960" />
            <token id="20" string="and" />
            <token id="21" string="1964" />
          </tokens>
        </chunking>
        <chunking id="7" string="most enduring" type="ADJP">
          <tokens>
            <token id="6" string="most" />
            <token id="7" string="enduring" />
          </tokens>
        </chunking>
        <chunking id="8" string="who won the marathon gold medal in 1960 and 1964" type="SBAR">
          <tokens>
            <token id="12" string="who" />
            <token id="13" string="won" />
            <token id="14" string="the" />
            <token id="15" string="marathon" />
            <token id="16" string="gold" />
            <token id="17" string="medal" />
            <token id="18" string="in" />
            <token id="19" string="1960" />
            <token id="20" string="and" />
            <token id="21" string="1964" />
          </tokens>
        </chunking>
        <chunking id="9" string="won the marathon gold medal in 1960 and 1964" type="VP">
          <tokens>
            <token id="13" string="won" />
            <token id="14" string="the" />
            <token id="15" string="marathon" />
            <token id="16" string="gold" />
            <token id="17" string="medal" />
            <token id="18" string="in" />
            <token id="19" string="1960" />
            <token id="20" string="and" />
            <token id="21" string="1964" />
          </tokens>
        </chunking>
        <chunking id="10" string="1960 and 1964" type="NP">
          <tokens>
            <token id="19" string="1960" />
            <token id="20" string="and" />
            <token id="21" string="1964" />
          </tokens>
        </chunking>
        <chunking id="11" string="the marathon 's most enduring figures" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="marathon" />
            <token id="5" string="'s" />
            <token id="6" string="most" />
            <token id="7" string="enduring" />
            <token id="8" string="figures" />
          </tokens>
        </chunking>
        <chunking id="12" string="the marathon gold medal" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="marathon" />
            <token id="16" string="gold" />
            <token id="17" string="medal" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="10">Bikila</governor>
          <dependent id="1">One</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">figures</governor>
          <dependent id="2">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">marathon</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">figures</governor>
          <dependent id="4">marathon</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">marathon</governor>
          <dependent id="5">'s</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">enduring</governor>
          <dependent id="6">most</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">figures</governor>
          <dependent id="7">enduring</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">One</governor>
          <dependent id="8">figures</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="10">Bikila</governor>
          <dependent id="9">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">Bikila</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">won</governor>
          <dependent id="12">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="10">Bikila</governor>
          <dependent id="13">won</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">medal</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">medal</governor>
          <dependent id="15">marathon</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">medal</governor>
          <dependent id="16">gold</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">won</governor>
          <dependent id="17">medal</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">1960</governor>
          <dependent id="18">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">won</governor>
          <dependent id="19">1960</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="19">1960</governor>
          <dependent id="20">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="19">1960</governor>
          <dependent id="21">1964</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Bikila" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Bikila" />
          </tokens>
        </entity>
        <entity id="2" string="1964" type="DATE" score="0.0">
          <tokens>
            <token id="21" string="1964" />
          </tokens>
        </entity>
        <entity id="3" string="One" type="NUMBER" score="0.0">
          <tokens>
            <token id="1" string="One" />
          </tokens>
        </entity>
        <entity id="4" string="1960" type="DATE" score="0.0">
          <tokens>
            <token id="19" string="1960" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="34" has_coreference="false">
      <content>Ethiopia also took the marathon gold in 1968, when Mamo Wolde, 36, won at altitude in Mexico City.</content>
      <tokens>
        <token id="1" string="Ethiopia" lemma="Ethiopia" stem="ethiopia" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="2" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="took" lemma="take" stem="took" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="marathon" lemma="marathon" stem="marathon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="gold" lemma="gold" stem="gold" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="1968" lemma="1968" stem="1968" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Mamo" lemma="Mamo" stem="mamo" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="12" string="Wolde" lemma="Wolde" stem="wold" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="36" lemma="36" stem="36" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="won" lemma="win" stem="won" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="altitude" lemma="altitude" stem="altitud" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="Mexico" lemma="Mexico" stem="mexico" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="21" string="City" lemma="City" stem="citi" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Ethiopia)) (ADVP (RB also)) (VP (VBD took) (NP (DT the) (NN marathon) (NN gold)) (PP (IN in) (NP (CD 1968))) (, ,) (SBAR (WHADVP (WRB when)) (S (NP (NP (NNP Mamo) (NNP Wolde)) (, ,) (NP (CD 36)) (, ,)) (VP (VBD won) (PP (IN at) (NP (NN altitude))) (PP (IN in) (NP (NNP Mexico) (NNP City))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="won at altitude in Mexico City" type="VP">
          <tokens>
            <token id="16" string="won" />
            <token id="17" string="at" />
            <token id="18" string="altitude" />
            <token id="19" string="in" />
            <token id="20" string="Mexico" />
            <token id="21" string="City" />
          </tokens>
        </chunking>
        <chunking id="2" string="36" type="NP">
          <tokens>
            <token id="14" string="36" />
          </tokens>
        </chunking>
        <chunking id="3" string="altitude" type="NP">
          <tokens>
            <token id="18" string="altitude" />
          </tokens>
        </chunking>
        <chunking id="4" string="when Mamo Wolde , 36 , won at altitude in Mexico City" type="SBAR">
          <tokens>
            <token id="10" string="when" />
            <token id="11" string="Mamo" />
            <token id="12" string="Wolde" />
            <token id="13" string="," />
            <token id="14" string="36" />
            <token id="15" string="," />
            <token id="16" string="won" />
            <token id="17" string="at" />
            <token id="18" string="altitude" />
            <token id="19" string="in" />
            <token id="20" string="Mexico" />
            <token id="21" string="City" />
          </tokens>
        </chunking>
        <chunking id="5" string="Mamo Wolde , 36 ," type="NP">
          <tokens>
            <token id="11" string="Mamo" />
            <token id="12" string="Wolde" />
            <token id="13" string="," />
            <token id="14" string="36" />
            <token id="15" string="," />
          </tokens>
        </chunking>
        <chunking id="6" string="the marathon gold" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="marathon" />
            <token id="6" string="gold" />
          </tokens>
        </chunking>
        <chunking id="7" string="Mamo Wolde" type="NP">
          <tokens>
            <token id="11" string="Mamo" />
            <token id="12" string="Wolde" />
          </tokens>
        </chunking>
        <chunking id="8" string="took the marathon gold in 1968 , when Mamo Wolde , 36 , won at altitude in Mexico City" type="VP">
          <tokens>
            <token id="3" string="took" />
            <token id="4" string="the" />
            <token id="5" string="marathon" />
            <token id="6" string="gold" />
            <token id="7" string="in" />
            <token id="8" string="1968" />
            <token id="9" string="," />
            <token id="10" string="when" />
            <token id="11" string="Mamo" />
            <token id="12" string="Wolde" />
            <token id="13" string="," />
            <token id="14" string="36" />
            <token id="15" string="," />
            <token id="16" string="won" />
            <token id="17" string="at" />
            <token id="18" string="altitude" />
            <token id="19" string="in" />
            <token id="20" string="Mexico" />
            <token id="21" string="City" />
          </tokens>
        </chunking>
        <chunking id="9" string="Mexico City" type="NP">
          <tokens>
            <token id="20" string="Mexico" />
            <token id="21" string="City" />
          </tokens>
        </chunking>
        <chunking id="10" string="1968" type="NP">
          <tokens>
            <token id="8" string="1968" />
          </tokens>
        </chunking>
        <chunking id="11" string="when" type="WHADVP">
          <tokens>
            <token id="10" string="when" />
          </tokens>
        </chunking>
        <chunking id="12" string="Ethiopia" type="NP">
          <tokens>
            <token id="1" string="Ethiopia" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">took</governor>
          <dependent id="1">Ethiopia</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">took</governor>
          <dependent id="2">also</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">took</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">gold</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">gold</governor>
          <dependent id="5">marathon</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">took</governor>
          <dependent id="6">gold</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">1968</governor>
          <dependent id="7">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">took</governor>
          <dependent id="8">1968</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">won</governor>
          <dependent id="10">when</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Wolde</governor>
          <dependent id="11">Mamo</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">won</governor>
          <dependent id="12">Wolde</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">Wolde</governor>
          <dependent id="14">36</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">took</governor>
          <dependent id="16">won</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">altitude</governor>
          <dependent id="17">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">won</governor>
          <dependent id="18">altitude</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">City</governor>
          <dependent id="19">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">City</governor>
          <dependent id="20">Mexico</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">won</governor>
          <dependent id="21">City</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="36" type="NUMBER" score="0.0">
          <tokens>
            <token id="14" string="36" />
          </tokens>
        </entity>
        <entity id="2" string="Mamo Wolde" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Mamo" />
            <token id="12" string="Wolde" />
          </tokens>
        </entity>
        <entity id="3" string="Mexico City" type="LOCATION" score="0.0">
          <tokens>
            <token id="20" string="Mexico" />
            <token id="21" string="City" />
          </tokens>
        </entity>
        <entity id="4" string="1968" type="DATE" score="0.0">
          <tokens>
            <token id="8" string="1968" />
          </tokens>
        </entity>
        <entity id="5" string="Ethiopia" type="LOCATION" score="0.0">
          <tokens>
            <token id="1" string="Ethiopia" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="35" has_coreference="true">
      <content>It is the altitude at which the Ethiopians train that enhances their aerobic capacity.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="altitude" lemma="altitude" stem="altitud" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="Ethiopians" lemma="Ethiopians" stem="ethiopian" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="true" />
        <token id="9" string="train" lemma="train" stem="train" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="enhances" lemma="enhance" stem="enhanc" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="aerobic" lemma="aerobic" stem="aerob" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="capacity" lemma="capacity" stem="capac" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP It)) (VP (VBZ is) (NP (NP (DT the) (NN altitude)) (SBAR (WHPP (IN at) (WHNP (WDT which))) (S (NP (DT the) (NNPS Ethiopians)) (VP (NN train) (SBAR (WHNP (WDT that)) (S (VP (VBZ enhances) (NP (PRP$ their) (JJ aerobic) (NN capacity)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="train that enhances their aerobic capacity" type="VP">
          <tokens>
            <token id="9" string="train" />
            <token id="10" string="that" />
            <token id="11" string="enhances" />
            <token id="12" string="their" />
            <token id="13" string="aerobic" />
            <token id="14" string="capacity" />
          </tokens>
        </chunking>
        <chunking id="2" string="the altitude" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="altitude" />
          </tokens>
        </chunking>
        <chunking id="3" string="is the altitude at which the Ethiopians train that enhances their aerobic capacity" type="VP">
          <tokens>
            <token id="2" string="is" />
            <token id="3" string="the" />
            <token id="4" string="altitude" />
            <token id="5" string="at" />
            <token id="6" string="which" />
            <token id="7" string="the" />
            <token id="8" string="Ethiopians" />
            <token id="9" string="train" />
            <token id="10" string="that" />
            <token id="11" string="enhances" />
            <token id="12" string="their" />
            <token id="13" string="aerobic" />
            <token id="14" string="capacity" />
          </tokens>
        </chunking>
        <chunking id="4" string="at which the Ethiopians train that enhances their aerobic capacity" type="SBAR">
          <tokens>
            <token id="5" string="at" />
            <token id="6" string="which" />
            <token id="7" string="the" />
            <token id="8" string="Ethiopians" />
            <token id="9" string="train" />
            <token id="10" string="that" />
            <token id="11" string="enhances" />
            <token id="12" string="their" />
            <token id="13" string="aerobic" />
            <token id="14" string="capacity" />
          </tokens>
        </chunking>
        <chunking id="5" string="their aerobic capacity" type="NP">
          <tokens>
            <token id="12" string="their" />
            <token id="13" string="aerobic" />
            <token id="14" string="capacity" />
          </tokens>
        </chunking>
        <chunking id="6" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="7" string="the altitude at which the Ethiopians train that enhances their aerobic capacity" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="altitude" />
            <token id="5" string="at" />
            <token id="6" string="which" />
            <token id="7" string="the" />
            <token id="8" string="Ethiopians" />
            <token id="9" string="train" />
            <token id="10" string="that" />
            <token id="11" string="enhances" />
            <token id="12" string="their" />
            <token id="13" string="aerobic" />
            <token id="14" string="capacity" />
          </tokens>
        </chunking>
        <chunking id="8" string="enhances their aerobic capacity" type="VP">
          <tokens>
            <token id="11" string="enhances" />
            <token id="12" string="their" />
            <token id="13" string="aerobic" />
            <token id="14" string="capacity" />
          </tokens>
        </chunking>
        <chunking id="9" string="the Ethiopians" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="Ethiopians" />
          </tokens>
        </chunking>
        <chunking id="10" string="that enhances their aerobic capacity" type="SBAR">
          <tokens>
            <token id="10" string="that" />
            <token id="11" string="enhances" />
            <token id="12" string="their" />
            <token id="13" string="aerobic" />
            <token id="14" string="capacity" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">altitude</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">altitude</governor>
          <dependent id="2">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">altitude</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">altitude</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">which</governor>
          <dependent id="5">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">train</governor>
          <dependent id="6">which</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">Ethiopians</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">train</governor>
          <dependent id="8">Ethiopians</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="4">altitude</governor>
          <dependent id="9">train</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">enhances</governor>
          <dependent id="10">that</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="9">train</governor>
          <dependent id="11">enhances</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="14">capacity</governor>
          <dependent id="12">their</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">capacity</governor>
          <dependent id="13">aerobic</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">enhances</governor>
          <dependent id="14">capacity</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ethiopians" type="MISC" score="0.0">
          <tokens>
            <token id="8" string="Ethiopians" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="36" has_coreference="true">
      <content>Much of the central part of the country is mountainous, ranging in altitude from 6,000 to 15,000 feet.</content>
      <tokens>
        <token id="1" string="Much" lemma="much" stem="much" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="2" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="central" lemma="central" stem="central" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="part" lemma="part" stem="part" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="country" lemma="country" stem="countri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="mountainous" lemma="mountainous" stem="mountain" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="ranging" lemma="range" stem="rang" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="altitude" lemma="altitude" stem="altitud" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="6,000" lemma="6,000" stem="6,000" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="17" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="18" string="15,000" lemma="15,000" stem="15,000" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="19" string="feet" lemma="foot" stem="feet" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (JJ Much)) (PP (IN of) (NP (NP (DT the) (JJ central) (NN part)) (PP (IN of) (NP (DT the) (NN country)))))) (VP (VBZ is) (ADJP (JJ mountainous))) (, ,) (VP (VBG ranging) (PP (IN in) (NP (NN altitude))) (PP (IN from) (NP (QP (CD 6,000) (TO to) (CD 15,000)) (NNS feet)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="6,000 to 15,000 feet" type="NP">
          <tokens>
            <token id="16" string="6,000" />
            <token id="17" string="to" />
            <token id="18" string="15,000" />
            <token id="19" string="feet" />
          </tokens>
        </chunking>
        <chunking id="2" string="Much of the central part of the country" type="NP">
          <tokens>
            <token id="1" string="Much" />
            <token id="2" string="of" />
            <token id="3" string="the" />
            <token id="4" string="central" />
            <token id="5" string="part" />
            <token id="6" string="of" />
            <token id="7" string="the" />
            <token id="8" string="country" />
          </tokens>
        </chunking>
        <chunking id="3" string="altitude" type="NP">
          <tokens>
            <token id="14" string="altitude" />
          </tokens>
        </chunking>
        <chunking id="4" string="the country" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="country" />
          </tokens>
        </chunking>
        <chunking id="5" string="is mountainous" type="VP">
          <tokens>
            <token id="9" string="is" />
            <token id="10" string="mountainous" />
          </tokens>
        </chunking>
        <chunking id="6" string="Much" type="NP">
          <tokens>
            <token id="1" string="Much" />
          </tokens>
        </chunking>
        <chunking id="7" string="the central part of the country" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="central" />
            <token id="5" string="part" />
            <token id="6" string="of" />
            <token id="7" string="the" />
            <token id="8" string="country" />
          </tokens>
        </chunking>
        <chunking id="8" string="mountainous" type="ADJP">
          <tokens>
            <token id="10" string="mountainous" />
          </tokens>
        </chunking>
        <chunking id="9" string="ranging in altitude from 6,000 to 15,000 feet" type="VP">
          <tokens>
            <token id="12" string="ranging" />
            <token id="13" string="in" />
            <token id="14" string="altitude" />
            <token id="15" string="from" />
            <token id="16" string="6,000" />
            <token id="17" string="to" />
            <token id="18" string="15,000" />
            <token id="19" string="feet" />
          </tokens>
        </chunking>
        <chunking id="10" string="the central part" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="central" />
            <token id="5" string="part" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="10">mountainous</governor>
          <dependent id="1">Much</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">part</governor>
          <dependent id="2">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">part</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">part</governor>
          <dependent id="4">central</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Much</governor>
          <dependent id="5">part</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">country</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">country</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">part</governor>
          <dependent id="8">country</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="10">mountainous</governor>
          <dependent id="9">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">mountainous</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="10">mountainous</governor>
          <dependent id="12">ranging</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">altitude</governor>
          <dependent id="13">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">ranging</governor>
          <dependent id="14">altitude</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">feet</governor>
          <dependent id="15">from</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">15,000</governor>
          <dependent id="16">6,000</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="18">15,000</governor>
          <dependent id="17">to</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="19">feet</governor>
          <dependent id="18">15,000</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">ranging</governor>
          <dependent id="19">feet</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="6,000 to 15,000" type="NUMBER" score="0.0">
          <tokens>
            <token id="16" string="6,000" />
            <token id="17" string="to" />
            <token id="18" string="15,000" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="37" has_coreference="true">
      <content>It was the first time since 1963 that an Ethiopian had run at Boston and Mekonnen, 24, made the most of it.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="true" is_refers="true" />
        <token id="5" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="since" lemma="since" stem="sinc" pos="IN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="1963" lemma="1963" stem="1963" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="8" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="Ethiopian" lemma="ethiopian" stem="ethiopian" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="true" is_refers="false" />
        <token id="11" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="run" lemma="run" stem="run" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Boston" lemma="Boston" stem="boston" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="Mekonnen" lemma="Mekonnen" stem="mekonnen" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="24" lemma="24" stem="24" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="true" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="made" lemma="make" stem="made" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="most" lemma="most" stem="most" pos="JJS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP It)) (VP (VBD was) (NP (NP (DT the) (JJ first) (NN time)) (PP (IN since) (NP (CD 1963)))) (SBAR (IN that) (S (NP (DT an) (JJ Ethiopian)) (VP (VBD had) (VP (VBN run) (PP (IN at) (NP (NNP Boston))))))))) (CC and) (S (NP (NP (NNP Mekonnen)) (, ,) (NP (CD 24)) (, ,)) (VP (VBD made) (NP (NP (DT the) (JJS most)) (PP (IN of) (NP (PRP it)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="was the first time since 1963 that an Ethiopian had run at Boston" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="the" />
            <token id="4" string="first" />
            <token id="5" string="time" />
            <token id="6" string="since" />
            <token id="7" string="1963" />
            <token id="8" string="that" />
            <token id="9" string="an" />
            <token id="10" string="Ethiopian" />
            <token id="11" string="had" />
            <token id="12" string="run" />
            <token id="13" string="at" />
            <token id="14" string="Boston" />
          </tokens>
        </chunking>
        <chunking id="2" string="24" type="NP">
          <tokens>
            <token id="18" string="24" />
          </tokens>
        </chunking>
        <chunking id="3" string="run at Boston" type="VP">
          <tokens>
            <token id="12" string="run" />
            <token id="13" string="at" />
            <token id="14" string="Boston" />
          </tokens>
        </chunking>
        <chunking id="4" string="Mekonnen , 24 ," type="NP">
          <tokens>
            <token id="16" string="Mekonnen" />
            <token id="17" string="," />
            <token id="18" string="24" />
            <token id="19" string="," />
          </tokens>
        </chunking>
        <chunking id="5" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="6" string="it" type="NP">
          <tokens>
            <token id="24" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="that an Ethiopian had run at Boston" type="SBAR">
          <tokens>
            <token id="8" string="that" />
            <token id="9" string="an" />
            <token id="10" string="Ethiopian" />
            <token id="11" string="had" />
            <token id="12" string="run" />
            <token id="13" string="at" />
            <token id="14" string="Boston" />
          </tokens>
        </chunking>
        <chunking id="8" string="had run at Boston" type="VP">
          <tokens>
            <token id="11" string="had" />
            <token id="12" string="run" />
            <token id="13" string="at" />
            <token id="14" string="Boston" />
          </tokens>
        </chunking>
        <chunking id="9" string="made the most of it" type="VP">
          <tokens>
            <token id="20" string="made" />
            <token id="21" string="the" />
            <token id="22" string="most" />
            <token id="23" string="of" />
            <token id="24" string="it" />
          </tokens>
        </chunking>
        <chunking id="10" string="the most" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="most" />
          </tokens>
        </chunking>
        <chunking id="11" string="the first time" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="first" />
            <token id="5" string="time" />
          </tokens>
        </chunking>
        <chunking id="12" string="Mekonnen" type="NP">
          <tokens>
            <token id="16" string="Mekonnen" />
          </tokens>
        </chunking>
        <chunking id="13" string="1963" type="NP">
          <tokens>
            <token id="7" string="1963" />
          </tokens>
        </chunking>
        <chunking id="14" string="an Ethiopian" type="NP">
          <tokens>
            <token id="9" string="an" />
            <token id="10" string="Ethiopian" />
          </tokens>
        </chunking>
        <chunking id="15" string="the first time since 1963" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="first" />
            <token id="5" string="time" />
            <token id="6" string="since" />
            <token id="7" string="1963" />
          </tokens>
        </chunking>
        <chunking id="16" string="the most of it" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="most" />
            <token id="23" string="of" />
            <token id="24" string="it" />
          </tokens>
        </chunking>
        <chunking id="17" string="Boston" type="NP">
          <tokens>
            <token id="14" string="Boston" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">time</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">time</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">time</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">time</governor>
          <dependent id="4">first</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">time</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">1963</governor>
          <dependent id="6">since</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">time</governor>
          <dependent id="7">1963</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">run</governor>
          <dependent id="8">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">Ethiopian</governor>
          <dependent id="9">an</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">run</governor>
          <dependent id="10">Ethiopian</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">run</governor>
          <dependent id="11">had</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">time</governor>
          <dependent id="12">run</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">Boston</governor>
          <dependent id="13">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">run</governor>
          <dependent id="14">Boston</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">time</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">made</governor>
          <dependent id="16">Mekonnen</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">Mekonnen</governor>
          <dependent id="18">24</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">time</governor>
          <dependent id="20">made</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">most</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">made</governor>
          <dependent id="22">most</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">it</governor>
          <dependent id="23">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">most</governor>
          <dependent id="24">it</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="4" string="first" />
          </tokens>
        </entity>
        <entity id="2" string="24" type="NUMBER" score="0.0">
          <tokens>
            <token id="18" string="24" />
          </tokens>
        </entity>
        <entity id="3" string="Mekonnen" type="PERSON" score="0.0">
          <tokens>
            <token id="16" string="Mekonnen" />
          </tokens>
        </entity>
        <entity id="4" string="1963" type="DATE" score="0.0">
          <tokens>
            <token id="7" string="1963" />
          </tokens>
        </entity>
        <entity id="5" string="Ethiopian" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="10" string="Ethiopian" />
          </tokens>
        </entity>
        <entity id="6" string="Boston" type="LOCATION" score="0.0">
          <tokens>
            <token id="14" string="Boston" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="38" has_coreference="true">
      <content>He was among the pack of four African runners that led the 6,418 entrants race for 15 miles.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="among" lemma="among" stem="among" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="pack" lemma="pack" stem="pack" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="four" lemma="four" stem="four" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="8" string="African" lemma="african" stem="african" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="9" string="runners" lemma="runner" stem="runner" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="led" lemma="lead" stem="led" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="6,418" lemma="6,418" stem="6,418" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="14" string="entrants" lemma="entrant" stem="entrant" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="race" lemma="race" stem="race" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="15" lemma="15" stem="15" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="18" string="miles" lemma="mile" stem="mile" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VBD was) (PP (IN among) (NP (NP (DT the) (NN pack)) (PP (IN of) (NP (NP (CD four) (JJ African) (NNS runners)) (SBAR (WHNP (WDT that)) (S (VP (VBD led) (NP (DT the) (CD 6,418) (NNS entrants) (NN race)) (PP (IN for) (NP (CD 15) (NNS miles))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="four African runners that led the 6,418 entrants race for 15 miles" type="NP">
          <tokens>
            <token id="7" string="four" />
            <token id="8" string="African" />
            <token id="9" string="runners" />
            <token id="10" string="that" />
            <token id="11" string="led" />
            <token id="12" string="the" />
            <token id="13" string="6,418" />
            <token id="14" string="entrants" />
            <token id="15" string="race" />
            <token id="16" string="for" />
            <token id="17" string="15" />
            <token id="18" string="miles" />
          </tokens>
        </chunking>
        <chunking id="2" string="that led the 6,418 entrants race for 15 miles" type="SBAR">
          <tokens>
            <token id="10" string="that" />
            <token id="11" string="led" />
            <token id="12" string="the" />
            <token id="13" string="6,418" />
            <token id="14" string="entrants" />
            <token id="15" string="race" />
            <token id="16" string="for" />
            <token id="17" string="15" />
            <token id="18" string="miles" />
          </tokens>
        </chunking>
        <chunking id="3" string="15 miles" type="NP">
          <tokens>
            <token id="17" string="15" />
            <token id="18" string="miles" />
          </tokens>
        </chunking>
        <chunking id="4" string="the pack" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="pack" />
          </tokens>
        </chunking>
        <chunking id="5" string="the pack of four African runners that led the 6,418 entrants race for 15 miles" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="pack" />
            <token id="6" string="of" />
            <token id="7" string="four" />
            <token id="8" string="African" />
            <token id="9" string="runners" />
            <token id="10" string="that" />
            <token id="11" string="led" />
            <token id="12" string="the" />
            <token id="13" string="6,418" />
            <token id="14" string="entrants" />
            <token id="15" string="race" />
            <token id="16" string="for" />
            <token id="17" string="15" />
            <token id="18" string="miles" />
          </tokens>
        </chunking>
        <chunking id="6" string="four African runners" type="NP">
          <tokens>
            <token id="7" string="four" />
            <token id="8" string="African" />
            <token id="9" string="runners" />
          </tokens>
        </chunking>
        <chunking id="7" string="led the 6,418 entrants race for 15 miles" type="VP">
          <tokens>
            <token id="11" string="led" />
            <token id="12" string="the" />
            <token id="13" string="6,418" />
            <token id="14" string="entrants" />
            <token id="15" string="race" />
            <token id="16" string="for" />
            <token id="17" string="15" />
            <token id="18" string="miles" />
          </tokens>
        </chunking>
        <chunking id="8" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="9" string="was among the pack of four African runners that led the 6,418 entrants race for 15 miles" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="among" />
            <token id="4" string="the" />
            <token id="5" string="pack" />
            <token id="6" string="of" />
            <token id="7" string="four" />
            <token id="8" string="African" />
            <token id="9" string="runners" />
            <token id="10" string="that" />
            <token id="11" string="led" />
            <token id="12" string="the" />
            <token id="13" string="6,418" />
            <token id="14" string="entrants" />
            <token id="15" string="race" />
            <token id="16" string="for" />
            <token id="17" string="15" />
            <token id="18" string="miles" />
          </tokens>
        </chunking>
        <chunking id="10" string="the 6,418 entrants race" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="6,418" />
            <token id="14" string="entrants" />
            <token id="15" string="race" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">pack</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">pack</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">pack</governor>
          <dependent id="3">among</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">pack</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">pack</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">runners</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="9">runners</governor>
          <dependent id="7">four</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">runners</governor>
          <dependent id="8">African</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">pack</governor>
          <dependent id="9">runners</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">led</governor>
          <dependent id="10">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="9">runners</governor>
          <dependent id="11">led</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">race</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="15">race</governor>
          <dependent id="13">6,418</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">race</governor>
          <dependent id="14">entrants</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">led</governor>
          <dependent id="15">race</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">miles</governor>
          <dependent id="16">for</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="18">miles</governor>
          <dependent id="17">15</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">led</governor>
          <dependent id="18">miles</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="15" type="NUMBER" score="0.0">
          <tokens>
            <token id="17" string="15" />
          </tokens>
        </entity>
        <entity id="2" string="four" type="NUMBER" score="0.0">
          <tokens>
            <token id="7" string="four" />
          </tokens>
        </entity>
        <entity id="3" string="African" type="MISC" score="0.0">
          <tokens>
            <token id="8" string="African" />
          </tokens>
        </entity>
        <entity id="4" string="6,418" type="NUMBER" score="0.0">
          <tokens>
            <token id="13" string="6,418" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="39" has_coreference="true">
      <content>At about mile 16, Mekonnen and Ikangaa took off, running at first side by side, then with Ikangaa holding a slight lead.</content>
      <tokens>
        <token id="1" string="At" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="mile" lemma="mile" stem="mile" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="16" lemma="16" stem="16" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Mekonnen" lemma="Mekonnen" stem="mekonnen" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="7" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="Ikangaa" lemma="Ikangaa" stem="ikangaa" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="9" string="took" lemma="take" stem="took" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="off" lemma="off" stem="off" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="running" lemma="run" stem="run" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="true" />
        <token id="15" string="side" lemma="side" stem="side" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="side" lemma="side" stem="side" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="Ikangaa" lemma="Ikangaa" stem="ikangaa" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="22" string="holding" lemma="hold" stem="hold" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="slight" lemma="slight" stem="slight" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="lead" lemma="lead" stem="lead" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN At) (PP (IN about) (NP (NN mile) (CD 16)))) (, ,) (NP (NNP Mekonnen) (CC and) (NNP Ikangaa)) (VP (VBD took) (PRT (RP off)) (, ,) (S (VP (VBG running) (PP (IN at) (NP (JJ first) (NN side))) (PP (IN by) (NP (NN side))) (, ,) (S (ADVP (RB then)) (PP (IN with) (NP (NNP Ikangaa))) (VP (VBG holding) (NP (DT a) (JJ slight) (NN lead))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Ikangaa" type="NP">
          <tokens>
            <token id="21" string="Ikangaa" />
          </tokens>
        </chunking>
        <chunking id="2" string="running at first side by side , then with Ikangaa holding a slight lead" type="VP">
          <tokens>
            <token id="12" string="running" />
            <token id="13" string="at" />
            <token id="14" string="first" />
            <token id="15" string="side" />
            <token id="16" string="by" />
            <token id="17" string="side" />
            <token id="18" string="," />
            <token id="19" string="then" />
            <token id="20" string="with" />
            <token id="21" string="Ikangaa" />
            <token id="22" string="holding" />
            <token id="23" string="a" />
            <token id="24" string="slight" />
            <token id="25" string="lead" />
          </tokens>
        </chunking>
        <chunking id="3" string="side" type="NP">
          <tokens>
            <token id="17" string="side" />
          </tokens>
        </chunking>
        <chunking id="4" string="first side" type="NP">
          <tokens>
            <token id="14" string="first" />
            <token id="15" string="side" />
          </tokens>
        </chunking>
        <chunking id="5" string="a slight lead" type="NP">
          <tokens>
            <token id="23" string="a" />
            <token id="24" string="slight" />
            <token id="25" string="lead" />
          </tokens>
        </chunking>
        <chunking id="6" string="holding a slight lead" type="VP">
          <tokens>
            <token id="22" string="holding" />
            <token id="23" string="a" />
            <token id="24" string="slight" />
            <token id="25" string="lead" />
          </tokens>
        </chunking>
        <chunking id="7" string="mile 16" type="NP">
          <tokens>
            <token id="3" string="mile" />
            <token id="4" string="16" />
          </tokens>
        </chunking>
        <chunking id="8" string="took off , running at first side by side , then with Ikangaa holding a slight lead" type="VP">
          <tokens>
            <token id="9" string="took" />
            <token id="10" string="off" />
            <token id="11" string="," />
            <token id="12" string="running" />
            <token id="13" string="at" />
            <token id="14" string="first" />
            <token id="15" string="side" />
            <token id="16" string="by" />
            <token id="17" string="side" />
            <token id="18" string="," />
            <token id="19" string="then" />
            <token id="20" string="with" />
            <token id="21" string="Ikangaa" />
            <token id="22" string="holding" />
            <token id="23" string="a" />
            <token id="24" string="slight" />
            <token id="25" string="lead" />
          </tokens>
        </chunking>
        <chunking id="9" string="Mekonnen and Ikangaa" type="NP">
          <tokens>
            <token id="6" string="Mekonnen" />
            <token id="7" string="and" />
            <token id="8" string="Ikangaa" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">mile</governor>
          <dependent id="1">At</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">mile</governor>
          <dependent id="2">about</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">took</governor>
          <dependent id="3">mile</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="3">mile</governor>
          <dependent id="4">16</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">took</governor>
          <dependent id="6">Mekonnen</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">Mekonnen</governor>
          <dependent id="7">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">Mekonnen</governor>
          <dependent id="8">Ikangaa</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">took</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="9">took</governor>
          <dependent id="10">off</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="9">took</governor>
          <dependent id="12">running</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">side</governor>
          <dependent id="13">at</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">side</governor>
          <dependent id="14">first</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">running</governor>
          <dependent id="15">side</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">side</governor>
          <dependent id="16">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">running</governor>
          <dependent id="17">side</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="22">holding</governor>
          <dependent id="19">then</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">Ikangaa</governor>
          <dependent id="20">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">holding</governor>
          <dependent id="21">Ikangaa</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="12">running</governor>
          <dependent id="22">holding</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">lead</governor>
          <dependent id="23">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">lead</governor>
          <dependent id="24">slight</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">holding</governor>
          <dependent id="25">lead</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ikangaa" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Ikangaa" />
          </tokens>
        </entity>
        <entity id="2" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="14" string="first" />
          </tokens>
        </entity>
        <entity id="3" string="Mekonnen" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Mekonnen" />
          </tokens>
        </entity>
        <entity id="4" string="16" type="NUMBER" score="0.0">
          <tokens>
            <token id="4" string="16" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="40" has_coreference="true">
      <content>And they ran not as strangers, because Mekonnen had beaten Ikangaa in winning last year&amp;apost;s Tokyo Marathon.</content>
      <tokens>
        <token id="1" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="ran" lemma="run" stem="ran" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="strangers" lemma="stranger" stem="stranger" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Mekonnen" lemma="Mekonnen" stem="mekonnen" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="10" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="beaten" lemma="beat" stem="beaten" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="Ikangaa" lemma="Ikangaa" stem="ikangaa" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="13" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="winning" lemma="win" stem="win" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="true" />
        <token id="16" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="true" />
        <token id="17" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="18" string="Tokyo" lemma="Tokyo" stem="tokyo" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="19" string="Marathon" lemma="Marathon" stem="marathon" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC And) (NP (PRP they)) (VP (VBD ran) (RB not) (PP (IN as) (NP (NNS strangers))) (, ,) (SBAR (IN because) (S (NP (NNP Mekonnen)) (VP (VBD had) (VP (VBN beaten) (NP (NNP Ikangaa)) (PP (IN in) (S (VP (VBG winning) (NP (NP (JJ last) (NN year) (POS 's)) (NNP Tokyo) (NNP Marathon)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Ikangaa" type="NP">
          <tokens>
            <token id="12" string="Ikangaa" />
          </tokens>
        </chunking>
        <chunking id="2" string="they" type="NP">
          <tokens>
            <token id="2" string="they" />
          </tokens>
        </chunking>
        <chunking id="3" string="last year 's" type="NP">
          <tokens>
            <token id="15" string="last" />
            <token id="16" string="year" />
            <token id="17" string="'s" />
          </tokens>
        </chunking>
        <chunking id="4" string="Mekonnen" type="NP">
          <tokens>
            <token id="9" string="Mekonnen" />
          </tokens>
        </chunking>
        <chunking id="5" string="last year 's Tokyo Marathon" type="NP">
          <tokens>
            <token id="15" string="last" />
            <token id="16" string="year" />
            <token id="17" string="'s" />
            <token id="18" string="Tokyo" />
            <token id="19" string="Marathon" />
          </tokens>
        </chunking>
        <chunking id="6" string="because Mekonnen had beaten Ikangaa in winning last year 's Tokyo Marathon" type="SBAR">
          <tokens>
            <token id="8" string="because" />
            <token id="9" string="Mekonnen" />
            <token id="10" string="had" />
            <token id="11" string="beaten" />
            <token id="12" string="Ikangaa" />
            <token id="13" string="in" />
            <token id="14" string="winning" />
            <token id="15" string="last" />
            <token id="16" string="year" />
            <token id="17" string="'s" />
            <token id="18" string="Tokyo" />
            <token id="19" string="Marathon" />
          </tokens>
        </chunking>
        <chunking id="7" string="ran not as strangers , because Mekonnen had beaten Ikangaa in winning last year 's Tokyo Marathon" type="VP">
          <tokens>
            <token id="3" string="ran" />
            <token id="4" string="not" />
            <token id="5" string="as" />
            <token id="6" string="strangers" />
            <token id="7" string="," />
            <token id="8" string="because" />
            <token id="9" string="Mekonnen" />
            <token id="10" string="had" />
            <token id="11" string="beaten" />
            <token id="12" string="Ikangaa" />
            <token id="13" string="in" />
            <token id="14" string="winning" />
            <token id="15" string="last" />
            <token id="16" string="year" />
            <token id="17" string="'s" />
            <token id="18" string="Tokyo" />
            <token id="19" string="Marathon" />
          </tokens>
        </chunking>
        <chunking id="8" string="winning last year 's Tokyo Marathon" type="VP">
          <tokens>
            <token id="14" string="winning" />
            <token id="15" string="last" />
            <token id="16" string="year" />
            <token id="17" string="'s" />
            <token id="18" string="Tokyo" />
            <token id="19" string="Marathon" />
          </tokens>
        </chunking>
        <chunking id="9" string="beaten Ikangaa in winning last year 's Tokyo Marathon" type="VP">
          <tokens>
            <token id="11" string="beaten" />
            <token id="12" string="Ikangaa" />
            <token id="13" string="in" />
            <token id="14" string="winning" />
            <token id="15" string="last" />
            <token id="16" string="year" />
            <token id="17" string="'s" />
            <token id="18" string="Tokyo" />
            <token id="19" string="Marathon" />
          </tokens>
        </chunking>
        <chunking id="10" string="strangers" type="NP">
          <tokens>
            <token id="6" string="strangers" />
          </tokens>
        </chunking>
        <chunking id="11" string="had beaten Ikangaa in winning last year 's Tokyo Marathon" type="VP">
          <tokens>
            <token id="10" string="had" />
            <token id="11" string="beaten" />
            <token id="12" string="Ikangaa" />
            <token id="13" string="in" />
            <token id="14" string="winning" />
            <token id="15" string="last" />
            <token id="16" string="year" />
            <token id="17" string="'s" />
            <token id="18" string="Tokyo" />
            <token id="19" string="Marathon" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="3">ran</governor>
          <dependent id="1">And</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">ran</governor>
          <dependent id="2">they</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">ran</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="3">ran</governor>
          <dependent id="4">not</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">strangers</governor>
          <dependent id="5">as</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">ran</governor>
          <dependent id="6">strangers</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">beaten</governor>
          <dependent id="8">because</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">beaten</governor>
          <dependent id="9">Mekonnen</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">beaten</governor>
          <dependent id="10">had</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">ran</governor>
          <dependent id="11">beaten</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">beaten</governor>
          <dependent id="12">Ikangaa</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">winning</governor>
          <dependent id="13">in</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="11">beaten</governor>
          <dependent id="14">winning</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">year</governor>
          <dependent id="15">last</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="19">Marathon</governor>
          <dependent id="16">year</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">year</governor>
          <dependent id="17">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">Marathon</governor>
          <dependent id="18">Tokyo</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">winning</governor>
          <dependent id="19">Marathon</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ikangaa" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Ikangaa" />
          </tokens>
        </entity>
        <entity id="2" string="Mekonnen" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="Mekonnen" />
          </tokens>
        </entity>
        <entity id="3" string="last year" type="DATE" score="0.0">
          <tokens>
            <token id="15" string="last" />
            <token id="16" string="year" />
          </tokens>
        </entity>
        <entity id="4" string="Tokyo Marathon" type="LOCATION" score="0.0">
          <tokens>
            <token id="18" string="Tokyo" />
            <token id="19" string="Marathon" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="41" has_coreference="true">
      <content>&amp;quot;I know him very well as a runner,&amp;quot; Mekonnen said through an interpreter.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="know" lemma="know" stem="know" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="very" lemma="very" stem="veri" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="well" lemma="well" stem="well" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="runner" lemma="runner" stem="runner" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Mekonnen" lemma="Mekonnen" stem="mekonnen" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="13" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="interpreter" lemma="interpreter" stem="interpret" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP I)) (VP (VBP know) (NP (PRP him)) (ADVP (ADVP (RB very) (RB well)) (PP (IN as) (NP (DT a) (NN runner)))))) (, ,) ('' '') (NP (NNP Mekonnen)) (VP (VBD said) (PP (IN through) (NP (DT an) (NN interpreter)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Mekonnen" type="NP">
          <tokens>
            <token id="12" string="Mekonnen" />
          </tokens>
        </chunking>
        <chunking id="2" string="said through an interpreter" type="VP">
          <tokens>
            <token id="13" string="said" />
            <token id="14" string="through" />
            <token id="15" string="an" />
            <token id="16" string="interpreter" />
          </tokens>
        </chunking>
        <chunking id="3" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="4" string="a runner" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="runner" />
          </tokens>
        </chunking>
        <chunking id="5" string="know him very well as a runner" type="VP">
          <tokens>
            <token id="3" string="know" />
            <token id="4" string="him" />
            <token id="5" string="very" />
            <token id="6" string="well" />
            <token id="7" string="as" />
            <token id="8" string="a" />
            <token id="9" string="runner" />
          </tokens>
        </chunking>
        <chunking id="6" string="him" type="NP">
          <tokens>
            <token id="4" string="him" />
          </tokens>
        </chunking>
        <chunking id="7" string="an interpreter" type="NP">
          <tokens>
            <token id="15" string="an" />
            <token id="16" string="interpreter" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">know</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="13">said</governor>
          <dependent id="3">know</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">know</governor>
          <dependent id="4">him</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">well</governor>
          <dependent id="5">very</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">know</governor>
          <dependent id="6">well</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">runner</governor>
          <dependent id="7">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">runner</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">well</governor>
          <dependent id="9">runner</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">said</governor>
          <dependent id="12">Mekonnen</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">said</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">interpreter</governor>
          <dependent id="14">through</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">interpreter</governor>
          <dependent id="15">an</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">said</governor>
          <dependent id="16">interpreter</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Mekonnen" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Mekonnen" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="42" has_coreference="true">
      <content>&amp;quot;I knew that I should stay with him until the last (two miles).</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="knew" lemma="know" stem="knew" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="should" lemma="should" stem="should" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="stay" lemma="stay" stem="stai" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="until" lemma="until" stem="until" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="15" string="miles" lemma="mile" stem="mile" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP I)) (VP (VBD knew) (SBAR (IN that) (S (NP (PRP I)) (VP (MD should) (VP (VB stay) (PP (IN with) (NP (PRP him))) (PP (IN until) (NP (NP (DT the) (JJ last)) (PRN (-LRB- -LRB-) (NP (CD two) (NNS miles)) (-RRB- -RRB-))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="knew that I should stay with him until the last -LRB- two miles -RRB-" type="VP">
          <tokens>
            <token id="3" string="knew" />
            <token id="4" string="that" />
            <token id="5" string="I" />
            <token id="6" string="should" />
            <token id="7" string="stay" />
            <token id="8" string="with" />
            <token id="9" string="him" />
            <token id="10" string="until" />
            <token id="11" string="the" />
            <token id="12" string="last" />
            <token id="13" string="(" />
            <token id="14" string="two" />
            <token id="15" string="miles" />
            <token id="16" string=")" />
          </tokens>
        </chunking>
        <chunking id="2" string="that I should stay with him until the last -LRB- two miles -RRB-" type="SBAR">
          <tokens>
            <token id="4" string="that" />
            <token id="5" string="I" />
            <token id="6" string="should" />
            <token id="7" string="stay" />
            <token id="8" string="with" />
            <token id="9" string="him" />
            <token id="10" string="until" />
            <token id="11" string="the" />
            <token id="12" string="last" />
            <token id="13" string="(" />
            <token id="14" string="two" />
            <token id="15" string="miles" />
            <token id="16" string=")" />
          </tokens>
        </chunking>
        <chunking id="3" string="stay with him until the last -LRB- two miles -RRB-" type="VP">
          <tokens>
            <token id="7" string="stay" />
            <token id="8" string="with" />
            <token id="9" string="him" />
            <token id="10" string="until" />
            <token id="11" string="the" />
            <token id="12" string="last" />
            <token id="13" string="(" />
            <token id="14" string="two" />
            <token id="15" string="miles" />
            <token id="16" string=")" />
          </tokens>
        </chunking>
        <chunking id="4" string="two miles" type="NP">
          <tokens>
            <token id="14" string="two" />
            <token id="15" string="miles" />
          </tokens>
        </chunking>
        <chunking id="5" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="6" string="him" type="NP">
          <tokens>
            <token id="9" string="him" />
          </tokens>
        </chunking>
        <chunking id="7" string="should stay with him until the last -LRB- two miles -RRB-" type="VP">
          <tokens>
            <token id="6" string="should" />
            <token id="7" string="stay" />
            <token id="8" string="with" />
            <token id="9" string="him" />
            <token id="10" string="until" />
            <token id="11" string="the" />
            <token id="12" string="last" />
            <token id="13" string="(" />
            <token id="14" string="two" />
            <token id="15" string="miles" />
            <token id="16" string=")" />
          </tokens>
        </chunking>
        <chunking id="8" string="the last" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="last" />
          </tokens>
        </chunking>
        <chunking id="9" string="the last -LRB- two miles -RRB-" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="last" />
            <token id="13" string="(" />
            <token id="14" string="two" />
            <token id="15" string="miles" />
            <token id="16" string=")" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">knew</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">knew</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">stay</governor>
          <dependent id="4">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">stay</governor>
          <dependent id="5">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">stay</governor>
          <dependent id="6">should</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">knew</governor>
          <dependent id="7">stay</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">him</governor>
          <dependent id="8">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">stay</governor>
          <dependent id="9">him</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">last</governor>
          <dependent id="10">until</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">last</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">stay</governor>
          <dependent id="12">last</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="15">miles</governor>
          <dependent id="14">two</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="12">last</governor>
          <dependent id="15">miles</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="14" string="two" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="43" has_coreference="true">
      <content>He&amp;apost;s a good runner, but he does not have a good finish.&amp;quot;</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="good" lemma="good" stem="good" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="runner" lemma="runner" stem="runner" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="does" lemma="do" stem="doe" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="good" lemma="good" stem="good" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="finish" lemma="finish" stem="finish" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP He)) (VP (VBZ 's) (NP (DT a) (JJ good) (NN runner)))) (, ,) (CC but) (S (NP (PRP he)) (VP (VBZ does) (RB not) (VP (VB have) (NP (DT a) (JJ good) (NN finish))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="'s a good runner" type="VP">
          <tokens>
            <token id="2" string="'s" />
            <token id="3" string="a" />
            <token id="4" string="good" />
            <token id="5" string="runner" />
          </tokens>
        </chunking>
        <chunking id="2" string="does not have a good finish" type="VP">
          <tokens>
            <token id="9" string="does" />
            <token id="10" string="not" />
            <token id="11" string="have" />
            <token id="12" string="a" />
            <token id="13" string="good" />
            <token id="14" string="finish" />
          </tokens>
        </chunking>
        <chunking id="3" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="4" string="he" type="NP">
          <tokens>
            <token id="8" string="he" />
          </tokens>
        </chunking>
        <chunking id="5" string="have a good finish" type="VP">
          <tokens>
            <token id="11" string="have" />
            <token id="12" string="a" />
            <token id="13" string="good" />
            <token id="14" string="finish" />
          </tokens>
        </chunking>
        <chunking id="6" string="a good finish" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="good" />
            <token id="14" string="finish" />
          </tokens>
        </chunking>
        <chunking id="7" string="a good runner" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="good" />
            <token id="5" string="runner" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">runner</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">runner</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">runner</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">runner</governor>
          <dependent id="4">good</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">runner</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">runner</governor>
          <dependent id="7">but</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">have</governor>
          <dependent id="8">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">have</governor>
          <dependent id="9">does</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="11">have</governor>
          <dependent id="10">not</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">runner</governor>
          <dependent id="11">have</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">finish</governor>
          <dependent id="12">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">finish</governor>
          <dependent id="13">good</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">have</governor>
          <dependent id="14">finish</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="44" has_coreference="true">
      <content>Mekonnen and Kristiansen each earned $45,000.</content>
      <tokens>
        <token id="1" string="Mekonnen" lemma="Mekonnen" stem="mekonnen" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="2" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="Kristiansen" lemma="Kristiansen" stem="kristiansen" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="4" string="each" lemma="each" stem="each" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="earned" lemma="earn" stem="earn" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="7" string="45,000" lemma="45,000" stem="45,000" pos="CD" type="Word" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Mekonnen) (CC and) (NNP Kristiansen)) (DT each) (VP (VBD earned) (NP ($ $) (CD 45,000))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Mekonnen and Kristiansen" type="NP">
          <tokens>
            <token id="1" string="Mekonnen" />
            <token id="2" string="and" />
            <token id="3" string="Kristiansen" />
          </tokens>
        </chunking>
        <chunking id="2" string="earned $ 45,000" type="VP">
          <tokens>
            <token id="5" string="earned" />
            <token id="6" string="$" />
            <token id="7" string="45,000" />
          </tokens>
        </chunking>
        <chunking id="3" string="$ 45,000" type="NP">
          <tokens>
            <token id="6" string="$" />
            <token id="7" string="45,000" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">earned</governor>
          <dependent id="1">Mekonnen</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="1">Mekonnen</governor>
          <dependent id="2">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="1">Mekonnen</governor>
          <dependent id="3">Kristiansen</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="5">earned</governor>
          <dependent id="4">each</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">earned</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="7">45,000</governor>
          <dependent id="6">$</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">earned</governor>
          <dependent id="7">45,000</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Mekonnen" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Mekonnen" />
          </tokens>
        </entity>
        <entity id="2" string="$ 45,000" type="MONEY" score="0.0">
          <tokens>
            <token id="6" string="$" />
            <token id="7" string="45,000" />
          </tokens>
        </entity>
        <entity id="3" string="Kristiansen" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Kristiansen" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="45" has_coreference="true">
      <content>John Treacy of Ireland, who was third behind Ikangaa here last year, was third again in 2:10:24.</content>
      <tokens>
        <token id="1" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="Treacy" lemma="Treacy" stem="treaci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="Ireland" lemma="Ireland" stem="ireland" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="third" lemma="third" stem="third" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="true" is_refers="false" />
        <token id="9" string="behind" lemma="behind" stem="behind" pos="IN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="Ikangaa" lemma="Ikangaa" stem="ikangaa" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="11" string="here" lemma="here" stem="here" pos="RB" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="13" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="third" lemma="third" stem="third" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="17" string="again" lemma="again" stem="again" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="2:10:24" lemma="2:10:24" stem="2:10:24" pos="CD" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP John) (NNP Treacy)) (PP (IN of) (NP (NNP Ireland))) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBD was) (ADJP (JJ third) (PP (IN behind) (NP (NNP Ikangaa)))) (NP-TMP (RB here) (JJ last) (NN year))))) (, ,)) (VP (VBD was) (ADJP (JJ third)) (PP (ADVP (RB again)) (IN in) (NP (CD 2:10:24)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="John Treacy of Ireland , who was third behind Ikangaa here last year ," type="NP">
          <tokens>
            <token id="1" string="John" />
            <token id="2" string="Treacy" />
            <token id="3" string="of" />
            <token id="4" string="Ireland" />
            <token id="5" string="," />
            <token id="6" string="who" />
            <token id="7" string="was" />
            <token id="8" string="third" />
            <token id="9" string="behind" />
            <token id="10" string="Ikangaa" />
            <token id="11" string="here" />
            <token id="12" string="last" />
            <token id="13" string="year" />
            <token id="14" string="," />
          </tokens>
        </chunking>
        <chunking id="2" string="Ikangaa" type="NP">
          <tokens>
            <token id="10" string="Ikangaa" />
          </tokens>
        </chunking>
        <chunking id="3" string="who was third behind Ikangaa here last year" type="SBAR">
          <tokens>
            <token id="6" string="who" />
            <token id="7" string="was" />
            <token id="8" string="third" />
            <token id="9" string="behind" />
            <token id="10" string="Ikangaa" />
            <token id="11" string="here" />
            <token id="12" string="last" />
            <token id="13" string="year" />
          </tokens>
        </chunking>
        <chunking id="4" string="John Treacy" type="NP">
          <tokens>
            <token id="1" string="John" />
            <token id="2" string="Treacy" />
          </tokens>
        </chunking>
        <chunking id="5" string="third behind Ikangaa" type="ADJP">
          <tokens>
            <token id="8" string="third" />
            <token id="9" string="behind" />
            <token id="10" string="Ikangaa" />
          </tokens>
        </chunking>
        <chunking id="6" string="third" type="ADJP">
          <tokens>
            <token id="16" string="third" />
          </tokens>
        </chunking>
        <chunking id="7" string="Ireland" type="NP">
          <tokens>
            <token id="4" string="Ireland" />
          </tokens>
        </chunking>
        <chunking id="8" string="was third again in 2:10:24" type="VP">
          <tokens>
            <token id="15" string="was" />
            <token id="16" string="third" />
            <token id="17" string="again" />
            <token id="18" string="in" />
            <token id="19" string="2:10:24" />
          </tokens>
        </chunking>
        <chunking id="9" string="2:10:24" type="NP">
          <tokens>
            <token id="19" string="2:10:24" />
          </tokens>
        </chunking>
        <chunking id="10" string="was third behind Ikangaa here last year" type="VP">
          <tokens>
            <token id="7" string="was" />
            <token id="8" string="third" />
            <token id="9" string="behind" />
            <token id="10" string="Ikangaa" />
            <token id="11" string="here" />
            <token id="12" string="last" />
            <token id="13" string="year" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Treacy</governor>
          <dependent id="1">John</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">third</governor>
          <dependent id="2">Treacy</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">Ireland</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">Treacy</governor>
          <dependent id="4">Ireland</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">third</governor>
          <dependent id="6">who</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="8">third</governor>
          <dependent id="7">was</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="2">Treacy</governor>
          <dependent id="8">third</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">Ikangaa</governor>
          <dependent id="9">behind</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">third</governor>
          <dependent id="10">Ikangaa</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">year</governor>
          <dependent id="11">here</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">year</governor>
          <dependent id="12">last</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="8">third</governor>
          <dependent id="13">year</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="16">third</governor>
          <dependent id="15">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="16">third</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="19">2:10:24</governor>
          <dependent id="17">again</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">2:10:24</governor>
          <dependent id="18">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">third</governor>
          <dependent id="19">2:10:24</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ikangaa" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Ikangaa" />
          </tokens>
        </entity>
        <entity id="2" string="John Treacy" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="John" />
            <token id="2" string="Treacy" />
          </tokens>
        </entity>
        <entity id="3" string="third" type="ORDINAL" score="0.0">
          <tokens>
            <token id="8" string="third" />
          </tokens>
        </entity>
        <entity id="4" string="Ireland" type="LOCATION" score="0.0">
          <tokens>
            <token id="4" string="Ireland" />
          </tokens>
        </entity>
        <entity id="5" string="last year" type="DATE" score="0.0">
          <tokens>
            <token id="12" string="last" />
            <token id="13" string="year" />
          </tokens>
        </entity>
        <entity id="6" string="2:10:24" type="TIME" score="0.0">
          <tokens>
            <token id="19" string="2:10:24" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="46" has_coreference="true">
      <content>&amp;quot;I knew that they had gone out very hard,&amp;quot; Treacy said of the blistering early pace.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="knew" lemma="know" stem="knew" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="gone" lemma="go" stem="gone" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="out" lemma="out" stem="out" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="very" lemma="very" stem="veri" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="hard" lemma="hard" stem="hard" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Treacy" lemma="Treacy" stem="treaci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="14" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="blistering" lemma="blister" stem="blister" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="early" lemma="early" stem="earli" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="pace" lemma="pace" stem="pace" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP I)) (VP (VBD knew) (SBAR (IN that) (S (NP (PRP they)) (VP (VBD had) (VP (VBN gone) (PRT (RB out)) (ADVP (RB very) (RB hard)))))))) (, ,) ('' '') (NP (NNP Treacy)) (VP (VBD said) (PP (IN of) (NP (DT the) (VBG blistering) (JJ early) (NN pace)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="they" type="NP">
          <tokens>
            <token id="5" string="they" />
          </tokens>
        </chunking>
        <chunking id="2" string="that they had gone out very hard" type="SBAR">
          <tokens>
            <token id="4" string="that" />
            <token id="5" string="they" />
            <token id="6" string="had" />
            <token id="7" string="gone" />
            <token id="8" string="out" />
            <token id="9" string="very" />
            <token id="10" string="hard" />
          </tokens>
        </chunking>
        <chunking id="3" string="Treacy" type="NP">
          <tokens>
            <token id="13" string="Treacy" />
          </tokens>
        </chunking>
        <chunking id="4" string="knew that they had gone out very hard" type="VP">
          <tokens>
            <token id="3" string="knew" />
            <token id="4" string="that" />
            <token id="5" string="they" />
            <token id="6" string="had" />
            <token id="7" string="gone" />
            <token id="8" string="out" />
            <token id="9" string="very" />
            <token id="10" string="hard" />
          </tokens>
        </chunking>
        <chunking id="5" string="had gone out very hard" type="VP">
          <tokens>
            <token id="6" string="had" />
            <token id="7" string="gone" />
            <token id="8" string="out" />
            <token id="9" string="very" />
            <token id="10" string="hard" />
          </tokens>
        </chunking>
        <chunking id="6" string="gone out very hard" type="VP">
          <tokens>
            <token id="7" string="gone" />
            <token id="8" string="out" />
            <token id="9" string="very" />
            <token id="10" string="hard" />
          </tokens>
        </chunking>
        <chunking id="7" string="the blistering early pace" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="blistering" />
            <token id="18" string="early" />
            <token id="19" string="pace" />
          </tokens>
        </chunking>
        <chunking id="8" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="9" string="said of the blistering early pace" type="VP">
          <tokens>
            <token id="14" string="said" />
            <token id="15" string="of" />
            <token id="16" string="the" />
            <token id="17" string="blistering" />
            <token id="18" string="early" />
            <token id="19" string="pace" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">knew</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="14">said</governor>
          <dependent id="3">knew</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">gone</governor>
          <dependent id="4">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">gone</governor>
          <dependent id="5">they</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">gone</governor>
          <dependent id="6">had</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">knew</governor>
          <dependent id="7">gone</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="7">gone</governor>
          <dependent id="8">out</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">hard</governor>
          <dependent id="9">very</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">gone</governor>
          <dependent id="10">hard</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">said</governor>
          <dependent id="13">Treacy</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">said</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">pace</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">pace</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">pace</governor>
          <dependent id="17">blistering</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">pace</governor>
          <dependent id="18">early</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">said</governor>
          <dependent id="19">pace</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Treacy" type="PERSON" score="0.0">
          <tokens>
            <token id="13" string="Treacy" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="47" has_coreference="true">
      <content>Until the halfway point, the men were on a 2:04 pace, dangerous in Monday&amp;apost;s heat.</content>
      <tokens>
        <token id="1" string="Until" lemma="until" stem="until" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="halfway" lemma="halfway" stem="halfwai" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="point" lemma="point" stem="point" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="men" lemma="man" stem="men" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="2:04" lemma="2:04" stem="2:04" pos="CD" type="Word" isStopWord="false" ner="TIME" is_referenced="true" is_refers="false" />
        <token id="12" string="pace" lemma="pace" stem="pace" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="dangerous" lemma="dangerous" stem="danger" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="Monday" lemma="Monday" stem="mondai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="17" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="heat" lemma="heat" stem="heat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN Until) (NP (DT the) (ADJP (RB halfway)) (NN point))) (, ,) (NP (DT the) (NNS men)) (VP (VBD were) (ADJP (ADJP (PP (IN on) (NP (DT a) (CD 2:04) (NN pace))) (, ,) (JJ dangerous)) (PP (IN in) (NP (NP (NNP Monday) (POS 's)) (NN heat))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a 2:04 pace" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="2:04" />
            <token id="12" string="pace" />
          </tokens>
        </chunking>
        <chunking id="2" string="were on a 2:04 pace , dangerous in Monday 's heat" type="VP">
          <tokens>
            <token id="8" string="were" />
            <token id="9" string="on" />
            <token id="10" string="a" />
            <token id="11" string="2:04" />
            <token id="12" string="pace" />
            <token id="13" string="," />
            <token id="14" string="dangerous" />
            <token id="15" string="in" />
            <token id="16" string="Monday" />
            <token id="17" string="'s" />
            <token id="18" string="heat" />
          </tokens>
        </chunking>
        <chunking id="3" string="on a 2:04 pace , dangerous in Monday 's heat" type="ADJP">
          <tokens>
            <token id="9" string="on" />
            <token id="10" string="a" />
            <token id="11" string="2:04" />
            <token id="12" string="pace" />
            <token id="13" string="," />
            <token id="14" string="dangerous" />
            <token id="15" string="in" />
            <token id="16" string="Monday" />
            <token id="17" string="'s" />
            <token id="18" string="heat" />
          </tokens>
        </chunking>
        <chunking id="4" string="Monday 's" type="NP">
          <tokens>
            <token id="16" string="Monday" />
            <token id="17" string="'s" />
          </tokens>
        </chunking>
        <chunking id="5" string="Monday 's heat" type="NP">
          <tokens>
            <token id="16" string="Monday" />
            <token id="17" string="'s" />
            <token id="18" string="heat" />
          </tokens>
        </chunking>
        <chunking id="6" string="the halfway point" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="halfway" />
            <token id="4" string="point" />
          </tokens>
        </chunking>
        <chunking id="7" string="on a 2:04 pace , dangerous" type="ADJP">
          <tokens>
            <token id="9" string="on" />
            <token id="10" string="a" />
            <token id="11" string="2:04" />
            <token id="12" string="pace" />
            <token id="13" string="," />
            <token id="14" string="dangerous" />
          </tokens>
        </chunking>
        <chunking id="8" string="halfway" type="ADJP">
          <tokens>
            <token id="3" string="halfway" />
          </tokens>
        </chunking>
        <chunking id="9" string="the men" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="men" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">point</governor>
          <dependent id="1">Until</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">point</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">point</governor>
          <dependent id="3">halfway</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">dangerous</governor>
          <dependent id="4">point</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">men</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">dangerous</governor>
          <dependent id="7">men</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="14">dangerous</governor>
          <dependent id="8">were</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">pace</governor>
          <dependent id="9">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">pace</governor>
          <dependent id="10">a</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="12">pace</governor>
          <dependent id="11">2:04</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">dangerous</governor>
          <dependent id="12">pace</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">dangerous</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">heat</governor>
          <dependent id="15">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="18">heat</governor>
          <dependent id="16">Monday</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">Monday</governor>
          <dependent id="17">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">dangerous</governor>
          <dependent id="18">heat</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Monday" type="DATE" score="0.0">
          <tokens>
            <token id="16" string="Monday" />
          </tokens>
        </entity>
        <entity id="2" string="2:04" type="TIME" score="0.0">
          <tokens>
            <token id="11" string="2:04" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="48" has_coreference="true">
      <content>The pace got the best of Saimon Robert Haali of Tanzania, who led the race for five miles.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="pace" lemma="pace" stem="pace" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="got" lemma="get" stem="got" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="best" lemma="best" stem="best" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Saimon" lemma="Saimon" stem="saimon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="8" string="Robert" lemma="Robert" stem="robert" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="9" string="Haali" lemma="Haali" stem="haali" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="Tanzania" lemma="Tanzania" stem="tanzania" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="led" lemma="lead" stem="led" pos="VBD" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="16" string="race" lemma="race" stem="race" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="17" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="five" lemma="five" stem="five" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="19" string="miles" lemma="mile" stem="mile" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN pace)) (VP (VBD got) (NP (NP (DT the) (JJS best)) (PP (IN of) (NP (NP (NNP Saimon) (NNP Robert) (NNP Haali)) (PP (IN of) (NP (NNP Tanzania))) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBD led) (NP (DT the) (NN race)) (PP (IN for) (NP (CD five) (NNS miles)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="led the race for five miles" type="VP">
          <tokens>
            <token id="14" string="led" />
            <token id="15" string="the" />
            <token id="16" string="race" />
            <token id="17" string="for" />
            <token id="18" string="five" />
            <token id="19" string="miles" />
          </tokens>
        </chunking>
        <chunking id="2" string="Tanzania" type="NP">
          <tokens>
            <token id="11" string="Tanzania" />
          </tokens>
        </chunking>
        <chunking id="3" string="Saimon Robert Haali" type="NP">
          <tokens>
            <token id="7" string="Saimon" />
            <token id="8" string="Robert" />
            <token id="9" string="Haali" />
          </tokens>
        </chunking>
        <chunking id="4" string="got the best of Saimon Robert Haali of Tanzania , who led the race for five miles" type="VP">
          <tokens>
            <token id="3" string="got" />
            <token id="4" string="the" />
            <token id="5" string="best" />
            <token id="6" string="of" />
            <token id="7" string="Saimon" />
            <token id="8" string="Robert" />
            <token id="9" string="Haali" />
            <token id="10" string="of" />
            <token id="11" string="Tanzania" />
            <token id="12" string="," />
            <token id="13" string="who" />
            <token id="14" string="led" />
            <token id="15" string="the" />
            <token id="16" string="race" />
            <token id="17" string="for" />
            <token id="18" string="five" />
            <token id="19" string="miles" />
          </tokens>
        </chunking>
        <chunking id="5" string="the best" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="best" />
          </tokens>
        </chunking>
        <chunking id="6" string="the best of Saimon Robert Haali of Tanzania , who led the race for five miles" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="best" />
            <token id="6" string="of" />
            <token id="7" string="Saimon" />
            <token id="8" string="Robert" />
            <token id="9" string="Haali" />
            <token id="10" string="of" />
            <token id="11" string="Tanzania" />
            <token id="12" string="," />
            <token id="13" string="who" />
            <token id="14" string="led" />
            <token id="15" string="the" />
            <token id="16" string="race" />
            <token id="17" string="for" />
            <token id="18" string="five" />
            <token id="19" string="miles" />
          </tokens>
        </chunking>
        <chunking id="7" string="The pace" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="pace" />
          </tokens>
        </chunking>
        <chunking id="8" string="Saimon Robert Haali of Tanzania , who led the race for five miles" type="NP">
          <tokens>
            <token id="7" string="Saimon" />
            <token id="8" string="Robert" />
            <token id="9" string="Haali" />
            <token id="10" string="of" />
            <token id="11" string="Tanzania" />
            <token id="12" string="," />
            <token id="13" string="who" />
            <token id="14" string="led" />
            <token id="15" string="the" />
            <token id="16" string="race" />
            <token id="17" string="for" />
            <token id="18" string="five" />
            <token id="19" string="miles" />
          </tokens>
        </chunking>
        <chunking id="9" string="who led the race for five miles" type="SBAR">
          <tokens>
            <token id="13" string="who" />
            <token id="14" string="led" />
            <token id="15" string="the" />
            <token id="16" string="race" />
            <token id="17" string="for" />
            <token id="18" string="five" />
            <token id="19" string="miles" />
          </tokens>
        </chunking>
        <chunking id="10" string="the race" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="race" />
          </tokens>
        </chunking>
        <chunking id="11" string="five miles" type="NP">
          <tokens>
            <token id="18" string="five" />
            <token id="19" string="miles" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">pace</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">got</governor>
          <dependent id="2">pace</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">got</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">best</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">got</governor>
          <dependent id="5">best</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Haali</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Haali</governor>
          <dependent id="7">Saimon</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Haali</governor>
          <dependent id="8">Robert</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">best</governor>
          <dependent id="9">Haali</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Tanzania</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">Haali</governor>
          <dependent id="11">Tanzania</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">led</governor>
          <dependent id="13">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="9">Haali</governor>
          <dependent id="14">led</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">race</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">led</governor>
          <dependent id="16">race</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">miles</governor>
          <dependent id="17">for</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="19">miles</governor>
          <dependent id="18">five</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">led</governor>
          <dependent id="19">miles</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Tanzania" type="LOCATION" score="0.0">
          <tokens>
            <token id="11" string="Tanzania" />
          </tokens>
        </entity>
        <entity id="2" string="Saimon Robert Haali" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Saimon" />
            <token id="8" string="Robert" />
            <token id="9" string="Haali" />
          </tokens>
        </entity>
        <entity id="3" string="five" type="NUMBER" score="0.0">
          <tokens>
            <token id="18" string="five" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="49" has_coreference="true">
      <content>He finished sixth.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="finished" lemma="finish" stem="finish" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="sixth" lemma="sixth" stem="sixth" pos="RB" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="4" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VBD finished) (ADVP (RB sixth))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="finished sixth" type="VP">
          <tokens>
            <token id="2" string="finished" />
            <token id="3" string="sixth" />
          </tokens>
        </chunking>
        <chunking id="2" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">finished</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">finished</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="2">finished</governor>
          <dependent id="3">sixth</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="sixth" type="ORDINAL" score="0.0">
          <tokens>
            <token id="3" string="sixth" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="50" has_coreference="true">
      <content>The women&amp;apost;s race had only one leader, Kristiansen.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="women" lemma="woman" stem="women" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="race" lemma="race" stem="race" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="only" lemma="only" stem="onli" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="8" string="leader" lemma="leader" stem="leader" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Kristiansen" lemma="Kristiansen" stem="kristiansen" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (NNS women) (POS 's)) (NN race)) (VP (VBD had) (NP (NP (RB only) (CD one) (NN leader)) (, ,) (NP (NNP Kristiansen)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="had only one leader , Kristiansen" type="VP">
          <tokens>
            <token id="5" string="had" />
            <token id="6" string="only" />
            <token id="7" string="one" />
            <token id="8" string="leader" />
            <token id="9" string="," />
            <token id="10" string="Kristiansen" />
          </tokens>
        </chunking>
        <chunking id="2" string="The women 's race" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="women" />
            <token id="3" string="'s" />
            <token id="4" string="race" />
          </tokens>
        </chunking>
        <chunking id="3" string="The women 's" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="women" />
            <token id="3" string="'s" />
          </tokens>
        </chunking>
        <chunking id="4" string="only one leader" type="NP">
          <tokens>
            <token id="6" string="only" />
            <token id="7" string="one" />
            <token id="8" string="leader" />
          </tokens>
        </chunking>
        <chunking id="5" string="only one leader , Kristiansen" type="NP">
          <tokens>
            <token id="6" string="only" />
            <token id="7" string="one" />
            <token id="8" string="leader" />
            <token id="9" string="," />
            <token id="10" string="Kristiansen" />
          </tokens>
        </chunking>
        <chunking id="6" string="Kristiansen" type="NP">
          <tokens>
            <token id="10" string="Kristiansen" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">women</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">race</governor>
          <dependent id="2">women</dependent>
        </dependency>
        <dependency type="case">
          <governor id="2">women</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">had</governor>
          <dependent id="4">race</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">had</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">leader</governor>
          <dependent id="6">only</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="8">leader</governor>
          <dependent id="7">one</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">had</governor>
          <dependent id="8">leader</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="8">leader</governor>
          <dependent id="10">Kristiansen</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="7" string="one" />
          </tokens>
        </entity>
        <entity id="2" string="Kristiansen" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Kristiansen" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="51" has_coreference="true">
      <content>She, too, set an incredible early pace.</content>
      <tokens>
        <token id="1" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="too" lemma="too" stem="too" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="set" lemma="set" stem="set" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="incredible" lemma="incredible" stem="incred" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="early" lemma="early" stem="earli" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="pace" lemma="pace" stem="pace" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP She)) (, ,) (ADVP (RB too)) (, ,) (VP (VBD set) (NP (DT an) (JJ incredible) (JJ early) (NN pace))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="set an incredible early pace" type="VP">
          <tokens>
            <token id="5" string="set" />
            <token id="6" string="an" />
            <token id="7" string="incredible" />
            <token id="8" string="early" />
            <token id="9" string="pace" />
          </tokens>
        </chunking>
        <chunking id="2" string="She" type="NP">
          <tokens>
            <token id="1" string="She" />
          </tokens>
        </chunking>
        <chunking id="3" string="an incredible early pace" type="NP">
          <tokens>
            <token id="6" string="an" />
            <token id="7" string="incredible" />
            <token id="8" string="early" />
            <token id="9" string="pace" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">set</governor>
          <dependent id="1">She</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">set</governor>
          <dependent id="3">too</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">set</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">pace</governor>
          <dependent id="6">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">pace</governor>
          <dependent id="7">incredible</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">pace</governor>
          <dependent id="8">early</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">set</governor>
          <dependent id="9">pace</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="52" has_coreference="true">
      <content>For the first few miles, before the heat, Kristiansen was running at a 2:17 pace.</content>
      <tokens>
        <token id="1" string="For" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="true" />
        <token id="4" string="few" lemma="few" stem="few" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="miles" lemma="mile" stem="mile" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="before" lemma="before" stem="befor" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="heat" lemma="heat" stem="heat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Kristiansen" lemma="Kristiansen" stem="kristiansen" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="12" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="running" lemma="run" stem="run" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="2:17" lemma="2:17" stem="2:17" pos="CD" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="17" string="pace" lemma="pace" stem="pace" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN For) (NP (DT the) (JJ first) (JJ few) (NNS miles))) (, ,) (PP (IN before) (NP (DT the) (NN heat))) (, ,) (NP (NNP Kristiansen)) (VP (VBD was) (VP (VBG running) (PP (IN at) (NP (DT a) (CD 2:17) (NN pace))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the heat" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="heat" />
          </tokens>
        </chunking>
        <chunking id="2" string="was running at a 2:17 pace" type="VP">
          <tokens>
            <token id="12" string="was" />
            <token id="13" string="running" />
            <token id="14" string="at" />
            <token id="15" string="a" />
            <token id="16" string="2:17" />
            <token id="17" string="pace" />
          </tokens>
        </chunking>
        <chunking id="3" string="running at a 2:17 pace" type="VP">
          <tokens>
            <token id="13" string="running" />
            <token id="14" string="at" />
            <token id="15" string="a" />
            <token id="16" string="2:17" />
            <token id="17" string="pace" />
          </tokens>
        </chunking>
        <chunking id="4" string="the first few miles" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="first" />
            <token id="4" string="few" />
            <token id="5" string="miles" />
          </tokens>
        </chunking>
        <chunking id="5" string="Kristiansen" type="NP">
          <tokens>
            <token id="11" string="Kristiansen" />
          </tokens>
        </chunking>
        <chunking id="6" string="a 2:17 pace" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="2:17" />
            <token id="17" string="pace" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="5">miles</governor>
          <dependent id="1">For</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">miles</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">miles</governor>
          <dependent id="3">first</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">miles</governor>
          <dependent id="4">few</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">running</governor>
          <dependent id="5">miles</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">heat</governor>
          <dependent id="7">before</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">heat</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">running</governor>
          <dependent id="9">heat</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">running</governor>
          <dependent id="11">Kristiansen</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="13">running</governor>
          <dependent id="12">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">running</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">pace</governor>
          <dependent id="14">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">pace</governor>
          <dependent id="15">a</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="17">pace</governor>
          <dependent id="16">2:17</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">running</governor>
          <dependent id="17">pace</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="3" string="first" />
          </tokens>
        </entity>
        <entity id="2" string="2:17" type="TIME" score="0.0">
          <tokens>
            <token id="16" string="2:17" />
          </tokens>
        </entity>
        <entity id="3" string="Kristiansen" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Kristiansen" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="53" has_coreference="true">
      <content>By the 17th mile, she had added more than 20 seconds to her mile splits.</content>
      <tokens>
        <token id="1" string="By" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="17th" lemma="17th" stem="17th" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="true" is_refers="false" />
        <token id="4" string="mile" lemma="mile" stem="mile" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="added" lemma="add" stem="ad" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="10" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="11" string="20" lemma="20" stem="20" pos="CD" type="Number" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="12" string="seconds" lemma="seconds" stem="second" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="13" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="mile" lemma="mile" stem="mile" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="splits" lemma="split" stem="split" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN By) (NP (DT the) (JJ 17th) (NN mile))) (, ,) (NP (PRP she)) (VP (VBD had) (VP (VBN added) (NP (QP (RBR more) (IN than) (CD 20)) (NNS seconds)) (PP (TO to) (NP (NP (PRP$ her) (NN mile)) (VP (VBZ splits)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="her mile splits" type="NP">
          <tokens>
            <token id="14" string="her" />
            <token id="15" string="mile" />
            <token id="16" string="splits" />
          </tokens>
        </chunking>
        <chunking id="2" string="her mile" type="NP">
          <tokens>
            <token id="14" string="her" />
            <token id="15" string="mile" />
          </tokens>
        </chunking>
        <chunking id="3" string="added more than 20 seconds to her mile splits" type="VP">
          <tokens>
            <token id="8" string="added" />
            <token id="9" string="more" />
            <token id="10" string="than" />
            <token id="11" string="20" />
            <token id="12" string="seconds" />
            <token id="13" string="to" />
            <token id="14" string="her" />
            <token id="15" string="mile" />
            <token id="16" string="splits" />
          </tokens>
        </chunking>
        <chunking id="4" string="splits" type="VP">
          <tokens>
            <token id="16" string="splits" />
          </tokens>
        </chunking>
        <chunking id="5" string="the 17th mile" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="17th" />
            <token id="4" string="mile" />
          </tokens>
        </chunking>
        <chunking id="6" string="more than 20 seconds" type="NP">
          <tokens>
            <token id="9" string="more" />
            <token id="10" string="than" />
            <token id="11" string="20" />
            <token id="12" string="seconds" />
          </tokens>
        </chunking>
        <chunking id="7" string="had added more than 20 seconds to her mile splits" type="VP">
          <tokens>
            <token id="7" string="had" />
            <token id="8" string="added" />
            <token id="9" string="more" />
            <token id="10" string="than" />
            <token id="11" string="20" />
            <token id="12" string="seconds" />
            <token id="13" string="to" />
            <token id="14" string="her" />
            <token id="15" string="mile" />
            <token id="16" string="splits" />
          </tokens>
        </chunking>
        <chunking id="8" string="she" type="NP">
          <tokens>
            <token id="6" string="she" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">mile</governor>
          <dependent id="1">By</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">mile</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">mile</governor>
          <dependent id="3">17th</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">added</governor>
          <dependent id="4">mile</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">added</governor>
          <dependent id="6">she</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">added</governor>
          <dependent id="7">had</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">added</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">20</governor>
          <dependent id="9">more</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="9">more</governor>
          <dependent id="10">than</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="12">seconds</governor>
          <dependent id="11">20</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">added</governor>
          <dependent id="12">seconds</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">mile</governor>
          <dependent id="13">to</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="15">mile</governor>
          <dependent id="14">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">added</governor>
          <dependent id="15">mile</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="15">mile</governor>
          <dependent id="16">splits</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="more than 20 seconds" type="DURATION" score="0.0">
          <tokens>
            <token id="9" string="more" />
            <token id="10" string="than" />
            <token id="11" string="20" />
            <token id="12" string="seconds" />
          </tokens>
        </entity>
        <entity id="2" string="17th" type="ORDINAL" score="0.0">
          <tokens>
            <token id="3" string="17th" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="54" has_coreference="true">
      <content>By her own reckoning, it was at almost 16 miles that Kristiansen felt the heat.</content>
      <tokens>
        <token id="1" string="By" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="3" string="own" lemma="own" stem="own" pos="JJ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="reckoning" lemma="reckoning" stem="reckon" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="almost" lemma="almost" stem="almost" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="16" lemma="16" stem="16" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="11" string="miles" lemma="mile" stem="mile" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Kristiansen" lemma="Kristiansen" stem="kristiansen" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="14" string="felt" lemma="feel" stem="felt" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="heat" lemma="heat" stem="heat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN By) (NP (PRP$ her) (JJ own) (NN reckoning))) (, ,) (NP (PRP it)) (VP (VBD was) (PP (IN at) (NP (QP (RB almost) (CD 16)) (NNS miles))) (SBAR (WHNP (WDT that)) (S (NP (NNP Kristiansen)) (VP (VBD felt) (NP (DT the) (NN heat)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="her own reckoning" type="NP">
          <tokens>
            <token id="2" string="her" />
            <token id="3" string="own" />
            <token id="4" string="reckoning" />
          </tokens>
        </chunking>
        <chunking id="2" string="was at almost 16 miles that Kristiansen felt the heat" type="VP">
          <tokens>
            <token id="7" string="was" />
            <token id="8" string="at" />
            <token id="9" string="almost" />
            <token id="10" string="16" />
            <token id="11" string="miles" />
            <token id="12" string="that" />
            <token id="13" string="Kristiansen" />
            <token id="14" string="felt" />
            <token id="15" string="the" />
            <token id="16" string="heat" />
          </tokens>
        </chunking>
        <chunking id="3" string="the heat" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="heat" />
          </tokens>
        </chunking>
        <chunking id="4" string="that Kristiansen felt the heat" type="SBAR">
          <tokens>
            <token id="12" string="that" />
            <token id="13" string="Kristiansen" />
            <token id="14" string="felt" />
            <token id="15" string="the" />
            <token id="16" string="heat" />
          </tokens>
        </chunking>
        <chunking id="5" string="almost 16 miles" type="NP">
          <tokens>
            <token id="9" string="almost" />
            <token id="10" string="16" />
            <token id="11" string="miles" />
          </tokens>
        </chunking>
        <chunking id="6" string="it" type="NP">
          <tokens>
            <token id="6" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="Kristiansen" type="NP">
          <tokens>
            <token id="13" string="Kristiansen" />
          </tokens>
        </chunking>
        <chunking id="8" string="felt the heat" type="VP">
          <tokens>
            <token id="14" string="felt" />
            <token id="15" string="the" />
            <token id="16" string="heat" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">reckoning</governor>
          <dependent id="1">By</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">reckoning</governor>
          <dependent id="2">her</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">reckoning</governor>
          <dependent id="3">own</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">miles</governor>
          <dependent id="4">reckoning</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">miles</governor>
          <dependent id="6">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="11">miles</governor>
          <dependent id="7">was</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">miles</governor>
          <dependent id="8">at</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">16</governor>
          <dependent id="9">almost</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="11">miles</governor>
          <dependent id="10">16</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">miles</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">felt</governor>
          <dependent id="12">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">felt</governor>
          <dependent id="13">Kristiansen</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">miles</governor>
          <dependent id="14">felt</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">heat</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">felt</governor>
          <dependent id="16">heat</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="16" type="NUMBER" score="0.0">
          <tokens>
            <token id="10" string="16" />
          </tokens>
        </entity>
        <entity id="2" string="Kristiansen" type="PERSON" score="0.0">
          <tokens>
            <token id="13" string="Kristiansen" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="55" has_coreference="true">
      <content>&amp;quot;I decided to just win the race,&amp;quot; she said.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="decided" lemma="decide" stem="decid" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="win" lemma="win" stem="win" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="race" lemma="race" stem="race" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP I)) (VP (VBD decided) (S (VP (TO to) (VP (ADVP (RB just)) (VB win) (NP (DT the) (NN race))))))) (, ,) ('' '') (NP (PRP she)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="to just win the race" type="VP">
          <tokens>
            <token id="4" string="to" />
            <token id="5" string="just" />
            <token id="6" string="win" />
            <token id="7" string="the" />
            <token id="8" string="race" />
          </tokens>
        </chunking>
        <chunking id="2" string="just win the race" type="VP">
          <tokens>
            <token id="5" string="just" />
            <token id="6" string="win" />
            <token id="7" string="the" />
            <token id="8" string="race" />
          </tokens>
        </chunking>
        <chunking id="3" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="4" string="the race" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="race" />
          </tokens>
        </chunking>
        <chunking id="5" string="said" type="VP">
          <tokens>
            <token id="12" string="said" />
          </tokens>
        </chunking>
        <chunking id="6" string="decided to just win the race" type="VP">
          <tokens>
            <token id="3" string="decided" />
            <token id="4" string="to" />
            <token id="5" string="just" />
            <token id="6" string="win" />
            <token id="7" string="the" />
            <token id="8" string="race" />
          </tokens>
        </chunking>
        <chunking id="7" string="she" type="NP">
          <tokens>
            <token id="11" string="she" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">decided</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="12">said</governor>
          <dependent id="3">decided</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">win</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">win</governor>
          <dependent id="5">just</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">decided</governor>
          <dependent id="6">win</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">race</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">win</governor>
          <dependent id="8">race</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">said</governor>
          <dependent id="11">she</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">said</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="56" has_coreference="true">
      <content>&amp;quot;It was too hot to set the world record.&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="too" lemma="too" stem="too" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="hot" lemma="hot" stem="hot" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="set" lemma="set" stem="set" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="record" lemma="record" stem="record" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP It)) (VP (VBD was) (ADJP (RB too) (JJ hot) (S (VP (TO to) (VP (VB set) (NP (DT the) (NN world) (NN record))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="too hot to set the world record" type="ADJP">
          <tokens>
            <token id="4" string="too" />
            <token id="5" string="hot" />
            <token id="6" string="to" />
            <token id="7" string="set" />
            <token id="8" string="the" />
            <token id="9" string="world" />
            <token id="10" string="record" />
          </tokens>
        </chunking>
        <chunking id="2" string="was too hot to set the world record" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="too" />
            <token id="5" string="hot" />
            <token id="6" string="to" />
            <token id="7" string="set" />
            <token id="8" string="the" />
            <token id="9" string="world" />
            <token id="10" string="record" />
          </tokens>
        </chunking>
        <chunking id="3" string="to set the world record" type="VP">
          <tokens>
            <token id="6" string="to" />
            <token id="7" string="set" />
            <token id="8" string="the" />
            <token id="9" string="world" />
            <token id="10" string="record" />
          </tokens>
        </chunking>
        <chunking id="4" string="set the world record" type="VP">
          <tokens>
            <token id="7" string="set" />
            <token id="8" string="the" />
            <token id="9" string="world" />
            <token id="10" string="record" />
          </tokens>
        </chunking>
        <chunking id="5" string="It" type="NP">
          <tokens>
            <token id="2" string="It" />
          </tokens>
        </chunking>
        <chunking id="6" string="the world record" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="world" />
            <token id="10" string="record" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">hot</governor>
          <dependent id="2">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">hot</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">hot</governor>
          <dependent id="4">too</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">hot</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">set</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">hot</governor>
          <dependent id="7">set</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">record</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">record</governor>
          <dependent id="9">world</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">set</governor>
          <dependent id="10">record</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="57" has_coreference="true">
      <content>Samuelson held on to second place and even ran comfortably until about 11 miles, when she came undone.</content>
      <tokens>
        <token id="1" string="Samuelson" lemma="Samuelson" stem="samuelson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="held" lemma="hold" stem="held" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="second" lemma="second" stem="second" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="6" string="place" lemma="place" stem="place" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="ran" lemma="run" stem="ran" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="comfortably" lemma="comfortably" stem="comfort" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="until" lemma="until" stem="until" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="11" lemma="11" stem="11" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="true" />
        <token id="14" string="miles" lemma="mile" stem="mile" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="came" lemma="come" stem="came" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="19" string="undone" lemma="undo" stem="undon" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Samuelson)) (VP (VP (VBD held) (PP (IN on) (PP (TO to) (NP (JJ second) (NN place))))) (CC and) (VP (ADVP (RB even)) (VBD ran) (PP (ADVP (RB comfortably)) (IN until) (IN about) (NP (NP (CD 11) (NNS miles)) (, ,) (SBAR (WHADVP (WRB when)) (S (NP (PRP she)) (VP (VBD came) (VP (VBN undone))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="held on to second place" type="VP">
          <tokens>
            <token id="2" string="held" />
            <token id="3" string="on" />
            <token id="4" string="to" />
            <token id="5" string="second" />
            <token id="6" string="place" />
          </tokens>
        </chunking>
        <chunking id="2" string="held on to second place and even ran comfortably until about 11 miles , when she came undone" type="VP">
          <tokens>
            <token id="2" string="held" />
            <token id="3" string="on" />
            <token id="4" string="to" />
            <token id="5" string="second" />
            <token id="6" string="place" />
            <token id="7" string="and" />
            <token id="8" string="even" />
            <token id="9" string="ran" />
            <token id="10" string="comfortably" />
            <token id="11" string="until" />
            <token id="12" string="about" />
            <token id="13" string="11" />
            <token id="14" string="miles" />
            <token id="15" string="," />
            <token id="16" string="when" />
            <token id="17" string="she" />
            <token id="18" string="came" />
            <token id="19" string="undone" />
          </tokens>
        </chunking>
        <chunking id="3" string="Samuelson" type="NP">
          <tokens>
            <token id="1" string="Samuelson" />
          </tokens>
        </chunking>
        <chunking id="4" string="second place" type="NP">
          <tokens>
            <token id="5" string="second" />
            <token id="6" string="place" />
          </tokens>
        </chunking>
        <chunking id="5" string="11 miles" type="NP">
          <tokens>
            <token id="13" string="11" />
            <token id="14" string="miles" />
          </tokens>
        </chunking>
        <chunking id="6" string="when she came undone" type="SBAR">
          <tokens>
            <token id="16" string="when" />
            <token id="17" string="she" />
            <token id="18" string="came" />
            <token id="19" string="undone" />
          </tokens>
        </chunking>
        <chunking id="7" string="even ran comfortably until about 11 miles , when she came undone" type="VP">
          <tokens>
            <token id="8" string="even" />
            <token id="9" string="ran" />
            <token id="10" string="comfortably" />
            <token id="11" string="until" />
            <token id="12" string="about" />
            <token id="13" string="11" />
            <token id="14" string="miles" />
            <token id="15" string="," />
            <token id="16" string="when" />
            <token id="17" string="she" />
            <token id="18" string="came" />
            <token id="19" string="undone" />
          </tokens>
        </chunking>
        <chunking id="8" string="when" type="WHADVP">
          <tokens>
            <token id="16" string="when" />
          </tokens>
        </chunking>
        <chunking id="9" string="she" type="NP">
          <tokens>
            <token id="17" string="she" />
          </tokens>
        </chunking>
        <chunking id="10" string="came undone" type="VP">
          <tokens>
            <token id="18" string="came" />
            <token id="19" string="undone" />
          </tokens>
        </chunking>
        <chunking id="11" string="undone" type="VP">
          <tokens>
            <token id="19" string="undone" />
          </tokens>
        </chunking>
        <chunking id="12" string="11 miles , when she came undone" type="NP">
          <tokens>
            <token id="13" string="11" />
            <token id="14" string="miles" />
            <token id="15" string="," />
            <token id="16" string="when" />
            <token id="17" string="she" />
            <token id="18" string="came" />
            <token id="19" string="undone" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">held</governor>
          <dependent id="1">Samuelson</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">held</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">place</governor>
          <dependent id="3">on</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">place</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">place</governor>
          <dependent id="5">second</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">held</governor>
          <dependent id="6">place</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">held</governor>
          <dependent id="7">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">ran</governor>
          <dependent id="8">even</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">held</governor>
          <dependent id="9">ran</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">miles</governor>
          <dependent id="10">comfortably</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">miles</governor>
          <dependent id="11">until</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">miles</governor>
          <dependent id="12">about</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="14">miles</governor>
          <dependent id="13">11</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">ran</governor>
          <dependent id="14">miles</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">came</governor>
          <dependent id="16">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">came</governor>
          <dependent id="17">she</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="14">miles</governor>
          <dependent id="18">came</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="18">came</governor>
          <dependent id="19">undone</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Samuelson" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Samuelson" />
          </tokens>
        </entity>
        <entity id="2" string="second" type="ORDINAL" score="0.0">
          <tokens>
            <token id="5" string="second" />
          </tokens>
        </entity>
        <entity id="3" string="11" type="NUMBER" score="0.0">
          <tokens>
            <token id="13" string="11" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="58" has_coreference="true">
      <content>&amp;quot;I was prepared for hot weather and it certainly was hot, but the heat wasn&amp;apost;t my problem today,&amp;quot; Samuelson said.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="prepared" lemma="prepare" stem="prepar" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="hot" lemma="hot" stem="hot" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="weather" lemma="weather" stem="weather" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="certainly" lemma="certainly" stem="certainli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="hot" lemma="hot" stem="hot" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="heat" lemma="heat" stem="heat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="my" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="20" string="problem" lemma="problem" stem="problem" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="today" lemma="today" stem="todai" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="Samuelson" lemma="Samuelson" stem="samuelson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="25" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (S (S (NP (PRP I)) (VP (VBD was) (VP (VBN prepared) (PP (IN for) (NP (JJ hot) (NN weather)))))) (CC and) (S (NP (PRP it)) (ADVP (RB certainly)) (VP (VBD was) (ADJP (JJ hot))))) (, ,) (CC but) (S (NP (DT the) (NN heat)) (VP (VBD was) (RB n't) (NP (PRP$ my) (NN problem) (NN today))))) (, ,) ('' '') (NP (NNP Samuelson)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="was prepared for hot weather" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="prepared" />
            <token id="5" string="for" />
            <token id="6" string="hot" />
            <token id="7" string="weather" />
          </tokens>
        </chunking>
        <chunking id="2" string="the heat" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="heat" />
          </tokens>
        </chunking>
        <chunking id="3" string="prepared for hot weather" type="VP">
          <tokens>
            <token id="4" string="prepared" />
            <token id="5" string="for" />
            <token id="6" string="hot" />
            <token id="7" string="weather" />
          </tokens>
        </chunking>
        <chunking id="4" string="hot weather" type="NP">
          <tokens>
            <token id="6" string="hot" />
            <token id="7" string="weather" />
          </tokens>
        </chunking>
        <chunking id="5" string="was hot" type="VP">
          <tokens>
            <token id="11" string="was" />
            <token id="12" string="hot" />
          </tokens>
        </chunking>
        <chunking id="6" string="my problem today" type="NP">
          <tokens>
            <token id="19" string="my" />
            <token id="20" string="problem" />
            <token id="21" string="today" />
          </tokens>
        </chunking>
        <chunking id="7" string="Samuelson" type="NP">
          <tokens>
            <token id="24" string="Samuelson" />
          </tokens>
        </chunking>
        <chunking id="8" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="9" string="it" type="NP">
          <tokens>
            <token id="9" string="it" />
          </tokens>
        </chunking>
        <chunking id="10" string="hot" type="ADJP">
          <tokens>
            <token id="12" string="hot" />
          </tokens>
        </chunking>
        <chunking id="11" string="said" type="VP">
          <tokens>
            <token id="25" string="said" />
          </tokens>
        </chunking>
        <chunking id="12" string="was n't my problem today" type="VP">
          <tokens>
            <token id="17" string="was" />
            <token id="18" string="n't" />
            <token id="19" string="my" />
            <token id="20" string="problem" />
            <token id="21" string="today" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="4">prepared</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="4">prepared</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="25">said</governor>
          <dependent id="4">prepared</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">weather</governor>
          <dependent id="5">for</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">weather</governor>
          <dependent id="6">hot</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">prepared</governor>
          <dependent id="7">weather</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">prepared</governor>
          <dependent id="8">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">hot</governor>
          <dependent id="9">it</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">hot</governor>
          <dependent id="10">certainly</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="12">hot</governor>
          <dependent id="11">was</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">prepared</governor>
          <dependent id="12">hot</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">prepared</governor>
          <dependent id="14">but</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">heat</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">today</governor>
          <dependent id="16">heat</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="21">today</governor>
          <dependent id="17">was</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="21">today</governor>
          <dependent id="18">n't</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="21">today</governor>
          <dependent id="19">my</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">today</governor>
          <dependent id="20">problem</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">prepared</governor>
          <dependent id="21">today</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">said</governor>
          <dependent id="24">Samuelson</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="25">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="today" type="DATE" score="0.0">
          <tokens>
            <token id="21" string="today" />
          </tokens>
        </entity>
        <entity id="2" string="Samuelson" type="PERSON" score="0.0">
          <tokens>
            <token id="24" string="Samuelson" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="59" has_coreference="true">
      <content>&amp;quot;I felt real easy the first 11 miles, I felt I was right in the groove.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="felt" lemma="feel" stem="felt" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="real" lemma="real" stem="real" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="easy" lemma="easy" stem="easi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="true" />
        <token id="8" string="11" lemma="11" stem="11" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="9" string="miles" lemma="mile" stem="mile" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="felt" lemma="feel" stem="felt" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="right" lemma="right" stem="right" pos="RB" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="true" is_refers="false" />
        <token id="16" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="groove" lemma="groove" stem="groov" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP I)) (VP (VBD felt) (S (NP (ADJP (JJ real) (JJ easy)) (NP (DT the) (JJ first) (CD 11) (NNS miles)))))) (, ,) (NP (PRP I)) (VP (VBD felt) (SBAR (S (NP (PRP I)) (VP (VBD was) (ADVP (RB right)) (PP (IN in) (NP (DT the) (NN groove))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="I was right in the groove" type="SBAR">
          <tokens>
            <token id="13" string="I" />
            <token id="14" string="was" />
            <token id="15" string="right" />
            <token id="16" string="in" />
            <token id="17" string="the" />
            <token id="18" string="groove" />
          </tokens>
        </chunking>
        <chunking id="2" string="was right in the groove" type="VP">
          <tokens>
            <token id="14" string="was" />
            <token id="15" string="right" />
            <token id="16" string="in" />
            <token id="17" string="the" />
            <token id="18" string="groove" />
          </tokens>
        </chunking>
        <chunking id="3" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="4" string="real easy the first 11 miles" type="NP">
          <tokens>
            <token id="4" string="real" />
            <token id="5" string="easy" />
            <token id="6" string="the" />
            <token id="7" string="first" />
            <token id="8" string="11" />
            <token id="9" string="miles" />
          </tokens>
        </chunking>
        <chunking id="5" string="the groove" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="groove" />
          </tokens>
        </chunking>
        <chunking id="6" string="real easy" type="ADJP">
          <tokens>
            <token id="4" string="real" />
            <token id="5" string="easy" />
          </tokens>
        </chunking>
        <chunking id="7" string="the first 11 miles" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="first" />
            <token id="8" string="11" />
            <token id="9" string="miles" />
          </tokens>
        </chunking>
        <chunking id="8" string="felt real easy the first 11 miles" type="VP">
          <tokens>
            <token id="3" string="felt" />
            <token id="4" string="real" />
            <token id="5" string="easy" />
            <token id="6" string="the" />
            <token id="7" string="first" />
            <token id="8" string="11" />
            <token id="9" string="miles" />
          </tokens>
        </chunking>
        <chunking id="9" string="felt I was right in the groove" type="VP">
          <tokens>
            <token id="12" string="felt" />
            <token id="13" string="I" />
            <token id="14" string="was" />
            <token id="15" string="right" />
            <token id="16" string="in" />
            <token id="17" string="the" />
            <token id="18" string="groove" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">felt</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="12">felt</governor>
          <dependent id="3">felt</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">easy</governor>
          <dependent id="4">real</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">miles</governor>
          <dependent id="5">easy</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">miles</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">miles</governor>
          <dependent id="7">first</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="9">miles</governor>
          <dependent id="8">11</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">felt</governor>
          <dependent id="9">miles</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">felt</governor>
          <dependent id="11">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">felt</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">groove</governor>
          <dependent id="13">I</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="18">groove</governor>
          <dependent id="14">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">groove</governor>
          <dependent id="15">right</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">groove</governor>
          <dependent id="16">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">groove</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="12">felt</governor>
          <dependent id="18">groove</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="7" string="first" />
          </tokens>
        </entity>
        <entity id="2" string="right" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="15" string="right" />
          </tokens>
        </entity>
        <entity id="3" string="11" type="NUMBER" score="0.0">
          <tokens>
            <token id="8" string="11" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="60" has_coreference="true">
      <content>I was right where I wanted to be.</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="right" lemma="right" stem="right" pos="RB" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="4" string="where" lemma="where" stem="where" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="wanted" lemma="want" stem="want" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (VP (VBD was) (ADJP (RB right)) (SBAR (WHADVP (WRB where)) (S (NP (PRP I)) (VP (VBD wanted) (S (VP (TO to) (VP (VB be)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="to be" type="VP">
          <tokens>
            <token id="7" string="to" />
            <token id="8" string="be" />
          </tokens>
        </chunking>
        <chunking id="2" string="be" type="VP">
          <tokens>
            <token id="8" string="be" />
          </tokens>
        </chunking>
        <chunking id="3" string="wanted to be" type="VP">
          <tokens>
            <token id="6" string="wanted" />
            <token id="7" string="to" />
            <token id="8" string="be" />
          </tokens>
        </chunking>
        <chunking id="4" string="was right where I wanted to be" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="right" />
            <token id="4" string="where" />
            <token id="5" string="I" />
            <token id="6" string="wanted" />
            <token id="7" string="to" />
            <token id="8" string="be" />
          </tokens>
        </chunking>
        <chunking id="5" string="where I wanted to be" type="SBAR">
          <tokens>
            <token id="4" string="where" />
            <token id="5" string="I" />
            <token id="6" string="wanted" />
            <token id="7" string="to" />
            <token id="8" string="be" />
          </tokens>
        </chunking>
        <chunking id="6" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="7" string="where" type="WHADVP">
          <tokens>
            <token id="4" string="where" />
          </tokens>
        </chunking>
        <chunking id="8" string="right" type="ADJP">
          <tokens>
            <token id="3" string="right" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">right</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="3">right</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">right</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">wanted</governor>
          <dependent id="4">where</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">wanted</governor>
          <dependent id="5">I</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">right</governor>
          <dependent id="6">wanted</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">be</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">wanted</governor>
          <dependent id="8">be</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="right" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="3" string="right" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="61" has_coreference="true">
      <content>&amp;quot;Before I came to Boston, I had a lot of problems with my hip and my back.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Before" lemma="before" stem="befor" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="came" lemma="come" stem="came" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Boston" lemma="Boston" stem="boston" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="lot" lemma="lot" stem="lot" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="problems" lemma="problem" stem="problem" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="my" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="hip" lemma="hip" stem="hip" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="my" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="back" lemma="back" stem="back" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (SBAR (IN Before) (S (NP (PRP I)) (VP (VBD came) (PP (TO to) (NP (NNP Boston)))))) (, ,) (NP (PRP I)) (VP (VBD had) (NP (NP (DT a) (NN lot)) (PP (IN of) (NP (NNS problems)))) (PP (IN with) (NP (NP (PRP$ my) (NN hip)) (CC and) (NP (PRP$ my) (NN back))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="had a lot of problems with my hip and my back" type="VP">
          <tokens>
            <token id="9" string="had" />
            <token id="10" string="a" />
            <token id="11" string="lot" />
            <token id="12" string="of" />
            <token id="13" string="problems" />
            <token id="14" string="with" />
            <token id="15" string="my" />
            <token id="16" string="hip" />
            <token id="17" string="and" />
            <token id="18" string="my" />
            <token id="19" string="back" />
          </tokens>
        </chunking>
        <chunking id="2" string="Before I came to Boston" type="SBAR">
          <tokens>
            <token id="2" string="Before" />
            <token id="3" string="I" />
            <token id="4" string="came" />
            <token id="5" string="to" />
            <token id="6" string="Boston" />
          </tokens>
        </chunking>
        <chunking id="3" string="came to Boston" type="VP">
          <tokens>
            <token id="4" string="came" />
            <token id="5" string="to" />
            <token id="6" string="Boston" />
          </tokens>
        </chunking>
        <chunking id="4" string="a lot of problems" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="lot" />
            <token id="12" string="of" />
            <token id="13" string="problems" />
          </tokens>
        </chunking>
        <chunking id="5" string="my hip and my back" type="NP">
          <tokens>
            <token id="15" string="my" />
            <token id="16" string="hip" />
            <token id="17" string="and" />
            <token id="18" string="my" />
            <token id="19" string="back" />
          </tokens>
        </chunking>
        <chunking id="6" string="my hip" type="NP">
          <tokens>
            <token id="15" string="my" />
            <token id="16" string="hip" />
          </tokens>
        </chunking>
        <chunking id="7" string="a lot" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="lot" />
          </tokens>
        </chunking>
        <chunking id="8" string="I" type="NP">
          <tokens>
            <token id="3" string="I" />
          </tokens>
        </chunking>
        <chunking id="9" string="problems" type="NP">
          <tokens>
            <token id="13" string="problems" />
          </tokens>
        </chunking>
        <chunking id="10" string="my back" type="NP">
          <tokens>
            <token id="18" string="my" />
            <token id="19" string="back" />
          </tokens>
        </chunking>
        <chunking id="11" string="Boston" type="NP">
          <tokens>
            <token id="6" string="Boston" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="4">came</governor>
          <dependent id="2">Before</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">came</governor>
          <dependent id="3">I</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="9">had</governor>
          <dependent id="4">came</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">Boston</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">came</governor>
          <dependent id="6">Boston</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">had</governor>
          <dependent id="8">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">had</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">lot</governor>
          <dependent id="10">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">had</governor>
          <dependent id="11">lot</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">problems</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">lot</governor>
          <dependent id="13">problems</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">hip</governor>
          <dependent id="14">with</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="16">hip</governor>
          <dependent id="15">my</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">had</governor>
          <dependent id="16">hip</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="16">hip</governor>
          <dependent id="17">and</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="19">back</governor>
          <dependent id="18">my</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">hip</governor>
          <dependent id="19">back</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Boston" type="LOCATION" score="0.0">
          <tokens>
            <token id="6" string="Boston" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="62" has_coreference="true">
      <content>At about 11 miles, it went very quickly.</content>
      <tokens>
        <token id="1" string="At" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="11" lemma="11" stem="11" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="4" string="miles" lemma="mile" stem="mile" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="went" lemma="go" stem="went" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="very" lemma="very" stem="veri" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="quickly" lemma="quickly" stem="quickli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN At) (PP (IN about) (NP (CD 11) (NNS miles)))) (, ,) (NP (PRP it)) (VP (VBD went) (ADVP (RB very) (RB quickly))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="11 miles" type="NP">
          <tokens>
            <token id="3" string="11" />
            <token id="4" string="miles" />
          </tokens>
        </chunking>
        <chunking id="2" string="it" type="NP">
          <tokens>
            <token id="6" string="it" />
          </tokens>
        </chunking>
        <chunking id="3" string="went very quickly" type="VP">
          <tokens>
            <token id="7" string="went" />
            <token id="8" string="very" />
            <token id="9" string="quickly" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">miles</governor>
          <dependent id="1">At</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">miles</governor>
          <dependent id="2">about</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="4">miles</governor>
          <dependent id="3">11</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">went</governor>
          <dependent id="4">miles</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">went</governor>
          <dependent id="6">it</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">went</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">quickly</governor>
          <dependent id="8">very</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">went</governor>
          <dependent id="9">quickly</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="11" type="NUMBER" score="0.0">
          <tokens>
            <token id="3" string="11" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="63" has_coreference="true">
      <content>I lost my stride from that point.</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="lost" lemma="lose" stem="lost" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="my" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="4" string="stride" lemma="stride" stem="stride" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="point" lemma="point" stem="point" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (VP (VBD lost) (NP (PRP$ my) (NN stride)) (PP (IN from) (NP (DT that) (NN point)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="my stride" type="NP">
          <tokens>
            <token id="3" string="my" />
            <token id="4" string="stride" />
          </tokens>
        </chunking>
        <chunking id="2" string="that point" type="NP">
          <tokens>
            <token id="6" string="that" />
            <token id="7" string="point" />
          </tokens>
        </chunking>
        <chunking id="3" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="4" string="lost my stride from that point" type="VP">
          <tokens>
            <token id="2" string="lost" />
            <token id="3" string="my" />
            <token id="4" string="stride" />
            <token id="5" string="from" />
            <token id="6" string="that" />
            <token id="7" string="point" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">lost</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">lost</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">stride</governor>
          <dependent id="3">my</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">lost</governor>
          <dependent id="4">stride</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">point</governor>
          <dependent id="5">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">point</governor>
          <dependent id="6">that</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">lost</governor>
          <dependent id="7">point</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="64" has_coreference="true">
      <content>Lisa Weidenbach went flying by me at that point.</content>
      <tokens>
        <token id="1" string="Lisa" lemma="Lisa" stem="lisa" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="Weidenbach" lemma="Weidenbach" stem="weidenbach" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="went" lemma="go" stem="went" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="flying" lemma="fly" stem="fly" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="point" lemma="point" stem="point" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Lisa) (NNP Weidenbach)) (VP (VBD went) (S (VP (VBG flying) (PP (IN by) (NP (PRP me))) (PP (IN at) (NP (DT that) (NN point)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="flying by me at that point" type="VP">
          <tokens>
            <token id="4" string="flying" />
            <token id="5" string="by" />
            <token id="6" string="me" />
            <token id="7" string="at" />
            <token id="8" string="that" />
            <token id="9" string="point" />
          </tokens>
        </chunking>
        <chunking id="2" string="that point" type="NP">
          <tokens>
            <token id="8" string="that" />
            <token id="9" string="point" />
          </tokens>
        </chunking>
        <chunking id="3" string="me" type="NP">
          <tokens>
            <token id="6" string="me" />
          </tokens>
        </chunking>
        <chunking id="4" string="Lisa Weidenbach" type="NP">
          <tokens>
            <token id="1" string="Lisa" />
            <token id="2" string="Weidenbach" />
          </tokens>
        </chunking>
        <chunking id="5" string="went flying by me at that point" type="VP">
          <tokens>
            <token id="3" string="went" />
            <token id="4" string="flying" />
            <token id="5" string="by" />
            <token id="6" string="me" />
            <token id="7" string="at" />
            <token id="8" string="that" />
            <token id="9" string="point" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Weidenbach</governor>
          <dependent id="1">Lisa</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">went</governor>
          <dependent id="2">Weidenbach</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">went</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">went</governor>
          <dependent id="4">flying</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">me</governor>
          <dependent id="5">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">flying</governor>
          <dependent id="6">me</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">point</governor>
          <dependent id="7">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">point</governor>
          <dependent id="8">that</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">flying</governor>
          <dependent id="9">point</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lisa Weidenbach" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Lisa" />
            <token id="2" string="Weidenbach" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="65" has_coreference="true">
      <content>Marguerite (Buist) went shortly thereafter.</content>
      <tokens>
        <token id="1" string="Marguerite" lemma="Marguerite" stem="marguerit" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="2" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Buist" lemma="Buist" stem="buist" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="4" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="went" lemma="go" stem="went" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="shortly" lemma="shortly" stem="shortli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="thereafter" lemma="thereafter" stem="thereaft" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Marguerite)) (PRN (-LRB- -LRB-) (NP (NNP Buist)) (-RRB- -RRB-))) (VP (VBD went) (ADVP (RB shortly)) (ADVP (RB thereafter))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Marguerite" type="NP">
          <tokens>
            <token id="1" string="Marguerite" />
          </tokens>
        </chunking>
        <chunking id="2" string="went shortly thereafter" type="VP">
          <tokens>
            <token id="5" string="went" />
            <token id="6" string="shortly" />
            <token id="7" string="thereafter" />
          </tokens>
        </chunking>
        <chunking id="3" string="Buist" type="NP">
          <tokens>
            <token id="3" string="Buist" />
          </tokens>
        </chunking>
        <chunking id="4" string="Marguerite -LRB- Buist -RRB-" type="NP">
          <tokens>
            <token id="1" string="Marguerite" />
            <token id="2" string="(" />
            <token id="3" string="Buist" />
            <token id="4" string=")" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">went</governor>
          <dependent id="1">Marguerite</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="1">Marguerite</governor>
          <dependent id="3">Buist</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">went</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">went</governor>
          <dependent id="6">shortly</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">went</governor>
          <dependent id="7">thereafter</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Marguerite" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Marguerite" />
          </tokens>
        </entity>
        <entity id="2" string="Buist" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Buist" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="66" has_coreference="true">
      <content>I kept thinking I&amp;apost;d pull it off.</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="kept" lemma="keep" stem="kept" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="thinking" lemma="think" stem="think" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="'d" lemma="would" stem="'d" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="pull" lemma="pull" stem="pull" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="off" lemma="off" stem="off" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (VP (VBD kept) (S (VP (VBG thinking) (SBAR (S (NP (PRP I)) (VP (MD 'd) (VP (VB pull) (NP (PRP it)) (PRT (RP off))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="kept thinking I 'd pull it off" type="VP">
          <tokens>
            <token id="2" string="kept" />
            <token id="3" string="thinking" />
            <token id="4" string="I" />
            <token id="5" string="'d" />
            <token id="6" string="pull" />
            <token id="7" string="it" />
            <token id="8" string="off" />
          </tokens>
        </chunking>
        <chunking id="2" string="'d pull it off" type="VP">
          <tokens>
            <token id="5" string="'d" />
            <token id="6" string="pull" />
            <token id="7" string="it" />
            <token id="8" string="off" />
          </tokens>
        </chunking>
        <chunking id="3" string="thinking I 'd pull it off" type="VP">
          <tokens>
            <token id="3" string="thinking" />
            <token id="4" string="I" />
            <token id="5" string="'d" />
            <token id="6" string="pull" />
            <token id="7" string="it" />
            <token id="8" string="off" />
          </tokens>
        </chunking>
        <chunking id="4" string="pull it off" type="VP">
          <tokens>
            <token id="6" string="pull" />
            <token id="7" string="it" />
            <token id="8" string="off" />
          </tokens>
        </chunking>
        <chunking id="5" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="6" string="it" type="NP">
          <tokens>
            <token id="7" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="I 'd pull it off" type="SBAR">
          <tokens>
            <token id="4" string="I" />
            <token id="5" string="'d" />
            <token id="6" string="pull" />
            <token id="7" string="it" />
            <token id="8" string="off" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">kept</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">kept</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="2">kept</governor>
          <dependent id="3">thinking</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">pull</governor>
          <dependent id="4">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">pull</governor>
          <dependent id="5">'d</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">thinking</governor>
          <dependent id="6">pull</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">pull</governor>
          <dependent id="7">it</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="6">pull</governor>
          <dependent id="8">off</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="67" has_coreference="true">
      <content>I didn&amp;apost;t have the day I really wanted.</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="6" string="day" lemma="day" stem="dai" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="7" string="I" lemma="i" stem="i" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="8" string="really" lemma="really" stem="realli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="wanted" lemma="want" stem="want" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (VP (VBD did) (RB n't) (VP (VB have) (NP (NP (DT the) (NN day)) (SBAR (S (NP (CD I)) (ADVP (RB really)) (VP (VBD wanted))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="I really wanted" type="SBAR">
          <tokens>
            <token id="7" string="I" />
            <token id="8" string="really" />
            <token id="9" string="wanted" />
          </tokens>
        </chunking>
        <chunking id="2" string="the day I really wanted" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="day" />
            <token id="7" string="I" />
            <token id="8" string="really" />
            <token id="9" string="wanted" />
          </tokens>
        </chunking>
        <chunking id="3" string="wanted" type="VP">
          <tokens>
            <token id="9" string="wanted" />
          </tokens>
        </chunking>
        <chunking id="4" string="have the day I really wanted" type="VP">
          <tokens>
            <token id="4" string="have" />
            <token id="5" string="the" />
            <token id="6" string="day" />
            <token id="7" string="I" />
            <token id="8" string="really" />
            <token id="9" string="wanted" />
          </tokens>
        </chunking>
        <chunking id="5" string="the day" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="day" />
          </tokens>
        </chunking>
        <chunking id="6" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="7" string="did n't have the day I really wanted" type="VP">
          <tokens>
            <token id="2" string="did" />
            <token id="3" string="n't" />
            <token id="4" string="have" />
            <token id="5" string="the" />
            <token id="6" string="day" />
            <token id="7" string="I" />
            <token id="8" string="really" />
            <token id="9" string="wanted" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">have</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">have</governor>
          <dependent id="2">did</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="4">have</governor>
          <dependent id="3">n't</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">have</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">day</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">have</governor>
          <dependent id="6">day</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">wanted</governor>
          <dependent id="7">I</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">wanted</governor>
          <dependent id="8">really</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="6">day</governor>
          <dependent id="9">wanted</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="the day" type="DATE" score="0.0">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="day" />
          </tokens>
        </entity>
        <entity id="2" string="I" type="NUMBER" score="0.0">
          <tokens>
            <token id="7" string="I" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="68" has_coreference="false">
      <content>I was duly humbled.&amp;quot;</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="duly" lemma="duly" stem="duli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="humbled" lemma="humble" stem="humbl" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (VP (VBD was) (VP (ADVP (RB duly)) (VBN humbled))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="duly humbled" type="VP">
          <tokens>
            <token id="3" string="duly" />
            <token id="4" string="humbled" />
          </tokens>
        </chunking>
        <chunking id="2" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="3" string="was duly humbled" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="duly" />
            <token id="4" string="humbled" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="4">humbled</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="4">humbled</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">humbled</governor>
          <dependent id="3">duly</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">humbled</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="69" has_coreference="true">
      <content>Samuelson, who had knee surgery in February, continued to fade as her stride faltered and was beaten by three U.S. runners.</content>
      <tokens>
        <token id="1" string="Samuelson" lemma="Samuelson" stem="samuelson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="knee" lemma="knee" stem="knee" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="surgery" lemma="surgery" stem="surgeri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="February" lemma="February" stem="februari" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="true" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="continued" lemma="continue" stem="continu" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="fade" lemma="fade" stem="fade" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="stride" lemma="stride" stem="stride" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="faltered" lemma="falter" stem="falter" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="beaten" lemma="beat" stem="beaten" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="three" lemma="three" stem="three" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="22" string="U.S." lemma="U.S." stem="u.s." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="23" string="runners" lemma="runner" stem="runner" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Samuelson)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBD had) (NP (NP (NN knee) (NN surgery)) (PP (IN in) (NP (NNP February))))))) (, ,)) (VP (VBD continued) (S (VP (TO to) (VP (VB fade) (SBAR (IN as) (S (NP (PRP$ her) (NN stride)) (VP (VP (VBD faltered)) (CC and) (VP (VBD was) (VP (VBN beaten) (PP (IN by) (NP (CD three) (NNP U.S.) (NNS runners)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="had knee surgery in February" type="VP">
          <tokens>
            <token id="4" string="had" />
            <token id="5" string="knee" />
            <token id="6" string="surgery" />
            <token id="7" string="in" />
            <token id="8" string="February" />
          </tokens>
        </chunking>
        <chunking id="2" string="beaten by three U.S. runners" type="VP">
          <tokens>
            <token id="19" string="beaten" />
            <token id="20" string="by" />
            <token id="21" string="three" />
            <token id="22" string="U.S." />
            <token id="23" string="runners" />
          </tokens>
        </chunking>
        <chunking id="3" string="Samuelson" type="NP">
          <tokens>
            <token id="1" string="Samuelson" />
          </tokens>
        </chunking>
        <chunking id="4" string="was beaten by three U.S. runners" type="VP">
          <tokens>
            <token id="18" string="was" />
            <token id="19" string="beaten" />
            <token id="20" string="by" />
            <token id="21" string="three" />
            <token id="22" string="U.S." />
            <token id="23" string="runners" />
          </tokens>
        </chunking>
        <chunking id="5" string="who had knee surgery in February" type="SBAR">
          <tokens>
            <token id="3" string="who" />
            <token id="4" string="had" />
            <token id="5" string="knee" />
            <token id="6" string="surgery" />
            <token id="7" string="in" />
            <token id="8" string="February" />
          </tokens>
        </chunking>
        <chunking id="6" string="Samuelson , who had knee surgery in February ," type="NP">
          <tokens>
            <token id="1" string="Samuelson" />
            <token id="2" string="," />
            <token id="3" string="who" />
            <token id="4" string="had" />
            <token id="5" string="knee" />
            <token id="6" string="surgery" />
            <token id="7" string="in" />
            <token id="8" string="February" />
            <token id="9" string="," />
          </tokens>
        </chunking>
        <chunking id="7" string="knee surgery in February" type="NP">
          <tokens>
            <token id="5" string="knee" />
            <token id="6" string="surgery" />
            <token id="7" string="in" />
            <token id="8" string="February" />
          </tokens>
        </chunking>
        <chunking id="8" string="three U.S. runners" type="NP">
          <tokens>
            <token id="21" string="three" />
            <token id="22" string="U.S." />
            <token id="23" string="runners" />
          </tokens>
        </chunking>
        <chunking id="9" string="as her stride faltered and was beaten by three U.S. runners" type="SBAR">
          <tokens>
            <token id="13" string="as" />
            <token id="14" string="her" />
            <token id="15" string="stride" />
            <token id="16" string="faltered" />
            <token id="17" string="and" />
            <token id="18" string="was" />
            <token id="19" string="beaten" />
            <token id="20" string="by" />
            <token id="21" string="three" />
            <token id="22" string="U.S." />
            <token id="23" string="runners" />
          </tokens>
        </chunking>
        <chunking id="10" string="faltered and was beaten by three U.S. runners" type="VP">
          <tokens>
            <token id="16" string="faltered" />
            <token id="17" string="and" />
            <token id="18" string="was" />
            <token id="19" string="beaten" />
            <token id="20" string="by" />
            <token id="21" string="three" />
            <token id="22" string="U.S." />
            <token id="23" string="runners" />
          </tokens>
        </chunking>
        <chunking id="11" string="knee surgery" type="NP">
          <tokens>
            <token id="5" string="knee" />
            <token id="6" string="surgery" />
          </tokens>
        </chunking>
        <chunking id="12" string="her stride" type="NP">
          <tokens>
            <token id="14" string="her" />
            <token id="15" string="stride" />
          </tokens>
        </chunking>
        <chunking id="13" string="faltered" type="VP">
          <tokens>
            <token id="16" string="faltered" />
          </tokens>
        </chunking>
        <chunking id="14" string="to fade as her stride faltered and was beaten by three U.S. runners" type="VP">
          <tokens>
            <token id="11" string="to" />
            <token id="12" string="fade" />
            <token id="13" string="as" />
            <token id="14" string="her" />
            <token id="15" string="stride" />
            <token id="16" string="faltered" />
            <token id="17" string="and" />
            <token id="18" string="was" />
            <token id="19" string="beaten" />
            <token id="20" string="by" />
            <token id="21" string="three" />
            <token id="22" string="U.S." />
            <token id="23" string="runners" />
          </tokens>
        </chunking>
        <chunking id="15" string="fade as her stride faltered and was beaten by three U.S. runners" type="VP">
          <tokens>
            <token id="12" string="fade" />
            <token id="13" string="as" />
            <token id="14" string="her" />
            <token id="15" string="stride" />
            <token id="16" string="faltered" />
            <token id="17" string="and" />
            <token id="18" string="was" />
            <token id="19" string="beaten" />
            <token id="20" string="by" />
            <token id="21" string="three" />
            <token id="22" string="U.S." />
            <token id="23" string="runners" />
          </tokens>
        </chunking>
        <chunking id="16" string="February" type="NP">
          <tokens>
            <token id="8" string="February" />
          </tokens>
        </chunking>
        <chunking id="17" string="continued to fade as her stride faltered and was beaten by three U.S. runners" type="VP">
          <tokens>
            <token id="10" string="continued" />
            <token id="11" string="to" />
            <token id="12" string="fade" />
            <token id="13" string="as" />
            <token id="14" string="her" />
            <token id="15" string="stride" />
            <token id="16" string="faltered" />
            <token id="17" string="and" />
            <token id="18" string="was" />
            <token id="19" string="beaten" />
            <token id="20" string="by" />
            <token id="21" string="three" />
            <token id="22" string="U.S." />
            <token id="23" string="runners" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="10">continued</governor>
          <dependent id="1">Samuelson</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">had</governor>
          <dependent id="3">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="1">Samuelson</governor>
          <dependent id="4">had</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">surgery</governor>
          <dependent id="5">knee</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">had</governor>
          <dependent id="6">surgery</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">February</governor>
          <dependent id="7">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">surgery</governor>
          <dependent id="8">February</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">continued</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">fade</governor>
          <dependent id="11">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="10">continued</governor>
          <dependent id="12">fade</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">faltered</governor>
          <dependent id="13">as</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="15">stride</governor>
          <dependent id="14">her</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">faltered</governor>
          <dependent id="15">stride</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="12">fade</governor>
          <dependent id="16">faltered</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="16">faltered</governor>
          <dependent id="17">and</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="19">beaten</governor>
          <dependent id="18">was</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">faltered</governor>
          <dependent id="19">beaten</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">runners</governor>
          <dependent id="20">by</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="23">runners</governor>
          <dependent id="21">three</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">runners</governor>
          <dependent id="22">U.S.</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">beaten</governor>
          <dependent id="23">runners</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="U.S." type="LOCATION" score="0.0">
          <tokens>
            <token id="22" string="U.S." />
          </tokens>
        </entity>
        <entity id="2" string="Samuelson" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Samuelson" />
          </tokens>
        </entity>
        <entity id="3" string="February" type="DATE" score="0.0">
          <tokens>
            <token id="8" string="February" />
          </tokens>
        </entity>
        <entity id="4" string="three" type="NUMBER" score="0.0">
          <tokens>
            <token id="21" string="three" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="70" has_coreference="true">
      <content>It had been at least eight years since Samuelson was beaten in the marathon by an American.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="5" string="least" lemma="least" stem="least" pos="JJS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="6" string="eight" lemma="eight" stem="eight" pos="CD" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="7" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="8" string="since" lemma="since" stem="sinc" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="Samuelson" lemma="Samuelson" stem="samuelson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="10" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="beaten" lemma="beat" stem="beaten" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="marathon" lemma="marathon" stem="marathon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="American" lemma="american" stem="american" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP It)) (VP (VBD had) (VP (VBN been) (ADVP (ADVP (IN at) (JJS least)) (SBAR (NP (CD eight) (NNS years)) (IN since) (S (NP (NNP Samuelson)) (VP (VBD was) (VP (VBN beaten) (PP (IN in) (NP (DT the) (NN marathon))) (PP (IN by) (NP (DT an) (JJ American)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="beaten in the marathon by an American" type="VP">
          <tokens>
            <token id="11" string="beaten" />
            <token id="12" string="in" />
            <token id="13" string="the" />
            <token id="14" string="marathon" />
            <token id="15" string="by" />
            <token id="16" string="an" />
            <token id="17" string="American" />
          </tokens>
        </chunking>
        <chunking id="2" string="had been at least eight years since Samuelson was beaten in the marathon by an American" type="VP">
          <tokens>
            <token id="2" string="had" />
            <token id="3" string="been" />
            <token id="4" string="at" />
            <token id="5" string="least" />
            <token id="6" string="eight" />
            <token id="7" string="years" />
            <token id="8" string="since" />
            <token id="9" string="Samuelson" />
            <token id="10" string="was" />
            <token id="11" string="beaten" />
            <token id="12" string="in" />
            <token id="13" string="the" />
            <token id="14" string="marathon" />
            <token id="15" string="by" />
            <token id="16" string="an" />
            <token id="17" string="American" />
          </tokens>
        </chunking>
        <chunking id="3" string="been at least eight years since Samuelson was beaten in the marathon by an American" type="VP">
          <tokens>
            <token id="3" string="been" />
            <token id="4" string="at" />
            <token id="5" string="least" />
            <token id="6" string="eight" />
            <token id="7" string="years" />
            <token id="8" string="since" />
            <token id="9" string="Samuelson" />
            <token id="10" string="was" />
            <token id="11" string="beaten" />
            <token id="12" string="in" />
            <token id="13" string="the" />
            <token id="14" string="marathon" />
            <token id="15" string="by" />
            <token id="16" string="an" />
            <token id="17" string="American" />
          </tokens>
        </chunking>
        <chunking id="4" string="the marathon" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="marathon" />
          </tokens>
        </chunking>
        <chunking id="5" string="Samuelson" type="NP">
          <tokens>
            <token id="9" string="Samuelson" />
          </tokens>
        </chunking>
        <chunking id="6" string="eight years" type="NP">
          <tokens>
            <token id="6" string="eight" />
            <token id="7" string="years" />
          </tokens>
        </chunking>
        <chunking id="7" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="8" string="was beaten in the marathon by an American" type="VP">
          <tokens>
            <token id="10" string="was" />
            <token id="11" string="beaten" />
            <token id="12" string="in" />
            <token id="13" string="the" />
            <token id="14" string="marathon" />
            <token id="15" string="by" />
            <token id="16" string="an" />
            <token id="17" string="American" />
          </tokens>
        </chunking>
        <chunking id="9" string="an American" type="NP">
          <tokens>
            <token id="16" string="an" />
            <token id="17" string="American" />
          </tokens>
        </chunking>
        <chunking id="10" string="eight years since Samuelson was beaten in the marathon by an American" type="SBAR">
          <tokens>
            <token id="6" string="eight" />
            <token id="7" string="years" />
            <token id="8" string="since" />
            <token id="9" string="Samuelson" />
            <token id="10" string="was" />
            <token id="11" string="beaten" />
            <token id="12" string="in" />
            <token id="13" string="the" />
            <token id="14" string="marathon" />
            <token id="15" string="by" />
            <token id="16" string="an" />
            <token id="17" string="American" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">been</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="3">been</governor>
          <dependent id="2">had</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">been</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">been</governor>
          <dependent id="4">at</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="4">at</governor>
          <dependent id="5">least</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="7">years</governor>
          <dependent id="6">eight</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="11">beaten</governor>
          <dependent id="7">years</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">beaten</governor>
          <dependent id="8">since</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="11">beaten</governor>
          <dependent id="9">Samuelson</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="11">beaten</governor>
          <dependent id="10">was</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">at</governor>
          <dependent id="11">beaten</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">marathon</governor>
          <dependent id="12">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">marathon</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">beaten</governor>
          <dependent id="14">marathon</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">American</governor>
          <dependent id="15">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">American</governor>
          <dependent id="16">an</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">beaten</governor>
          <dependent id="17">American</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="at least eight years" type="DURATION" score="0.0">
          <tokens>
            <token id="4" string="at" />
            <token id="5" string="least" />
            <token id="6" string="eight" />
            <token id="7" string="years" />
          </tokens>
        </entity>
        <entity id="2" string="Samuelson" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="Samuelson" />
          </tokens>
        </entity>
        <entity id="3" string="American" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="17" string="American" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="71" has_coreference="true">
      <content>Buist, of New Zealand, was second in 2:29:04.</content>
      <tokens>
        <token id="1" string="Buist" lemma="Buist" stem="buist" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="New" lemma="New" stem="new" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="5" string="Zealand" lemma="Zealand" stem="zealand" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="second" lemma="second" stem="second" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="9" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="10" string="2:29:04" lemma="2:29:04" stem="2:29:04" pos="CD" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Buist)) (, ,) (PP (IN of) (NP (NNP New) (NNP Zealand))) (, ,)) (VP (VBD was) (ADJP (JJ second) (PP (IN in) (NP (CD 2:29:04))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="New Zealand" type="NP">
          <tokens>
            <token id="4" string="New" />
            <token id="5" string="Zealand" />
          </tokens>
        </chunking>
        <chunking id="2" string="2:29:04" type="NP">
          <tokens>
            <token id="10" string="2:29:04" />
          </tokens>
        </chunking>
        <chunking id="3" string="was second in 2:29:04" type="VP">
          <tokens>
            <token id="7" string="was" />
            <token id="8" string="second" />
            <token id="9" string="in" />
            <token id="10" string="2:29:04" />
          </tokens>
        </chunking>
        <chunking id="4" string="Buist , of New Zealand ," type="NP">
          <tokens>
            <token id="1" string="Buist" />
            <token id="2" string="," />
            <token id="3" string="of" />
            <token id="4" string="New" />
            <token id="5" string="Zealand" />
            <token id="6" string="," />
          </tokens>
        </chunking>
        <chunking id="5" string="Buist" type="NP">
          <tokens>
            <token id="1" string="Buist" />
          </tokens>
        </chunking>
        <chunking id="6" string="second in 2:29:04" type="ADJP">
          <tokens>
            <token id="8" string="second" />
            <token id="9" string="in" />
            <token id="10" string="2:29:04" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="8">second</governor>
          <dependent id="1">Buist</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">Zealand</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Zealand</governor>
          <dependent id="4">New</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Buist</governor>
          <dependent id="5">Zealand</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="8">second</governor>
          <dependent id="7">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">second</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">2:29:04</governor>
          <dependent id="9">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">second</governor>
          <dependent id="10">2:29:04</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="New Zealand" type="LOCATION" score="0.0">
          <tokens>
            <token id="4" string="New" />
            <token id="5" string="Zealand" />
          </tokens>
        </entity>
        <entity id="2" string="Buist" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Buist" />
          </tokens>
        </entity>
        <entity id="3" string="second in 2:29:04" type="DATE" score="0.0">
          <tokens>
            <token id="8" string="second" />
            <token id="9" string="in" />
            <token id="10" string="2:29:04" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="72" has_coreference="true">
      <content>Kim Jones of Spokane, Wash., was third in 2:29:34.</content>
      <tokens>
        <token id="1" string="Kim" lemma="Kim" stem="kim" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="2" string="Jones" lemma="Jones" stem="jone" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Spokane" lemma="Spokane" stem="spokan" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Wash." lemma="Wash." stem="wash." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="third" lemma="third" stem="third" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="10" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="2:29:34" lemma="2:29:34" stem="2:29:34" pos="CD" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Kim) (NNP Jones)) (PP (IN of) (NP (NNP Spokane) (, ,) (NNP Wash.) (, ,)))) (VP (VBD was) (ADJP (JJ third) (PP (IN in) (NP (CD 2:29:34))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Kim Jones" type="NP">
          <tokens>
            <token id="1" string="Kim" />
            <token id="2" string="Jones" />
          </tokens>
        </chunking>
        <chunking id="2" string="third in 2:29:34" type="ADJP">
          <tokens>
            <token id="9" string="third" />
            <token id="10" string="in" />
            <token id="11" string="2:29:34" />
          </tokens>
        </chunking>
        <chunking id="3" string="2:29:34" type="NP">
          <tokens>
            <token id="11" string="2:29:34" />
          </tokens>
        </chunking>
        <chunking id="4" string="Spokane , Wash. ," type="NP">
          <tokens>
            <token id="4" string="Spokane" />
            <token id="5" string="," />
            <token id="6" string="Wash." />
            <token id="7" string="," />
          </tokens>
        </chunking>
        <chunking id="5" string="was third in 2:29:34" type="VP">
          <tokens>
            <token id="8" string="was" />
            <token id="9" string="third" />
            <token id="10" string="in" />
            <token id="11" string="2:29:34" />
          </tokens>
        </chunking>
        <chunking id="6" string="Kim Jones of Spokane , Wash. ," type="NP">
          <tokens>
            <token id="1" string="Kim" />
            <token id="2" string="Jones" />
            <token id="3" string="of" />
            <token id="4" string="Spokane" />
            <token id="5" string="," />
            <token id="6" string="Wash." />
            <token id="7" string="," />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Jones</governor>
          <dependent id="1">Kim</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">third</governor>
          <dependent id="2">Jones</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">Wash.</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Wash.</governor>
          <dependent id="4">Spokane</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">Jones</governor>
          <dependent id="6">Wash.</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="9">third</governor>
          <dependent id="8">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">third</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">2:29:34</governor>
          <dependent id="10">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">third</governor>
          <dependent id="11">2:29:34</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Kim Jones" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Kim" />
            <token id="2" string="Jones" />
          </tokens>
        </entity>
        <entity id="2" string="third" type="ORDINAL" score="0.0">
          <tokens>
            <token id="9" string="third" />
          </tokens>
        </entity>
        <entity id="3" string="2:29:34" type="TIME" score="0.0">
          <tokens>
            <token id="11" string="2:29:34" />
          </tokens>
        </entity>
        <entity id="4" string="Wash." type="LOCATION" score="0.0">
          <tokens>
            <token id="6" string="Wash." />
          </tokens>
        </entity>
        <entity id="5" string="Spokane" type="LOCATION" score="0.0">
          <tokens>
            <token id="4" string="Spokane" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="73" has_coreference="true">
      <content>Weidenbach was fifth.</content>
      <tokens>
        <token id="1" string="Weidenbach" lemma="Weidenbach" stem="weidenbach" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="fifth" lemma="fifth" stem="fifth" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="true" is_refers="false" />
        <token id="4" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Weidenbach)) (VP (VBD was) (ADJP (JJ fifth))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Weidenbach" type="NP">
          <tokens>
            <token id="1" string="Weidenbach" />
          </tokens>
        </chunking>
        <chunking id="2" string="was fifth" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="fifth" />
          </tokens>
        </chunking>
        <chunking id="3" string="fifth" type="ADJP">
          <tokens>
            <token id="3" string="fifth" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">fifth</governor>
          <dependent id="1">Weidenbach</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="3">fifth</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">fifth</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Weidenbach" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Weidenbach" />
          </tokens>
        </entity>
        <entity id="2" string="fifth" type="ORDINAL" score="0.0">
          <tokens>
            <token id="3" string="fifth" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="74" has_coreference="true">
      <content>&amp;quot;It&amp;apost;s always difficult to be beaten by Americans when you are the American champion,&amp;quot; Kristiansen said.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="always" lemma="always" stem="alwai" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="difficult" lemma="difficult" stem="difficult" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="beaten" lemma="beat" stem="beaten" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Americans" lemma="Americans" stem="american" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="11" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="American" lemma="american" stem="american" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="true" is_refers="false" />
        <token id="16" string="champion" lemma="champion" stem="champion" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="Kristiansen" lemma="Kristiansen" stem="kristiansen" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="20" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP It)) (VP (VBZ 's) (ADVP (RB always)) (ADJP (JJ difficult) (S (VP (TO to) (VP (VB be) (VP (VBN beaten) (PP (IN by) (NP (NNPS Americans)))))))) (SBAR (WHADVP (WRB when)) (S (NP (PRP you)) (VP (VBP are) (NP (DT the) (JJ American) (NN champion))))))) (, ,) ('' '') (NP (NNP Kristiansen)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="are the American champion" type="VP">
          <tokens>
            <token id="13" string="are" />
            <token id="14" string="the" />
            <token id="15" string="American" />
            <token id="16" string="champion" />
          </tokens>
        </chunking>
        <chunking id="2" string="Americans" type="NP">
          <tokens>
            <token id="10" string="Americans" />
          </tokens>
        </chunking>
        <chunking id="3" string="difficult to be beaten by Americans" type="ADJP">
          <tokens>
            <token id="5" string="difficult" />
            <token id="6" string="to" />
            <token id="7" string="be" />
            <token id="8" string="beaten" />
            <token id="9" string="by" />
            <token id="10" string="Americans" />
          </tokens>
        </chunking>
        <chunking id="4" string="It" type="NP">
          <tokens>
            <token id="2" string="It" />
          </tokens>
        </chunking>
        <chunking id="5" string="to be beaten by Americans" type="VP">
          <tokens>
            <token id="6" string="to" />
            <token id="7" string="be" />
            <token id="8" string="beaten" />
            <token id="9" string="by" />
            <token id="10" string="Americans" />
          </tokens>
        </chunking>
        <chunking id="6" string="when" type="WHADVP">
          <tokens>
            <token id="11" string="when" />
          </tokens>
        </chunking>
        <chunking id="7" string="'s always difficult to be beaten by Americans when you are the American champion" type="VP">
          <tokens>
            <token id="3" string="'s" />
            <token id="4" string="always" />
            <token id="5" string="difficult" />
            <token id="6" string="to" />
            <token id="7" string="be" />
            <token id="8" string="beaten" />
            <token id="9" string="by" />
            <token id="10" string="Americans" />
            <token id="11" string="when" />
            <token id="12" string="you" />
            <token id="13" string="are" />
            <token id="14" string="the" />
            <token id="15" string="American" />
            <token id="16" string="champion" />
          </tokens>
        </chunking>
        <chunking id="8" string="be beaten by Americans" type="VP">
          <tokens>
            <token id="7" string="be" />
            <token id="8" string="beaten" />
            <token id="9" string="by" />
            <token id="10" string="Americans" />
          </tokens>
        </chunking>
        <chunking id="9" string="when you are the American champion" type="SBAR">
          <tokens>
            <token id="11" string="when" />
            <token id="12" string="you" />
            <token id="13" string="are" />
            <token id="14" string="the" />
            <token id="15" string="American" />
            <token id="16" string="champion" />
          </tokens>
        </chunking>
        <chunking id="10" string="the American champion" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="American" />
            <token id="16" string="champion" />
          </tokens>
        </chunking>
        <chunking id="11" string="beaten by Americans" type="VP">
          <tokens>
            <token id="8" string="beaten" />
            <token id="9" string="by" />
            <token id="10" string="Americans" />
          </tokens>
        </chunking>
        <chunking id="12" string="said" type="VP">
          <tokens>
            <token id="20" string="said" />
          </tokens>
        </chunking>
        <chunking id="13" string="you" type="NP">
          <tokens>
            <token id="12" string="you" />
          </tokens>
        </chunking>
        <chunking id="14" string="Kristiansen" type="NP">
          <tokens>
            <token id="19" string="Kristiansen" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">difficult</governor>
          <dependent id="2">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">difficult</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">difficult</governor>
          <dependent id="4">always</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="20">said</governor>
          <dependent id="5">difficult</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">beaten</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="8">beaten</governor>
          <dependent id="7">be</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">difficult</governor>
          <dependent id="8">beaten</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">Americans</governor>
          <dependent id="9">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">beaten</governor>
          <dependent id="10">Americans</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">champion</governor>
          <dependent id="11">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">champion</governor>
          <dependent id="12">you</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="16">champion</governor>
          <dependent id="13">are</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">champion</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">champion</governor>
          <dependent id="15">American</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="5">difficult</governor>
          <dependent id="16">champion</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">said</governor>
          <dependent id="19">Kristiansen</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="20">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Americans" type="MISC" score="0.0">
          <tokens>
            <token id="10" string="Americans" />
          </tokens>
        </entity>
        <entity id="2" string="American" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="15" string="American" />
          </tokens>
        </entity>
        <entity id="3" string="Kristiansen" type="PERSON" score="0.0">
          <tokens>
            <token id="19" string="Kristiansen" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="75" has_coreference="true">
      <content>&amp;quot;The easiest way to be beaten is to drop out of a race.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="easiest" lemma="easiest" stem="easiest" pos="JJS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="way" lemma="way" stem="wai" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="beaten" lemma="beat" stem="beaten" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="drop" lemma="drop" stem="drop" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="out" lemma="out" stem="out" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="race" lemma="race" stem="race" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (`` ``) (DT The) (JJS easiest) (NN way)) (SBAR (S (VP (TO to) (VP (VB be) (VP (VBN beaten))))))) (VP (VBZ is) (S (VP (TO to) (VP (VB drop) (PRT (IN out)) (PP (IN of) (NP (DT a) (NN race))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a race" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="race" />
          </tokens>
        </chunking>
        <chunking id="2" string="to drop out of a race" type="VP">
          <tokens>
            <token id="9" string="to" />
            <token id="10" string="drop" />
            <token id="11" string="out" />
            <token id="12" string="of" />
            <token id="13" string="a" />
            <token id="14" string="race" />
          </tokens>
        </chunking>
        <chunking id="3" string="`` The easiest way" type="NP">
          <tokens>
            <token id="1" string="&quot;" />
            <token id="2" string="The" />
            <token id="3" string="easiest" />
            <token id="4" string="way" />
          </tokens>
        </chunking>
        <chunking id="4" string="be beaten" type="VP">
          <tokens>
            <token id="6" string="be" />
            <token id="7" string="beaten" />
          </tokens>
        </chunking>
        <chunking id="5" string="drop out of a race" type="VP">
          <tokens>
            <token id="10" string="drop" />
            <token id="11" string="out" />
            <token id="12" string="of" />
            <token id="13" string="a" />
            <token id="14" string="race" />
          </tokens>
        </chunking>
        <chunking id="6" string="beaten" type="VP">
          <tokens>
            <token id="7" string="beaten" />
          </tokens>
        </chunking>
        <chunking id="7" string="to be beaten" type="SBAR">
          <tokens>
            <token id="5" string="to" />
            <token id="6" string="be" />
            <token id="7" string="beaten" />
          </tokens>
        </chunking>
        <chunking id="8" string="`` The easiest way to be beaten" type="NP">
          <tokens>
            <token id="1" string="&quot;" />
            <token id="2" string="The" />
            <token id="3" string="easiest" />
            <token id="4" string="way" />
            <token id="5" string="to" />
            <token id="6" string="be" />
            <token id="7" string="beaten" />
          </tokens>
        </chunking>
        <chunking id="9" string="is to drop out of a race" type="VP">
          <tokens>
            <token id="8" string="is" />
            <token id="9" string="to" />
            <token id="10" string="drop" />
            <token id="11" string="out" />
            <token id="12" string="of" />
            <token id="13" string="a" />
            <token id="14" string="race" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="4">way</governor>
          <dependent id="2">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">way</governor>
          <dependent id="3">easiest</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">is</governor>
          <dependent id="4">way</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">beaten</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="7">beaten</governor>
          <dependent id="6">be</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="4">way</governor>
          <dependent id="7">beaten</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">is</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">drop</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="8">is</governor>
          <dependent id="10">drop</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="10">drop</governor>
          <dependent id="11">out</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">race</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">race</governor>
          <dependent id="13">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">drop</governor>
          <dependent id="14">race</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="76" has_coreference="true">
      <content>And she didn&amp;apost;t.</content>
      <tokens>
        <token id="1" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC And) (NP (PRP she)) (VP (VBD did) (RB n't)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="did n't" type="VP">
          <tokens>
            <token id="3" string="did" />
            <token id="4" string="n't" />
          </tokens>
        </chunking>
        <chunking id="2" string="she" type="NP">
          <tokens>
            <token id="2" string="she" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="3">did</governor>
          <dependent id="1">And</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">did</governor>
          <dependent id="2">she</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">did</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="3">did</governor>
          <dependent id="4">n't</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="77" has_coreference="true">
      <content>I think it&amp;apost;s great that she finished.&amp;quot;</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="think" lemma="think" stem="think" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="great" lemma="great" stem="great" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="finished" lemma="finish" stem="finish" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (VP (VBP think) (SBAR (S (NP (PRP it)) (VP (VBZ 's) (ADJP (JJ great)) (SBAR (IN that) (S (NP (PRP she)) (VP (VBD finished)))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="'s great that she finished" type="VP">
          <tokens>
            <token id="4" string="'s" />
            <token id="5" string="great" />
            <token id="6" string="that" />
            <token id="7" string="she" />
            <token id="8" string="finished" />
          </tokens>
        </chunking>
        <chunking id="2" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="3" string="it 's great that she finished" type="SBAR">
          <tokens>
            <token id="3" string="it" />
            <token id="4" string="'s" />
            <token id="5" string="great" />
            <token id="6" string="that" />
            <token id="7" string="she" />
            <token id="8" string="finished" />
          </tokens>
        </chunking>
        <chunking id="4" string="finished" type="VP">
          <tokens>
            <token id="8" string="finished" />
          </tokens>
        </chunking>
        <chunking id="5" string="it" type="NP">
          <tokens>
            <token id="3" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="great" type="ADJP">
          <tokens>
            <token id="5" string="great" />
          </tokens>
        </chunking>
        <chunking id="7" string="think it 's great that she finished" type="VP">
          <tokens>
            <token id="2" string="think" />
            <token id="3" string="it" />
            <token id="4" string="'s" />
            <token id="5" string="great" />
            <token id="6" string="that" />
            <token id="7" string="she" />
            <token id="8" string="finished" />
          </tokens>
        </chunking>
        <chunking id="8" string="that she finished" type="SBAR">
          <tokens>
            <token id="6" string="that" />
            <token id="7" string="she" />
            <token id="8" string="finished" />
          </tokens>
        </chunking>
        <chunking id="9" string="she" type="NP">
          <tokens>
            <token id="7" string="she" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">think</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">think</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">great</governor>
          <dependent id="3">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">great</governor>
          <dependent id="4">'s</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">think</governor>
          <dependent id="5">great</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">finished</governor>
          <dependent id="6">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">finished</governor>
          <dependent id="7">she</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">great</governor>
          <dependent id="8">finished</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="78" has_coreference="true">
      <content>Such compliments did little to placate Samuelson.</content>
      <tokens>
        <token id="1" string="Such" lemma="such" stem="such" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="compliments" lemma="compliment" stem="compliment" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="little" lemma="little" stem="littl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="placate" lemma="placate" stem="placat" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="Samuelson" lemma="Samuelson" stem="samuelson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (JJ Such) (NNS compliments)) (VP (VBD did) (ADJP (JJ little) (S (VP (TO to) (VP (VB placate) (NP (NNP Samuelson))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="little to placate Samuelson" type="ADJP">
          <tokens>
            <token id="4" string="little" />
            <token id="5" string="to" />
            <token id="6" string="placate" />
            <token id="7" string="Samuelson" />
          </tokens>
        </chunking>
        <chunking id="2" string="Samuelson" type="NP">
          <tokens>
            <token id="7" string="Samuelson" />
          </tokens>
        </chunking>
        <chunking id="3" string="to placate Samuelson" type="VP">
          <tokens>
            <token id="5" string="to" />
            <token id="6" string="placate" />
            <token id="7" string="Samuelson" />
          </tokens>
        </chunking>
        <chunking id="4" string="did little to placate Samuelson" type="VP">
          <tokens>
            <token id="3" string="did" />
            <token id="4" string="little" />
            <token id="5" string="to" />
            <token id="6" string="placate" />
            <token id="7" string="Samuelson" />
          </tokens>
        </chunking>
        <chunking id="5" string="placate Samuelson" type="VP">
          <tokens>
            <token id="6" string="placate" />
            <token id="7" string="Samuelson" />
          </tokens>
        </chunking>
        <chunking id="6" string="Such compliments" type="NP">
          <tokens>
            <token id="1" string="Such" />
            <token id="2" string="compliments" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="2">compliments</governor>
          <dependent id="1">Such</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">did</governor>
          <dependent id="2">compliments</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">did</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">did</governor>
          <dependent id="4">little</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">placate</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">little</governor>
          <dependent id="6">placate</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">placate</governor>
          <dependent id="7">Samuelson</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Samuelson" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Samuelson" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="79" has_coreference="true">
      <content>In the postrace news conference, the private Samuelson was as emotional as she has ever been in public.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="postrace" lemma="postrace" stem="postrac" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="news" lemma="news" stem="new" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="conference" lemma="conference" stem="confer" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="private" lemma="private" stem="privat" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="Samuelson" lemma="Samuelson" stem="samuelson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="10" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="emotional" lemma="emotional" stem="emot" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="ever" lemma="ever" stem="ever" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="public" lemma="public" stem="public" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (DT the) (JJ postrace) (NN news) (NN conference))) (, ,) (NP (DT the) (JJ private) (NNP Samuelson)) (VP (VBD was) (ADJP (IN as) (JJ emotional)) (SBAR (IN as) (S (NP (PRP she)) (VP (VBZ has) (ADVP (RB ever)) (VP (VBN been) (PP (IN in) (NP (NN public)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="has ever been in public" type="VP">
          <tokens>
            <token id="15" string="has" />
            <token id="16" string="ever" />
            <token id="17" string="been" />
            <token id="18" string="in" />
            <token id="19" string="public" />
          </tokens>
        </chunking>
        <chunking id="2" string="the postrace news conference" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="postrace" />
            <token id="4" string="news" />
            <token id="5" string="conference" />
          </tokens>
        </chunking>
        <chunking id="3" string="public" type="NP">
          <tokens>
            <token id="19" string="public" />
          </tokens>
        </chunking>
        <chunking id="4" string="been in public" type="VP">
          <tokens>
            <token id="17" string="been" />
            <token id="18" string="in" />
            <token id="19" string="public" />
          </tokens>
        </chunking>
        <chunking id="5" string="was as emotional as she has ever been in public" type="VP">
          <tokens>
            <token id="10" string="was" />
            <token id="11" string="as" />
            <token id="12" string="emotional" />
            <token id="13" string="as" />
            <token id="14" string="she" />
            <token id="15" string="has" />
            <token id="16" string="ever" />
            <token id="17" string="been" />
            <token id="18" string="in" />
            <token id="19" string="public" />
          </tokens>
        </chunking>
        <chunking id="6" string="the private Samuelson" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="private" />
            <token id="9" string="Samuelson" />
          </tokens>
        </chunking>
        <chunking id="7" string="as emotional" type="ADJP">
          <tokens>
            <token id="11" string="as" />
            <token id="12" string="emotional" />
          </tokens>
        </chunking>
        <chunking id="8" string="as she has ever been in public" type="SBAR">
          <tokens>
            <token id="13" string="as" />
            <token id="14" string="she" />
            <token id="15" string="has" />
            <token id="16" string="ever" />
            <token id="17" string="been" />
            <token id="18" string="in" />
            <token id="19" string="public" />
          </tokens>
        </chunking>
        <chunking id="9" string="she" type="NP">
          <tokens>
            <token id="14" string="she" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="5">conference</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">conference</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">conference</governor>
          <dependent id="3">postrace</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">conference</governor>
          <dependent id="4">news</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">emotional</governor>
          <dependent id="5">conference</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">Samuelson</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">Samuelson</governor>
          <dependent id="8">private</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">emotional</governor>
          <dependent id="9">Samuelson</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="12">emotional</governor>
          <dependent id="10">was</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="12">emotional</governor>
          <dependent id="11">as</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">emotional</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">public</governor>
          <dependent id="13">as</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">public</governor>
          <dependent id="14">she</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="19">public</governor>
          <dependent id="15">has</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="19">public</governor>
          <dependent id="16">ever</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="19">public</governor>
          <dependent id="17">been</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">public</governor>
          <dependent id="18">in</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="12">emotional</governor>
          <dependent id="19">public</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Samuelson" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="Samuelson" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="80" has_coreference="true">
      <content>Her voice broke several times.</content>
      <tokens>
        <token id="1" string="Her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="voice" lemma="voice" stem="voic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="broke" lemma="break" stem="broke" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="several" lemma="several" stem="sever" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="times" lemma="time" stem="time" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP$ Her) (NN voice)) (VP (VBD broke) (NP (JJ several) (NNS times))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="broke several times" type="VP">
          <tokens>
            <token id="3" string="broke" />
            <token id="4" string="several" />
            <token id="5" string="times" />
          </tokens>
        </chunking>
        <chunking id="2" string="several times" type="NP">
          <tokens>
            <token id="4" string="several" />
            <token id="5" string="times" />
          </tokens>
        </chunking>
        <chunking id="3" string="Her voice" type="NP">
          <tokens>
            <token id="1" string="Her" />
            <token id="2" string="voice" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="2">voice</governor>
          <dependent id="1">Her</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">broke</governor>
          <dependent id="2">voice</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">broke</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">times</governor>
          <dependent id="4">several</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">broke</governor>
          <dependent id="5">times</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="81" has_coreference="true">
      <content>&amp;quot;I&amp;apost;ve run some very good races and I think I have some very good races left in me,&amp;quot; she said.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="'ve" lemma="have" stem="'ve" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="run" lemma="run" stem="run" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="very" lemma="very" stem="veri" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="good" lemma="good" stem="good" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="races" lemma="race" stem="race" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="think" lemma="think" stem="think" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="very" lemma="very" stem="veri" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="good" lemma="good" stem="good" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="races" lemma="race" stem="race" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="left" lemma="leave" stem="left" pos="VBN" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="19" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (S (NP (PRP I)) (VP (VBP 've) (VP (VBN run) (NP (DT some) (ADJP (RB very) (JJ good)) (NNS races))))) (CC and) (S (NP (PRP I)) (VP (VBP think) (SBAR (S (NP (PRP I)) (VP (VBP have) (NP (NP (DT some) (ADJP (RB very) (JJ good)) (NNS races)) (VP (VBN left) (PP (IN in) (NP (PRP me))))))))))) (, ,) ('' '') (NP (PRP she)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="left in me" type="VP">
          <tokens>
            <token id="18" string="left" />
            <token id="19" string="in" />
            <token id="20" string="me" />
          </tokens>
        </chunking>
        <chunking id="2" string="think I have some very good races left in me" type="VP">
          <tokens>
            <token id="11" string="think" />
            <token id="12" string="I" />
            <token id="13" string="have" />
            <token id="14" string="some" />
            <token id="15" string="very" />
            <token id="16" string="good" />
            <token id="17" string="races" />
            <token id="18" string="left" />
            <token id="19" string="in" />
            <token id="20" string="me" />
          </tokens>
        </chunking>
        <chunking id="3" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="4" string="some very good races" type="NP">
          <tokens>
            <token id="5" string="some" />
            <token id="6" string="very" />
            <token id="7" string="good" />
            <token id="8" string="races" />
          </tokens>
        </chunking>
        <chunking id="5" string="she" type="NP">
          <tokens>
            <token id="23" string="she" />
          </tokens>
        </chunking>
        <chunking id="6" string="very good" type="ADJP">
          <tokens>
            <token id="6" string="very" />
            <token id="7" string="good" />
          </tokens>
        </chunking>
        <chunking id="7" string="run some very good races" type="VP">
          <tokens>
            <token id="4" string="run" />
            <token id="5" string="some" />
            <token id="6" string="very" />
            <token id="7" string="good" />
            <token id="8" string="races" />
          </tokens>
        </chunking>
        <chunking id="8" string="me" type="NP">
          <tokens>
            <token id="20" string="me" />
          </tokens>
        </chunking>
        <chunking id="9" string="'ve run some very good races" type="VP">
          <tokens>
            <token id="3" string="'ve" />
            <token id="4" string="run" />
            <token id="5" string="some" />
            <token id="6" string="very" />
            <token id="7" string="good" />
            <token id="8" string="races" />
          </tokens>
        </chunking>
        <chunking id="10" string="I have some very good races left in me" type="SBAR">
          <tokens>
            <token id="12" string="I" />
            <token id="13" string="have" />
            <token id="14" string="some" />
            <token id="15" string="very" />
            <token id="16" string="good" />
            <token id="17" string="races" />
            <token id="18" string="left" />
            <token id="19" string="in" />
            <token id="20" string="me" />
          </tokens>
        </chunking>
        <chunking id="11" string="some very good races left in me" type="NP">
          <tokens>
            <token id="14" string="some" />
            <token id="15" string="very" />
            <token id="16" string="good" />
            <token id="17" string="races" />
            <token id="18" string="left" />
            <token id="19" string="in" />
            <token id="20" string="me" />
          </tokens>
        </chunking>
        <chunking id="12" string="have some very good races left in me" type="VP">
          <tokens>
            <token id="13" string="have" />
            <token id="14" string="some" />
            <token id="15" string="very" />
            <token id="16" string="good" />
            <token id="17" string="races" />
            <token id="18" string="left" />
            <token id="19" string="in" />
            <token id="20" string="me" />
          </tokens>
        </chunking>
        <chunking id="13" string="said" type="VP">
          <tokens>
            <token id="24" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">run</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">run</governor>
          <dependent id="3">'ve</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="24">said</governor>
          <dependent id="4">run</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">races</governor>
          <dependent id="5">some</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">good</governor>
          <dependent id="6">very</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">races</governor>
          <dependent id="7">good</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">run</governor>
          <dependent id="8">races</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">run</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">think</governor>
          <dependent id="10">I</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">run</governor>
          <dependent id="11">think</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">have</governor>
          <dependent id="12">I</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">think</governor>
          <dependent id="13">have</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">races</governor>
          <dependent id="14">some</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">good</governor>
          <dependent id="15">very</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">races</governor>
          <dependent id="16">good</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">have</governor>
          <dependent id="17">races</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="17">races</governor>
          <dependent id="18">left</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">me</governor>
          <dependent id="19">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">left</governor>
          <dependent id="20">me</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">said</governor>
          <dependent id="23">she</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="24">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="left" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="18" string="left" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="82" has_coreference="true">
      <content>&amp;quot;A lot of people are expecting me to say this is it.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="lot" lemma="lot" stem="lot" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="6" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="expecting" lemma="expect" stem="expect" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="say" lemma="say" stem="sai" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (NP (DT A) (NN lot)) (PP (IN of) (NP (NNS people)))) (VP (VBP are) (VP (VBG expecting) (S (NP (PRP me)) (VP (TO to) (VP (VB say) (SBAR (S (NP (DT this)) (VP (VBZ is) (NP (PRP it)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="A lot of people" type="NP">
          <tokens>
            <token id="2" string="A" />
            <token id="3" string="lot" />
            <token id="4" string="of" />
            <token id="5" string="people" />
          </tokens>
        </chunking>
        <chunking id="2" string="are expecting me to say this is it" type="VP">
          <tokens>
            <token id="6" string="are" />
            <token id="7" string="expecting" />
            <token id="8" string="me" />
            <token id="9" string="to" />
            <token id="10" string="say" />
            <token id="11" string="this" />
            <token id="12" string="is" />
            <token id="13" string="it" />
          </tokens>
        </chunking>
        <chunking id="3" string="A lot" type="NP">
          <tokens>
            <token id="2" string="A" />
            <token id="3" string="lot" />
          </tokens>
        </chunking>
        <chunking id="4" string="to say this is it" type="VP">
          <tokens>
            <token id="9" string="to" />
            <token id="10" string="say" />
            <token id="11" string="this" />
            <token id="12" string="is" />
            <token id="13" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="me" type="NP">
          <tokens>
            <token id="8" string="me" />
          </tokens>
        </chunking>
        <chunking id="6" string="it" type="NP">
          <tokens>
            <token id="13" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="say this is it" type="VP">
          <tokens>
            <token id="10" string="say" />
            <token id="11" string="this" />
            <token id="12" string="is" />
            <token id="13" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="this" type="NP">
          <tokens>
            <token id="11" string="this" />
          </tokens>
        </chunking>
        <chunking id="9" string="people" type="NP">
          <tokens>
            <token id="5" string="people" />
          </tokens>
        </chunking>
        <chunking id="10" string="is it" type="VP">
          <tokens>
            <token id="12" string="is" />
            <token id="13" string="it" />
          </tokens>
        </chunking>
        <chunking id="11" string="expecting me to say this is it" type="VP">
          <tokens>
            <token id="7" string="expecting" />
            <token id="8" string="me" />
            <token id="9" string="to" />
            <token id="10" string="say" />
            <token id="11" string="this" />
            <token id="12" string="is" />
            <token id="13" string="it" />
          </tokens>
        </chunking>
        <chunking id="12" string="this is it" type="SBAR">
          <tokens>
            <token id="11" string="this" />
            <token id="12" string="is" />
            <token id="13" string="it" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">lot</governor>
          <dependent id="2">A</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">expecting</governor>
          <dependent id="3">lot</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">people</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">lot</governor>
          <dependent id="5">people</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">expecting</governor>
          <dependent id="6">are</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">expecting</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">expecting</governor>
          <dependent id="8">me</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">say</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="7">expecting</governor>
          <dependent id="10">say</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">it</governor>
          <dependent id="11">this</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="13">it</governor>
          <dependent id="12">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">say</governor>
          <dependent id="13">it</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="83" has_coreference="true">
      <content>It&amp;apost;s not it.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP It)) (VP (VBZ 's) (RB not) (NP (PRP it))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="2" string="'s not it" type="VP">
          <tokens>
            <token id="2" string="'s" />
            <token id="3" string="not" />
            <token id="4" string="it" />
          </tokens>
        </chunking>
        <chunking id="3" string="it" type="NP">
          <tokens>
            <token id="4" string="it" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">it</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">it</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="4">it</governor>
          <dependent id="3">not</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">it</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="84" has_coreference="true">
      <content>(But) I have been spending as much time in physical therapy as I have in training and I can&amp;apost;t continue that.</content>
      <tokens>
        <token id="1" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="spending" lemma="spend" stem="spend" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="as" lemma="as" stem="a" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="much" lemma="much" stem="much" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="physical" lemma="physical" stem="physic" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="therapy" lemma="therapy" stem="therapi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="training" lemma="training" stem="train" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="ca" lemma="can" stem="ca" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="continue" lemma="continue" stem="continu" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (-LRB- -LRB-) (NP (CC But)) (-RRB- -RRB-) (VP (VP (ADVP (PRP I)) (VBP have) (VP (VBN been) (VP (VBG spending) (PP (ADVP (RB as) (JJ much) (NN time)) (IN in) (NP (JJ physical) (NN therapy)))))) (SBAR (IN as) (S (NP (PRP I)) (VP (VBP have) (VP (PP (IN in) (NP (NN training))))))))) (CC and) (S (NP (PRP I)) (VP (MD ca) (RB n't) (VP (VB continue) (NP (DT that))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="But" type="NP">
          <tokens>
            <token id="2" string="But" />
          </tokens>
        </chunking>
        <chunking id="2" string="ca n't continue that" type="VP">
          <tokens>
            <token id="21" string="ca" />
            <token id="22" string="n't" />
            <token id="23" string="continue" />
            <token id="24" string="that" />
          </tokens>
        </chunking>
        <chunking id="3" string="continue that" type="VP">
          <tokens>
            <token id="23" string="continue" />
            <token id="24" string="that" />
          </tokens>
        </chunking>
        <chunking id="4" string="spending as much time in physical therapy" type="VP">
          <tokens>
            <token id="7" string="spending" />
            <token id="8" string="as" />
            <token id="9" string="much" />
            <token id="10" string="time" />
            <token id="11" string="in" />
            <token id="12" string="physical" />
            <token id="13" string="therapy" />
          </tokens>
        </chunking>
        <chunking id="5" string="physical therapy" type="NP">
          <tokens>
            <token id="12" string="physical" />
            <token id="13" string="therapy" />
          </tokens>
        </chunking>
        <chunking id="6" string="I" type="NP">
          <tokens>
            <token id="15" string="I" />
          </tokens>
        </chunking>
        <chunking id="7" string="training" type="NP">
          <tokens>
            <token id="18" string="training" />
          </tokens>
        </chunking>
        <chunking id="8" string="as I have in training" type="SBAR">
          <tokens>
            <token id="14" string="as" />
            <token id="15" string="I" />
            <token id="16" string="have" />
            <token id="17" string="in" />
            <token id="18" string="training" />
          </tokens>
        </chunking>
        <chunking id="9" string="I have been spending as much time in physical therapy as I have in training" type="VP">
          <tokens>
            <token id="4" string="I" />
            <token id="5" string="have" />
            <token id="6" string="been" />
            <token id="7" string="spending" />
            <token id="8" string="as" />
            <token id="9" string="much" />
            <token id="10" string="time" />
            <token id="11" string="in" />
            <token id="12" string="physical" />
            <token id="13" string="therapy" />
            <token id="14" string="as" />
            <token id="15" string="I" />
            <token id="16" string="have" />
            <token id="17" string="in" />
            <token id="18" string="training" />
          </tokens>
        </chunking>
        <chunking id="10" string="in training" type="VP">
          <tokens>
            <token id="17" string="in" />
            <token id="18" string="training" />
          </tokens>
        </chunking>
        <chunking id="11" string="that" type="NP">
          <tokens>
            <token id="24" string="that" />
          </tokens>
        </chunking>
        <chunking id="12" string="I have been spending as much time in physical therapy" type="VP">
          <tokens>
            <token id="4" string="I" />
            <token id="5" string="have" />
            <token id="6" string="been" />
            <token id="7" string="spending" />
            <token id="8" string="as" />
            <token id="9" string="much" />
            <token id="10" string="time" />
            <token id="11" string="in" />
            <token id="12" string="physical" />
            <token id="13" string="therapy" />
          </tokens>
        </chunking>
        <chunking id="13" string="been spending as much time in physical therapy" type="VP">
          <tokens>
            <token id="6" string="been" />
            <token id="7" string="spending" />
            <token id="8" string="as" />
            <token id="9" string="much" />
            <token id="10" string="time" />
            <token id="11" string="in" />
            <token id="12" string="physical" />
            <token id="13" string="therapy" />
          </tokens>
        </chunking>
        <chunking id="14" string="have in training" type="VP">
          <tokens>
            <token id="16" string="have" />
            <token id="17" string="in" />
            <token id="18" string="training" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="7">spending</governor>
          <dependent id="2">But</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">spending</governor>
          <dependent id="4">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">spending</governor>
          <dependent id="5">have</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">spending</governor>
          <dependent id="6">been</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">spending</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">much</governor>
          <dependent id="8">as</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">therapy</governor>
          <dependent id="9">much</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="9">much</governor>
          <dependent id="10">time</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">therapy</governor>
          <dependent id="11">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">therapy</governor>
          <dependent id="12">physical</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">spending</governor>
          <dependent id="13">therapy</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">training</governor>
          <dependent id="14">as</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">training</governor>
          <dependent id="15">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="18">training</governor>
          <dependent id="16">have</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">training</governor>
          <dependent id="17">in</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="7">spending</governor>
          <dependent id="18">training</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">spending</governor>
          <dependent id="19">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">continue</governor>
          <dependent id="20">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="23">continue</governor>
          <dependent id="21">ca</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="23">continue</governor>
          <dependent id="22">n't</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">spending</governor>
          <dependent id="23">continue</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="23">continue</governor>
          <dependent id="24">that</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="85" has_coreference="true">
      <content>I think I need to take an indefinite rest.</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="think" lemma="think" stem="think" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="need" lemma="need" stem="need" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="take" lemma="take" stem="take" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="indefinite" lemma="indefinite" stem="indefinit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="rest" lemma="rest" stem="rest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (VP (VBP think) (S (NP (PRP I)) (VP (VB need) (S (VP (TO to) (VP (VB take) (NP (DT an) (JJ indefinite) (NN rest)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="to take an indefinite rest" type="VP">
          <tokens>
            <token id="5" string="to" />
            <token id="6" string="take" />
            <token id="7" string="an" />
            <token id="8" string="indefinite" />
            <token id="9" string="rest" />
          </tokens>
        </chunking>
        <chunking id="2" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="3" string="think I need to take an indefinite rest" type="VP">
          <tokens>
            <token id="2" string="think" />
            <token id="3" string="I" />
            <token id="4" string="need" />
            <token id="5" string="to" />
            <token id="6" string="take" />
            <token id="7" string="an" />
            <token id="8" string="indefinite" />
            <token id="9" string="rest" />
          </tokens>
        </chunking>
        <chunking id="4" string="need to take an indefinite rest" type="VP">
          <tokens>
            <token id="4" string="need" />
            <token id="5" string="to" />
            <token id="6" string="take" />
            <token id="7" string="an" />
            <token id="8" string="indefinite" />
            <token id="9" string="rest" />
          </tokens>
        </chunking>
        <chunking id="5" string="take an indefinite rest" type="VP">
          <tokens>
            <token id="6" string="take" />
            <token id="7" string="an" />
            <token id="8" string="indefinite" />
            <token id="9" string="rest" />
          </tokens>
        </chunking>
        <chunking id="6" string="an indefinite rest" type="NP">
          <tokens>
            <token id="7" string="an" />
            <token id="8" string="indefinite" />
            <token id="9" string="rest" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">think</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">think</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">need</governor>
          <dependent id="3">I</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">think</governor>
          <dependent id="4">need</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">take</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">need</governor>
          <dependent id="6">take</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">rest</governor>
          <dependent id="7">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">rest</governor>
          <dependent id="8">indefinite</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">take</governor>
          <dependent id="9">rest</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="86" has_coreference="true">
      <content>It could be a year, it could be five years.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="true" />
        <token id="5" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="true" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="five" lemma="five" stem="five" pos="CD" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="11" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP It)) (VP (MD could) (VP (VB be) (NP (DT a) (NN year))))) (, ,) (NP (PRP it)) (VP (MD could) (VP (VB be) (NP (CD five) (NNS years)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="could be a year" type="VP">
          <tokens>
            <token id="2" string="could" />
            <token id="3" string="be" />
            <token id="4" string="a" />
            <token id="5" string="year" />
          </tokens>
        </chunking>
        <chunking id="2" string="could be five years" type="VP">
          <tokens>
            <token id="8" string="could" />
            <token id="9" string="be" />
            <token id="10" string="five" />
            <token id="11" string="years" />
          </tokens>
        </chunking>
        <chunking id="3" string="be five years" type="VP">
          <tokens>
            <token id="9" string="be" />
            <token id="10" string="five" />
            <token id="11" string="years" />
          </tokens>
        </chunking>
        <chunking id="4" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="5" string="be a year" type="VP">
          <tokens>
            <token id="3" string="be" />
            <token id="4" string="a" />
            <token id="5" string="year" />
          </tokens>
        </chunking>
        <chunking id="6" string="a year" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="year" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="7" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="five years" type="NP">
          <tokens>
            <token id="10" string="five" />
            <token id="11" string="years" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">year</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">year</governor>
          <dependent id="2">could</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">year</governor>
          <dependent id="3">be</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">year</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">years</governor>
          <dependent id="5">year</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">years</governor>
          <dependent id="7">it</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">years</governor>
          <dependent id="8">could</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="11">years</governor>
          <dependent id="9">be</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="11">years</governor>
          <dependent id="10">five</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">years</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="a year" type="DURATION" score="0.0">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="year" />
          </tokens>
        </entity>
        <entity id="2" string="five years" type="DURATION" score="0.0">
          <tokens>
            <token id="10" string="five" />
            <token id="11" string="years" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="87" has_coreference="true">
      <content>I just can&amp;apost;t go on with my responsibilities as a wife and mother and spend this amount of time in physical therapy and training.</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="ca" lemma="can" stem="ca" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="go" lemma="go" stem="go" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="my" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="responsibilities" lemma="responsibility" stem="respons" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="wife" lemma="wife" stem="wife" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="mother" lemma="mother" stem="mother" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="spend" lemma="spend" stem="spend" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="amount" lemma="amount" stem="amount" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="physical" lemma="physical" stem="physic" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="therapy" lemma="therapy" stem="therapi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="training" lemma="training" stem="train" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (ADVP (RB just)) (VP (MD ca) (RB n't) (VP (VP (VB go) (PP (IN on) (IN with) (NP (NP (PRP$ my) (NNS responsibilities)) (PP (IN as) (NP (DT a) (NN wife) (CC and) (NN mother)))))) (CC and) (VP (VB spend) (NP (NP (DT this) (NN amount)) (PP (IN of) (NP (NN time)))) (PP (IN in) (NP (JJ physical) (NN therapy) (CC and) (NN training)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a wife and mother" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="wife" />
            <token id="13" string="and" />
            <token id="14" string="mother" />
          </tokens>
        </chunking>
        <chunking id="2" string="spend this amount of time in physical therapy and training" type="VP">
          <tokens>
            <token id="16" string="spend" />
            <token id="17" string="this" />
            <token id="18" string="amount" />
            <token id="19" string="of" />
            <token id="20" string="time" />
            <token id="21" string="in" />
            <token id="22" string="physical" />
            <token id="23" string="therapy" />
            <token id="24" string="and" />
            <token id="25" string="training" />
          </tokens>
        </chunking>
        <chunking id="3" string="my responsibilities" type="NP">
          <tokens>
            <token id="8" string="my" />
            <token id="9" string="responsibilities" />
          </tokens>
        </chunking>
        <chunking id="4" string="go on with my responsibilities as a wife and mother and spend this amount of time in physical therapy and training" type="VP">
          <tokens>
            <token id="5" string="go" />
            <token id="6" string="on" />
            <token id="7" string="with" />
            <token id="8" string="my" />
            <token id="9" string="responsibilities" />
            <token id="10" string="as" />
            <token id="11" string="a" />
            <token id="12" string="wife" />
            <token id="13" string="and" />
            <token id="14" string="mother" />
            <token id="15" string="and" />
            <token id="16" string="spend" />
            <token id="17" string="this" />
            <token id="18" string="amount" />
            <token id="19" string="of" />
            <token id="20" string="time" />
            <token id="21" string="in" />
            <token id="22" string="physical" />
            <token id="23" string="therapy" />
            <token id="24" string="and" />
            <token id="25" string="training" />
          </tokens>
        </chunking>
        <chunking id="5" string="my responsibilities as a wife and mother" type="NP">
          <tokens>
            <token id="8" string="my" />
            <token id="9" string="responsibilities" />
            <token id="10" string="as" />
            <token id="11" string="a" />
            <token id="12" string="wife" />
            <token id="13" string="and" />
            <token id="14" string="mother" />
          </tokens>
        </chunking>
        <chunking id="6" string="ca n't go on with my responsibilities as a wife and mother and spend this amount of time in physical therapy and training" type="VP">
          <tokens>
            <token id="3" string="ca" />
            <token id="4" string="n't" />
            <token id="5" string="go" />
            <token id="6" string="on" />
            <token id="7" string="with" />
            <token id="8" string="my" />
            <token id="9" string="responsibilities" />
            <token id="10" string="as" />
            <token id="11" string="a" />
            <token id="12" string="wife" />
            <token id="13" string="and" />
            <token id="14" string="mother" />
            <token id="15" string="and" />
            <token id="16" string="spend" />
            <token id="17" string="this" />
            <token id="18" string="amount" />
            <token id="19" string="of" />
            <token id="20" string="time" />
            <token id="21" string="in" />
            <token id="22" string="physical" />
            <token id="23" string="therapy" />
            <token id="24" string="and" />
            <token id="25" string="training" />
          </tokens>
        </chunking>
        <chunking id="7" string="go on with my responsibilities as a wife and mother" type="VP">
          <tokens>
            <token id="5" string="go" />
            <token id="6" string="on" />
            <token id="7" string="with" />
            <token id="8" string="my" />
            <token id="9" string="responsibilities" />
            <token id="10" string="as" />
            <token id="11" string="a" />
            <token id="12" string="wife" />
            <token id="13" string="and" />
            <token id="14" string="mother" />
          </tokens>
        </chunking>
        <chunking id="8" string="this amount of time" type="NP">
          <tokens>
            <token id="17" string="this" />
            <token id="18" string="amount" />
            <token id="19" string="of" />
            <token id="20" string="time" />
          </tokens>
        </chunking>
        <chunking id="9" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="10" string="this amount" type="NP">
          <tokens>
            <token id="17" string="this" />
            <token id="18" string="amount" />
          </tokens>
        </chunking>
        <chunking id="11" string="time" type="NP">
          <tokens>
            <token id="20" string="time" />
          </tokens>
        </chunking>
        <chunking id="12" string="physical therapy and training" type="NP">
          <tokens>
            <token id="22" string="physical" />
            <token id="23" string="therapy" />
            <token id="24" string="and" />
            <token id="25" string="training" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">go</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">go</governor>
          <dependent id="2">just</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">go</governor>
          <dependent id="3">ca</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">go</governor>
          <dependent id="4">n't</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">go</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">responsibilities</governor>
          <dependent id="6">on</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">responsibilities</governor>
          <dependent id="7">with</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="9">responsibilities</governor>
          <dependent id="8">my</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">go</governor>
          <dependent id="9">responsibilities</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">wife</governor>
          <dependent id="10">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">wife</governor>
          <dependent id="11">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">responsibilities</governor>
          <dependent id="12">wife</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="12">wife</governor>
          <dependent id="13">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">wife</governor>
          <dependent id="14">mother</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">go</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">go</governor>
          <dependent id="16">spend</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">amount</governor>
          <dependent id="17">this</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">spend</governor>
          <dependent id="18">amount</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">time</governor>
          <dependent id="19">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">amount</governor>
          <dependent id="20">time</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">therapy</governor>
          <dependent id="21">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">therapy</governor>
          <dependent id="22">physical</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">spend</governor>
          <dependent id="23">therapy</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="23">therapy</governor>
          <dependent id="24">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="23">therapy</governor>
          <dependent id="25">training</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="88" has_coreference="true">
      <content>I&amp;apost;ll just take a break.&amp;quot;</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="'ll" lemma="will" stem="'ll" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="take" lemma="take" stem="take" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="break" lemma="break" stem="break" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (VP (MD 'll) (ADVP (RB just)) (VP (VB take) (NP (DT a) (NN break)))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="'ll just take a break" type="VP">
          <tokens>
            <token id="2" string="'ll" />
            <token id="3" string="just" />
            <token id="4" string="take" />
            <token id="5" string="a" />
            <token id="6" string="break" />
          </tokens>
        </chunking>
        <chunking id="2" string="take a break" type="VP">
          <tokens>
            <token id="4" string="take" />
            <token id="5" string="a" />
            <token id="6" string="break" />
          </tokens>
        </chunking>
        <chunking id="3" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="4" string="a break" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="break" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">take</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">take</governor>
          <dependent id="2">'ll</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">take</governor>
          <dependent id="3">just</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">take</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">break</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">take</governor>
          <dependent id="6">break</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="89" has_coreference="true">
      <content>Samuelson, who holds the U.S. marathon record, said she will significantly decrease her training mileage and probably run shorter races.</content>
      <tokens>
        <token id="1" string="Samuelson" lemma="Samuelson" stem="samuelson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="holds" lemma="hold" stem="hold" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="U.S." lemma="U.S." stem="u.s." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="7" string="marathon" lemma="marathon" stem="marathon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="record" lemma="record" stem="record" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="significantly" lemma="significantly" stem="significantli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="decrease" lemma="decrease" stem="decreas" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="training" lemma="training" stem="train" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="mileage" lemma="mileage" stem="mileag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="probably" lemma="probably" stem="probabl" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="run" lemma="run" stem="run" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="shorter" lemma="shorter" stem="shorter" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="races" lemma="race" stem="race" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Samuelson)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBZ holds) (NP (DT the) (NNP U.S.) (NN marathon) (NN record))))) (, ,)) (VP (VBD said) (SBAR (S (NP (PRP she)) (VP (MD will) (ADVP (RB significantly)) (VP (VP (VB decrease) (NP (PRP$ her) (NN training) (NN mileage))) (CC and) (VP (ADVP (RB probably)) (VB run) (NP (JJR shorter) (NNS races)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="she will significantly decrease her training mileage and probably run shorter races" type="SBAR">
          <tokens>
            <token id="11" string="she" />
            <token id="12" string="will" />
            <token id="13" string="significantly" />
            <token id="14" string="decrease" />
            <token id="15" string="her" />
            <token id="16" string="training" />
            <token id="17" string="mileage" />
            <token id="18" string="and" />
            <token id="19" string="probably" />
            <token id="20" string="run" />
            <token id="21" string="shorter" />
            <token id="22" string="races" />
          </tokens>
        </chunking>
        <chunking id="2" string="who holds the U.S. marathon record" type="SBAR">
          <tokens>
            <token id="3" string="who" />
            <token id="4" string="holds" />
            <token id="5" string="the" />
            <token id="6" string="U.S." />
            <token id="7" string="marathon" />
            <token id="8" string="record" />
          </tokens>
        </chunking>
        <chunking id="3" string="Samuelson" type="NP">
          <tokens>
            <token id="1" string="Samuelson" />
          </tokens>
        </chunking>
        <chunking id="4" string="said she will significantly decrease her training mileage and probably run shorter races" type="VP">
          <tokens>
            <token id="10" string="said" />
            <token id="11" string="she" />
            <token id="12" string="will" />
            <token id="13" string="significantly" />
            <token id="14" string="decrease" />
            <token id="15" string="her" />
            <token id="16" string="training" />
            <token id="17" string="mileage" />
            <token id="18" string="and" />
            <token id="19" string="probably" />
            <token id="20" string="run" />
            <token id="21" string="shorter" />
            <token id="22" string="races" />
          </tokens>
        </chunking>
        <chunking id="5" string="holds the U.S. marathon record" type="VP">
          <tokens>
            <token id="4" string="holds" />
            <token id="5" string="the" />
            <token id="6" string="U.S." />
            <token id="7" string="marathon" />
            <token id="8" string="record" />
          </tokens>
        </chunking>
        <chunking id="6" string="Samuelson , who holds the U.S. marathon record ," type="NP">
          <tokens>
            <token id="1" string="Samuelson" />
            <token id="2" string="," />
            <token id="3" string="who" />
            <token id="4" string="holds" />
            <token id="5" string="the" />
            <token id="6" string="U.S." />
            <token id="7" string="marathon" />
            <token id="8" string="record" />
            <token id="9" string="," />
          </tokens>
        </chunking>
        <chunking id="7" string="the U.S. marathon record" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="U.S." />
            <token id="7" string="marathon" />
            <token id="8" string="record" />
          </tokens>
        </chunking>
        <chunking id="8" string="she" type="NP">
          <tokens>
            <token id="11" string="she" />
          </tokens>
        </chunking>
        <chunking id="9" string="probably run shorter races" type="VP">
          <tokens>
            <token id="19" string="probably" />
            <token id="20" string="run" />
            <token id="21" string="shorter" />
            <token id="22" string="races" />
          </tokens>
        </chunking>
        <chunking id="10" string="will significantly decrease her training mileage and probably run shorter races" type="VP">
          <tokens>
            <token id="12" string="will" />
            <token id="13" string="significantly" />
            <token id="14" string="decrease" />
            <token id="15" string="her" />
            <token id="16" string="training" />
            <token id="17" string="mileage" />
            <token id="18" string="and" />
            <token id="19" string="probably" />
            <token id="20" string="run" />
            <token id="21" string="shorter" />
            <token id="22" string="races" />
          </tokens>
        </chunking>
        <chunking id="11" string="decrease her training mileage and probably run shorter races" type="VP">
          <tokens>
            <token id="14" string="decrease" />
            <token id="15" string="her" />
            <token id="16" string="training" />
            <token id="17" string="mileage" />
            <token id="18" string="and" />
            <token id="19" string="probably" />
            <token id="20" string="run" />
            <token id="21" string="shorter" />
            <token id="22" string="races" />
          </tokens>
        </chunking>
        <chunking id="12" string="shorter races" type="NP">
          <tokens>
            <token id="21" string="shorter" />
            <token id="22" string="races" />
          </tokens>
        </chunking>
        <chunking id="13" string="her training mileage" type="NP">
          <tokens>
            <token id="15" string="her" />
            <token id="16" string="training" />
            <token id="17" string="mileage" />
          </tokens>
        </chunking>
        <chunking id="14" string="decrease her training mileage" type="VP">
          <tokens>
            <token id="14" string="decrease" />
            <token id="15" string="her" />
            <token id="16" string="training" />
            <token id="17" string="mileage" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="10">said</governor>
          <dependent id="1">Samuelson</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">holds</governor>
          <dependent id="3">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="1">Samuelson</governor>
          <dependent id="4">holds</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">record</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">record</governor>
          <dependent id="6">U.S.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">record</governor>
          <dependent id="7">marathon</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">holds</governor>
          <dependent id="8">record</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">decrease</governor>
          <dependent id="11">she</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="14">decrease</governor>
          <dependent id="12">will</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">decrease</governor>
          <dependent id="13">significantly</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">said</governor>
          <dependent id="14">decrease</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="17">mileage</governor>
          <dependent id="15">her</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">mileage</governor>
          <dependent id="16">training</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">decrease</governor>
          <dependent id="17">mileage</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="14">decrease</governor>
          <dependent id="18">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="20">run</governor>
          <dependent id="19">probably</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">decrease</governor>
          <dependent id="20">run</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">races</governor>
          <dependent id="21">shorter</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">run</governor>
          <dependent id="22">races</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="U.S." type="LOCATION" score="0.0">
          <tokens>
            <token id="6" string="U.S." />
          </tokens>
        </entity>
        <entity id="2" string="Samuelson" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Samuelson" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="90" has_coreference="true">
      <content>She said she will run an eight-kilometer event next month in Washington, D.C. &amp;quot;I want everyone to know that it&amp;apost;s still there,&amp;quot; Samuelson said, tears welling in her eyes.</content>
      <tokens>
        <token id="1" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="run" lemma="run" stem="run" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="eight-kilometer" lemma="eight-kilometer" stem="eight-kilomet" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="event" lemma="event" stem="event" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="next" lemma="next" stem="next" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="10" string="month" lemma="month" stem="month" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="11" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Washington" lemma="Washington" stem="washington" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="D.C." lemma="D.C." stem="d.c." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="15" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="want" lemma="want" stem="want" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="everyone" lemma="everyone" stem="everyon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="know" lemma="know" stem="know" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="still" lemma="still" stem="still" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="there" lemma="there" stem="there" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="Samuelson" lemma="Samuelson" stem="samuelson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="29" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="tears" lemma="tear" stem="tear" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="welling" lemma="well" stem="well" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="35" string="eyes" lemma="eye" stem="ey" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP She)) (VP (VBD said) (SBAR (S (NP (PRP she)) (VP (MD will) (VP (VB run) (NP (DT an) (JJ eight-kilometer) (NN event)) (NP-TMP (JJ next) (NN month)) (PP (IN in) (NP (NNP Washington))))))))) (, ,) (NP (NNP D.C.)) (`` ``) (S (NP (PRP I)) (VP (VBP want) (NP (NN everyone)) (S (VP (TO to) (VP (VB know) (SBAR (IN that) (S (NP (PRP it)) (VP (VBZ 's) (ADVP (RB still)) (ADVP (RB there)))))))))) (, ,) ('' '') (NP (NNP Samuelson)) (VP (VBD said) (, ,) (S (NP (NNS tears)) (VP (VBG welling) (PP (IN in) (NP (PRP$ her) (NNS eyes)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="run an eight-kilometer event next month in Washington" type="VP">
          <tokens>
            <token id="5" string="run" />
            <token id="6" string="an" />
            <token id="7" string="eight-kilometer" />
            <token id="8" string="event" />
            <token id="9" string="next" />
            <token id="10" string="month" />
            <token id="11" string="in" />
            <token id="12" string="Washington" />
          </tokens>
        </chunking>
        <chunking id="2" string="tears" type="NP">
          <tokens>
            <token id="31" string="tears" />
          </tokens>
        </chunking>
        <chunking id="3" string="everyone" type="NP">
          <tokens>
            <token id="18" string="everyone" />
          </tokens>
        </chunking>
        <chunking id="4" string="Samuelson" type="NP">
          <tokens>
            <token id="28" string="Samuelson" />
          </tokens>
        </chunking>
        <chunking id="5" string="her eyes" type="NP">
          <tokens>
            <token id="34" string="her" />
            <token id="35" string="eyes" />
          </tokens>
        </chunking>
        <chunking id="6" string="I" type="NP">
          <tokens>
            <token id="16" string="I" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="22" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="'s still there" type="VP">
          <tokens>
            <token id="23" string="'s" />
            <token id="24" string="still" />
            <token id="25" string="there" />
          </tokens>
        </chunking>
        <chunking id="9" string="an eight-kilometer event" type="NP">
          <tokens>
            <token id="6" string="an" />
            <token id="7" string="eight-kilometer" />
            <token id="8" string="event" />
          </tokens>
        </chunking>
        <chunking id="10" string="D.C." type="NP">
          <tokens>
            <token id="14" string="D.C." />
          </tokens>
        </chunking>
        <chunking id="11" string="said , tears welling in her eyes" type="VP">
          <tokens>
            <token id="29" string="said" />
            <token id="30" string="," />
            <token id="31" string="tears" />
            <token id="32" string="welling" />
            <token id="33" string="in" />
            <token id="34" string="her" />
            <token id="35" string="eyes" />
          </tokens>
        </chunking>
        <chunking id="12" string="She" type="NP">
          <tokens>
            <token id="1" string="She" />
          </tokens>
        </chunking>
        <chunking id="13" string="she" type="NP">
          <tokens>
            <token id="3" string="she" />
          </tokens>
        </chunking>
        <chunking id="14" string="to know that it 's still there" type="VP">
          <tokens>
            <token id="19" string="to" />
            <token id="20" string="know" />
            <token id="21" string="that" />
            <token id="22" string="it" />
            <token id="23" string="'s" />
            <token id="24" string="still" />
            <token id="25" string="there" />
          </tokens>
        </chunking>
        <chunking id="15" string="Washington" type="NP">
          <tokens>
            <token id="12" string="Washington" />
          </tokens>
        </chunking>
        <chunking id="16" string="she will run an eight-kilometer event next month in Washington" type="SBAR">
          <tokens>
            <token id="3" string="she" />
            <token id="4" string="will" />
            <token id="5" string="run" />
            <token id="6" string="an" />
            <token id="7" string="eight-kilometer" />
            <token id="8" string="event" />
            <token id="9" string="next" />
            <token id="10" string="month" />
            <token id="11" string="in" />
            <token id="12" string="Washington" />
          </tokens>
        </chunking>
        <chunking id="17" string="know that it 's still there" type="VP">
          <tokens>
            <token id="20" string="know" />
            <token id="21" string="that" />
            <token id="22" string="it" />
            <token id="23" string="'s" />
            <token id="24" string="still" />
            <token id="25" string="there" />
          </tokens>
        </chunking>
        <chunking id="18" string="want everyone to know that it 's still there" type="VP">
          <tokens>
            <token id="17" string="want" />
            <token id="18" string="everyone" />
            <token id="19" string="to" />
            <token id="20" string="know" />
            <token id="21" string="that" />
            <token id="22" string="it" />
            <token id="23" string="'s" />
            <token id="24" string="still" />
            <token id="25" string="there" />
          </tokens>
        </chunking>
        <chunking id="19" string="will run an eight-kilometer event next month in Washington" type="VP">
          <tokens>
            <token id="4" string="will" />
            <token id="5" string="run" />
            <token id="6" string="an" />
            <token id="7" string="eight-kilometer" />
            <token id="8" string="event" />
            <token id="9" string="next" />
            <token id="10" string="month" />
            <token id="11" string="in" />
            <token id="12" string="Washington" />
          </tokens>
        </chunking>
        <chunking id="20" string="welling in her eyes" type="VP">
          <tokens>
            <token id="32" string="welling" />
            <token id="33" string="in" />
            <token id="34" string="her" />
            <token id="35" string="eyes" />
          </tokens>
        </chunking>
        <chunking id="21" string="said she will run an eight-kilometer event next month in Washington" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="she" />
            <token id="4" string="will" />
            <token id="5" string="run" />
            <token id="6" string="an" />
            <token id="7" string="eight-kilometer" />
            <token id="8" string="event" />
            <token id="9" string="next" />
            <token id="10" string="month" />
            <token id="11" string="in" />
            <token id="12" string="Washington" />
          </tokens>
        </chunking>
        <chunking id="22" string="that it 's still there" type="SBAR">
          <tokens>
            <token id="21" string="that" />
            <token id="22" string="it" />
            <token id="23" string="'s" />
            <token id="24" string="still" />
            <token id="25" string="there" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">She</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="29">said</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">run</governor>
          <dependent id="3">she</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">run</governor>
          <dependent id="4">will</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="5">run</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">event</governor>
          <dependent id="6">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">event</governor>
          <dependent id="7">eight-kilometer</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">run</governor>
          <dependent id="8">event</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">month</governor>
          <dependent id="9">next</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="5">run</governor>
          <dependent id="10">month</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">Washington</governor>
          <dependent id="11">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">run</governor>
          <dependent id="12">Washington</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">said</governor>
          <dependent id="14">D.C.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">want</governor>
          <dependent id="16">I</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="29">said</governor>
          <dependent id="17">want</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">want</governor>
          <dependent id="18">everyone</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="20">know</governor>
          <dependent id="19">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="17">want</governor>
          <dependent id="20">know</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="23">'s</governor>
          <dependent id="21">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">'s</governor>
          <dependent id="22">it</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="20">know</governor>
          <dependent id="23">'s</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="23">'s</governor>
          <dependent id="24">still</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="23">'s</governor>
          <dependent id="25">there</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">said</governor>
          <dependent id="28">Samuelson</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="29">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="32">welling</governor>
          <dependent id="31">tears</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="29">said</governor>
          <dependent id="32">welling</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">eyes</governor>
          <dependent id="33">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="35">eyes</governor>
          <dependent id="34">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="32">welling</governor>
          <dependent id="35">eyes</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Washington" type="LOCATION" score="0.0">
          <tokens>
            <token id="12" string="Washington" />
          </tokens>
        </entity>
        <entity id="2" string="Samuelson" type="PERSON" score="0.0">
          <tokens>
            <token id="28" string="Samuelson" />
          </tokens>
        </entity>
        <entity id="3" string="D.C." type="LOCATION" score="0.0">
          <tokens>
            <token id="14" string="D.C." />
          </tokens>
        </entity>
        <entity id="4" string="next month" type="DATE" score="0.0">
          <tokens>
            <token id="9" string="next" />
            <token id="10" string="month" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="91" has_coreference="true">
      <content>&amp;quot;I will run again.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="run" lemma="run" stem="run" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="again" lemma="again" stem="again" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP I)) (VP (MD will) (VP (VB run) (ADVP (RB again)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="2" string="will run again" type="VP">
          <tokens>
            <token id="3" string="will" />
            <token id="4" string="run" />
            <token id="5" string="again" />
          </tokens>
        </chunking>
        <chunking id="3" string="run again" type="VP">
          <tokens>
            <token id="4" string="run" />
            <token id="5" string="again" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">run</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">run</governor>
          <dependent id="3">will</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">run</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">run</governor>
          <dependent id="5">again</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="92" has_coreference="true">
      <content>I need to get beyond this problem.&amp;quot;</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="need" lemma="need" stem="need" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="get" lemma="get" stem="get" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="beyond" lemma="beyond" stem="beyond" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="problem" lemma="problem" stem="problem" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (VP (VBP need) (S (VP (TO to) (VP (VB get) (PP (IN beyond) (NP (DT this) (NN problem))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="get beyond this problem" type="VP">
          <tokens>
            <token id="4" string="get" />
            <token id="5" string="beyond" />
            <token id="6" string="this" />
            <token id="7" string="problem" />
          </tokens>
        </chunking>
        <chunking id="2" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="3" string="this problem" type="NP">
          <tokens>
            <token id="6" string="this" />
            <token id="7" string="problem" />
          </tokens>
        </chunking>
        <chunking id="4" string="need to get beyond this problem" type="VP">
          <tokens>
            <token id="2" string="need" />
            <token id="3" string="to" />
            <token id="4" string="get" />
            <token id="5" string="beyond" />
            <token id="6" string="this" />
            <token id="7" string="problem" />
          </tokens>
        </chunking>
        <chunking id="5" string="to get beyond this problem" type="VP">
          <tokens>
            <token id="3" string="to" />
            <token id="4" string="get" />
            <token id="5" string="beyond" />
            <token id="6" string="this" />
            <token id="7" string="problem" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">need</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">need</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="4">get</governor>
          <dependent id="3">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="2">need</governor>
          <dependent id="4">get</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">problem</governor>
          <dependent id="5">beyond</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">problem</governor>
          <dependent id="6">this</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">get</governor>
          <dependent id="7">problem</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="93" has_coreference="true">
      <content>THEY&amp;apost;VE GOT A LOCK ON THE MARATHON How Ethiopia&amp;apost;s marathoners have fared the last two days: Date Race Result Sunday Rotterdam Marathon Belayneh Dinsamo, 2:08:39, first place Sunday Milan, Italy Keleke Metaferia, 2:10:28, first place, Dereje Nedi, World Cup Marathon 2:10:36, second place.</content>
      <tokens>
        <token id="1" string="THEY" lemma="THEY" stem="they" pos="NNP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="'VE" lemma="'VE" stem="'ve" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="GOT" lemma="get" stem="got" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="LOCK" lemma="lock" stem="lock" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="ON" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="THE" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="MARATHON" lemma="MARATHON" stem="marathon" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="How" lemma="how" stem="how" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Ethiopia" lemma="Ethiopia" stem="ethiopia" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="11" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="marathoners" lemma="marathoner" stem="marathon" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="fared" lemma="fare" stem="fare" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="16" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="17" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="18" string="days" lemma="day" stem="dai" pos="NNS" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="19" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="Date" lemma="Date" stem="date" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="Race" lemma="Race" stem="race" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="Result" lemma="result" stem="result" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="Sunday" lemma="Sunday" stem="sundai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="24" string="Rotterdam" lemma="Rotterdam" stem="rotterdam" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="25" string="Marathon" lemma="Marathon" stem="marathon" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="26" string="Belayneh" lemma="Belayneh" stem="belayneh" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="27" string="Dinsamo" lemma="Dinsamo" stem="dinsamo" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="28" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="2:08:39" lemma="2:08:39" stem="2:08:39" pos="CD" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="30" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="first" lemma="first" stem="first" pos="RB" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="true" />
        <token id="32" string="place" lemma="place" stem="place" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="33" string="Sunday" lemma="Sunday" stem="sundai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="34" string="Milan" lemma="Milan" stem="milan" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="35" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="Italy" lemma="Italy" stem="itali" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="37" string="Keleke" lemma="Keleke" stem="kelek" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="38" string="Metaferia" lemma="Metaferia" stem="metaferia" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="39" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="2:10:28" lemma="2:10:28" stem="2:10:28" pos="CD" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="41" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="first" lemma="first" stem="first" pos="RB" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="true" is_refers="true" />
        <token id="43" string="place" lemma="place" stem="place" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="44" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="Dereje" lemma="Dereje" stem="derej" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="46" string="Nedi" lemma="Nedi" stem="nedi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="47" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="48" string="World" lemma="World" stem="world" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="49" string="Cup" lemma="Cup" stem="cup" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="50" string="Marathon" lemma="Marathon" stem="marathon" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="51" string="2:10:36" lemma="2:10:36" stem="2:10:36" pos="CD" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="52" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="53" string="second" lemma="second" stem="second" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="54" string="place" lemma="place" stem="place" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="55" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP THEY) (NNP 'VE)) (VP (VBD GOT) (NP (NP (DT A) (NN LOCK)) (PP (IN ON) (NP (DT THE) (NNP MARATHON)))) (SBAR (WHADVP (WRB How)) (S (NP (NP (NNP Ethiopia) (POS 's)) (NNS marathoners)) (VP (VBP have) (VP (VBN fared) (NP (NP (DT the) (JJ last) (CD two) (NNS days)) (: :) (NP (NP (NP (NNP Date) (NNP Race) (NN Result) (NNP Sunday) (NNP Rotterdam) (NNP Marathon) (NNP Belayneh) (NNP Dinsamo)) (, ,) (NP (CD 2:08:39))) (, ,) (RRC (ADVP (RB first)) (NP (NP (NN place) (NNP Sunday) (NNP Milan)) (, ,) (NP (NNP Italy) (NNP Keleke) (NNP Metaferia)) (, ,) (NP (CD 2:10:28)) (, ,) (NP (RB first) (NN place)) (, ,) (NP (NNP Dereje) (NNP Nedi)) (, ,) (NP (NP (NNP World) (NNP Cup) (NNP Marathon)) (NP (CD 2:10:36))) (, ,) (NP (JJ second) (NN place))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="2:08:39" type="NP">
          <tokens>
            <token id="29" string="2:08:39" />
          </tokens>
        </chunking>
        <chunking id="2" string="World Cup Marathon" type="NP">
          <tokens>
            <token id="48" string="World" />
            <token id="49" string="Cup" />
            <token id="50" string="Marathon" />
          </tokens>
        </chunking>
        <chunking id="3" string="GOT A LOCK ON THE MARATHON How Ethiopia 's marathoners have fared the last two days : Date Race Result Sunday Rotterdam Marathon Belayneh Dinsamo , 2:08:39 , first place Sunday Milan , Italy Keleke Metaferia , 2:10:28 , first place , Dereje Nedi , World Cup Marathon 2:10:36 , second place" type="VP">
          <tokens>
            <token id="3" string="GOT" />
            <token id="4" string="A" />
            <token id="5" string="LOCK" />
            <token id="6" string="ON" />
            <token id="7" string="THE" />
            <token id="8" string="MARATHON" />
            <token id="9" string="How" />
            <token id="10" string="Ethiopia" />
            <token id="11" string="'s" />
            <token id="12" string="marathoners" />
            <token id="13" string="have" />
            <token id="14" string="fared" />
            <token id="15" string="the" />
            <token id="16" string="last" />
            <token id="17" string="two" />
            <token id="18" string="days" />
            <token id="19" string=":" />
            <token id="20" string="Date" />
            <token id="21" string="Race" />
            <token id="22" string="Result" />
            <token id="23" string="Sunday" />
            <token id="24" string="Rotterdam" />
            <token id="25" string="Marathon" />
            <token id="26" string="Belayneh" />
            <token id="27" string="Dinsamo" />
            <token id="28" string="," />
            <token id="29" string="2:08:39" />
            <token id="30" string="," />
            <token id="31" string="first" />
            <token id="32" string="place" />
            <token id="33" string="Sunday" />
            <token id="34" string="Milan" />
            <token id="35" string="," />
            <token id="36" string="Italy" />
            <token id="37" string="Keleke" />
            <token id="38" string="Metaferia" />
            <token id="39" string="," />
            <token id="40" string="2:10:28" />
            <token id="41" string="," />
            <token id="42" string="first" />
            <token id="43" string="place" />
            <token id="44" string="," />
            <token id="45" string="Dereje" />
            <token id="46" string="Nedi" />
            <token id="47" string="," />
            <token id="48" string="World" />
            <token id="49" string="Cup" />
            <token id="50" string="Marathon" />
            <token id="51" string="2:10:36" />
            <token id="52" string="," />
            <token id="53" string="second" />
            <token id="54" string="place" />
          </tokens>
        </chunking>
        <chunking id="4" string="How Ethiopia 's marathoners have fared the last two days : Date Race Result Sunday Rotterdam Marathon Belayneh Dinsamo , 2:08:39 , first place Sunday Milan , Italy Keleke Metaferia , 2:10:28 , first place , Dereje Nedi , World Cup Marathon 2:10:36 , second place" type="SBAR">
          <tokens>
            <token id="9" string="How" />
            <token id="10" string="Ethiopia" />
            <token id="11" string="'s" />
            <token id="12" string="marathoners" />
            <token id="13" string="have" />
            <token id="14" string="fared" />
            <token id="15" string="the" />
            <token id="16" string="last" />
            <token id="17" string="two" />
            <token id="18" string="days" />
            <token id="19" string=":" />
            <token id="20" string="Date" />
            <token id="21" string="Race" />
            <token id="22" string="Result" />
            <token id="23" string="Sunday" />
            <token id="24" string="Rotterdam" />
            <token id="25" string="Marathon" />
            <token id="26" string="Belayneh" />
            <token id="27" string="Dinsamo" />
            <token id="28" string="," />
            <token id="29" string="2:08:39" />
            <token id="30" string="," />
            <token id="31" string="first" />
            <token id="32" string="place" />
            <token id="33" string="Sunday" />
            <token id="34" string="Milan" />
            <token id="35" string="," />
            <token id="36" string="Italy" />
            <token id="37" string="Keleke" />
            <token id="38" string="Metaferia" />
            <token id="39" string="," />
            <token id="40" string="2:10:28" />
            <token id="41" string="," />
            <token id="42" string="first" />
            <token id="43" string="place" />
            <token id="44" string="," />
            <token id="45" string="Dereje" />
            <token id="46" string="Nedi" />
            <token id="47" string="," />
            <token id="48" string="World" />
            <token id="49" string="Cup" />
            <token id="50" string="Marathon" />
            <token id="51" string="2:10:36" />
            <token id="52" string="," />
            <token id="53" string="second" />
            <token id="54" string="place" />
          </tokens>
        </chunking>
        <chunking id="5" string="fared the last two days : Date Race Result Sunday Rotterdam Marathon Belayneh Dinsamo , 2:08:39 , first place Sunday Milan , Italy Keleke Metaferia , 2:10:28 , first place , Dereje Nedi , World Cup Marathon 2:10:36 , second place" type="VP">
          <tokens>
            <token id="14" string="fared" />
            <token id="15" string="the" />
            <token id="16" string="last" />
            <token id="17" string="two" />
            <token id="18" string="days" />
            <token id="19" string=":" />
            <token id="20" string="Date" />
            <token id="21" string="Race" />
            <token id="22" string="Result" />
            <token id="23" string="Sunday" />
            <token id="24" string="Rotterdam" />
            <token id="25" string="Marathon" />
            <token id="26" string="Belayneh" />
            <token id="27" string="Dinsamo" />
            <token id="28" string="," />
            <token id="29" string="2:08:39" />
            <token id="30" string="," />
            <token id="31" string="first" />
            <token id="32" string="place" />
            <token id="33" string="Sunday" />
            <token id="34" string="Milan" />
            <token id="35" string="," />
            <token id="36" string="Italy" />
            <token id="37" string="Keleke" />
            <token id="38" string="Metaferia" />
            <token id="39" string="," />
            <token id="40" string="2:10:28" />
            <token id="41" string="," />
            <token id="42" string="first" />
            <token id="43" string="place" />
            <token id="44" string="," />
            <token id="45" string="Dereje" />
            <token id="46" string="Nedi" />
            <token id="47" string="," />
            <token id="48" string="World" />
            <token id="49" string="Cup" />
            <token id="50" string="Marathon" />
            <token id="51" string="2:10:36" />
            <token id="52" string="," />
            <token id="53" string="second" />
            <token id="54" string="place" />
          </tokens>
        </chunking>
        <chunking id="6" string="2:10:36" type="NP">
          <tokens>
            <token id="51" string="2:10:36" />
          </tokens>
        </chunking>
        <chunking id="7" string="How" type="WHADVP">
          <tokens>
            <token id="9" string="How" />
          </tokens>
        </chunking>
        <chunking id="8" string="the last two days : Date Race Result Sunday Rotterdam Marathon Belayneh Dinsamo , 2:08:39 , first place Sunday Milan , Italy Keleke Metaferia , 2:10:28 , first place , Dereje Nedi , World Cup Marathon 2:10:36 , second place" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="last" />
            <token id="17" string="two" />
            <token id="18" string="days" />
            <token id="19" string=":" />
            <token id="20" string="Date" />
            <token id="21" string="Race" />
            <token id="22" string="Result" />
            <token id="23" string="Sunday" />
            <token id="24" string="Rotterdam" />
            <token id="25" string="Marathon" />
            <token id="26" string="Belayneh" />
            <token id="27" string="Dinsamo" />
            <token id="28" string="," />
            <token id="29" string="2:08:39" />
            <token id="30" string="," />
            <token id="31" string="first" />
            <token id="32" string="place" />
            <token id="33" string="Sunday" />
            <token id="34" string="Milan" />
            <token id="35" string="," />
            <token id="36" string="Italy" />
            <token id="37" string="Keleke" />
            <token id="38" string="Metaferia" />
            <token id="39" string="," />
            <token id="40" string="2:10:28" />
            <token id="41" string="," />
            <token id="42" string="first" />
            <token id="43" string="place" />
            <token id="44" string="," />
            <token id="45" string="Dereje" />
            <token id="46" string="Nedi" />
            <token id="47" string="," />
            <token id="48" string="World" />
            <token id="49" string="Cup" />
            <token id="50" string="Marathon" />
            <token id="51" string="2:10:36" />
            <token id="52" string="," />
            <token id="53" string="second" />
            <token id="54" string="place" />
          </tokens>
        </chunking>
        <chunking id="9" string="A LOCK ON THE MARATHON" type="NP">
          <tokens>
            <token id="4" string="A" />
            <token id="5" string="LOCK" />
            <token id="6" string="ON" />
            <token id="7" string="THE" />
            <token id="8" string="MARATHON" />
          </tokens>
        </chunking>
        <chunking id="10" string="place Sunday Milan" type="NP">
          <tokens>
            <token id="32" string="place" />
            <token id="33" string="Sunday" />
            <token id="34" string="Milan" />
          </tokens>
        </chunking>
        <chunking id="11" string="A LOCK" type="NP">
          <tokens>
            <token id="4" string="A" />
            <token id="5" string="LOCK" />
          </tokens>
        </chunking>
        <chunking id="12" string="first place" type="NP">
          <tokens>
            <token id="42" string="first" />
            <token id="43" string="place" />
          </tokens>
        </chunking>
        <chunking id="13" string="place Sunday Milan , Italy Keleke Metaferia , 2:10:28 , first place , Dereje Nedi , World Cup Marathon 2:10:36 , second place" type="NP">
          <tokens>
            <token id="32" string="place" />
            <token id="33" string="Sunday" />
            <token id="34" string="Milan" />
            <token id="35" string="," />
            <token id="36" string="Italy" />
            <token id="37" string="Keleke" />
            <token id="38" string="Metaferia" />
            <token id="39" string="," />
            <token id="40" string="2:10:28" />
            <token id="41" string="," />
            <token id="42" string="first" />
            <token id="43" string="place" />
            <token id="44" string="," />
            <token id="45" string="Dereje" />
            <token id="46" string="Nedi" />
            <token id="47" string="," />
            <token id="48" string="World" />
            <token id="49" string="Cup" />
            <token id="50" string="Marathon" />
            <token id="51" string="2:10:36" />
            <token id="52" string="," />
            <token id="53" string="second" />
            <token id="54" string="place" />
          </tokens>
        </chunking>
        <chunking id="14" string="2:10:28" type="NP">
          <tokens>
            <token id="40" string="2:10:28" />
          </tokens>
        </chunking>
        <chunking id="15" string="Date Race Result Sunday Rotterdam Marathon Belayneh Dinsamo , 2:08:39" type="NP">
          <tokens>
            <token id="20" string="Date" />
            <token id="21" string="Race" />
            <token id="22" string="Result" />
            <token id="23" string="Sunday" />
            <token id="24" string="Rotterdam" />
            <token id="25" string="Marathon" />
            <token id="26" string="Belayneh" />
            <token id="27" string="Dinsamo" />
            <token id="28" string="," />
            <token id="29" string="2:08:39" />
          </tokens>
        </chunking>
        <chunking id="16" string="Date Race Result Sunday Rotterdam Marathon Belayneh Dinsamo" type="NP">
          <tokens>
            <token id="20" string="Date" />
            <token id="21" string="Race" />
            <token id="22" string="Result" />
            <token id="23" string="Sunday" />
            <token id="24" string="Rotterdam" />
            <token id="25" string="Marathon" />
            <token id="26" string="Belayneh" />
            <token id="27" string="Dinsamo" />
          </tokens>
        </chunking>
        <chunking id="17" string="THEY 'VE" type="NP">
          <tokens>
            <token id="1" string="THEY" />
            <token id="2" string="'VE" />
          </tokens>
        </chunking>
        <chunking id="18" string="THE MARATHON" type="NP">
          <tokens>
            <token id="7" string="THE" />
            <token id="8" string="MARATHON" />
          </tokens>
        </chunking>
        <chunking id="19" string="have fared the last two days : Date Race Result Sunday Rotterdam Marathon Belayneh Dinsamo , 2:08:39 , first place Sunday Milan , Italy Keleke Metaferia , 2:10:28 , first place , Dereje Nedi , World Cup Marathon 2:10:36 , second place" type="VP">
          <tokens>
            <token id="13" string="have" />
            <token id="14" string="fared" />
            <token id="15" string="the" />
            <token id="16" string="last" />
            <token id="17" string="two" />
            <token id="18" string="days" />
            <token id="19" string=":" />
            <token id="20" string="Date" />
            <token id="21" string="Race" />
            <token id="22" string="Result" />
            <token id="23" string="Sunday" />
            <token id="24" string="Rotterdam" />
            <token id="25" string="Marathon" />
            <token id="26" string="Belayneh" />
            <token id="27" string="Dinsamo" />
            <token id="28" string="," />
            <token id="29" string="2:08:39" />
            <token id="30" string="," />
            <token id="31" string="first" />
            <token id="32" string="place" />
            <token id="33" string="Sunday" />
            <token id="34" string="Milan" />
            <token id="35" string="," />
            <token id="36" string="Italy" />
            <token id="37" string="Keleke" />
            <token id="38" string="Metaferia" />
            <token id="39" string="," />
            <token id="40" string="2:10:28" />
            <token id="41" string="," />
            <token id="42" string="first" />
            <token id="43" string="place" />
            <token id="44" string="," />
            <token id="45" string="Dereje" />
            <token id="46" string="Nedi" />
            <token id="47" string="," />
            <token id="48" string="World" />
            <token id="49" string="Cup" />
            <token id="50" string="Marathon" />
            <token id="51" string="2:10:36" />
            <token id="52" string="," />
            <token id="53" string="second" />
            <token id="54" string="place" />
          </tokens>
        </chunking>
        <chunking id="20" string="Italy Keleke Metaferia" type="NP">
          <tokens>
            <token id="36" string="Italy" />
            <token id="37" string="Keleke" />
            <token id="38" string="Metaferia" />
          </tokens>
        </chunking>
        <chunking id="21" string="Ethiopia 's marathoners" type="NP">
          <tokens>
            <token id="10" string="Ethiopia" />
            <token id="11" string="'s" />
            <token id="12" string="marathoners" />
          </tokens>
        </chunking>
        <chunking id="22" string="the last two days" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="last" />
            <token id="17" string="two" />
            <token id="18" string="days" />
          </tokens>
        </chunking>
        <chunking id="23" string="Dereje Nedi" type="NP">
          <tokens>
            <token id="45" string="Dereje" />
            <token id="46" string="Nedi" />
          </tokens>
        </chunking>
        <chunking id="24" string="Ethiopia 's" type="NP">
          <tokens>
            <token id="10" string="Ethiopia" />
            <token id="11" string="'s" />
          </tokens>
        </chunking>
        <chunking id="25" string="second place" type="NP">
          <tokens>
            <token id="53" string="second" />
            <token id="54" string="place" />
          </tokens>
        </chunking>
        <chunking id="26" string="World Cup Marathon 2:10:36" type="NP">
          <tokens>
            <token id="48" string="World" />
            <token id="49" string="Cup" />
            <token id="50" string="Marathon" />
            <token id="51" string="2:10:36" />
          </tokens>
        </chunking>
        <chunking id="27" string="Date Race Result Sunday Rotterdam Marathon Belayneh Dinsamo , 2:08:39 , first place Sunday Milan , Italy Keleke Metaferia , 2:10:28 , first place , Dereje Nedi , World Cup Marathon 2:10:36 , second place" type="NP">
          <tokens>
            <token id="20" string="Date" />
            <token id="21" string="Race" />
            <token id="22" string="Result" />
            <token id="23" string="Sunday" />
            <token id="24" string="Rotterdam" />
            <token id="25" string="Marathon" />
            <token id="26" string="Belayneh" />
            <token id="27" string="Dinsamo" />
            <token id="28" string="," />
            <token id="29" string="2:08:39" />
            <token id="30" string="," />
            <token id="31" string="first" />
            <token id="32" string="place" />
            <token id="33" string="Sunday" />
            <token id="34" string="Milan" />
            <token id="35" string="," />
            <token id="36" string="Italy" />
            <token id="37" string="Keleke" />
            <token id="38" string="Metaferia" />
            <token id="39" string="," />
            <token id="40" string="2:10:28" />
            <token id="41" string="," />
            <token id="42" string="first" />
            <token id="43" string="place" />
            <token id="44" string="," />
            <token id="45" string="Dereje" />
            <token id="46" string="Nedi" />
            <token id="47" string="," />
            <token id="48" string="World" />
            <token id="49" string="Cup" />
            <token id="50" string="Marathon" />
            <token id="51" string="2:10:36" />
            <token id="52" string="," />
            <token id="53" string="second" />
            <token id="54" string="place" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">'VE</governor>
          <dependent id="1">THEY</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">GOT</governor>
          <dependent id="2">'VE</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">GOT</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">LOCK</governor>
          <dependent id="4">A</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">GOT</governor>
          <dependent id="5">LOCK</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">MARATHON</governor>
          <dependent id="6">ON</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">MARATHON</governor>
          <dependent id="7">THE</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">LOCK</governor>
          <dependent id="8">MARATHON</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">fared</governor>
          <dependent id="9">How</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="12">marathoners</governor>
          <dependent id="10">Ethiopia</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">Ethiopia</governor>
          <dependent id="11">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">fared</governor>
          <dependent id="12">marathoners</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="14">fared</governor>
          <dependent id="13">have</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="3">GOT</governor>
          <dependent id="14">fared</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">days</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">days</governor>
          <dependent id="16">last</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="18">days</governor>
          <dependent id="17">two</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">fared</governor>
          <dependent id="18">days</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">Dinsamo</governor>
          <dependent id="20">Date</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">Dinsamo</governor>
          <dependent id="21">Race</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">Dinsamo</governor>
          <dependent id="22">Result</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">Dinsamo</governor>
          <dependent id="23">Sunday</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">Dinsamo</governor>
          <dependent id="24">Rotterdam</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">Dinsamo</governor>
          <dependent id="25">Marathon</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">Dinsamo</governor>
          <dependent id="26">Belayneh</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="18">days</governor>
          <dependent id="27">Dinsamo</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="27">Dinsamo</governor>
          <dependent id="29">2:08:39</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="34">Milan</governor>
          <dependent id="31">first</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="34">Milan</governor>
          <dependent id="32">place</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="34">Milan</governor>
          <dependent id="33">Sunday</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="27">Dinsamo</governor>
          <dependent id="34">Milan</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="38">Metaferia</governor>
          <dependent id="36">Italy</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="38">Metaferia</governor>
          <dependent id="37">Keleke</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="34">Milan</governor>
          <dependent id="38">Metaferia</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="34">Milan</governor>
          <dependent id="40">2:10:28</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="43">place</governor>
          <dependent id="42">first</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="34">Milan</governor>
          <dependent id="43">place</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="46">Nedi</governor>
          <dependent id="45">Dereje</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="34">Milan</governor>
          <dependent id="46">Nedi</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="50">Marathon</governor>
          <dependent id="48">World</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="50">Marathon</governor>
          <dependent id="49">Cup</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="34">Milan</governor>
          <dependent id="50">Marathon</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="50">Marathon</governor>
          <dependent id="51">2:10:36</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="54">place</governor>
          <dependent id="53">second</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="34">Milan</governor>
          <dependent id="54">place</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="2:08:39" type="TIME" score="0.0">
          <tokens>
            <token id="29" string="2:08:39" />
          </tokens>
        </entity>
        <entity id="2" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="31" string="first" />
          </tokens>
        </entity>
        <entity id="3" string="2:10:28" type="TIME" score="0.0">
          <tokens>
            <token id="40" string="2:10:28" />
          </tokens>
        </entity>
        <entity id="4" string="World Cup Marathon" type="MISC" score="0.0">
          <tokens>
            <token id="48" string="World" />
            <token id="49" string="Cup" />
            <token id="50" string="Marathon" />
          </tokens>
        </entity>
        <entity id="5" string="last two days" type="DATE" score="0.0">
          <tokens>
            <token id="16" string="last" />
            <token id="17" string="two" />
            <token id="18" string="days" />
          </tokens>
        </entity>
        <entity id="6" string="second" type="ORDINAL" score="0.0">
          <tokens>
            <token id="53" string="second" />
          </tokens>
        </entity>
        <entity id="7" string="Sunday" type="DATE" score="0.0">
          <tokens>
            <token id="23" string="Sunday" />
          </tokens>
        </entity>
        <entity id="8" string="2:10:36" type="TIME" score="0.0">
          <tokens>
            <token id="51" string="2:10:36" />
          </tokens>
        </entity>
        <entity id="9" string="the" type="DURATION" score="0.0">
          <tokens>
            <token id="15" string="the" />
          </tokens>
        </entity>
        <entity id="10" string="Dereje Nedi" type="PERSON" score="0.0">
          <tokens>
            <token id="45" string="Dereje" />
            <token id="46" string="Nedi" />
          </tokens>
        </entity>
        <entity id="11" string="Italy" type="LOCATION" score="0.0">
          <tokens>
            <token id="36" string="Italy" />
          </tokens>
        </entity>
        <entity id="12" string="Keleke Metaferia" type="PERSON" score="0.0">
          <tokens>
            <token id="37" string="Keleke" />
            <token id="38" string="Metaferia" />
          </tokens>
        </entity>
        <entity id="13" string="Rotterdam Marathon Belayneh Dinsamo" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="24" string="Rotterdam" />
            <token id="25" string="Marathon" />
            <token id="26" string="Belayneh" />
            <token id="27" string="Dinsamo" />
          </tokens>
        </entity>
        <entity id="14" string="Ethiopia" type="LOCATION" score="0.0">
          <tokens>
            <token id="10" string="Ethiopia" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="94" has_coreference="true">
      <content>Ethiopia wins team title Monday Boston Marathon Abebe Mekonnen, 2:09:06, first place.</content>
      <tokens>
        <token id="1" string="Ethiopia" lemma="Ethiopia" stem="ethiopia" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="2" string="wins" lemma="win" stem="win" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="team" lemma="team" stem="team" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="title" lemma="title" stem="titl" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="Monday" lemma="Monday" stem="mondai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="6" string="Boston" lemma="Boston" stem="boston" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="7" string="Marathon" lemma="Marathon" stem="marathon" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="8" string="Abebe" lemma="Abebe" stem="abebe" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="9" string="Mekonnen" lemma="Mekonnen" stem="mekonnen" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="2:09:06" lemma="2:09:06" stem="2:09:06" pos="CD" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="first" lemma="first" stem="first" pos="RB" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="true" />
        <token id="14" string="place" lemma="place" stem="place" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Ethiopia)) (VP (VBZ wins) (NP (NP (NN team) (NN title) (NNP Monday) (NNP Boston) (NNP Marathon) (NNP Abebe) (NNP Mekonnen)) (, ,) (NP (NP (CD 2:09:06)) (, ,) (NP (RB first) (NN place))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="wins team title Monday Boston Marathon Abebe Mekonnen , 2:09:06 , first place" type="VP">
          <tokens>
            <token id="2" string="wins" />
            <token id="3" string="team" />
            <token id="4" string="title" />
            <token id="5" string="Monday" />
            <token id="6" string="Boston" />
            <token id="7" string="Marathon" />
            <token id="8" string="Abebe" />
            <token id="9" string="Mekonnen" />
            <token id="10" string="," />
            <token id="11" string="2:09:06" />
            <token id="12" string="," />
            <token id="13" string="first" />
            <token id="14" string="place" />
          </tokens>
        </chunking>
        <chunking id="2" string="team title Monday Boston Marathon Abebe Mekonnen" type="NP">
          <tokens>
            <token id="3" string="team" />
            <token id="4" string="title" />
            <token id="5" string="Monday" />
            <token id="6" string="Boston" />
            <token id="7" string="Marathon" />
            <token id="8" string="Abebe" />
            <token id="9" string="Mekonnen" />
          </tokens>
        </chunking>
        <chunking id="3" string="2:09:06" type="NP">
          <tokens>
            <token id="11" string="2:09:06" />
          </tokens>
        </chunking>
        <chunking id="4" string="2:09:06 , first place" type="NP">
          <tokens>
            <token id="11" string="2:09:06" />
            <token id="12" string="," />
            <token id="13" string="first" />
            <token id="14" string="place" />
          </tokens>
        </chunking>
        <chunking id="5" string="team title Monday Boston Marathon Abebe Mekonnen , 2:09:06 , first place" type="NP">
          <tokens>
            <token id="3" string="team" />
            <token id="4" string="title" />
            <token id="5" string="Monday" />
            <token id="6" string="Boston" />
            <token id="7" string="Marathon" />
            <token id="8" string="Abebe" />
            <token id="9" string="Mekonnen" />
            <token id="10" string="," />
            <token id="11" string="2:09:06" />
            <token id="12" string="," />
            <token id="13" string="first" />
            <token id="14" string="place" />
          </tokens>
        </chunking>
        <chunking id="6" string="Ethiopia" type="NP">
          <tokens>
            <token id="1" string="Ethiopia" />
          </tokens>
        </chunking>
        <chunking id="7" string="first place" type="NP">
          <tokens>
            <token id="13" string="first" />
            <token id="14" string="place" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">wins</governor>
          <dependent id="1">Ethiopia</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">wins</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Mekonnen</governor>
          <dependent id="3">team</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Mekonnen</governor>
          <dependent id="4">title</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Mekonnen</governor>
          <dependent id="5">Monday</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Mekonnen</governor>
          <dependent id="6">Boston</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Mekonnen</governor>
          <dependent id="7">Marathon</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Mekonnen</governor>
          <dependent id="8">Abebe</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">wins</governor>
          <dependent id="9">Mekonnen</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="9">Mekonnen</governor>
          <dependent id="11">2:09:06</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">place</governor>
          <dependent id="13">first</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="11">2:09:06</governor>
          <dependent id="14">place</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Boston Marathon" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="6" string="Boston" />
            <token id="7" string="Marathon" />
          </tokens>
        </entity>
        <entity id="2" string="2:09:06" type="TIME" score="0.0">
          <tokens>
            <token id="11" string="2:09:06" />
          </tokens>
        </entity>
        <entity id="3" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="13" string="first" />
          </tokens>
        </entity>
        <entity id="4" string="Abebe Mekonnen" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Abebe" />
            <token id="9" string="Mekonnen" />
          </tokens>
        </entity>
        <entity id="5" string="Monday" type="DATE" score="0.0">
          <tokens>
            <token id="5" string="Monday" />
          </tokens>
        </entity>
        <entity id="6" string="Ethiopia" type="LOCATION" score="0.0">
          <tokens>
            <token id="1" string="Ethiopia" />
          </tokens>
        </entity>
      </entities>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="3" type="PROPER">
      <referenced ids_tokens="8" string="Ethiopia" id_sentence="2" />
      <mentions>
        <mention ids_tokens="1-2" string="Ethiopia's" id_sentence="26" />
        <mention ids_tokens="4-5" string="Ethiopia's" id_sentence="30" />
        <mention ids_tokens="7-8" string="the Ethiopians" id_sentence="35" />
        <mention ids_tokens="10-11" string="Ethiopia's" id_sentence="93" />
      </mentions>
    </coreference>
    <coreference id="4" type="PROPER">
      <referenced ids_tokens="16" string="three" id_sentence="2" />
      <mentions>
        <mention ids_tokens="2" string="its" id_sentence="32" />
      </mentions>
    </coreference>
    <coreference id="5" type="PROPER">
      <referenced ids_tokens="11-12-13" string="the Olympic Games" id_sentence="30" />
      <mentions>
        <mention ids_tokens="18" string="Olympic" id_sentence="2" />
        <mention ids_tokens="30" string="Olympic" id_sentence="3" />
        <mention ids_tokens="16" string="Olympic" id_sentence="15" />
        <mention ids_tokens="12" string="Olympic" id_sentence="32" />
      </mentions>
    </coreference>
    <coreference id="7" type="PROPER">
      <referenced ids_tokens="15-16-17-18-19" string="last year 's Tokyo Marathon" id_sentence="40" />
      <mentions>
        <mention ids_tokens="27-28" string="the marathon" id_sentence="2" />
        <mention ids_tokens="19-21" string="the London Marathon" id_sentence="25" />
        <mention ids_tokens="13-14" string="the marathon" id_sentence="70" />
        <mention ids_tokens="7-8" string="THE MARATHON" id_sentence="93" />
      </mentions>
    </coreference>
    <coreference id="8" type="PROPER">
      <referenced ids_tokens="11-12" string="Abebe Bikila" id_sentence="3" />
      <mentions>
        <mention ids_tokens="12" string="Bikila" id_sentence="4" />
        <mention ids_tokens="10-21" string="Bikila , who won the marathon gold medal in 1960 and 1964" id_sentence="33" />
        <mention ids_tokens="10" string="Bikila" id_sentence="33" />
      </mentions>
    </coreference>
    <coreference id="10" type="PROPER">
      <referenced ids_tokens="25-26-27-28-29-30-31" string="the first of his two Olympic golds" id_sentence="3" />
      <mentions>
        <mention ids_tokens="5" string="first" id_sentence="14" />
        <mention ids_tokens="13" string="first" id_sentence="15" />
        <mention ids_tokens="4" string="first" id_sentence="37" />
        <mention ids_tokens="14" string="first" id_sentence="39" />
        <mention ids_tokens="3" string="first" id_sentence="52" />
        <mention ids_tokens="7" string="first" id_sentence="59" />
        <mention ids_tokens="31" string="first" id_sentence="93" />
        <mention ids_tokens="42" string="first" id_sentence="93" />
        <mention ids_tokens="13" string="first" id_sentence="94" />
      </mentions>
    </coreference>
    <coreference id="11" type="PROPER">
      <referenced ids_tokens="3-4-5-6-7-8-9" string="team title Monday Boston Marathon Abebe Mekonnen" id_sentence="94" />
      <mentions>
        <mention ids_tokens="4-5" string="Abebe Mekonnen" id_sentence="4" />
        <mention ids_tokens="1-8" string="Mekonnen , a police lieutenant from Addis Ababa" id_sentence="5" />
        <mention ids_tokens="1" string="Mekonnen" id_sentence="5" />
        <mention ids_tokens="3-8" string="a police lieutenant from Addis Ababa" id_sentence="5" />
        <mention ids_tokens="11" string="Mekonnen" id_sentence="16" />
        <mention ids_tokens="13" string="his" id_sentence="16" />
        <mention ids_tokens="16-18" string="Mekonnen , 24" id_sentence="37" />
        <mention ids_tokens="16" string="Mekonnen" id_sentence="37" />
        <mention ids_tokens="6" string="Mekonnen" id_sentence="39" />
        <mention ids_tokens="9" string="Mekonnen" id_sentence="40" />
        <mention ids_tokens="2" string="I" id_sentence="41" />
        <mention ids_tokens="12" string="Mekonnen" id_sentence="41" />
        <mention ids_tokens="2" string="I" id_sentence="42" />
        <mention ids_tokens="5" string="I" id_sentence="42" />
        <mention ids_tokens="1" string="Mekonnen" id_sentence="44" />
      </mentions>
    </coreference>
    <coreference id="14" type="PROPER">
      <referenced ids_tokens="21-22-23-24" string="Juma Ikangaa of Tanzania" id_sentence="5" />
      <mentions>
        <mention ids_tokens="1" string="Ikangaa" id_sentence="6" />
        <mention ids_tokens="8" string="Ikangaa" id_sentence="39" />
        <mention ids_tokens="21" string="Ikangaa" id_sentence="39" />
        <mention ids_tokens="12" string="Ikangaa" id_sentence="40" />
        <mention ids_tokens="4" string="him" id_sentence="41" />
        <mention ids_tokens="9" string="him" id_sentence="42" />
        <mention ids_tokens="1" string="He" id_sentence="43" />
        <mention ids_tokens="3-5" string="a good runner" id_sentence="43" />
        <mention ids_tokens="8" string="he" id_sentence="43" />
        <mention ids_tokens="10" string="Ikangaa" id_sentence="45" />
      </mentions>
    </coreference>
    <coreference id="15" type="PROPER">
      <referenced ids_tokens="27-28-29-30-31-32-33-34-35" string="Monday 's Boston Marathon in 2 hours 9 minutes" id_sentence="5" />
      <mentions>
        <mention ids_tokens="6-7" string="Boston Marathon" id_sentence="94" />
      </mentions>
    </coreference>
    <coreference id="17" type="PROPER">
      <referenced ids_tokens="5" string="second" id_sentence="7" />
      <mentions>
        <mention ids_tokens="9" string="it" id_sentence="58" />
      </mentions>
    </coreference>
    <coreference id="18" type="PROPER">
      <referenced ids_tokens="1-2-3-4" string="Ingrid Kristiansen of Norway" id_sentence="8" />
      <mentions>
        <mention ids_tokens="1-8" string="Kristiansen , the women's marathon world record-holder" id_sentence="9" />
        <mention ids_tokens="1" string="Kristiansen" id_sentence="9" />
        <mention ids_tokens="3-8" string="the women's marathon world record-holder" id_sentence="9" />
        <mention ids_tokens="3" string="Kristiansen" id_sentence="11" />
        <mention ids_tokens="7" string="Kristiansen" id_sentence="14" />
        <mention ids_tokens="27" string="she" id_sentence="15" />
        <mention ids_tokens="31" string="her" id_sentence="15" />
        <mention ids_tokens="3" string="Kristiansen" id_sentence="44" />
        <mention ids_tokens="10" string="Kristiansen" id_sentence="50" />
        <mention ids_tokens="1" string="She" id_sentence="51" />
        <mention ids_tokens="11" string="Kristiansen" id_sentence="52" />
        <mention ids_tokens="13" string="Kristiansen" id_sentence="54" />
        <mention ids_tokens="19" string="Kristiansen" id_sentence="74" />
        <mention ids_tokens="1" string="I" id_sentence="77" />
        <mention ids_tokens="14" string="she" id_sentence="79" />
        <mention ids_tokens="1" string="Her" id_sentence="80" />
        <mention ids_tokens="2" string="I" id_sentence="81" />
        <mention ids_tokens="10" string="I" id_sentence="81" />
        <mention ids_tokens="12" string="I" id_sentence="81" />
        <mention ids_tokens="20" string="me" id_sentence="81" />
        <mention ids_tokens="23" string="she" id_sentence="81" />
        <mention ids_tokens="8" string="me" id_sentence="82" />
        <mention ids_tokens="4" string="I" id_sentence="84" />
        <mention ids_tokens="15" string="I" id_sentence="84" />
        <mention ids_tokens="20" string="I" id_sentence="84" />
        <mention ids_tokens="1" string="I" id_sentence="85" />
        <mention ids_tokens="3" string="I" id_sentence="85" />
        <mention ids_tokens="1" string="I" id_sentence="87" />
        <mention ids_tokens="8" string="my" id_sentence="87" />
        <mention ids_tokens="1" string="I" id_sentence="88" />
        <mention ids_tokens="11" string="she" id_sentence="89" />
        <mention ids_tokens="15" string="her" id_sentence="89" />
        <mention ids_tokens="1" string="She" id_sentence="90" />
        <mention ids_tokens="3" string="she" id_sentence="90" />
        <mention ids_tokens="16" string="I" id_sentence="90" />
        <mention ids_tokens="34" string="her" id_sentence="90" />
        <mention ids_tokens="2" string="I" id_sentence="91" />
        <mention ids_tokens="1" string="I" id_sentence="92" />
      </mentions>
    </coreference>
    <coreference id="19" type="NOMINAL">
      <referenced ids_tokens="7-8-9-10-11-12" string="the women 's race in 2:24:33" id_sentence="8" />
      <mentions>
        <mention ids_tokens="1-4" string="The women's race" id_sentence="50" />
      </mentions>
    </coreference>
    <coreference id="20" type="NOMINAL">
      <referenced ids_tokens="7-8-9" string="the women 's" id_sentence="8" />
      <mentions>
        <mention ids_tokens="34-35" string="the women" id_sentence="12" />
      </mentions>
    </coreference>
    <coreference id="21" type="NOMINAL">
      <referenced ids_tokens="8-9-10-11-12" string="the Patriot 's Day race" id_sentence="10" />
      <mentions>
        <mention ids_tokens="18-19" string="this race" id_sentence="11" />
      </mentions>
    </coreference>
    <coreference id="22" type="PROPER">
      <referenced ids_tokens="22-23" string="next Sunday" id_sentence="25" />
      <mentions>
        <mention ids_tokens="21" string="it" id_sentence="10" />
        <mention ids_tokens="23" string="Sunday" id_sentence="10" />
        <mention ids_tokens="4" string="Sunday" id_sentence="18" />
        <mention ids_tokens="3" string="Sunday" id_sentence="20" />
      </mentions>
    </coreference>
    <coreference id="23" type="PROPER">
      <referenced ids_tokens="1-2-3" string="Joan Benoit Samuelson" id_sentence="12" />
      <mentions>
        <mention ids_tokens="8" string="her" id_sentence="13" />
      </mentions>
    </coreference>
    <coreference id="24" type="PROPER">
      <referenced ids_tokens="26" string="11" id_sentence="12" />
      <mentions>
        <mention ids_tokens="6" string="it" id_sentence="62" />
      </mentions>
    </coreference>
    <coreference id="25" type="NOMINAL">
      <referenced ids_tokens="3-4-5-6-7-8-9" string="the worst marathon performance of her career" id_sentence="13" />
      <mentions>
        <mention ids_tokens="7-9" string="a world record" id_sentence="12" />
      </mentions>
    </coreference>
    <coreference id="26" type="NOMINAL">
      <referenced ids_tokens="19-20-21-22-23-24-25-26-27" string="physical problems that altered her stride at 11 miles" id_sentence="12" />
      <mentions>
        <mention ids_tokens="13" string="problems" id_sentence="61" />
      </mentions>
    </coreference>
    <coreference id="27" type="NOMINAL">
      <referenced ids_tokens="3-4" string="my stride" id_sentence="63" />
      <mentions>
        <mention ids_tokens="24-27" string="stride at 11 miles" id_sentence="12" />
        <mention ids_tokens="14-15" string="her stride" id_sentence="69" />
      </mentions>
    </coreference>
    <coreference id="28" type="NOMINAL">
      <referenced ids_tokens="26-27" string="11 miles" id_sentence="12" />
      <mentions>
        <mention ids_tokens="13-19" string="11 miles , when she came undone" id_sentence="57" />
      </mentions>
    </coreference>
    <coreference id="29" type="PROPER">
      <referenced ids_tokens="7-8-9" string="the private Samuelson" id_sentence="79" />
      <mentions>
        <mention ids_tokens="8" string="Samuelson" id_sentence="15" />
        <mention ids_tokens="1" string="Samuelson" id_sentence="57" />
        <mention ids_tokens="2" string="I" id_sentence="58" />
        <mention ids_tokens="19" string="my" id_sentence="58" />
        <mention ids_tokens="24" string="Samuelson" id_sentence="58" />
        <mention ids_tokens="2" string="I" id_sentence="59" />
        <mention ids_tokens="11" string="I" id_sentence="59" />
        <mention ids_tokens="13" string="I" id_sentence="59" />
        <mention ids_tokens="1" string="I" id_sentence="60" />
        <mention ids_tokens="5" string="I" id_sentence="60" />
        <mention ids_tokens="1-8" string="Samuelson , who had knee surgery in February" id_sentence="69" />
        <mention ids_tokens="1" string="Samuelson" id_sentence="69" />
        <mention ids_tokens="9" string="Samuelson" id_sentence="70" />
        <mention ids_tokens="7" string="Samuelson" id_sentence="78" />
        <mention ids_tokens="1-8" string="Samuelson , who holds the U.S. marathon record" id_sentence="89" />
        <mention ids_tokens="1" string="Samuelson" id_sentence="89" />
        <mention ids_tokens="28" string="Samuelson" id_sentence="90" />
      </mentions>
    </coreference>
    <coreference id="30" type="PROPER">
      <referenced ids_tokens="7-8" string="93rd Boston" id_sentence="16" />
      <mentions>
        <mention ids_tokens="8" string="Boston" id_sentence="24" />
        <mention ids_tokens="14" string="Boston" id_sentence="37" />
        <mention ids_tokens="6" string="Boston" id_sentence="61" />
      </mentions>
    </coreference>
    <coreference id="31" type="NOMINAL">
      <referenced ids_tokens="5-6-7-8-9" string="Monday 's 93rd Boston race" id_sentence="16" />
      <mentions>
        <mention ids_tokens="6-9" string="Monday's Boston race" id_sentence="24" />
      </mentions>
    </coreference>
    <coreference id="32" type="PROPER">
      <referenced ids_tokens="20-21-22-23-24-25-26-27" string="Date Race Result Sunday Rotterdam Marathon Belayneh Dinsamo" id_sentence="93" />
      <mentions>
        <mention ids_tokens="6-7" string="Belayneh Dinsamo" id_sentence="18" />
        <mention ids_tokens="1" string="Dinsamo" id_sentence="19" />
      </mentions>
    </coreference>
    <coreference id="34" type="NOMINAL">
      <referenced ids_tokens="3-4-5-6-7-8-9-10-11-12-13-14-15" string="the world record of 2:06:50 , set last year on the same course" id_sentence="19" />
      <mentions>
        <mention ids_tokens="8-10" string="the world record" id_sentence="56" />
      </mentions>
    </coreference>
    <coreference id="35" type="PROPER">
      <referenced ids_tokens="11-12-13" string="here last year" id_sentence="45" />
      <mentions>
        <mention ids_tokens="10-11" string="last year" id_sentence="19" />
        <mention ids_tokens="15-17" string="last year's" id_sentence="40" />
        <mention ids_tokens="1" string="It" id_sentence="86" />
        <mention ids_tokens="4-5" string="a year" id_sentence="86" />
      </mentions>
    </coreference>
    <coreference id="36" type="PROPER">
      <referenced ids_tokens="11" string="Milan" id_sentence="20" />
      <mentions>
        <mention ids_tokens="32-34" string="place Sunday Milan" id_sentence="93" />
      </mentions>
    </coreference>
    <coreference id="37" type="PROPER">
      <referenced ids_tokens="6-7-8-9-10-11" string="the World Cup Marathon at Milan" id_sentence="20" />
      <mentions>
        <mention ids_tokens="6-7" string="World Cup" id_sentence="22" />
      </mentions>
    </coreference>
    <coreference id="38" type="PROPER">
      <referenced ids_tokens="36-37-38" string="Italy Keleke Metaferia" id_sentence="93" />
      <mentions>
        <mention ids_tokens="1-2" string="Keleke Metaferia" id_sentence="21" />
      </mentions>
    </coreference>
    <coreference id="44" type="NOMINAL">
      <referenced ids_tokens="1-2-3-4-5" string="More than 1 million people" id_sentence="27" />
      <mentions>
        <mention ids_tokens="5" string="people" id_sentence="82" />
      </mentions>
    </coreference>
    <coreference id="45" type="NOMINAL">
      <referenced ids_tokens="14-15" string="the needy" id_sentence="29" />
      <mentions>
        <mention ids_tokens="2" string="they" id_sentence="31" />
      </mentions>
    </coreference>
    <coreference id="46" type="NOMINAL">
      <referenced ids_tokens="18-19-20" string="the men 's" id_sentence="31" />
      <mentions>
        <mention ids_tokens="6-7" string="the men" id_sentence="47" />
      </mentions>
    </coreference>
    <coreference id="47" type="NOMINAL">
      <referenced ids_tokens="3-4-5-6-7" string="the first time since 1963" id_sentence="37" />
      <mentions>
        <mention ids_tokens="1-8" string="Much of the central part of the country" id_sentence="36" />
      </mentions>
    </coreference>
    <coreference id="49" type="PROPER">
      <referenced ids_tokens="9-10" string="an Ethiopian" id_sentence="37" />
      <mentions>
        <mention ids_tokens="1" string="He" id_sentence="38" />
      </mentions>
    </coreference>
    <coreference id="50" type="NOMINAL">
      <referenced ids_tokens="12-13-14-15" string="the 6,418 entrants race" id_sentence="38" />
      <mentions>
        <mention ids_tokens="15-16" string="the race" id_sentence="48" />
        <mention ids_tokens="7-8" string="the race" id_sentence="55" />
      </mentions>
    </coreference>
    <coreference id="52" type="LIST">
      <referenced ids_tokens="6-7-8" string="Mekonnen and Ikangaa" id_sentence="39" />
      <mentions>
        <mention ids_tokens="2" string="they" id_sentence="40" />
      </mentions>
    </coreference>
    <coreference id="53" type="LIST">
      <referenced ids_tokens="1-2-3" string="Mekonnen and Kristiansen" id_sentence="44" />
      <mentions>
        <mention ids_tokens="5" string="they" id_sentence="46" />
      </mentions>
    </coreference>
    <coreference id="55" type="PROPER">
      <referenced ids_tokens="1-2-3-4-5-6-7-8-9-10-11-12-13" string="John Treacy of Ireland , who was third behind Ikangaa here last year" id_sentence="45" />
      <mentions>
        <mention ids_tokens="2" string="I" id_sentence="46" />
        <mention ids_tokens="13" string="Treacy" id_sentence="46" />
      </mentions>
    </coreference>
    <coreference id="56" type="NOMINAL">
      <referenced ids_tokens="2-3-4" string="the halfway point" id_sentence="47" />
      <mentions>
        <mention ids_tokens="6-7" string="that point" id_sentence="63" />
        <mention ids_tokens="8-9" string="that point" id_sentence="64" />
        <mention ids_tokens="7" string="it" id_sentence="66" />
      </mentions>
    </coreference>
    <coreference id="57" type="NOMINAL">
      <referenced ids_tokens="10-11-12" string="a 2:04 pace" id_sentence="47" />
      <mentions>
        <mention ids_tokens="1-2" string="The pace" id_sentence="48" />
      </mentions>
    </coreference>
    <coreference id="58" type="PROPER">
      <referenced ids_tokens="7-8-9-10-11-12-13-14-15-16-17-18-19" string="Saimon Robert Haali of Tanzania , who led the race for five miles" id_sentence="48" />
      <mentions>
        <mention ids_tokens="1" string="He" id_sentence="49" />
      </mentions>
    </coreference>
    <coreference id="59" type="PROPER">
      <referenced ids_tokens="19-20-21" string="my problem today" id_sentence="58" />
      <mentions>
        <mention ids_tokens="8-9" string="the heat" id_sentence="52" />
        <mention ids_tokens="15-16" string="the heat" id_sentence="54" />
      </mentions>
    </coreference>
    <coreference id="60" type="PROPER">
      <referenced ids_tokens="3" string="17th" id_sentence="53" />
      <mentions>
        <mention ids_tokens="2" string="her" id_sentence="54" />
        <mention ids_tokens="2" string="I" id_sentence="55" />
        <mention ids_tokens="11" string="she" id_sentence="55" />
        <mention ids_tokens="17" string="she" id_sentence="57" />
      </mentions>
    </coreference>
    <coreference id="63" type="PROPER">
      <referenced ids_tokens="7" string="I" id_sentence="67" />
      <mentions>
        <mention ids_tokens="15" string="my" id_sentence="61" />
        <mention ids_tokens="18" string="my" id_sentence="61" />
        <mention ids_tokens="3" string="my" id_sentence="63" />
        <mention ids_tokens="6" string="me" id_sentence="64" />
        <mention ids_tokens="14" string="her" id_sentence="69" />
      </mentions>
    </coreference>
    <coreference id="64" type="PROPER">
      <referenced ids_tokens="1-2" string="Lisa Weidenbach" id_sentence="64" />
      <mentions>
        <mention ids_tokens="1" string="Weidenbach" id_sentence="73" />
        <mention ids_tokens="2" string="she" id_sentence="76" />
        <mention ids_tokens="7" string="she" id_sentence="77" />
      </mentions>
    </coreference>
    <coreference id="65" type="PROPER">
      <referenced ids_tokens="3" string="Buist" id_sentence="65" />
      <mentions>
        <mention ids_tokens="1-5" string="Buist , of New Zealand" id_sentence="71" />
      </mentions>
    </coreference>
    <coreference id="66" type="PROPER">
      <referenced ids_tokens="8" string="February" id_sentence="69" />
      <mentions>
        <mention ids_tokens="1" string="It" id_sentence="70" />
      </mentions>
    </coreference>
    <coreference id="67" type="PROPER">
      <referenced ids_tokens="6" string="Wash." id_sentence="72" />
      <mentions>
        <mention ids_tokens="12" string="Washington" id_sentence="90" />
      </mentions>
    </coreference>
    <coreference id="68" type="PROPER">
      <referenced ids_tokens="3" string="fifth" id_sentence="73" />
      <mentions>
        <mention ids_tokens="2" string="It" id_sentence="74" />
      </mentions>
    </coreference>
    <coreference id="70" type="NOMINAL">
      <referenced ids_tokens="1-2-3-4-5-6-7" string="&quot; The easiest way to be beaten" id_sentence="75" />
      <mentions>
        <mention ids_tokens="3" string="it" id_sentence="77" />
      </mentions>
    </coreference>
    <coreference id="71" type="NOMINAL">
      <referenced ids_tokens="2-3-4-5" string="A lot of people" id_sentence="82" />
      <mentions>
        <mention ids_tokens="1" string="It" id_sentence="83" />
        <mention ids_tokens="4" string="it" id_sentence="83" />
      </mentions>
    </coreference>
  </coreferences>
</document>
