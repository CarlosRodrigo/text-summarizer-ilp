<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="LA011889-0067">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>The Los Angeles County district attorney&amp;apost;s office and the FBI are investigating a videotaped incident in which a white Long Beach police officer appeared to shove a black man&amp;apost;s face into a plate glass window after a routine traffic stop.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="Los" lemma="Los" stem="lo" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="3" string="Angeles" lemma="Angeles" stem="angele" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="4" string="County" lemma="County" stem="counti" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="5" string="district" lemma="district" stem="district" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="attorney" lemma="attorney" stem="attornei" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="office" lemma="office" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="FBI" lemma="FBI" stem="fbi" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="12" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="investigating" lemma="investigate" stem="investig" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="videotaped" lemma="videotaped" stem="videotap" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="incident" lemma="incident" stem="incid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="white" lemma="white" stem="white" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="Long" lemma="long" stem="long" pos="JJ" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="22" string="Beach" lemma="Beach" stem="beach" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="23" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="officer" lemma="officer" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="25" string="appeared" lemma="appear" stem="appear" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="shove" lemma="shove" stem="shove" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="black" lemma="black" stem="black" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="man" lemma="man" stem="man" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="face" lemma="face" stem="face" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="35" string="plate" lemma="plate" stem="plate" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="36" string="glass" lemma="glass" stem="glass" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="37" string="window" lemma="window" stem="window" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="38" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="routine" lemma="routine" stem="routin" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="traffic" lemma="traffic" stem="traffic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="stop" lemma="stop" stem="stop" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NP (DT The) (NNP Los) (NNP Angeles) (NNP County) (NN district) (NN attorney) (POS 's)) (NN office)) (CC and) (NP (DT the) (NNP FBI))) (VP (VBP are) (VP (VBG investigating) (NP (NP (DT a) (JJ videotaped) (NN incident)) (SBAR (WHPP (IN in) (WHNP (WDT which))) (S (NP (NP (DT a) (JJ white) (JJ Long) (NNP Beach) (NN police)) (NP (NN officer))) (VP (VBD appeared) (S (VP (TO to) (VP (VB shove) (NP (NP (DT a) (JJ black) (NN man) (POS 's)) (NN face)) (PP (IN into) (NP (DT a) (NN plate) (NN glass) (NN window))) (PP (IN after) (NP (DT a) (JJ routine) (NN traffic) (NN stop)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="The Los Angeles County district attorney 's office and the FBI" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Los" />
            <token id="3" string="Angeles" />
            <token id="4" string="County" />
            <token id="5" string="district" />
            <token id="6" string="attorney" />
            <token id="7" string="'s" />
            <token id="8" string="office" />
            <token id="9" string="and" />
            <token id="10" string="the" />
            <token id="11" string="FBI" />
          </tokens>
        </chunking>
        <chunking id="2" string="a routine traffic stop" type="NP">
          <tokens>
            <token id="39" string="a" />
            <token id="40" string="routine" />
            <token id="41" string="traffic" />
            <token id="42" string="stop" />
          </tokens>
        </chunking>
        <chunking id="3" string="The Los Angeles County district attorney 's" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Los" />
            <token id="3" string="Angeles" />
            <token id="4" string="County" />
            <token id="5" string="district" />
            <token id="6" string="attorney" />
            <token id="7" string="'s" />
          </tokens>
        </chunking>
        <chunking id="4" string="officer" type="NP">
          <tokens>
            <token id="24" string="officer" />
          </tokens>
        </chunking>
        <chunking id="5" string="are investigating a videotaped incident in which a white Long Beach police officer appeared to shove a black man 's face into a plate glass window after a routine traffic stop" type="VP">
          <tokens>
            <token id="12" string="are" />
            <token id="13" string="investigating" />
            <token id="14" string="a" />
            <token id="15" string="videotaped" />
            <token id="16" string="incident" />
            <token id="17" string="in" />
            <token id="18" string="which" />
            <token id="19" string="a" />
            <token id="20" string="white" />
            <token id="21" string="Long" />
            <token id="22" string="Beach" />
            <token id="23" string="police" />
            <token id="24" string="officer" />
            <token id="25" string="appeared" />
            <token id="26" string="to" />
            <token id="27" string="shove" />
            <token id="28" string="a" />
            <token id="29" string="black" />
            <token id="30" string="man" />
            <token id="31" string="'s" />
            <token id="32" string="face" />
            <token id="33" string="into" />
            <token id="34" string="a" />
            <token id="35" string="plate" />
            <token id="36" string="glass" />
            <token id="37" string="window" />
            <token id="38" string="after" />
            <token id="39" string="a" />
            <token id="40" string="routine" />
            <token id="41" string="traffic" />
            <token id="42" string="stop" />
          </tokens>
        </chunking>
        <chunking id="6" string="a black man 's face" type="NP">
          <tokens>
            <token id="28" string="a" />
            <token id="29" string="black" />
            <token id="30" string="man" />
            <token id="31" string="'s" />
            <token id="32" string="face" />
          </tokens>
        </chunking>
        <chunking id="7" string="The Los Angeles County district attorney 's office" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Los" />
            <token id="3" string="Angeles" />
            <token id="4" string="County" />
            <token id="5" string="district" />
            <token id="6" string="attorney" />
            <token id="7" string="'s" />
            <token id="8" string="office" />
          </tokens>
        </chunking>
        <chunking id="8" string="a white Long Beach police officer" type="NP">
          <tokens>
            <token id="19" string="a" />
            <token id="20" string="white" />
            <token id="21" string="Long" />
            <token id="22" string="Beach" />
            <token id="23" string="police" />
            <token id="24" string="officer" />
          </tokens>
        </chunking>
        <chunking id="9" string="appeared to shove a black man 's face into a plate glass window after a routine traffic stop" type="VP">
          <tokens>
            <token id="25" string="appeared" />
            <token id="26" string="to" />
            <token id="27" string="shove" />
            <token id="28" string="a" />
            <token id="29" string="black" />
            <token id="30" string="man" />
            <token id="31" string="'s" />
            <token id="32" string="face" />
            <token id="33" string="into" />
            <token id="34" string="a" />
            <token id="35" string="plate" />
            <token id="36" string="glass" />
            <token id="37" string="window" />
            <token id="38" string="after" />
            <token id="39" string="a" />
            <token id="40" string="routine" />
            <token id="41" string="traffic" />
            <token id="42" string="stop" />
          </tokens>
        </chunking>
        <chunking id="10" string="a black man 's" type="NP">
          <tokens>
            <token id="28" string="a" />
            <token id="29" string="black" />
            <token id="30" string="man" />
            <token id="31" string="'s" />
          </tokens>
        </chunking>
        <chunking id="11" string="a white Long Beach police" type="NP">
          <tokens>
            <token id="19" string="a" />
            <token id="20" string="white" />
            <token id="21" string="Long" />
            <token id="22" string="Beach" />
            <token id="23" string="police" />
          </tokens>
        </chunking>
        <chunking id="12" string="a plate glass window" type="NP">
          <tokens>
            <token id="34" string="a" />
            <token id="35" string="plate" />
            <token id="36" string="glass" />
            <token id="37" string="window" />
          </tokens>
        </chunking>
        <chunking id="13" string="in which a white Long Beach police officer appeared to shove a black man 's face into a plate glass window after a routine traffic stop" type="SBAR">
          <tokens>
            <token id="17" string="in" />
            <token id="18" string="which" />
            <token id="19" string="a" />
            <token id="20" string="white" />
            <token id="21" string="Long" />
            <token id="22" string="Beach" />
            <token id="23" string="police" />
            <token id="24" string="officer" />
            <token id="25" string="appeared" />
            <token id="26" string="to" />
            <token id="27" string="shove" />
            <token id="28" string="a" />
            <token id="29" string="black" />
            <token id="30" string="man" />
            <token id="31" string="'s" />
            <token id="32" string="face" />
            <token id="33" string="into" />
            <token id="34" string="a" />
            <token id="35" string="plate" />
            <token id="36" string="glass" />
            <token id="37" string="window" />
            <token id="38" string="after" />
            <token id="39" string="a" />
            <token id="40" string="routine" />
            <token id="41" string="traffic" />
            <token id="42" string="stop" />
          </tokens>
        </chunking>
        <chunking id="14" string="the FBI" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="FBI" />
          </tokens>
        </chunking>
        <chunking id="15" string="to shove a black man 's face into a plate glass window after a routine traffic stop" type="VP">
          <tokens>
            <token id="26" string="to" />
            <token id="27" string="shove" />
            <token id="28" string="a" />
            <token id="29" string="black" />
            <token id="30" string="man" />
            <token id="31" string="'s" />
            <token id="32" string="face" />
            <token id="33" string="into" />
            <token id="34" string="a" />
            <token id="35" string="plate" />
            <token id="36" string="glass" />
            <token id="37" string="window" />
            <token id="38" string="after" />
            <token id="39" string="a" />
            <token id="40" string="routine" />
            <token id="41" string="traffic" />
            <token id="42" string="stop" />
          </tokens>
        </chunking>
        <chunking id="16" string="investigating a videotaped incident in which a white Long Beach police officer appeared to shove a black man 's face into a plate glass window after a routine traffic stop" type="VP">
          <tokens>
            <token id="13" string="investigating" />
            <token id="14" string="a" />
            <token id="15" string="videotaped" />
            <token id="16" string="incident" />
            <token id="17" string="in" />
            <token id="18" string="which" />
            <token id="19" string="a" />
            <token id="20" string="white" />
            <token id="21" string="Long" />
            <token id="22" string="Beach" />
            <token id="23" string="police" />
            <token id="24" string="officer" />
            <token id="25" string="appeared" />
            <token id="26" string="to" />
            <token id="27" string="shove" />
            <token id="28" string="a" />
            <token id="29" string="black" />
            <token id="30" string="man" />
            <token id="31" string="'s" />
            <token id="32" string="face" />
            <token id="33" string="into" />
            <token id="34" string="a" />
            <token id="35" string="plate" />
            <token id="36" string="glass" />
            <token id="37" string="window" />
            <token id="38" string="after" />
            <token id="39" string="a" />
            <token id="40" string="routine" />
            <token id="41" string="traffic" />
            <token id="42" string="stop" />
          </tokens>
        </chunking>
        <chunking id="17" string="a videotaped incident" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="videotaped" />
            <token id="16" string="incident" />
          </tokens>
        </chunking>
        <chunking id="18" string="a videotaped incident in which a white Long Beach police officer appeared to shove a black man 's face into a plate glass window after a routine traffic stop" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="videotaped" />
            <token id="16" string="incident" />
            <token id="17" string="in" />
            <token id="18" string="which" />
            <token id="19" string="a" />
            <token id="20" string="white" />
            <token id="21" string="Long" />
            <token id="22" string="Beach" />
            <token id="23" string="police" />
            <token id="24" string="officer" />
            <token id="25" string="appeared" />
            <token id="26" string="to" />
            <token id="27" string="shove" />
            <token id="28" string="a" />
            <token id="29" string="black" />
            <token id="30" string="man" />
            <token id="31" string="'s" />
            <token id="32" string="face" />
            <token id="33" string="into" />
            <token id="34" string="a" />
            <token id="35" string="plate" />
            <token id="36" string="glass" />
            <token id="37" string="window" />
            <token id="38" string="after" />
            <token id="39" string="a" />
            <token id="40" string="routine" />
            <token id="41" string="traffic" />
            <token id="42" string="stop" />
          </tokens>
        </chunking>
        <chunking id="19" string="shove a black man 's face into a plate glass window after a routine traffic stop" type="VP">
          <tokens>
            <token id="27" string="shove" />
            <token id="28" string="a" />
            <token id="29" string="black" />
            <token id="30" string="man" />
            <token id="31" string="'s" />
            <token id="32" string="face" />
            <token id="33" string="into" />
            <token id="34" string="a" />
            <token id="35" string="plate" />
            <token id="36" string="glass" />
            <token id="37" string="window" />
            <token id="38" string="after" />
            <token id="39" string="a" />
            <token id="40" string="routine" />
            <token id="41" string="traffic" />
            <token id="42" string="stop" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="6">attorney</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">attorney</governor>
          <dependent id="2">Los</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">attorney</governor>
          <dependent id="3">Angeles</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">attorney</governor>
          <dependent id="4">County</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">attorney</governor>
          <dependent id="5">district</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">office</governor>
          <dependent id="6">attorney</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">attorney</governor>
          <dependent id="7">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">investigating</governor>
          <dependent id="8">office</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">office</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">FBI</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">office</governor>
          <dependent id="11">FBI</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="13">investigating</governor>
          <dependent id="12">are</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">investigating</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">incident</governor>
          <dependent id="14">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">incident</governor>
          <dependent id="15">videotaped</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">investigating</governor>
          <dependent id="16">incident</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">which</governor>
          <dependent id="17">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">appeared</governor>
          <dependent id="18">which</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">police</governor>
          <dependent id="19">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">police</governor>
          <dependent id="20">white</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">police</governor>
          <dependent id="21">Long</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">police</governor>
          <dependent id="22">Beach</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">appeared</governor>
          <dependent id="23">police</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="23">police</governor>
          <dependent id="24">officer</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="16">incident</governor>
          <dependent id="25">appeared</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="27">shove</governor>
          <dependent id="26">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="25">appeared</governor>
          <dependent id="27">shove</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">man</governor>
          <dependent id="28">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="30">man</governor>
          <dependent id="29">black</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="32">face</governor>
          <dependent id="30">man</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">man</governor>
          <dependent id="31">'s</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="27">shove</governor>
          <dependent id="32">face</dependent>
        </dependency>
        <dependency type="case">
          <governor id="37">window</governor>
          <dependent id="33">into</dependent>
        </dependency>
        <dependency type="det">
          <governor id="37">window</governor>
          <dependent id="34">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="37">window</governor>
          <dependent id="35">plate</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="37">window</governor>
          <dependent id="36">glass</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">shove</governor>
          <dependent id="37">window</dependent>
        </dependency>
        <dependency type="case">
          <governor id="42">stop</governor>
          <dependent id="38">after</dependent>
        </dependency>
        <dependency type="det">
          <governor id="42">stop</governor>
          <dependent id="39">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="42">stop</governor>
          <dependent id="40">routine</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="42">stop</governor>
          <dependent id="41">traffic</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">shove</governor>
          <dependent id="42">stop</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Los Angeles County" type="LOCATION" score="0.0">
          <tokens>
            <token id="2" string="Los" />
            <token id="3" string="Angeles" />
            <token id="4" string="County" />
          </tokens>
        </entity>
        <entity id="2" string="Long Beach" type="LOCATION" score="0.0">
          <tokens>
            <token id="21" string="Long" />
            <token id="22" string="Beach" />
          </tokens>
        </entity>
        <entity id="3" string="FBI" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="11" string="FBI" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>The Long Beach City Council voted Tuesday to ask the district attorney&amp;apost;s office to launch an independent investigation of the Saturday night incident, which was secretly recorded by an NBC television crew.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="Long" lemma="Long" stem="long" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="3" string="Beach" lemma="Beach" stem="beach" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="4" string="City" lemma="City" stem="citi" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="5" string="Council" lemma="Council" stem="council" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="6" string="voted" lemma="vote" stem="vote" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="Tuesday" lemma="Tuesday" stem="tuesdai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="ask" lemma="ask" stem="ask" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="11" string="district" lemma="district" stem="district" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="12" string="attorney" lemma="attorney" stem="attornei" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="13" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="14" string="office" lemma="office" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="launch" lemma="launch" stem="launch" pos="VB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="independent" lemma="independent" stem="independ" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="true" is_refers="false" />
        <token id="19" string="investigation" lemma="investigation" stem="investig" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="Saturday" lemma="Saturday" stem="saturdai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="23" string="night" lemma="night" stem="night" pos="NN" type="Word" isStopWord="false" ner="TIME" is_referenced="true" is_refers="false" />
        <token id="24" string="incident" lemma="incident" stem="incid" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="25" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="26" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="27" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="28" string="secretly" lemma="secretly" stem="secretli" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="29" string="recorded" lemma="record" stem="record" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="30" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="31" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="32" string="NBC" lemma="NBC" stem="nbc" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="33" string="television" lemma="television" stem="televis" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="34" string="crew" lemma="crew" stem="crew" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="35" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NNP Long) (NNP Beach) (NNP City) (NNP Council)) (VP (VBD voted) (NP-TMP (NNP Tuesday)) (S (VP (TO to) (VP (VB ask) (NP (NP (DT the) (NN district) (NN attorney) (POS 's)) (NN office) (S (VP (TO to) (VP (VB launch) (NP (NP (DT an) (JJ independent) (NN investigation)) (PP (IN of) (NP (NP (DT the) (NNP Saturday) (NN night) (NN incident)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBD was) (ADVP (RB secretly)) (VP (VBN recorded) (PP (IN by) (NP (DT an) (NNP NBC) (NN television) (NN crew)))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="to launch an independent investigation of the Saturday night incident , which was secretly recorded by an NBC television crew" type="VP">
          <tokens>
            <token id="15" string="to" />
            <token id="16" string="launch" />
            <token id="17" string="an" />
            <token id="18" string="independent" />
            <token id="19" string="investigation" />
            <token id="20" string="of" />
            <token id="21" string="the" />
            <token id="22" string="Saturday" />
            <token id="23" string="night" />
            <token id="24" string="incident" />
            <token id="25" string="," />
            <token id="26" string="which" />
            <token id="27" string="was" />
            <token id="28" string="secretly" />
            <token id="29" string="recorded" />
            <token id="30" string="by" />
            <token id="31" string="an" />
            <token id="32" string="NBC" />
            <token id="33" string="television" />
            <token id="34" string="crew" />
          </tokens>
        </chunking>
        <chunking id="2" string="launch an independent investigation of the Saturday night incident , which was secretly recorded by an NBC television crew" type="VP">
          <tokens>
            <token id="16" string="launch" />
            <token id="17" string="an" />
            <token id="18" string="independent" />
            <token id="19" string="investigation" />
            <token id="20" string="of" />
            <token id="21" string="the" />
            <token id="22" string="Saturday" />
            <token id="23" string="night" />
            <token id="24" string="incident" />
            <token id="25" string="," />
            <token id="26" string="which" />
            <token id="27" string="was" />
            <token id="28" string="secretly" />
            <token id="29" string="recorded" />
            <token id="30" string="by" />
            <token id="31" string="an" />
            <token id="32" string="NBC" />
            <token id="33" string="television" />
            <token id="34" string="crew" />
          </tokens>
        </chunking>
        <chunking id="3" string="the Saturday night incident , which was secretly recorded by an NBC television crew" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="Saturday" />
            <token id="23" string="night" />
            <token id="24" string="incident" />
            <token id="25" string="," />
            <token id="26" string="which" />
            <token id="27" string="was" />
            <token id="28" string="secretly" />
            <token id="29" string="recorded" />
            <token id="30" string="by" />
            <token id="31" string="an" />
            <token id="32" string="NBC" />
            <token id="33" string="television" />
            <token id="34" string="crew" />
          </tokens>
        </chunking>
        <chunking id="4" string="the Saturday night incident" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="Saturday" />
            <token id="23" string="night" />
            <token id="24" string="incident" />
          </tokens>
        </chunking>
        <chunking id="5" string="voted Tuesday to ask the district attorney 's office to launch an independent investigation of the Saturday night incident , which was secretly recorded by an NBC television crew" type="VP">
          <tokens>
            <token id="6" string="voted" />
            <token id="7" string="Tuesday" />
            <token id="8" string="to" />
            <token id="9" string="ask" />
            <token id="10" string="the" />
            <token id="11" string="district" />
            <token id="12" string="attorney" />
            <token id="13" string="'s" />
            <token id="14" string="office" />
            <token id="15" string="to" />
            <token id="16" string="launch" />
            <token id="17" string="an" />
            <token id="18" string="independent" />
            <token id="19" string="investigation" />
            <token id="20" string="of" />
            <token id="21" string="the" />
            <token id="22" string="Saturday" />
            <token id="23" string="night" />
            <token id="24" string="incident" />
            <token id="25" string="," />
            <token id="26" string="which" />
            <token id="27" string="was" />
            <token id="28" string="secretly" />
            <token id="29" string="recorded" />
            <token id="30" string="by" />
            <token id="31" string="an" />
            <token id="32" string="NBC" />
            <token id="33" string="television" />
            <token id="34" string="crew" />
          </tokens>
        </chunking>
        <chunking id="6" string="ask the district attorney 's office to launch an independent investigation of the Saturday night incident , which was secretly recorded by an NBC television crew" type="VP">
          <tokens>
            <token id="9" string="ask" />
            <token id="10" string="the" />
            <token id="11" string="district" />
            <token id="12" string="attorney" />
            <token id="13" string="'s" />
            <token id="14" string="office" />
            <token id="15" string="to" />
            <token id="16" string="launch" />
            <token id="17" string="an" />
            <token id="18" string="independent" />
            <token id="19" string="investigation" />
            <token id="20" string="of" />
            <token id="21" string="the" />
            <token id="22" string="Saturday" />
            <token id="23" string="night" />
            <token id="24" string="incident" />
            <token id="25" string="," />
            <token id="26" string="which" />
            <token id="27" string="was" />
            <token id="28" string="secretly" />
            <token id="29" string="recorded" />
            <token id="30" string="by" />
            <token id="31" string="an" />
            <token id="32" string="NBC" />
            <token id="33" string="television" />
            <token id="34" string="crew" />
          </tokens>
        </chunking>
        <chunking id="7" string="an independent investigation of the Saturday night incident , which was secretly recorded by an NBC television crew" type="NP">
          <tokens>
            <token id="17" string="an" />
            <token id="18" string="independent" />
            <token id="19" string="investigation" />
            <token id="20" string="of" />
            <token id="21" string="the" />
            <token id="22" string="Saturday" />
            <token id="23" string="night" />
            <token id="24" string="incident" />
            <token id="25" string="," />
            <token id="26" string="which" />
            <token id="27" string="was" />
            <token id="28" string="secretly" />
            <token id="29" string="recorded" />
            <token id="30" string="by" />
            <token id="31" string="an" />
            <token id="32" string="NBC" />
            <token id="33" string="television" />
            <token id="34" string="crew" />
          </tokens>
        </chunking>
        <chunking id="8" string="recorded by an NBC television crew" type="VP">
          <tokens>
            <token id="29" string="recorded" />
            <token id="30" string="by" />
            <token id="31" string="an" />
            <token id="32" string="NBC" />
            <token id="33" string="television" />
            <token id="34" string="crew" />
          </tokens>
        </chunking>
        <chunking id="9" string="The Long Beach City Council" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Long" />
            <token id="3" string="Beach" />
            <token id="4" string="City" />
            <token id="5" string="Council" />
          </tokens>
        </chunking>
        <chunking id="10" string="which was secretly recorded by an NBC television crew" type="SBAR">
          <tokens>
            <token id="26" string="which" />
            <token id="27" string="was" />
            <token id="28" string="secretly" />
            <token id="29" string="recorded" />
            <token id="30" string="by" />
            <token id="31" string="an" />
            <token id="32" string="NBC" />
            <token id="33" string="television" />
            <token id="34" string="crew" />
          </tokens>
        </chunking>
        <chunking id="11" string="the district attorney 's" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="district" />
            <token id="12" string="attorney" />
            <token id="13" string="'s" />
          </tokens>
        </chunking>
        <chunking id="12" string="an independent investigation" type="NP">
          <tokens>
            <token id="17" string="an" />
            <token id="18" string="independent" />
            <token id="19" string="investigation" />
          </tokens>
        </chunking>
        <chunking id="13" string="the district attorney 's office to launch an independent investigation of the Saturday night incident , which was secretly recorded by an NBC television crew" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="district" />
            <token id="12" string="attorney" />
            <token id="13" string="'s" />
            <token id="14" string="office" />
            <token id="15" string="to" />
            <token id="16" string="launch" />
            <token id="17" string="an" />
            <token id="18" string="independent" />
            <token id="19" string="investigation" />
            <token id="20" string="of" />
            <token id="21" string="the" />
            <token id="22" string="Saturday" />
            <token id="23" string="night" />
            <token id="24" string="incident" />
            <token id="25" string="," />
            <token id="26" string="which" />
            <token id="27" string="was" />
            <token id="28" string="secretly" />
            <token id="29" string="recorded" />
            <token id="30" string="by" />
            <token id="31" string="an" />
            <token id="32" string="NBC" />
            <token id="33" string="television" />
            <token id="34" string="crew" />
          </tokens>
        </chunking>
        <chunking id="14" string="an NBC television crew" type="NP">
          <tokens>
            <token id="31" string="an" />
            <token id="32" string="NBC" />
            <token id="33" string="television" />
            <token id="34" string="crew" />
          </tokens>
        </chunking>
        <chunking id="15" string="to ask the district attorney 's office to launch an independent investigation of the Saturday night incident , which was secretly recorded by an NBC television crew" type="VP">
          <tokens>
            <token id="8" string="to" />
            <token id="9" string="ask" />
            <token id="10" string="the" />
            <token id="11" string="district" />
            <token id="12" string="attorney" />
            <token id="13" string="'s" />
            <token id="14" string="office" />
            <token id="15" string="to" />
            <token id="16" string="launch" />
            <token id="17" string="an" />
            <token id="18" string="independent" />
            <token id="19" string="investigation" />
            <token id="20" string="of" />
            <token id="21" string="the" />
            <token id="22" string="Saturday" />
            <token id="23" string="night" />
            <token id="24" string="incident" />
            <token id="25" string="," />
            <token id="26" string="which" />
            <token id="27" string="was" />
            <token id="28" string="secretly" />
            <token id="29" string="recorded" />
            <token id="30" string="by" />
            <token id="31" string="an" />
            <token id="32" string="NBC" />
            <token id="33" string="television" />
            <token id="34" string="crew" />
          </tokens>
        </chunking>
        <chunking id="16" string="was secretly recorded by an NBC television crew" type="VP">
          <tokens>
            <token id="27" string="was" />
            <token id="28" string="secretly" />
            <token id="29" string="recorded" />
            <token id="30" string="by" />
            <token id="31" string="an" />
            <token id="32" string="NBC" />
            <token id="33" string="television" />
            <token id="34" string="crew" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="5">Council</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Council</governor>
          <dependent id="2">Long</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Council</governor>
          <dependent id="3">Beach</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Council</governor>
          <dependent id="4">City</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">voted</governor>
          <dependent id="5">Council</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">voted</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="6">voted</governor>
          <dependent id="7">Tuesday</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">ask</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">voted</governor>
          <dependent id="9">ask</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">attorney</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">attorney</governor>
          <dependent id="11">district</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="14">office</governor>
          <dependent id="12">attorney</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">attorney</governor>
          <dependent id="13">'s</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">ask</governor>
          <dependent id="14">office</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">launch</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="14">office</governor>
          <dependent id="16">launch</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">investigation</governor>
          <dependent id="17">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">investigation</governor>
          <dependent id="18">independent</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">launch</governor>
          <dependent id="19">investigation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">incident</governor>
          <dependent id="20">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">incident</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">incident</governor>
          <dependent id="22">Saturday</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">incident</governor>
          <dependent id="23">night</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">investigation</governor>
          <dependent id="24">incident</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="29">recorded</governor>
          <dependent id="26">which</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="29">recorded</governor>
          <dependent id="27">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="29">recorded</governor>
          <dependent id="28">secretly</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="24">incident</governor>
          <dependent id="29">recorded</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">crew</governor>
          <dependent id="30">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="34">crew</governor>
          <dependent id="31">an</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="34">crew</governor>
          <dependent id="32">NBC</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="34">crew</governor>
          <dependent id="33">television</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">recorded</governor>
          <dependent id="34">crew</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="independent" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="18" string="independent" />
          </tokens>
        </entity>
        <entity id="2" string="night" type="TIME" score="0.0">
          <tokens>
            <token id="23" string="night" />
          </tokens>
        </entity>
        <entity id="3" string="Tuesday" type="DATE" score="0.0">
          <tokens>
            <token id="7" string="Tuesday" />
          </tokens>
        </entity>
        <entity id="4" string="Saturday" type="DATE" score="0.0">
          <tokens>
            <token id="22" string="Saturday" />
          </tokens>
        </entity>
        <entity id="5" string="Long Beach City Council" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="2" string="Long" />
            <token id="3" string="Beach" />
            <token id="4" string="City" />
            <token id="5" string="Council" />
          </tokens>
        </entity>
        <entity id="6" string="NBC" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="32" string="NBC" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="false">
      <content>But Assistant Dist.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Assistant" lemma="Assistant" stem="assistant" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="false" is_refers="false" />
        <token id="3" string="Dist" lemma="Dist" stem="dist" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (NP (NP (ADVP (CC But)) (NP (NP (NNP Assistant)) (NNP Dist))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="But Assistant Dist" type="NP">
          <tokens>
            <token id="1" string="But" />
            <token id="2" string="Assistant" />
            <token id="3" string="Dist" />
          </tokens>
        </chunking>
        <chunking id="2" string="Assistant" type="NP">
          <tokens>
            <token id="2" string="Assistant" />
          </tokens>
        </chunking>
        <chunking id="3" string="But Assistant Dist ." type="NP">
          <tokens>
            <token id="1" string="But" />
            <token id="2" string="Assistant" />
            <token id="3" string="Dist" />
            <token id="4" string="." />
          </tokens>
        </chunking>
        <chunking id="4" string="Assistant Dist" type="NP">
          <tokens>
            <token id="2" string="Assistant" />
            <token id="3" string="Dist" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="3">Dist</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Dist</governor>
          <dependent id="2">Assistant</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">Dist</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Assistant" type="TITLE" score="0.0">
          <tokens>
            <token id="2" string="Assistant" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>Atty. Curt Livesay said the office was already looking into the case at the request of the Long Beach police chief.</content>
      <tokens>
        <token id="1" string="Atty." lemma="Atty." stem="atty." pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="Curt" lemma="Curt" stem="curt" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="Livesay" lemma="Livesay" stem="livesai" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="4" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="office" lemma="office" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="already" lemma="already" stem="alreadi" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="looking" lemma="look" stem="look" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="request" lemma="request" stem="request" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="Long" lemma="Long" stem="long" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="19" string="Beach" lemma="Beach" stem="beach" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="20" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="21" string="chief" lemma="chief" stem="chief" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Atty.) (NNP Curt) (NNP Livesay)) (VP (VBD said) (SBAR (S (NP (DT the) (NN office)) (VP (VBD was) (ADVP (RB already)) (VP (VBG looking) (PP (IN into) (NP (NP (DT the) (NN case)) (PP (IN at) (NP (NP (DT the) (NN request)) (PP (IN of) (NP (DT the) (NNP Long) (NNP Beach) (NN police) (NN chief)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the case at the request of the Long Beach police chief" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="case" />
            <token id="13" string="at" />
            <token id="14" string="the" />
            <token id="15" string="request" />
            <token id="16" string="of" />
            <token id="17" string="the" />
            <token id="18" string="Long" />
            <token id="19" string="Beach" />
            <token id="20" string="police" />
            <token id="21" string="chief" />
          </tokens>
        </chunking>
        <chunking id="2" string="the office" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="office" />
          </tokens>
        </chunking>
        <chunking id="3" string="was already looking into the case at the request of the Long Beach police chief" type="VP">
          <tokens>
            <token id="7" string="was" />
            <token id="8" string="already" />
            <token id="9" string="looking" />
            <token id="10" string="into" />
            <token id="11" string="the" />
            <token id="12" string="case" />
            <token id="13" string="at" />
            <token id="14" string="the" />
            <token id="15" string="request" />
            <token id="16" string="of" />
            <token id="17" string="the" />
            <token id="18" string="Long" />
            <token id="19" string="Beach" />
            <token id="20" string="police" />
            <token id="21" string="chief" />
          </tokens>
        </chunking>
        <chunking id="4" string="the request" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="request" />
          </tokens>
        </chunking>
        <chunking id="5" string="the Long Beach police chief" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="Long" />
            <token id="19" string="Beach" />
            <token id="20" string="police" />
            <token id="21" string="chief" />
          </tokens>
        </chunking>
        <chunking id="6" string="the case" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="case" />
          </tokens>
        </chunking>
        <chunking id="7" string="said the office was already looking into the case at the request of the Long Beach police chief" type="VP">
          <tokens>
            <token id="4" string="said" />
            <token id="5" string="the" />
            <token id="6" string="office" />
            <token id="7" string="was" />
            <token id="8" string="already" />
            <token id="9" string="looking" />
            <token id="10" string="into" />
            <token id="11" string="the" />
            <token id="12" string="case" />
            <token id="13" string="at" />
            <token id="14" string="the" />
            <token id="15" string="request" />
            <token id="16" string="of" />
            <token id="17" string="the" />
            <token id="18" string="Long" />
            <token id="19" string="Beach" />
            <token id="20" string="police" />
            <token id="21" string="chief" />
          </tokens>
        </chunking>
        <chunking id="8" string="looking into the case at the request of the Long Beach police chief" type="VP">
          <tokens>
            <token id="9" string="looking" />
            <token id="10" string="into" />
            <token id="11" string="the" />
            <token id="12" string="case" />
            <token id="13" string="at" />
            <token id="14" string="the" />
            <token id="15" string="request" />
            <token id="16" string="of" />
            <token id="17" string="the" />
            <token id="18" string="Long" />
            <token id="19" string="Beach" />
            <token id="20" string="police" />
            <token id="21" string="chief" />
          </tokens>
        </chunking>
        <chunking id="9" string="the request of the Long Beach police chief" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="request" />
            <token id="16" string="of" />
            <token id="17" string="the" />
            <token id="18" string="Long" />
            <token id="19" string="Beach" />
            <token id="20" string="police" />
            <token id="21" string="chief" />
          </tokens>
        </chunking>
        <chunking id="10" string="Atty. Curt Livesay" type="NP">
          <tokens>
            <token id="1" string="Atty." />
            <token id="2" string="Curt" />
            <token id="3" string="Livesay" />
          </tokens>
        </chunking>
        <chunking id="11" string="the office was already looking into the case at the request of the Long Beach police chief" type="SBAR">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="office" />
            <token id="7" string="was" />
            <token id="8" string="already" />
            <token id="9" string="looking" />
            <token id="10" string="into" />
            <token id="11" string="the" />
            <token id="12" string="case" />
            <token id="13" string="at" />
            <token id="14" string="the" />
            <token id="15" string="request" />
            <token id="16" string="of" />
            <token id="17" string="the" />
            <token id="18" string="Long" />
            <token id="19" string="Beach" />
            <token id="20" string="police" />
            <token id="21" string="chief" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">Livesay</governor>
          <dependent id="1">Atty.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Livesay</governor>
          <dependent id="2">Curt</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">said</governor>
          <dependent id="3">Livesay</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">said</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">office</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">looking</governor>
          <dependent id="6">office</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">looking</governor>
          <dependent id="7">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">looking</governor>
          <dependent id="8">already</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">said</governor>
          <dependent id="9">looking</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">case</governor>
          <dependent id="10">into</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">case</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">looking</governor>
          <dependent id="12">case</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">request</governor>
          <dependent id="13">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">request</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">case</governor>
          <dependent id="15">request</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">chief</governor>
          <dependent id="16">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">chief</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">chief</governor>
          <dependent id="18">Long</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">chief</governor>
          <dependent id="19">Beach</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">chief</governor>
          <dependent id="20">police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">request</governor>
          <dependent id="21">chief</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Curt Livesay" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Curt" />
            <token id="3" string="Livesay" />
          </tokens>
        </entity>
        <entity id="2" string="Long Beach" type="LOCATION" score="0.0">
          <tokens>
            <token id="18" string="Long" />
            <token id="19" string="Beach" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>&amp;quot;We agreed to review the matter to determine whether a criminal investigation is appropriate,&amp;quot; Livesay said, adding that his office hopes to decide by Friday whether a full-fledged investigation is merited.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="We" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="agreed" lemma="agree" stem="agre" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="review" lemma="review" stem="review" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="matter" lemma="matter" stem="matter" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="determine" lemma="determine" stem="determin" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="whether" lemma="whether" stem="whether" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="criminal" lemma="criminal" stem="crimin" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="investigation" lemma="investigation" stem="investig" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="appropriate" lemma="appropriate" stem="appropri" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Livesay" lemma="Livesay" stem="livesai" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="19" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="adding" lemma="add" stem="ad" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="office" lemma="office" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="25" string="hopes" lemma="hope" stem="hope" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="decide" lemma="decide" stem="decid" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="Friday" lemma="Friday" stem="fridai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="30" string="whether" lemma="whether" stem="whether" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="full-fledged" lemma="full-fledged" stem="full-fledg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="investigation" lemma="investigation" stem="investig" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="merited" lemma="merit" stem="merit" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP We)) (VP (VBD agreed) (S (VP (TO to) (VP (VB review) (NP (DT the) (NN matter) (S (VP (TO to) (VP (VB determine) (SBAR (IN whether) (S (NP (DT a) (JJ criminal) (NN investigation)) (VP (VBZ is) (ADJP (JJ appropriate)))))))))))))) (, ,) ('' '') (NP (NNP Livesay)) (VP (VBD said) (, ,) (S (VP (VBG adding) (SBAR (IN that) (S (NP (PRP$ his) (NN office)) (VP (VBZ hopes) (S (VP (TO to) (VP (VB decide) (PP (IN by) (NP (NNP Friday))) (SBAR (IN whether) (S (NP (DT a) (JJ full-fledged) (NN investigation)) (VP (VBZ is) (VP (VBN merited)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="is appropriate" type="VP">
          <tokens>
            <token id="14" string="is" />
            <token id="15" string="appropriate" />
          </tokens>
        </chunking>
        <chunking id="2" string="whether a full-fledged investigation is merited" type="SBAR">
          <tokens>
            <token id="30" string="whether" />
            <token id="31" string="a" />
            <token id="32" string="full-fledged" />
            <token id="33" string="investigation" />
            <token id="34" string="is" />
            <token id="35" string="merited" />
          </tokens>
        </chunking>
        <chunking id="3" string="appropriate" type="ADJP">
          <tokens>
            <token id="15" string="appropriate" />
          </tokens>
        </chunking>
        <chunking id="4" string="that his office hopes to decide by Friday whether a full-fledged investigation is merited" type="SBAR">
          <tokens>
            <token id="22" string="that" />
            <token id="23" string="his" />
            <token id="24" string="office" />
            <token id="25" string="hopes" />
            <token id="26" string="to" />
            <token id="27" string="decide" />
            <token id="28" string="by" />
            <token id="29" string="Friday" />
            <token id="30" string="whether" />
            <token id="31" string="a" />
            <token id="32" string="full-fledged" />
            <token id="33" string="investigation" />
            <token id="34" string="is" />
            <token id="35" string="merited" />
          </tokens>
        </chunking>
        <chunking id="5" string="the matter to determine whether a criminal investigation is appropriate" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="matter" />
            <token id="8" string="to" />
            <token id="9" string="determine" />
            <token id="10" string="whether" />
            <token id="11" string="a" />
            <token id="12" string="criminal" />
            <token id="13" string="investigation" />
            <token id="14" string="is" />
            <token id="15" string="appropriate" />
          </tokens>
        </chunking>
        <chunking id="6" string="determine whether a criminal investigation is appropriate" type="VP">
          <tokens>
            <token id="9" string="determine" />
            <token id="10" string="whether" />
            <token id="11" string="a" />
            <token id="12" string="criminal" />
            <token id="13" string="investigation" />
            <token id="14" string="is" />
            <token id="15" string="appropriate" />
          </tokens>
        </chunking>
        <chunking id="7" string="his office" type="NP">
          <tokens>
            <token id="23" string="his" />
            <token id="24" string="office" />
          </tokens>
        </chunking>
        <chunking id="8" string="to decide by Friday whether a full-fledged investigation is merited" type="VP">
          <tokens>
            <token id="26" string="to" />
            <token id="27" string="decide" />
            <token id="28" string="by" />
            <token id="29" string="Friday" />
            <token id="30" string="whether" />
            <token id="31" string="a" />
            <token id="32" string="full-fledged" />
            <token id="33" string="investigation" />
            <token id="34" string="is" />
            <token id="35" string="merited" />
          </tokens>
        </chunking>
        <chunking id="9" string="a criminal investigation" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="criminal" />
            <token id="13" string="investigation" />
          </tokens>
        </chunking>
        <chunking id="10" string="Livesay" type="NP">
          <tokens>
            <token id="18" string="Livesay" />
          </tokens>
        </chunking>
        <chunking id="11" string="We" type="NP">
          <tokens>
            <token id="2" string="We" />
          </tokens>
        </chunking>
        <chunking id="12" string="whether a criminal investigation is appropriate" type="SBAR">
          <tokens>
            <token id="10" string="whether" />
            <token id="11" string="a" />
            <token id="12" string="criminal" />
            <token id="13" string="investigation" />
            <token id="14" string="is" />
            <token id="15" string="appropriate" />
          </tokens>
        </chunking>
        <chunking id="13" string="decide by Friday whether a full-fledged investigation is merited" type="VP">
          <tokens>
            <token id="27" string="decide" />
            <token id="28" string="by" />
            <token id="29" string="Friday" />
            <token id="30" string="whether" />
            <token id="31" string="a" />
            <token id="32" string="full-fledged" />
            <token id="33" string="investigation" />
            <token id="34" string="is" />
            <token id="35" string="merited" />
          </tokens>
        </chunking>
        <chunking id="14" string="a full-fledged investigation" type="NP">
          <tokens>
            <token id="31" string="a" />
            <token id="32" string="full-fledged" />
            <token id="33" string="investigation" />
          </tokens>
        </chunking>
        <chunking id="15" string="to determine whether a criminal investigation is appropriate" type="VP">
          <tokens>
            <token id="8" string="to" />
            <token id="9" string="determine" />
            <token id="10" string="whether" />
            <token id="11" string="a" />
            <token id="12" string="criminal" />
            <token id="13" string="investigation" />
            <token id="14" string="is" />
            <token id="15" string="appropriate" />
          </tokens>
        </chunking>
        <chunking id="16" string="agreed to review the matter to determine whether a criminal investigation is appropriate" type="VP">
          <tokens>
            <token id="3" string="agreed" />
            <token id="4" string="to" />
            <token id="5" string="review" />
            <token id="6" string="the" />
            <token id="7" string="matter" />
            <token id="8" string="to" />
            <token id="9" string="determine" />
            <token id="10" string="whether" />
            <token id="11" string="a" />
            <token id="12" string="criminal" />
            <token id="13" string="investigation" />
            <token id="14" string="is" />
            <token id="15" string="appropriate" />
          </tokens>
        </chunking>
        <chunking id="17" string="Friday" type="NP">
          <tokens>
            <token id="29" string="Friday" />
          </tokens>
        </chunking>
        <chunking id="18" string="said , adding that his office hopes to decide by Friday whether a full-fledged investigation is merited" type="VP">
          <tokens>
            <token id="19" string="said" />
            <token id="20" string="," />
            <token id="21" string="adding" />
            <token id="22" string="that" />
            <token id="23" string="his" />
            <token id="24" string="office" />
            <token id="25" string="hopes" />
            <token id="26" string="to" />
            <token id="27" string="decide" />
            <token id="28" string="by" />
            <token id="29" string="Friday" />
            <token id="30" string="whether" />
            <token id="31" string="a" />
            <token id="32" string="full-fledged" />
            <token id="33" string="investigation" />
            <token id="34" string="is" />
            <token id="35" string="merited" />
          </tokens>
        </chunking>
        <chunking id="19" string="is merited" type="VP">
          <tokens>
            <token id="34" string="is" />
            <token id="35" string="merited" />
          </tokens>
        </chunking>
        <chunking id="20" string="review the matter to determine whether a criminal investigation is appropriate" type="VP">
          <tokens>
            <token id="5" string="review" />
            <token id="6" string="the" />
            <token id="7" string="matter" />
            <token id="8" string="to" />
            <token id="9" string="determine" />
            <token id="10" string="whether" />
            <token id="11" string="a" />
            <token id="12" string="criminal" />
            <token id="13" string="investigation" />
            <token id="14" string="is" />
            <token id="15" string="appropriate" />
          </tokens>
        </chunking>
        <chunking id="21" string="merited" type="VP">
          <tokens>
            <token id="35" string="merited" />
          </tokens>
        </chunking>
        <chunking id="22" string="hopes to decide by Friday whether a full-fledged investigation is merited" type="VP">
          <tokens>
            <token id="25" string="hopes" />
            <token id="26" string="to" />
            <token id="27" string="decide" />
            <token id="28" string="by" />
            <token id="29" string="Friday" />
            <token id="30" string="whether" />
            <token id="31" string="a" />
            <token id="32" string="full-fledged" />
            <token id="33" string="investigation" />
            <token id="34" string="is" />
            <token id="35" string="merited" />
          </tokens>
        </chunking>
        <chunking id="23" string="to review the matter to determine whether a criminal investigation is appropriate" type="VP">
          <tokens>
            <token id="4" string="to" />
            <token id="5" string="review" />
            <token id="6" string="the" />
            <token id="7" string="matter" />
            <token id="8" string="to" />
            <token id="9" string="determine" />
            <token id="10" string="whether" />
            <token id="11" string="a" />
            <token id="12" string="criminal" />
            <token id="13" string="investigation" />
            <token id="14" string="is" />
            <token id="15" string="appropriate" />
          </tokens>
        </chunking>
        <chunking id="24" string="adding that his office hopes to decide by Friday whether a full-fledged investigation is merited" type="VP">
          <tokens>
            <token id="21" string="adding" />
            <token id="22" string="that" />
            <token id="23" string="his" />
            <token id="24" string="office" />
            <token id="25" string="hopes" />
            <token id="26" string="to" />
            <token id="27" string="decide" />
            <token id="28" string="by" />
            <token id="29" string="Friday" />
            <token id="30" string="whether" />
            <token id="31" string="a" />
            <token id="32" string="full-fledged" />
            <token id="33" string="investigation" />
            <token id="34" string="is" />
            <token id="35" string="merited" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">agreed</governor>
          <dependent id="2">We</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="19">said</governor>
          <dependent id="3">agreed</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">review</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">agreed</governor>
          <dependent id="5">review</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">matter</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">review</governor>
          <dependent id="7">matter</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">determine</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="7">matter</governor>
          <dependent id="9">determine</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">appropriate</governor>
          <dependent id="10">whether</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">investigation</governor>
          <dependent id="11">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">investigation</governor>
          <dependent id="12">criminal</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">appropriate</governor>
          <dependent id="13">investigation</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="15">appropriate</governor>
          <dependent id="14">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="9">determine</governor>
          <dependent id="15">appropriate</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">said</governor>
          <dependent id="18">Livesay</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="19">said</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="19">said</governor>
          <dependent id="21">adding</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="25">hopes</governor>
          <dependent id="22">that</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="24">office</governor>
          <dependent id="23">his</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">hopes</governor>
          <dependent id="24">office</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="21">adding</governor>
          <dependent id="25">hopes</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="27">decide</governor>
          <dependent id="26">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="25">hopes</governor>
          <dependent id="27">decide</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">Friday</governor>
          <dependent id="28">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">decide</governor>
          <dependent id="29">Friday</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="35">merited</governor>
          <dependent id="30">whether</dependent>
        </dependency>
        <dependency type="det">
          <governor id="33">investigation</governor>
          <dependent id="31">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="33">investigation</governor>
          <dependent id="32">full-fledged</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="35">merited</governor>
          <dependent id="33">investigation</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="35">merited</governor>
          <dependent id="34">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="27">decide</governor>
          <dependent id="35">merited</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Friday" type="DATE" score="0.0">
          <tokens>
            <token id="29" string="Friday" />
          </tokens>
        </entity>
        <entity id="2" string="Livesay" type="PERSON" score="0.0">
          <tokens>
            <token id="18" string="Livesay" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="false">
      <content>If such an inquiry reveals that brutality was involved, either misdemeanor or felony charges could be filed against the officer, he said.</content>
      <tokens>
        <token id="1" string="If" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="such" lemma="such" stem="such" pos="PDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="inquiry" lemma="inquiry" stem="inquiri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="reveals" lemma="reveal" stem="reveal" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="brutality" lemma="brutality" stem="brutal" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="involved" lemma="involve" stem="involv" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="either" lemma="either" stem="either" pos="CC" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="misdemeanor" lemma="misdemeanor" stem="misdemeanor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="felony" lemma="felony" stem="feloni" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="charges" lemma="charge" stem="charg" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="filed" lemma="file" stem="file" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="officer" lemma="officer" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN If) (S (NP (PDT such) (DT an) (NN inquiry)) (VP (VBZ reveals) (SBAR (IN that) (S (S (NP (NN brutality)) (VP (VBD was) (VP (VBN involved)))) (, ,) (CC either) (S (NP (NN misdemeanor) (CC or) (NN felony) (NNS charges)) (VP (MD could) (VP (VB be) (VP (VBN filed) (PP (IN against) (NP (DT the) (NN officer)))))))))))) (, ,) (NP (PRP he)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="that brutality was involved , either misdemeanor or felony charges could be filed against the officer" type="SBAR">
          <tokens>
            <token id="6" string="that" />
            <token id="7" string="brutality" />
            <token id="8" string="was" />
            <token id="9" string="involved" />
            <token id="10" string="," />
            <token id="11" string="either" />
            <token id="12" string="misdemeanor" />
            <token id="13" string="or" />
            <token id="14" string="felony" />
            <token id="15" string="charges" />
            <token id="16" string="could" />
            <token id="17" string="be" />
            <token id="18" string="filed" />
            <token id="19" string="against" />
            <token id="20" string="the" />
            <token id="21" string="officer" />
          </tokens>
        </chunking>
        <chunking id="2" string="be filed against the officer" type="VP">
          <tokens>
            <token id="17" string="be" />
            <token id="18" string="filed" />
            <token id="19" string="against" />
            <token id="20" string="the" />
            <token id="21" string="officer" />
          </tokens>
        </chunking>
        <chunking id="3" string="such an inquiry" type="NP">
          <tokens>
            <token id="2" string="such" />
            <token id="3" string="an" />
            <token id="4" string="inquiry" />
          </tokens>
        </chunking>
        <chunking id="4" string="reveals that brutality was involved , either misdemeanor or felony charges could be filed against the officer" type="VP">
          <tokens>
            <token id="5" string="reveals" />
            <token id="6" string="that" />
            <token id="7" string="brutality" />
            <token id="8" string="was" />
            <token id="9" string="involved" />
            <token id="10" string="," />
            <token id="11" string="either" />
            <token id="12" string="misdemeanor" />
            <token id="13" string="or" />
            <token id="14" string="felony" />
            <token id="15" string="charges" />
            <token id="16" string="could" />
            <token id="17" string="be" />
            <token id="18" string="filed" />
            <token id="19" string="against" />
            <token id="20" string="the" />
            <token id="21" string="officer" />
          </tokens>
        </chunking>
        <chunking id="5" string="was involved" type="VP">
          <tokens>
            <token id="8" string="was" />
            <token id="9" string="involved" />
          </tokens>
        </chunking>
        <chunking id="6" string="could be filed against the officer" type="VP">
          <tokens>
            <token id="16" string="could" />
            <token id="17" string="be" />
            <token id="18" string="filed" />
            <token id="19" string="against" />
            <token id="20" string="the" />
            <token id="21" string="officer" />
          </tokens>
        </chunking>
        <chunking id="7" string="filed against the officer" type="VP">
          <tokens>
            <token id="18" string="filed" />
            <token id="19" string="against" />
            <token id="20" string="the" />
            <token id="21" string="officer" />
          </tokens>
        </chunking>
        <chunking id="8" string="the officer" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="officer" />
          </tokens>
        </chunking>
        <chunking id="9" string="If such an inquiry reveals that brutality was involved , either misdemeanor or felony charges could be filed against the officer" type="SBAR">
          <tokens>
            <token id="1" string="If" />
            <token id="2" string="such" />
            <token id="3" string="an" />
            <token id="4" string="inquiry" />
            <token id="5" string="reveals" />
            <token id="6" string="that" />
            <token id="7" string="brutality" />
            <token id="8" string="was" />
            <token id="9" string="involved" />
            <token id="10" string="," />
            <token id="11" string="either" />
            <token id="12" string="misdemeanor" />
            <token id="13" string="or" />
            <token id="14" string="felony" />
            <token id="15" string="charges" />
            <token id="16" string="could" />
            <token id="17" string="be" />
            <token id="18" string="filed" />
            <token id="19" string="against" />
            <token id="20" string="the" />
            <token id="21" string="officer" />
          </tokens>
        </chunking>
        <chunking id="10" string="involved" type="VP">
          <tokens>
            <token id="9" string="involved" />
          </tokens>
        </chunking>
        <chunking id="11" string="misdemeanor or felony charges" type="NP">
          <tokens>
            <token id="12" string="misdemeanor" />
            <token id="13" string="or" />
            <token id="14" string="felony" />
            <token id="15" string="charges" />
          </tokens>
        </chunking>
        <chunking id="12" string="he" type="NP">
          <tokens>
            <token id="23" string="he" />
          </tokens>
        </chunking>
        <chunking id="13" string="said" type="VP">
          <tokens>
            <token id="24" string="said" />
          </tokens>
        </chunking>
        <chunking id="14" string="brutality" type="NP">
          <tokens>
            <token id="7" string="brutality" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="5">reveals</governor>
          <dependent id="1">If</dependent>
        </dependency>
        <dependency type="det:predet">
          <governor id="4">inquiry</governor>
          <dependent id="2">such</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">inquiry</governor>
          <dependent id="3">an</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">reveals</governor>
          <dependent id="4">inquiry</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="24">said</governor>
          <dependent id="5">reveals</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">involved</governor>
          <dependent id="6">that</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="9">involved</governor>
          <dependent id="7">brutality</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="9">involved</governor>
          <dependent id="8">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">reveals</governor>
          <dependent id="9">involved</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="9">involved</governor>
          <dependent id="11">either</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">charges</governor>
          <dependent id="12">misdemeanor</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="12">misdemeanor</governor>
          <dependent id="13">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">misdemeanor</governor>
          <dependent id="14">felony</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="18">filed</governor>
          <dependent id="15">charges</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="18">filed</governor>
          <dependent id="16">could</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="18">filed</governor>
          <dependent id="17">be</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">involved</governor>
          <dependent id="18">filed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">officer</governor>
          <dependent id="19">against</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">officer</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">filed</governor>
          <dependent id="21">officer</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">said</governor>
          <dependent id="23">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="24">said</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>The FBI has also been called in to determine whether the civil rights of the man who was arrested -- Don Jackson, a sergeant on administrative leave from the Hawthorne Police Department -- were violated during his altercation with two Long Beach officers on Pacific Coast Highway, spokesman Fred Reagan said.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="FBI" lemma="FBI" stem="fbi" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="3" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="called" lemma="call" stem="call" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="determine" lemma="determine" stem="determin" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="whether" lemma="whether" stem="whether" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="civil" lemma="civil" stem="civil" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="rights" lemma="rights" stem="right" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="man" lemma="man" stem="man" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="arrested" lemma="arrest" stem="arrest" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="Don" lemma="Don" stem="don" pos="NNP" type="Word" isStopWord="true" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="22" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="24" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="25" string="sergeant" lemma="sergeant" stem="sergeant" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="26" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="27" string="administrative" lemma="administrative" stem="administr" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="28" string="leave" lemma="leave" stem="leav" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="29" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="30" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="31" string="Hawthorne" lemma="Hawthorne" stem="hawthorn" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="32" string="Police" lemma="Police" stem="polic" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="33" string="Department" lemma="Department" stem="depart" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="34" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="35" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="violated" lemma="violate" stem="violat" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="during" lemma="during" stem="dure" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="39" string="altercation" lemma="altercation" stem="alterc" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="40" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="42" string="Long" lemma="long" stem="long" pos="JJ" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="43" string="Beach" lemma="Beach" stem="beach" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="44" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="45" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="46" string="Pacific" lemma="Pacific" stem="pacif" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="47" string="Coast" lemma="Coast" stem="coast" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="48" string="Highway" lemma="Highway" stem="highwai" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="49" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="50" string="spokesman" lemma="spokesman" stem="spokesman" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="51" string="Fred" lemma="Fred" stem="fred" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="52" string="Reagan" lemma="Reagan" stem="reagan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="53" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="54" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (DT The) (NNP FBI)) (VP (VBZ has) (ADVP (RB also)) (VP (VBN been) (VP (VBN called) (PP (IN in)) (S (VP (TO to) (VP (VB determine) (SBAR (IN whether) (S (NP (NP (DT the) (JJ civil) (NNS rights)) (PP (IN of) (NP (NP (DT the) (NN man)) (SBAR (WHNP (WP who)) (S (VP (VBD was) (VP (VBN arrested))))) (PRN (: --) (NP (NP (NNP Don) (NNP Jackson)) (, ,) (NP (NP (DT a) (NN sergeant)) (PP (IN on) (NP (NP (JJ administrative) (NN leave)) (PP (IN from) (NP (DT the) (NNP Hawthorne) (NNP Police) (NNP Department))))))) (: --))))) (VP (VBD were) (VP (VBN violated) (PP (IN during) (NP (PRP$ his) (NN altercation))) (PP (IN with) (NP (NP (CD two) (JJ Long) (NNP Beach) (NNS officers)) (PP (IN on) (NP (NNP Pacific) (NNP Coast) (NNP Highway)))))))))))))))) (, ,) (NP (NN spokesman) (NNP Fred) (NNP Reagan)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="two Long Beach officers" type="NP">
          <tokens>
            <token id="41" string="two" />
            <token id="42" string="Long" />
            <token id="43" string="Beach" />
            <token id="44" string="officers" />
          </tokens>
        </chunking>
        <chunking id="2" string="determine whether the civil rights of the man who was arrested -- Don Jackson , a sergeant on administrative leave from the Hawthorne Police Department -- were violated during his altercation with two Long Beach officers on Pacific Coast Highway" type="VP">
          <tokens>
            <token id="9" string="determine" />
            <token id="10" string="whether" />
            <token id="11" string="the" />
            <token id="12" string="civil" />
            <token id="13" string="rights" />
            <token id="14" string="of" />
            <token id="15" string="the" />
            <token id="16" string="man" />
            <token id="17" string="who" />
            <token id="18" string="was" />
            <token id="19" string="arrested" />
            <token id="20" string="--" />
            <token id="21" string="Don" />
            <token id="22" string="Jackson" />
            <token id="23" string="," />
            <token id="24" string="a" />
            <token id="25" string="sergeant" />
            <token id="26" string="on" />
            <token id="27" string="administrative" />
            <token id="28" string="leave" />
            <token id="29" string="from" />
            <token id="30" string="the" />
            <token id="31" string="Hawthorne" />
            <token id="32" string="Police" />
            <token id="33" string="Department" />
            <token id="34" string="--" />
            <token id="35" string="were" />
            <token id="36" string="violated" />
            <token id="37" string="during" />
            <token id="38" string="his" />
            <token id="39" string="altercation" />
            <token id="40" string="with" />
            <token id="41" string="two" />
            <token id="42" string="Long" />
            <token id="43" string="Beach" />
            <token id="44" string="officers" />
            <token id="45" string="on" />
            <token id="46" string="Pacific" />
            <token id="47" string="Coast" />
            <token id="48" string="Highway" />
          </tokens>
        </chunking>
        <chunking id="3" string="administrative leave from the Hawthorne Police Department" type="NP">
          <tokens>
            <token id="27" string="administrative" />
            <token id="28" string="leave" />
            <token id="29" string="from" />
            <token id="30" string="the" />
            <token id="31" string="Hawthorne" />
            <token id="32" string="Police" />
            <token id="33" string="Department" />
          </tokens>
        </chunking>
        <chunking id="4" string="been called in to determine whether the civil rights of the man who was arrested -- Don Jackson , a sergeant on administrative leave from the Hawthorne Police Department -- were violated during his altercation with two Long Beach officers on Pacific Coast Highway" type="VP">
          <tokens>
            <token id="5" string="been" />
            <token id="6" string="called" />
            <token id="7" string="in" />
            <token id="8" string="to" />
            <token id="9" string="determine" />
            <token id="10" string="whether" />
            <token id="11" string="the" />
            <token id="12" string="civil" />
            <token id="13" string="rights" />
            <token id="14" string="of" />
            <token id="15" string="the" />
            <token id="16" string="man" />
            <token id="17" string="who" />
            <token id="18" string="was" />
            <token id="19" string="arrested" />
            <token id="20" string="--" />
            <token id="21" string="Don" />
            <token id="22" string="Jackson" />
            <token id="23" string="," />
            <token id="24" string="a" />
            <token id="25" string="sergeant" />
            <token id="26" string="on" />
            <token id="27" string="administrative" />
            <token id="28" string="leave" />
            <token id="29" string="from" />
            <token id="30" string="the" />
            <token id="31" string="Hawthorne" />
            <token id="32" string="Police" />
            <token id="33" string="Department" />
            <token id="34" string="--" />
            <token id="35" string="were" />
            <token id="36" string="violated" />
            <token id="37" string="during" />
            <token id="38" string="his" />
            <token id="39" string="altercation" />
            <token id="40" string="with" />
            <token id="41" string="two" />
            <token id="42" string="Long" />
            <token id="43" string="Beach" />
            <token id="44" string="officers" />
            <token id="45" string="on" />
            <token id="46" string="Pacific" />
            <token id="47" string="Coast" />
            <token id="48" string="Highway" />
          </tokens>
        </chunking>
        <chunking id="5" string="Don Jackson" type="NP">
          <tokens>
            <token id="21" string="Don" />
            <token id="22" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="6" string="two Long Beach officers on Pacific Coast Highway" type="NP">
          <tokens>
            <token id="41" string="two" />
            <token id="42" string="Long" />
            <token id="43" string="Beach" />
            <token id="44" string="officers" />
            <token id="45" string="on" />
            <token id="46" string="Pacific" />
            <token id="47" string="Coast" />
            <token id="48" string="Highway" />
          </tokens>
        </chunking>
        <chunking id="7" string="the man who was arrested -- Don Jackson , a sergeant on administrative leave from the Hawthorne Police Department --" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="man" />
            <token id="17" string="who" />
            <token id="18" string="was" />
            <token id="19" string="arrested" />
            <token id="20" string="--" />
            <token id="21" string="Don" />
            <token id="22" string="Jackson" />
            <token id="23" string="," />
            <token id="24" string="a" />
            <token id="25" string="sergeant" />
            <token id="26" string="on" />
            <token id="27" string="administrative" />
            <token id="28" string="leave" />
            <token id="29" string="from" />
            <token id="30" string="the" />
            <token id="31" string="Hawthorne" />
            <token id="32" string="Police" />
            <token id="33" string="Department" />
            <token id="34" string="--" />
          </tokens>
        </chunking>
        <chunking id="8" string="who was arrested" type="SBAR">
          <tokens>
            <token id="17" string="who" />
            <token id="18" string="was" />
            <token id="19" string="arrested" />
          </tokens>
        </chunking>
        <chunking id="9" string="the Hawthorne Police Department" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="Hawthorne" />
            <token id="32" string="Police" />
            <token id="33" string="Department" />
          </tokens>
        </chunking>
        <chunking id="10" string="Don Jackson , a sergeant on administrative leave from the Hawthorne Police Department" type="NP">
          <tokens>
            <token id="21" string="Don" />
            <token id="22" string="Jackson" />
            <token id="23" string="," />
            <token id="24" string="a" />
            <token id="25" string="sergeant" />
            <token id="26" string="on" />
            <token id="27" string="administrative" />
            <token id="28" string="leave" />
            <token id="29" string="from" />
            <token id="30" string="the" />
            <token id="31" string="Hawthorne" />
            <token id="32" string="Police" />
            <token id="33" string="Department" />
          </tokens>
        </chunking>
        <chunking id="11" string="the civil rights" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="civil" />
            <token id="13" string="rights" />
          </tokens>
        </chunking>
        <chunking id="12" string="the man" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="man" />
          </tokens>
        </chunking>
        <chunking id="13" string="whether the civil rights of the man who was arrested -- Don Jackson , a sergeant on administrative leave from the Hawthorne Police Department -- were violated during his altercation with two Long Beach officers on Pacific Coast Highway" type="SBAR">
          <tokens>
            <token id="10" string="whether" />
            <token id="11" string="the" />
            <token id="12" string="civil" />
            <token id="13" string="rights" />
            <token id="14" string="of" />
            <token id="15" string="the" />
            <token id="16" string="man" />
            <token id="17" string="who" />
            <token id="18" string="was" />
            <token id="19" string="arrested" />
            <token id="20" string="--" />
            <token id="21" string="Don" />
            <token id="22" string="Jackson" />
            <token id="23" string="," />
            <token id="24" string="a" />
            <token id="25" string="sergeant" />
            <token id="26" string="on" />
            <token id="27" string="administrative" />
            <token id="28" string="leave" />
            <token id="29" string="from" />
            <token id="30" string="the" />
            <token id="31" string="Hawthorne" />
            <token id="32" string="Police" />
            <token id="33" string="Department" />
            <token id="34" string="--" />
            <token id="35" string="were" />
            <token id="36" string="violated" />
            <token id="37" string="during" />
            <token id="38" string="his" />
            <token id="39" string="altercation" />
            <token id="40" string="with" />
            <token id="41" string="two" />
            <token id="42" string="Long" />
            <token id="43" string="Beach" />
            <token id="44" string="officers" />
            <token id="45" string="on" />
            <token id="46" string="Pacific" />
            <token id="47" string="Coast" />
            <token id="48" string="Highway" />
          </tokens>
        </chunking>
        <chunking id="14" string="arrested" type="VP">
          <tokens>
            <token id="19" string="arrested" />
          </tokens>
        </chunking>
        <chunking id="15" string="a sergeant" type="NP">
          <tokens>
            <token id="24" string="a" />
            <token id="25" string="sergeant" />
          </tokens>
        </chunking>
        <chunking id="16" string="spokesman Fred Reagan" type="NP">
          <tokens>
            <token id="50" string="spokesman" />
            <token id="51" string="Fred" />
            <token id="52" string="Reagan" />
          </tokens>
        </chunking>
        <chunking id="17" string="administrative leave" type="NP">
          <tokens>
            <token id="27" string="administrative" />
            <token id="28" string="leave" />
          </tokens>
        </chunking>
        <chunking id="18" string="called in to determine whether the civil rights of the man who was arrested -- Don Jackson , a sergeant on administrative leave from the Hawthorne Police Department -- were violated during his altercation with two Long Beach officers on Pacific Coast Highway" type="VP">
          <tokens>
            <token id="6" string="called" />
            <token id="7" string="in" />
            <token id="8" string="to" />
            <token id="9" string="determine" />
            <token id="10" string="whether" />
            <token id="11" string="the" />
            <token id="12" string="civil" />
            <token id="13" string="rights" />
            <token id="14" string="of" />
            <token id="15" string="the" />
            <token id="16" string="man" />
            <token id="17" string="who" />
            <token id="18" string="was" />
            <token id="19" string="arrested" />
            <token id="20" string="--" />
            <token id="21" string="Don" />
            <token id="22" string="Jackson" />
            <token id="23" string="," />
            <token id="24" string="a" />
            <token id="25" string="sergeant" />
            <token id="26" string="on" />
            <token id="27" string="administrative" />
            <token id="28" string="leave" />
            <token id="29" string="from" />
            <token id="30" string="the" />
            <token id="31" string="Hawthorne" />
            <token id="32" string="Police" />
            <token id="33" string="Department" />
            <token id="34" string="--" />
            <token id="35" string="were" />
            <token id="36" string="violated" />
            <token id="37" string="during" />
            <token id="38" string="his" />
            <token id="39" string="altercation" />
            <token id="40" string="with" />
            <token id="41" string="two" />
            <token id="42" string="Long" />
            <token id="43" string="Beach" />
            <token id="44" string="officers" />
            <token id="45" string="on" />
            <token id="46" string="Pacific" />
            <token id="47" string="Coast" />
            <token id="48" string="Highway" />
          </tokens>
        </chunking>
        <chunking id="19" string="to determine whether the civil rights of the man who was arrested -- Don Jackson , a sergeant on administrative leave from the Hawthorne Police Department -- were violated during his altercation with two Long Beach officers on Pacific Coast Highway" type="VP">
          <tokens>
            <token id="8" string="to" />
            <token id="9" string="determine" />
            <token id="10" string="whether" />
            <token id="11" string="the" />
            <token id="12" string="civil" />
            <token id="13" string="rights" />
            <token id="14" string="of" />
            <token id="15" string="the" />
            <token id="16" string="man" />
            <token id="17" string="who" />
            <token id="18" string="was" />
            <token id="19" string="arrested" />
            <token id="20" string="--" />
            <token id="21" string="Don" />
            <token id="22" string="Jackson" />
            <token id="23" string="," />
            <token id="24" string="a" />
            <token id="25" string="sergeant" />
            <token id="26" string="on" />
            <token id="27" string="administrative" />
            <token id="28" string="leave" />
            <token id="29" string="from" />
            <token id="30" string="the" />
            <token id="31" string="Hawthorne" />
            <token id="32" string="Police" />
            <token id="33" string="Department" />
            <token id="34" string="--" />
            <token id="35" string="were" />
            <token id="36" string="violated" />
            <token id="37" string="during" />
            <token id="38" string="his" />
            <token id="39" string="altercation" />
            <token id="40" string="with" />
            <token id="41" string="two" />
            <token id="42" string="Long" />
            <token id="43" string="Beach" />
            <token id="44" string="officers" />
            <token id="45" string="on" />
            <token id="46" string="Pacific" />
            <token id="47" string="Coast" />
            <token id="48" string="Highway" />
          </tokens>
        </chunking>
        <chunking id="20" string="has also been called in to determine whether the civil rights of the man who was arrested -- Don Jackson , a sergeant on administrative leave from the Hawthorne Police Department -- were violated during his altercation with two Long Beach officers on Pacific Coast Highway" type="VP">
          <tokens>
            <token id="3" string="has" />
            <token id="4" string="also" />
            <token id="5" string="been" />
            <token id="6" string="called" />
            <token id="7" string="in" />
            <token id="8" string="to" />
            <token id="9" string="determine" />
            <token id="10" string="whether" />
            <token id="11" string="the" />
            <token id="12" string="civil" />
            <token id="13" string="rights" />
            <token id="14" string="of" />
            <token id="15" string="the" />
            <token id="16" string="man" />
            <token id="17" string="who" />
            <token id="18" string="was" />
            <token id="19" string="arrested" />
            <token id="20" string="--" />
            <token id="21" string="Don" />
            <token id="22" string="Jackson" />
            <token id="23" string="," />
            <token id="24" string="a" />
            <token id="25" string="sergeant" />
            <token id="26" string="on" />
            <token id="27" string="administrative" />
            <token id="28" string="leave" />
            <token id="29" string="from" />
            <token id="30" string="the" />
            <token id="31" string="Hawthorne" />
            <token id="32" string="Police" />
            <token id="33" string="Department" />
            <token id="34" string="--" />
            <token id="35" string="were" />
            <token id="36" string="violated" />
            <token id="37" string="during" />
            <token id="38" string="his" />
            <token id="39" string="altercation" />
            <token id="40" string="with" />
            <token id="41" string="two" />
            <token id="42" string="Long" />
            <token id="43" string="Beach" />
            <token id="44" string="officers" />
            <token id="45" string="on" />
            <token id="46" string="Pacific" />
            <token id="47" string="Coast" />
            <token id="48" string="Highway" />
          </tokens>
        </chunking>
        <chunking id="21" string="violated during his altercation with two Long Beach officers on Pacific Coast Highway" type="VP">
          <tokens>
            <token id="36" string="violated" />
            <token id="37" string="during" />
            <token id="38" string="his" />
            <token id="39" string="altercation" />
            <token id="40" string="with" />
            <token id="41" string="two" />
            <token id="42" string="Long" />
            <token id="43" string="Beach" />
            <token id="44" string="officers" />
            <token id="45" string="on" />
            <token id="46" string="Pacific" />
            <token id="47" string="Coast" />
            <token id="48" string="Highway" />
          </tokens>
        </chunking>
        <chunking id="22" string="the civil rights of the man who was arrested -- Don Jackson , a sergeant on administrative leave from the Hawthorne Police Department --" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="civil" />
            <token id="13" string="rights" />
            <token id="14" string="of" />
            <token id="15" string="the" />
            <token id="16" string="man" />
            <token id="17" string="who" />
            <token id="18" string="was" />
            <token id="19" string="arrested" />
            <token id="20" string="--" />
            <token id="21" string="Don" />
            <token id="22" string="Jackson" />
            <token id="23" string="," />
            <token id="24" string="a" />
            <token id="25" string="sergeant" />
            <token id="26" string="on" />
            <token id="27" string="administrative" />
            <token id="28" string="leave" />
            <token id="29" string="from" />
            <token id="30" string="the" />
            <token id="31" string="Hawthorne" />
            <token id="32" string="Police" />
            <token id="33" string="Department" />
            <token id="34" string="--" />
          </tokens>
        </chunking>
        <chunking id="23" string="his altercation" type="NP">
          <tokens>
            <token id="38" string="his" />
            <token id="39" string="altercation" />
          </tokens>
        </chunking>
        <chunking id="24" string="a sergeant on administrative leave from the Hawthorne Police Department" type="NP">
          <tokens>
            <token id="24" string="a" />
            <token id="25" string="sergeant" />
            <token id="26" string="on" />
            <token id="27" string="administrative" />
            <token id="28" string="leave" />
            <token id="29" string="from" />
            <token id="30" string="the" />
            <token id="31" string="Hawthorne" />
            <token id="32" string="Police" />
            <token id="33" string="Department" />
          </tokens>
        </chunking>
        <chunking id="25" string="was arrested" type="VP">
          <tokens>
            <token id="18" string="was" />
            <token id="19" string="arrested" />
          </tokens>
        </chunking>
        <chunking id="26" string="were violated during his altercation with two Long Beach officers on Pacific Coast Highway" type="VP">
          <tokens>
            <token id="35" string="were" />
            <token id="36" string="violated" />
            <token id="37" string="during" />
            <token id="38" string="his" />
            <token id="39" string="altercation" />
            <token id="40" string="with" />
            <token id="41" string="two" />
            <token id="42" string="Long" />
            <token id="43" string="Beach" />
            <token id="44" string="officers" />
            <token id="45" string="on" />
            <token id="46" string="Pacific" />
            <token id="47" string="Coast" />
            <token id="48" string="Highway" />
          </tokens>
        </chunking>
        <chunking id="27" string="Pacific Coast Highway" type="NP">
          <tokens>
            <token id="46" string="Pacific" />
            <token id="47" string="Coast" />
            <token id="48" string="Highway" />
          </tokens>
        </chunking>
        <chunking id="28" string="said" type="VP">
          <tokens>
            <token id="53" string="said" />
          </tokens>
        </chunking>
        <chunking id="29" string="The FBI" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="FBI" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">FBI</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="6">called</governor>
          <dependent id="2">FBI</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">called</governor>
          <dependent id="3">has</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">called</governor>
          <dependent id="4">also</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="6">called</governor>
          <dependent id="5">been</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="53">said</governor>
          <dependent id="6">called</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">called</governor>
          <dependent id="7">in</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">determine</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">called</governor>
          <dependent id="9">determine</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="36">violated</governor>
          <dependent id="10">whether</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">rights</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">rights</governor>
          <dependent id="12">civil</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="36">violated</governor>
          <dependent id="13">rights</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">man</governor>
          <dependent id="14">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">man</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">rights</governor>
          <dependent id="16">man</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="19">arrested</governor>
          <dependent id="17">who</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="19">arrested</governor>
          <dependent id="18">was</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="16">man</governor>
          <dependent id="19">arrested</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">Jackson</governor>
          <dependent id="21">Don</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="16">man</governor>
          <dependent id="22">Jackson</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">sergeant</governor>
          <dependent id="24">a</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="22">Jackson</governor>
          <dependent id="25">sergeant</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">leave</governor>
          <dependent id="26">on</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">leave</governor>
          <dependent id="27">administrative</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">sergeant</governor>
          <dependent id="28">leave</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">Department</governor>
          <dependent id="29">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="33">Department</governor>
          <dependent id="30">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="33">Department</governor>
          <dependent id="31">Hawthorne</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="33">Department</governor>
          <dependent id="32">Police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">leave</governor>
          <dependent id="33">Department</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="36">violated</governor>
          <dependent id="35">were</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="9">determine</governor>
          <dependent id="36">violated</dependent>
        </dependency>
        <dependency type="case">
          <governor id="39">altercation</governor>
          <dependent id="37">during</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="39">altercation</governor>
          <dependent id="38">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="36">violated</governor>
          <dependent id="39">altercation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="44">officers</governor>
          <dependent id="40">with</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="44">officers</governor>
          <dependent id="41">two</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="44">officers</governor>
          <dependent id="42">Long</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="44">officers</governor>
          <dependent id="43">Beach</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="36">violated</governor>
          <dependent id="44">officers</dependent>
        </dependency>
        <dependency type="case">
          <governor id="48">Highway</governor>
          <dependent id="45">on</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="48">Highway</governor>
          <dependent id="46">Pacific</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="48">Highway</governor>
          <dependent id="47">Coast</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="44">officers</governor>
          <dependent id="48">Highway</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="52">Reagan</governor>
          <dependent id="50">spokesman</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="52">Reagan</governor>
          <dependent id="51">Fred</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="53">said</governor>
          <dependent id="52">Reagan</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="53">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Long Beach" type="LOCATION" score="0.0">
          <tokens>
            <token id="42" string="Long" />
            <token id="43" string="Beach" />
          </tokens>
        </entity>
        <entity id="2" string="Don Jackson" type="PERSON" score="0.0">
          <tokens>
            <token id="21" string="Don" />
            <token id="22" string="Jackson" />
          </tokens>
        </entity>
        <entity id="3" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="41" string="two" />
          </tokens>
        </entity>
        <entity id="4" string="Pacific Coast Highway" type="LOCATION" score="0.0">
          <tokens>
            <token id="46" string="Pacific" />
            <token id="47" string="Coast" />
            <token id="48" string="Highway" />
          </tokens>
        </entity>
        <entity id="5" string="FBI" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="2" string="FBI" />
          </tokens>
        </entity>
        <entity id="6" string="Hawthorne Police Department" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="31" string="Hawthorne" />
            <token id="32" string="Police" />
            <token id="33" string="Department" />
          </tokens>
        </entity>
        <entity id="7" string="Fred Reagan" type="PERSON" score="0.0">
          <tokens>
            <token id="51" string="Fred" />
            <token id="52" string="Reagan" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>He refused to say who had requested the federal investigation.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="refused" lemma="refuse" stem="refus" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="say" lemma="say" stem="sai" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="requested" lemma="request" stem="request" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="federal" lemma="federal" stem="feder" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="investigation" lemma="investigation" stem="investig" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VBD refused) (S (VP (TO to) (VP (VB say) (SBAR (WHNP (WP who)) (S (VP (VBD had) (VP (VBN requested) (NP (DT the) (JJ federal) (NN investigation)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="had requested the federal investigation" type="VP">
          <tokens>
            <token id="6" string="had" />
            <token id="7" string="requested" />
            <token id="8" string="the" />
            <token id="9" string="federal" />
            <token id="10" string="investigation" />
          </tokens>
        </chunking>
        <chunking id="2" string="who had requested the federal investigation" type="SBAR">
          <tokens>
            <token id="5" string="who" />
            <token id="6" string="had" />
            <token id="7" string="requested" />
            <token id="8" string="the" />
            <token id="9" string="federal" />
            <token id="10" string="investigation" />
          </tokens>
        </chunking>
        <chunking id="3" string="say who had requested the federal investigation" type="VP">
          <tokens>
            <token id="4" string="say" />
            <token id="5" string="who" />
            <token id="6" string="had" />
            <token id="7" string="requested" />
            <token id="8" string="the" />
            <token id="9" string="federal" />
            <token id="10" string="investigation" />
          </tokens>
        </chunking>
        <chunking id="4" string="to say who had requested the federal investigation" type="VP">
          <tokens>
            <token id="3" string="to" />
            <token id="4" string="say" />
            <token id="5" string="who" />
            <token id="6" string="had" />
            <token id="7" string="requested" />
            <token id="8" string="the" />
            <token id="9" string="federal" />
            <token id="10" string="investigation" />
          </tokens>
        </chunking>
        <chunking id="5" string="the federal investigation" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="federal" />
            <token id="10" string="investigation" />
          </tokens>
        </chunking>
        <chunking id="6" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="7" string="refused to say who had requested the federal investigation" type="VP">
          <tokens>
            <token id="2" string="refused" />
            <token id="3" string="to" />
            <token id="4" string="say" />
            <token id="5" string="who" />
            <token id="6" string="had" />
            <token id="7" string="requested" />
            <token id="8" string="the" />
            <token id="9" string="federal" />
            <token id="10" string="investigation" />
          </tokens>
        </chunking>
        <chunking id="8" string="requested the federal investigation" type="VP">
          <tokens>
            <token id="7" string="requested" />
            <token id="8" string="the" />
            <token id="9" string="federal" />
            <token id="10" string="investigation" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">refused</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">refused</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="4">say</governor>
          <dependent id="3">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="2">refused</governor>
          <dependent id="4">say</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">requested</governor>
          <dependent id="5">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">requested</governor>
          <dependent id="6">had</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">say</governor>
          <dependent id="7">requested</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">investigation</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">investigation</governor>
          <dependent id="9">federal</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">requested</governor>
          <dependent id="10">investigation</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>&amp;quot;We&amp;apost;ve had an allegation of a civil rights violation and we opened a ticket on it this morning,&amp;quot; he said.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="We" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="'ve" lemma="have" stem="'ve" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="allegation" lemma="allegation" stem="alleg" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="civil" lemma="civil" stem="civil" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="rights" lemma="rights" stem="right" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="violation" lemma="violation" stem="violat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="opened" lemma="open" stem="open" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="ticket" lemma="ticket" stem="ticket" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" ner="TIME" is_referenced="true" is_refers="false" />
        <token id="20" string="morning" lemma="morning" stem="morn" pos="NN" type="Word" isStopWord="false" ner="TIME" is_referenced="true" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (S (NP (PRP We)) (VP (VBP 've) (VP (VBD had) (NP (NP (DT an) (NN allegation)) (PP (IN of) (NP (DT a) (JJ civil) (NNS rights) (NN violation))))))) (CC and) (S (NP (PRP we)) (VP (VBD opened) (NP (DT a) (NN ticket)) (PP (IN on) (NP (PRP it))) (NP-TMP (DT this) (NN morning))))) (, ,) ('' '') (NP (PRP he)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="an allegation of a civil rights violation" type="NP">
          <tokens>
            <token id="5" string="an" />
            <token id="6" string="allegation" />
            <token id="7" string="of" />
            <token id="8" string="a" />
            <token id="9" string="civil" />
            <token id="10" string="rights" />
            <token id="11" string="violation" />
          </tokens>
        </chunking>
        <chunking id="2" string="a civil rights violation" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="civil" />
            <token id="10" string="rights" />
            <token id="11" string="violation" />
          </tokens>
        </chunking>
        <chunking id="3" string="opened a ticket on it this morning" type="VP">
          <tokens>
            <token id="14" string="opened" />
            <token id="15" string="a" />
            <token id="16" string="ticket" />
            <token id="17" string="on" />
            <token id="18" string="it" />
            <token id="19" string="this" />
            <token id="20" string="morning" />
          </tokens>
        </chunking>
        <chunking id="4" string="it" type="NP">
          <tokens>
            <token id="18" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="'ve had an allegation of a civil rights violation" type="VP">
          <tokens>
            <token id="3" string="'ve" />
            <token id="4" string="had" />
            <token id="5" string="an" />
            <token id="6" string="allegation" />
            <token id="7" string="of" />
            <token id="8" string="a" />
            <token id="9" string="civil" />
            <token id="10" string="rights" />
            <token id="11" string="violation" />
          </tokens>
        </chunking>
        <chunking id="6" string="a ticket" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="ticket" />
          </tokens>
        </chunking>
        <chunking id="7" string="an allegation" type="NP">
          <tokens>
            <token id="5" string="an" />
            <token id="6" string="allegation" />
          </tokens>
        </chunking>
        <chunking id="8" string="he" type="NP">
          <tokens>
            <token id="23" string="he" />
          </tokens>
        </chunking>
        <chunking id="9" string="We" type="NP">
          <tokens>
            <token id="2" string="We" />
          </tokens>
        </chunking>
        <chunking id="10" string="had an allegation of a civil rights violation" type="VP">
          <tokens>
            <token id="4" string="had" />
            <token id="5" string="an" />
            <token id="6" string="allegation" />
            <token id="7" string="of" />
            <token id="8" string="a" />
            <token id="9" string="civil" />
            <token id="10" string="rights" />
            <token id="11" string="violation" />
          </tokens>
        </chunking>
        <chunking id="11" string="we" type="NP">
          <tokens>
            <token id="13" string="we" />
          </tokens>
        </chunking>
        <chunking id="12" string="said" type="VP">
          <tokens>
            <token id="24" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">had</governor>
          <dependent id="2">We</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">had</governor>
          <dependent id="3">'ve</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="24">said</governor>
          <dependent id="4">had</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">allegation</governor>
          <dependent id="5">an</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">had</governor>
          <dependent id="6">allegation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">violation</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">violation</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">violation</governor>
          <dependent id="9">civil</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">violation</governor>
          <dependent id="10">rights</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">allegation</governor>
          <dependent id="11">violation</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">had</governor>
          <dependent id="12">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">opened</governor>
          <dependent id="13">we</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">had</governor>
          <dependent id="14">opened</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">ticket</governor>
          <dependent id="15">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">opened</governor>
          <dependent id="16">ticket</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">it</governor>
          <dependent id="17">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">opened</governor>
          <dependent id="18">it</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">morning</governor>
          <dependent id="19">this</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="14">opened</governor>
          <dependent id="20">morning</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">said</governor>
          <dependent id="23">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="24">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="this morning" type="TIME" score="0.0">
          <tokens>
            <token id="19" string="this" />
            <token id="20" string="morning" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>Jackson and Jeff Hill, an off-duty federal corrections officer, donned dirty old clothes and drove into Long Beach in a rented 12-year-old sedan Saturday night as the television crew followed behind in a van.</content>
      <tokens>
        <token id="1" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Jeff" lemma="Jeff" stem="jeff" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="4" string="Hill" lemma="Hill" stem="hill" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="off-duty" lemma="off-duty" stem="off-duti" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="federal" lemma="federal" stem="feder" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="corrections" lemma="correction" stem="correct" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="officer" lemma="officer" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="donned" lemma="don" stem="don" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="dirty" lemma="dirty" stem="dirti" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="old" lemma="old" stem="old" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="clothes" lemma="clothes" stem="cloth" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="drove" lemma="drive" stem="drove" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="Long" lemma="Long" stem="long" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="20" string="Beach" lemma="Beach" stem="beach" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="21" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="rented" lemma="rent" stem="rent" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="12-year-old" lemma="12-year-old" stem="12-year-old" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="25" string="sedan" lemma="sedan" stem="sedan" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="Saturday" lemma="Saturday" stem="saturdai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="27" string="night" lemma="night" stem="night" pos="NN" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="28" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="30" string="television" lemma="television" stem="televis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="31" string="crew" lemma="crew" stem="crew" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="32" string="followed" lemma="follow" stem="follow" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="behind" lemma="behind" stem="behind" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="van" lemma="van" stem="van" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Jackson) (CC and) (NNP Jeff) (NNP Hill)) (, ,) (NP (DT an) (JJ off-duty) (JJ federal) (NNS corrections) (NN officer)) (, ,)) (VP (VP (VBN donned) (NP (JJ dirty) (JJ old) (NNS clothes))) (CC and) (VP (VBD drove) (PP (IN into) (NP (NP (NNP Long) (NNP Beach)) (PP (IN in) (NP (DT a) (VBN rented) (JJ 12-year-old) (NN sedan))))) (NP-TMP (NNP Saturday) (NN night)) (SBAR (IN as) (S (NP (DT the) (NN television) (NN crew)) (VP (VBD followed) (ADVP (IN behind)) (PP (IN in) (NP (DT a) (NN van)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the television crew" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="television" />
            <token id="31" string="crew" />
          </tokens>
        </chunking>
        <chunking id="2" string="a van" type="NP">
          <tokens>
            <token id="35" string="a" />
            <token id="36" string="van" />
          </tokens>
        </chunking>
        <chunking id="3" string="followed behind in a van" type="VP">
          <tokens>
            <token id="32" string="followed" />
            <token id="33" string="behind" />
            <token id="34" string="in" />
            <token id="35" string="a" />
            <token id="36" string="van" />
          </tokens>
        </chunking>
        <chunking id="4" string="donned dirty old clothes and drove into Long Beach in a rented 12-year-old sedan Saturday night as the television crew followed behind in a van" type="VP">
          <tokens>
            <token id="12" string="donned" />
            <token id="13" string="dirty" />
            <token id="14" string="old" />
            <token id="15" string="clothes" />
            <token id="16" string="and" />
            <token id="17" string="drove" />
            <token id="18" string="into" />
            <token id="19" string="Long" />
            <token id="20" string="Beach" />
            <token id="21" string="in" />
            <token id="22" string="a" />
            <token id="23" string="rented" />
            <token id="24" string="12-year-old" />
            <token id="25" string="sedan" />
            <token id="26" string="Saturday" />
            <token id="27" string="night" />
            <token id="28" string="as" />
            <token id="29" string="the" />
            <token id="30" string="television" />
            <token id="31" string="crew" />
            <token id="32" string="followed" />
            <token id="33" string="behind" />
            <token id="34" string="in" />
            <token id="35" string="a" />
            <token id="36" string="van" />
          </tokens>
        </chunking>
        <chunking id="5" string="a rented 12-year-old sedan" type="NP">
          <tokens>
            <token id="22" string="a" />
            <token id="23" string="rented" />
            <token id="24" string="12-year-old" />
            <token id="25" string="sedan" />
          </tokens>
        </chunking>
        <chunking id="6" string="Jackson and Jeff Hill , an off-duty federal corrections officer ," type="NP">
          <tokens>
            <token id="1" string="Jackson" />
            <token id="2" string="and" />
            <token id="3" string="Jeff" />
            <token id="4" string="Hill" />
            <token id="5" string="," />
            <token id="6" string="an" />
            <token id="7" string="off-duty" />
            <token id="8" string="federal" />
            <token id="9" string="corrections" />
            <token id="10" string="officer" />
            <token id="11" string="," />
          </tokens>
        </chunking>
        <chunking id="7" string="Long Beach in a rented 12-year-old sedan" type="NP">
          <tokens>
            <token id="19" string="Long" />
            <token id="20" string="Beach" />
            <token id="21" string="in" />
            <token id="22" string="a" />
            <token id="23" string="rented" />
            <token id="24" string="12-year-old" />
            <token id="25" string="sedan" />
          </tokens>
        </chunking>
        <chunking id="8" string="Jackson and Jeff Hill" type="NP">
          <tokens>
            <token id="1" string="Jackson" />
            <token id="2" string="and" />
            <token id="3" string="Jeff" />
            <token id="4" string="Hill" />
          </tokens>
        </chunking>
        <chunking id="9" string="donned dirty old clothes" type="VP">
          <tokens>
            <token id="12" string="donned" />
            <token id="13" string="dirty" />
            <token id="14" string="old" />
            <token id="15" string="clothes" />
          </tokens>
        </chunking>
        <chunking id="10" string="dirty old clothes" type="NP">
          <tokens>
            <token id="13" string="dirty" />
            <token id="14" string="old" />
            <token id="15" string="clothes" />
          </tokens>
        </chunking>
        <chunking id="11" string="Long Beach" type="NP">
          <tokens>
            <token id="19" string="Long" />
            <token id="20" string="Beach" />
          </tokens>
        </chunking>
        <chunking id="12" string="an off-duty federal corrections officer" type="NP">
          <tokens>
            <token id="6" string="an" />
            <token id="7" string="off-duty" />
            <token id="8" string="federal" />
            <token id="9" string="corrections" />
            <token id="10" string="officer" />
          </tokens>
        </chunking>
        <chunking id="13" string="as the television crew followed behind in a van" type="SBAR">
          <tokens>
            <token id="28" string="as" />
            <token id="29" string="the" />
            <token id="30" string="television" />
            <token id="31" string="crew" />
            <token id="32" string="followed" />
            <token id="33" string="behind" />
            <token id="34" string="in" />
            <token id="35" string="a" />
            <token id="36" string="van" />
          </tokens>
        </chunking>
        <chunking id="14" string="drove into Long Beach in a rented 12-year-old sedan Saturday night as the television crew followed behind in a van" type="VP">
          <tokens>
            <token id="17" string="drove" />
            <token id="18" string="into" />
            <token id="19" string="Long" />
            <token id="20" string="Beach" />
            <token id="21" string="in" />
            <token id="22" string="a" />
            <token id="23" string="rented" />
            <token id="24" string="12-year-old" />
            <token id="25" string="sedan" />
            <token id="26" string="Saturday" />
            <token id="27" string="night" />
            <token id="28" string="as" />
            <token id="29" string="the" />
            <token id="30" string="television" />
            <token id="31" string="crew" />
            <token id="32" string="followed" />
            <token id="33" string="behind" />
            <token id="34" string="in" />
            <token id="35" string="a" />
            <token id="36" string="van" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="4">Hill</governor>
          <dependent id="1">Jackson</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="1">Jackson</governor>
          <dependent id="2">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="1">Jackson</governor>
          <dependent id="3">Jeff</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">donned</governor>
          <dependent id="4">Hill</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">officer</governor>
          <dependent id="6">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">officer</governor>
          <dependent id="7">off-duty</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">officer</governor>
          <dependent id="8">federal</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">officer</governor>
          <dependent id="9">corrections</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="4">Hill</governor>
          <dependent id="10">officer</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">donned</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">clothes</governor>
          <dependent id="13">dirty</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">clothes</governor>
          <dependent id="14">old</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">donned</governor>
          <dependent id="15">clothes</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="12">donned</governor>
          <dependent id="16">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">donned</governor>
          <dependent id="17">drove</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">Beach</governor>
          <dependent id="18">into</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">Beach</governor>
          <dependent id="19">Long</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">drove</governor>
          <dependent id="20">Beach</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">sedan</governor>
          <dependent id="21">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">sedan</governor>
          <dependent id="22">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">sedan</governor>
          <dependent id="23">rented</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">sedan</governor>
          <dependent id="24">12-year-old</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">Beach</governor>
          <dependent id="25">sedan</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">night</governor>
          <dependent id="26">Saturday</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="17">drove</governor>
          <dependent id="27">night</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="32">followed</governor>
          <dependent id="28">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">crew</governor>
          <dependent id="29">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">crew</governor>
          <dependent id="30">television</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="32">followed</governor>
          <dependent id="31">crew</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="17">drove</governor>
          <dependent id="32">followed</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="32">followed</governor>
          <dependent id="33">behind</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">van</governor>
          <dependent id="34">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="36">van</governor>
          <dependent id="35">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="32">followed</governor>
          <dependent id="36">van</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Long Beach" type="LOCATION" score="0.0">
          <tokens>
            <token id="19" string="Long" />
            <token id="20" string="Beach" />
          </tokens>
        </entity>
        <entity id="2" string="Jeff Hill" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Jeff" />
            <token id="4" string="Hill" />
          </tokens>
        </entity>
        <entity id="3" string="night" type="TIME" score="0.0">
          <tokens>
            <token id="27" string="night" />
          </tokens>
        </entity>
        <entity id="4" string="Jackson" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Jackson" />
          </tokens>
        </entity>
        <entity id="5" string="12-year-old" type="DURATION" score="0.0">
          <tokens>
            <token id="24" string="12-year-old" />
          </tokens>
        </entity>
        <entity id="6" string="Saturday" type="DATE" score="0.0">
          <tokens>
            <token id="26" string="Saturday" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="11" has_coreference="false">
      <content>The two men said they wanted to demonstrate a long-standing problem of abuse of minority group members by Long Beach police officers.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="3" string="men" lemma="man" stem="men" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="wanted" lemma="want" stem="want" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="demonstrate" lemma="demonstrate" stem="demonstr" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="long-standing" lemma="long-standing" stem="long-stand" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="problem" lemma="problem" stem="problem" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="abuse" lemma="abuse" stem="abus" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="minority" lemma="minority" stem="minor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="group" lemma="group" stem="group" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="members" lemma="member" stem="member" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="Long" lemma="Long" stem="long" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="20" string="Beach" lemma="Beach" stem="beach" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="21" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (CD two) (NNS men)) (VP (VBD said) (SBAR (S (NP (PRP they)) (VP (VBD wanted) (S (VP (TO to) (VP (VB demonstrate) (NP (NP (DT a) (JJ long-standing) (NN problem)) (PP (IN of) (NP (NP (NN abuse)) (PP (IN of) (NP (NN minority) (NN group) (NNS members)))))) (PP (IN by) (NP (NNP Long) (NNP Beach) (NN police) (NNS officers)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="they wanted to demonstrate a long-standing problem of abuse of minority group members by Long Beach police officers" type="SBAR">
          <tokens>
            <token id="5" string="they" />
            <token id="6" string="wanted" />
            <token id="7" string="to" />
            <token id="8" string="demonstrate" />
            <token id="9" string="a" />
            <token id="10" string="long-standing" />
            <token id="11" string="problem" />
            <token id="12" string="of" />
            <token id="13" string="abuse" />
            <token id="14" string="of" />
            <token id="15" string="minority" />
            <token id="16" string="group" />
            <token id="17" string="members" />
            <token id="18" string="by" />
            <token id="19" string="Long" />
            <token id="20" string="Beach" />
            <token id="21" string="police" />
            <token id="22" string="officers" />
          </tokens>
        </chunking>
        <chunking id="2" string="abuse" type="NP">
          <tokens>
            <token id="13" string="abuse" />
          </tokens>
        </chunking>
        <chunking id="3" string="a long-standing problem" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="long-standing" />
            <token id="11" string="problem" />
          </tokens>
        </chunking>
        <chunking id="4" string="minority group members" type="NP">
          <tokens>
            <token id="15" string="minority" />
            <token id="16" string="group" />
            <token id="17" string="members" />
          </tokens>
        </chunking>
        <chunking id="5" string="The two men" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="two" />
            <token id="3" string="men" />
          </tokens>
        </chunking>
        <chunking id="6" string="Long Beach police officers" type="NP">
          <tokens>
            <token id="19" string="Long" />
            <token id="20" string="Beach" />
            <token id="21" string="police" />
            <token id="22" string="officers" />
          </tokens>
        </chunking>
        <chunking id="7" string="abuse of minority group members" type="NP">
          <tokens>
            <token id="13" string="abuse" />
            <token id="14" string="of" />
            <token id="15" string="minority" />
            <token id="16" string="group" />
            <token id="17" string="members" />
          </tokens>
        </chunking>
        <chunking id="8" string="to demonstrate a long-standing problem of abuse of minority group members by Long Beach police officers" type="VP">
          <tokens>
            <token id="7" string="to" />
            <token id="8" string="demonstrate" />
            <token id="9" string="a" />
            <token id="10" string="long-standing" />
            <token id="11" string="problem" />
            <token id="12" string="of" />
            <token id="13" string="abuse" />
            <token id="14" string="of" />
            <token id="15" string="minority" />
            <token id="16" string="group" />
            <token id="17" string="members" />
            <token id="18" string="by" />
            <token id="19" string="Long" />
            <token id="20" string="Beach" />
            <token id="21" string="police" />
            <token id="22" string="officers" />
          </tokens>
        </chunking>
        <chunking id="9" string="they" type="NP">
          <tokens>
            <token id="5" string="they" />
          </tokens>
        </chunking>
        <chunking id="10" string="wanted to demonstrate a long-standing problem of abuse of minority group members by Long Beach police officers" type="VP">
          <tokens>
            <token id="6" string="wanted" />
            <token id="7" string="to" />
            <token id="8" string="demonstrate" />
            <token id="9" string="a" />
            <token id="10" string="long-standing" />
            <token id="11" string="problem" />
            <token id="12" string="of" />
            <token id="13" string="abuse" />
            <token id="14" string="of" />
            <token id="15" string="minority" />
            <token id="16" string="group" />
            <token id="17" string="members" />
            <token id="18" string="by" />
            <token id="19" string="Long" />
            <token id="20" string="Beach" />
            <token id="21" string="police" />
            <token id="22" string="officers" />
          </tokens>
        </chunking>
        <chunking id="11" string="demonstrate a long-standing problem of abuse of minority group members by Long Beach police officers" type="VP">
          <tokens>
            <token id="8" string="demonstrate" />
            <token id="9" string="a" />
            <token id="10" string="long-standing" />
            <token id="11" string="problem" />
            <token id="12" string="of" />
            <token id="13" string="abuse" />
            <token id="14" string="of" />
            <token id="15" string="minority" />
            <token id="16" string="group" />
            <token id="17" string="members" />
            <token id="18" string="by" />
            <token id="19" string="Long" />
            <token id="20" string="Beach" />
            <token id="21" string="police" />
            <token id="22" string="officers" />
          </tokens>
        </chunking>
        <chunking id="12" string="said they wanted to demonstrate a long-standing problem of abuse of minority group members by Long Beach police officers" type="VP">
          <tokens>
            <token id="4" string="said" />
            <token id="5" string="they" />
            <token id="6" string="wanted" />
            <token id="7" string="to" />
            <token id="8" string="demonstrate" />
            <token id="9" string="a" />
            <token id="10" string="long-standing" />
            <token id="11" string="problem" />
            <token id="12" string="of" />
            <token id="13" string="abuse" />
            <token id="14" string="of" />
            <token id="15" string="minority" />
            <token id="16" string="group" />
            <token id="17" string="members" />
            <token id="18" string="by" />
            <token id="19" string="Long" />
            <token id="20" string="Beach" />
            <token id="21" string="police" />
            <token id="22" string="officers" />
          </tokens>
        </chunking>
        <chunking id="13" string="a long-standing problem of abuse of minority group members" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="long-standing" />
            <token id="11" string="problem" />
            <token id="12" string="of" />
            <token id="13" string="abuse" />
            <token id="14" string="of" />
            <token id="15" string="minority" />
            <token id="16" string="group" />
            <token id="17" string="members" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">men</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="3">men</governor>
          <dependent id="2">two</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">said</governor>
          <dependent id="3">men</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">wanted</governor>
          <dependent id="5">they</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">said</governor>
          <dependent id="6">wanted</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">demonstrate</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">wanted</governor>
          <dependent id="8">demonstrate</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">problem</governor>
          <dependent id="9">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">problem</governor>
          <dependent id="10">long-standing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">demonstrate</governor>
          <dependent id="11">problem</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">abuse</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">problem</governor>
          <dependent id="13">abuse</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">members</governor>
          <dependent id="14">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">members</governor>
          <dependent id="15">minority</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">members</governor>
          <dependent id="16">group</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">abuse</governor>
          <dependent id="17">members</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">officers</governor>
          <dependent id="18">by</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">officers</governor>
          <dependent id="19">Long</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">officers</governor>
          <dependent id="20">Beach</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">officers</governor>
          <dependent id="21">police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">demonstrate</governor>
          <dependent id="22">officers</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Long Beach" type="LOCATION" score="0.0">
          <tokens>
            <token id="19" string="Long" />
            <token id="20" string="Beach" />
          </tokens>
        </entity>
        <entity id="2" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="2" string="two" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>Full Tape Withheld While edited portions of the tape have been broadcast, Long Beach officials have said they need to see everything filmed by the NBC crew to move ahead with their own investigation of the incident.</content>
      <tokens>
        <token id="1" string="Full" lemma="full" stem="full" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="Tape" lemma="tape" stem="tape" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Withheld" lemma="Withheld" stem="withheld" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="While" lemma="while" stem="while" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="edited" lemma="edited" stem="edit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="portions" lemma="portion" stem="portion" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="tape" lemma="tape" stem="tape" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="broadcast" lemma="broadcast" stem="broadcast" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Long" lemma="Long" stem="long" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="15" string="Beach" lemma="Beach" stem="beach" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="16" string="officials" lemma="official" stem="offici" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="said" lemma="say" stem="said" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="need" lemma="need" stem="need" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="see" lemma="see" stem="see" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="everything" lemma="everything" stem="everyth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="filmed" lemma="film" stem="film" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="27" string="NBC" lemma="NBC" stem="nbc" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="28" string="crew" lemma="crew" stem="crew" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="29" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="move" lemma="move" stem="move" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="ahead" lemma="ahead" stem="ahead" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="34" string="own" lemma="own" stem="own" pos="JJ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="35" string="investigation" lemma="investigation" stem="investig" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="36" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="37" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="38" string="incident" lemma="incident" stem="incid" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="39" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (JJ Full) (NN Tape) (NNP Withheld)) (SBAR (IN While) (S (NP (NP (JJ edited) (NNS portions)) (PP (IN of) (NP (DT the) (NN tape)))) (VP (VBP have) (VP (VBN been) (VP (VBN broadcast))))))) (, ,) (NP (NNP Long) (NNP Beach) (NNS officials)) (VP (VBP have) (VP (VBN said) (SBAR (S (NP (PRP they)) (VP (VBP need) (S (VP (TO to) (VP (VB see) (NP (NP (NN everything)) (VP (VBN filmed) (PP (IN by) (NP (DT the) (NNP NBC) (NN crew))) (S (VP (TO to) (VP (VB move) (ADVP (RB ahead)) (PP (IN with) (NP (NP (PRP$ their) (JJ own) (NN investigation)) (PP (IN of) (NP (DT the) (NN incident)))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="to move ahead with their own investigation of the incident" type="VP">
          <tokens>
            <token id="29" string="to" />
            <token id="30" string="move" />
            <token id="31" string="ahead" />
            <token id="32" string="with" />
            <token id="33" string="their" />
            <token id="34" string="own" />
            <token id="35" string="investigation" />
            <token id="36" string="of" />
            <token id="37" string="the" />
            <token id="38" string="incident" />
          </tokens>
        </chunking>
        <chunking id="2" string="everything filmed by the NBC crew to move ahead with their own investigation of the incident" type="NP">
          <tokens>
            <token id="23" string="everything" />
            <token id="24" string="filmed" />
            <token id="25" string="by" />
            <token id="26" string="the" />
            <token id="27" string="NBC" />
            <token id="28" string="crew" />
            <token id="29" string="to" />
            <token id="30" string="move" />
            <token id="31" string="ahead" />
            <token id="32" string="with" />
            <token id="33" string="their" />
            <token id="34" string="own" />
            <token id="35" string="investigation" />
            <token id="36" string="of" />
            <token id="37" string="the" />
            <token id="38" string="incident" />
          </tokens>
        </chunking>
        <chunking id="3" string="Long Beach officials" type="NP">
          <tokens>
            <token id="14" string="Long" />
            <token id="15" string="Beach" />
            <token id="16" string="officials" />
          </tokens>
        </chunking>
        <chunking id="4" string="said they need to see everything filmed by the NBC crew to move ahead with their own investigation of the incident" type="VP">
          <tokens>
            <token id="18" string="said" />
            <token id="19" string="they" />
            <token id="20" string="need" />
            <token id="21" string="to" />
            <token id="22" string="see" />
            <token id="23" string="everything" />
            <token id="24" string="filmed" />
            <token id="25" string="by" />
            <token id="26" string="the" />
            <token id="27" string="NBC" />
            <token id="28" string="crew" />
            <token id="29" string="to" />
            <token id="30" string="move" />
            <token id="31" string="ahead" />
            <token id="32" string="with" />
            <token id="33" string="their" />
            <token id="34" string="own" />
            <token id="35" string="investigation" />
            <token id="36" string="of" />
            <token id="37" string="the" />
            <token id="38" string="incident" />
          </tokens>
        </chunking>
        <chunking id="5" string="have been broadcast" type="VP">
          <tokens>
            <token id="10" string="have" />
            <token id="11" string="been" />
            <token id="12" string="broadcast" />
          </tokens>
        </chunking>
        <chunking id="6" string="move ahead with their own investigation of the incident" type="VP">
          <tokens>
            <token id="30" string="move" />
            <token id="31" string="ahead" />
            <token id="32" string="with" />
            <token id="33" string="their" />
            <token id="34" string="own" />
            <token id="35" string="investigation" />
            <token id="36" string="of" />
            <token id="37" string="the" />
            <token id="38" string="incident" />
          </tokens>
        </chunking>
        <chunking id="7" string="been broadcast" type="VP">
          <tokens>
            <token id="11" string="been" />
            <token id="12" string="broadcast" />
          </tokens>
        </chunking>
        <chunking id="8" string="filmed by the NBC crew to move ahead with their own investigation of the incident" type="VP">
          <tokens>
            <token id="24" string="filmed" />
            <token id="25" string="by" />
            <token id="26" string="the" />
            <token id="27" string="NBC" />
            <token id="28" string="crew" />
            <token id="29" string="to" />
            <token id="30" string="move" />
            <token id="31" string="ahead" />
            <token id="32" string="with" />
            <token id="33" string="their" />
            <token id="34" string="own" />
            <token id="35" string="investigation" />
            <token id="36" string="of" />
            <token id="37" string="the" />
            <token id="38" string="incident" />
          </tokens>
        </chunking>
        <chunking id="9" string="they need to see everything filmed by the NBC crew to move ahead with their own investigation of the incident" type="SBAR">
          <tokens>
            <token id="19" string="they" />
            <token id="20" string="need" />
            <token id="21" string="to" />
            <token id="22" string="see" />
            <token id="23" string="everything" />
            <token id="24" string="filmed" />
            <token id="25" string="by" />
            <token id="26" string="the" />
            <token id="27" string="NBC" />
            <token id="28" string="crew" />
            <token id="29" string="to" />
            <token id="30" string="move" />
            <token id="31" string="ahead" />
            <token id="32" string="with" />
            <token id="33" string="their" />
            <token id="34" string="own" />
            <token id="35" string="investigation" />
            <token id="36" string="of" />
            <token id="37" string="the" />
            <token id="38" string="incident" />
          </tokens>
        </chunking>
        <chunking id="10" string="their own investigation" type="NP">
          <tokens>
            <token id="33" string="their" />
            <token id="34" string="own" />
            <token id="35" string="investigation" />
          </tokens>
        </chunking>
        <chunking id="11" string="have said they need to see everything filmed by the NBC crew to move ahead with their own investigation of the incident" type="VP">
          <tokens>
            <token id="17" string="have" />
            <token id="18" string="said" />
            <token id="19" string="they" />
            <token id="20" string="need" />
            <token id="21" string="to" />
            <token id="22" string="see" />
            <token id="23" string="everything" />
            <token id="24" string="filmed" />
            <token id="25" string="by" />
            <token id="26" string="the" />
            <token id="27" string="NBC" />
            <token id="28" string="crew" />
            <token id="29" string="to" />
            <token id="30" string="move" />
            <token id="31" string="ahead" />
            <token id="32" string="with" />
            <token id="33" string="their" />
            <token id="34" string="own" />
            <token id="35" string="investigation" />
            <token id="36" string="of" />
            <token id="37" string="the" />
            <token id="38" string="incident" />
          </tokens>
        </chunking>
        <chunking id="12" string="the incident" type="NP">
          <tokens>
            <token id="37" string="the" />
            <token id="38" string="incident" />
          </tokens>
        </chunking>
        <chunking id="13" string="broadcast" type="VP">
          <tokens>
            <token id="12" string="broadcast" />
          </tokens>
        </chunking>
        <chunking id="14" string="to see everything filmed by the NBC crew to move ahead with their own investigation of the incident" type="VP">
          <tokens>
            <token id="21" string="to" />
            <token id="22" string="see" />
            <token id="23" string="everything" />
            <token id="24" string="filmed" />
            <token id="25" string="by" />
            <token id="26" string="the" />
            <token id="27" string="NBC" />
            <token id="28" string="crew" />
            <token id="29" string="to" />
            <token id="30" string="move" />
            <token id="31" string="ahead" />
            <token id="32" string="with" />
            <token id="33" string="their" />
            <token id="34" string="own" />
            <token id="35" string="investigation" />
            <token id="36" string="of" />
            <token id="37" string="the" />
            <token id="38" string="incident" />
          </tokens>
        </chunking>
        <chunking id="15" string="see everything filmed by the NBC crew to move ahead with their own investigation of the incident" type="VP">
          <tokens>
            <token id="22" string="see" />
            <token id="23" string="everything" />
            <token id="24" string="filmed" />
            <token id="25" string="by" />
            <token id="26" string="the" />
            <token id="27" string="NBC" />
            <token id="28" string="crew" />
            <token id="29" string="to" />
            <token id="30" string="move" />
            <token id="31" string="ahead" />
            <token id="32" string="with" />
            <token id="33" string="their" />
            <token id="34" string="own" />
            <token id="35" string="investigation" />
            <token id="36" string="of" />
            <token id="37" string="the" />
            <token id="38" string="incident" />
          </tokens>
        </chunking>
        <chunking id="16" string="Full Tape Withheld" type="NP">
          <tokens>
            <token id="1" string="Full" />
            <token id="2" string="Tape" />
            <token id="3" string="Withheld" />
          </tokens>
        </chunking>
        <chunking id="17" string="the NBC crew" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="NBC" />
            <token id="28" string="crew" />
          </tokens>
        </chunking>
        <chunking id="18" string="their own investigation of the incident" type="NP">
          <tokens>
            <token id="33" string="their" />
            <token id="34" string="own" />
            <token id="35" string="investigation" />
            <token id="36" string="of" />
            <token id="37" string="the" />
            <token id="38" string="incident" />
          </tokens>
        </chunking>
        <chunking id="19" string="they" type="NP">
          <tokens>
            <token id="19" string="they" />
          </tokens>
        </chunking>
        <chunking id="20" string="need to see everything filmed by the NBC crew to move ahead with their own investigation of the incident" type="VP">
          <tokens>
            <token id="20" string="need" />
            <token id="21" string="to" />
            <token id="22" string="see" />
            <token id="23" string="everything" />
            <token id="24" string="filmed" />
            <token id="25" string="by" />
            <token id="26" string="the" />
            <token id="27" string="NBC" />
            <token id="28" string="crew" />
            <token id="29" string="to" />
            <token id="30" string="move" />
            <token id="31" string="ahead" />
            <token id="32" string="with" />
            <token id="33" string="their" />
            <token id="34" string="own" />
            <token id="35" string="investigation" />
            <token id="36" string="of" />
            <token id="37" string="the" />
            <token id="38" string="incident" />
          </tokens>
        </chunking>
        <chunking id="21" string="While edited portions of the tape have been broadcast" type="SBAR">
          <tokens>
            <token id="4" string="While" />
            <token id="5" string="edited" />
            <token id="6" string="portions" />
            <token id="7" string="of" />
            <token id="8" string="the" />
            <token id="9" string="tape" />
            <token id="10" string="have" />
            <token id="11" string="been" />
            <token id="12" string="broadcast" />
          </tokens>
        </chunking>
        <chunking id="22" string="the tape" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="tape" />
          </tokens>
        </chunking>
        <chunking id="23" string="edited portions of the tape" type="NP">
          <tokens>
            <token id="5" string="edited" />
            <token id="6" string="portions" />
            <token id="7" string="of" />
            <token id="8" string="the" />
            <token id="9" string="tape" />
          </tokens>
        </chunking>
        <chunking id="24" string="everything" type="NP">
          <tokens>
            <token id="23" string="everything" />
          </tokens>
        </chunking>
        <chunking id="25" string="edited portions" type="NP">
          <tokens>
            <token id="5" string="edited" />
            <token id="6" string="portions" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="3">Withheld</governor>
          <dependent id="1">Full</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Withheld</governor>
          <dependent id="2">Tape</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="12">broadcast</governor>
          <dependent id="3">Withheld</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">broadcast</governor>
          <dependent id="4">While</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">portions</governor>
          <dependent id="5">edited</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="12">broadcast</governor>
          <dependent id="6">portions</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">tape</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">tape</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">portions</governor>
          <dependent id="9">tape</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">broadcast</governor>
          <dependent id="10">have</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="12">broadcast</governor>
          <dependent id="11">been</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="18">said</governor>
          <dependent id="12">broadcast</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">officials</governor>
          <dependent id="14">Long</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">officials</governor>
          <dependent id="15">Beach</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">said</governor>
          <dependent id="16">officials</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="18">said</governor>
          <dependent id="17">have</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="18">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">need</governor>
          <dependent id="19">they</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="18">said</governor>
          <dependent id="20">need</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">see</governor>
          <dependent id="21">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="20">need</governor>
          <dependent id="22">see</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">see</governor>
          <dependent id="23">everything</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="23">everything</governor>
          <dependent id="24">filmed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">crew</governor>
          <dependent id="25">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">crew</governor>
          <dependent id="26">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">crew</governor>
          <dependent id="27">NBC</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">filmed</governor>
          <dependent id="28">crew</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="30">move</governor>
          <dependent id="29">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="24">filmed</governor>
          <dependent id="30">move</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="30">move</governor>
          <dependent id="31">ahead</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">investigation</governor>
          <dependent id="32">with</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="35">investigation</governor>
          <dependent id="33">their</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="35">investigation</governor>
          <dependent id="34">own</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">move</governor>
          <dependent id="35">investigation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="38">incident</governor>
          <dependent id="36">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="38">incident</governor>
          <dependent id="37">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="35">investigation</governor>
          <dependent id="38">incident</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Long Beach" type="LOCATION" score="0.0">
          <tokens>
            <token id="14" string="Long" />
            <token id="15" string="Beach" />
          </tokens>
        </entity>
        <entity id="2" string="NBC" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="27" string="NBC" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>NBC officials have declined to release the full tape, saying that it would violate company policy to release unedited footage.</content>
      <tokens>
        <token id="1" string="NBC" lemma="NBC" stem="nbc" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="2" string="officials" lemma="official" stem="offici" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="declined" lemma="decline" stem="declin" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="release" lemma="release" stem="releas" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="full" lemma="full" stem="full" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="tape" lemma="tape" stem="tape" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="saying" lemma="say" stem="sai" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="violate" lemma="violate" stem="violat" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="company" lemma="company" stem="compani" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="policy" lemma="policy" stem="polici" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="release" lemma="release" stem="releas" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="unedited" lemma="unedited" stem="unedit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="footage" lemma="footage" stem="footag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP NBC) (NNS officials)) (VP (VBP have) (VP (VBN declined) (S (VP (TO to) (VP (VB release) (NP (DT the) (JJ full) (NN tape))))) (, ,) (S (VP (VBG saying) (SBAR (IN that) (S (NP (PRP it)) (VP (MD would) (VP (VB violate) (NP (NN company) (NN policy)) (S (VP (TO to) (VP (VB release) (NP (JJ unedited) (NN footage))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="have declined to release the full tape , saying that it would violate company policy to release unedited footage" type="VP">
          <tokens>
            <token id="3" string="have" />
            <token id="4" string="declined" />
            <token id="5" string="to" />
            <token id="6" string="release" />
            <token id="7" string="the" />
            <token id="8" string="full" />
            <token id="9" string="tape" />
            <token id="10" string="," />
            <token id="11" string="saying" />
            <token id="12" string="that" />
            <token id="13" string="it" />
            <token id="14" string="would" />
            <token id="15" string="violate" />
            <token id="16" string="company" />
            <token id="17" string="policy" />
            <token id="18" string="to" />
            <token id="19" string="release" />
            <token id="20" string="unedited" />
            <token id="21" string="footage" />
          </tokens>
        </chunking>
        <chunking id="2" string="that it would violate company policy to release unedited footage" type="SBAR">
          <tokens>
            <token id="12" string="that" />
            <token id="13" string="it" />
            <token id="14" string="would" />
            <token id="15" string="violate" />
            <token id="16" string="company" />
            <token id="17" string="policy" />
            <token id="18" string="to" />
            <token id="19" string="release" />
            <token id="20" string="unedited" />
            <token id="21" string="footage" />
          </tokens>
        </chunking>
        <chunking id="3" string="to release the full tape" type="VP">
          <tokens>
            <token id="5" string="to" />
            <token id="6" string="release" />
            <token id="7" string="the" />
            <token id="8" string="full" />
            <token id="9" string="tape" />
          </tokens>
        </chunking>
        <chunking id="4" string="unedited footage" type="NP">
          <tokens>
            <token id="20" string="unedited" />
            <token id="21" string="footage" />
          </tokens>
        </chunking>
        <chunking id="5" string="NBC officials" type="NP">
          <tokens>
            <token id="1" string="NBC" />
            <token id="2" string="officials" />
          </tokens>
        </chunking>
        <chunking id="6" string="the full tape" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="full" />
            <token id="9" string="tape" />
          </tokens>
        </chunking>
        <chunking id="7" string="declined to release the full tape , saying that it would violate company policy to release unedited footage" type="VP">
          <tokens>
            <token id="4" string="declined" />
            <token id="5" string="to" />
            <token id="6" string="release" />
            <token id="7" string="the" />
            <token id="8" string="full" />
            <token id="9" string="tape" />
            <token id="10" string="," />
            <token id="11" string="saying" />
            <token id="12" string="that" />
            <token id="13" string="it" />
            <token id="14" string="would" />
            <token id="15" string="violate" />
            <token id="16" string="company" />
            <token id="17" string="policy" />
            <token id="18" string="to" />
            <token id="19" string="release" />
            <token id="20" string="unedited" />
            <token id="21" string="footage" />
          </tokens>
        </chunking>
        <chunking id="8" string="it" type="NP">
          <tokens>
            <token id="13" string="it" />
          </tokens>
        </chunking>
        <chunking id="9" string="to release unedited footage" type="VP">
          <tokens>
            <token id="18" string="to" />
            <token id="19" string="release" />
            <token id="20" string="unedited" />
            <token id="21" string="footage" />
          </tokens>
        </chunking>
        <chunking id="10" string="release the full tape" type="VP">
          <tokens>
            <token id="6" string="release" />
            <token id="7" string="the" />
            <token id="8" string="full" />
            <token id="9" string="tape" />
          </tokens>
        </chunking>
        <chunking id="11" string="violate company policy to release unedited footage" type="VP">
          <tokens>
            <token id="15" string="violate" />
            <token id="16" string="company" />
            <token id="17" string="policy" />
            <token id="18" string="to" />
            <token id="19" string="release" />
            <token id="20" string="unedited" />
            <token id="21" string="footage" />
          </tokens>
        </chunking>
        <chunking id="12" string="company policy" type="NP">
          <tokens>
            <token id="16" string="company" />
            <token id="17" string="policy" />
          </tokens>
        </chunking>
        <chunking id="13" string="release unedited footage" type="VP">
          <tokens>
            <token id="19" string="release" />
            <token id="20" string="unedited" />
            <token id="21" string="footage" />
          </tokens>
        </chunking>
        <chunking id="14" string="would violate company policy to release unedited footage" type="VP">
          <tokens>
            <token id="14" string="would" />
            <token id="15" string="violate" />
            <token id="16" string="company" />
            <token id="17" string="policy" />
            <token id="18" string="to" />
            <token id="19" string="release" />
            <token id="20" string="unedited" />
            <token id="21" string="footage" />
          </tokens>
        </chunking>
        <chunking id="15" string="saying that it would violate company policy to release unedited footage" type="VP">
          <tokens>
            <token id="11" string="saying" />
            <token id="12" string="that" />
            <token id="13" string="it" />
            <token id="14" string="would" />
            <token id="15" string="violate" />
            <token id="16" string="company" />
            <token id="17" string="policy" />
            <token id="18" string="to" />
            <token id="19" string="release" />
            <token id="20" string="unedited" />
            <token id="21" string="footage" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">officials</governor>
          <dependent id="1">NBC</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">declined</governor>
          <dependent id="2">officials</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">declined</governor>
          <dependent id="3">have</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">declined</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">release</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">declined</governor>
          <dependent id="6">release</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">tape</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">tape</governor>
          <dependent id="8">full</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">release</governor>
          <dependent id="9">tape</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">declined</governor>
          <dependent id="11">saying</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">violate</governor>
          <dependent id="12">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">violate</governor>
          <dependent id="13">it</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="15">violate</governor>
          <dependent id="14">would</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">saying</governor>
          <dependent id="15">violate</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">policy</governor>
          <dependent id="16">company</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">violate</governor>
          <dependent id="17">policy</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">release</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="15">violate</governor>
          <dependent id="19">release</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">footage</governor>
          <dependent id="20">unedited</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">release</governor>
          <dependent id="21">footage</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="NBC" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="1" string="NBC" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>A Long Beach assistant city attorney said his office is considering legal action to obtain the tapes.</content>
      <tokens>
        <token id="1" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="Long" lemma="Long" stem="long" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="3" string="Beach" lemma="Beach" stem="beach" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="4" string="assistant" lemma="assistant" stem="assist" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="city" lemma="city" stem="citi" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="attorney" lemma="attorney" stem="attornei" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="office" lemma="office" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="considering" lemma="consider" stem="consid" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="legal" lemma="legal" stem="legal" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="action" lemma="action" stem="action" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="obtain" lemma="obtain" stem="obtain" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="tapes" lemma="tape" stem="tape" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT A) (NNP Long) (NNP Beach) (JJ assistant) (NN city) (NN attorney)) (VP (VBD said) (SBAR (S (NP (PRP$ his) (NN office)) (VP (VBZ is) (VP (VBG considering) (NP (JJ legal) (NN action)) (S (VP (TO to) (VP (VB obtain) (NP (DT the) (NNS tapes)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="legal action" type="NP">
          <tokens>
            <token id="12" string="legal" />
            <token id="13" string="action" />
          </tokens>
        </chunking>
        <chunking id="2" string="is considering legal action to obtain the tapes" type="VP">
          <tokens>
            <token id="10" string="is" />
            <token id="11" string="considering" />
            <token id="12" string="legal" />
            <token id="13" string="action" />
            <token id="14" string="to" />
            <token id="15" string="obtain" />
            <token id="16" string="the" />
            <token id="17" string="tapes" />
          </tokens>
        </chunking>
        <chunking id="3" string="considering legal action to obtain the tapes" type="VP">
          <tokens>
            <token id="11" string="considering" />
            <token id="12" string="legal" />
            <token id="13" string="action" />
            <token id="14" string="to" />
            <token id="15" string="obtain" />
            <token id="16" string="the" />
            <token id="17" string="tapes" />
          </tokens>
        </chunking>
        <chunking id="4" string="his office" type="NP">
          <tokens>
            <token id="8" string="his" />
            <token id="9" string="office" />
          </tokens>
        </chunking>
        <chunking id="5" string="A Long Beach assistant city attorney" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="Long" />
            <token id="3" string="Beach" />
            <token id="4" string="assistant" />
            <token id="5" string="city" />
            <token id="6" string="attorney" />
          </tokens>
        </chunking>
        <chunking id="6" string="obtain the tapes" type="VP">
          <tokens>
            <token id="15" string="obtain" />
            <token id="16" string="the" />
            <token id="17" string="tapes" />
          </tokens>
        </chunking>
        <chunking id="7" string="his office is considering legal action to obtain the tapes" type="SBAR">
          <tokens>
            <token id="8" string="his" />
            <token id="9" string="office" />
            <token id="10" string="is" />
            <token id="11" string="considering" />
            <token id="12" string="legal" />
            <token id="13" string="action" />
            <token id="14" string="to" />
            <token id="15" string="obtain" />
            <token id="16" string="the" />
            <token id="17" string="tapes" />
          </tokens>
        </chunking>
        <chunking id="8" string="to obtain the tapes" type="VP">
          <tokens>
            <token id="14" string="to" />
            <token id="15" string="obtain" />
            <token id="16" string="the" />
            <token id="17" string="tapes" />
          </tokens>
        </chunking>
        <chunking id="9" string="the tapes" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="tapes" />
          </tokens>
        </chunking>
        <chunking id="10" string="said his office is considering legal action to obtain the tapes" type="VP">
          <tokens>
            <token id="7" string="said" />
            <token id="8" string="his" />
            <token id="9" string="office" />
            <token id="10" string="is" />
            <token id="11" string="considering" />
            <token id="12" string="legal" />
            <token id="13" string="action" />
            <token id="14" string="to" />
            <token id="15" string="obtain" />
            <token id="16" string="the" />
            <token id="17" string="tapes" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="6">attorney</governor>
          <dependent id="1">A</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">attorney</governor>
          <dependent id="2">Long</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">attorney</governor>
          <dependent id="3">Beach</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">attorney</governor>
          <dependent id="4">assistant</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">attorney</governor>
          <dependent id="5">city</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">said</governor>
          <dependent id="6">attorney</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">said</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="9">office</governor>
          <dependent id="8">his</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">considering</governor>
          <dependent id="9">office</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">considering</governor>
          <dependent id="10">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">said</governor>
          <dependent id="11">considering</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">action</governor>
          <dependent id="12">legal</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">considering</governor>
          <dependent id="13">action</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">obtain</governor>
          <dependent id="14">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="11">considering</governor>
          <dependent id="15">obtain</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">tapes</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">obtain</governor>
          <dependent id="17">tapes</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Long Beach" type="LOCATION" score="0.0">
          <tokens>
            <token id="2" string="Long" />
            <token id="3" string="Beach" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>Although Long Beach Mayor Ernie Kell told NBC&amp;apost;s &amp;quot;Today Show&amp;quot; on Tuesday morning that the two police officers had been suspended, Police Chief Lawrence L. Binkley said that the officers, Mark Dickey and Mark Ramsey, will remain on duty at this stage of the investigation.</content>
      <tokens>
        <token id="1" string="Although" lemma="although" stem="although" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="Long" lemma="Long" stem="long" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="Beach" lemma="Beach" stem="beach" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="Mayor" lemma="Mayor" stem="mayor" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="true" is_refers="false" />
        <token id="5" string="Ernie" lemma="Ernie" stem="ernie" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="6" string="Kell" lemma="Kell" stem="kell" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="7" string="told" lemma="tell" stem="told" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="NBC" lemma="NBC" stem="nbc" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="9" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Today" lemma="today" stem="todai" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="12" string="Show" lemma="show" stem="show" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="Tuesday" lemma="Tuesday" stem="tuesdai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="16" string="morning" lemma="morning" stem="morn" pos="NN" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="true" />
        <token id="17" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="20" string="police" lemma="police" stem="polic" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="suspended" lemma="suspend" stem="suspend" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="Police" lemma="Police" stem="polic" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="Chief" lemma="Chief" stem="chief" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="true" is_refers="false" />
        <token id="28" string="Lawrence" lemma="Lawrence" stem="lawrenc" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="29" string="L." lemma="L." stem="l." pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="30" string="Binkley" lemma="Binkley" stem="binklei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="31" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="Mark" lemma="Mark" stem="mark" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="37" string="Dickey" lemma="Dickey" stem="dickei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="38" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="Mark" lemma="Mark" stem="mark" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="40" string="Ramsey" lemma="Ramsey" stem="ramsei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="41" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="remain" lemma="remain" stem="remain" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="44" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="duty" lemma="duty" stem="duti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="46" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="47" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="48" string="stage" lemma="stage" stem="stage" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="49" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="50" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="51" string="investigation" lemma="investigation" stem="investig" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="52" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN Although) (S (NP (NNP Long) (NNP Beach) (NNP Mayor) (NNP Ernie) (NNP Kell)) (VP (VBD told) (NP (NP (NP (NNP NBC) (POS 's)) (`` ``) (NN Today) (NN Show) ('' '')) (PP (IN on) (NP (NNP Tuesday)))) (NP-TMP (NN morning)) (SBAR (IN that) (S (NP (DT the) (CD two) (NNS police) (NNS officers)) (VP (VBD had) (VP (VBN been) (VP (VBN suspended))))))))) (, ,) (NP (NNP Police) (NNP Chief) (NNP Lawrence) (NNP L.) (NNP Binkley)) (VP (VBD said) (SBAR (IN that) (S (NP (NP (DT the) (NNS officers)) (, ,) (NP (NP (NNP Mark) (NNP Dickey)) (CC and) (NP (NNP Mark) (NNP Ramsey))) (, ,)) (VP (MD will) (VP (VB remain) (PP (IN on) (NP (NN duty))) (PP (IN at) (NP (NP (DT this) (NN stage)) (PP (IN of) (NP (DT the) (NN investigation)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="told NBC 's `` Today Show '' on Tuesday morning that the two police officers had been suspended" type="VP">
          <tokens>
            <token id="7" string="told" />
            <token id="8" string="NBC" />
            <token id="9" string="'s" />
            <token id="10" string="&quot;" />
            <token id="11" string="Today" />
            <token id="12" string="Show" />
            <token id="13" string="&quot;" />
            <token id="14" string="on" />
            <token id="15" string="Tuesday" />
            <token id="16" string="morning" />
            <token id="17" string="that" />
            <token id="18" string="the" />
            <token id="19" string="two" />
            <token id="20" string="police" />
            <token id="21" string="officers" />
            <token id="22" string="had" />
            <token id="23" string="been" />
            <token id="24" string="suspended" />
          </tokens>
        </chunking>
        <chunking id="2" string="Long Beach Mayor Ernie Kell" type="NP">
          <tokens>
            <token id="2" string="Long" />
            <token id="3" string="Beach" />
            <token id="4" string="Mayor" />
            <token id="5" string="Ernie" />
            <token id="6" string="Kell" />
          </tokens>
        </chunking>
        <chunking id="3" string="NBC 's `` Today Show '' on Tuesday" type="NP">
          <tokens>
            <token id="8" string="NBC" />
            <token id="9" string="'s" />
            <token id="10" string="&quot;" />
            <token id="11" string="Today" />
            <token id="12" string="Show" />
            <token id="13" string="&quot;" />
            <token id="14" string="on" />
            <token id="15" string="Tuesday" />
          </tokens>
        </chunking>
        <chunking id="4" string="NBC 's `` Today Show ''" type="NP">
          <tokens>
            <token id="8" string="NBC" />
            <token id="9" string="'s" />
            <token id="10" string="&quot;" />
            <token id="11" string="Today" />
            <token id="12" string="Show" />
            <token id="13" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="5" string="Mark Dickey and Mark Ramsey" type="NP">
          <tokens>
            <token id="36" string="Mark" />
            <token id="37" string="Dickey" />
            <token id="38" string="and" />
            <token id="39" string="Mark" />
            <token id="40" string="Ramsey" />
          </tokens>
        </chunking>
        <chunking id="6" string="that the two police officers had been suspended" type="SBAR">
          <tokens>
            <token id="17" string="that" />
            <token id="18" string="the" />
            <token id="19" string="two" />
            <token id="20" string="police" />
            <token id="21" string="officers" />
            <token id="22" string="had" />
            <token id="23" string="been" />
            <token id="24" string="suspended" />
          </tokens>
        </chunking>
        <chunking id="7" string="remain on duty at this stage of the investigation" type="VP">
          <tokens>
            <token id="43" string="remain" />
            <token id="44" string="on" />
            <token id="45" string="duty" />
            <token id="46" string="at" />
            <token id="47" string="this" />
            <token id="48" string="stage" />
            <token id="49" string="of" />
            <token id="50" string="the" />
            <token id="51" string="investigation" />
          </tokens>
        </chunking>
        <chunking id="8" string="suspended" type="VP">
          <tokens>
            <token id="24" string="suspended" />
          </tokens>
        </chunking>
        <chunking id="9" string="Mark Dickey" type="NP">
          <tokens>
            <token id="36" string="Mark" />
            <token id="37" string="Dickey" />
          </tokens>
        </chunking>
        <chunking id="10" string="been suspended" type="VP">
          <tokens>
            <token id="23" string="been" />
            <token id="24" string="suspended" />
          </tokens>
        </chunking>
        <chunking id="11" string="Although Long Beach Mayor Ernie Kell told NBC 's `` Today Show '' on Tuesday morning that the two police officers had been suspended" type="SBAR">
          <tokens>
            <token id="1" string="Although" />
            <token id="2" string="Long" />
            <token id="3" string="Beach" />
            <token id="4" string="Mayor" />
            <token id="5" string="Ernie" />
            <token id="6" string="Kell" />
            <token id="7" string="told" />
            <token id="8" string="NBC" />
            <token id="9" string="'s" />
            <token id="10" string="&quot;" />
            <token id="11" string="Today" />
            <token id="12" string="Show" />
            <token id="13" string="&quot;" />
            <token id="14" string="on" />
            <token id="15" string="Tuesday" />
            <token id="16" string="morning" />
            <token id="17" string="that" />
            <token id="18" string="the" />
            <token id="19" string="two" />
            <token id="20" string="police" />
            <token id="21" string="officers" />
            <token id="22" string="had" />
            <token id="23" string="been" />
            <token id="24" string="suspended" />
          </tokens>
        </chunking>
        <chunking id="12" string="this stage" type="NP">
          <tokens>
            <token id="47" string="this" />
            <token id="48" string="stage" />
          </tokens>
        </chunking>
        <chunking id="13" string="the officers , Mark Dickey and Mark Ramsey ," type="NP">
          <tokens>
            <token id="33" string="the" />
            <token id="34" string="officers" />
            <token id="35" string="," />
            <token id="36" string="Mark" />
            <token id="37" string="Dickey" />
            <token id="38" string="and" />
            <token id="39" string="Mark" />
            <token id="40" string="Ramsey" />
            <token id="41" string="," />
          </tokens>
        </chunking>
        <chunking id="14" string="duty" type="NP">
          <tokens>
            <token id="45" string="duty" />
          </tokens>
        </chunking>
        <chunking id="15" string="had been suspended" type="VP">
          <tokens>
            <token id="22" string="had" />
            <token id="23" string="been" />
            <token id="24" string="suspended" />
          </tokens>
        </chunking>
        <chunking id="16" string="that the officers , Mark Dickey and Mark Ramsey , will remain on duty at this stage of the investigation" type="SBAR">
          <tokens>
            <token id="32" string="that" />
            <token id="33" string="the" />
            <token id="34" string="officers" />
            <token id="35" string="," />
            <token id="36" string="Mark" />
            <token id="37" string="Dickey" />
            <token id="38" string="and" />
            <token id="39" string="Mark" />
            <token id="40" string="Ramsey" />
            <token id="41" string="," />
            <token id="42" string="will" />
            <token id="43" string="remain" />
            <token id="44" string="on" />
            <token id="45" string="duty" />
            <token id="46" string="at" />
            <token id="47" string="this" />
            <token id="48" string="stage" />
            <token id="49" string="of" />
            <token id="50" string="the" />
            <token id="51" string="investigation" />
          </tokens>
        </chunking>
        <chunking id="17" string="this stage of the investigation" type="NP">
          <tokens>
            <token id="47" string="this" />
            <token id="48" string="stage" />
            <token id="49" string="of" />
            <token id="50" string="the" />
            <token id="51" string="investigation" />
          </tokens>
        </chunking>
        <chunking id="18" string="NBC 's" type="NP">
          <tokens>
            <token id="8" string="NBC" />
            <token id="9" string="'s" />
          </tokens>
        </chunking>
        <chunking id="19" string="Police Chief Lawrence L. Binkley" type="NP">
          <tokens>
            <token id="26" string="Police" />
            <token id="27" string="Chief" />
            <token id="28" string="Lawrence" />
            <token id="29" string="L." />
            <token id="30" string="Binkley" />
          </tokens>
        </chunking>
        <chunking id="20" string="Mark Ramsey" type="NP">
          <tokens>
            <token id="39" string="Mark" />
            <token id="40" string="Ramsey" />
          </tokens>
        </chunking>
        <chunking id="21" string="said that the officers , Mark Dickey and Mark Ramsey , will remain on duty at this stage of the investigation" type="VP">
          <tokens>
            <token id="31" string="said" />
            <token id="32" string="that" />
            <token id="33" string="the" />
            <token id="34" string="officers" />
            <token id="35" string="," />
            <token id="36" string="Mark" />
            <token id="37" string="Dickey" />
            <token id="38" string="and" />
            <token id="39" string="Mark" />
            <token id="40" string="Ramsey" />
            <token id="41" string="," />
            <token id="42" string="will" />
            <token id="43" string="remain" />
            <token id="44" string="on" />
            <token id="45" string="duty" />
            <token id="46" string="at" />
            <token id="47" string="this" />
            <token id="48" string="stage" />
            <token id="49" string="of" />
            <token id="50" string="the" />
            <token id="51" string="investigation" />
          </tokens>
        </chunking>
        <chunking id="22" string="the investigation" type="NP">
          <tokens>
            <token id="50" string="the" />
            <token id="51" string="investigation" />
          </tokens>
        </chunking>
        <chunking id="23" string="the two police officers" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="two" />
            <token id="20" string="police" />
            <token id="21" string="officers" />
          </tokens>
        </chunking>
        <chunking id="24" string="the officers" type="NP">
          <tokens>
            <token id="33" string="the" />
            <token id="34" string="officers" />
          </tokens>
        </chunking>
        <chunking id="25" string="Tuesday" type="NP">
          <tokens>
            <token id="15" string="Tuesday" />
          </tokens>
        </chunking>
        <chunking id="26" string="will remain on duty at this stage of the investigation" type="VP">
          <tokens>
            <token id="42" string="will" />
            <token id="43" string="remain" />
            <token id="44" string="on" />
            <token id="45" string="duty" />
            <token id="46" string="at" />
            <token id="47" string="this" />
            <token id="48" string="stage" />
            <token id="49" string="of" />
            <token id="50" string="the" />
            <token id="51" string="investigation" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="7">told</governor>
          <dependent id="1">Although</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Kell</governor>
          <dependent id="2">Long</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Kell</governor>
          <dependent id="3">Beach</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Kell</governor>
          <dependent id="4">Mayor</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Kell</governor>
          <dependent id="5">Ernie</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">told</governor>
          <dependent id="6">Kell</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="31">said</governor>
          <dependent id="7">told</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="12">Show</governor>
          <dependent id="8">NBC</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">NBC</governor>
          <dependent id="9">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Show</governor>
          <dependent id="11">Today</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">told</governor>
          <dependent id="12">Show</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">Tuesday</governor>
          <dependent id="14">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">Show</governor>
          <dependent id="15">Tuesday</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="7">told</governor>
          <dependent id="16">morning</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="24">suspended</governor>
          <dependent id="17">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">officers</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="21">officers</governor>
          <dependent id="19">two</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">officers</governor>
          <dependent id="20">police</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="24">suspended</governor>
          <dependent id="21">officers</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="24">suspended</governor>
          <dependent id="22">had</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="24">suspended</governor>
          <dependent id="23">been</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">told</governor>
          <dependent id="24">suspended</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="30">Binkley</governor>
          <dependent id="26">Police</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="30">Binkley</governor>
          <dependent id="27">Chief</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="30">Binkley</governor>
          <dependent id="28">Lawrence</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="30">Binkley</governor>
          <dependent id="29">L.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="31">said</governor>
          <dependent id="30">Binkley</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="31">said</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="43">remain</governor>
          <dependent id="32">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="34">officers</governor>
          <dependent id="33">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="43">remain</governor>
          <dependent id="34">officers</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="37">Dickey</governor>
          <dependent id="36">Mark</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="34">officers</governor>
          <dependent id="37">Dickey</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="37">Dickey</governor>
          <dependent id="38">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="40">Ramsey</governor>
          <dependent id="39">Mark</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="37">Dickey</governor>
          <dependent id="40">Ramsey</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="43">remain</governor>
          <dependent id="42">will</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="31">said</governor>
          <dependent id="43">remain</dependent>
        </dependency>
        <dependency type="case">
          <governor id="45">duty</governor>
          <dependent id="44">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="43">remain</governor>
          <dependent id="45">duty</dependent>
        </dependency>
        <dependency type="case">
          <governor id="48">stage</governor>
          <dependent id="46">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="48">stage</governor>
          <dependent id="47">this</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="43">remain</governor>
          <dependent id="48">stage</dependent>
        </dependency>
        <dependency type="case">
          <governor id="51">investigation</governor>
          <dependent id="49">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="51">investigation</governor>
          <dependent id="50">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="48">stage</governor>
          <dependent id="51">investigation</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lawrence L. Binkley" type="PERSON" score="0.0">
          <tokens>
            <token id="28" string="Lawrence" />
            <token id="29" string="L." />
            <token id="30" string="Binkley" />
          </tokens>
        </entity>
        <entity id="2" string="Today" type="DATE" score="0.0">
          <tokens>
            <token id="11" string="Today" />
          </tokens>
        </entity>
        <entity id="3" string="Chief" type="TITLE" score="0.0">
          <tokens>
            <token id="27" string="Chief" />
          </tokens>
        </entity>
        <entity id="4" string="Ernie Kell" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Ernie" />
            <token id="6" string="Kell" />
          </tokens>
        </entity>
        <entity id="5" string="morning" type="TIME" score="0.0">
          <tokens>
            <token id="16" string="morning" />
          </tokens>
        </entity>
        <entity id="6" string="Mark Ramsey" type="PERSON" score="0.0">
          <tokens>
            <token id="39" string="Mark" />
            <token id="40" string="Ramsey" />
          </tokens>
        </entity>
        <entity id="7" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="19" string="two" />
          </tokens>
        </entity>
        <entity id="8" string="Tuesday" type="DATE" score="0.0">
          <tokens>
            <token id="15" string="Tuesday" />
          </tokens>
        </entity>
        <entity id="9" string="Mayor" type="TITLE" score="0.0">
          <tokens>
            <token id="4" string="Mayor" />
          </tokens>
        </entity>
        <entity id="10" string="NBC" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="8" string="NBC" />
          </tokens>
        </entity>
        <entity id="11" string="Mark Dickey" type="PERSON" score="0.0">
          <tokens>
            <token id="36" string="Mark" />
            <token id="37" string="Dickey" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>They have, however, been reassigned from patrol duty to the detective bureau, he said.</content>
      <tokens>
        <token id="1" string="They" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="however" lemma="however" stem="howev" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="reassigned" lemma="reassign" stem="reassign" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="patrol" lemma="patrol" stem="patrol" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="duty" lemma="duty" stem="duti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="detective" lemma="detective" stem="detect" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="bureau" lemma="bureau" stem="bureau" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP They)) (VP (VBP have))) (, ,) (ADVP (RB however)) (, ,) (S (S (VP (VBN been) (VP (VBN reassigned) (PP (IN from) (NP (NN patrol) (NN duty))) (PP (TO to) (NP (DT the) (NN detective) (NN bureau)))))) (, ,) (NP (PRP he)) (VP (VBD said))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="They" type="NP">
          <tokens>
            <token id="1" string="They" />
          </tokens>
        </chunking>
        <chunking id="2" string="patrol duty" type="NP">
          <tokens>
            <token id="9" string="patrol" />
            <token id="10" string="duty" />
          </tokens>
        </chunking>
        <chunking id="3" string="the detective bureau" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="detective" />
            <token id="14" string="bureau" />
          </tokens>
        </chunking>
        <chunking id="4" string="have" type="VP">
          <tokens>
            <token id="2" string="have" />
          </tokens>
        </chunking>
        <chunking id="5" string="been reassigned from patrol duty to the detective bureau" type="VP">
          <tokens>
            <token id="6" string="been" />
            <token id="7" string="reassigned" />
            <token id="8" string="from" />
            <token id="9" string="patrol" />
            <token id="10" string="duty" />
            <token id="11" string="to" />
            <token id="12" string="the" />
            <token id="13" string="detective" />
            <token id="14" string="bureau" />
          </tokens>
        </chunking>
        <chunking id="6" string="reassigned from patrol duty to the detective bureau" type="VP">
          <tokens>
            <token id="7" string="reassigned" />
            <token id="8" string="from" />
            <token id="9" string="patrol" />
            <token id="10" string="duty" />
            <token id="11" string="to" />
            <token id="12" string="the" />
            <token id="13" string="detective" />
            <token id="14" string="bureau" />
          </tokens>
        </chunking>
        <chunking id="7" string="he" type="NP">
          <tokens>
            <token id="16" string="he" />
          </tokens>
        </chunking>
        <chunking id="8" string="said" type="VP">
          <tokens>
            <token id="17" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">have</governor>
          <dependent id="1">They</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">have</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="2">have</governor>
          <dependent id="4">however</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="7">reassigned</governor>
          <dependent id="6">been</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="17">said</governor>
          <dependent id="7">reassigned</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">duty</governor>
          <dependent id="8">from</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">duty</governor>
          <dependent id="9">patrol</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">reassigned</governor>
          <dependent id="10">duty</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">bureau</governor>
          <dependent id="11">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">bureau</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">bureau</governor>
          <dependent id="13">detective</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">reassigned</governor>
          <dependent id="14">bureau</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">said</governor>
          <dependent id="16">he</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="2">have</governor>
          <dependent id="17">said</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="17" has_coreference="true">
      <content>Kell admitted later Tuesday that he was in error in his &amp;quot;Today Show&amp;quot; comments, but said he would favor firing the officers if it is proved that they used brutal tactics in dealing with Jackson.</content>
      <tokens>
        <token id="1" string="Kell" lemma="Kell" stem="kell" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="admitted" lemma="admit" stem="admit" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="later" lemma="later" stem="later" pos="RBR" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="4" string="Tuesday" lemma="Tuesday" stem="tuesdai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="5" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="error" lemma="error" stem="error" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Today" lemma="today" stem="todai" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="14" string="Show" lemma="show" stem="show" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="comments" lemma="comment" stem="comment" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="favor" lemma="favor" stem="favor" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="firing" lemma="firing" stem="fire" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="26" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="proved" lemma="prove" stem="prove" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="32" string="used" lemma="use" stem="us" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="brutal" lemma="brutal" stem="brutal" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="tactics" lemma="tactic" stem="tactic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="dealing" lemma="deal" stem="deal" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="39" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Kell)) (VP (VP (VBD admitted) (ADVP (RBR later)) (NP-TMP (NNP Tuesday)) (SBAR (IN that) (S (NP (PRP he)) (VP (VBD was) (PP (IN in) (NP (NP (NN error)) (PP (IN in) (NP (NP (PRP$ his) (`` ``) (NN Today) (NN Show) ('' '')) (NP (NNS comments)))))))))) (, ,) (CC but) (VP (VBD said) (SBAR (S (NP (PRP he)) (VP (MD would) (VP (VB favor) (S (NP (NN firing)) (NP (DT the) (NNS officers)) (SBAR (IN if) (S (NP (PRP it)) (VP (VBZ is) (VP (VBN proved) (SBAR (IN that) (S (NP (PRP they)) (VP (VBD used) (NP (JJ brutal) (NNS tactics)) (PP (IN in) (S (VP (VBG dealing) (PP (IN with) (NP (NNP Jackson)))))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="is proved that they used brutal tactics in dealing with Jackson" type="VP">
          <tokens>
            <token id="28" string="is" />
            <token id="29" string="proved" />
            <token id="30" string="that" />
            <token id="31" string="they" />
            <token id="32" string="used" />
            <token id="33" string="brutal" />
            <token id="34" string="tactics" />
            <token id="35" string="in" />
            <token id="36" string="dealing" />
            <token id="37" string="with" />
            <token id="38" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="2" string="said he would favor firing the officers if it is proved that they used brutal tactics in dealing with Jackson" type="VP">
          <tokens>
            <token id="19" string="said" />
            <token id="20" string="he" />
            <token id="21" string="would" />
            <token id="22" string="favor" />
            <token id="23" string="firing" />
            <token id="24" string="the" />
            <token id="25" string="officers" />
            <token id="26" string="if" />
            <token id="27" string="it" />
            <token id="28" string="is" />
            <token id="29" string="proved" />
            <token id="30" string="that" />
            <token id="31" string="they" />
            <token id="32" string="used" />
            <token id="33" string="brutal" />
            <token id="34" string="tactics" />
            <token id="35" string="in" />
            <token id="36" string="dealing" />
            <token id="37" string="with" />
            <token id="38" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="3" string="comments" type="NP">
          <tokens>
            <token id="16" string="comments" />
          </tokens>
        </chunking>
        <chunking id="4" string="that they used brutal tactics in dealing with Jackson" type="SBAR">
          <tokens>
            <token id="30" string="that" />
            <token id="31" string="they" />
            <token id="32" string="used" />
            <token id="33" string="brutal" />
            <token id="34" string="tactics" />
            <token id="35" string="in" />
            <token id="36" string="dealing" />
            <token id="37" string="with" />
            <token id="38" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="5" string="it" type="NP">
          <tokens>
            <token id="27" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="dealing with Jackson" type="VP">
          <tokens>
            <token id="36" string="dealing" />
            <token id="37" string="with" />
            <token id="38" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="7" string="would favor firing the officers if it is proved that they used brutal tactics in dealing with Jackson" type="VP">
          <tokens>
            <token id="21" string="would" />
            <token id="22" string="favor" />
            <token id="23" string="firing" />
            <token id="24" string="the" />
            <token id="25" string="officers" />
            <token id="26" string="if" />
            <token id="27" string="it" />
            <token id="28" string="is" />
            <token id="29" string="proved" />
            <token id="30" string="that" />
            <token id="31" string="they" />
            <token id="32" string="used" />
            <token id="33" string="brutal" />
            <token id="34" string="tactics" />
            <token id="35" string="in" />
            <token id="36" string="dealing" />
            <token id="37" string="with" />
            <token id="38" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="8" string="firing" type="NP">
          <tokens>
            <token id="23" string="firing" />
          </tokens>
        </chunking>
        <chunking id="9" string="he" type="NP">
          <tokens>
            <token id="6" string="he" />
          </tokens>
        </chunking>
        <chunking id="10" string="admitted later Tuesday that he was in error in his `` Today Show '' comments , but said he would favor firing the officers if it is proved that they used brutal tactics in dealing with Jackson" type="VP">
          <tokens>
            <token id="2" string="admitted" />
            <token id="3" string="later" />
            <token id="4" string="Tuesday" />
            <token id="5" string="that" />
            <token id="6" string="he" />
            <token id="7" string="was" />
            <token id="8" string="in" />
            <token id="9" string="error" />
            <token id="10" string="in" />
            <token id="11" string="his" />
            <token id="12" string="&quot;" />
            <token id="13" string="Today" />
            <token id="14" string="Show" />
            <token id="15" string="&quot;" />
            <token id="16" string="comments" />
            <token id="17" string="," />
            <token id="18" string="but" />
            <token id="19" string="said" />
            <token id="20" string="he" />
            <token id="21" string="would" />
            <token id="22" string="favor" />
            <token id="23" string="firing" />
            <token id="24" string="the" />
            <token id="25" string="officers" />
            <token id="26" string="if" />
            <token id="27" string="it" />
            <token id="28" string="is" />
            <token id="29" string="proved" />
            <token id="30" string="that" />
            <token id="31" string="they" />
            <token id="32" string="used" />
            <token id="33" string="brutal" />
            <token id="34" string="tactics" />
            <token id="35" string="in" />
            <token id="36" string="dealing" />
            <token id="37" string="with" />
            <token id="38" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="11" string="favor firing the officers if it is proved that they used brutal tactics in dealing with Jackson" type="VP">
          <tokens>
            <token id="22" string="favor" />
            <token id="23" string="firing" />
            <token id="24" string="the" />
            <token id="25" string="officers" />
            <token id="26" string="if" />
            <token id="27" string="it" />
            <token id="28" string="is" />
            <token id="29" string="proved" />
            <token id="30" string="that" />
            <token id="31" string="they" />
            <token id="32" string="used" />
            <token id="33" string="brutal" />
            <token id="34" string="tactics" />
            <token id="35" string="in" />
            <token id="36" string="dealing" />
            <token id="37" string="with" />
            <token id="38" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="12" string="error" type="NP">
          <tokens>
            <token id="9" string="error" />
          </tokens>
        </chunking>
        <chunking id="13" string="admitted later Tuesday that he was in error in his `` Today Show '' comments" type="VP">
          <tokens>
            <token id="2" string="admitted" />
            <token id="3" string="later" />
            <token id="4" string="Tuesday" />
            <token id="5" string="that" />
            <token id="6" string="he" />
            <token id="7" string="was" />
            <token id="8" string="in" />
            <token id="9" string="error" />
            <token id="10" string="in" />
            <token id="11" string="his" />
            <token id="12" string="&quot;" />
            <token id="13" string="Today" />
            <token id="14" string="Show" />
            <token id="15" string="&quot;" />
            <token id="16" string="comments" />
          </tokens>
        </chunking>
        <chunking id="14" string="his `` Today Show ''" type="NP">
          <tokens>
            <token id="11" string="his" />
            <token id="12" string="&quot;" />
            <token id="13" string="Today" />
            <token id="14" string="Show" />
            <token id="15" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="15" string="proved that they used brutal tactics in dealing with Jackson" type="VP">
          <tokens>
            <token id="29" string="proved" />
            <token id="30" string="that" />
            <token id="31" string="they" />
            <token id="32" string="used" />
            <token id="33" string="brutal" />
            <token id="34" string="tactics" />
            <token id="35" string="in" />
            <token id="36" string="dealing" />
            <token id="37" string="with" />
            <token id="38" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="16" string="if it is proved that they used brutal tactics in dealing with Jackson" type="SBAR">
          <tokens>
            <token id="26" string="if" />
            <token id="27" string="it" />
            <token id="28" string="is" />
            <token id="29" string="proved" />
            <token id="30" string="that" />
            <token id="31" string="they" />
            <token id="32" string="used" />
            <token id="33" string="brutal" />
            <token id="34" string="tactics" />
            <token id="35" string="in" />
            <token id="36" string="dealing" />
            <token id="37" string="with" />
            <token id="38" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="17" string="Jackson" type="NP">
          <tokens>
            <token id="38" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="18" string="error in his `` Today Show '' comments" type="NP">
          <tokens>
            <token id="9" string="error" />
            <token id="10" string="in" />
            <token id="11" string="his" />
            <token id="12" string="&quot;" />
            <token id="13" string="Today" />
            <token id="14" string="Show" />
            <token id="15" string="&quot;" />
            <token id="16" string="comments" />
          </tokens>
        </chunking>
        <chunking id="19" string="used brutal tactics in dealing with Jackson" type="VP">
          <tokens>
            <token id="32" string="used" />
            <token id="33" string="brutal" />
            <token id="34" string="tactics" />
            <token id="35" string="in" />
            <token id="36" string="dealing" />
            <token id="37" string="with" />
            <token id="38" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="20" string="they" type="NP">
          <tokens>
            <token id="31" string="they" />
          </tokens>
        </chunking>
        <chunking id="21" string="that he was in error in his `` Today Show '' comments" type="SBAR">
          <tokens>
            <token id="5" string="that" />
            <token id="6" string="he" />
            <token id="7" string="was" />
            <token id="8" string="in" />
            <token id="9" string="error" />
            <token id="10" string="in" />
            <token id="11" string="his" />
            <token id="12" string="&quot;" />
            <token id="13" string="Today" />
            <token id="14" string="Show" />
            <token id="15" string="&quot;" />
            <token id="16" string="comments" />
          </tokens>
        </chunking>
        <chunking id="22" string="his `` Today Show '' comments" type="NP">
          <tokens>
            <token id="11" string="his" />
            <token id="12" string="&quot;" />
            <token id="13" string="Today" />
            <token id="14" string="Show" />
            <token id="15" string="&quot;" />
            <token id="16" string="comments" />
          </tokens>
        </chunking>
        <chunking id="23" string="brutal tactics" type="NP">
          <tokens>
            <token id="33" string="brutal" />
            <token id="34" string="tactics" />
          </tokens>
        </chunking>
        <chunking id="24" string="Kell" type="NP">
          <tokens>
            <token id="1" string="Kell" />
          </tokens>
        </chunking>
        <chunking id="25" string="was in error in his `` Today Show '' comments" type="VP">
          <tokens>
            <token id="7" string="was" />
            <token id="8" string="in" />
            <token id="9" string="error" />
            <token id="10" string="in" />
            <token id="11" string="his" />
            <token id="12" string="&quot;" />
            <token id="13" string="Today" />
            <token id="14" string="Show" />
            <token id="15" string="&quot;" />
            <token id="16" string="comments" />
          </tokens>
        </chunking>
        <chunking id="26" string="he would favor firing the officers if it is proved that they used brutal tactics in dealing with Jackson" type="SBAR">
          <tokens>
            <token id="20" string="he" />
            <token id="21" string="would" />
            <token id="22" string="favor" />
            <token id="23" string="firing" />
            <token id="24" string="the" />
            <token id="25" string="officers" />
            <token id="26" string="if" />
            <token id="27" string="it" />
            <token id="28" string="is" />
            <token id="29" string="proved" />
            <token id="30" string="that" />
            <token id="31" string="they" />
            <token id="32" string="used" />
            <token id="33" string="brutal" />
            <token id="34" string="tactics" />
            <token id="35" string="in" />
            <token id="36" string="dealing" />
            <token id="37" string="with" />
            <token id="38" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="27" string="the officers" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="officers" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">admitted</governor>
          <dependent id="1">Kell</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">admitted</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="2">admitted</governor>
          <dependent id="3">later</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="2">admitted</governor>
          <dependent id="4">Tuesday</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">error</governor>
          <dependent id="5">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">error</governor>
          <dependent id="6">he</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="9">error</governor>
          <dependent id="7">was</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">error</governor>
          <dependent id="8">in</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">admitted</governor>
          <dependent id="9">error</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">Show</governor>
          <dependent id="10">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="14">Show</governor>
          <dependent id="11">his</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Show</governor>
          <dependent id="13">Today</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">error</governor>
          <dependent id="14">Show</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="14">Show</governor>
          <dependent id="16">comments</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">admitted</governor>
          <dependent id="18">but</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">admitted</governor>
          <dependent id="19">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">favor</governor>
          <dependent id="20">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="22">favor</governor>
          <dependent id="21">would</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="19">said</governor>
          <dependent id="22">favor</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="29">proved</governor>
          <dependent id="23">firing</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">officers</governor>
          <dependent id="24">the</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="29">proved</governor>
          <dependent id="25">officers</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="29">proved</governor>
          <dependent id="26">if</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="29">proved</governor>
          <dependent id="27">it</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="29">proved</governor>
          <dependent id="28">is</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="22">favor</governor>
          <dependent id="29">proved</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="32">used</governor>
          <dependent id="30">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="32">used</governor>
          <dependent id="31">they</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="29">proved</governor>
          <dependent id="32">used</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="34">tactics</governor>
          <dependent id="33">brutal</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="32">used</governor>
          <dependent id="34">tactics</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="36">dealing</governor>
          <dependent id="35">in</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="32">used</governor>
          <dependent id="36">dealing</dependent>
        </dependency>
        <dependency type="case">
          <governor id="38">Jackson</governor>
          <dependent id="37">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="36">dealing</governor>
          <dependent id="38">Jackson</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Today" type="DATE" score="0.0">
          <tokens>
            <token id="13" string="Today" />
          </tokens>
        </entity>
        <entity id="2" string="Kell" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Kell" />
          </tokens>
        </entity>
        <entity id="3" string="Jackson" type="PERSON" score="0.0">
          <tokens>
            <token id="38" string="Jackson" />
          </tokens>
        </entity>
        <entity id="4" string="later Tuesday" type="DATE" score="0.0">
          <tokens>
            <token id="3" string="later" />
            <token id="4" string="Tuesday" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="18" has_coreference="true">
      <content>Called &amp;apost;Unfortunate&amp;apost; At Tuesday&amp;apost;s City Council meeting, the mayor called the incident &amp;quot;an unfortunate set of circumstances.</content>
      <tokens>
        <token id="1" string="Called" lemma="call" stem="call" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="'" lemma="`" stem="'" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Unfortunate" lemma="Unfortunate" stem="unfortun" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="At" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Tuesday" lemma="Tuesday" stem="tuesdai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="7" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="City" lemma="City" stem="citi" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="9" string="Council" lemma="Council" stem="council" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="10" string="meeting" lemma="meeting" stem="meet" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="mayor" lemma="mayor" stem="mayor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="called" lemma="call" stem="call" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="incident" lemma="incident" stem="incid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="unfortunate" lemma="unfortunate" stem="unfortun" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="set" lemma="set" stem="set" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="circumstances" lemma="circumstance" stem="circumst" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (VBN Called) (S (`` `) (NP (NNP Unfortunate)) ('' ') (PP (IN At) (NP (NP (NNP Tuesday) (POS 's)) (NNP City) (NNP Council) (NN meeting)))))) (, ,) (NP (DT the) (NN mayor)) (VP (VBD called) (S (NP (DT the) (NN incident)) (`` ``) (NP (NP (DT an) (ADJP (JJ unfortunate)) (NN set)) (PP (IN of) (NP (NNS circumstances)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Tuesday 's City Council meeting" type="NP">
          <tokens>
            <token id="6" string="Tuesday" />
            <token id="7" string="'s" />
            <token id="8" string="City" />
            <token id="9" string="Council" />
            <token id="10" string="meeting" />
          </tokens>
        </chunking>
        <chunking id="2" string="an unfortunate set of circumstances" type="NP">
          <tokens>
            <token id="18" string="an" />
            <token id="19" string="unfortunate" />
            <token id="20" string="set" />
            <token id="21" string="of" />
            <token id="22" string="circumstances" />
          </tokens>
        </chunking>
        <chunking id="3" string="the mayor" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="mayor" />
          </tokens>
        </chunking>
        <chunking id="4" string="unfortunate" type="ADJP">
          <tokens>
            <token id="19" string="unfortunate" />
          </tokens>
        </chunking>
        <chunking id="5" string="Unfortunate" type="NP">
          <tokens>
            <token id="3" string="Unfortunate" />
          </tokens>
        </chunking>
        <chunking id="6" string="circumstances" type="NP">
          <tokens>
            <token id="22" string="circumstances" />
          </tokens>
        </chunking>
        <chunking id="7" string="called the incident `` an unfortunate set of circumstances" type="VP">
          <tokens>
            <token id="14" string="called" />
            <token id="15" string="the" />
            <token id="16" string="incident" />
            <token id="17" string="&quot;" />
            <token id="18" string="an" />
            <token id="19" string="unfortunate" />
            <token id="20" string="set" />
            <token id="21" string="of" />
            <token id="22" string="circumstances" />
          </tokens>
        </chunking>
        <chunking id="8" string="an unfortunate set" type="NP">
          <tokens>
            <token id="18" string="an" />
            <token id="19" string="unfortunate" />
            <token id="20" string="set" />
          </tokens>
        </chunking>
        <chunking id="9" string="Tuesday 's" type="NP">
          <tokens>
            <token id="6" string="Tuesday" />
            <token id="7" string="'s" />
          </tokens>
        </chunking>
        <chunking id="10" string="Called ` Unfortunate ' At Tuesday 's City Council meeting" type="VP">
          <tokens>
            <token id="1" string="Called" />
            <token id="2" string="'" />
            <token id="3" string="Unfortunate" />
            <token id="4" string="'" />
            <token id="5" string="At" />
            <token id="6" string="Tuesday" />
            <token id="7" string="'s" />
            <token id="8" string="City" />
            <token id="9" string="Council" />
            <token id="10" string="meeting" />
          </tokens>
        </chunking>
        <chunking id="11" string="the incident" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="incident" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advcl">
          <governor id="14">called</governor>
          <dependent id="1">Called</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="1">Called</governor>
          <dependent id="3">Unfortunate</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">meeting</governor>
          <dependent id="5">At</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="10">meeting</governor>
          <dependent id="6">Tuesday</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">Tuesday</governor>
          <dependent id="7">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">meeting</governor>
          <dependent id="8">City</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">meeting</governor>
          <dependent id="9">Council</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="3">Unfortunate</governor>
          <dependent id="10">meeting</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">mayor</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">called</governor>
          <dependent id="13">mayor</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">called</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">incident</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="20">set</governor>
          <dependent id="16">incident</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">set</governor>
          <dependent id="18">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">set</governor>
          <dependent id="19">unfortunate</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="14">called</governor>
          <dependent id="20">set</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">circumstances</governor>
          <dependent id="21">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">set</governor>
          <dependent id="22">circumstances</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Tuesday" type="DATE" score="0.0">
          <tokens>
            <token id="6" string="Tuesday" />
          </tokens>
        </entity>
        <entity id="2" string="City Council" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="8" string="City" />
            <token id="9" string="Council" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="19" has_coreference="true">
      <content>We will not tolerate this. . . .</content>
      <tokens>
        <token id="1" string="We" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="tolerate" lemma="tolerate" stem="toler" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string=". . ." lemma="..." stem=". . ." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP We)) (VP (MD will) (RB not) (VP (VB tolerate) (NP (DT this)))) (: ...) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="tolerate this" type="VP">
          <tokens>
            <token id="4" string="tolerate" />
            <token id="5" string="this" />
          </tokens>
        </chunking>
        <chunking id="2" string="will not tolerate this" type="VP">
          <tokens>
            <token id="2" string="will" />
            <token id="3" string="not" />
            <token id="4" string="tolerate" />
            <token id="5" string="this" />
          </tokens>
        </chunking>
        <chunking id="3" string="this" type="NP">
          <tokens>
            <token id="5" string="this" />
          </tokens>
        </chunking>
        <chunking id="4" string="We" type="NP">
          <tokens>
            <token id="1" string="We" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">tolerate</governor>
          <dependent id="1">We</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">tolerate</governor>
          <dependent id="2">will</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="4">tolerate</governor>
          <dependent id="3">not</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">tolerate</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">tolerate</governor>
          <dependent id="5">this</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="20" has_coreference="true">
      <content>We need to find out what happened here and make sure it never happens again.&amp;quot;</content>
      <tokens>
        <token id="1" string="We" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="need" lemma="need" stem="need" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="find" lemma="find" stem="find" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="happened" lemma="happen" stem="happen" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="here" lemma="here" stem="here" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="make" lemma="make" stem="make" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="sure" lemma="sure" stem="sure" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="happens" lemma="happen" stem="happen" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="again" lemma="again" stem="again" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP We)) (VP (VBP need) (S (VP (TO to) (VP (VP (VB find) (PRT (RP out)) (SBAR (WHNP (WP what)) (S (VP (VBD happened) (ADVP (RB here)))))) (CC and) (VP (VB make) (ADJP (JJ sure) (SBAR (S (NP (PRP it)) (ADVP (RB never)) (VP (VBZ happens) (ADVP (RB again))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="to find out what happened here and make sure it never happens again" type="VP">
          <tokens>
            <token id="3" string="to" />
            <token id="4" string="find" />
            <token id="5" string="out" />
            <token id="6" string="what" />
            <token id="7" string="happened" />
            <token id="8" string="here" />
            <token id="9" string="and" />
            <token id="10" string="make" />
            <token id="11" string="sure" />
            <token id="12" string="it" />
            <token id="13" string="never" />
            <token id="14" string="happens" />
            <token id="15" string="again" />
          </tokens>
        </chunking>
        <chunking id="2" string="find out what happened here and make sure it never happens again" type="VP">
          <tokens>
            <token id="4" string="find" />
            <token id="5" string="out" />
            <token id="6" string="what" />
            <token id="7" string="happened" />
            <token id="8" string="here" />
            <token id="9" string="and" />
            <token id="10" string="make" />
            <token id="11" string="sure" />
            <token id="12" string="it" />
            <token id="13" string="never" />
            <token id="14" string="happens" />
            <token id="15" string="again" />
          </tokens>
        </chunking>
        <chunking id="3" string="find out what happened here" type="VP">
          <tokens>
            <token id="4" string="find" />
            <token id="5" string="out" />
            <token id="6" string="what" />
            <token id="7" string="happened" />
            <token id="8" string="here" />
          </tokens>
        </chunking>
        <chunking id="4" string="need to find out what happened here and make sure it never happens again" type="VP">
          <tokens>
            <token id="2" string="need" />
            <token id="3" string="to" />
            <token id="4" string="find" />
            <token id="5" string="out" />
            <token id="6" string="what" />
            <token id="7" string="happened" />
            <token id="8" string="here" />
            <token id="9" string="and" />
            <token id="10" string="make" />
            <token id="11" string="sure" />
            <token id="12" string="it" />
            <token id="13" string="never" />
            <token id="14" string="happens" />
            <token id="15" string="again" />
          </tokens>
        </chunking>
        <chunking id="5" string="happened here" type="VP">
          <tokens>
            <token id="7" string="happened" />
            <token id="8" string="here" />
          </tokens>
        </chunking>
        <chunking id="6" string="what happened here" type="SBAR">
          <tokens>
            <token id="6" string="what" />
            <token id="7" string="happened" />
            <token id="8" string="here" />
          </tokens>
        </chunking>
        <chunking id="7" string="happens again" type="VP">
          <tokens>
            <token id="14" string="happens" />
            <token id="15" string="again" />
          </tokens>
        </chunking>
        <chunking id="8" string="make sure it never happens again" type="VP">
          <tokens>
            <token id="10" string="make" />
            <token id="11" string="sure" />
            <token id="12" string="it" />
            <token id="13" string="never" />
            <token id="14" string="happens" />
            <token id="15" string="again" />
          </tokens>
        </chunking>
        <chunking id="9" string="it" type="NP">
          <tokens>
            <token id="12" string="it" />
          </tokens>
        </chunking>
        <chunking id="10" string="sure it never happens again" type="ADJP">
          <tokens>
            <token id="11" string="sure" />
            <token id="12" string="it" />
            <token id="13" string="never" />
            <token id="14" string="happens" />
            <token id="15" string="again" />
          </tokens>
        </chunking>
        <chunking id="11" string="We" type="NP">
          <tokens>
            <token id="1" string="We" />
          </tokens>
        </chunking>
        <chunking id="12" string="it never happens again" type="SBAR">
          <tokens>
            <token id="12" string="it" />
            <token id="13" string="never" />
            <token id="14" string="happens" />
            <token id="15" string="again" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">need</governor>
          <dependent id="1">We</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">need</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="4">find</governor>
          <dependent id="3">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="2">need</governor>
          <dependent id="4">find</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="4">find</governor>
          <dependent id="5">out</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">happened</governor>
          <dependent id="6">what</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">find</governor>
          <dependent id="7">happened</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">happened</governor>
          <dependent id="8">here</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">find</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">find</governor>
          <dependent id="10">make</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="10">make</governor>
          <dependent id="11">sure</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">happens</governor>
          <dependent id="12">it</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="14">happens</governor>
          <dependent id="13">never</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">sure</governor>
          <dependent id="14">happens</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">happens</governor>
          <dependent id="15">again</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="21" has_coreference="true">
      <content>An investigation by the district attorney will add credibility to the city&amp;apost;s own consideration of the brutality allegations, Kell said.</content>
      <tokens>
        <token id="1" string="An" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="investigation" lemma="investigation" stem="investig" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="district" lemma="district" stem="district" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="attorney" lemma="attorney" stem="attornei" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="add" lemma="add" stem="add" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="credibility" lemma="credibility" stem="credibl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="city" lemma="city" stem="citi" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="own" lemma="own" stem="own" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="consideration" lemma="consideration" stem="consider" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="brutality" lemma="brutality" stem="brutal" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="allegations" lemma="allegation" stem="alleg" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="Kell" lemma="Kell" stem="kell" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="22" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (DT An) (NN investigation)) (PP (IN by) (NP (DT the) (NN district) (NN attorney)))) (VP (MD will) (VP (VB add) (NP (NN credibility)) (PP (TO to) (NP (NP (NP (DT the) (NN city) (POS 's)) (JJ own) (NN consideration)) (PP (IN of) (NP (DT the) (NN brutality) (NNS allegations)))))))) (, ,) (NP (NNP Kell)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the city 's own consideration of the brutality allegations" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="city" />
            <token id="13" string="'s" />
            <token id="14" string="own" />
            <token id="15" string="consideration" />
            <token id="16" string="of" />
            <token id="17" string="the" />
            <token id="18" string="brutality" />
            <token id="19" string="allegations" />
          </tokens>
        </chunking>
        <chunking id="2" string="An investigation by the district attorney" type="NP">
          <tokens>
            <token id="1" string="An" />
            <token id="2" string="investigation" />
            <token id="3" string="by" />
            <token id="4" string="the" />
            <token id="5" string="district" />
            <token id="6" string="attorney" />
          </tokens>
        </chunking>
        <chunking id="3" string="the district attorney" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="district" />
            <token id="6" string="attorney" />
          </tokens>
        </chunking>
        <chunking id="4" string="add credibility to the city 's own consideration of the brutality allegations" type="VP">
          <tokens>
            <token id="8" string="add" />
            <token id="9" string="credibility" />
            <token id="10" string="to" />
            <token id="11" string="the" />
            <token id="12" string="city" />
            <token id="13" string="'s" />
            <token id="14" string="own" />
            <token id="15" string="consideration" />
            <token id="16" string="of" />
            <token id="17" string="the" />
            <token id="18" string="brutality" />
            <token id="19" string="allegations" />
          </tokens>
        </chunking>
        <chunking id="5" string="the brutality allegations" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="brutality" />
            <token id="19" string="allegations" />
          </tokens>
        </chunking>
        <chunking id="6" string="Kell" type="NP">
          <tokens>
            <token id="21" string="Kell" />
          </tokens>
        </chunking>
        <chunking id="7" string="An investigation" type="NP">
          <tokens>
            <token id="1" string="An" />
            <token id="2" string="investigation" />
          </tokens>
        </chunking>
        <chunking id="8" string="will add credibility to the city 's own consideration of the brutality allegations" type="VP">
          <tokens>
            <token id="7" string="will" />
            <token id="8" string="add" />
            <token id="9" string="credibility" />
            <token id="10" string="to" />
            <token id="11" string="the" />
            <token id="12" string="city" />
            <token id="13" string="'s" />
            <token id="14" string="own" />
            <token id="15" string="consideration" />
            <token id="16" string="of" />
            <token id="17" string="the" />
            <token id="18" string="brutality" />
            <token id="19" string="allegations" />
          </tokens>
        </chunking>
        <chunking id="9" string="credibility" type="NP">
          <tokens>
            <token id="9" string="credibility" />
          </tokens>
        </chunking>
        <chunking id="10" string="the city 's own consideration" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="city" />
            <token id="13" string="'s" />
            <token id="14" string="own" />
            <token id="15" string="consideration" />
          </tokens>
        </chunking>
        <chunking id="11" string="the city 's" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="city" />
            <token id="13" string="'s" />
          </tokens>
        </chunking>
        <chunking id="12" string="said" type="VP">
          <tokens>
            <token id="22" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">investigation</governor>
          <dependent id="1">An</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">add</governor>
          <dependent id="2">investigation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">attorney</governor>
          <dependent id="3">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">attorney</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">attorney</governor>
          <dependent id="5">district</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">investigation</governor>
          <dependent id="6">attorney</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">add</governor>
          <dependent id="7">will</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="22">said</governor>
          <dependent id="8">add</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">add</governor>
          <dependent id="9">credibility</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">consideration</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">city</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="15">consideration</governor>
          <dependent id="12">city</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">city</governor>
          <dependent id="13">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">consideration</governor>
          <dependent id="14">own</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">add</governor>
          <dependent id="15">consideration</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">allegations</governor>
          <dependent id="16">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">allegations</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">allegations</governor>
          <dependent id="18">brutality</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">consideration</governor>
          <dependent id="19">allegations</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">said</governor>
          <dependent id="21">Kell</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="22">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Kell" type="PERSON" score="0.0">
          <tokens>
            <token id="21" string="Kell" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="22" has_coreference="true">
      <content>It is not unusual for the district attorney to look into allegations of police brutality, Livesay said, estimating that the office takes on four to six such cases a year.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="unusual" lemma="unusual" stem="unusu" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="district" lemma="district" stem="district" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="attorney" lemma="attorney" stem="attornei" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="look" lemma="look" stem="look" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="allegations" lemma="allegation" stem="alleg" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="brutality" lemma="brutality" stem="brutal" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Livesay" lemma="Livesay" stem="livesai" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="18" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="estimating" lemma="estimate" stem="estim" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="office" lemma="office" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="24" string="takes" lemma="take" stem="take" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="on" lemma="on" stem="on" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="four" lemma="four" stem="four" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="27" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="six" lemma="six" stem="six" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="29" string="such" lemma="such" stem="such" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="cases" lemma="case" stem="case" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="32" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP It)) (VP (VBZ is) (RB not) (ADJP (JJ unusual) (PP (IN for) (NP (DT the) (NN district) (NN attorney)))) (S (VP (TO to) (VP (VB look) (PP (IN into) (NP (NP (NNS allegations)) (PP (IN of) (NP (NN police) (NN brutality)))))))))) (, ,) (NP (NNP Livesay)) (VP (VBD said) (, ,) (S (VP (VBG estimating) (SBAR (IN that) (S (NP (DT the) (NN office)) (VP (VBZ takes) (PRT (RP on)) (NP (NP (QP (CD four) (TO to) (CD six)) (JJ such) (NNS cases)) (NP (DT a) (NN year))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="four to six such cases a year" type="NP">
          <tokens>
            <token id="26" string="four" />
            <token id="27" string="to" />
            <token id="28" string="six" />
            <token id="29" string="such" />
            <token id="30" string="cases" />
            <token id="31" string="a" />
            <token id="32" string="year" />
          </tokens>
        </chunking>
        <chunking id="2" string="the office" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="office" />
          </tokens>
        </chunking>
        <chunking id="3" string="is not unusual for the district attorney to look into allegations of police brutality" type="VP">
          <tokens>
            <token id="2" string="is" />
            <token id="3" string="not" />
            <token id="4" string="unusual" />
            <token id="5" string="for" />
            <token id="6" string="the" />
            <token id="7" string="district" />
            <token id="8" string="attorney" />
            <token id="9" string="to" />
            <token id="10" string="look" />
            <token id="11" string="into" />
            <token id="12" string="allegations" />
            <token id="13" string="of" />
            <token id="14" string="police" />
            <token id="15" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="4" string="the district attorney" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="district" />
            <token id="8" string="attorney" />
          </tokens>
        </chunking>
        <chunking id="5" string="estimating that the office takes on four to six such cases a year" type="VP">
          <tokens>
            <token id="20" string="estimating" />
            <token id="21" string="that" />
            <token id="22" string="the" />
            <token id="23" string="office" />
            <token id="24" string="takes" />
            <token id="25" string="on" />
            <token id="26" string="four" />
            <token id="27" string="to" />
            <token id="28" string="six" />
            <token id="29" string="such" />
            <token id="30" string="cases" />
            <token id="31" string="a" />
            <token id="32" string="year" />
          </tokens>
        </chunking>
        <chunking id="6" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="7" string="Livesay" type="NP">
          <tokens>
            <token id="17" string="Livesay" />
          </tokens>
        </chunking>
        <chunking id="8" string="unusual for the district attorney" type="ADJP">
          <tokens>
            <token id="4" string="unusual" />
            <token id="5" string="for" />
            <token id="6" string="the" />
            <token id="7" string="district" />
            <token id="8" string="attorney" />
          </tokens>
        </chunking>
        <chunking id="9" string="said , estimating that the office takes on four to six such cases a year" type="VP">
          <tokens>
            <token id="18" string="said" />
            <token id="19" string="," />
            <token id="20" string="estimating" />
            <token id="21" string="that" />
            <token id="22" string="the" />
            <token id="23" string="office" />
            <token id="24" string="takes" />
            <token id="25" string="on" />
            <token id="26" string="four" />
            <token id="27" string="to" />
            <token id="28" string="six" />
            <token id="29" string="such" />
            <token id="30" string="cases" />
            <token id="31" string="a" />
            <token id="32" string="year" />
          </tokens>
        </chunking>
        <chunking id="10" string="look into allegations of police brutality" type="VP">
          <tokens>
            <token id="10" string="look" />
            <token id="11" string="into" />
            <token id="12" string="allegations" />
            <token id="13" string="of" />
            <token id="14" string="police" />
            <token id="15" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="11" string="allegations" type="NP">
          <tokens>
            <token id="12" string="allegations" />
          </tokens>
        </chunking>
        <chunking id="12" string="takes on four to six such cases a year" type="VP">
          <tokens>
            <token id="24" string="takes" />
            <token id="25" string="on" />
            <token id="26" string="four" />
            <token id="27" string="to" />
            <token id="28" string="six" />
            <token id="29" string="such" />
            <token id="30" string="cases" />
            <token id="31" string="a" />
            <token id="32" string="year" />
          </tokens>
        </chunking>
        <chunking id="13" string="four to six such cases" type="NP">
          <tokens>
            <token id="26" string="four" />
            <token id="27" string="to" />
            <token id="28" string="six" />
            <token id="29" string="such" />
            <token id="30" string="cases" />
          </tokens>
        </chunking>
        <chunking id="14" string="to look into allegations of police brutality" type="VP">
          <tokens>
            <token id="9" string="to" />
            <token id="10" string="look" />
            <token id="11" string="into" />
            <token id="12" string="allegations" />
            <token id="13" string="of" />
            <token id="14" string="police" />
            <token id="15" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="15" string="police brutality" type="NP">
          <tokens>
            <token id="14" string="police" />
            <token id="15" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="16" string="a year" type="NP">
          <tokens>
            <token id="31" string="a" />
            <token id="32" string="year" />
          </tokens>
        </chunking>
        <chunking id="17" string="that the office takes on four to six such cases a year" type="SBAR">
          <tokens>
            <token id="21" string="that" />
            <token id="22" string="the" />
            <token id="23" string="office" />
            <token id="24" string="takes" />
            <token id="25" string="on" />
            <token id="26" string="four" />
            <token id="27" string="to" />
            <token id="28" string="six" />
            <token id="29" string="such" />
            <token id="30" string="cases" />
            <token id="31" string="a" />
            <token id="32" string="year" />
          </tokens>
        </chunking>
        <chunking id="18" string="allegations of police brutality" type="NP">
          <tokens>
            <token id="12" string="allegations" />
            <token id="13" string="of" />
            <token id="14" string="police" />
            <token id="15" string="brutality" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">unusual</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">unusual</governor>
          <dependent id="2">is</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="4">unusual</governor>
          <dependent id="3">not</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="18">said</governor>
          <dependent id="4">unusual</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">attorney</governor>
          <dependent id="5">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">attorney</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">attorney</governor>
          <dependent id="7">district</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">unusual</governor>
          <dependent id="8">attorney</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">look</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">unusual</governor>
          <dependent id="10">look</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">allegations</governor>
          <dependent id="11">into</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">look</governor>
          <dependent id="12">allegations</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">brutality</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">brutality</governor>
          <dependent id="14">police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">allegations</governor>
          <dependent id="15">brutality</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">said</governor>
          <dependent id="17">Livesay</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="18">said</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="18">said</governor>
          <dependent id="20">estimating</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="24">takes</governor>
          <dependent id="21">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">office</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">takes</governor>
          <dependent id="23">office</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="20">estimating</governor>
          <dependent id="24">takes</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="24">takes</governor>
          <dependent id="25">on</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">six</governor>
          <dependent id="26">four</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="28">six</governor>
          <dependent id="27">to</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="30">cases</governor>
          <dependent id="28">six</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="30">cases</governor>
          <dependent id="29">such</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="24">takes</governor>
          <dependent id="30">cases</dependent>
        </dependency>
        <dependency type="det">
          <governor id="32">year</governor>
          <dependent id="31">a</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="30">cases</governor>
          <dependent id="32">year</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="six" type="NUMBER" score="0.0">
          <tokens>
            <token id="28" string="six" />
          </tokens>
        </entity>
        <entity id="2" string="four" type="NUMBER" score="0.0">
          <tokens>
            <token id="26" string="four" />
          </tokens>
        </entity>
        <entity id="3" string="Livesay" type="PERSON" score="0.0">
          <tokens>
            <token id="17" string="Livesay" />
          </tokens>
        </entity>
        <entity id="4" string="a year" type="DURATION" score="0.0">
          <tokens>
            <token id="31" string="a" />
            <token id="32" string="year" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="23" has_coreference="true">
      <content>In determining whether a police officer has used excessive force, prosecutors have to decide whether the officer acted &amp;quot;without lawful necessity&amp;quot; in assaulting or beating a suspect.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="determining" lemma="determine" stem="determin" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="whether" lemma="whether" stem="whether" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="officer" lemma="officer" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="used" lemma="use" stem="us" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="excessive" lemma="excessive" stem="excess" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="force" lemma="force" stem="forc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="prosecutors" lemma="prosecutor" stem="prosecutor" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="decide" lemma="decide" stem="decid" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="whether" lemma="whether" stem="whether" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="officer" lemma="officer" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="acted" lemma="act" stem="act" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="without" lemma="without" stem="without" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="lawful" lemma="lawful" stem="law" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="necessity" lemma="necessity" stem="necess" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="assaulting" lemma="assault" stem="assault" pos="VBG" type="Word" isStopWord="false" ner="CRIMINAL_CHARGE" is_referenced="false" is_refers="false" />
        <token id="27" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="beating" lemma="beat" stem="beat" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="suspect" lemma="suspect" stem="suspect" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (S (VP (VBG determining) (SBAR (IN whether) (S (NP (DT a) (NN police) (NN officer)) (VP (VBZ has) (VP (VBN used) (NP (JJ excessive) (NN force))))))))) (, ,) (NP (NNS prosecutors)) (VP (VBP have) (S (VP (TO to) (VP (VB decide) (SBAR (IN whether) (S (NP (DT the) (NN officer)) (VP (VBD acted) (`` ``) (PP (IN without) (NP (JJ lawful) (NN necessity))) ('' '') (PP (IN in) (S (VP (VBG assaulting) (CC or) (VBG beating) (NP (DT a) (NN suspect)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="decide whether the officer acted `` without lawful necessity '' in assaulting or beating a suspect" type="VP">
          <tokens>
            <token id="15" string="decide" />
            <token id="16" string="whether" />
            <token id="17" string="the" />
            <token id="18" string="officer" />
            <token id="19" string="acted" />
            <token id="20" string="&quot;" />
            <token id="21" string="without" />
            <token id="22" string="lawful" />
            <token id="23" string="necessity" />
            <token id="24" string="&quot;" />
            <token id="25" string="in" />
            <token id="26" string="assaulting" />
            <token id="27" string="or" />
            <token id="28" string="beating" />
            <token id="29" string="a" />
            <token id="30" string="suspect" />
          </tokens>
        </chunking>
        <chunking id="2" string="determining whether a police officer has used excessive force" type="VP">
          <tokens>
            <token id="2" string="determining" />
            <token id="3" string="whether" />
            <token id="4" string="a" />
            <token id="5" string="police" />
            <token id="6" string="officer" />
            <token id="7" string="has" />
            <token id="8" string="used" />
            <token id="9" string="excessive" />
            <token id="10" string="force" />
          </tokens>
        </chunking>
        <chunking id="3" string="whether the officer acted `` without lawful necessity '' in assaulting or beating a suspect" type="SBAR">
          <tokens>
            <token id="16" string="whether" />
            <token id="17" string="the" />
            <token id="18" string="officer" />
            <token id="19" string="acted" />
            <token id="20" string="&quot;" />
            <token id="21" string="without" />
            <token id="22" string="lawful" />
            <token id="23" string="necessity" />
            <token id="24" string="&quot;" />
            <token id="25" string="in" />
            <token id="26" string="assaulting" />
            <token id="27" string="or" />
            <token id="28" string="beating" />
            <token id="29" string="a" />
            <token id="30" string="suspect" />
          </tokens>
        </chunking>
        <chunking id="4" string="to decide whether the officer acted `` without lawful necessity '' in assaulting or beating a suspect" type="VP">
          <tokens>
            <token id="14" string="to" />
            <token id="15" string="decide" />
            <token id="16" string="whether" />
            <token id="17" string="the" />
            <token id="18" string="officer" />
            <token id="19" string="acted" />
            <token id="20" string="&quot;" />
            <token id="21" string="without" />
            <token id="22" string="lawful" />
            <token id="23" string="necessity" />
            <token id="24" string="&quot;" />
            <token id="25" string="in" />
            <token id="26" string="assaulting" />
            <token id="27" string="or" />
            <token id="28" string="beating" />
            <token id="29" string="a" />
            <token id="30" string="suspect" />
          </tokens>
        </chunking>
        <chunking id="5" string="a suspect" type="NP">
          <tokens>
            <token id="29" string="a" />
            <token id="30" string="suspect" />
          </tokens>
        </chunking>
        <chunking id="6" string="the officer" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="officer" />
          </tokens>
        </chunking>
        <chunking id="7" string="excessive force" type="NP">
          <tokens>
            <token id="9" string="excessive" />
            <token id="10" string="force" />
          </tokens>
        </chunking>
        <chunking id="8" string="used excessive force" type="VP">
          <tokens>
            <token id="8" string="used" />
            <token id="9" string="excessive" />
            <token id="10" string="force" />
          </tokens>
        </chunking>
        <chunking id="9" string="prosecutors" type="NP">
          <tokens>
            <token id="12" string="prosecutors" />
          </tokens>
        </chunking>
        <chunking id="10" string="assaulting or beating a suspect" type="VP">
          <tokens>
            <token id="26" string="assaulting" />
            <token id="27" string="or" />
            <token id="28" string="beating" />
            <token id="29" string="a" />
            <token id="30" string="suspect" />
          </tokens>
        </chunking>
        <chunking id="11" string="whether a police officer has used excessive force" type="SBAR">
          <tokens>
            <token id="3" string="whether" />
            <token id="4" string="a" />
            <token id="5" string="police" />
            <token id="6" string="officer" />
            <token id="7" string="has" />
            <token id="8" string="used" />
            <token id="9" string="excessive" />
            <token id="10" string="force" />
          </tokens>
        </chunking>
        <chunking id="12" string="have to decide whether the officer acted `` without lawful necessity '' in assaulting or beating a suspect" type="VP">
          <tokens>
            <token id="13" string="have" />
            <token id="14" string="to" />
            <token id="15" string="decide" />
            <token id="16" string="whether" />
            <token id="17" string="the" />
            <token id="18" string="officer" />
            <token id="19" string="acted" />
            <token id="20" string="&quot;" />
            <token id="21" string="without" />
            <token id="22" string="lawful" />
            <token id="23" string="necessity" />
            <token id="24" string="&quot;" />
            <token id="25" string="in" />
            <token id="26" string="assaulting" />
            <token id="27" string="or" />
            <token id="28" string="beating" />
            <token id="29" string="a" />
            <token id="30" string="suspect" />
          </tokens>
        </chunking>
        <chunking id="13" string="lawful necessity" type="NP">
          <tokens>
            <token id="22" string="lawful" />
            <token id="23" string="necessity" />
          </tokens>
        </chunking>
        <chunking id="14" string="a police officer" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="police" />
            <token id="6" string="officer" />
          </tokens>
        </chunking>
        <chunking id="15" string="has used excessive force" type="VP">
          <tokens>
            <token id="7" string="has" />
            <token id="8" string="used" />
            <token id="9" string="excessive" />
            <token id="10" string="force" />
          </tokens>
        </chunking>
        <chunking id="16" string="acted `` without lawful necessity '' in assaulting or beating a suspect" type="VP">
          <tokens>
            <token id="19" string="acted" />
            <token id="20" string="&quot;" />
            <token id="21" string="without" />
            <token id="22" string="lawful" />
            <token id="23" string="necessity" />
            <token id="24" string="&quot;" />
            <token id="25" string="in" />
            <token id="26" string="assaulting" />
            <token id="27" string="or" />
            <token id="28" string="beating" />
            <token id="29" string="a" />
            <token id="30" string="suspect" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="2">determining</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="13">have</governor>
          <dependent id="2">determining</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">used</governor>
          <dependent id="3">whether</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">officer</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">officer</governor>
          <dependent id="5">police</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">used</governor>
          <dependent id="6">officer</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">used</governor>
          <dependent id="7">has</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">determining</governor>
          <dependent id="8">used</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">force</governor>
          <dependent id="9">excessive</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">used</governor>
          <dependent id="10">force</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">have</governor>
          <dependent id="12">prosecutors</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">have</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">decide</governor>
          <dependent id="14">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="13">have</governor>
          <dependent id="15">decide</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">acted</governor>
          <dependent id="16">whether</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">officer</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">acted</governor>
          <dependent id="18">officer</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="15">decide</governor>
          <dependent id="19">acted</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">necessity</governor>
          <dependent id="21">without</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">necessity</governor>
          <dependent id="22">lawful</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">acted</governor>
          <dependent id="23">necessity</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="26">assaulting</governor>
          <dependent id="25">in</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="19">acted</governor>
          <dependent id="26">assaulting</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="26">assaulting</governor>
          <dependent id="27">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="26">assaulting</governor>
          <dependent id="28">beating</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">suspect</governor>
          <dependent id="29">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="26">assaulting</governor>
          <dependent id="30">suspect</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="assaulting" type="CRIMINAL_CHARGE" score="0.0">
          <tokens>
            <token id="26" string="assaulting" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="24" has_coreference="true">
      <content>He declined to detail what would constitute unnecessary force, saying that it would be a &amp;quot;judgement call&amp;quot; by prosecutors based on the actions and statements of the police officers and suspects, and the injuries suffered.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="declined" lemma="decline" stem="declin" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="detail" lemma="detail" stem="detail" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="what" lemma="what" stem="what" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="constitute" lemma="constitute" stem="constitut" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="unnecessary" lemma="unnecessary" stem="unnecessari" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="force" lemma="force" stem="forc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="saying" lemma="say" stem="sai" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="judgement" lemma="judgement" stem="judgement" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="call" lemma="call" stem="call" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="prosecutors" lemma="prosecutor" stem="prosecutor" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="based" lemma="base" stem="base" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="25" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="26" string="actions" lemma="action" stem="action" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="27" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="28" string="statements" lemma="statement" stem="statement" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="29" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="30" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="31" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="32" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="33" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="34" string="suspects" lemma="suspect" stem="suspect" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="35" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="injuries" lemma="injury" stem="injuri" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="suffered" lemma="suffer" stem="suffer" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP He)) (VP (VBD declined) (PP (TO to) (NP (NP (NN detail)) (SBAR (WHNP (WDT what)) (S (VP (MD would) (VP (VB constitute) (NP (JJ unnecessary) (NN force)))))))) (, ,) (S (VP (VBG saying) (SBAR (IN that) (S (NP (PRP it)) (VP (MD would) (VP (VB be) (NP (NP (DT a) (`` ``) (NN judgement) (NN call) ('' '')) (PP (IN by) (NP (NP (NNS prosecutors)) (VP (VBN based) (PP (IN on) (NP (NP (DT the) (NNS actions) (CC and) (NNS statements)) (PP (IN of) (NP (DT the) (NN police) (NNS officers) (CC and) (NNS suspects))))))))))))))))) (, ,) (CC and) (S (NP (DT the) (NNS injuries)) (VP (VBD suffered))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="prosecutors based on the actions and statements of the police officers and suspects" type="NP">
          <tokens>
            <token id="22" string="prosecutors" />
            <token id="23" string="based" />
            <token id="24" string="on" />
            <token id="25" string="the" />
            <token id="26" string="actions" />
            <token id="27" string="and" />
            <token id="28" string="statements" />
            <token id="29" string="of" />
            <token id="30" string="the" />
            <token id="31" string="police" />
            <token id="32" string="officers" />
            <token id="33" string="and" />
            <token id="34" string="suspects" />
          </tokens>
        </chunking>
        <chunking id="2" string="based on the actions and statements of the police officers and suspects" type="VP">
          <tokens>
            <token id="23" string="based" />
            <token id="24" string="on" />
            <token id="25" string="the" />
            <token id="26" string="actions" />
            <token id="27" string="and" />
            <token id="28" string="statements" />
            <token id="29" string="of" />
            <token id="30" string="the" />
            <token id="31" string="police" />
            <token id="32" string="officers" />
            <token id="33" string="and" />
            <token id="34" string="suspects" />
          </tokens>
        </chunking>
        <chunking id="3" string="would be a `` judgement call '' by prosecutors based on the actions and statements of the police officers and suspects" type="VP">
          <tokens>
            <token id="14" string="would" />
            <token id="15" string="be" />
            <token id="16" string="a" />
            <token id="17" string="&quot;" />
            <token id="18" string="judgement" />
            <token id="19" string="call" />
            <token id="20" string="&quot;" />
            <token id="21" string="by" />
            <token id="22" string="prosecutors" />
            <token id="23" string="based" />
            <token id="24" string="on" />
            <token id="25" string="the" />
            <token id="26" string="actions" />
            <token id="27" string="and" />
            <token id="28" string="statements" />
            <token id="29" string="of" />
            <token id="30" string="the" />
            <token id="31" string="police" />
            <token id="32" string="officers" />
            <token id="33" string="and" />
            <token id="34" string="suspects" />
          </tokens>
        </chunking>
        <chunking id="4" string="unnecessary force" type="NP">
          <tokens>
            <token id="8" string="unnecessary" />
            <token id="9" string="force" />
          </tokens>
        </chunking>
        <chunking id="5" string="saying that it would be a `` judgement call '' by prosecutors based on the actions and statements of the police officers and suspects" type="VP">
          <tokens>
            <token id="11" string="saying" />
            <token id="12" string="that" />
            <token id="13" string="it" />
            <token id="14" string="would" />
            <token id="15" string="be" />
            <token id="16" string="a" />
            <token id="17" string="&quot;" />
            <token id="18" string="judgement" />
            <token id="19" string="call" />
            <token id="20" string="&quot;" />
            <token id="21" string="by" />
            <token id="22" string="prosecutors" />
            <token id="23" string="based" />
            <token id="24" string="on" />
            <token id="25" string="the" />
            <token id="26" string="actions" />
            <token id="27" string="and" />
            <token id="28" string="statements" />
            <token id="29" string="of" />
            <token id="30" string="the" />
            <token id="31" string="police" />
            <token id="32" string="officers" />
            <token id="33" string="and" />
            <token id="34" string="suspects" />
          </tokens>
        </chunking>
        <chunking id="6" string="it" type="NP">
          <tokens>
            <token id="13" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="would constitute unnecessary force" type="VP">
          <tokens>
            <token id="6" string="would" />
            <token id="7" string="constitute" />
            <token id="8" string="unnecessary" />
            <token id="9" string="force" />
          </tokens>
        </chunking>
        <chunking id="8" string="be a `` judgement call '' by prosecutors based on the actions and statements of the police officers and suspects" type="VP">
          <tokens>
            <token id="15" string="be" />
            <token id="16" string="a" />
            <token id="17" string="&quot;" />
            <token id="18" string="judgement" />
            <token id="19" string="call" />
            <token id="20" string="&quot;" />
            <token id="21" string="by" />
            <token id="22" string="prosecutors" />
            <token id="23" string="based" />
            <token id="24" string="on" />
            <token id="25" string="the" />
            <token id="26" string="actions" />
            <token id="27" string="and" />
            <token id="28" string="statements" />
            <token id="29" string="of" />
            <token id="30" string="the" />
            <token id="31" string="police" />
            <token id="32" string="officers" />
            <token id="33" string="and" />
            <token id="34" string="suspects" />
          </tokens>
        </chunking>
        <chunking id="9" string="prosecutors" type="NP">
          <tokens>
            <token id="22" string="prosecutors" />
          </tokens>
        </chunking>
        <chunking id="10" string="that it would be a `` judgement call '' by prosecutors based on the actions and statements of the police officers and suspects" type="SBAR">
          <tokens>
            <token id="12" string="that" />
            <token id="13" string="it" />
            <token id="14" string="would" />
            <token id="15" string="be" />
            <token id="16" string="a" />
            <token id="17" string="&quot;" />
            <token id="18" string="judgement" />
            <token id="19" string="call" />
            <token id="20" string="&quot;" />
            <token id="21" string="by" />
            <token id="22" string="prosecutors" />
            <token id="23" string="based" />
            <token id="24" string="on" />
            <token id="25" string="the" />
            <token id="26" string="actions" />
            <token id="27" string="and" />
            <token id="28" string="statements" />
            <token id="29" string="of" />
            <token id="30" string="the" />
            <token id="31" string="police" />
            <token id="32" string="officers" />
            <token id="33" string="and" />
            <token id="34" string="suspects" />
          </tokens>
        </chunking>
        <chunking id="11" string="detail what would constitute unnecessary force" type="NP">
          <tokens>
            <token id="4" string="detail" />
            <token id="5" string="what" />
            <token id="6" string="would" />
            <token id="7" string="constitute" />
            <token id="8" string="unnecessary" />
            <token id="9" string="force" />
          </tokens>
        </chunking>
        <chunking id="12" string="a `` judgement call ''" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="&quot;" />
            <token id="18" string="judgement" />
            <token id="19" string="call" />
            <token id="20" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="13" string="constitute unnecessary force" type="VP">
          <tokens>
            <token id="7" string="constitute" />
            <token id="8" string="unnecessary" />
            <token id="9" string="force" />
          </tokens>
        </chunking>
        <chunking id="14" string="suffered" type="VP">
          <tokens>
            <token id="39" string="suffered" />
          </tokens>
        </chunking>
        <chunking id="15" string="detail" type="NP">
          <tokens>
            <token id="4" string="detail" />
          </tokens>
        </chunking>
        <chunking id="16" string="what would constitute unnecessary force" type="SBAR">
          <tokens>
            <token id="5" string="what" />
            <token id="6" string="would" />
            <token id="7" string="constitute" />
            <token id="8" string="unnecessary" />
            <token id="9" string="force" />
          </tokens>
        </chunking>
        <chunking id="17" string="the actions and statements" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="actions" />
            <token id="27" string="and" />
            <token id="28" string="statements" />
          </tokens>
        </chunking>
        <chunking id="18" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="19" string="declined to detail what would constitute unnecessary force , saying that it would be a `` judgement call '' by prosecutors based on the actions and statements of the police officers and suspects" type="VP">
          <tokens>
            <token id="2" string="declined" />
            <token id="3" string="to" />
            <token id="4" string="detail" />
            <token id="5" string="what" />
            <token id="6" string="would" />
            <token id="7" string="constitute" />
            <token id="8" string="unnecessary" />
            <token id="9" string="force" />
            <token id="10" string="," />
            <token id="11" string="saying" />
            <token id="12" string="that" />
            <token id="13" string="it" />
            <token id="14" string="would" />
            <token id="15" string="be" />
            <token id="16" string="a" />
            <token id="17" string="&quot;" />
            <token id="18" string="judgement" />
            <token id="19" string="call" />
            <token id="20" string="&quot;" />
            <token id="21" string="by" />
            <token id="22" string="prosecutors" />
            <token id="23" string="based" />
            <token id="24" string="on" />
            <token id="25" string="the" />
            <token id="26" string="actions" />
            <token id="27" string="and" />
            <token id="28" string="statements" />
            <token id="29" string="of" />
            <token id="30" string="the" />
            <token id="31" string="police" />
            <token id="32" string="officers" />
            <token id="33" string="and" />
            <token id="34" string="suspects" />
          </tokens>
        </chunking>
        <chunking id="20" string="the injuries" type="NP">
          <tokens>
            <token id="37" string="the" />
            <token id="38" string="injuries" />
          </tokens>
        </chunking>
        <chunking id="21" string="the actions and statements of the police officers and suspects" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="actions" />
            <token id="27" string="and" />
            <token id="28" string="statements" />
            <token id="29" string="of" />
            <token id="30" string="the" />
            <token id="31" string="police" />
            <token id="32" string="officers" />
            <token id="33" string="and" />
            <token id="34" string="suspects" />
          </tokens>
        </chunking>
        <chunking id="22" string="a `` judgement call '' by prosecutors based on the actions and statements of the police officers and suspects" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="&quot;" />
            <token id="18" string="judgement" />
            <token id="19" string="call" />
            <token id="20" string="&quot;" />
            <token id="21" string="by" />
            <token id="22" string="prosecutors" />
            <token id="23" string="based" />
            <token id="24" string="on" />
            <token id="25" string="the" />
            <token id="26" string="actions" />
            <token id="27" string="and" />
            <token id="28" string="statements" />
            <token id="29" string="of" />
            <token id="30" string="the" />
            <token id="31" string="police" />
            <token id="32" string="officers" />
            <token id="33" string="and" />
            <token id="34" string="suspects" />
          </tokens>
        </chunking>
        <chunking id="23" string="the police officers and suspects" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="police" />
            <token id="32" string="officers" />
            <token id="33" string="and" />
            <token id="34" string="suspects" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">declined</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">declined</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">detail</governor>
          <dependent id="3">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">declined</governor>
          <dependent id="4">detail</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">constitute</governor>
          <dependent id="5">what</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">constitute</governor>
          <dependent id="6">would</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="4">detail</governor>
          <dependent id="7">constitute</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">force</governor>
          <dependent id="8">unnecessary</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">constitute</governor>
          <dependent id="9">force</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="2">declined</governor>
          <dependent id="11">saying</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">call</governor>
          <dependent id="12">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">call</governor>
          <dependent id="13">it</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="19">call</governor>
          <dependent id="14">would</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="19">call</governor>
          <dependent id="15">be</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">call</governor>
          <dependent id="16">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">call</governor>
          <dependent id="18">judgement</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">saying</governor>
          <dependent id="19">call</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">prosecutors</governor>
          <dependent id="21">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">call</governor>
          <dependent id="22">prosecutors</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="22">prosecutors</governor>
          <dependent id="23">based</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">actions</governor>
          <dependent id="24">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">actions</governor>
          <dependent id="25">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">based</governor>
          <dependent id="26">actions</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="26">actions</governor>
          <dependent id="27">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="26">actions</governor>
          <dependent id="28">statements</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">officers</governor>
          <dependent id="29">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="32">officers</governor>
          <dependent id="30">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="32">officers</governor>
          <dependent id="31">police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">actions</governor>
          <dependent id="32">officers</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="32">officers</governor>
          <dependent id="33">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="32">officers</governor>
          <dependent id="34">suspects</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">declined</governor>
          <dependent id="36">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="38">injuries</governor>
          <dependent id="37">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="39">suffered</governor>
          <dependent id="38">injuries</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">declined</governor>
          <dependent id="39">suffered</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="25" has_coreference="true">
      <content>Attorney Michael Hannon, who is representing the two officers, said Tuesday that he will contest any allegations of brutality.</content>
      <tokens>
        <token id="1" string="Attorney" lemma="Attorney" stem="attornei" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="true" is_refers="false" />
        <token id="2" string="Michael" lemma="Michael" stem="michael" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="Hannon" lemma="Hannon" stem="hannon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="representing" lemma="represent" stem="repres" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="true" />
        <token id="10" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="Tuesday" lemma="Tuesday" stem="tuesdai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="14" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="contest" lemma="contest" stem="contest" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="any" lemma="any" stem="ani" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="allegations" lemma="allegation" stem="alleg" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="brutality" lemma="brutality" stem="brutal" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Attorney) (NNP Michael) (NNP Hannon)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBZ is) (VP (VBG representing) (NP (DT the) (CD two) (NNS officers)))))) (, ,)) (VP (VBD said) (NP-TMP (NNP Tuesday)) (SBAR (IN that) (S (NP (PRP he)) (VP (MD will) (VP (VB contest) (NP (NP (DT any) (NNS allegations)) (PP (IN of) (NP (NN brutality))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="that he will contest any allegations of brutality" type="SBAR">
          <tokens>
            <token id="14" string="that" />
            <token id="15" string="he" />
            <token id="16" string="will" />
            <token id="17" string="contest" />
            <token id="18" string="any" />
            <token id="19" string="allegations" />
            <token id="20" string="of" />
            <token id="21" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="2" string="is representing the two officers" type="VP">
          <tokens>
            <token id="6" string="is" />
            <token id="7" string="representing" />
            <token id="8" string="the" />
            <token id="9" string="two" />
            <token id="10" string="officers" />
          </tokens>
        </chunking>
        <chunking id="3" string="will contest any allegations of brutality" type="VP">
          <tokens>
            <token id="16" string="will" />
            <token id="17" string="contest" />
            <token id="18" string="any" />
            <token id="19" string="allegations" />
            <token id="20" string="of" />
            <token id="21" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="4" string="who is representing the two officers" type="SBAR">
          <tokens>
            <token id="5" string="who" />
            <token id="6" string="is" />
            <token id="7" string="representing" />
            <token id="8" string="the" />
            <token id="9" string="two" />
            <token id="10" string="officers" />
          </tokens>
        </chunking>
        <chunking id="5" string="any allegations" type="NP">
          <tokens>
            <token id="18" string="any" />
            <token id="19" string="allegations" />
          </tokens>
        </chunking>
        <chunking id="6" string="the two officers" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="two" />
            <token id="10" string="officers" />
          </tokens>
        </chunking>
        <chunking id="7" string="any allegations of brutality" type="NP">
          <tokens>
            <token id="18" string="any" />
            <token id="19" string="allegations" />
            <token id="20" string="of" />
            <token id="21" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="8" string="contest any allegations of brutality" type="VP">
          <tokens>
            <token id="17" string="contest" />
            <token id="18" string="any" />
            <token id="19" string="allegations" />
            <token id="20" string="of" />
            <token id="21" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="9" string="Attorney Michael Hannon" type="NP">
          <tokens>
            <token id="1" string="Attorney" />
            <token id="2" string="Michael" />
            <token id="3" string="Hannon" />
          </tokens>
        </chunking>
        <chunking id="10" string="he" type="NP">
          <tokens>
            <token id="15" string="he" />
          </tokens>
        </chunking>
        <chunking id="11" string="Attorney Michael Hannon , who is representing the two officers ," type="NP">
          <tokens>
            <token id="1" string="Attorney" />
            <token id="2" string="Michael" />
            <token id="3" string="Hannon" />
            <token id="4" string="," />
            <token id="5" string="who" />
            <token id="6" string="is" />
            <token id="7" string="representing" />
            <token id="8" string="the" />
            <token id="9" string="two" />
            <token id="10" string="officers" />
            <token id="11" string="," />
          </tokens>
        </chunking>
        <chunking id="12" string="said Tuesday that he will contest any allegations of brutality" type="VP">
          <tokens>
            <token id="12" string="said" />
            <token id="13" string="Tuesday" />
            <token id="14" string="that" />
            <token id="15" string="he" />
            <token id="16" string="will" />
            <token id="17" string="contest" />
            <token id="18" string="any" />
            <token id="19" string="allegations" />
            <token id="20" string="of" />
            <token id="21" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="13" string="brutality" type="NP">
          <tokens>
            <token id="21" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="14" string="representing the two officers" type="VP">
          <tokens>
            <token id="7" string="representing" />
            <token id="8" string="the" />
            <token id="9" string="two" />
            <token id="10" string="officers" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">Hannon</governor>
          <dependent id="1">Attorney</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Hannon</governor>
          <dependent id="2">Michael</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">said</governor>
          <dependent id="3">Hannon</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">representing</governor>
          <dependent id="5">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">representing</governor>
          <dependent id="6">is</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="3">Hannon</governor>
          <dependent id="7">representing</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">officers</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="10">officers</governor>
          <dependent id="9">two</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">representing</governor>
          <dependent id="10">officers</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">said</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="12">said</governor>
          <dependent id="13">Tuesday</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">contest</governor>
          <dependent id="14">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">contest</governor>
          <dependent id="15">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="17">contest</governor>
          <dependent id="16">will</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="12">said</governor>
          <dependent id="17">contest</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">allegations</governor>
          <dependent id="18">any</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">contest</governor>
          <dependent id="19">allegations</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">brutality</governor>
          <dependent id="20">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">allegations</governor>
          <dependent id="21">brutality</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Michael Hannon" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Michael" />
            <token id="3" string="Hannon" />
          </tokens>
        </entity>
        <entity id="2" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="9" string="two" />
          </tokens>
        </entity>
        <entity id="3" string="Tuesday" type="DATE" score="0.0">
          <tokens>
            <token id="13" string="Tuesday" />
          </tokens>
        </entity>
        <entity id="4" string="Attorney" type="TITLE" score="0.0">
          <tokens>
            <token id="1" string="Attorney" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="26" has_coreference="true">
      <content>He said the officers were &amp;quot;set up&amp;quot; by black activists intent on creating a scene with police.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="set" lemma="set" stem="set" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="black" lemma="black" stem="black" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="activists" lemma="activist" stem="activist" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="intent" lemma="intent" stem="intent" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="creating" lemma="create" stem="creat" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="scene" lemma="scene" stem="scene" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VBD said) (SBAR (S (NP (DT the) (NNS officers)) (VP (VBD were) (`` ``) (VP (VBN set) (PRT (RP up)) ('' '') (PP (IN by) (NP (NP (JJ black) (NNS activists) (NN intent)) (PP (IN on) (S (VP (VBG creating) (NP (DT a) (NN scene)) (PP (IN with) (NP (NN police))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="police" type="NP">
          <tokens>
            <token id="19" string="police" />
          </tokens>
        </chunking>
        <chunking id="2" string="said the officers were `` set up '' by black activists intent on creating a scene with police" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="the" />
            <token id="4" string="officers" />
            <token id="5" string="were" />
            <token id="6" string="&quot;" />
            <token id="7" string="set" />
            <token id="8" string="up" />
            <token id="9" string="&quot;" />
            <token id="10" string="by" />
            <token id="11" string="black" />
            <token id="12" string="activists" />
            <token id="13" string="intent" />
            <token id="14" string="on" />
            <token id="15" string="creating" />
            <token id="16" string="a" />
            <token id="17" string="scene" />
            <token id="18" string="with" />
            <token id="19" string="police" />
          </tokens>
        </chunking>
        <chunking id="3" string="were `` set up '' by black activists intent on creating a scene with police" type="VP">
          <tokens>
            <token id="5" string="were" />
            <token id="6" string="&quot;" />
            <token id="7" string="set" />
            <token id="8" string="up" />
            <token id="9" string="&quot;" />
            <token id="10" string="by" />
            <token id="11" string="black" />
            <token id="12" string="activists" />
            <token id="13" string="intent" />
            <token id="14" string="on" />
            <token id="15" string="creating" />
            <token id="16" string="a" />
            <token id="17" string="scene" />
            <token id="18" string="with" />
            <token id="19" string="police" />
          </tokens>
        </chunking>
        <chunking id="4" string="the officers were `` set up '' by black activists intent on creating a scene with police" type="SBAR">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="officers" />
            <token id="5" string="were" />
            <token id="6" string="&quot;" />
            <token id="7" string="set" />
            <token id="8" string="up" />
            <token id="9" string="&quot;" />
            <token id="10" string="by" />
            <token id="11" string="black" />
            <token id="12" string="activists" />
            <token id="13" string="intent" />
            <token id="14" string="on" />
            <token id="15" string="creating" />
            <token id="16" string="a" />
            <token id="17" string="scene" />
            <token id="18" string="with" />
            <token id="19" string="police" />
          </tokens>
        </chunking>
        <chunking id="5" string="creating a scene with police" type="VP">
          <tokens>
            <token id="15" string="creating" />
            <token id="16" string="a" />
            <token id="17" string="scene" />
            <token id="18" string="with" />
            <token id="19" string="police" />
          </tokens>
        </chunking>
        <chunking id="6" string="a scene" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="scene" />
          </tokens>
        </chunking>
        <chunking id="7" string="set up '' by black activists intent on creating a scene with police" type="VP">
          <tokens>
            <token id="7" string="set" />
            <token id="8" string="up" />
            <token id="9" string="&quot;" />
            <token id="10" string="by" />
            <token id="11" string="black" />
            <token id="12" string="activists" />
            <token id="13" string="intent" />
            <token id="14" string="on" />
            <token id="15" string="creating" />
            <token id="16" string="a" />
            <token id="17" string="scene" />
            <token id="18" string="with" />
            <token id="19" string="police" />
          </tokens>
        </chunking>
        <chunking id="8" string="the officers" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="officers" />
          </tokens>
        </chunking>
        <chunking id="9" string="black activists intent" type="NP">
          <tokens>
            <token id="11" string="black" />
            <token id="12" string="activists" />
            <token id="13" string="intent" />
          </tokens>
        </chunking>
        <chunking id="10" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="11" string="black activists intent on creating a scene with police" type="NP">
          <tokens>
            <token id="11" string="black" />
            <token id="12" string="activists" />
            <token id="13" string="intent" />
            <token id="14" string="on" />
            <token id="15" string="creating" />
            <token id="16" string="a" />
            <token id="17" string="scene" />
            <token id="18" string="with" />
            <token id="19" string="police" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">officers</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="7">set</governor>
          <dependent id="4">officers</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="7">set</governor>
          <dependent id="5">were</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="7">set</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="7">set</governor>
          <dependent id="8">up</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">intent</governor>
          <dependent id="10">by</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">intent</governor>
          <dependent id="11">black</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">intent</governor>
          <dependent id="12">activists</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">set</governor>
          <dependent id="13">intent</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">creating</governor>
          <dependent id="14">on</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="13">intent</governor>
          <dependent id="15">creating</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">scene</governor>
          <dependent id="16">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">creating</governor>
          <dependent id="17">scene</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">police</governor>
          <dependent id="18">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">creating</governor>
          <dependent id="19">police</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="27" has_coreference="true">
      <content>Police Have No Comment In a statement released a day after the incident, Long Beach police said that Jackson&amp;apost;s and Hill&amp;apost;s sedan was pulled over for weaving across the center line of the highway.</content>
      <tokens>
        <token id="1" string="Police" lemma="police" stem="polic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="2" string="Have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="No" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Comment" lemma="comment" stem="comment" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="statement" lemma="statement" stem="statement" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="released" lemma="release" stem="releas" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="10" string="day" lemma="day" stem="dai" pos="NN" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="11" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="incident" lemma="incident" stem="incid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="Long" lemma="Long" stem="long" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="16" string="Beach" lemma="Beach" stem="beach" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="17" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="18" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="21" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="22" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="23" string="Hill" lemma="Hill" stem="hill" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="24" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="25" string="sedan" lemma="sedan" stem="sedan" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="26" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="pulled" lemma="pull" stem="pull" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="over" lemma="over" stem="over" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="weaving" lemma="weave" stem="weav" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="across" lemma="across" stem="across" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="center" lemma="center" stem="center" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="line" lemma="line" stem="line" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="37" string="highway" lemma="highway" stem="highwai" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="38" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNS Police)) (VP (VBP Have) (NP (NP (DT No) (NN Comment)) (SBAR (S (SBAR (IN In) (S (NP (DT a) (NN statement)) (VP (VBD released) (NP (DT a) (NN day)) (PP (IN after) (NP (DT the) (NN incident)))))) (, ,) (NP (NNP Long) (NNP Beach) (NN police)) (VP (VBD said) (SBAR (IN that) (S (NP (NP (NP (NNP Jackson) (POS 's)) (CC and) (NP (NNP Hill) (POS 's))) (NP (NN sedan))) (VP (VBD was) (VP (VBN pulled) (PRT (RP over)) (PP (IN for) (S (VP (VBG weaving) (PP (IN across) (NP (NP (DT the) (NN center) (NN line)) (PP (IN of) (NP (DT the) (NN highway))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a statement" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="statement" />
          </tokens>
        </chunking>
        <chunking id="2" string="said that Jackson 's and Hill 's sedan was pulled over for weaving across the center line of the highway" type="VP">
          <tokens>
            <token id="18" string="said" />
            <token id="19" string="that" />
            <token id="20" string="Jackson" />
            <token id="21" string="'s" />
            <token id="22" string="and" />
            <token id="23" string="Hill" />
            <token id="24" string="'s" />
            <token id="25" string="sedan" />
            <token id="26" string="was" />
            <token id="27" string="pulled" />
            <token id="28" string="over" />
            <token id="29" string="for" />
            <token id="30" string="weaving" />
            <token id="31" string="across" />
            <token id="32" string="the" />
            <token id="33" string="center" />
            <token id="34" string="line" />
            <token id="35" string="of" />
            <token id="36" string="the" />
            <token id="37" string="highway" />
          </tokens>
        </chunking>
        <chunking id="3" string="No Comment In a statement released a day after the incident , Long Beach police said that Jackson 's and Hill 's sedan was pulled over for weaving across the center line of the highway" type="NP">
          <tokens>
            <token id="3" string="No" />
            <token id="4" string="Comment" />
            <token id="5" string="In" />
            <token id="6" string="a" />
            <token id="7" string="statement" />
            <token id="8" string="released" />
            <token id="9" string="a" />
            <token id="10" string="day" />
            <token id="11" string="after" />
            <token id="12" string="the" />
            <token id="13" string="incident" />
            <token id="14" string="," />
            <token id="15" string="Long" />
            <token id="16" string="Beach" />
            <token id="17" string="police" />
            <token id="18" string="said" />
            <token id="19" string="that" />
            <token id="20" string="Jackson" />
            <token id="21" string="'s" />
            <token id="22" string="and" />
            <token id="23" string="Hill" />
            <token id="24" string="'s" />
            <token id="25" string="sedan" />
            <token id="26" string="was" />
            <token id="27" string="pulled" />
            <token id="28" string="over" />
            <token id="29" string="for" />
            <token id="30" string="weaving" />
            <token id="31" string="across" />
            <token id="32" string="the" />
            <token id="33" string="center" />
            <token id="34" string="line" />
            <token id="35" string="of" />
            <token id="36" string="the" />
            <token id="37" string="highway" />
          </tokens>
        </chunking>
        <chunking id="4" string="In a statement released a day after the incident" type="SBAR">
          <tokens>
            <token id="5" string="In" />
            <token id="6" string="a" />
            <token id="7" string="statement" />
            <token id="8" string="released" />
            <token id="9" string="a" />
            <token id="10" string="day" />
            <token id="11" string="after" />
            <token id="12" string="the" />
            <token id="13" string="incident" />
          </tokens>
        </chunking>
        <chunking id="5" string="released a day after the incident" type="VP">
          <tokens>
            <token id="8" string="released" />
            <token id="9" string="a" />
            <token id="10" string="day" />
            <token id="11" string="after" />
            <token id="12" string="the" />
            <token id="13" string="incident" />
          </tokens>
        </chunking>
        <chunking id="6" string="was pulled over for weaving across the center line of the highway" type="VP">
          <tokens>
            <token id="26" string="was" />
            <token id="27" string="pulled" />
            <token id="28" string="over" />
            <token id="29" string="for" />
            <token id="30" string="weaving" />
            <token id="31" string="across" />
            <token id="32" string="the" />
            <token id="33" string="center" />
            <token id="34" string="line" />
            <token id="35" string="of" />
            <token id="36" string="the" />
            <token id="37" string="highway" />
          </tokens>
        </chunking>
        <chunking id="7" string="Long Beach police" type="NP">
          <tokens>
            <token id="15" string="Long" />
            <token id="16" string="Beach" />
            <token id="17" string="police" />
          </tokens>
        </chunking>
        <chunking id="8" string="Jackson 's and Hill 's" type="NP">
          <tokens>
            <token id="20" string="Jackson" />
            <token id="21" string="'s" />
            <token id="22" string="and" />
            <token id="23" string="Hill" />
            <token id="24" string="'s" />
          </tokens>
        </chunking>
        <chunking id="9" string="Police" type="NP">
          <tokens>
            <token id="1" string="Police" />
          </tokens>
        </chunking>
        <chunking id="10" string="No Comment" type="NP">
          <tokens>
            <token id="3" string="No" />
            <token id="4" string="Comment" />
          </tokens>
        </chunking>
        <chunking id="11" string="that Jackson 's and Hill 's sedan was pulled over for weaving across the center line of the highway" type="SBAR">
          <tokens>
            <token id="19" string="that" />
            <token id="20" string="Jackson" />
            <token id="21" string="'s" />
            <token id="22" string="and" />
            <token id="23" string="Hill" />
            <token id="24" string="'s" />
            <token id="25" string="sedan" />
            <token id="26" string="was" />
            <token id="27" string="pulled" />
            <token id="28" string="over" />
            <token id="29" string="for" />
            <token id="30" string="weaving" />
            <token id="31" string="across" />
            <token id="32" string="the" />
            <token id="33" string="center" />
            <token id="34" string="line" />
            <token id="35" string="of" />
            <token id="36" string="the" />
            <token id="37" string="highway" />
          </tokens>
        </chunking>
        <chunking id="12" string="the highway" type="NP">
          <tokens>
            <token id="36" string="the" />
            <token id="37" string="highway" />
          </tokens>
        </chunking>
        <chunking id="13" string="Have No Comment In a statement released a day after the incident , Long Beach police said that Jackson 's and Hill 's sedan was pulled over for weaving across the center line of the highway" type="VP">
          <tokens>
            <token id="2" string="Have" />
            <token id="3" string="No" />
            <token id="4" string="Comment" />
            <token id="5" string="In" />
            <token id="6" string="a" />
            <token id="7" string="statement" />
            <token id="8" string="released" />
            <token id="9" string="a" />
            <token id="10" string="day" />
            <token id="11" string="after" />
            <token id="12" string="the" />
            <token id="13" string="incident" />
            <token id="14" string="," />
            <token id="15" string="Long" />
            <token id="16" string="Beach" />
            <token id="17" string="police" />
            <token id="18" string="said" />
            <token id="19" string="that" />
            <token id="20" string="Jackson" />
            <token id="21" string="'s" />
            <token id="22" string="and" />
            <token id="23" string="Hill" />
            <token id="24" string="'s" />
            <token id="25" string="sedan" />
            <token id="26" string="was" />
            <token id="27" string="pulled" />
            <token id="28" string="over" />
            <token id="29" string="for" />
            <token id="30" string="weaving" />
            <token id="31" string="across" />
            <token id="32" string="the" />
            <token id="33" string="center" />
            <token id="34" string="line" />
            <token id="35" string="of" />
            <token id="36" string="the" />
            <token id="37" string="highway" />
          </tokens>
        </chunking>
        <chunking id="14" string="the center line of the highway" type="NP">
          <tokens>
            <token id="32" string="the" />
            <token id="33" string="center" />
            <token id="34" string="line" />
            <token id="35" string="of" />
            <token id="36" string="the" />
            <token id="37" string="highway" />
          </tokens>
        </chunking>
        <chunking id="15" string="weaving across the center line of the highway" type="VP">
          <tokens>
            <token id="30" string="weaving" />
            <token id="31" string="across" />
            <token id="32" string="the" />
            <token id="33" string="center" />
            <token id="34" string="line" />
            <token id="35" string="of" />
            <token id="36" string="the" />
            <token id="37" string="highway" />
          </tokens>
        </chunking>
        <chunking id="16" string="the center line" type="NP">
          <tokens>
            <token id="32" string="the" />
            <token id="33" string="center" />
            <token id="34" string="line" />
          </tokens>
        </chunking>
        <chunking id="17" string="In a statement released a day after the incident , Long Beach police said that Jackson 's and Hill 's sedan was pulled over for weaving across the center line of the highway" type="SBAR">
          <tokens>
            <token id="5" string="In" />
            <token id="6" string="a" />
            <token id="7" string="statement" />
            <token id="8" string="released" />
            <token id="9" string="a" />
            <token id="10" string="day" />
            <token id="11" string="after" />
            <token id="12" string="the" />
            <token id="13" string="incident" />
            <token id="14" string="," />
            <token id="15" string="Long" />
            <token id="16" string="Beach" />
            <token id="17" string="police" />
            <token id="18" string="said" />
            <token id="19" string="that" />
            <token id="20" string="Jackson" />
            <token id="21" string="'s" />
            <token id="22" string="and" />
            <token id="23" string="Hill" />
            <token id="24" string="'s" />
            <token id="25" string="sedan" />
            <token id="26" string="was" />
            <token id="27" string="pulled" />
            <token id="28" string="over" />
            <token id="29" string="for" />
            <token id="30" string="weaving" />
            <token id="31" string="across" />
            <token id="32" string="the" />
            <token id="33" string="center" />
            <token id="34" string="line" />
            <token id="35" string="of" />
            <token id="36" string="the" />
            <token id="37" string="highway" />
          </tokens>
        </chunking>
        <chunking id="18" string="a day" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="day" />
          </tokens>
        </chunking>
        <chunking id="19" string="Jackson 's" type="NP">
          <tokens>
            <token id="20" string="Jackson" />
            <token id="21" string="'s" />
          </tokens>
        </chunking>
        <chunking id="20" string="Hill 's" type="NP">
          <tokens>
            <token id="23" string="Hill" />
            <token id="24" string="'s" />
          </tokens>
        </chunking>
        <chunking id="21" string="Jackson 's and Hill 's sedan" type="NP">
          <tokens>
            <token id="20" string="Jackson" />
            <token id="21" string="'s" />
            <token id="22" string="and" />
            <token id="23" string="Hill" />
            <token id="24" string="'s" />
            <token id="25" string="sedan" />
          </tokens>
        </chunking>
        <chunking id="22" string="sedan" type="NP">
          <tokens>
            <token id="25" string="sedan" />
          </tokens>
        </chunking>
        <chunking id="23" string="the incident" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="incident" />
          </tokens>
        </chunking>
        <chunking id="24" string="pulled over for weaving across the center line of the highway" type="VP">
          <tokens>
            <token id="27" string="pulled" />
            <token id="28" string="over" />
            <token id="29" string="for" />
            <token id="30" string="weaving" />
            <token id="31" string="across" />
            <token id="32" string="the" />
            <token id="33" string="center" />
            <token id="34" string="line" />
            <token id="35" string="of" />
            <token id="36" string="the" />
            <token id="37" string="highway" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">Have</governor>
          <dependent id="1">Police</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">Have</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="4">Comment</governor>
          <dependent id="3">No</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">Have</governor>
          <dependent id="4">Comment</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">released</governor>
          <dependent id="5">In</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">statement</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">released</governor>
          <dependent id="7">statement</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="18">said</governor>
          <dependent id="8">released</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">day</governor>
          <dependent id="9">a</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="8">released</governor>
          <dependent id="10">day</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">incident</governor>
          <dependent id="11">after</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">incident</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">released</governor>
          <dependent id="13">incident</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">police</governor>
          <dependent id="15">Long</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">police</governor>
          <dependent id="16">Beach</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">said</governor>
          <dependent id="17">police</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="4">Comment</governor>
          <dependent id="18">said</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="27">pulled</governor>
          <dependent id="19">that</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="27">pulled</governor>
          <dependent id="20">Jackson</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">Jackson</governor>
          <dependent id="21">'s</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="20">Jackson</governor>
          <dependent id="22">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="20">Jackson</governor>
          <dependent id="23">Hill</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">Hill</governor>
          <dependent id="24">'s</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="20">Jackson</governor>
          <dependent id="25">sedan</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="27">pulled</governor>
          <dependent id="26">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="18">said</governor>
          <dependent id="27">pulled</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="27">pulled</governor>
          <dependent id="28">over</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="30">weaving</governor>
          <dependent id="29">for</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="27">pulled</governor>
          <dependent id="30">weaving</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">line</governor>
          <dependent id="31">across</dependent>
        </dependency>
        <dependency type="det">
          <governor id="34">line</governor>
          <dependent id="32">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="34">line</governor>
          <dependent id="33">center</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">weaving</governor>
          <dependent id="34">line</dependent>
        </dependency>
        <dependency type="case">
          <governor id="37">highway</governor>
          <dependent id="35">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="37">highway</governor>
          <dependent id="36">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="34">line</governor>
          <dependent id="37">highway</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Hill" type="PERSON" score="0.0">
          <tokens>
            <token id="23" string="Hill" />
          </tokens>
        </entity>
        <entity id="2" string="Long Beach" type="LOCATION" score="0.0">
          <tokens>
            <token id="15" string="Long" />
            <token id="16" string="Beach" />
          </tokens>
        </entity>
        <entity id="3" string="a day" type="DURATION" score="0.0">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="day" />
          </tokens>
        </entity>
        <entity id="4" string="Jackson" type="PERSON" score="0.0">
          <tokens>
            <token id="20" string="Jackson" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="28" has_coreference="true">
      <content>They denied that Jackson&amp;apost;s head was shoved through the window, saying that his elbow smashed the glass.</content>
      <tokens>
        <token id="1" string="They" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="denied" lemma="deny" stem="deni" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="5" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="head" lemma="head" stem="head" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="shoved" lemma="shove" stem="shove" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="window" lemma="window" stem="window" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="saying" lemma="say" stem="sai" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="elbow" lemma="elbow" stem="elbow" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="smashed" lemma="smash" stem="smash" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="glass" lemma="glass" stem="glass" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP They)) (VP (VBD denied) (SBAR (IN that) (S (NP (NP (NNP Jackson) (POS 's)) (NN head)) (VP (VBD was) (VP (VBN shoved) (PP (IN through) (NP (DT the) (NN window))))))) (, ,) (S (VP (VBG saying) (SBAR (IN that) (S (NP (PRP$ his) (NN elbow)) (VP (VBD smashed) (NP (DT the) (NN glass)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="They" type="NP">
          <tokens>
            <token id="1" string="They" />
          </tokens>
        </chunking>
        <chunking id="2" string="the window" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="window" />
          </tokens>
        </chunking>
        <chunking id="3" string="Jackson 's head" type="NP">
          <tokens>
            <token id="4" string="Jackson" />
            <token id="5" string="'s" />
            <token id="6" string="head" />
          </tokens>
        </chunking>
        <chunking id="4" string="his elbow" type="NP">
          <tokens>
            <token id="15" string="his" />
            <token id="16" string="elbow" />
          </tokens>
        </chunking>
        <chunking id="5" string="the glass" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="glass" />
          </tokens>
        </chunking>
        <chunking id="6" string="smashed the glass" type="VP">
          <tokens>
            <token id="17" string="smashed" />
            <token id="18" string="the" />
            <token id="19" string="glass" />
          </tokens>
        </chunking>
        <chunking id="7" string="was shoved through the window" type="VP">
          <tokens>
            <token id="7" string="was" />
            <token id="8" string="shoved" />
            <token id="9" string="through" />
            <token id="10" string="the" />
            <token id="11" string="window" />
          </tokens>
        </chunking>
        <chunking id="8" string="that Jackson 's head was shoved through the window" type="SBAR">
          <tokens>
            <token id="3" string="that" />
            <token id="4" string="Jackson" />
            <token id="5" string="'s" />
            <token id="6" string="head" />
            <token id="7" string="was" />
            <token id="8" string="shoved" />
            <token id="9" string="through" />
            <token id="10" string="the" />
            <token id="11" string="window" />
          </tokens>
        </chunking>
        <chunking id="9" string="saying that his elbow smashed the glass" type="VP">
          <tokens>
            <token id="13" string="saying" />
            <token id="14" string="that" />
            <token id="15" string="his" />
            <token id="16" string="elbow" />
            <token id="17" string="smashed" />
            <token id="18" string="the" />
            <token id="19" string="glass" />
          </tokens>
        </chunking>
        <chunking id="10" string="that his elbow smashed the glass" type="SBAR">
          <tokens>
            <token id="14" string="that" />
            <token id="15" string="his" />
            <token id="16" string="elbow" />
            <token id="17" string="smashed" />
            <token id="18" string="the" />
            <token id="19" string="glass" />
          </tokens>
        </chunking>
        <chunking id="11" string="Jackson 's" type="NP">
          <tokens>
            <token id="4" string="Jackson" />
            <token id="5" string="'s" />
          </tokens>
        </chunking>
        <chunking id="12" string="denied that Jackson 's head was shoved through the window , saying that his elbow smashed the glass" type="VP">
          <tokens>
            <token id="2" string="denied" />
            <token id="3" string="that" />
            <token id="4" string="Jackson" />
            <token id="5" string="'s" />
            <token id="6" string="head" />
            <token id="7" string="was" />
            <token id="8" string="shoved" />
            <token id="9" string="through" />
            <token id="10" string="the" />
            <token id="11" string="window" />
            <token id="12" string="," />
            <token id="13" string="saying" />
            <token id="14" string="that" />
            <token id="15" string="his" />
            <token id="16" string="elbow" />
            <token id="17" string="smashed" />
            <token id="18" string="the" />
            <token id="19" string="glass" />
          </tokens>
        </chunking>
        <chunking id="13" string="shoved through the window" type="VP">
          <tokens>
            <token id="8" string="shoved" />
            <token id="9" string="through" />
            <token id="10" string="the" />
            <token id="11" string="window" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">denied</governor>
          <dependent id="1">They</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">denied</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">shoved</governor>
          <dependent id="3">that</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="6">head</governor>
          <dependent id="4">Jackson</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">Jackson</governor>
          <dependent id="5">'s</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="8">shoved</governor>
          <dependent id="6">head</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="8">shoved</governor>
          <dependent id="7">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">denied</governor>
          <dependent id="8">shoved</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">window</governor>
          <dependent id="9">through</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">window</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">shoved</governor>
          <dependent id="11">window</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="2">denied</governor>
          <dependent id="13">saying</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">smashed</governor>
          <dependent id="14">that</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="16">elbow</governor>
          <dependent id="15">his</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">smashed</governor>
          <dependent id="16">elbow</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="13">saying</governor>
          <dependent id="17">smashed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">glass</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">smashed</governor>
          <dependent id="19">glass</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Jackson" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Jackson" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="29" has_coreference="false">
      <content>On Monday, however, department officials stopped releasing that statement and said they would have no comment pending the outcome of their internal investigation.</content>
      <tokens>
        <token id="1" string="On" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Monday" lemma="Monday" stem="mondai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="however" lemma="however" stem="howev" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="department" lemma="department" stem="depart" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="officials" lemma="official" stem="offici" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="stopped" lemma="stop" stem="stop" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="releasing" lemma="release" stem="releas" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="statement" lemma="statement" stem="statement" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="comment" lemma="comment" stem="comment" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="pending" lemma="pend" stem="pend" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="outcome" lemma="outcome" stem="outcom" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="internal" lemma="internal" stem="intern" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="investigation" lemma="investigation" stem="investig" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN On) (NP (NNP Monday))) (, ,) (ADVP (RB however)) (, ,) (NP (NN department) (NNS officials)) (VP (VP (VBD stopped) (S (VP (VBG releasing) (PP (IN that) (NP (NN statement)))))) (CC and) (VP (VBD said) (SBAR (S (NP (PRP they)) (VP (MD would) (VP (VB have) (NP (NP (DT no) (NN comment)) (PP (VBG pending) (NP (NP (DT the) (NN outcome)) (PP (IN of) (NP (PRP$ their) (JJ internal) (NN investigation)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="said they would have no comment pending the outcome of their internal investigation" type="VP">
          <tokens>
            <token id="13" string="said" />
            <token id="14" string="they" />
            <token id="15" string="would" />
            <token id="16" string="have" />
            <token id="17" string="no" />
            <token id="18" string="comment" />
            <token id="19" string="pending" />
            <token id="20" string="the" />
            <token id="21" string="outcome" />
            <token id="22" string="of" />
            <token id="23" string="their" />
            <token id="24" string="internal" />
            <token id="25" string="investigation" />
          </tokens>
        </chunking>
        <chunking id="2" string="the outcome of their internal investigation" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="outcome" />
            <token id="22" string="of" />
            <token id="23" string="their" />
            <token id="24" string="internal" />
            <token id="25" string="investigation" />
          </tokens>
        </chunking>
        <chunking id="3" string="no comment pending the outcome of their internal investigation" type="NP">
          <tokens>
            <token id="17" string="no" />
            <token id="18" string="comment" />
            <token id="19" string="pending" />
            <token id="20" string="the" />
            <token id="21" string="outcome" />
            <token id="22" string="of" />
            <token id="23" string="their" />
            <token id="24" string="internal" />
            <token id="25" string="investigation" />
          </tokens>
        </chunking>
        <chunking id="4" string="the outcome" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="outcome" />
          </tokens>
        </chunking>
        <chunking id="5" string="department officials" type="NP">
          <tokens>
            <token id="6" string="department" />
            <token id="7" string="officials" />
          </tokens>
        </chunking>
        <chunking id="6" string="they" type="NP">
          <tokens>
            <token id="14" string="they" />
          </tokens>
        </chunking>
        <chunking id="7" string="releasing that statement" type="VP">
          <tokens>
            <token id="9" string="releasing" />
            <token id="10" string="that" />
            <token id="11" string="statement" />
          </tokens>
        </chunking>
        <chunking id="8" string="their internal investigation" type="NP">
          <tokens>
            <token id="23" string="their" />
            <token id="24" string="internal" />
            <token id="25" string="investigation" />
          </tokens>
        </chunking>
        <chunking id="9" string="statement" type="NP">
          <tokens>
            <token id="11" string="statement" />
          </tokens>
        </chunking>
        <chunking id="10" string="no comment" type="NP">
          <tokens>
            <token id="17" string="no" />
            <token id="18" string="comment" />
          </tokens>
        </chunking>
        <chunking id="11" string="Monday" type="NP">
          <tokens>
            <token id="2" string="Monday" />
          </tokens>
        </chunking>
        <chunking id="12" string="would have no comment pending the outcome of their internal investigation" type="VP">
          <tokens>
            <token id="15" string="would" />
            <token id="16" string="have" />
            <token id="17" string="no" />
            <token id="18" string="comment" />
            <token id="19" string="pending" />
            <token id="20" string="the" />
            <token id="21" string="outcome" />
            <token id="22" string="of" />
            <token id="23" string="their" />
            <token id="24" string="internal" />
            <token id="25" string="investigation" />
          </tokens>
        </chunking>
        <chunking id="13" string="have no comment pending the outcome of their internal investigation" type="VP">
          <tokens>
            <token id="16" string="have" />
            <token id="17" string="no" />
            <token id="18" string="comment" />
            <token id="19" string="pending" />
            <token id="20" string="the" />
            <token id="21" string="outcome" />
            <token id="22" string="of" />
            <token id="23" string="their" />
            <token id="24" string="internal" />
            <token id="25" string="investigation" />
          </tokens>
        </chunking>
        <chunking id="14" string="they would have no comment pending the outcome of their internal investigation" type="SBAR">
          <tokens>
            <token id="14" string="they" />
            <token id="15" string="would" />
            <token id="16" string="have" />
            <token id="17" string="no" />
            <token id="18" string="comment" />
            <token id="19" string="pending" />
            <token id="20" string="the" />
            <token id="21" string="outcome" />
            <token id="22" string="of" />
            <token id="23" string="their" />
            <token id="24" string="internal" />
            <token id="25" string="investigation" />
          </tokens>
        </chunking>
        <chunking id="15" string="stopped releasing that statement and said they would have no comment pending the outcome of their internal investigation" type="VP">
          <tokens>
            <token id="8" string="stopped" />
            <token id="9" string="releasing" />
            <token id="10" string="that" />
            <token id="11" string="statement" />
            <token id="12" string="and" />
            <token id="13" string="said" />
            <token id="14" string="they" />
            <token id="15" string="would" />
            <token id="16" string="have" />
            <token id="17" string="no" />
            <token id="18" string="comment" />
            <token id="19" string="pending" />
            <token id="20" string="the" />
            <token id="21" string="outcome" />
            <token id="22" string="of" />
            <token id="23" string="their" />
            <token id="24" string="internal" />
            <token id="25" string="investigation" />
          </tokens>
        </chunking>
        <chunking id="16" string="stopped releasing that statement" type="VP">
          <tokens>
            <token id="8" string="stopped" />
            <token id="9" string="releasing" />
            <token id="10" string="that" />
            <token id="11" string="statement" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">Monday</governor>
          <dependent id="1">On</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">stopped</governor>
          <dependent id="2">Monday</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">stopped</governor>
          <dependent id="4">however</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">officials</governor>
          <dependent id="6">department</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">stopped</governor>
          <dependent id="7">officials</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">stopped</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="8">stopped</governor>
          <dependent id="9">releasing</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">statement</governor>
          <dependent id="10">that</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">releasing</governor>
          <dependent id="11">statement</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">stopped</governor>
          <dependent id="12">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">stopped</governor>
          <dependent id="13">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">have</governor>
          <dependent id="14">they</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">have</governor>
          <dependent id="15">would</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="13">said</governor>
          <dependent id="16">have</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="18">comment</governor>
          <dependent id="17">no</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">have</governor>
          <dependent id="18">comment</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">outcome</governor>
          <dependent id="19">pending</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">outcome</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">comment</governor>
          <dependent id="21">outcome</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">investigation</governor>
          <dependent id="22">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="25">investigation</governor>
          <dependent id="23">their</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">investigation</governor>
          <dependent id="24">internal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">outcome</governor>
          <dependent id="25">investigation</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Monday" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="Monday" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="30" has_coreference="true">
      <content>A spokesman for the Police Misconduct Lawyer Referral Service, a nonprofit group that investigates citizen complaints against law enforcement agencies, said the televised tape makes it clear that Dickey pushed Jackson&amp;apost;s head and right arm through the window.</content>
      <tokens>
        <token id="1" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="spokesman" lemma="spokesman" stem="spokesman" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Police" lemma="Police" stem="polic" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="Misconduct" lemma="Misconduct" stem="misconduct" pos="NNP" type="Word" isStopWord="false" ner="CRIMINAL_CHARGE" is_referenced="false" is_refers="false" />
        <token id="7" string="Lawyer" lemma="Lawyer" stem="lawyer" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="true" is_refers="false" />
        <token id="8" string="Referral" lemma="Referral" stem="referr" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="Service" lemma="Service" stem="servic" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="nonprofit" lemma="nonprofit" stem="nonprofit" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="group" lemma="group" stem="group" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="investigates" lemma="investigate" stem="investig" pos="VBZ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="citizen" lemma="citizen" stem="citizen" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="complaints" lemma="complaint" stem="complaint" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="law" lemma="law" stem="law" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="enforcement" lemma="enforcement" stem="enforc" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="agencies" lemma="agency" stem="agenc" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="25" string="televised" lemma="televise" stem="televis" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="26" string="tape" lemma="tape" stem="tape" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="27" string="makes" lemma="make" stem="make" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="clear" lemma="clear" stem="clear" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="Dickey" lemma="Dickey" stem="dickei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="32" string="pushed" lemma="push" stem="push" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="34" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="35" string="head" lemma="head" stem="head" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="right" lemma="right" stem="right" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="38" string="arm" lemma="arm" stem="arm" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="41" string="window" lemma="window" stem="window" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="42" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NP (DT A) (NN spokesman)) (PP (IN for) (NP (DT the) (NNP Police) (NNP Misconduct) (NNP Lawyer) (NNP Referral) (NNP Service)))) (, ,) (NP (NP (DT a) (JJ nonprofit) (NN group)) (SBAR (WHNP (WDT that)) (S (VP (VBZ investigates) (NP (NP (NN citizen) (NNS complaints)) (PP (IN against) (NP (NN law) (NN enforcement) (NNS agencies)))))))) (, ,)) (VP (VBD said) (SBAR (S (NP (DT the) (VBN televised) (NN tape)) (VP (VBZ makes) (S (NP (PRP it)) (ADJP (JJ clear))) (SBAR (IN that) (S (NP (NNP Dickey)) (VP (VBD pushed) (NP (NP (NNP Jackson) (POS 's)) (NN head) (CC and) (JJ right) (NN arm)) (PP (IN through) (NP (DT the) (NN window)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the window" type="NP">
          <tokens>
            <token id="40" string="the" />
            <token id="41" string="window" />
          </tokens>
        </chunking>
        <chunking id="2" string="citizen complaints" type="NP">
          <tokens>
            <token id="16" string="citizen" />
            <token id="17" string="complaints" />
          </tokens>
        </chunking>
        <chunking id="3" string="the televised tape" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="televised" />
            <token id="26" string="tape" />
          </tokens>
        </chunking>
        <chunking id="4" string="A spokesman" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="spokesman" />
          </tokens>
        </chunking>
        <chunking id="5" string="law enforcement agencies" type="NP">
          <tokens>
            <token id="19" string="law" />
            <token id="20" string="enforcement" />
            <token id="21" string="agencies" />
          </tokens>
        </chunking>
        <chunking id="6" string="the Police Misconduct Lawyer Referral Service" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="Police" />
            <token id="6" string="Misconduct" />
            <token id="7" string="Lawyer" />
            <token id="8" string="Referral" />
            <token id="9" string="Service" />
          </tokens>
        </chunking>
        <chunking id="7" string="pushed Jackson 's head and right arm through the window" type="VP">
          <tokens>
            <token id="32" string="pushed" />
            <token id="33" string="Jackson" />
            <token id="34" string="'s" />
            <token id="35" string="head" />
            <token id="36" string="and" />
            <token id="37" string="right" />
            <token id="38" string="arm" />
            <token id="39" string="through" />
            <token id="40" string="the" />
            <token id="41" string="window" />
          </tokens>
        </chunking>
        <chunking id="8" string="clear" type="ADJP">
          <tokens>
            <token id="29" string="clear" />
          </tokens>
        </chunking>
        <chunking id="9" string="it" type="NP">
          <tokens>
            <token id="28" string="it" />
          </tokens>
        </chunking>
        <chunking id="10" string="makes it clear that Dickey pushed Jackson 's head and right arm through the window" type="VP">
          <tokens>
            <token id="27" string="makes" />
            <token id="28" string="it" />
            <token id="29" string="clear" />
            <token id="30" string="that" />
            <token id="31" string="Dickey" />
            <token id="32" string="pushed" />
            <token id="33" string="Jackson" />
            <token id="34" string="'s" />
            <token id="35" string="head" />
            <token id="36" string="and" />
            <token id="37" string="right" />
            <token id="38" string="arm" />
            <token id="39" string="through" />
            <token id="40" string="the" />
            <token id="41" string="window" />
          </tokens>
        </chunking>
        <chunking id="11" string="the televised tape makes it clear that Dickey pushed Jackson 's head and right arm through the window" type="SBAR">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="televised" />
            <token id="26" string="tape" />
            <token id="27" string="makes" />
            <token id="28" string="it" />
            <token id="29" string="clear" />
            <token id="30" string="that" />
            <token id="31" string="Dickey" />
            <token id="32" string="pushed" />
            <token id="33" string="Jackson" />
            <token id="34" string="'s" />
            <token id="35" string="head" />
            <token id="36" string="and" />
            <token id="37" string="right" />
            <token id="38" string="arm" />
            <token id="39" string="through" />
            <token id="40" string="the" />
            <token id="41" string="window" />
          </tokens>
        </chunking>
        <chunking id="12" string="that Dickey pushed Jackson 's head and right arm through the window" type="SBAR">
          <tokens>
            <token id="30" string="that" />
            <token id="31" string="Dickey" />
            <token id="32" string="pushed" />
            <token id="33" string="Jackson" />
            <token id="34" string="'s" />
            <token id="35" string="head" />
            <token id="36" string="and" />
            <token id="37" string="right" />
            <token id="38" string="arm" />
            <token id="39" string="through" />
            <token id="40" string="the" />
            <token id="41" string="window" />
          </tokens>
        </chunking>
        <chunking id="13" string="A spokesman for the Police Misconduct Lawyer Referral Service" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="spokesman" />
            <token id="3" string="for" />
            <token id="4" string="the" />
            <token id="5" string="Police" />
            <token id="6" string="Misconduct" />
            <token id="7" string="Lawyer" />
            <token id="8" string="Referral" />
            <token id="9" string="Service" />
          </tokens>
        </chunking>
        <chunking id="14" string="investigates citizen complaints against law enforcement agencies" type="VP">
          <tokens>
            <token id="15" string="investigates" />
            <token id="16" string="citizen" />
            <token id="17" string="complaints" />
            <token id="18" string="against" />
            <token id="19" string="law" />
            <token id="20" string="enforcement" />
            <token id="21" string="agencies" />
          </tokens>
        </chunking>
        <chunking id="15" string="A spokesman for the Police Misconduct Lawyer Referral Service , a nonprofit group that investigates citizen complaints against law enforcement agencies ," type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="spokesman" />
            <token id="3" string="for" />
            <token id="4" string="the" />
            <token id="5" string="Police" />
            <token id="6" string="Misconduct" />
            <token id="7" string="Lawyer" />
            <token id="8" string="Referral" />
            <token id="9" string="Service" />
            <token id="10" string="," />
            <token id="11" string="a" />
            <token id="12" string="nonprofit" />
            <token id="13" string="group" />
            <token id="14" string="that" />
            <token id="15" string="investigates" />
            <token id="16" string="citizen" />
            <token id="17" string="complaints" />
            <token id="18" string="against" />
            <token id="19" string="law" />
            <token id="20" string="enforcement" />
            <token id="21" string="agencies" />
            <token id="22" string="," />
          </tokens>
        </chunking>
        <chunking id="16" string="a nonprofit group that investigates citizen complaints against law enforcement agencies" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="nonprofit" />
            <token id="13" string="group" />
            <token id="14" string="that" />
            <token id="15" string="investigates" />
            <token id="16" string="citizen" />
            <token id="17" string="complaints" />
            <token id="18" string="against" />
            <token id="19" string="law" />
            <token id="20" string="enforcement" />
            <token id="21" string="agencies" />
          </tokens>
        </chunking>
        <chunking id="17" string="citizen complaints against law enforcement agencies" type="NP">
          <tokens>
            <token id="16" string="citizen" />
            <token id="17" string="complaints" />
            <token id="18" string="against" />
            <token id="19" string="law" />
            <token id="20" string="enforcement" />
            <token id="21" string="agencies" />
          </tokens>
        </chunking>
        <chunking id="18" string="said the televised tape makes it clear that Dickey pushed Jackson 's head and right arm through the window" type="VP">
          <tokens>
            <token id="23" string="said" />
            <token id="24" string="the" />
            <token id="25" string="televised" />
            <token id="26" string="tape" />
            <token id="27" string="makes" />
            <token id="28" string="it" />
            <token id="29" string="clear" />
            <token id="30" string="that" />
            <token id="31" string="Dickey" />
            <token id="32" string="pushed" />
            <token id="33" string="Jackson" />
            <token id="34" string="'s" />
            <token id="35" string="head" />
            <token id="36" string="and" />
            <token id="37" string="right" />
            <token id="38" string="arm" />
            <token id="39" string="through" />
            <token id="40" string="the" />
            <token id="41" string="window" />
          </tokens>
        </chunking>
        <chunking id="19" string="Jackson 's" type="NP">
          <tokens>
            <token id="33" string="Jackson" />
            <token id="34" string="'s" />
          </tokens>
        </chunking>
        <chunking id="20" string="that investigates citizen complaints against law enforcement agencies" type="SBAR">
          <tokens>
            <token id="14" string="that" />
            <token id="15" string="investigates" />
            <token id="16" string="citizen" />
            <token id="17" string="complaints" />
            <token id="18" string="against" />
            <token id="19" string="law" />
            <token id="20" string="enforcement" />
            <token id="21" string="agencies" />
          </tokens>
        </chunking>
        <chunking id="21" string="a nonprofit group" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="nonprofit" />
            <token id="13" string="group" />
          </tokens>
        </chunking>
        <chunking id="22" string="Dickey" type="NP">
          <tokens>
            <token id="31" string="Dickey" />
          </tokens>
        </chunking>
        <chunking id="23" string="Jackson 's head and right arm" type="NP">
          <tokens>
            <token id="33" string="Jackson" />
            <token id="34" string="'s" />
            <token id="35" string="head" />
            <token id="36" string="and" />
            <token id="37" string="right" />
            <token id="38" string="arm" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">spokesman</governor>
          <dependent id="1">A</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">said</governor>
          <dependent id="2">spokesman</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Service</governor>
          <dependent id="3">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">Service</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Service</governor>
          <dependent id="5">Police</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Service</governor>
          <dependent id="6">Misconduct</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Service</governor>
          <dependent id="7">Lawyer</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Service</governor>
          <dependent id="8">Referral</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">spokesman</governor>
          <dependent id="9">Service</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">group</governor>
          <dependent id="11">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">group</governor>
          <dependent id="12">nonprofit</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="2">spokesman</governor>
          <dependent id="13">group</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">investigates</governor>
          <dependent id="14">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="13">group</governor>
          <dependent id="15">investigates</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">complaints</governor>
          <dependent id="16">citizen</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">investigates</governor>
          <dependent id="17">complaints</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">agencies</governor>
          <dependent id="18">against</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">agencies</governor>
          <dependent id="19">law</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">agencies</governor>
          <dependent id="20">enforcement</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">complaints</governor>
          <dependent id="21">agencies</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="23">said</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">tape</governor>
          <dependent id="24">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">tape</governor>
          <dependent id="25">televised</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">makes</governor>
          <dependent id="26">tape</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="23">said</governor>
          <dependent id="27">makes</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">clear</governor>
          <dependent id="28">it</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="27">makes</governor>
          <dependent id="29">clear</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="32">pushed</governor>
          <dependent id="30">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="32">pushed</governor>
          <dependent id="31">Dickey</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="27">makes</governor>
          <dependent id="32">pushed</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="35">head</governor>
          <dependent id="33">Jackson</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">Jackson</governor>
          <dependent id="34">'s</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="32">pushed</governor>
          <dependent id="35">head</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="35">head</governor>
          <dependent id="36">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="38">arm</governor>
          <dependent id="37">right</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="35">head</governor>
          <dependent id="38">arm</dependent>
        </dependency>
        <dependency type="case">
          <governor id="41">window</governor>
          <dependent id="39">through</dependent>
        </dependency>
        <dependency type="det">
          <governor id="41">window</governor>
          <dependent id="40">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="32">pushed</governor>
          <dependent id="41">window</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Misconduct" type="CRIMINAL_CHARGE" score="0.0">
          <tokens>
            <token id="6" string="Misconduct" />
          </tokens>
        </entity>
        <entity id="2" string="Jackson" type="PERSON" score="0.0">
          <tokens>
            <token id="33" string="Jackson" />
          </tokens>
        </entity>
        <entity id="3" string="Lawyer" type="TITLE" score="0.0">
          <tokens>
            <token id="7" string="Lawyer" />
          </tokens>
        </entity>
        <entity id="4" string="right" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="37" string="right" />
          </tokens>
        </entity>
        <entity id="5" string="Dickey" type="PERSON" score="0.0">
          <tokens>
            <token id="31" string="Dickey" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="31" has_coreference="true">
      <content>Spokesman David Lynn maintained that Hill, the driver of the car, was not violating any traffic laws when he was stopped.</content>
      <tokens>
        <token id="1" string="Spokesman" lemma="Spokesman" stem="spokesman" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="David" lemma="David" stem="david" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="Lynn" lemma="Lynn" stem="lynn" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="4" string="maintained" lemma="maintain" stem="maintain" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Hill" lemma="Hill" stem="hill" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="driver" lemma="driver" stem="driver" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="12" string="car" lemma="car" stem="car" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="violating" lemma="violate" stem="violat" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="any" lemma="any" stem="ani" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="traffic" lemma="traffic" stem="traffic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="laws" lemma="law" stem="law" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="stopped" lemma="stop" stem="stop" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Spokesman) (NNP David) (NNP Lynn)) (VP (VBD maintained) (SBAR (IN that) (S (NP (NP (NNP Hill)) (, ,) (NP (NP (DT the) (NN driver)) (PP (IN of) (NP (DT the) (NN car)))) (, ,)) (VP (VBD was) (RB not) (VP (VBG violating) (NP (DT any) (NN traffic) (NNS laws)) (SBAR (WHADVP (WRB when)) (S (NP (PRP he)) (VP (VBD was) (VP (VBN stopped)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="was stopped" type="VP">
          <tokens>
            <token id="22" string="was" />
            <token id="23" string="stopped" />
          </tokens>
        </chunking>
        <chunking id="2" string="Hill" type="NP">
          <tokens>
            <token id="6" string="Hill" />
          </tokens>
        </chunking>
        <chunking id="3" string="stopped" type="VP">
          <tokens>
            <token id="23" string="stopped" />
          </tokens>
        </chunking>
        <chunking id="4" string="that Hill , the driver of the car , was not violating any traffic laws when he was stopped" type="SBAR">
          <tokens>
            <token id="5" string="that" />
            <token id="6" string="Hill" />
            <token id="7" string="," />
            <token id="8" string="the" />
            <token id="9" string="driver" />
            <token id="10" string="of" />
            <token id="11" string="the" />
            <token id="12" string="car" />
            <token id="13" string="," />
            <token id="14" string="was" />
            <token id="15" string="not" />
            <token id="16" string="violating" />
            <token id="17" string="any" />
            <token id="18" string="traffic" />
            <token id="19" string="laws" />
            <token id="20" string="when" />
            <token id="21" string="he" />
            <token id="22" string="was" />
            <token id="23" string="stopped" />
          </tokens>
        </chunking>
        <chunking id="5" string="the car" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="car" />
          </tokens>
        </chunking>
        <chunking id="6" string="was not violating any traffic laws when he was stopped" type="VP">
          <tokens>
            <token id="14" string="was" />
            <token id="15" string="not" />
            <token id="16" string="violating" />
            <token id="17" string="any" />
            <token id="18" string="traffic" />
            <token id="19" string="laws" />
            <token id="20" string="when" />
            <token id="21" string="he" />
            <token id="22" string="was" />
            <token id="23" string="stopped" />
          </tokens>
        </chunking>
        <chunking id="7" string="when" type="WHADVP">
          <tokens>
            <token id="20" string="when" />
          </tokens>
        </chunking>
        <chunking id="8" string="violating any traffic laws when he was stopped" type="VP">
          <tokens>
            <token id="16" string="violating" />
            <token id="17" string="any" />
            <token id="18" string="traffic" />
            <token id="19" string="laws" />
            <token id="20" string="when" />
            <token id="21" string="he" />
            <token id="22" string="was" />
            <token id="23" string="stopped" />
          </tokens>
        </chunking>
        <chunking id="9" string="maintained that Hill , the driver of the car , was not violating any traffic laws when he was stopped" type="VP">
          <tokens>
            <token id="4" string="maintained" />
            <token id="5" string="that" />
            <token id="6" string="Hill" />
            <token id="7" string="," />
            <token id="8" string="the" />
            <token id="9" string="driver" />
            <token id="10" string="of" />
            <token id="11" string="the" />
            <token id="12" string="car" />
            <token id="13" string="," />
            <token id="14" string="was" />
            <token id="15" string="not" />
            <token id="16" string="violating" />
            <token id="17" string="any" />
            <token id="18" string="traffic" />
            <token id="19" string="laws" />
            <token id="20" string="when" />
            <token id="21" string="he" />
            <token id="22" string="was" />
            <token id="23" string="stopped" />
          </tokens>
        </chunking>
        <chunking id="10" string="Spokesman David Lynn" type="NP">
          <tokens>
            <token id="1" string="Spokesman" />
            <token id="2" string="David" />
            <token id="3" string="Lynn" />
          </tokens>
        </chunking>
        <chunking id="11" string="when he was stopped" type="SBAR">
          <tokens>
            <token id="20" string="when" />
            <token id="21" string="he" />
            <token id="22" string="was" />
            <token id="23" string="stopped" />
          </tokens>
        </chunking>
        <chunking id="12" string="the driver" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="driver" />
          </tokens>
        </chunking>
        <chunking id="13" string="Hill , the driver of the car ," type="NP">
          <tokens>
            <token id="6" string="Hill" />
            <token id="7" string="," />
            <token id="8" string="the" />
            <token id="9" string="driver" />
            <token id="10" string="of" />
            <token id="11" string="the" />
            <token id="12" string="car" />
            <token id="13" string="," />
          </tokens>
        </chunking>
        <chunking id="14" string="any traffic laws" type="NP">
          <tokens>
            <token id="17" string="any" />
            <token id="18" string="traffic" />
            <token id="19" string="laws" />
          </tokens>
        </chunking>
        <chunking id="15" string="he" type="NP">
          <tokens>
            <token id="21" string="he" />
          </tokens>
        </chunking>
        <chunking id="16" string="the driver of the car" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="driver" />
            <token id="10" string="of" />
            <token id="11" string="the" />
            <token id="12" string="car" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">Lynn</governor>
          <dependent id="1">Spokesman</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Lynn</governor>
          <dependent id="2">David</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">maintained</governor>
          <dependent id="3">Lynn</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">maintained</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">violating</governor>
          <dependent id="5">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">violating</governor>
          <dependent id="6">Hill</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">driver</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="6">Hill</governor>
          <dependent id="9">driver</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">car</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">car</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">driver</governor>
          <dependent id="12">car</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">violating</governor>
          <dependent id="14">was</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="16">violating</governor>
          <dependent id="15">not</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">maintained</governor>
          <dependent id="16">violating</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">laws</governor>
          <dependent id="17">any</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">laws</governor>
          <dependent id="18">traffic</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">violating</governor>
          <dependent id="19">laws</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="23">stopped</governor>
          <dependent id="20">when</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="23">stopped</governor>
          <dependent id="21">he</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="23">stopped</governor>
          <dependent id="22">was</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="16">violating</governor>
          <dependent id="23">stopped</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Hill" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Hill" />
          </tokens>
        </entity>
        <entity id="2" string="David Lynn" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="David" />
            <token id="3" string="Lynn" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="32" has_coreference="true">
      <content>The group also complained that Dickey also used a string of obscenities in his conversation with Jackson, who was booked for suspicion of using offensive language, challenging an officer to fight and obstructing arrest.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="group" lemma="group" stem="group" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="complained" lemma="complain" stem="complain" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Dickey" lemma="Dickey" stem="dickei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="7" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="used" lemma="use" stem="us" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="string" lemma="string" stem="string" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="obscenities" lemma="obscenity" stem="obscen" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="15" string="conversation" lemma="conversation" stem="convers" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="booked" lemma="book" stem="book" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="22" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="suspicion" lemma="suspicion" stem="suspicion" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="24" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="using" lemma="use" stem="us" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="26" string="offensive" lemma="offensive" stem="offens" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="27" string="language" lemma="language" stem="languag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="28" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="29" string="challenging" lemma="challenge" stem="challeng" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="30" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="31" string="officer" lemma="officer" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="32" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="33" string="fight" lemma="fight" stem="fight" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="34" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="35" string="obstructing" lemma="obstruct" stem="obstruct" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="36" string="arrest" lemma="arrest" stem="arrest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="37" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN group)) (ADVP (RB also)) (VP (VBD complained) (SBAR (IN that) (S (NP (NNP Dickey)) (ADVP (RB also)) (VP (VBD used) (NP (NP (DT a) (NN string)) (PP (IN of) (NP (NP (NNS obscenities)) (PP (IN in) (NP (PRP$ his) (NN conversation)))))) (PP (IN with) (NP (NP (NNP Jackson)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBD was) (VP (VBN booked) (PP (IN for) (NP (NP (NN suspicion)) (PP (IN of) (S (VP (VP (VBG using) (NP (JJ offensive) (NN language))) (, ,) (VP (VBG challenging) (NP (DT an) (NN officer) (S (VP (TO to) (VP (VB fight)))))) (CC and) (VP (VBG obstructing) (NP (NN arrest)))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="that Dickey also used a string of obscenities in his conversation with Jackson , who was booked for suspicion of using offensive language , challenging an officer to fight and obstructing arrest" type="SBAR">
          <tokens>
            <token id="5" string="that" />
            <token id="6" string="Dickey" />
            <token id="7" string="also" />
            <token id="8" string="used" />
            <token id="9" string="a" />
            <token id="10" string="string" />
            <token id="11" string="of" />
            <token id="12" string="obscenities" />
            <token id="13" string="in" />
            <token id="14" string="his" />
            <token id="15" string="conversation" />
            <token id="16" string="with" />
            <token id="17" string="Jackson" />
            <token id="18" string="," />
            <token id="19" string="who" />
            <token id="20" string="was" />
            <token id="21" string="booked" />
            <token id="22" string="for" />
            <token id="23" string="suspicion" />
            <token id="24" string="of" />
            <token id="25" string="using" />
            <token id="26" string="offensive" />
            <token id="27" string="language" />
            <token id="28" string="," />
            <token id="29" string="challenging" />
            <token id="30" string="an" />
            <token id="31" string="officer" />
            <token id="32" string="to" />
            <token id="33" string="fight" />
            <token id="34" string="and" />
            <token id="35" string="obstructing" />
            <token id="36" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="2" string="suspicion" type="NP">
          <tokens>
            <token id="23" string="suspicion" />
          </tokens>
        </chunking>
        <chunking id="3" string="was booked for suspicion of using offensive language , challenging an officer to fight and obstructing arrest" type="VP">
          <tokens>
            <token id="20" string="was" />
            <token id="21" string="booked" />
            <token id="22" string="for" />
            <token id="23" string="suspicion" />
            <token id="24" string="of" />
            <token id="25" string="using" />
            <token id="26" string="offensive" />
            <token id="27" string="language" />
            <token id="28" string="," />
            <token id="29" string="challenging" />
            <token id="30" string="an" />
            <token id="31" string="officer" />
            <token id="32" string="to" />
            <token id="33" string="fight" />
            <token id="34" string="and" />
            <token id="35" string="obstructing" />
            <token id="36" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="4" string="The group" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="group" />
          </tokens>
        </chunking>
        <chunking id="5" string="using offensive language , challenging an officer to fight and obstructing arrest" type="VP">
          <tokens>
            <token id="25" string="using" />
            <token id="26" string="offensive" />
            <token id="27" string="language" />
            <token id="28" string="," />
            <token id="29" string="challenging" />
            <token id="30" string="an" />
            <token id="31" string="officer" />
            <token id="32" string="to" />
            <token id="33" string="fight" />
            <token id="34" string="and" />
            <token id="35" string="obstructing" />
            <token id="36" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="6" string="to fight" type="VP">
          <tokens>
            <token id="32" string="to" />
            <token id="33" string="fight" />
          </tokens>
        </chunking>
        <chunking id="7" string="his conversation" type="NP">
          <tokens>
            <token id="14" string="his" />
            <token id="15" string="conversation" />
          </tokens>
        </chunking>
        <chunking id="8" string="complained that Dickey also used a string of obscenities in his conversation with Jackson , who was booked for suspicion of using offensive language , challenging an officer to fight and obstructing arrest" type="VP">
          <tokens>
            <token id="4" string="complained" />
            <token id="5" string="that" />
            <token id="6" string="Dickey" />
            <token id="7" string="also" />
            <token id="8" string="used" />
            <token id="9" string="a" />
            <token id="10" string="string" />
            <token id="11" string="of" />
            <token id="12" string="obscenities" />
            <token id="13" string="in" />
            <token id="14" string="his" />
            <token id="15" string="conversation" />
            <token id="16" string="with" />
            <token id="17" string="Jackson" />
            <token id="18" string="," />
            <token id="19" string="who" />
            <token id="20" string="was" />
            <token id="21" string="booked" />
            <token id="22" string="for" />
            <token id="23" string="suspicion" />
            <token id="24" string="of" />
            <token id="25" string="using" />
            <token id="26" string="offensive" />
            <token id="27" string="language" />
            <token id="28" string="," />
            <token id="29" string="challenging" />
            <token id="30" string="an" />
            <token id="31" string="officer" />
            <token id="32" string="to" />
            <token id="33" string="fight" />
            <token id="34" string="and" />
            <token id="35" string="obstructing" />
            <token id="36" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="9" string="used a string of obscenities in his conversation with Jackson , who was booked for suspicion of using offensive language , challenging an officer to fight and obstructing arrest" type="VP">
          <tokens>
            <token id="8" string="used" />
            <token id="9" string="a" />
            <token id="10" string="string" />
            <token id="11" string="of" />
            <token id="12" string="obscenities" />
            <token id="13" string="in" />
            <token id="14" string="his" />
            <token id="15" string="conversation" />
            <token id="16" string="with" />
            <token id="17" string="Jackson" />
            <token id="18" string="," />
            <token id="19" string="who" />
            <token id="20" string="was" />
            <token id="21" string="booked" />
            <token id="22" string="for" />
            <token id="23" string="suspicion" />
            <token id="24" string="of" />
            <token id="25" string="using" />
            <token id="26" string="offensive" />
            <token id="27" string="language" />
            <token id="28" string="," />
            <token id="29" string="challenging" />
            <token id="30" string="an" />
            <token id="31" string="officer" />
            <token id="32" string="to" />
            <token id="33" string="fight" />
            <token id="34" string="and" />
            <token id="35" string="obstructing" />
            <token id="36" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="10" string="obstructing arrest" type="VP">
          <tokens>
            <token id="35" string="obstructing" />
            <token id="36" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="11" string="using offensive language" type="VP">
          <tokens>
            <token id="25" string="using" />
            <token id="26" string="offensive" />
            <token id="27" string="language" />
          </tokens>
        </chunking>
        <chunking id="12" string="a string of obscenities in his conversation" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="string" />
            <token id="11" string="of" />
            <token id="12" string="obscenities" />
            <token id="13" string="in" />
            <token id="14" string="his" />
            <token id="15" string="conversation" />
          </tokens>
        </chunking>
        <chunking id="13" string="Jackson , who was booked for suspicion of using offensive language , challenging an officer to fight and obstructing arrest" type="NP">
          <tokens>
            <token id="17" string="Jackson" />
            <token id="18" string="," />
            <token id="19" string="who" />
            <token id="20" string="was" />
            <token id="21" string="booked" />
            <token id="22" string="for" />
            <token id="23" string="suspicion" />
            <token id="24" string="of" />
            <token id="25" string="using" />
            <token id="26" string="offensive" />
            <token id="27" string="language" />
            <token id="28" string="," />
            <token id="29" string="challenging" />
            <token id="30" string="an" />
            <token id="31" string="officer" />
            <token id="32" string="to" />
            <token id="33" string="fight" />
            <token id="34" string="and" />
            <token id="35" string="obstructing" />
            <token id="36" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="14" string="suspicion of using offensive language , challenging an officer to fight and obstructing arrest" type="NP">
          <tokens>
            <token id="23" string="suspicion" />
            <token id="24" string="of" />
            <token id="25" string="using" />
            <token id="26" string="offensive" />
            <token id="27" string="language" />
            <token id="28" string="," />
            <token id="29" string="challenging" />
            <token id="30" string="an" />
            <token id="31" string="officer" />
            <token id="32" string="to" />
            <token id="33" string="fight" />
            <token id="34" string="and" />
            <token id="35" string="obstructing" />
            <token id="36" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="15" string="Dickey" type="NP">
          <tokens>
            <token id="6" string="Dickey" />
          </tokens>
        </chunking>
        <chunking id="16" string="a string" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="string" />
          </tokens>
        </chunking>
        <chunking id="17" string="fight" type="VP">
          <tokens>
            <token id="33" string="fight" />
          </tokens>
        </chunking>
        <chunking id="18" string="arrest" type="NP">
          <tokens>
            <token id="36" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="19" string="who was booked for suspicion of using offensive language , challenging an officer to fight and obstructing arrest" type="SBAR">
          <tokens>
            <token id="19" string="who" />
            <token id="20" string="was" />
            <token id="21" string="booked" />
            <token id="22" string="for" />
            <token id="23" string="suspicion" />
            <token id="24" string="of" />
            <token id="25" string="using" />
            <token id="26" string="offensive" />
            <token id="27" string="language" />
            <token id="28" string="," />
            <token id="29" string="challenging" />
            <token id="30" string="an" />
            <token id="31" string="officer" />
            <token id="32" string="to" />
            <token id="33" string="fight" />
            <token id="34" string="and" />
            <token id="35" string="obstructing" />
            <token id="36" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="20" string="Jackson" type="NP">
          <tokens>
            <token id="17" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="21" string="an officer to fight" type="NP">
          <tokens>
            <token id="30" string="an" />
            <token id="31" string="officer" />
            <token id="32" string="to" />
            <token id="33" string="fight" />
          </tokens>
        </chunking>
        <chunking id="22" string="booked for suspicion of using offensive language , challenging an officer to fight and obstructing arrest" type="VP">
          <tokens>
            <token id="21" string="booked" />
            <token id="22" string="for" />
            <token id="23" string="suspicion" />
            <token id="24" string="of" />
            <token id="25" string="using" />
            <token id="26" string="offensive" />
            <token id="27" string="language" />
            <token id="28" string="," />
            <token id="29" string="challenging" />
            <token id="30" string="an" />
            <token id="31" string="officer" />
            <token id="32" string="to" />
            <token id="33" string="fight" />
            <token id="34" string="and" />
            <token id="35" string="obstructing" />
            <token id="36" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="23" string="offensive language" type="NP">
          <tokens>
            <token id="26" string="offensive" />
            <token id="27" string="language" />
          </tokens>
        </chunking>
        <chunking id="24" string="obscenities in his conversation" type="NP">
          <tokens>
            <token id="12" string="obscenities" />
            <token id="13" string="in" />
            <token id="14" string="his" />
            <token id="15" string="conversation" />
          </tokens>
        </chunking>
        <chunking id="25" string="challenging an officer to fight" type="VP">
          <tokens>
            <token id="29" string="challenging" />
            <token id="30" string="an" />
            <token id="31" string="officer" />
            <token id="32" string="to" />
            <token id="33" string="fight" />
          </tokens>
        </chunking>
        <chunking id="26" string="obscenities" type="NP">
          <tokens>
            <token id="12" string="obscenities" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">group</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">complained</governor>
          <dependent id="2">group</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">complained</governor>
          <dependent id="3">also</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">complained</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">used</governor>
          <dependent id="5">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">used</governor>
          <dependent id="6">Dickey</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">used</governor>
          <dependent id="7">also</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">complained</governor>
          <dependent id="8">used</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">string</governor>
          <dependent id="9">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">used</governor>
          <dependent id="10">string</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">obscenities</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">string</governor>
          <dependent id="12">obscenities</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">conversation</governor>
          <dependent id="13">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="15">conversation</governor>
          <dependent id="14">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">obscenities</governor>
          <dependent id="15">conversation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">Jackson</governor>
          <dependent id="16">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">used</governor>
          <dependent id="17">Jackson</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="21">booked</governor>
          <dependent id="19">who</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="21">booked</governor>
          <dependent id="20">was</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="17">Jackson</governor>
          <dependent id="21">booked</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">suspicion</governor>
          <dependent id="22">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">booked</governor>
          <dependent id="23">suspicion</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="25">using</governor>
          <dependent id="24">of</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="23">suspicion</governor>
          <dependent id="25">using</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="27">language</governor>
          <dependent id="26">offensive</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="25">using</governor>
          <dependent id="27">language</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="25">using</governor>
          <dependent id="29">challenging</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">officer</governor>
          <dependent id="30">an</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="29">challenging</governor>
          <dependent id="31">officer</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="33">fight</governor>
          <dependent id="32">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="31">officer</governor>
          <dependent id="33">fight</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="25">using</governor>
          <dependent id="34">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="25">using</governor>
          <dependent id="35">obstructing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="35">obstructing</governor>
          <dependent id="36">arrest</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Jackson" type="PERSON" score="0.0">
          <tokens>
            <token id="17" string="Jackson" />
          </tokens>
        </entity>
        <entity id="2" string="Dickey" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Dickey" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="33" has_coreference="true">
      <content>He was released on his own recognizance pending a Jan. 25 court appearance.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="released" lemma="release" stem="releas" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="own" lemma="own" stem="own" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="recognizance" lemma="recognizance" stem="recogniz" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="pending" lemma="pend" stem="pend" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="Jan." lemma="Jan." stem="jan." pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="11" string="25" lemma="25" stem="25" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="12" string="court" lemma="court" stem="court" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="appearance" lemma="appearance" stem="appear" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VBD was) (VP (VBN released) (PP (IN on) (NP (NP (PRP$ his) (JJ own) (NN recognizance)) (PP (VBG pending) (NP (DT a) (NNP Jan.) (CD 25) (NN court) (NN appearance))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="his own recognizance pending a Jan. 25 court appearance" type="NP">
          <tokens>
            <token id="5" string="his" />
            <token id="6" string="own" />
            <token id="7" string="recognizance" />
            <token id="8" string="pending" />
            <token id="9" string="a" />
            <token id="10" string="Jan." />
            <token id="11" string="25" />
            <token id="12" string="court" />
            <token id="13" string="appearance" />
          </tokens>
        </chunking>
        <chunking id="2" string="a Jan. 25 court appearance" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="Jan." />
            <token id="11" string="25" />
            <token id="12" string="court" />
            <token id="13" string="appearance" />
          </tokens>
        </chunking>
        <chunking id="3" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="4" string="his own recognizance" type="NP">
          <tokens>
            <token id="5" string="his" />
            <token id="6" string="own" />
            <token id="7" string="recognizance" />
          </tokens>
        </chunking>
        <chunking id="5" string="was released on his own recognizance pending a Jan. 25 court appearance" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="released" />
            <token id="4" string="on" />
            <token id="5" string="his" />
            <token id="6" string="own" />
            <token id="7" string="recognizance" />
            <token id="8" string="pending" />
            <token id="9" string="a" />
            <token id="10" string="Jan." />
            <token id="11" string="25" />
            <token id="12" string="court" />
            <token id="13" string="appearance" />
          </tokens>
        </chunking>
        <chunking id="6" string="released on his own recognizance pending a Jan. 25 court appearance" type="VP">
          <tokens>
            <token id="3" string="released" />
            <token id="4" string="on" />
            <token id="5" string="his" />
            <token id="6" string="own" />
            <token id="7" string="recognizance" />
            <token id="8" string="pending" />
            <token id="9" string="a" />
            <token id="10" string="Jan." />
            <token id="11" string="25" />
            <token id="12" string="court" />
            <token id="13" string="appearance" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="3">released</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="3">released</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">released</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">recognizance</governor>
          <dependent id="4">on</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="7">recognizance</governor>
          <dependent id="5">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">recognizance</governor>
          <dependent id="6">own</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">released</governor>
          <dependent id="7">recognizance</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">appearance</governor>
          <dependent id="8">pending</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">appearance</governor>
          <dependent id="9">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">appearance</governor>
          <dependent id="10">Jan.</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="13">appearance</governor>
          <dependent id="11">25</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">appearance</governor>
          <dependent id="12">court</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">recognizance</governor>
          <dependent id="13">appearance</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Jan. 25" type="DATE" score="0.0">
          <tokens>
            <token id="10" string="Jan." />
            <token id="11" string="25" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="34" has_coreference="true">
      <content>Clarence Smith, the only black member of the Long Beach City Council, said he found the tape &amp;quot;shocking.&amp;quot;</content>
      <tokens>
        <token id="1" string="Clarence" lemma="Clarence" stem="clarenc" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="Smith" lemma="Smith" stem="smith" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="only" lemma="only" stem="onli" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="black" lemma="black" stem="black" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="member" lemma="member" stem="member" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Long" lemma="Long" stem="long" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="11" string="Beach" lemma="Beach" stem="beach" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="12" string="City" lemma="City" stem="citi" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="13" string="Council" lemma="Council" stem="council" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="found" lemma="find" stem="found" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="tape" lemma="tape" stem="tape" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="shocking" lemma="shocking" stem="shock" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Clarence) (NNP Smith)) (, ,) (NP (NP (DT the) (JJ only) (JJ black) (NN member)) (PP (IN of) (NP (DT the) (NNP Long) (NNP Beach) (NNP City) (NNP Council)))) (, ,)) (VP (VBD said) (SBAR (S (NP (PRP he)) (VP (VBD found) (S (NP (DT the) (NN tape)) (`` ``) (ADJP (JJ shocking))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="the only black member of the Long Beach City Council" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="only" />
            <token id="6" string="black" />
            <token id="7" string="member" />
            <token id="8" string="of" />
            <token id="9" string="the" />
            <token id="10" string="Long" />
            <token id="11" string="Beach" />
            <token id="12" string="City" />
            <token id="13" string="Council" />
          </tokens>
        </chunking>
        <chunking id="2" string="shocking" type="ADJP">
          <tokens>
            <token id="21" string="shocking" />
          </tokens>
        </chunking>
        <chunking id="3" string="he found the tape `` shocking" type="SBAR">
          <tokens>
            <token id="16" string="he" />
            <token id="17" string="found" />
            <token id="18" string="the" />
            <token id="19" string="tape" />
            <token id="20" string="&quot;" />
            <token id="21" string="shocking" />
          </tokens>
        </chunking>
        <chunking id="4" string="Clarence Smith" type="NP">
          <tokens>
            <token id="1" string="Clarence" />
            <token id="2" string="Smith" />
          </tokens>
        </chunking>
        <chunking id="5" string="the only black member" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="only" />
            <token id="6" string="black" />
            <token id="7" string="member" />
          </tokens>
        </chunking>
        <chunking id="6" string="the tape" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="tape" />
          </tokens>
        </chunking>
        <chunking id="7" string="the Long Beach City Council" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="Long" />
            <token id="11" string="Beach" />
            <token id="12" string="City" />
            <token id="13" string="Council" />
          </tokens>
        </chunking>
        <chunking id="8" string="found the tape `` shocking" type="VP">
          <tokens>
            <token id="17" string="found" />
            <token id="18" string="the" />
            <token id="19" string="tape" />
            <token id="20" string="&quot;" />
            <token id="21" string="shocking" />
          </tokens>
        </chunking>
        <chunking id="9" string="Clarence Smith , the only black member of the Long Beach City Council ," type="NP">
          <tokens>
            <token id="1" string="Clarence" />
            <token id="2" string="Smith" />
            <token id="3" string="," />
            <token id="4" string="the" />
            <token id="5" string="only" />
            <token id="6" string="black" />
            <token id="7" string="member" />
            <token id="8" string="of" />
            <token id="9" string="the" />
            <token id="10" string="Long" />
            <token id="11" string="Beach" />
            <token id="12" string="City" />
            <token id="13" string="Council" />
            <token id="14" string="," />
          </tokens>
        </chunking>
        <chunking id="10" string="he" type="NP">
          <tokens>
            <token id="16" string="he" />
          </tokens>
        </chunking>
        <chunking id="11" string="said he found the tape `` shocking" type="VP">
          <tokens>
            <token id="15" string="said" />
            <token id="16" string="he" />
            <token id="17" string="found" />
            <token id="18" string="the" />
            <token id="19" string="tape" />
            <token id="20" string="&quot;" />
            <token id="21" string="shocking" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Smith</governor>
          <dependent id="1">Clarence</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">said</governor>
          <dependent id="2">Smith</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">member</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">member</governor>
          <dependent id="5">only</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">member</governor>
          <dependent id="6">black</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="2">Smith</governor>
          <dependent id="7">member</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Council</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">Council</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Council</governor>
          <dependent id="10">Long</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Council</governor>
          <dependent id="11">Beach</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Council</governor>
          <dependent id="12">City</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">member</governor>
          <dependent id="13">Council</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">found</governor>
          <dependent id="16">he</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="15">said</governor>
          <dependent id="17">found</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">tape</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="21">shocking</governor>
          <dependent id="19">tape</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="17">found</governor>
          <dependent id="21">shocking</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Clarence Smith" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Clarence" />
            <token id="2" string="Smith" />
          </tokens>
        </entity>
        <entity id="2" string="Long Beach City Council" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="10" string="Long" />
            <token id="11" string="Beach" />
            <token id="12" string="City" />
            <token id="13" string="Council" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="35" has_coreference="true">
      <content>But other city officials argued that the television footage was not necessarily conclusive because it showed the altercation from only one angle and showed Jackson and Dickey only from the waist up.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="city" lemma="city" stem="citi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="officials" lemma="official" stem="offici" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="argued" lemma="argue" stem="argu" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="television" lemma="television" stem="televis" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="footage" lemma="footage" stem="footag" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="necessarily" lemma="necessarily" stem="necessarili" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="conclusive" lemma="conclusive" stem="conclus" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="showed" lemma="show" stem="show" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="altercation" lemma="altercation" stem="alterc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="19" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="only" lemma="only" stem="onli" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="22" string="angle" lemma="angle" stem="angl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="showed" lemma="show" stem="show" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="26" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="27" string="Dickey" lemma="Dickey" stem="dickei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="28" string="only" lemma="only" stem="onli" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="31" string="waist" lemma="waist" stem="waist" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="32" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (JJ other) (NN city) (NNS officials)) (VP (VBD argued) (SBAR (IN that) (S (NP (DT the) (NN television) (NN footage)) (VP (VBD was) (RB not) (ADJP (RB necessarily) (JJ conclusive)) (SBAR (IN because) (S (NP (PRP it)) (VP (VP (VBD showed) (NP (DT the) (NN altercation)) (PP (IN from) (NP (RB only) (CD one) (NN angle)))) (CC and) (VP (VBD showed) (NP (NNP Jackson) (CC and) (NNP Dickey)) (ADVP (RB only)) (PP (IN from) (NP (DT the) (NN waist))) (ADVP (RP up)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="argued that the television footage was not necessarily conclusive because it showed the altercation from only one angle and showed Jackson and Dickey only from the waist up" type="VP">
          <tokens>
            <token id="5" string="argued" />
            <token id="6" string="that" />
            <token id="7" string="the" />
            <token id="8" string="television" />
            <token id="9" string="footage" />
            <token id="10" string="was" />
            <token id="11" string="not" />
            <token id="12" string="necessarily" />
            <token id="13" string="conclusive" />
            <token id="14" string="because" />
            <token id="15" string="it" />
            <token id="16" string="showed" />
            <token id="17" string="the" />
            <token id="18" string="altercation" />
            <token id="19" string="from" />
            <token id="20" string="only" />
            <token id="21" string="one" />
            <token id="22" string="angle" />
            <token id="23" string="and" />
            <token id="24" string="showed" />
            <token id="25" string="Jackson" />
            <token id="26" string="and" />
            <token id="27" string="Dickey" />
            <token id="28" string="only" />
            <token id="29" string="from" />
            <token id="30" string="the" />
            <token id="31" string="waist" />
            <token id="32" string="up" />
          </tokens>
        </chunking>
        <chunking id="2" string="showed the altercation from only one angle" type="VP">
          <tokens>
            <token id="16" string="showed" />
            <token id="17" string="the" />
            <token id="18" string="altercation" />
            <token id="19" string="from" />
            <token id="20" string="only" />
            <token id="21" string="one" />
            <token id="22" string="angle" />
          </tokens>
        </chunking>
        <chunking id="3" string="other city officials" type="NP">
          <tokens>
            <token id="2" string="other" />
            <token id="3" string="city" />
            <token id="4" string="officials" />
          </tokens>
        </chunking>
        <chunking id="4" string="was not necessarily conclusive because it showed the altercation from only one angle and showed Jackson and Dickey only from the waist up" type="VP">
          <tokens>
            <token id="10" string="was" />
            <token id="11" string="not" />
            <token id="12" string="necessarily" />
            <token id="13" string="conclusive" />
            <token id="14" string="because" />
            <token id="15" string="it" />
            <token id="16" string="showed" />
            <token id="17" string="the" />
            <token id="18" string="altercation" />
            <token id="19" string="from" />
            <token id="20" string="only" />
            <token id="21" string="one" />
            <token id="22" string="angle" />
            <token id="23" string="and" />
            <token id="24" string="showed" />
            <token id="25" string="Jackson" />
            <token id="26" string="and" />
            <token id="27" string="Dickey" />
            <token id="28" string="only" />
            <token id="29" string="from" />
            <token id="30" string="the" />
            <token id="31" string="waist" />
            <token id="32" string="up" />
          </tokens>
        </chunking>
        <chunking id="5" string="necessarily conclusive" type="ADJP">
          <tokens>
            <token id="12" string="necessarily" />
            <token id="13" string="conclusive" />
          </tokens>
        </chunking>
        <chunking id="6" string="showed the altercation from only one angle and showed Jackson and Dickey only from the waist up" type="VP">
          <tokens>
            <token id="16" string="showed" />
            <token id="17" string="the" />
            <token id="18" string="altercation" />
            <token id="19" string="from" />
            <token id="20" string="only" />
            <token id="21" string="one" />
            <token id="22" string="angle" />
            <token id="23" string="and" />
            <token id="24" string="showed" />
            <token id="25" string="Jackson" />
            <token id="26" string="and" />
            <token id="27" string="Dickey" />
            <token id="28" string="only" />
            <token id="29" string="from" />
            <token id="30" string="the" />
            <token id="31" string="waist" />
            <token id="32" string="up" />
          </tokens>
        </chunking>
        <chunking id="7" string="that the television footage was not necessarily conclusive because it showed the altercation from only one angle and showed Jackson and Dickey only from the waist up" type="SBAR">
          <tokens>
            <token id="6" string="that" />
            <token id="7" string="the" />
            <token id="8" string="television" />
            <token id="9" string="footage" />
            <token id="10" string="was" />
            <token id="11" string="not" />
            <token id="12" string="necessarily" />
            <token id="13" string="conclusive" />
            <token id="14" string="because" />
            <token id="15" string="it" />
            <token id="16" string="showed" />
            <token id="17" string="the" />
            <token id="18" string="altercation" />
            <token id="19" string="from" />
            <token id="20" string="only" />
            <token id="21" string="one" />
            <token id="22" string="angle" />
            <token id="23" string="and" />
            <token id="24" string="showed" />
            <token id="25" string="Jackson" />
            <token id="26" string="and" />
            <token id="27" string="Dickey" />
            <token id="28" string="only" />
            <token id="29" string="from" />
            <token id="30" string="the" />
            <token id="31" string="waist" />
            <token id="32" string="up" />
          </tokens>
        </chunking>
        <chunking id="8" string="it" type="NP">
          <tokens>
            <token id="15" string="it" />
          </tokens>
        </chunking>
        <chunking id="9" string="because it showed the altercation from only one angle and showed Jackson and Dickey only from the waist up" type="SBAR">
          <tokens>
            <token id="14" string="because" />
            <token id="15" string="it" />
            <token id="16" string="showed" />
            <token id="17" string="the" />
            <token id="18" string="altercation" />
            <token id="19" string="from" />
            <token id="20" string="only" />
            <token id="21" string="one" />
            <token id="22" string="angle" />
            <token id="23" string="and" />
            <token id="24" string="showed" />
            <token id="25" string="Jackson" />
            <token id="26" string="and" />
            <token id="27" string="Dickey" />
            <token id="28" string="only" />
            <token id="29" string="from" />
            <token id="30" string="the" />
            <token id="31" string="waist" />
            <token id="32" string="up" />
          </tokens>
        </chunking>
        <chunking id="10" string="Jackson and Dickey" type="NP">
          <tokens>
            <token id="25" string="Jackson" />
            <token id="26" string="and" />
            <token id="27" string="Dickey" />
          </tokens>
        </chunking>
        <chunking id="11" string="only one angle" type="NP">
          <tokens>
            <token id="20" string="only" />
            <token id="21" string="one" />
            <token id="22" string="angle" />
          </tokens>
        </chunking>
        <chunking id="12" string="the altercation" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="altercation" />
          </tokens>
        </chunking>
        <chunking id="13" string="the waist" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="waist" />
          </tokens>
        </chunking>
        <chunking id="14" string="showed Jackson and Dickey only from the waist up" type="VP">
          <tokens>
            <token id="24" string="showed" />
            <token id="25" string="Jackson" />
            <token id="26" string="and" />
            <token id="27" string="Dickey" />
            <token id="28" string="only" />
            <token id="29" string="from" />
            <token id="30" string="the" />
            <token id="31" string="waist" />
            <token id="32" string="up" />
          </tokens>
        </chunking>
        <chunking id="15" string="the television footage" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="television" />
            <token id="9" string="footage" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="5">argued</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">officials</governor>
          <dependent id="2">other</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">officials</governor>
          <dependent id="3">city</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">argued</governor>
          <dependent id="4">officials</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">argued</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">conclusive</governor>
          <dependent id="6">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">footage</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">footage</governor>
          <dependent id="8">television</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">conclusive</governor>
          <dependent id="9">footage</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="13">conclusive</governor>
          <dependent id="10">was</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="13">conclusive</governor>
          <dependent id="11">not</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">conclusive</governor>
          <dependent id="12">necessarily</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">argued</governor>
          <dependent id="13">conclusive</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">showed</governor>
          <dependent id="14">because</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">showed</governor>
          <dependent id="15">it</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="13">conclusive</governor>
          <dependent id="16">showed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">altercation</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">showed</governor>
          <dependent id="18">altercation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">angle</governor>
          <dependent id="19">from</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="22">angle</governor>
          <dependent id="20">only</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="22">angle</governor>
          <dependent id="21">one</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">showed</governor>
          <dependent id="22">angle</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="16">showed</governor>
          <dependent id="23">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">showed</governor>
          <dependent id="24">showed</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="24">showed</governor>
          <dependent id="25">Jackson</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="25">Jackson</governor>
          <dependent id="26">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="25">Jackson</governor>
          <dependent id="27">Dickey</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="24">showed</governor>
          <dependent id="28">only</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">waist</governor>
          <dependent id="29">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">waist</governor>
          <dependent id="30">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">showed</governor>
          <dependent id="31">waist</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="24">showed</governor>
          <dependent id="32">up</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="21" string="one" />
          </tokens>
        </entity>
        <entity id="2" string="Jackson" type="PERSON" score="0.0">
          <tokens>
            <token id="25" string="Jackson" />
          </tokens>
        </entity>
        <entity id="3" string="Dickey" type="PERSON" score="0.0">
          <tokens>
            <token id="27" string="Dickey" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="36" has_coreference="true">
      <content>&amp;quot;It&amp;apost;s real hard to tell what&amp;apost;s happening below the waist,&amp;quot; said Councilman Evan Anderson Braude, maintaining that it is vital that NBC release the rest of its videotapes.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="real" lemma="real" stem="real" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="hard" lemma="hard" stem="hard" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="tell" lemma="tell" stem="tell" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="happening" lemma="happen" stem="happen" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="below" lemma="below" stem="below" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="waist" lemma="waist" stem="waist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="Councilman" lemma="Councilman" stem="councilman" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="18" string="Evan" lemma="Evan" stem="evan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="19" string="Anderson" lemma="Anderson" stem="anderson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="20" string="Braude" lemma="Braude" stem="braud" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="maintaining" lemma="maintain" stem="maintain" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="vital" lemma="vital" stem="vital" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="NBC" lemma="NBC" stem="nbc" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="29" string="release" lemma="release" stem="releas" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="rest" lemma="rest" stem="rest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="34" string="videotapes" lemma="videotape" stem="videotap" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (NP (PRP It)) (VP (VBZ 's) (ADVP (JJ real)) (ADJP (JJ hard) (S (VP (TO to) (VP (VB tell) (SBAR (WHNP (WP what)) (S (VP (VBZ 's) (VP (VBG happening) (PP (IN below) (NP (DT the) (NN waist))))))))))))) (, ,) ('' '') (VP (VBD said)) (NP (NNP Councilman) (NNP Evan) (NNP Anderson) (NNP Braude)) (, ,) (S (VP (VBG maintaining) (SBAR (IN that) (S (NP (PRP it)) (VP (VBZ is) (ADJP (JJ vital)) (SBAR (IN that) (S (NP (NNP NBC)) (VP (VBP release) (NP (NP (DT the) (NN rest)) (PP (IN of) (NP (PRP$ its) (NNS videotapes)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the rest" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="rest" />
          </tokens>
        </chunking>
        <chunking id="2" string="release the rest of its videotapes" type="VP">
          <tokens>
            <token id="29" string="release" />
            <token id="30" string="the" />
            <token id="31" string="rest" />
            <token id="32" string="of" />
            <token id="33" string="its" />
            <token id="34" string="videotapes" />
          </tokens>
        </chunking>
        <chunking id="3" string="happening below the waist" type="VP">
          <tokens>
            <token id="10" string="happening" />
            <token id="11" string="below" />
            <token id="12" string="the" />
            <token id="13" string="waist" />
          </tokens>
        </chunking>
        <chunking id="4" string="that it is vital that NBC release the rest of its videotapes" type="SBAR">
          <tokens>
            <token id="23" string="that" />
            <token id="24" string="it" />
            <token id="25" string="is" />
            <token id="26" string="vital" />
            <token id="27" string="that" />
            <token id="28" string="NBC" />
            <token id="29" string="release" />
            <token id="30" string="the" />
            <token id="31" string="rest" />
            <token id="32" string="of" />
            <token id="33" string="its" />
            <token id="34" string="videotapes" />
          </tokens>
        </chunking>
        <chunking id="5" string="its videotapes" type="NP">
          <tokens>
            <token id="33" string="its" />
            <token id="34" string="videotapes" />
          </tokens>
        </chunking>
        <chunking id="6" string="tell what 's happening below the waist" type="VP">
          <tokens>
            <token id="7" string="tell" />
            <token id="8" string="what" />
            <token id="9" string="'s" />
            <token id="10" string="happening" />
            <token id="11" string="below" />
            <token id="12" string="the" />
            <token id="13" string="waist" />
          </tokens>
        </chunking>
        <chunking id="7" string="maintaining that it is vital that NBC release the rest of its videotapes" type="VP">
          <tokens>
            <token id="22" string="maintaining" />
            <token id="23" string="that" />
            <token id="24" string="it" />
            <token id="25" string="is" />
            <token id="26" string="vital" />
            <token id="27" string="that" />
            <token id="28" string="NBC" />
            <token id="29" string="release" />
            <token id="30" string="the" />
            <token id="31" string="rest" />
            <token id="32" string="of" />
            <token id="33" string="its" />
            <token id="34" string="videotapes" />
          </tokens>
        </chunking>
        <chunking id="8" string="hard to tell what 's happening below the waist" type="ADJP">
          <tokens>
            <token id="5" string="hard" />
            <token id="6" string="to" />
            <token id="7" string="tell" />
            <token id="8" string="what" />
            <token id="9" string="'s" />
            <token id="10" string="happening" />
            <token id="11" string="below" />
            <token id="12" string="the" />
            <token id="13" string="waist" />
          </tokens>
        </chunking>
        <chunking id="9" string="Councilman Evan Anderson Braude" type="NP">
          <tokens>
            <token id="17" string="Councilman" />
            <token id="18" string="Evan" />
            <token id="19" string="Anderson" />
            <token id="20" string="Braude" />
          </tokens>
        </chunking>
        <chunking id="10" string="the rest of its videotapes" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="rest" />
            <token id="32" string="of" />
            <token id="33" string="its" />
            <token id="34" string="videotapes" />
          </tokens>
        </chunking>
        <chunking id="11" string="It" type="NP">
          <tokens>
            <token id="2" string="It" />
          </tokens>
        </chunking>
        <chunking id="12" string="it" type="NP">
          <tokens>
            <token id="24" string="it" />
          </tokens>
        </chunking>
        <chunking id="13" string="what 's happening below the waist" type="SBAR">
          <tokens>
            <token id="8" string="what" />
            <token id="9" string="'s" />
            <token id="10" string="happening" />
            <token id="11" string="below" />
            <token id="12" string="the" />
            <token id="13" string="waist" />
          </tokens>
        </chunking>
        <chunking id="14" string="NBC" type="NP">
          <tokens>
            <token id="28" string="NBC" />
          </tokens>
        </chunking>
        <chunking id="15" string="'s real hard to tell what 's happening below the waist" type="VP">
          <tokens>
            <token id="3" string="'s" />
            <token id="4" string="real" />
            <token id="5" string="hard" />
            <token id="6" string="to" />
            <token id="7" string="tell" />
            <token id="8" string="what" />
            <token id="9" string="'s" />
            <token id="10" string="happening" />
            <token id="11" string="below" />
            <token id="12" string="the" />
            <token id="13" string="waist" />
          </tokens>
        </chunking>
        <chunking id="16" string="is vital that NBC release the rest of its videotapes" type="VP">
          <tokens>
            <token id="25" string="is" />
            <token id="26" string="vital" />
            <token id="27" string="that" />
            <token id="28" string="NBC" />
            <token id="29" string="release" />
            <token id="30" string="the" />
            <token id="31" string="rest" />
            <token id="32" string="of" />
            <token id="33" string="its" />
            <token id="34" string="videotapes" />
          </tokens>
        </chunking>
        <chunking id="17" string="that NBC release the rest of its videotapes" type="SBAR">
          <tokens>
            <token id="27" string="that" />
            <token id="28" string="NBC" />
            <token id="29" string="release" />
            <token id="30" string="the" />
            <token id="31" string="rest" />
            <token id="32" string="of" />
            <token id="33" string="its" />
            <token id="34" string="videotapes" />
          </tokens>
        </chunking>
        <chunking id="18" string="to tell what 's happening below the waist" type="VP">
          <tokens>
            <token id="6" string="to" />
            <token id="7" string="tell" />
            <token id="8" string="what" />
            <token id="9" string="'s" />
            <token id="10" string="happening" />
            <token id="11" string="below" />
            <token id="12" string="the" />
            <token id="13" string="waist" />
          </tokens>
        </chunking>
        <chunking id="19" string="the waist" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="waist" />
          </tokens>
        </chunking>
        <chunking id="20" string="vital" type="ADJP">
          <tokens>
            <token id="26" string="vital" />
          </tokens>
        </chunking>
        <chunking id="21" string="'s happening below the waist" type="VP">
          <tokens>
            <token id="9" string="'s" />
            <token id="10" string="happening" />
            <token id="11" string="below" />
            <token id="12" string="the" />
            <token id="13" string="waist" />
          </tokens>
        </chunking>
        <chunking id="22" string="said" type="VP">
          <tokens>
            <token id="16" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">hard</governor>
          <dependent id="2">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">hard</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">hard</governor>
          <dependent id="4">real</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="16">said</governor>
          <dependent id="5">hard</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">tell</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">hard</governor>
          <dependent id="7">tell</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">happening</governor>
          <dependent id="8">what</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="10">happening</governor>
          <dependent id="9">'s</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">tell</governor>
          <dependent id="10">happening</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">waist</governor>
          <dependent id="11">below</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">waist</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">happening</governor>
          <dependent id="13">waist</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="16">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">Braude</governor>
          <dependent id="17">Councilman</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">Braude</governor>
          <dependent id="18">Evan</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">Braude</governor>
          <dependent id="19">Anderson</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">said</governor>
          <dependent id="20">Braude</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="16">said</governor>
          <dependent id="22">maintaining</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="26">vital</governor>
          <dependent id="23">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">vital</governor>
          <dependent id="24">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="26">vital</governor>
          <dependent id="25">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="22">maintaining</governor>
          <dependent id="26">vital</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="29">release</governor>
          <dependent id="27">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">release</governor>
          <dependent id="28">NBC</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="26">vital</governor>
          <dependent id="29">release</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">rest</governor>
          <dependent id="30">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="29">release</governor>
          <dependent id="31">rest</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">videotapes</governor>
          <dependent id="32">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="34">videotapes</governor>
          <dependent id="33">its</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">rest</governor>
          <dependent id="34">videotapes</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Evan Anderson Braude" type="PERSON" score="0.0">
          <tokens>
            <token id="18" string="Evan" />
            <token id="19" string="Anderson" />
            <token id="20" string="Braude" />
          </tokens>
        </entity>
        <entity id="2" string="Councilman" type="MISC" score="0.0">
          <tokens>
            <token id="17" string="Councilman" />
          </tokens>
        </entity>
        <entity id="3" string="NBC" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="28" string="NBC" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="37" has_coreference="true">
      <content>Concedes Error by Officer Attorney Hannon conceded that Dickey was wrong to spice his orders to Jackson with obscenities, but he said the cursing was evidence of discourtesy, rather than racism.</content>
      <tokens>
        <token id="1" string="Concedes" lemma="concede" stem="conced" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="Error" lemma="error" stem="error" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Officer" lemma="Officer" stem="officer" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="Attorney" lemma="Attorney" stem="attornei" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="true" is_refers="false" />
        <token id="6" string="Hannon" lemma="Hannon" stem="hannon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="7" string="conceded" lemma="concede" stem="conced" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Dickey" lemma="Dickey" stem="dickei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="10" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="wrong" lemma="wrong" stem="wrong" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="spice" lemma="spice" stem="spice" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="orders" lemma="order" stem="order" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="18" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="obscenities" lemma="obscenity" stem="obscen" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="25" string="cursing" lemma="cursing" stem="curs" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="26" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="evidence" lemma="evidence" stem="evid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="discourtesy" lemma="discourtesy" stem="discourtesi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="rather" lemma="rather" stem="rather" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="racism" lemma="racism" stem="racism" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (S (VP (VBZ Concedes) (NP (NN Error)) (PP (IN by) (NP (NNP Officer) (NNP Attorney) (NNP Hannon))))) (VP (VBD conceded) (SBAR (IN that) (S (NP (NNP Dickey)) (VP (VBD was) (ADJP (JJ wrong) (S (VP (TO to) (VP (NN spice) (NP (PRP$ his) (NNS orders)) (PP (TO to) (NP (NNP Jackson))) (PP (IN with) (NP (NNS obscenities)))))))))))) (, ,) (CC but) (S (NP (PRP he)) (VP (VBD said) (SBAR (S (NP (DT the) (NN cursing)) (VP (VBD was) (NP (NP (NP (NN evidence)) (PP (IN of) (NP (NN discourtesy)))) (, ,) (CONJP (RB rather) (IN than)) (NP (NN racism)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the cursing was evidence of discourtesy , rather than racism" type="SBAR">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="cursing" />
            <token id="26" string="was" />
            <token id="27" string="evidence" />
            <token id="28" string="of" />
            <token id="29" string="discourtesy" />
            <token id="30" string="," />
            <token id="31" string="rather" />
            <token id="32" string="than" />
            <token id="33" string="racism" />
          </tokens>
        </chunking>
        <chunking id="2" string="evidence of discourtesy" type="NP">
          <tokens>
            <token id="27" string="evidence" />
            <token id="28" string="of" />
            <token id="29" string="discourtesy" />
          </tokens>
        </chunking>
        <chunking id="3" string="racism" type="NP">
          <tokens>
            <token id="33" string="racism" />
          </tokens>
        </chunking>
        <chunking id="4" string="said the cursing was evidence of discourtesy , rather than racism" type="VP">
          <tokens>
            <token id="23" string="said" />
            <token id="24" string="the" />
            <token id="25" string="cursing" />
            <token id="26" string="was" />
            <token id="27" string="evidence" />
            <token id="28" string="of" />
            <token id="29" string="discourtesy" />
            <token id="30" string="," />
            <token id="31" string="rather" />
            <token id="32" string="than" />
            <token id="33" string="racism" />
          </tokens>
        </chunking>
        <chunking id="5" string="was evidence of discourtesy , rather than racism" type="VP">
          <tokens>
            <token id="26" string="was" />
            <token id="27" string="evidence" />
            <token id="28" string="of" />
            <token id="29" string="discourtesy" />
            <token id="30" string="," />
            <token id="31" string="rather" />
            <token id="32" string="than" />
            <token id="33" string="racism" />
          </tokens>
        </chunking>
        <chunking id="6" string="evidence" type="NP">
          <tokens>
            <token id="27" string="evidence" />
          </tokens>
        </chunking>
        <chunking id="7" string="Error" type="NP">
          <tokens>
            <token id="2" string="Error" />
          </tokens>
        </chunking>
        <chunking id="8" string="his orders" type="NP">
          <tokens>
            <token id="14" string="his" />
            <token id="15" string="orders" />
          </tokens>
        </chunking>
        <chunking id="9" string="Jackson" type="NP">
          <tokens>
            <token id="17" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="10" string="that Dickey was wrong to spice his orders to Jackson with obscenities" type="SBAR">
          <tokens>
            <token id="8" string="that" />
            <token id="9" string="Dickey" />
            <token id="10" string="was" />
            <token id="11" string="wrong" />
            <token id="12" string="to" />
            <token id="13" string="spice" />
            <token id="14" string="his" />
            <token id="15" string="orders" />
            <token id="16" string="to" />
            <token id="17" string="Jackson" />
            <token id="18" string="with" />
            <token id="19" string="obscenities" />
          </tokens>
        </chunking>
        <chunking id="11" string="to spice his orders to Jackson with obscenities" type="VP">
          <tokens>
            <token id="12" string="to" />
            <token id="13" string="spice" />
            <token id="14" string="his" />
            <token id="15" string="orders" />
            <token id="16" string="to" />
            <token id="17" string="Jackson" />
            <token id="18" string="with" />
            <token id="19" string="obscenities" />
          </tokens>
        </chunking>
        <chunking id="12" string="discourtesy" type="NP">
          <tokens>
            <token id="29" string="discourtesy" />
          </tokens>
        </chunking>
        <chunking id="13" string="Officer Attorney Hannon" type="NP">
          <tokens>
            <token id="4" string="Officer" />
            <token id="5" string="Attorney" />
            <token id="6" string="Hannon" />
          </tokens>
        </chunking>
        <chunking id="14" string="wrong to spice his orders to Jackson with obscenities" type="ADJP">
          <tokens>
            <token id="11" string="wrong" />
            <token id="12" string="to" />
            <token id="13" string="spice" />
            <token id="14" string="his" />
            <token id="15" string="orders" />
            <token id="16" string="to" />
            <token id="17" string="Jackson" />
            <token id="18" string="with" />
            <token id="19" string="obscenities" />
          </tokens>
        </chunking>
        <chunking id="15" string="spice his orders to Jackson with obscenities" type="VP">
          <tokens>
            <token id="13" string="spice" />
            <token id="14" string="his" />
            <token id="15" string="orders" />
            <token id="16" string="to" />
            <token id="17" string="Jackson" />
            <token id="18" string="with" />
            <token id="19" string="obscenities" />
          </tokens>
        </chunking>
        <chunking id="16" string="the cursing" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="cursing" />
          </tokens>
        </chunking>
        <chunking id="17" string="Concedes Error by Officer Attorney Hannon" type="VP">
          <tokens>
            <token id="1" string="Concedes" />
            <token id="2" string="Error" />
            <token id="3" string="by" />
            <token id="4" string="Officer" />
            <token id="5" string="Attorney" />
            <token id="6" string="Hannon" />
          </tokens>
        </chunking>
        <chunking id="18" string="conceded that Dickey was wrong to spice his orders to Jackson with obscenities" type="VP">
          <tokens>
            <token id="7" string="conceded" />
            <token id="8" string="that" />
            <token id="9" string="Dickey" />
            <token id="10" string="was" />
            <token id="11" string="wrong" />
            <token id="12" string="to" />
            <token id="13" string="spice" />
            <token id="14" string="his" />
            <token id="15" string="orders" />
            <token id="16" string="to" />
            <token id="17" string="Jackson" />
            <token id="18" string="with" />
            <token id="19" string="obscenities" />
          </tokens>
        </chunking>
        <chunking id="19" string="was wrong to spice his orders to Jackson with obscenities" type="VP">
          <tokens>
            <token id="10" string="was" />
            <token id="11" string="wrong" />
            <token id="12" string="to" />
            <token id="13" string="spice" />
            <token id="14" string="his" />
            <token id="15" string="orders" />
            <token id="16" string="to" />
            <token id="17" string="Jackson" />
            <token id="18" string="with" />
            <token id="19" string="obscenities" />
          </tokens>
        </chunking>
        <chunking id="20" string="evidence of discourtesy , rather than racism" type="NP">
          <tokens>
            <token id="27" string="evidence" />
            <token id="28" string="of" />
            <token id="29" string="discourtesy" />
            <token id="30" string="," />
            <token id="31" string="rather" />
            <token id="32" string="than" />
            <token id="33" string="racism" />
          </tokens>
        </chunking>
        <chunking id="21" string="he" type="NP">
          <tokens>
            <token id="22" string="he" />
          </tokens>
        </chunking>
        <chunking id="22" string="obscenities" type="NP">
          <tokens>
            <token id="19" string="obscenities" />
          </tokens>
        </chunking>
        <chunking id="23" string="Dickey" type="NP">
          <tokens>
            <token id="9" string="Dickey" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="csubj">
          <governor id="7">conceded</governor>
          <dependent id="1">Concedes</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="1">Concedes</governor>
          <dependent id="2">Error</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">Hannon</governor>
          <dependent id="3">by</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Hannon</governor>
          <dependent id="4">Officer</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Hannon</governor>
          <dependent id="5">Attorney</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Concedes</governor>
          <dependent id="6">Hannon</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">conceded</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">wrong</governor>
          <dependent id="8">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">wrong</governor>
          <dependent id="9">Dickey</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="11">wrong</governor>
          <dependent id="10">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">conceded</governor>
          <dependent id="11">wrong</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">spice</governor>
          <dependent id="12">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="11">wrong</governor>
          <dependent id="13">spice</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="15">orders</governor>
          <dependent id="14">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">spice</governor>
          <dependent id="15">orders</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">Jackson</governor>
          <dependent id="16">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">spice</governor>
          <dependent id="17">Jackson</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">obscenities</governor>
          <dependent id="18">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">spice</governor>
          <dependent id="19">obscenities</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">conceded</governor>
          <dependent id="21">but</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">said</governor>
          <dependent id="22">he</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">conceded</governor>
          <dependent id="23">said</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">cursing</governor>
          <dependent id="24">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">evidence</governor>
          <dependent id="25">cursing</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="27">evidence</governor>
          <dependent id="26">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="23">said</governor>
          <dependent id="27">evidence</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">discourtesy</governor>
          <dependent id="28">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">evidence</governor>
          <dependent id="29">discourtesy</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="27">evidence</governor>
          <dependent id="31">rather</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="31">rather</governor>
          <dependent id="32">than</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="27">evidence</governor>
          <dependent id="33">racism</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Hannon" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Hannon" />
          </tokens>
        </entity>
        <entity id="2" string="Jackson" type="PERSON" score="0.0">
          <tokens>
            <token id="17" string="Jackson" />
          </tokens>
        </entity>
        <entity id="3" string="Attorney" type="TITLE" score="0.0">
          <tokens>
            <token id="5" string="Attorney" />
          </tokens>
        </entity>
        <entity id="4" string="Dickey" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="Dickey" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="38" has_coreference="true">
      <content>He said the two officers saw the car weave within the traffic lane and wanted to check the driver for drunkenness.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="true" />
        <token id="5" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="saw" lemma="see" stem="saw" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="car" lemma="car" stem="car" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="weave" lemma="weave" stem="weav" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="within" lemma="within" stem="within" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="traffic" lemma="traffic" stem="traffic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="lane" lemma="lane" stem="lane" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="wanted" lemma="want" stem="want" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="check" lemma="check" stem="check" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="driver" lemma="driver" stem="driver" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="drunkenness" lemma="drunkenness" stem="drunken" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VBD said) (SBAR (S (NP (DT the) (CD two) (NNS officers)) (VP (VP (VBD saw) (S (NP (DT the) (NN car)) (VP (VB weave) (PP (IN within) (NP (DT the) (NN traffic) (NN lane)))))) (CC and) (VP (VBD wanted) (S (VP (TO to) (VP (VB check) (NP (NP (DT the) (NN driver)) (PP (IN for) (NP (NN drunkenness)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="said the two officers saw the car weave within the traffic lane and wanted to check the driver for drunkenness" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="the" />
            <token id="4" string="two" />
            <token id="5" string="officers" />
            <token id="6" string="saw" />
            <token id="7" string="the" />
            <token id="8" string="car" />
            <token id="9" string="weave" />
            <token id="10" string="within" />
            <token id="11" string="the" />
            <token id="12" string="traffic" />
            <token id="13" string="lane" />
            <token id="14" string="and" />
            <token id="15" string="wanted" />
            <token id="16" string="to" />
            <token id="17" string="check" />
            <token id="18" string="the" />
            <token id="19" string="driver" />
            <token id="20" string="for" />
            <token id="21" string="drunkenness" />
          </tokens>
        </chunking>
        <chunking id="2" string="the traffic lane" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="traffic" />
            <token id="13" string="lane" />
          </tokens>
        </chunking>
        <chunking id="3" string="the driver for drunkenness" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="driver" />
            <token id="20" string="for" />
            <token id="21" string="drunkenness" />
          </tokens>
        </chunking>
        <chunking id="4" string="drunkenness" type="NP">
          <tokens>
            <token id="21" string="drunkenness" />
          </tokens>
        </chunking>
        <chunking id="5" string="the two officers saw the car weave within the traffic lane and wanted to check the driver for drunkenness" type="SBAR">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="two" />
            <token id="5" string="officers" />
            <token id="6" string="saw" />
            <token id="7" string="the" />
            <token id="8" string="car" />
            <token id="9" string="weave" />
            <token id="10" string="within" />
            <token id="11" string="the" />
            <token id="12" string="traffic" />
            <token id="13" string="lane" />
            <token id="14" string="and" />
            <token id="15" string="wanted" />
            <token id="16" string="to" />
            <token id="17" string="check" />
            <token id="18" string="the" />
            <token id="19" string="driver" />
            <token id="20" string="for" />
            <token id="21" string="drunkenness" />
          </tokens>
        </chunking>
        <chunking id="6" string="the two officers" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="two" />
            <token id="5" string="officers" />
          </tokens>
        </chunking>
        <chunking id="7" string="weave within the traffic lane" type="VP">
          <tokens>
            <token id="9" string="weave" />
            <token id="10" string="within" />
            <token id="11" string="the" />
            <token id="12" string="traffic" />
            <token id="13" string="lane" />
          </tokens>
        </chunking>
        <chunking id="8" string="the car" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="car" />
          </tokens>
        </chunking>
        <chunking id="9" string="check the driver for drunkenness" type="VP">
          <tokens>
            <token id="17" string="check" />
            <token id="18" string="the" />
            <token id="19" string="driver" />
            <token id="20" string="for" />
            <token id="21" string="drunkenness" />
          </tokens>
        </chunking>
        <chunking id="10" string="saw the car weave within the traffic lane" type="VP">
          <tokens>
            <token id="6" string="saw" />
            <token id="7" string="the" />
            <token id="8" string="car" />
            <token id="9" string="weave" />
            <token id="10" string="within" />
            <token id="11" string="the" />
            <token id="12" string="traffic" />
            <token id="13" string="lane" />
          </tokens>
        </chunking>
        <chunking id="11" string="the driver" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="driver" />
          </tokens>
        </chunking>
        <chunking id="12" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="13" string="saw the car weave within the traffic lane and wanted to check the driver for drunkenness" type="VP">
          <tokens>
            <token id="6" string="saw" />
            <token id="7" string="the" />
            <token id="8" string="car" />
            <token id="9" string="weave" />
            <token id="10" string="within" />
            <token id="11" string="the" />
            <token id="12" string="traffic" />
            <token id="13" string="lane" />
            <token id="14" string="and" />
            <token id="15" string="wanted" />
            <token id="16" string="to" />
            <token id="17" string="check" />
            <token id="18" string="the" />
            <token id="19" string="driver" />
            <token id="20" string="for" />
            <token id="21" string="drunkenness" />
          </tokens>
        </chunking>
        <chunking id="14" string="wanted to check the driver for drunkenness" type="VP">
          <tokens>
            <token id="15" string="wanted" />
            <token id="16" string="to" />
            <token id="17" string="check" />
            <token id="18" string="the" />
            <token id="19" string="driver" />
            <token id="20" string="for" />
            <token id="21" string="drunkenness" />
          </tokens>
        </chunking>
        <chunking id="15" string="to check the driver for drunkenness" type="VP">
          <tokens>
            <token id="16" string="to" />
            <token id="17" string="check" />
            <token id="18" string="the" />
            <token id="19" string="driver" />
            <token id="20" string="for" />
            <token id="21" string="drunkenness" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">officers</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="5">officers</governor>
          <dependent id="4">two</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">saw</governor>
          <dependent id="5">officers</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="6">saw</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">car</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">weave</governor>
          <dependent id="8">car</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">saw</governor>
          <dependent id="9">weave</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">lane</governor>
          <dependent id="10">within</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">lane</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">lane</governor>
          <dependent id="12">traffic</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">weave</governor>
          <dependent id="13">lane</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">saw</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">saw</governor>
          <dependent id="15">wanted</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">check</governor>
          <dependent id="16">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="15">wanted</governor>
          <dependent id="17">check</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">driver</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">check</governor>
          <dependent id="19">driver</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">drunkenness</governor>
          <dependent id="20">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">driver</governor>
          <dependent id="21">drunkenness</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="4" string="two" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="39" has_coreference="true">
      <content>Although the two men in the car were black, driving an old car and dressed in shabby clothes, they were not stopped for those reasons, the lawyer said, adding that they were in a section of the city where their appearance was not unusual.</content>
      <tokens>
        <token id="1" string="Although" lemma="although" stem="although" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="4" string="men" lemma="man" stem="men" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="car" lemma="car" stem="car" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="black" lemma="black" stem="black" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="driving" lemma="drive" stem="drive" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="old" lemma="old" stem="old" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="car" lemma="car" stem="car" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="dressed" lemma="dress" stem="dress" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="shabby" lemma="shabby" stem="shabbi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="clothes" lemma="clothes" stem="cloth" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="stopped" lemma="stop" stem="stop" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="those" lemma="those" stem="those" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="reasons" lemma="reason" stem="reason" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="30" string="lawyer" lemma="lawyer" stem="lawyer" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="31" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="adding" lemma="add" stem="ad" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="section" lemma="section" stem="section" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="42" string="city" lemma="city" stem="citi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="43" string="where" lemma="where" stem="where" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="45" string="appearance" lemma="appearance" stem="appear" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="46" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="47" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="48" string="unusual" lemma="unusual" stem="unusu" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="49" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN Although) (S (S (NP (NP (DT the) (CD two) (NNS men)) (PP (IN in) (NP (DT the) (NN car)))) (VP (VBD were) (ADJP (JJ black)) (, ,) (S (VP (VBG driving) (NP (DT an) (JJ old) (NN car)))))) (CC and) (S (S (VP (VBN dressed) (PP (IN in) (NP (JJ shabby) (NNS clothes))))) (, ,) (NP (PRP they)) (VP (VBD were) (RB not) (VP (VBN stopped) (PP (IN for) (NP (DT those) (NNS reasons)))))))) (, ,) (NP (DT the) (NN lawyer)) (VP (VBD said) (, ,) (S (VP (VBG adding) (SBAR (IN that) (S (NP (PRP they)) (VP (VBD were) (PP (IN in) (NP (NP (DT a) (NN section)) (PP (IN of) (NP (DT the) (NN city))))) (SBAR (WHADVP (WRB where)) (S (NP (PRP$ their) (NN appearance)) (VP (VBD was) (RB not) (ADJP (JJ unusual))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the city" type="NP">
          <tokens>
            <token id="41" string="the" />
            <token id="42" string="city" />
          </tokens>
        </chunking>
        <chunking id="2" string="a section" type="NP">
          <tokens>
            <token id="38" string="a" />
            <token id="39" string="section" />
          </tokens>
        </chunking>
        <chunking id="3" string="stopped for those reasons" type="VP">
          <tokens>
            <token id="24" string="stopped" />
            <token id="25" string="for" />
            <token id="26" string="those" />
            <token id="27" string="reasons" />
          </tokens>
        </chunking>
        <chunking id="4" string="black" type="ADJP">
          <tokens>
            <token id="9" string="black" />
          </tokens>
        </chunking>
        <chunking id="5" string="their appearance" type="NP">
          <tokens>
            <token id="44" string="their" />
            <token id="45" string="appearance" />
          </tokens>
        </chunking>
        <chunking id="6" string="were black , driving an old car" type="VP">
          <tokens>
            <token id="8" string="were" />
            <token id="9" string="black" />
            <token id="10" string="," />
            <token id="11" string="driving" />
            <token id="12" string="an" />
            <token id="13" string="old" />
            <token id="14" string="car" />
          </tokens>
        </chunking>
        <chunking id="7" string="an old car" type="NP">
          <tokens>
            <token id="12" string="an" />
            <token id="13" string="old" />
            <token id="14" string="car" />
          </tokens>
        </chunking>
        <chunking id="8" string="was not unusual" type="VP">
          <tokens>
            <token id="46" string="was" />
            <token id="47" string="not" />
            <token id="48" string="unusual" />
          </tokens>
        </chunking>
        <chunking id="9" string="a section of the city" type="NP">
          <tokens>
            <token id="38" string="a" />
            <token id="39" string="section" />
            <token id="40" string="of" />
            <token id="41" string="the" />
            <token id="42" string="city" />
          </tokens>
        </chunking>
        <chunking id="10" string="adding that they were in a section of the city where their appearance was not unusual" type="VP">
          <tokens>
            <token id="33" string="adding" />
            <token id="34" string="that" />
            <token id="35" string="they" />
            <token id="36" string="were" />
            <token id="37" string="in" />
            <token id="38" string="a" />
            <token id="39" string="section" />
            <token id="40" string="of" />
            <token id="41" string="the" />
            <token id="42" string="city" />
            <token id="43" string="where" />
            <token id="44" string="their" />
            <token id="45" string="appearance" />
            <token id="46" string="was" />
            <token id="47" string="not" />
            <token id="48" string="unusual" />
          </tokens>
        </chunking>
        <chunking id="11" string="the two men" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="two" />
            <token id="4" string="men" />
          </tokens>
        </chunking>
        <chunking id="12" string="that they were in a section of the city where their appearance was not unusual" type="SBAR">
          <tokens>
            <token id="34" string="that" />
            <token id="35" string="they" />
            <token id="36" string="were" />
            <token id="37" string="in" />
            <token id="38" string="a" />
            <token id="39" string="section" />
            <token id="40" string="of" />
            <token id="41" string="the" />
            <token id="42" string="city" />
            <token id="43" string="where" />
            <token id="44" string="their" />
            <token id="45" string="appearance" />
            <token id="46" string="was" />
            <token id="47" string="not" />
            <token id="48" string="unusual" />
          </tokens>
        </chunking>
        <chunking id="13" string="were not stopped for those reasons" type="VP">
          <tokens>
            <token id="22" string="were" />
            <token id="23" string="not" />
            <token id="24" string="stopped" />
            <token id="25" string="for" />
            <token id="26" string="those" />
            <token id="27" string="reasons" />
          </tokens>
        </chunking>
        <chunking id="14" string="dressed in shabby clothes" type="VP">
          <tokens>
            <token id="16" string="dressed" />
            <token id="17" string="in" />
            <token id="18" string="shabby" />
            <token id="19" string="clothes" />
          </tokens>
        </chunking>
        <chunking id="15" string="said , adding that they were in a section of the city where their appearance was not unusual" type="VP">
          <tokens>
            <token id="31" string="said" />
            <token id="32" string="," />
            <token id="33" string="adding" />
            <token id="34" string="that" />
            <token id="35" string="they" />
            <token id="36" string="were" />
            <token id="37" string="in" />
            <token id="38" string="a" />
            <token id="39" string="section" />
            <token id="40" string="of" />
            <token id="41" string="the" />
            <token id="42" string="city" />
            <token id="43" string="where" />
            <token id="44" string="their" />
            <token id="45" string="appearance" />
            <token id="46" string="was" />
            <token id="47" string="not" />
            <token id="48" string="unusual" />
          </tokens>
        </chunking>
        <chunking id="16" string="the car" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="car" />
          </tokens>
        </chunking>
        <chunking id="17" string="shabby clothes" type="NP">
          <tokens>
            <token id="18" string="shabby" />
            <token id="19" string="clothes" />
          </tokens>
        </chunking>
        <chunking id="18" string="they" type="NP">
          <tokens>
            <token id="21" string="they" />
          </tokens>
        </chunking>
        <chunking id="19" string="were in a section of the city where their appearance was not unusual" type="VP">
          <tokens>
            <token id="36" string="were" />
            <token id="37" string="in" />
            <token id="38" string="a" />
            <token id="39" string="section" />
            <token id="40" string="of" />
            <token id="41" string="the" />
            <token id="42" string="city" />
            <token id="43" string="where" />
            <token id="44" string="their" />
            <token id="45" string="appearance" />
            <token id="46" string="was" />
            <token id="47" string="not" />
            <token id="48" string="unusual" />
          </tokens>
        </chunking>
        <chunking id="20" string="Although the two men in the car were black , driving an old car and dressed in shabby clothes , they were not stopped for those reasons" type="SBAR">
          <tokens>
            <token id="1" string="Although" />
            <token id="2" string="the" />
            <token id="3" string="two" />
            <token id="4" string="men" />
            <token id="5" string="in" />
            <token id="6" string="the" />
            <token id="7" string="car" />
            <token id="8" string="were" />
            <token id="9" string="black" />
            <token id="10" string="," />
            <token id="11" string="driving" />
            <token id="12" string="an" />
            <token id="13" string="old" />
            <token id="14" string="car" />
            <token id="15" string="and" />
            <token id="16" string="dressed" />
            <token id="17" string="in" />
            <token id="18" string="shabby" />
            <token id="19" string="clothes" />
            <token id="20" string="," />
            <token id="21" string="they" />
            <token id="22" string="were" />
            <token id="23" string="not" />
            <token id="24" string="stopped" />
            <token id="25" string="for" />
            <token id="26" string="those" />
            <token id="27" string="reasons" />
          </tokens>
        </chunking>
        <chunking id="21" string="the two men in the car" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="two" />
            <token id="4" string="men" />
            <token id="5" string="in" />
            <token id="6" string="the" />
            <token id="7" string="car" />
          </tokens>
        </chunking>
        <chunking id="22" string="those reasons" type="NP">
          <tokens>
            <token id="26" string="those" />
            <token id="27" string="reasons" />
          </tokens>
        </chunking>
        <chunking id="23" string="where their appearance was not unusual" type="SBAR">
          <tokens>
            <token id="43" string="where" />
            <token id="44" string="their" />
            <token id="45" string="appearance" />
            <token id="46" string="was" />
            <token id="47" string="not" />
            <token id="48" string="unusual" />
          </tokens>
        </chunking>
        <chunking id="24" string="where" type="WHADVP">
          <tokens>
            <token id="43" string="where" />
          </tokens>
        </chunking>
        <chunking id="25" string="unusual" type="ADJP">
          <tokens>
            <token id="48" string="unusual" />
          </tokens>
        </chunking>
        <chunking id="26" string="driving an old car" type="VP">
          <tokens>
            <token id="11" string="driving" />
            <token id="12" string="an" />
            <token id="13" string="old" />
            <token id="14" string="car" />
          </tokens>
        </chunking>
        <chunking id="27" string="the lawyer" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="lawyer" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="9">black</governor>
          <dependent id="1">Although</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">men</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="4">men</governor>
          <dependent id="3">two</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">black</governor>
          <dependent id="4">men</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">car</governor>
          <dependent id="5">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">car</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">men</governor>
          <dependent id="7">car</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="9">black</governor>
          <dependent id="8">were</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="31">said</governor>
          <dependent id="9">black</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="9">black</governor>
          <dependent id="11">driving</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">car</governor>
          <dependent id="12">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">car</governor>
          <dependent id="13">old</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">driving</governor>
          <dependent id="14">car</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">black</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="24">stopped</governor>
          <dependent id="16">dressed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">clothes</governor>
          <dependent id="17">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">clothes</governor>
          <dependent id="18">shabby</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">dressed</governor>
          <dependent id="19">clothes</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="24">stopped</governor>
          <dependent id="21">they</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="24">stopped</governor>
          <dependent id="22">were</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="24">stopped</governor>
          <dependent id="23">not</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">black</governor>
          <dependent id="24">stopped</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">reasons</governor>
          <dependent id="25">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">reasons</governor>
          <dependent id="26">those</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">stopped</governor>
          <dependent id="27">reasons</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">lawyer</governor>
          <dependent id="29">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="31">said</governor>
          <dependent id="30">lawyer</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="31">said</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="31">said</governor>
          <dependent id="33">adding</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="39">section</governor>
          <dependent id="34">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="39">section</governor>
          <dependent id="35">they</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="39">section</governor>
          <dependent id="36">were</dependent>
        </dependency>
        <dependency type="case">
          <governor id="39">section</governor>
          <dependent id="37">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="39">section</governor>
          <dependent id="38">a</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="33">adding</governor>
          <dependent id="39">section</dependent>
        </dependency>
        <dependency type="case">
          <governor id="42">city</governor>
          <dependent id="40">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="42">city</governor>
          <dependent id="41">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="39">section</governor>
          <dependent id="42">city</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="48">unusual</governor>
          <dependent id="43">where</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="45">appearance</governor>
          <dependent id="44">their</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="48">unusual</governor>
          <dependent id="45">appearance</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="48">unusual</governor>
          <dependent id="46">was</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="48">unusual</governor>
          <dependent id="47">not</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="39">section</governor>
          <dependent id="48">unusual</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="3" string="two" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="40" has_coreference="true">
      <content>&amp;quot;Obviously, they are not telling the truth when they say they did nothing to bring attention to themselves,&amp;quot; Hannon said of Jackson and Hill.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Obviously" lemma="obviously" stem="obviousli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="telling" lemma="tell" stem="tell" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="truth" lemma="truth" stem="truth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="say" lemma="say" stem="sai" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="nothing" lemma="nothing" stem="noth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="bring" lemma="bring" stem="bring" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="attention" lemma="attention" stem="attent" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="themselves" lemma="themselves" stem="themselv" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="Hannon" lemma="Hannon" stem="hannon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="24" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="27" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="28" string="Hill" lemma="Hill" stem="hill" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (ADVP (RB Obviously)) (, ,) (NP (PRP they)) (VP (VBP are) (RB not) (VP (VBG telling) (NP (NP (DT the) (NN truth)) (SBAR (WHADVP (WRB when)) (S (NP (PRP they)) (VP (VBP say) (SBAR (S (NP (PRP they)) (VP (VBD did) (NP (NN nothing)) (S (VP (TO to) (VP (VB bring) (NP (NN attention)) (PP (TO to) (NP (PRP themselves)))))))))))))))) (, ,) ('' '') (NP (NNP Hannon)) (VP (VBD said) (PP (IN of) (NP (NNP Jackson) (CC and) (NNP Hill)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="when they say they did nothing to bring attention to themselves" type="SBAR">
          <tokens>
            <token id="10" string="when" />
            <token id="11" string="they" />
            <token id="12" string="say" />
            <token id="13" string="they" />
            <token id="14" string="did" />
            <token id="15" string="nothing" />
            <token id="16" string="to" />
            <token id="17" string="bring" />
            <token id="18" string="attention" />
            <token id="19" string="to" />
            <token id="20" string="themselves" />
          </tokens>
        </chunking>
        <chunking id="2" string="Jackson and Hill" type="NP">
          <tokens>
            <token id="26" string="Jackson" />
            <token id="27" string="and" />
            <token id="28" string="Hill" />
          </tokens>
        </chunking>
        <chunking id="3" string="are not telling the truth when they say they did nothing to bring attention to themselves" type="VP">
          <tokens>
            <token id="5" string="are" />
            <token id="6" string="not" />
            <token id="7" string="telling" />
            <token id="8" string="the" />
            <token id="9" string="truth" />
            <token id="10" string="when" />
            <token id="11" string="they" />
            <token id="12" string="say" />
            <token id="13" string="they" />
            <token id="14" string="did" />
            <token id="15" string="nothing" />
            <token id="16" string="to" />
            <token id="17" string="bring" />
            <token id="18" string="attention" />
            <token id="19" string="to" />
            <token id="20" string="themselves" />
          </tokens>
        </chunking>
        <chunking id="4" string="nothing" type="NP">
          <tokens>
            <token id="15" string="nothing" />
          </tokens>
        </chunking>
        <chunking id="5" string="the truth when they say they did nothing to bring attention to themselves" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="truth" />
            <token id="10" string="when" />
            <token id="11" string="they" />
            <token id="12" string="say" />
            <token id="13" string="they" />
            <token id="14" string="did" />
            <token id="15" string="nothing" />
            <token id="16" string="to" />
            <token id="17" string="bring" />
            <token id="18" string="attention" />
            <token id="19" string="to" />
            <token id="20" string="themselves" />
          </tokens>
        </chunking>
        <chunking id="6" string="said of Jackson and Hill" type="VP">
          <tokens>
            <token id="24" string="said" />
            <token id="25" string="of" />
            <token id="26" string="Jackson" />
            <token id="27" string="and" />
            <token id="28" string="Hill" />
          </tokens>
        </chunking>
        <chunking id="7" string="when" type="WHADVP">
          <tokens>
            <token id="10" string="when" />
          </tokens>
        </chunking>
        <chunking id="8" string="they did nothing to bring attention to themselves" type="SBAR">
          <tokens>
            <token id="13" string="they" />
            <token id="14" string="did" />
            <token id="15" string="nothing" />
            <token id="16" string="to" />
            <token id="17" string="bring" />
            <token id="18" string="attention" />
            <token id="19" string="to" />
            <token id="20" string="themselves" />
          </tokens>
        </chunking>
        <chunking id="9" string="to bring attention to themselves" type="VP">
          <tokens>
            <token id="16" string="to" />
            <token id="17" string="bring" />
            <token id="18" string="attention" />
            <token id="19" string="to" />
            <token id="20" string="themselves" />
          </tokens>
        </chunking>
        <chunking id="10" string="Hannon" type="NP">
          <tokens>
            <token id="23" string="Hannon" />
          </tokens>
        </chunking>
        <chunking id="11" string="they" type="NP">
          <tokens>
            <token id="4" string="they" />
          </tokens>
        </chunking>
        <chunking id="12" string="did nothing to bring attention to themselves" type="VP">
          <tokens>
            <token id="14" string="did" />
            <token id="15" string="nothing" />
            <token id="16" string="to" />
            <token id="17" string="bring" />
            <token id="18" string="attention" />
            <token id="19" string="to" />
            <token id="20" string="themselves" />
          </tokens>
        </chunking>
        <chunking id="13" string="themselves" type="NP">
          <tokens>
            <token id="20" string="themselves" />
          </tokens>
        </chunking>
        <chunking id="14" string="say they did nothing to bring attention to themselves" type="VP">
          <tokens>
            <token id="12" string="say" />
            <token id="13" string="they" />
            <token id="14" string="did" />
            <token id="15" string="nothing" />
            <token id="16" string="to" />
            <token id="17" string="bring" />
            <token id="18" string="attention" />
            <token id="19" string="to" />
            <token id="20" string="themselves" />
          </tokens>
        </chunking>
        <chunking id="15" string="bring attention to themselves" type="VP">
          <tokens>
            <token id="17" string="bring" />
            <token id="18" string="attention" />
            <token id="19" string="to" />
            <token id="20" string="themselves" />
          </tokens>
        </chunking>
        <chunking id="16" string="attention" type="NP">
          <tokens>
            <token id="18" string="attention" />
          </tokens>
        </chunking>
        <chunking id="17" string="telling the truth when they say they did nothing to bring attention to themselves" type="VP">
          <tokens>
            <token id="7" string="telling" />
            <token id="8" string="the" />
            <token id="9" string="truth" />
            <token id="10" string="when" />
            <token id="11" string="they" />
            <token id="12" string="say" />
            <token id="13" string="they" />
            <token id="14" string="did" />
            <token id="15" string="nothing" />
            <token id="16" string="to" />
            <token id="17" string="bring" />
            <token id="18" string="attention" />
            <token id="19" string="to" />
            <token id="20" string="themselves" />
          </tokens>
        </chunking>
        <chunking id="18" string="the truth" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="truth" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="7">telling</governor>
          <dependent id="2">Obviously</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">telling</governor>
          <dependent id="4">they</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">telling</governor>
          <dependent id="5">are</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="7">telling</governor>
          <dependent id="6">not</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="24">said</governor>
          <dependent id="7">telling</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">truth</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">telling</governor>
          <dependent id="9">truth</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">say</governor>
          <dependent id="10">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">say</governor>
          <dependent id="11">they</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="9">truth</governor>
          <dependent id="12">say</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">did</governor>
          <dependent id="13">they</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="12">say</governor>
          <dependent id="14">did</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">did</governor>
          <dependent id="15">nothing</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">bring</governor>
          <dependent id="16">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="14">did</governor>
          <dependent id="17">bring</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">bring</governor>
          <dependent id="18">attention</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">themselves</governor>
          <dependent id="19">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">bring</governor>
          <dependent id="20">themselves</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">said</governor>
          <dependent id="23">Hannon</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="24">said</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">Jackson</governor>
          <dependent id="25">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">said</governor>
          <dependent id="26">Jackson</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="26">Jackson</governor>
          <dependent id="27">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="26">Jackson</governor>
          <dependent id="28">Hill</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Hannon" type="PERSON" score="0.0">
          <tokens>
            <token id="23" string="Hannon" />
          </tokens>
        </entity>
        <entity id="2" string="Hill" type="PERSON" score="0.0">
          <tokens>
            <token id="28" string="Hill" />
          </tokens>
        </entity>
        <entity id="3" string="Jackson" type="PERSON" score="0.0">
          <tokens>
            <token id="26" string="Jackson" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="41" has_coreference="true">
      <content>He said the two police officers become concerned for their safety when Jackson suspiciously exited the car as soon as it stopped, then immediately started arguing when Dickey ordered him to submit to a search for weapons.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="5" string="police" lemma="police" stem="polic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="become" lemma="become" stem="becom" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="concerned" lemma="concern" stem="concern" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="safety" lemma="safety" stem="safeti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="14" string="suspiciously" lemma="suspiciously" stem="suspici" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="exited" lemma="exit" stem="exit" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="car" lemma="car" stem="car" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="as" lemma="as" stem="a" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="soon" lemma="soon" stem="soon" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="stopped" lemma="stop" stem="stop" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="immediately" lemma="immediately" stem="immedi" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="started" lemma="start" stem="start" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="arguing" lemma="argue" stem="argu" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="Dickey" lemma="Dickey" stem="dickei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="30" string="ordered" lemma="order" stem="order" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="32" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="submit" lemma="submit" stem="submit" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="search" lemma="search" stem="search" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="weapons" lemma="weapon" stem="weapon" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VBD said) (SBAR (S (NP (DT the) (CD two) (NNS police) (NNS officers)) (VP (VBP become) (ADJP (VBN concerned) (PP (IN for) (NP (NP (PRP$ their) (NN safety)) (SBAR (WHADVP (WRB when)) (S (NP (NNP Jackson)) (ADVP (RB suspiciously)) (VP (VBD exited) (NP (DT the) (NN car)) (ADVP (ADVP (RB as) (RB soon)) (SBAR (IN as) (S (NP (PRP it)) (VP (VBD stopped) (SBAR (S (, ,) (ADVP (RB then)) (ADVP (RB immediately)) (VP (VBD started) (S (VP (VBG arguing) (SBAR (WHADVP (WRB when)) (S (NP (NNP Dickey)) (VP (VBD ordered) (S (NP (PRP him)) (VP (TO to) (VP (VB submit) (PP (TO to) (NP (NP (DT a) (NN search)) (PP (IN for) (NP (NNS weapons)))))))))))))))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="to submit to a search for weapons" type="VP">
          <tokens>
            <token id="32" string="to" />
            <token id="33" string="submit" />
            <token id="34" string="to" />
            <token id="35" string="a" />
            <token id="36" string="search" />
            <token id="37" string="for" />
            <token id="38" string="weapons" />
          </tokens>
        </chunking>
        <chunking id="2" string="said the two police officers become concerned for their safety when Jackson suspiciously exited the car as soon as it stopped , then immediately started arguing when Dickey ordered him to submit to a search for weapons" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="the" />
            <token id="4" string="two" />
            <token id="5" string="police" />
            <token id="6" string="officers" />
            <token id="7" string="become" />
            <token id="8" string="concerned" />
            <token id="9" string="for" />
            <token id="10" string="their" />
            <token id="11" string="safety" />
            <token id="12" string="when" />
            <token id="13" string="Jackson" />
            <token id="14" string="suspiciously" />
            <token id="15" string="exited" />
            <token id="16" string="the" />
            <token id="17" string="car" />
            <token id="18" string="as" />
            <token id="19" string="soon" />
            <token id="20" string="as" />
            <token id="21" string="it" />
            <token id="22" string="stopped" />
            <token id="23" string="," />
            <token id="24" string="then" />
            <token id="25" string="immediately" />
            <token id="26" string="started" />
            <token id="27" string="arguing" />
            <token id="28" string="when" />
            <token id="29" string="Dickey" />
            <token id="30" string="ordered" />
            <token id="31" string="him" />
            <token id="32" string="to" />
            <token id="33" string="submit" />
            <token id="34" string="to" />
            <token id="35" string="a" />
            <token id="36" string="search" />
            <token id="37" string="for" />
            <token id="38" string="weapons" />
          </tokens>
        </chunking>
        <chunking id="3" string="as it stopped , then immediately started arguing when Dickey ordered him to submit to a search for weapons" type="SBAR">
          <tokens>
            <token id="20" string="as" />
            <token id="21" string="it" />
            <token id="22" string="stopped" />
            <token id="23" string="," />
            <token id="24" string="then" />
            <token id="25" string="immediately" />
            <token id="26" string="started" />
            <token id="27" string="arguing" />
            <token id="28" string="when" />
            <token id="29" string="Dickey" />
            <token id="30" string="ordered" />
            <token id="31" string="him" />
            <token id="32" string="to" />
            <token id="33" string="submit" />
            <token id="34" string="to" />
            <token id="35" string="a" />
            <token id="36" string="search" />
            <token id="37" string="for" />
            <token id="38" string="weapons" />
          </tokens>
        </chunking>
        <chunking id="4" string="stopped , then immediately started arguing when Dickey ordered him to submit to a search for weapons" type="VP">
          <tokens>
            <token id="22" string="stopped" />
            <token id="23" string="," />
            <token id="24" string="then" />
            <token id="25" string="immediately" />
            <token id="26" string="started" />
            <token id="27" string="arguing" />
            <token id="28" string="when" />
            <token id="29" string="Dickey" />
            <token id="30" string="ordered" />
            <token id="31" string="him" />
            <token id="32" string="to" />
            <token id="33" string="submit" />
            <token id="34" string="to" />
            <token id="35" string="a" />
            <token id="36" string="search" />
            <token id="37" string="for" />
            <token id="38" string="weapons" />
          </tokens>
        </chunking>
        <chunking id="5" string="arguing when Dickey ordered him to submit to a search for weapons" type="VP">
          <tokens>
            <token id="27" string="arguing" />
            <token id="28" string="when" />
            <token id="29" string="Dickey" />
            <token id="30" string="ordered" />
            <token id="31" string="him" />
            <token id="32" string="to" />
            <token id="33" string="submit" />
            <token id="34" string="to" />
            <token id="35" string="a" />
            <token id="36" string="search" />
            <token id="37" string="for" />
            <token id="38" string="weapons" />
          </tokens>
        </chunking>
        <chunking id="6" string="submit to a search for weapons" type="VP">
          <tokens>
            <token id="33" string="submit" />
            <token id="34" string="to" />
            <token id="35" string="a" />
            <token id="36" string="search" />
            <token id="37" string="for" />
            <token id="38" string="weapons" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="21" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="their safety when Jackson suspiciously exited the car as soon as it stopped , then immediately started arguing when Dickey ordered him to submit to a search for weapons" type="NP">
          <tokens>
            <token id="10" string="their" />
            <token id="11" string="safety" />
            <token id="12" string="when" />
            <token id="13" string="Jackson" />
            <token id="14" string="suspiciously" />
            <token id="15" string="exited" />
            <token id="16" string="the" />
            <token id="17" string="car" />
            <token id="18" string="as" />
            <token id="19" string="soon" />
            <token id="20" string="as" />
            <token id="21" string="it" />
            <token id="22" string="stopped" />
            <token id="23" string="," />
            <token id="24" string="then" />
            <token id="25" string="immediately" />
            <token id="26" string="started" />
            <token id="27" string="arguing" />
            <token id="28" string="when" />
            <token id="29" string="Dickey" />
            <token id="30" string="ordered" />
            <token id="31" string="him" />
            <token id="32" string="to" />
            <token id="33" string="submit" />
            <token id="34" string="to" />
            <token id="35" string="a" />
            <token id="36" string="search" />
            <token id="37" string="for" />
            <token id="38" string="weapons" />
          </tokens>
        </chunking>
        <chunking id="9" string="when Jackson suspiciously exited the car as soon as it stopped , then immediately started arguing when Dickey ordered him to submit to a search for weapons" type="SBAR">
          <tokens>
            <token id="12" string="when" />
            <token id="13" string="Jackson" />
            <token id="14" string="suspiciously" />
            <token id="15" string="exited" />
            <token id="16" string="the" />
            <token id="17" string="car" />
            <token id="18" string="as" />
            <token id="19" string="soon" />
            <token id="20" string="as" />
            <token id="21" string="it" />
            <token id="22" string="stopped" />
            <token id="23" string="," />
            <token id="24" string="then" />
            <token id="25" string="immediately" />
            <token id="26" string="started" />
            <token id="27" string="arguing" />
            <token id="28" string="when" />
            <token id="29" string="Dickey" />
            <token id="30" string="ordered" />
            <token id="31" string="him" />
            <token id="32" string="to" />
            <token id="33" string="submit" />
            <token id="34" string="to" />
            <token id="35" string="a" />
            <token id="36" string="search" />
            <token id="37" string="for" />
            <token id="38" string="weapons" />
          </tokens>
        </chunking>
        <chunking id="10" string="when Dickey ordered him to submit to a search for weapons" type="SBAR">
          <tokens>
            <token id="28" string="when" />
            <token id="29" string="Dickey" />
            <token id="30" string="ordered" />
            <token id="31" string="him" />
            <token id="32" string="to" />
            <token id="33" string="submit" />
            <token id="34" string="to" />
            <token id="35" string="a" />
            <token id="36" string="search" />
            <token id="37" string="for" />
            <token id="38" string="weapons" />
          </tokens>
        </chunking>
        <chunking id="11" string=", then immediately started arguing when Dickey ordered him to submit to a search for weapons" type="SBAR">
          <tokens>
            <token id="23" string="," />
            <token id="24" string="then" />
            <token id="25" string="immediately" />
            <token id="26" string="started" />
            <token id="27" string="arguing" />
            <token id="28" string="when" />
            <token id="29" string="Dickey" />
            <token id="30" string="ordered" />
            <token id="31" string="him" />
            <token id="32" string="to" />
            <token id="33" string="submit" />
            <token id="34" string="to" />
            <token id="35" string="a" />
            <token id="36" string="search" />
            <token id="37" string="for" />
            <token id="38" string="weapons" />
          </tokens>
        </chunking>
        <chunking id="12" string="weapons" type="NP">
          <tokens>
            <token id="38" string="weapons" />
          </tokens>
        </chunking>
        <chunking id="13" string="a search for weapons" type="NP">
          <tokens>
            <token id="35" string="a" />
            <token id="36" string="search" />
            <token id="37" string="for" />
            <token id="38" string="weapons" />
          </tokens>
        </chunking>
        <chunking id="14" string="Dickey" type="NP">
          <tokens>
            <token id="29" string="Dickey" />
          </tokens>
        </chunking>
        <chunking id="15" string="become concerned for their safety when Jackson suspiciously exited the car as soon as it stopped , then immediately started arguing when Dickey ordered him to submit to a search for weapons" type="VP">
          <tokens>
            <token id="7" string="become" />
            <token id="8" string="concerned" />
            <token id="9" string="for" />
            <token id="10" string="their" />
            <token id="11" string="safety" />
            <token id="12" string="when" />
            <token id="13" string="Jackson" />
            <token id="14" string="suspiciously" />
            <token id="15" string="exited" />
            <token id="16" string="the" />
            <token id="17" string="car" />
            <token id="18" string="as" />
            <token id="19" string="soon" />
            <token id="20" string="as" />
            <token id="21" string="it" />
            <token id="22" string="stopped" />
            <token id="23" string="," />
            <token id="24" string="then" />
            <token id="25" string="immediately" />
            <token id="26" string="started" />
            <token id="27" string="arguing" />
            <token id="28" string="when" />
            <token id="29" string="Dickey" />
            <token id="30" string="ordered" />
            <token id="31" string="him" />
            <token id="32" string="to" />
            <token id="33" string="submit" />
            <token id="34" string="to" />
            <token id="35" string="a" />
            <token id="36" string="search" />
            <token id="37" string="for" />
            <token id="38" string="weapons" />
          </tokens>
        </chunking>
        <chunking id="16" string="the two police officers become concerned for their safety when Jackson suspiciously exited the car as soon as it stopped , then immediately started arguing when Dickey ordered him to submit to a search for weapons" type="SBAR">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="two" />
            <token id="5" string="police" />
            <token id="6" string="officers" />
            <token id="7" string="become" />
            <token id="8" string="concerned" />
            <token id="9" string="for" />
            <token id="10" string="their" />
            <token id="11" string="safety" />
            <token id="12" string="when" />
            <token id="13" string="Jackson" />
            <token id="14" string="suspiciously" />
            <token id="15" string="exited" />
            <token id="16" string="the" />
            <token id="17" string="car" />
            <token id="18" string="as" />
            <token id="19" string="soon" />
            <token id="20" string="as" />
            <token id="21" string="it" />
            <token id="22" string="stopped" />
            <token id="23" string="," />
            <token id="24" string="then" />
            <token id="25" string="immediately" />
            <token id="26" string="started" />
            <token id="27" string="arguing" />
            <token id="28" string="when" />
            <token id="29" string="Dickey" />
            <token id="30" string="ordered" />
            <token id="31" string="him" />
            <token id="32" string="to" />
            <token id="33" string="submit" />
            <token id="34" string="to" />
            <token id="35" string="a" />
            <token id="36" string="search" />
            <token id="37" string="for" />
            <token id="38" string="weapons" />
          </tokens>
        </chunking>
        <chunking id="17" string="Jackson" type="NP">
          <tokens>
            <token id="13" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="18" string="him" type="NP">
          <tokens>
            <token id="31" string="him" />
          </tokens>
        </chunking>
        <chunking id="19" string="when" type="WHADVP">
          <tokens>
            <token id="12" string="when" />
          </tokens>
        </chunking>
        <chunking id="20" string="the car" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="car" />
          </tokens>
        </chunking>
        <chunking id="21" string="exited the car as soon as it stopped , then immediately started arguing when Dickey ordered him to submit to a search for weapons" type="VP">
          <tokens>
            <token id="15" string="exited" />
            <token id="16" string="the" />
            <token id="17" string="car" />
            <token id="18" string="as" />
            <token id="19" string="soon" />
            <token id="20" string="as" />
            <token id="21" string="it" />
            <token id="22" string="stopped" />
            <token id="23" string="," />
            <token id="24" string="then" />
            <token id="25" string="immediately" />
            <token id="26" string="started" />
            <token id="27" string="arguing" />
            <token id="28" string="when" />
            <token id="29" string="Dickey" />
            <token id="30" string="ordered" />
            <token id="31" string="him" />
            <token id="32" string="to" />
            <token id="33" string="submit" />
            <token id="34" string="to" />
            <token id="35" string="a" />
            <token id="36" string="search" />
            <token id="37" string="for" />
            <token id="38" string="weapons" />
          </tokens>
        </chunking>
        <chunking id="22" string="their safety" type="NP">
          <tokens>
            <token id="10" string="their" />
            <token id="11" string="safety" />
          </tokens>
        </chunking>
        <chunking id="23" string="the two police officers" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="two" />
            <token id="5" string="police" />
            <token id="6" string="officers" />
          </tokens>
        </chunking>
        <chunking id="24" string="started arguing when Dickey ordered him to submit to a search for weapons" type="VP">
          <tokens>
            <token id="26" string="started" />
            <token id="27" string="arguing" />
            <token id="28" string="when" />
            <token id="29" string="Dickey" />
            <token id="30" string="ordered" />
            <token id="31" string="him" />
            <token id="32" string="to" />
            <token id="33" string="submit" />
            <token id="34" string="to" />
            <token id="35" string="a" />
            <token id="36" string="search" />
            <token id="37" string="for" />
            <token id="38" string="weapons" />
          </tokens>
        </chunking>
        <chunking id="25" string="a search" type="NP">
          <tokens>
            <token id="35" string="a" />
            <token id="36" string="search" />
          </tokens>
        </chunking>
        <chunking id="26" string="concerned for their safety when Jackson suspiciously exited the car as soon as it stopped , then immediately started arguing when Dickey ordered him to submit to a search for weapons" type="ADJP">
          <tokens>
            <token id="8" string="concerned" />
            <token id="9" string="for" />
            <token id="10" string="their" />
            <token id="11" string="safety" />
            <token id="12" string="when" />
            <token id="13" string="Jackson" />
            <token id="14" string="suspiciously" />
            <token id="15" string="exited" />
            <token id="16" string="the" />
            <token id="17" string="car" />
            <token id="18" string="as" />
            <token id="19" string="soon" />
            <token id="20" string="as" />
            <token id="21" string="it" />
            <token id="22" string="stopped" />
            <token id="23" string="," />
            <token id="24" string="then" />
            <token id="25" string="immediately" />
            <token id="26" string="started" />
            <token id="27" string="arguing" />
            <token id="28" string="when" />
            <token id="29" string="Dickey" />
            <token id="30" string="ordered" />
            <token id="31" string="him" />
            <token id="32" string="to" />
            <token id="33" string="submit" />
            <token id="34" string="to" />
            <token id="35" string="a" />
            <token id="36" string="search" />
            <token id="37" string="for" />
            <token id="38" string="weapons" />
          </tokens>
        </chunking>
        <chunking id="27" string="ordered him to submit to a search for weapons" type="VP">
          <tokens>
            <token id="30" string="ordered" />
            <token id="31" string="him" />
            <token id="32" string="to" />
            <token id="33" string="submit" />
            <token id="34" string="to" />
            <token id="35" string="a" />
            <token id="36" string="search" />
            <token id="37" string="for" />
            <token id="38" string="weapons" />
          </tokens>
        </chunking>
        <chunking id="28" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">officers</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="6">officers</governor>
          <dependent id="4">two</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">officers</governor>
          <dependent id="5">police</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">become</governor>
          <dependent id="6">officers</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="7">become</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="7">become</governor>
          <dependent id="8">concerned</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">safety</governor>
          <dependent id="9">for</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">safety</governor>
          <dependent id="10">their</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">concerned</governor>
          <dependent id="11">safety</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">exited</governor>
          <dependent id="12">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">exited</governor>
          <dependent id="13">Jackson</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">exited</governor>
          <dependent id="14">suspiciously</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="11">safety</governor>
          <dependent id="15">exited</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">car</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">exited</governor>
          <dependent id="17">car</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="19">soon</governor>
          <dependent id="18">as</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">exited</governor>
          <dependent id="19">soon</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">stopped</governor>
          <dependent id="20">as</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">stopped</governor>
          <dependent id="21">it</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="19">soon</governor>
          <dependent id="22">stopped</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="26">started</governor>
          <dependent id="24">then</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="26">started</governor>
          <dependent id="25">immediately</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="22">stopped</governor>
          <dependent id="26">started</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="26">started</governor>
          <dependent id="27">arguing</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="30">ordered</governor>
          <dependent id="28">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="30">ordered</governor>
          <dependent id="29">Dickey</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="27">arguing</governor>
          <dependent id="30">ordered</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="30">ordered</governor>
          <dependent id="31">him</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="33">submit</governor>
          <dependent id="32">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="30">ordered</governor>
          <dependent id="33">submit</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">search</governor>
          <dependent id="34">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="36">search</governor>
          <dependent id="35">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="33">submit</governor>
          <dependent id="36">search</dependent>
        </dependency>
        <dependency type="case">
          <governor id="38">weapons</governor>
          <dependent id="37">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="36">search</governor>
          <dependent id="38">weapons</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="4" string="two" />
          </tokens>
        </entity>
        <entity id="2" string="Jackson" type="PERSON" score="0.0">
          <tokens>
            <token id="13" string="Jackson" />
          </tokens>
        </entity>
        <entity id="3" string="Dickey" type="PERSON" score="0.0">
          <tokens>
            <token id="29" string="Dickey" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="42" has_coreference="true">
      <content>&amp;apost;Proper Police Tactics&amp;apost; &amp;quot;The officer, using proper police tactics, pushed him up (against) the side of a building and unfortunately, the window broke,&amp;quot; Hannon said.</content>
      <tokens>
        <token id="1" string="'" lemma="`" stem="'" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Proper" lemma="proper" stem="proper" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="Police" lemma="police" stem="polic" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="Tactics" lemma="tactic" stem="tactic" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="officer" lemma="officer" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="using" lemma="use" stem="us" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="proper" lemma="proper" stem="proper" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="tactics" lemma="tactic" stem="tactic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="pushed" lemma="push" stem="push" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="side" lemma="side" stem="side" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="building" lemma="building" stem="build" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="unfortunately" lemma="unfortunately" stem="unfortun" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="30" string="window" lemma="window" stem="window" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="31" string="broke" lemma="break" stem="broke" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="Hannon" lemma="Hannon" stem="hannon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="35" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` `) (S (S (NP (NP (NP (JJ Proper) (NNS Police) (NNS Tactics) (POS ')) (`` ``) (NX (DT The) (NN officer))) (, ,) (VP (VBG using) (NP (JJ proper) (NN police) (NNS tactics))) (, ,)) (VP (VBD pushed) (NP (NP (NP (PRP him)) (ADVP (RP up))) (PRN (-LRB- -LRB-) (PP (IN against)) (-RRB- -RRB-))) (NP (NP (DT the) (NN side)) (PP (IN of) (NP (DT a) (NN building)))))) (CC and) (S (ADVP (RB unfortunately)) (, ,) (NP (DT the) (NN window)) (VP (VBD broke)))) (, ,) ('' '') (NP (NNP Hannon)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the window" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="window" />
          </tokens>
        </chunking>
        <chunking id="2" string="Proper Police Tactics ' `` The officer" type="NP">
          <tokens>
            <token id="2" string="Proper" />
            <token id="3" string="Police" />
            <token id="4" string="Tactics" />
            <token id="5" string="'" />
            <token id="6" string="&quot;" />
            <token id="7" string="The" />
            <token id="8" string="officer" />
          </tokens>
        </chunking>
        <chunking id="3" string="broke" type="VP">
          <tokens>
            <token id="31" string="broke" />
          </tokens>
        </chunking>
        <chunking id="4" string="pushed him up -LRB- against -RRB- the side of a building" type="VP">
          <tokens>
            <token id="15" string="pushed" />
            <token id="16" string="him" />
            <token id="17" string="up" />
            <token id="18" string="(" />
            <token id="19" string="against" />
            <token id="20" string=")" />
            <token id="21" string="the" />
            <token id="22" string="side" />
            <token id="23" string="of" />
            <token id="24" string="a" />
            <token id="25" string="building" />
          </tokens>
        </chunking>
        <chunking id="5" string="the side of a building" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="side" />
            <token id="23" string="of" />
            <token id="24" string="a" />
            <token id="25" string="building" />
          </tokens>
        </chunking>
        <chunking id="6" string="the side" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="side" />
          </tokens>
        </chunking>
        <chunking id="7" string="a building" type="NP">
          <tokens>
            <token id="24" string="a" />
            <token id="25" string="building" />
          </tokens>
        </chunking>
        <chunking id="8" string="him up -LRB- against -RRB-" type="NP">
          <tokens>
            <token id="16" string="him" />
            <token id="17" string="up" />
            <token id="18" string="(" />
            <token id="19" string="against" />
            <token id="20" string=")" />
          </tokens>
        </chunking>
        <chunking id="9" string="him" type="NP">
          <tokens>
            <token id="16" string="him" />
          </tokens>
        </chunking>
        <chunking id="10" string="Hannon" type="NP">
          <tokens>
            <token id="34" string="Hannon" />
          </tokens>
        </chunking>
        <chunking id="11" string="Proper Police Tactics ' `` The officer , using proper police tactics ," type="NP">
          <tokens>
            <token id="2" string="Proper" />
            <token id="3" string="Police" />
            <token id="4" string="Tactics" />
            <token id="5" string="'" />
            <token id="6" string="&quot;" />
            <token id="7" string="The" />
            <token id="8" string="officer" />
            <token id="9" string="," />
            <token id="10" string="using" />
            <token id="11" string="proper" />
            <token id="12" string="police" />
            <token id="13" string="tactics" />
            <token id="14" string="," />
          </tokens>
        </chunking>
        <chunking id="12" string="proper police tactics" type="NP">
          <tokens>
            <token id="11" string="proper" />
            <token id="12" string="police" />
            <token id="13" string="tactics" />
          </tokens>
        </chunking>
        <chunking id="13" string="using proper police tactics" type="VP">
          <tokens>
            <token id="10" string="using" />
            <token id="11" string="proper" />
            <token id="12" string="police" />
            <token id="13" string="tactics" />
          </tokens>
        </chunking>
        <chunking id="14" string="Proper Police Tactics '" type="NP">
          <tokens>
            <token id="2" string="Proper" />
            <token id="3" string="Police" />
            <token id="4" string="Tactics" />
            <token id="5" string="'" />
          </tokens>
        </chunking>
        <chunking id="15" string="said" type="VP">
          <tokens>
            <token id="35" string="said" />
          </tokens>
        </chunking>
        <chunking id="16" string="him up" type="NP">
          <tokens>
            <token id="16" string="him" />
            <token id="17" string="up" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="4">Tactics</governor>
          <dependent id="2">Proper</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">Tactics</governor>
          <dependent id="3">Police</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">officer</governor>
          <dependent id="4">Tactics</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">Tactics</governor>
          <dependent id="5">'</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">officer</governor>
          <dependent id="7">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">pushed</governor>
          <dependent id="8">officer</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="8">officer</governor>
          <dependent id="10">using</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">tactics</governor>
          <dependent id="11">proper</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">tactics</governor>
          <dependent id="12">police</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">using</governor>
          <dependent id="13">tactics</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="35">said</governor>
          <dependent id="15">pushed</dependent>
        </dependency>
        <dependency type="iobj">
          <governor id="15">pushed</governor>
          <dependent id="16">him</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">him</governor>
          <dependent id="17">up</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">him</governor>
          <dependent id="19">against</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">side</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">pushed</governor>
          <dependent id="22">side</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">building</governor>
          <dependent id="23">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">building</governor>
          <dependent id="24">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">side</governor>
          <dependent id="25">building</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="15">pushed</governor>
          <dependent id="26">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="31">broke</governor>
          <dependent id="27">unfortunately</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">window</governor>
          <dependent id="29">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="31">broke</governor>
          <dependent id="30">window</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="15">pushed</governor>
          <dependent id="31">broke</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="35">said</governor>
          <dependent id="34">Hannon</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="35">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Hannon" type="PERSON" score="0.0">
          <tokens>
            <token id="34" string="Hannon" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="43" has_coreference="true">
      <content>&amp;quot;I&amp;apost;m sure neither Mr. Jackson nor the officer wanted the window to break, because it was dangerous.&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="'m" lemma="be" stem="'m" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="sure" lemma="sure" stem="sure" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="neither" lemma="neither" stem="neither" pos="CC" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="Mr." lemma="Mr." stem="mr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="8" string="nor" lemma="nor" stem="nor" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="officer" lemma="officer" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="wanted" lemma="want" stem="want" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="window" lemma="window" stem="window" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="break" lemma="break" stem="break" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="dangerous" lemma="dangerous" stem="danger" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP I)) (VP (VBP 'm) (ADJP (JJ sure) (SBAR (S (NP (CC neither) (NP (NNP Mr.) (NNP Jackson)) (CC nor) (NP (DT the) (NN officer))) (VP (VBD wanted) (NP (DT the) (NN window)) (S (VP (TO to) (VP (VB break)))) (, ,) (SBAR (IN because) (S (NP (PRP it)) (VP (VBD was) (ADJP (JJ dangerous)))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="the window" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="window" />
          </tokens>
        </chunking>
        <chunking id="2" string="neither Mr. Jackson nor the officer wanted the window to break , because it was dangerous" type="SBAR">
          <tokens>
            <token id="5" string="neither" />
            <token id="6" string="Mr." />
            <token id="7" string="Jackson" />
            <token id="8" string="nor" />
            <token id="9" string="the" />
            <token id="10" string="officer" />
            <token id="11" string="wanted" />
            <token id="12" string="the" />
            <token id="13" string="window" />
            <token id="14" string="to" />
            <token id="15" string="break" />
            <token id="16" string="," />
            <token id="17" string="because" />
            <token id="18" string="it" />
            <token id="19" string="was" />
            <token id="20" string="dangerous" />
          </tokens>
        </chunking>
        <chunking id="3" string="'m sure neither Mr. Jackson nor the officer wanted the window to break , because it was dangerous" type="VP">
          <tokens>
            <token id="3" string="'m" />
            <token id="4" string="sure" />
            <token id="5" string="neither" />
            <token id="6" string="Mr." />
            <token id="7" string="Jackson" />
            <token id="8" string="nor" />
            <token id="9" string="the" />
            <token id="10" string="officer" />
            <token id="11" string="wanted" />
            <token id="12" string="the" />
            <token id="13" string="window" />
            <token id="14" string="to" />
            <token id="15" string="break" />
            <token id="16" string="," />
            <token id="17" string="because" />
            <token id="18" string="it" />
            <token id="19" string="was" />
            <token id="20" string="dangerous" />
          </tokens>
        </chunking>
        <chunking id="4" string="break" type="VP">
          <tokens>
            <token id="15" string="break" />
          </tokens>
        </chunking>
        <chunking id="5" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="6" string="to break" type="VP">
          <tokens>
            <token id="14" string="to" />
            <token id="15" string="break" />
          </tokens>
        </chunking>
        <chunking id="7" string="because it was dangerous" type="SBAR">
          <tokens>
            <token id="17" string="because" />
            <token id="18" string="it" />
            <token id="19" string="was" />
            <token id="20" string="dangerous" />
          </tokens>
        </chunking>
        <chunking id="8" string="the officer" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="officer" />
          </tokens>
        </chunking>
        <chunking id="9" string="it" type="NP">
          <tokens>
            <token id="18" string="it" />
          </tokens>
        </chunking>
        <chunking id="10" string="dangerous" type="ADJP">
          <tokens>
            <token id="20" string="dangerous" />
          </tokens>
        </chunking>
        <chunking id="11" string="Mr. Jackson" type="NP">
          <tokens>
            <token id="6" string="Mr." />
            <token id="7" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="12" string="neither Mr. Jackson nor the officer" type="NP">
          <tokens>
            <token id="5" string="neither" />
            <token id="6" string="Mr." />
            <token id="7" string="Jackson" />
            <token id="8" string="nor" />
            <token id="9" string="the" />
            <token id="10" string="officer" />
          </tokens>
        </chunking>
        <chunking id="13" string="was dangerous" type="VP">
          <tokens>
            <token id="19" string="was" />
            <token id="20" string="dangerous" />
          </tokens>
        </chunking>
        <chunking id="14" string="wanted the window to break , because it was dangerous" type="VP">
          <tokens>
            <token id="11" string="wanted" />
            <token id="12" string="the" />
            <token id="13" string="window" />
            <token id="14" string="to" />
            <token id="15" string="break" />
            <token id="16" string="," />
            <token id="17" string="because" />
            <token id="18" string="it" />
            <token id="19" string="was" />
            <token id="20" string="dangerous" />
          </tokens>
        </chunking>
        <chunking id="15" string="sure neither Mr. Jackson nor the officer wanted the window to break , because it was dangerous" type="ADJP">
          <tokens>
            <token id="4" string="sure" />
            <token id="5" string="neither" />
            <token id="6" string="Mr." />
            <token id="7" string="Jackson" />
            <token id="8" string="nor" />
            <token id="9" string="the" />
            <token id="10" string="officer" />
            <token id="11" string="wanted" />
            <token id="12" string="the" />
            <token id="13" string="window" />
            <token id="14" string="to" />
            <token id="15" string="break" />
            <token id="16" string="," />
            <token id="17" string="because" />
            <token id="18" string="it" />
            <token id="19" string="was" />
            <token id="20" string="dangerous" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">sure</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">sure</governor>
          <dependent id="3">'m</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">sure</dependent>
        </dependency>
        <dependency type="cc:preconj">
          <governor id="7">Jackson</governor>
          <dependent id="5">neither</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Jackson</governor>
          <dependent id="6">Mr.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">wanted</governor>
          <dependent id="7">Jackson</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">Jackson</governor>
          <dependent id="8">nor</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">officer</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">Jackson</governor>
          <dependent id="10">officer</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">sure</governor>
          <dependent id="11">wanted</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">window</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">wanted</governor>
          <dependent id="13">window</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">break</governor>
          <dependent id="14">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="11">wanted</governor>
          <dependent id="15">break</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="20">dangerous</governor>
          <dependent id="17">because</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">dangerous</governor>
          <dependent id="18">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="20">dangerous</governor>
          <dependent id="19">was</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="11">wanted</governor>
          <dependent id="20">dangerous</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Jackson" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Jackson" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="44" has_coreference="true">
      <content>He said Jackson had an eye for the camera when he screamed as Dickey moved him over to the police cruiser for arrest.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="4" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="eye" lemma="eye" stem="ey" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="camera" lemma="camera" stem="camera" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="screamed" lemma="scream" stem="scream" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Dickey" lemma="Dickey" stem="dickei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="15" string="moved" lemma="move" stem="move" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="over" lemma="over" stem="over" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="cruiser" lemma="cruiser" stem="cruiser" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="arrest" lemma="arrest" stem="arrest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VBD said) (SBAR (S (NP (NNP Jackson)) (VP (VBD had) (NP (NP (DT an) (NN eye)) (PP (IN for) (NP (NP (DT the) (NN camera)) (SBAR (WHADVP (WRB when)) (S (NP (PRP he)) (VP (VBD screamed) (SBAR (IN as) (S (NP (NNP Dickey)) (VP (VBD moved) (NP (PRP him)) (PP (IN over) (PP (TO to) (NP (DT the) (NN police) (NN cruiser)))) (PP (IN for) (NP (NN arrest)))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the police cruiser" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="police" />
            <token id="21" string="cruiser" />
          </tokens>
        </chunking>
        <chunking id="2" string="arrest" type="NP">
          <tokens>
            <token id="23" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="3" string="moved him over to the police cruiser for arrest" type="VP">
          <tokens>
            <token id="15" string="moved" />
            <token id="16" string="him" />
            <token id="17" string="over" />
            <token id="18" string="to" />
            <token id="19" string="the" />
            <token id="20" string="police" />
            <token id="21" string="cruiser" />
            <token id="22" string="for" />
            <token id="23" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="4" string="as Dickey moved him over to the police cruiser for arrest" type="SBAR">
          <tokens>
            <token id="13" string="as" />
            <token id="14" string="Dickey" />
            <token id="15" string="moved" />
            <token id="16" string="him" />
            <token id="17" string="over" />
            <token id="18" string="to" />
            <token id="19" string="the" />
            <token id="20" string="police" />
            <token id="21" string="cruiser" />
            <token id="22" string="for" />
            <token id="23" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="5" string="Jackson" type="NP">
          <tokens>
            <token id="3" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="6" string="him" type="NP">
          <tokens>
            <token id="16" string="him" />
          </tokens>
        </chunking>
        <chunking id="7" string="an eye for the camera when he screamed as Dickey moved him over to the police cruiser for arrest" type="NP">
          <tokens>
            <token id="5" string="an" />
            <token id="6" string="eye" />
            <token id="7" string="for" />
            <token id="8" string="the" />
            <token id="9" string="camera" />
            <token id="10" string="when" />
            <token id="11" string="he" />
            <token id="12" string="screamed" />
            <token id="13" string="as" />
            <token id="14" string="Dickey" />
            <token id="15" string="moved" />
            <token id="16" string="him" />
            <token id="17" string="over" />
            <token id="18" string="to" />
            <token id="19" string="the" />
            <token id="20" string="police" />
            <token id="21" string="cruiser" />
            <token id="22" string="for" />
            <token id="23" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="8" string="when" type="WHADVP">
          <tokens>
            <token id="10" string="when" />
          </tokens>
        </chunking>
        <chunking id="9" string="said Jackson had an eye for the camera when he screamed as Dickey moved him over to the police cruiser for arrest" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="Jackson" />
            <token id="4" string="had" />
            <token id="5" string="an" />
            <token id="6" string="eye" />
            <token id="7" string="for" />
            <token id="8" string="the" />
            <token id="9" string="camera" />
            <token id="10" string="when" />
            <token id="11" string="he" />
            <token id="12" string="screamed" />
            <token id="13" string="as" />
            <token id="14" string="Dickey" />
            <token id="15" string="moved" />
            <token id="16" string="him" />
            <token id="17" string="over" />
            <token id="18" string="to" />
            <token id="19" string="the" />
            <token id="20" string="police" />
            <token id="21" string="cruiser" />
            <token id="22" string="for" />
            <token id="23" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="10" string="an eye" type="NP">
          <tokens>
            <token id="5" string="an" />
            <token id="6" string="eye" />
          </tokens>
        </chunking>
        <chunking id="11" string="when he screamed as Dickey moved him over to the police cruiser for arrest" type="SBAR">
          <tokens>
            <token id="10" string="when" />
            <token id="11" string="he" />
            <token id="12" string="screamed" />
            <token id="13" string="as" />
            <token id="14" string="Dickey" />
            <token id="15" string="moved" />
            <token id="16" string="him" />
            <token id="17" string="over" />
            <token id="18" string="to" />
            <token id="19" string="the" />
            <token id="20" string="police" />
            <token id="21" string="cruiser" />
            <token id="22" string="for" />
            <token id="23" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="12" string="the camera when he screamed as Dickey moved him over to the police cruiser for arrest" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="camera" />
            <token id="10" string="when" />
            <token id="11" string="he" />
            <token id="12" string="screamed" />
            <token id="13" string="as" />
            <token id="14" string="Dickey" />
            <token id="15" string="moved" />
            <token id="16" string="him" />
            <token id="17" string="over" />
            <token id="18" string="to" />
            <token id="19" string="the" />
            <token id="20" string="police" />
            <token id="21" string="cruiser" />
            <token id="22" string="for" />
            <token id="23" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="13" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="14" string="he" type="NP">
          <tokens>
            <token id="11" string="he" />
          </tokens>
        </chunking>
        <chunking id="15" string="Jackson had an eye for the camera when he screamed as Dickey moved him over to the police cruiser for arrest" type="SBAR">
          <tokens>
            <token id="3" string="Jackson" />
            <token id="4" string="had" />
            <token id="5" string="an" />
            <token id="6" string="eye" />
            <token id="7" string="for" />
            <token id="8" string="the" />
            <token id="9" string="camera" />
            <token id="10" string="when" />
            <token id="11" string="he" />
            <token id="12" string="screamed" />
            <token id="13" string="as" />
            <token id="14" string="Dickey" />
            <token id="15" string="moved" />
            <token id="16" string="him" />
            <token id="17" string="over" />
            <token id="18" string="to" />
            <token id="19" string="the" />
            <token id="20" string="police" />
            <token id="21" string="cruiser" />
            <token id="22" string="for" />
            <token id="23" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="16" string="had an eye for the camera when he screamed as Dickey moved him over to the police cruiser for arrest" type="VP">
          <tokens>
            <token id="4" string="had" />
            <token id="5" string="an" />
            <token id="6" string="eye" />
            <token id="7" string="for" />
            <token id="8" string="the" />
            <token id="9" string="camera" />
            <token id="10" string="when" />
            <token id="11" string="he" />
            <token id="12" string="screamed" />
            <token id="13" string="as" />
            <token id="14" string="Dickey" />
            <token id="15" string="moved" />
            <token id="16" string="him" />
            <token id="17" string="over" />
            <token id="18" string="to" />
            <token id="19" string="the" />
            <token id="20" string="police" />
            <token id="21" string="cruiser" />
            <token id="22" string="for" />
            <token id="23" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="17" string="the camera" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="camera" />
          </tokens>
        </chunking>
        <chunking id="18" string="screamed as Dickey moved him over to the police cruiser for arrest" type="VP">
          <tokens>
            <token id="12" string="screamed" />
            <token id="13" string="as" />
            <token id="14" string="Dickey" />
            <token id="15" string="moved" />
            <token id="16" string="him" />
            <token id="17" string="over" />
            <token id="18" string="to" />
            <token id="19" string="the" />
            <token id="20" string="police" />
            <token id="21" string="cruiser" />
            <token id="22" string="for" />
            <token id="23" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="19" string="Dickey" type="NP">
          <tokens>
            <token id="14" string="Dickey" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">had</governor>
          <dependent id="3">Jackson</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="4">had</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">eye</governor>
          <dependent id="5">an</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">had</governor>
          <dependent id="6">eye</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">camera</governor>
          <dependent id="7">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">camera</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">eye</governor>
          <dependent id="9">camera</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">screamed</governor>
          <dependent id="10">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">screamed</governor>
          <dependent id="11">he</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="9">camera</governor>
          <dependent id="12">screamed</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">moved</governor>
          <dependent id="13">as</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">moved</governor>
          <dependent id="14">Dickey</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="12">screamed</governor>
          <dependent id="15">moved</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">moved</governor>
          <dependent id="16">him</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">cruiser</governor>
          <dependent id="17">over</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">cruiser</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">cruiser</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">cruiser</governor>
          <dependent id="20">police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">moved</governor>
          <dependent id="21">cruiser</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">arrest</governor>
          <dependent id="22">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">moved</governor>
          <dependent id="23">arrest</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Jackson" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Jackson" />
          </tokens>
        </entity>
        <entity id="2" string="Dickey" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Dickey" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="45" has_coreference="true">
      <content>He said Dickey, who has been on the police force for four years, had one earlier complaint about his conduct, which was investigated by the department and determined to be unfounded.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Dickey" lemma="Dickey" stem="dickei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="force" lemma="force" stem="forc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="four" lemma="four" stem="four" pos="CD" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="true" />
        <token id="14" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="true" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="18" string="earlier" lemma="earlier" stem="earlier" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="complaint" lemma="complaint" stem="complaint" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="conduct" lemma="conduct" stem="conduct" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="investigated" lemma="investigate" stem="investig" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="29" string="department" lemma="department" stem="depart" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="30" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="determined" lemma="determine" stem="determin" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="unfounded" lemma="unfounded" stem="unfound" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VBD said) (SBAR (S (NP (NP (NNP Dickey)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBZ has) (VP (VBN been) (PP (IN on) (NP (DT the) (NN police) (NN force))) (PP (IN for) (NP (CD four) (NNS years))))))) (, ,)) (VP (VBD had) (NP (NP (CD one) (JJR earlier) (NN complaint)) (PP (IN about) (NP (NP (PRP$ his) (NN conduct)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBD was) (VP (VP (VBN investigated) (PP (IN by) (NP (DT the) (NN department)))) (CC and) (VP (VBN determined) (S (VP (TO to) (VP (VB be) (ADJP (JJ unfounded))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="been on the police force for four years" type="VP">
          <tokens>
            <token id="7" string="been" />
            <token id="8" string="on" />
            <token id="9" string="the" />
            <token id="10" string="police" />
            <token id="11" string="force" />
            <token id="12" string="for" />
            <token id="13" string="four" />
            <token id="14" string="years" />
          </tokens>
        </chunking>
        <chunking id="2" string="who has been on the police force for four years" type="SBAR">
          <tokens>
            <token id="5" string="who" />
            <token id="6" string="has" />
            <token id="7" string="been" />
            <token id="8" string="on" />
            <token id="9" string="the" />
            <token id="10" string="police" />
            <token id="11" string="force" />
            <token id="12" string="for" />
            <token id="13" string="four" />
            <token id="14" string="years" />
          </tokens>
        </chunking>
        <chunking id="3" string="four years" type="NP">
          <tokens>
            <token id="13" string="four" />
            <token id="14" string="years" />
          </tokens>
        </chunking>
        <chunking id="4" string="one earlier complaint" type="NP">
          <tokens>
            <token id="17" string="one" />
            <token id="18" string="earlier" />
            <token id="19" string="complaint" />
          </tokens>
        </chunking>
        <chunking id="5" string="had one earlier complaint about his conduct , which was investigated by the department and determined to be unfounded" type="VP">
          <tokens>
            <token id="16" string="had" />
            <token id="17" string="one" />
            <token id="18" string="earlier" />
            <token id="19" string="complaint" />
            <token id="20" string="about" />
            <token id="21" string="his" />
            <token id="22" string="conduct" />
            <token id="23" string="," />
            <token id="24" string="which" />
            <token id="25" string="was" />
            <token id="26" string="investigated" />
            <token id="27" string="by" />
            <token id="28" string="the" />
            <token id="29" string="department" />
            <token id="30" string="and" />
            <token id="31" string="determined" />
            <token id="32" string="to" />
            <token id="33" string="be" />
            <token id="34" string="unfounded" />
          </tokens>
        </chunking>
        <chunking id="6" string="one earlier complaint about his conduct , which was investigated by the department and determined to be unfounded" type="NP">
          <tokens>
            <token id="17" string="one" />
            <token id="18" string="earlier" />
            <token id="19" string="complaint" />
            <token id="20" string="about" />
            <token id="21" string="his" />
            <token id="22" string="conduct" />
            <token id="23" string="," />
            <token id="24" string="which" />
            <token id="25" string="was" />
            <token id="26" string="investigated" />
            <token id="27" string="by" />
            <token id="28" string="the" />
            <token id="29" string="department" />
            <token id="30" string="and" />
            <token id="31" string="determined" />
            <token id="32" string="to" />
            <token id="33" string="be" />
            <token id="34" string="unfounded" />
          </tokens>
        </chunking>
        <chunking id="7" string="has been on the police force for four years" type="VP">
          <tokens>
            <token id="6" string="has" />
            <token id="7" string="been" />
            <token id="8" string="on" />
            <token id="9" string="the" />
            <token id="10" string="police" />
            <token id="11" string="force" />
            <token id="12" string="for" />
            <token id="13" string="four" />
            <token id="14" string="years" />
          </tokens>
        </chunking>
        <chunking id="8" string="his conduct" type="NP">
          <tokens>
            <token id="21" string="his" />
            <token id="22" string="conduct" />
          </tokens>
        </chunking>
        <chunking id="9" string="was investigated by the department and determined to be unfounded" type="VP">
          <tokens>
            <token id="25" string="was" />
            <token id="26" string="investigated" />
            <token id="27" string="by" />
            <token id="28" string="the" />
            <token id="29" string="department" />
            <token id="30" string="and" />
            <token id="31" string="determined" />
            <token id="32" string="to" />
            <token id="33" string="be" />
            <token id="34" string="unfounded" />
          </tokens>
        </chunking>
        <chunking id="10" string="be unfounded" type="VP">
          <tokens>
            <token id="33" string="be" />
            <token id="34" string="unfounded" />
          </tokens>
        </chunking>
        <chunking id="11" string="which was investigated by the department and determined to be unfounded" type="SBAR">
          <tokens>
            <token id="24" string="which" />
            <token id="25" string="was" />
            <token id="26" string="investigated" />
            <token id="27" string="by" />
            <token id="28" string="the" />
            <token id="29" string="department" />
            <token id="30" string="and" />
            <token id="31" string="determined" />
            <token id="32" string="to" />
            <token id="33" string="be" />
            <token id="34" string="unfounded" />
          </tokens>
        </chunking>
        <chunking id="12" string="investigated by the department and determined to be unfounded" type="VP">
          <tokens>
            <token id="26" string="investigated" />
            <token id="27" string="by" />
            <token id="28" string="the" />
            <token id="29" string="department" />
            <token id="30" string="and" />
            <token id="31" string="determined" />
            <token id="32" string="to" />
            <token id="33" string="be" />
            <token id="34" string="unfounded" />
          </tokens>
        </chunking>
        <chunking id="13" string="the department" type="NP">
          <tokens>
            <token id="28" string="the" />
            <token id="29" string="department" />
          </tokens>
        </chunking>
        <chunking id="14" string="the police force" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="police" />
            <token id="11" string="force" />
          </tokens>
        </chunking>
        <chunking id="15" string="determined to be unfounded" type="VP">
          <tokens>
            <token id="31" string="determined" />
            <token id="32" string="to" />
            <token id="33" string="be" />
            <token id="34" string="unfounded" />
          </tokens>
        </chunking>
        <chunking id="16" string="unfounded" type="ADJP">
          <tokens>
            <token id="34" string="unfounded" />
          </tokens>
        </chunking>
        <chunking id="17" string="Dickey , who has been on the police force for four years , had one earlier complaint about his conduct , which was investigated by the department and determined to be unfounded" type="SBAR">
          <tokens>
            <token id="3" string="Dickey" />
            <token id="4" string="," />
            <token id="5" string="who" />
            <token id="6" string="has" />
            <token id="7" string="been" />
            <token id="8" string="on" />
            <token id="9" string="the" />
            <token id="10" string="police" />
            <token id="11" string="force" />
            <token id="12" string="for" />
            <token id="13" string="four" />
            <token id="14" string="years" />
            <token id="15" string="," />
            <token id="16" string="had" />
            <token id="17" string="one" />
            <token id="18" string="earlier" />
            <token id="19" string="complaint" />
            <token id="20" string="about" />
            <token id="21" string="his" />
            <token id="22" string="conduct" />
            <token id="23" string="," />
            <token id="24" string="which" />
            <token id="25" string="was" />
            <token id="26" string="investigated" />
            <token id="27" string="by" />
            <token id="28" string="the" />
            <token id="29" string="department" />
            <token id="30" string="and" />
            <token id="31" string="determined" />
            <token id="32" string="to" />
            <token id="33" string="be" />
            <token id="34" string="unfounded" />
          </tokens>
        </chunking>
        <chunking id="18" string="Dickey , who has been on the police force for four years ," type="NP">
          <tokens>
            <token id="3" string="Dickey" />
            <token id="4" string="," />
            <token id="5" string="who" />
            <token id="6" string="has" />
            <token id="7" string="been" />
            <token id="8" string="on" />
            <token id="9" string="the" />
            <token id="10" string="police" />
            <token id="11" string="force" />
            <token id="12" string="for" />
            <token id="13" string="four" />
            <token id="14" string="years" />
            <token id="15" string="," />
          </tokens>
        </chunking>
        <chunking id="19" string="his conduct , which was investigated by the department and determined to be unfounded" type="NP">
          <tokens>
            <token id="21" string="his" />
            <token id="22" string="conduct" />
            <token id="23" string="," />
            <token id="24" string="which" />
            <token id="25" string="was" />
            <token id="26" string="investigated" />
            <token id="27" string="by" />
            <token id="28" string="the" />
            <token id="29" string="department" />
            <token id="30" string="and" />
            <token id="31" string="determined" />
            <token id="32" string="to" />
            <token id="33" string="be" />
            <token id="34" string="unfounded" />
          </tokens>
        </chunking>
        <chunking id="20" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="21" string="said Dickey , who has been on the police force for four years , had one earlier complaint about his conduct , which was investigated by the department and determined to be unfounded" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="Dickey" />
            <token id="4" string="," />
            <token id="5" string="who" />
            <token id="6" string="has" />
            <token id="7" string="been" />
            <token id="8" string="on" />
            <token id="9" string="the" />
            <token id="10" string="police" />
            <token id="11" string="force" />
            <token id="12" string="for" />
            <token id="13" string="four" />
            <token id="14" string="years" />
            <token id="15" string="," />
            <token id="16" string="had" />
            <token id="17" string="one" />
            <token id="18" string="earlier" />
            <token id="19" string="complaint" />
            <token id="20" string="about" />
            <token id="21" string="his" />
            <token id="22" string="conduct" />
            <token id="23" string="," />
            <token id="24" string="which" />
            <token id="25" string="was" />
            <token id="26" string="investigated" />
            <token id="27" string="by" />
            <token id="28" string="the" />
            <token id="29" string="department" />
            <token id="30" string="and" />
            <token id="31" string="determined" />
            <token id="32" string="to" />
            <token id="33" string="be" />
            <token id="34" string="unfounded" />
          </tokens>
        </chunking>
        <chunking id="22" string="to be unfounded" type="VP">
          <tokens>
            <token id="32" string="to" />
            <token id="33" string="be" />
            <token id="34" string="unfounded" />
          </tokens>
        </chunking>
        <chunking id="23" string="Dickey" type="NP">
          <tokens>
            <token id="3" string="Dickey" />
          </tokens>
        </chunking>
        <chunking id="24" string="investigated by the department" type="VP">
          <tokens>
            <token id="26" string="investigated" />
            <token id="27" string="by" />
            <token id="28" string="the" />
            <token id="29" string="department" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">had</governor>
          <dependent id="3">Dickey</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">force</governor>
          <dependent id="5">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">force</governor>
          <dependent id="6">has</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="11">force</governor>
          <dependent id="7">been</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">force</governor>
          <dependent id="8">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">force</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">force</governor>
          <dependent id="10">police</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="3">Dickey</governor>
          <dependent id="11">force</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">years</governor>
          <dependent id="12">for</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="14">years</governor>
          <dependent id="13">four</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">force</governor>
          <dependent id="14">years</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="16">had</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="19">complaint</governor>
          <dependent id="17">one</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">complaint</governor>
          <dependent id="18">earlier</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">had</governor>
          <dependent id="19">complaint</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">conduct</governor>
          <dependent id="20">about</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="22">conduct</governor>
          <dependent id="21">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">complaint</governor>
          <dependent id="22">conduct</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="26">investigated</governor>
          <dependent id="24">which</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="26">investigated</governor>
          <dependent id="25">was</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="22">conduct</governor>
          <dependent id="26">investigated</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">department</governor>
          <dependent id="27">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">department</governor>
          <dependent id="28">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">investigated</governor>
          <dependent id="29">department</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="26">investigated</governor>
          <dependent id="30">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="26">investigated</governor>
          <dependent id="31">determined</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="34">unfounded</governor>
          <dependent id="32">to</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="34">unfounded</governor>
          <dependent id="33">be</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="31">determined</governor>
          <dependent id="34">unfounded</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="17" string="one" />
          </tokens>
        </entity>
        <entity id="2" string="four years" type="DURATION" score="0.0">
          <tokens>
            <token id="13" string="four" />
            <token id="14" string="years" />
          </tokens>
        </entity>
        <entity id="3" string="Dickey" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Dickey" />
          </tokens>
        </entity>
      </entities>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="2" type="PROPER">
      <referenced ids_tokens="1" string="Attorney" id_sentence="25" />
      <mentions>
        <mention ids_tokens="1-7" string="The Los Angeles County district attorney's" id_sentence="1" />
        <mention ids_tokens="10-13" string="the district attorney's" id_sentence="2" />
        <mention ids_tokens="4-6" string="the district attorney" id_sentence="21" />
        <mention ids_tokens="6-8" string="the district attorney" id_sentence="22" />
      </mentions>
    </coreference>
    <coreference id="4" type="NOMINAL">
      <referenced ids_tokens="7-8-9" string="the television footage" id_sentence="35" />
      <mentions>
        <mention ids_tokens="2" string="It" id_sentence="36" />
      </mentions>
    </coreference>
    <coreference id="5" type="NOMINAL">
      <referenced ids_tokens="19-20-21-22-23-24" string="a white Long Beach police officer" id_sentence="1" />
      <mentions>
        <mention ids_tokens="1" string="Police" id_sentence="27" />
        <mention ids_tokens="15-17" string="Long Beach police" id_sentence="27" />
        <mention ids_tokens="1" string="They" id_sentence="28" />
      </mentions>
    </coreference>
    <coreference id="6" type="NOMINAL">
      <referenced ids_tokens="34-35-36-37" string="a plate glass window" id_sentence="1" />
      <mentions>
        <mention ids_tokens="10-11" string="the window" id_sentence="28" />
        <mention ids_tokens="40-41" string="the window" id_sentence="30" />
        <mention ids_tokens="29-30" string="the window" id_sentence="42" />
        <mention ids_tokens="12-13" string="the window" id_sentence="43" />
        <mention ids_tokens="18" string="it" id_sentence="43" />
      </mentions>
    </coreference>
    <coreference id="8" type="PROPER">
      <referenced ids_tokens="32" string="NBC" id_sentence="2" />
      <mentions>
        <mention ids_tokens="13" string="it" id_sentence="13" />
        <mention ids_tokens="8-9" string="NBC's" id_sentence="15" />
        <mention ids_tokens="33" string="its" id_sentence="36" />
      </mentions>
    </coreference>
    <coreference id="9" type="PROPER">
      <referenced ids_tokens="1-2-3-4-5" string="The Long Beach City Council" id_sentence="2" />
      <mentions>
        <mention ids_tokens="8-9" string="City Council" id_sentence="18" />
        <mention ids_tokens="10-13" string="Long Beach City Council" id_sentence="34" />
      </mentions>
    </coreference>
    <coreference id="10" type="PROPER">
      <referenced ids_tokens="7" string="Tuesday" id_sentence="2" />
      <mentions>
        <mention ids_tokens="6-7" string="Tuesday's" id_sentence="18" />
      </mentions>
    </coreference>
    <coreference id="11" type="NOMINAL">
      <referenced ids_tokens="10-11-12-13-14-15-16-17-18-19-20-21-22-23-24-25-26-27-28-29-30-31-32-33-34" string="the district attorney 's office to launch an independent investigation of the Saturday night incident , which was secretly recorded by an NBC television crew" id_sentence="2" />
      <mentions>
        <mention ids_tokens="5-6" string="the office" id_sentence="4" />
        <mention ids_tokens="23-24" string="his office" id_sentence="5" />
        <mention ids_tokens="8-9" string="his office" id_sentence="14" />
        <mention ids_tokens="22-23" string="the office" id_sentence="22" />
      </mentions>
    </coreference>
    <coreference id="12" type="NOMINAL">
      <referenced ids_tokens="21-22-23-24" string="the Saturday night incident" id_sentence="2" />
      <mentions>
        <mention ids_tokens="37-38" string="the incident" id_sentence="12" />
        <mention ids_tokens="15-16" string="the incident" id_sentence="18" />
        <mention ids_tokens="12-13" string="the incident" id_sentence="27" />
      </mentions>
    </coreference>
    <coreference id="13" type="NOMINAL">
      <referenced ids_tokens="31-32-33-34" string="an NBC television crew" id_sentence="2" />
      <mentions>
        <mention ids_tokens="29-31" string="the television crew" id_sentence="10" />
        <mention ids_tokens="26-28" string="the NBC crew" id_sentence="12" />
      </mentions>
    </coreference>
    <coreference id="14" type="PROPER">
      <referenced ids_tokens="1-2-3" string="Atty. Curt Livesay" id_sentence="4" />
      <mentions>
        <mention ids_tokens="18" string="Livesay" id_sentence="5" />
        <mention ids_tokens="23" string="his" id_sentence="5" />
        <mention ids_tokens="17" string="Livesay" id_sentence="22" />
      </mentions>
    </coreference>
    <coreference id="15" type="PROPER">
      <referenced ids_tokens="27" string="Chief" id_sentence="15" />
      <mentions>
        <mention ids_tokens="17-21" string="the Long Beach police chief" id_sentence="4" />
      </mentions>
    </coreference>
    <coreference id="17" type="NOMINAL">
      <referenced ids_tokens="2-3-4-5-6-7" string="the two men in the car" id_sentence="39" />
      <mentions>
        <mention ids_tokens="4" string="they" id_sentence="40" />
        <mention ids_tokens="11" string="they" id_sentence="40" />
        <mention ids_tokens="13" string="they" id_sentence="40" />
        <mention ids_tokens="20" string="themselves" id_sentence="40" />
      </mentions>
    </coreference>
    <coreference id="19" type="PROPER">
      <referenced ids_tokens="21-22" string="Don Jackson" id_sentence="7" />
      <mentions>
        <mention ids_tokens="1" string="Jackson" id_sentence="10" />
        <mention ids_tokens="38" string="Jackson" id_sentence="17" />
        <mention ids_tokens="20-21" string="Jackson's" id_sentence="27" />
        <mention ids_tokens="4-5" string="Jackson's" id_sentence="28" />
        <mention ids_tokens="15" string="his" id_sentence="28" />
        <mention ids_tokens="33-34" string="Jackson's" id_sentence="30" />
        <mention ids_tokens="17-36" string="Jackson , who was booked for suspicion of using offensive language , challenging an officer to fight and obstructing arrest" id_sentence="32" />
        <mention ids_tokens="17" string="Jackson" id_sentence="32" />
        <mention ids_tokens="25" string="Jackson" id_sentence="35" />
        <mention ids_tokens="17" string="Jackson" id_sentence="37" />
        <mention ids_tokens="26" string="Jackson" id_sentence="40" />
        <mention ids_tokens="13" string="Jackson" id_sentence="41" />
        <mention ids_tokens="31" string="him" id_sentence="41" />
        <mention ids_tokens="16-20" string="him up ( against )" id_sentence="42" />
        <mention ids_tokens="6-7" string="Mr. Jackson" id_sentence="43" />
        <mention ids_tokens="7" string="Jackson" id_sentence="43" />
        <mention ids_tokens="3" string="Jackson" id_sentence="44" />
        <mention ids_tokens="11" string="he" id_sentence="44" />
        <mention ids_tokens="16" string="him" id_sentence="44" />
      </mentions>
    </coreference>
    <coreference id="21" type="PROPER">
      <referenced ids_tokens="46-47-48" string="Pacific Coast Highway" id_sentence="7" />
      <mentions>
        <mention ids_tokens="36-37" string="the highway" id_sentence="27" />
      </mentions>
    </coreference>
    <coreference id="22" type="NOMINAL">
      <referenced ids_tokens="15-16-17-18-19-20-21-22-23-24-25-26-27-28-29-30-31-32-33-34" string="the man who was arrested -- Don Jackson , a sergeant on administrative leave from the Hawthorne Police Department --" id_sentence="7" />
      <mentions>
        <mention ids_tokens="1" string="He" id_sentence="8" />
        <mention ids_tokens="23" string="he" id_sentence="9" />
      </mentions>
    </coreference>
    <coreference id="23" type="PROPER">
      <referenced ids_tokens="30-31-32-33" string="the Hawthorne Police Department" id_sentence="7" />
      <mentions>
        <mention ids_tokens="28-29" string="the department" id_sentence="45" />
      </mentions>
    </coreference>
    <coreference id="24" type="NOMINAL">
      <referenced ids_tokens="38-39" string="his altercation" id_sentence="7" />
      <mentions>
        <mention ids_tokens="17-18" string="the altercation" id_sentence="35" />
      </mentions>
    </coreference>
    <coreference id="25" type="NOMINAL">
      <referenced ids_tokens="41-42-43-44-45-46-47-48" string="two Long Beach officers on Pacific Coast Highway" id_sentence="7" />
      <mentions>
        <mention ids_tokens="2" string="We" id_sentence="9" />
        <mention ids_tokens="13" string="we" id_sentence="9" />
      </mentions>
    </coreference>
    <coreference id="27" type="PROPER">
      <referenced ids_tokens="19-20" string="this morning" id_sentence="9" />
      <mentions>
        <mention ids_tokens="16" string="morning" id_sentence="15" />
      </mentions>
    </coreference>
    <coreference id="28" type="PROPER">
      <referenced ids_tokens="3-4" string="Jeff Hill" id_sentence="10" />
      <mentions>
        <mention ids_tokens="23-24" string="Hill's" id_sentence="27" />
        <mention ids_tokens="6-12" string="Hill , the driver of the car" id_sentence="31" />
        <mention ids_tokens="6" string="Hill" id_sentence="31" />
        <mention ids_tokens="8-12" string="the driver of the car" id_sentence="31" />
        <mention ids_tokens="21" string="he" id_sentence="31" />
        <mention ids_tokens="28" string="Hill" id_sentence="40" />
      </mentions>
    </coreference>
    <coreference id="33" type="NOMINAL">
      <referenced ids_tokens="33-34-35-36-37-38" string="their own investigation of the incident" id_sentence="12" />
      <mentions>
        <mention ids_tokens="50-51" string="the investigation" id_sentence="15" />
      </mentions>
    </coreference>
    <coreference id="35" type="PROPER">
      <referenced ids_tokens="4" string="Mayor" id_sentence="15" />
      <mentions>
        <mention ids_tokens="12-13" string="the mayor" id_sentence="18" />
      </mentions>
    </coreference>
    <coreference id="36" type="PROPER">
      <referenced ids_tokens="2-3-4-5-6" string="Long Beach Mayor Ernie Kell" id_sentence="15" />
      <mentions>
        <mention ids_tokens="16" string="he" id_sentence="16" />
        <mention ids_tokens="1" string="Kell" id_sentence="17" />
        <mention ids_tokens="6" string="he" id_sentence="17" />
        <mention ids_tokens="11" string="his" id_sentence="17" />
        <mention ids_tokens="20" string="he" id_sentence="17" />
        <mention ids_tokens="21" string="Kell" id_sentence="21" />
      </mentions>
    </coreference>
    <coreference id="37" type="NOMINAL">
      <referenced ids_tokens="18-19-20-21" string="the two police officers" id_sentence="15" />
      <mentions>
        <mention ids_tokens="1" string="They" id_sentence="16" />
        <mention ids_tokens="8-10" string="the two officers" id_sentence="25" />
        <mention ids_tokens="3-5" string="the two officers" id_sentence="38" />
        <mention ids_tokens="10" string="their" id_sentence="41" />
      </mentions>
    </coreference>
    <coreference id="38" type="PROPER">
      <referenced ids_tokens="36-37" string="Mark Dickey" id_sentence="15" />
      <mentions>
        <mention ids_tokens="24-25" string="the officers" id_sentence="17" />
        <mention ids_tokens="31" string="they" id_sentence="17" />
        <mention ids_tokens="1" string="We" id_sentence="19" />
        <mention ids_tokens="1" string="We" id_sentence="20" />
        <mention ids_tokens="3-4" string="the officers" id_sentence="26" />
        <mention ids_tokens="31" string="Dickey" id_sentence="30" />
        <mention ids_tokens="6" string="Dickey" id_sentence="32" />
        <mention ids_tokens="25-27" string="Jackson and Dickey" id_sentence="35" />
        <mention ids_tokens="27" string="Dickey" id_sentence="35" />
        <mention ids_tokens="9" string="Dickey" id_sentence="37" />
        <mention ids_tokens="29" string="Dickey" id_sentence="41" />
        <mention ids_tokens="14" string="Dickey" id_sentence="44" />
        <mention ids_tokens="3-14" string="Dickey , who has been on the police force for four years" id_sentence="45" />
        <mention ids_tokens="3" string="Dickey" id_sentence="45" />
      </mentions>
    </coreference>
    <coreference id="39" type="NOMINAL">
      <referenced ids_tokens="5" string="this" id_sentence="19" />
      <mentions>
        <mention ids_tokens="12" string="it" id_sentence="20" />
      </mentions>
    </coreference>
    <coreference id="40" type="NOMINAL">
      <referenced ids_tokens="11-12-13" string="the city 's" id_sentence="21" />
      <mentions>
        <mention ids_tokens="41-42" string="the city" id_sentence="39" />
      </mentions>
    </coreference>
    <coreference id="41" type="NOMINAL">
      <referenced ids_tokens="4-5-6" string="a police officer" id_sentence="23" />
      <mentions>
        <mention ids_tokens="1" string="He" id_sentence="24" />
      </mentions>
    </coreference>
    <coreference id="43" type="PROPER">
      <referenced ids_tokens="4-5-6" string="Officer Attorney Hannon" id_sentence="37" />
      <mentions>
        <mention ids_tokens="2-3" string="Michael Hannon" id_sentence="25" />
        <mention ids_tokens="15" string="he" id_sentence="25" />
        <mention ids_tokens="1" string="He" id_sentence="26" />
        <mention ids_tokens="1" string="He" id_sentence="38" />
        <mention ids_tokens="23" string="Hannon" id_sentence="40" />
        <mention ids_tokens="1" string="He" id_sentence="41" />
        <mention ids_tokens="34" string="Hannon" id_sentence="42" />
        <mention ids_tokens="2" string="I" id_sentence="43" />
        <mention ids_tokens="1" string="He" id_sentence="44" />
        <mention ids_tokens="1" string="He" id_sentence="45" />
        <mention ids_tokens="21" string="his" id_sentence="45" />
      </mentions>
    </coreference>
    <coreference id="44" type="LIST">
      <referenced ids_tokens="20-21-22-23-24-25" string="Jackson 's and Hill 's sedan" id_sentence="27" />
      <mentions>
        <mention ids_tokens="26-28" string="Jackson and Hill" id_sentence="40" />
      </mentions>
    </coreference>
    <coreference id="46" type="PROPER">
      <referenced ids_tokens="7" string="Lawyer" id_sentence="30" />
      <mentions>
        <mention ids_tokens="29-30" string="the lawyer" id_sentence="39" />
      </mentions>
    </coreference>
    <coreference id="47" type="NOMINAL">
      <referenced ids_tokens="11-12-13-14-15-16-17-18-19-20-21" string="a nonprofit group that investigates citizen complaints against law enforcement agencies" id_sentence="30" />
      <mentions>
        <mention ids_tokens="1-2" string="The group" id_sentence="32" />
      </mentions>
    </coreference>
    <coreference id="49" type="PROPER">
      <referenced ids_tokens="1-2-3" string="Spokesman David Lynn" id_sentence="31" />
      <mentions>
        <mention ids_tokens="14" string="his" id_sentence="32" />
        <mention ids_tokens="1" string="He" id_sentence="33" />
        <mention ids_tokens="5" string="his" id_sentence="33" />
      </mentions>
    </coreference>
    <coreference id="50" type="NOMINAL">
      <referenced ids_tokens="11-12" string="the car" id_sentence="31" />
      <mentions>
        <mention ids_tokens="21" string="it" id_sentence="41" />
      </mentions>
    </coreference>
    <coreference id="51" type="NOMINAL">
      <referenced ids_tokens="12-13-14-15" string="obscenities in his conversation" id_sentence="32" />
      <mentions>
        <mention ids_tokens="19" string="obscenities" id_sentence="37" />
      </mentions>
    </coreference>
    <coreference id="52" type="NOMINAL">
      <referenced ids_tokens="9-10-11-12-13" string="a Jan. 25 court appearance" id_sentence="33" />
      <mentions>
        <mention ids_tokens="44-45" string="their appearance" id_sentence="39" />
      </mentions>
    </coreference>
  </coreferences>
</document>
