<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="WSJ910107-0139">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>Thus began another chapter in one of medicine&amp;apost;s most bizarre mysteries, a tale of sick sheep and mad cows, cannibals and Pennsylvanians, ancient life forms and a cat named Max.</content>
      <tokens>
        <token id="1" string="Thus" lemma="thus" stem="thu" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="began" lemma="begin" stem="began" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="another" lemma="another" stem="anoth" pos="DT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="chapter" lemma="chapter" stem="chapter" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="medicine" lemma="medicine" stem="medicin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="most" lemma="most" stem="most" pos="RBS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="bizarre" lemma="bizarre" stem="bizarr" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="mysteries" lemma="mystery" stem="mysteri" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="tale" lemma="tale" stem="tale" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="sick" lemma="sick" stem="sick" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="sheep" lemma="sheep" stem="sheep" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="mad" lemma="mad" stem="mad" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="cows" lemma="cow" stem="cow" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="cannibals" lemma="cannibal" stem="cannib" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="Pennsylvanians" lemma="pennsylvanian" stem="pennsylvanian" pos="NNS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="26" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="ancient" lemma="ancient" stem="ancient" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="28" string="life" lemma="life" stem="life" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="29" string="forms" lemma="form" stem="form" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="30" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="cat" lemma="cat" stem="cat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="named" lemma="name" stem="name" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="Max" lemma="Max" stem="max" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="35" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (ADVP (RB Thus)) (VP (VBD began)) (NP (NP (DT another) (NN chapter)) (PP (IN in) (NP (NP (NP (CD one)) (PP (IN of) (NP (NP (NN medicine) (POS 's)) (ADJP (RBS most) (JJ bizarre)) (NNS mysteries)))) (, ,) (NP (NP (DT a) (NN tale)) (PP (IN of) (NP (JJ sick) (NN sheep)))) (CC and) (NP (NP (JJ mad) (NNS cows) (, ,) (NNS cannibals) (CC and) (NNS Pennsylvanians)) (, ,) (NP (JJ ancient) (NN life) (NNS forms)) (CC and) (NP (DT a) (NN cat))))) (VP (VBN named) (NP (NNP Max)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="mad cows , cannibals and Pennsylvanians" type="NP">
          <tokens>
            <token id="20" string="mad" />
            <token id="21" string="cows" />
            <token id="22" string="," />
            <token id="23" string="cannibals" />
            <token id="24" string="and" />
            <token id="25" string="Pennsylvanians" />
          </tokens>
        </chunking>
        <chunking id="2" string="Max" type="NP">
          <tokens>
            <token id="34" string="Max" />
          </tokens>
        </chunking>
        <chunking id="3" string="another chapter" type="NP">
          <tokens>
            <token id="3" string="another" />
            <token id="4" string="chapter" />
          </tokens>
        </chunking>
        <chunking id="4" string="began" type="VP">
          <tokens>
            <token id="2" string="began" />
          </tokens>
        </chunking>
        <chunking id="5" string="one" type="NP">
          <tokens>
            <token id="6" string="one" />
          </tokens>
        </chunking>
        <chunking id="6" string="sick sheep" type="NP">
          <tokens>
            <token id="17" string="sick" />
            <token id="18" string="sheep" />
          </tokens>
        </chunking>
        <chunking id="7" string="ancient life forms" type="NP">
          <tokens>
            <token id="27" string="ancient" />
            <token id="28" string="life" />
            <token id="29" string="forms" />
          </tokens>
        </chunking>
        <chunking id="8" string="one of medicine 's most bizarre mysteries" type="NP">
          <tokens>
            <token id="6" string="one" />
            <token id="7" string="of" />
            <token id="8" string="medicine" />
            <token id="9" string="'s" />
            <token id="10" string="most" />
            <token id="11" string="bizarre" />
            <token id="12" string="mysteries" />
          </tokens>
        </chunking>
        <chunking id="9" string="another chapter in one of medicine 's most bizarre mysteries , a tale of sick sheep and mad cows , cannibals and Pennsylvanians , ancient life forms and a cat named Max" type="NP">
          <tokens>
            <token id="3" string="another" />
            <token id="4" string="chapter" />
            <token id="5" string="in" />
            <token id="6" string="one" />
            <token id="7" string="of" />
            <token id="8" string="medicine" />
            <token id="9" string="'s" />
            <token id="10" string="most" />
            <token id="11" string="bizarre" />
            <token id="12" string="mysteries" />
            <token id="13" string="," />
            <token id="14" string="a" />
            <token id="15" string="tale" />
            <token id="16" string="of" />
            <token id="17" string="sick" />
            <token id="18" string="sheep" />
            <token id="19" string="and" />
            <token id="20" string="mad" />
            <token id="21" string="cows" />
            <token id="22" string="," />
            <token id="23" string="cannibals" />
            <token id="24" string="and" />
            <token id="25" string="Pennsylvanians" />
            <token id="26" string="," />
            <token id="27" string="ancient" />
            <token id="28" string="life" />
            <token id="29" string="forms" />
            <token id="30" string="and" />
            <token id="31" string="a" />
            <token id="32" string="cat" />
            <token id="33" string="named" />
            <token id="34" string="Max" />
          </tokens>
        </chunking>
        <chunking id="10" string="medicine 's most bizarre mysteries" type="NP">
          <tokens>
            <token id="8" string="medicine" />
            <token id="9" string="'s" />
            <token id="10" string="most" />
            <token id="11" string="bizarre" />
            <token id="12" string="mysteries" />
          </tokens>
        </chunking>
        <chunking id="11" string="a tale of sick sheep" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="tale" />
            <token id="16" string="of" />
            <token id="17" string="sick" />
            <token id="18" string="sheep" />
          </tokens>
        </chunking>
        <chunking id="12" string="a cat" type="NP">
          <tokens>
            <token id="31" string="a" />
            <token id="32" string="cat" />
          </tokens>
        </chunking>
        <chunking id="13" string="medicine 's" type="NP">
          <tokens>
            <token id="8" string="medicine" />
            <token id="9" string="'s" />
          </tokens>
        </chunking>
        <chunking id="14" string="mad cows , cannibals and Pennsylvanians , ancient life forms and a cat" type="NP">
          <tokens>
            <token id="20" string="mad" />
            <token id="21" string="cows" />
            <token id="22" string="," />
            <token id="23" string="cannibals" />
            <token id="24" string="and" />
            <token id="25" string="Pennsylvanians" />
            <token id="26" string="," />
            <token id="27" string="ancient" />
            <token id="28" string="life" />
            <token id="29" string="forms" />
            <token id="30" string="and" />
            <token id="31" string="a" />
            <token id="32" string="cat" />
          </tokens>
        </chunking>
        <chunking id="15" string="named Max" type="VP">
          <tokens>
            <token id="33" string="named" />
            <token id="34" string="Max" />
          </tokens>
        </chunking>
        <chunking id="16" string="a tale" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="tale" />
          </tokens>
        </chunking>
        <chunking id="17" string="one of medicine 's most bizarre mysteries , a tale of sick sheep and mad cows , cannibals and Pennsylvanians , ancient life forms and a cat" type="NP">
          <tokens>
            <token id="6" string="one" />
            <token id="7" string="of" />
            <token id="8" string="medicine" />
            <token id="9" string="'s" />
            <token id="10" string="most" />
            <token id="11" string="bizarre" />
            <token id="12" string="mysteries" />
            <token id="13" string="," />
            <token id="14" string="a" />
            <token id="15" string="tale" />
            <token id="16" string="of" />
            <token id="17" string="sick" />
            <token id="18" string="sheep" />
            <token id="19" string="and" />
            <token id="20" string="mad" />
            <token id="21" string="cows" />
            <token id="22" string="," />
            <token id="23" string="cannibals" />
            <token id="24" string="and" />
            <token id="25" string="Pennsylvanians" />
            <token id="26" string="," />
            <token id="27" string="ancient" />
            <token id="28" string="life" />
            <token id="29" string="forms" />
            <token id="30" string="and" />
            <token id="31" string="a" />
            <token id="32" string="cat" />
          </tokens>
        </chunking>
        <chunking id="18" string="most bizarre" type="ADJP">
          <tokens>
            <token id="10" string="most" />
            <token id="11" string="bizarre" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="2">began</governor>
          <dependent id="1">Thus</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">began</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">chapter</governor>
          <dependent id="3">another</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="2">began</governor>
          <dependent id="4">chapter</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">one</governor>
          <dependent id="5">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">chapter</governor>
          <dependent id="6">one</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">mysteries</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="12">mysteries</governor>
          <dependent id="8">medicine</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">medicine</governor>
          <dependent id="9">'s</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">bizarre</governor>
          <dependent id="10">most</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">mysteries</governor>
          <dependent id="11">bizarre</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">one</governor>
          <dependent id="12">mysteries</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">tale</governor>
          <dependent id="14">a</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">one</governor>
          <dependent id="15">tale</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">sheep</governor>
          <dependent id="16">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">sheep</governor>
          <dependent id="17">sick</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">tale</governor>
          <dependent id="18">sheep</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">one</governor>
          <dependent id="19">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">cows</governor>
          <dependent id="20">mad</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">one</governor>
          <dependent id="21">cows</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="21">cows</governor>
          <dependent id="23">cannibals</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="21">cows</governor>
          <dependent id="24">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="21">cows</governor>
          <dependent id="25">Pennsylvanians</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="29">forms</governor>
          <dependent id="27">ancient</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="29">forms</governor>
          <dependent id="28">life</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="21">cows</governor>
          <dependent id="29">forms</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="21">cows</governor>
          <dependent id="30">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="32">cat</governor>
          <dependent id="31">a</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="21">cows</governor>
          <dependent id="32">cat</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="4">chapter</governor>
          <dependent id="33">named</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="33">named</governor>
          <dependent id="34">Max</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Max" type="PERSON" score="0.0">
          <tokens>
            <token id="34" string="Max" />
          </tokens>
        </entity>
        <entity id="2" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="6" string="one" />
          </tokens>
        </entity>
        <entity id="3" string="Pennsylvanians" type="MISC" score="0.0">
          <tokens>
            <token id="25" string="Pennsylvanians" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>The plot revolves around a family of brain diseases, probably variations of a single disorder, called spongiform encephalopathy.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="plot" lemma="plot" stem="plot" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="revolves" lemma="revolve" stem="revolv" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="around" lemma="around" stem="around" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="family" lemma="family" stem="famili" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="brain" lemma="brain" stem="brain" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="diseases" lemma="disease" stem="diseas" pos="NNS" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="probably" lemma="probably" stem="probabl" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="variations" lemma="variation" stem="variat" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="single" lemma="single" stem="singl" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="disorder" lemma="disorder" stem="disord" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="called" lemma="call" stem="call" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="spongiform" lemma="spongiform" stem="spongiform" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="encephalopathy" lemma="encephalopathy" stem="encephalopathi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN plot)) (VP (VBZ revolves) (PP (IN around) (NP (NP (NP (DT a) (NN family)) (PP (IN of) (NP (NN brain) (NNS diseases)))) (, ,) (ADVP (RB probably)) (NP (NP (NNS variations)) (PP (IN of) (NP (DT a) (JJ single) (NN disorder)))))) (, ,) (VP (VBN called) (NP (JJ spongiform) (NN encephalopathy)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a family of brain diseases" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="family" />
            <token id="7" string="of" />
            <token id="8" string="brain" />
            <token id="9" string="diseases" />
          </tokens>
        </chunking>
        <chunking id="2" string="a family" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="family" />
          </tokens>
        </chunking>
        <chunking id="3" string="The plot" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="plot" />
          </tokens>
        </chunking>
        <chunking id="4" string="spongiform encephalopathy" type="NP">
          <tokens>
            <token id="19" string="spongiform" />
            <token id="20" string="encephalopathy" />
          </tokens>
        </chunking>
        <chunking id="5" string="a single disorder" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="single" />
            <token id="16" string="disorder" />
          </tokens>
        </chunking>
        <chunking id="6" string="brain diseases" type="NP">
          <tokens>
            <token id="8" string="brain" />
            <token id="9" string="diseases" />
          </tokens>
        </chunking>
        <chunking id="7" string="called spongiform encephalopathy" type="VP">
          <tokens>
            <token id="18" string="called" />
            <token id="19" string="spongiform" />
            <token id="20" string="encephalopathy" />
          </tokens>
        </chunking>
        <chunking id="8" string="a family of brain diseases , probably variations of a single disorder" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="family" />
            <token id="7" string="of" />
            <token id="8" string="brain" />
            <token id="9" string="diseases" />
            <token id="10" string="," />
            <token id="11" string="probably" />
            <token id="12" string="variations" />
            <token id="13" string="of" />
            <token id="14" string="a" />
            <token id="15" string="single" />
            <token id="16" string="disorder" />
          </tokens>
        </chunking>
        <chunking id="9" string="variations" type="NP">
          <tokens>
            <token id="12" string="variations" />
          </tokens>
        </chunking>
        <chunking id="10" string="revolves around a family of brain diseases , probably variations of a single disorder , called spongiform encephalopathy" type="VP">
          <tokens>
            <token id="3" string="revolves" />
            <token id="4" string="around" />
            <token id="5" string="a" />
            <token id="6" string="family" />
            <token id="7" string="of" />
            <token id="8" string="brain" />
            <token id="9" string="diseases" />
            <token id="10" string="," />
            <token id="11" string="probably" />
            <token id="12" string="variations" />
            <token id="13" string="of" />
            <token id="14" string="a" />
            <token id="15" string="single" />
            <token id="16" string="disorder" />
            <token id="17" string="," />
            <token id="18" string="called" />
            <token id="19" string="spongiform" />
            <token id="20" string="encephalopathy" />
          </tokens>
        </chunking>
        <chunking id="11" string="variations of a single disorder" type="NP">
          <tokens>
            <token id="12" string="variations" />
            <token id="13" string="of" />
            <token id="14" string="a" />
            <token id="15" string="single" />
            <token id="16" string="disorder" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">plot</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">revolves</governor>
          <dependent id="2">plot</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">revolves</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">family</governor>
          <dependent id="4">around</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">family</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">revolves</governor>
          <dependent id="6">family</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">diseases</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">diseases</governor>
          <dependent id="8">brain</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">family</governor>
          <dependent id="9">diseases</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">variations</governor>
          <dependent id="11">probably</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="6">family</governor>
          <dependent id="12">variations</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">disorder</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">disorder</governor>
          <dependent id="14">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">disorder</governor>
          <dependent id="15">single</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">variations</governor>
          <dependent id="16">disorder</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="3">revolves</governor>
          <dependent id="18">called</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">encephalopathy</governor>
          <dependent id="19">spongiform</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">called</governor>
          <dependent id="20">encephalopathy</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="diseases" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="9" string="diseases" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="false">
      <content>It is infectious, invariably fatal and as insidious as termites, sometimes eating away brain cells for years without detection before a critical mass is spongified.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="infectious" lemma="infectious" stem="infecti" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="invariably" lemma="invariably" stem="invari" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="fatal" lemma="fatal" stem="fatal" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="insidious" lemma="insidious" stem="insidi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="termites" lemma="termite" stem="termit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="sometimes" lemma="sometimes" stem="sometim" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="eating" lemma="eat" stem="eat" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="away" lemma="away" stem="awai" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="brain" lemma="brain" stem="brain" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="cells" lemma="cell" stem="cell" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="20" string="without" lemma="without" stem="without" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="detection" lemma="detection" stem="detect" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="before" lemma="before" stem="befor" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="critical" lemma="critical" stem="critic" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="mass" lemma="mass" stem="mass" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="spongified" lemma="spongify" stem="spongifi" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP It)) (VP (VBZ is) (ADJP (ADJP (ADJP (JJ infectious)) (, ,) (ADJP (RB invariably) (JJ fatal)) (CC and) (ADJP (IN as) (JJ insidious))) (PP (IN as) (NP (NNS termites)))) (, ,) (S (ADVP (RB sometimes)) (VP (VBG eating) (PRT (RB away)) (NP (NP (NN brain) (NNS cells)) (PP (IN for) (NP (NP (NNS years)) (PP (IN without) (NP (NN detection)))))) (SBAR (IN before) (S (NP (DT a) (JJ critical) (NN mass)) (VP (VBZ is) (VP (VBN spongified)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="infectious" type="ADJP">
          <tokens>
            <token id="3" string="infectious" />
          </tokens>
        </chunking>
        <chunking id="2" string="detection" type="NP">
          <tokens>
            <token id="21" string="detection" />
          </tokens>
        </chunking>
        <chunking id="3" string="as insidious" type="ADJP">
          <tokens>
            <token id="8" string="as" />
            <token id="9" string="insidious" />
          </tokens>
        </chunking>
        <chunking id="4" string="spongified" type="VP">
          <tokens>
            <token id="27" string="spongified" />
          </tokens>
        </chunking>
        <chunking id="5" string="brain cells for years without detection" type="NP">
          <tokens>
            <token id="16" string="brain" />
            <token id="17" string="cells" />
            <token id="18" string="for" />
            <token id="19" string="years" />
            <token id="20" string="without" />
            <token id="21" string="detection" />
          </tokens>
        </chunking>
        <chunking id="6" string="is infectious , invariably fatal and as insidious as termites , sometimes eating away brain cells for years without detection before a critical mass is spongified" type="VP">
          <tokens>
            <token id="2" string="is" />
            <token id="3" string="infectious" />
            <token id="4" string="," />
            <token id="5" string="invariably" />
            <token id="6" string="fatal" />
            <token id="7" string="and" />
            <token id="8" string="as" />
            <token id="9" string="insidious" />
            <token id="10" string="as" />
            <token id="11" string="termites" />
            <token id="12" string="," />
            <token id="13" string="sometimes" />
            <token id="14" string="eating" />
            <token id="15" string="away" />
            <token id="16" string="brain" />
            <token id="17" string="cells" />
            <token id="18" string="for" />
            <token id="19" string="years" />
            <token id="20" string="without" />
            <token id="21" string="detection" />
            <token id="22" string="before" />
            <token id="23" string="a" />
            <token id="24" string="critical" />
            <token id="25" string="mass" />
            <token id="26" string="is" />
            <token id="27" string="spongified" />
          </tokens>
        </chunking>
        <chunking id="7" string="infectious , invariably fatal and as insidious" type="ADJP">
          <tokens>
            <token id="3" string="infectious" />
            <token id="4" string="," />
            <token id="5" string="invariably" />
            <token id="6" string="fatal" />
            <token id="7" string="and" />
            <token id="8" string="as" />
            <token id="9" string="insidious" />
          </tokens>
        </chunking>
        <chunking id="8" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="9" string="eating away brain cells for years without detection before a critical mass is spongified" type="VP">
          <tokens>
            <token id="14" string="eating" />
            <token id="15" string="away" />
            <token id="16" string="brain" />
            <token id="17" string="cells" />
            <token id="18" string="for" />
            <token id="19" string="years" />
            <token id="20" string="without" />
            <token id="21" string="detection" />
            <token id="22" string="before" />
            <token id="23" string="a" />
            <token id="24" string="critical" />
            <token id="25" string="mass" />
            <token id="26" string="is" />
            <token id="27" string="spongified" />
          </tokens>
        </chunking>
        <chunking id="10" string="years without detection" type="NP">
          <tokens>
            <token id="19" string="years" />
            <token id="20" string="without" />
            <token id="21" string="detection" />
          </tokens>
        </chunking>
        <chunking id="11" string="years" type="NP">
          <tokens>
            <token id="19" string="years" />
          </tokens>
        </chunking>
        <chunking id="12" string="a critical mass" type="NP">
          <tokens>
            <token id="23" string="a" />
            <token id="24" string="critical" />
            <token id="25" string="mass" />
          </tokens>
        </chunking>
        <chunking id="13" string="is spongified" type="VP">
          <tokens>
            <token id="26" string="is" />
            <token id="27" string="spongified" />
          </tokens>
        </chunking>
        <chunking id="14" string="before a critical mass is spongified" type="SBAR">
          <tokens>
            <token id="22" string="before" />
            <token id="23" string="a" />
            <token id="24" string="critical" />
            <token id="25" string="mass" />
            <token id="26" string="is" />
            <token id="27" string="spongified" />
          </tokens>
        </chunking>
        <chunking id="15" string="infectious , invariably fatal and as insidious as termites" type="ADJP">
          <tokens>
            <token id="3" string="infectious" />
            <token id="4" string="," />
            <token id="5" string="invariably" />
            <token id="6" string="fatal" />
            <token id="7" string="and" />
            <token id="8" string="as" />
            <token id="9" string="insidious" />
            <token id="10" string="as" />
            <token id="11" string="termites" />
          </tokens>
        </chunking>
        <chunking id="16" string="termites" type="NP">
          <tokens>
            <token id="11" string="termites" />
          </tokens>
        </chunking>
        <chunking id="17" string="brain cells" type="NP">
          <tokens>
            <token id="16" string="brain" />
            <token id="17" string="cells" />
          </tokens>
        </chunking>
        <chunking id="18" string="invariably fatal" type="ADJP">
          <tokens>
            <token id="5" string="invariably" />
            <token id="6" string="fatal" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">infectious</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="3">infectious</governor>
          <dependent id="2">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">infectious</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">fatal</governor>
          <dependent id="5">invariably</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">infectious</governor>
          <dependent id="6">fatal</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">infectious</governor>
          <dependent id="7">and</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="9">insidious</governor>
          <dependent id="8">as</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">infectious</governor>
          <dependent id="9">insidious</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">termites</governor>
          <dependent id="10">as</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">infectious</governor>
          <dependent id="11">termites</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">eating</governor>
          <dependent id="13">sometimes</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">infectious</governor>
          <dependent id="14">eating</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="14">eating</governor>
          <dependent id="15">away</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">cells</governor>
          <dependent id="16">brain</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">eating</governor>
          <dependent id="17">cells</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">years</governor>
          <dependent id="18">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">cells</governor>
          <dependent id="19">years</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">detection</governor>
          <dependent id="20">without</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">years</governor>
          <dependent id="21">detection</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="27">spongified</governor>
          <dependent id="22">before</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">mass</governor>
          <dependent id="23">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">mass</governor>
          <dependent id="24">critical</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="27">spongified</governor>
          <dependent id="25">mass</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="27">spongified</governor>
          <dependent id="26">is</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="14">eating</governor>
          <dependent id="27">spongified</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="years" type="DURATION" score="0.0">
          <tokens>
            <token id="19" string="years" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="false">
      <content>Then, over a few months, motor control buckles and cognition crumbles.</content>
      <tokens>
        <token id="1" string="Then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="over" lemma="over" stem="over" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="5" string="few" lemma="few" stem="few" pos="JJ" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="6" string="months" lemma="month" stem="month" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="motor" lemma="motor" stem="motor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="control" lemma="control" stem="control" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="buckles" lemma="buckle" stem="buckl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="cognition" lemma="cognition" stem="cognit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="crumbles" lemma="crumble" stem="crumbl" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Then)) (, ,) (PP (IN over) (NP (DT a) (JJ few) (NNS months))) (, ,) (NP (NN motor) (NN control) (NNS buckles) (CC and) (NN cognition)) (VP (VBZ crumbles)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="crumbles" type="VP">
          <tokens>
            <token id="13" string="crumbles" />
          </tokens>
        </chunking>
        <chunking id="2" string="motor control buckles and cognition" type="NP">
          <tokens>
            <token id="8" string="motor" />
            <token id="9" string="control" />
            <token id="10" string="buckles" />
            <token id="11" string="and" />
            <token id="12" string="cognition" />
          </tokens>
        </chunking>
        <chunking id="3" string="a few months" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="few" />
            <token id="6" string="months" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="13">crumbles</governor>
          <dependent id="1">Then</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">months</governor>
          <dependent id="3">over</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">months</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">months</governor>
          <dependent id="5">few</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">crumbles</governor>
          <dependent id="6">months</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">buckles</governor>
          <dependent id="8">motor</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">buckles</governor>
          <dependent id="9">control</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">crumbles</governor>
          <dependent id="10">buckles</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">buckles</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">buckles</governor>
          <dependent id="12">cognition</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">crumbles</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="a few months" type="DURATION" score="0.0">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="few" />
            <token id="6" string="months" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="5" has_coreference="false">
      <content>Victims then die quickly, usually within a year.</content>
      <tokens>
        <token id="1" string="Victims" lemma="victim" stem="victim" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="die" lemma="die" stem="die" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="quickly" lemma="quickly" stem="quickli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="usually" lemma="usually" stem="usual" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="within" lemma="within" stem="within" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="9" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNS Victims)) (ADVP (RB then)) (VP (VB die) (ADVP (RB quickly)) (, ,) (ADVP (RB usually)) (PP (IN within) (NP (DT a) (NN year)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Victims" type="NP">
          <tokens>
            <token id="1" string="Victims" />
          </tokens>
        </chunking>
        <chunking id="2" string="die quickly , usually within a year" type="VP">
          <tokens>
            <token id="3" string="die" />
            <token id="4" string="quickly" />
            <token id="5" string="," />
            <token id="6" string="usually" />
            <token id="7" string="within" />
            <token id="8" string="a" />
            <token id="9" string="year" />
          </tokens>
        </chunking>
        <chunking id="3" string="a year" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="year" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">die</governor>
          <dependent id="1">Victims</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">die</governor>
          <dependent id="2">then</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">die</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">die</governor>
          <dependent id="4">quickly</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">die</governor>
          <dependent id="6">usually</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">year</governor>
          <dependent id="7">within</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">year</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">die</governor>
          <dependent id="9">year</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="a year" type="DURATION" score="0.0">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="year" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>Now, after decades of detective work, medical sleuths appear to be closing in on the molecular culprits behind the disease.</content>
      <tokens>
        <token id="1" string="Now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="decades" lemma="decade" stem="decad" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="detective" lemma="detective" stem="detect" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="work" lemma="work" stem="work" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="medical" lemma="medical" stem="medic" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="sleuths" lemma="sleuth" stem="sleuth" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="appear" lemma="appear" stem="appear" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="closing" lemma="close" stem="close" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="molecular" lemma="molecular" stem="molecular" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="culprits" lemma="culprit" stem="culprit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="behind" lemma="behind" stem="behind" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="disease" lemma="disease" stem="diseas" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="true" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Now)) (, ,) (PP (IN after) (NP (NP (NNS decades)) (PP (IN of) (NP (NN detective) (NN work))))) (, ,) (NP (JJ medical) (NNS sleuths)) (VP (VBP appear) (S (VP (TO to) (VP (VB be) (VP (VBG closing) (PP (IN in) (IN on) (NP (NP (DT the) (JJ molecular) (NNS culprits)) (PP (IN behind) (NP (DT the) (NN disease)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="to be closing in on the molecular culprits behind the disease" type="VP">
          <tokens>
            <token id="12" string="to" />
            <token id="13" string="be" />
            <token id="14" string="closing" />
            <token id="15" string="in" />
            <token id="16" string="on" />
            <token id="17" string="the" />
            <token id="18" string="molecular" />
            <token id="19" string="culprits" />
            <token id="20" string="behind" />
            <token id="21" string="the" />
            <token id="22" string="disease" />
          </tokens>
        </chunking>
        <chunking id="2" string="the disease" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="disease" />
          </tokens>
        </chunking>
        <chunking id="3" string="appear to be closing in on the molecular culprits behind the disease" type="VP">
          <tokens>
            <token id="11" string="appear" />
            <token id="12" string="to" />
            <token id="13" string="be" />
            <token id="14" string="closing" />
            <token id="15" string="in" />
            <token id="16" string="on" />
            <token id="17" string="the" />
            <token id="18" string="molecular" />
            <token id="19" string="culprits" />
            <token id="20" string="behind" />
            <token id="21" string="the" />
            <token id="22" string="disease" />
          </tokens>
        </chunking>
        <chunking id="4" string="the molecular culprits behind the disease" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="molecular" />
            <token id="19" string="culprits" />
            <token id="20" string="behind" />
            <token id="21" string="the" />
            <token id="22" string="disease" />
          </tokens>
        </chunking>
        <chunking id="5" string="the molecular culprits" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="molecular" />
            <token id="19" string="culprits" />
          </tokens>
        </chunking>
        <chunking id="6" string="closing in on the molecular culprits behind the disease" type="VP">
          <tokens>
            <token id="14" string="closing" />
            <token id="15" string="in" />
            <token id="16" string="on" />
            <token id="17" string="the" />
            <token id="18" string="molecular" />
            <token id="19" string="culprits" />
            <token id="20" string="behind" />
            <token id="21" string="the" />
            <token id="22" string="disease" />
          </tokens>
        </chunking>
        <chunking id="7" string="medical sleuths" type="NP">
          <tokens>
            <token id="9" string="medical" />
            <token id="10" string="sleuths" />
          </tokens>
        </chunking>
        <chunking id="8" string="decades of detective work" type="NP">
          <tokens>
            <token id="4" string="decades" />
            <token id="5" string="of" />
            <token id="6" string="detective" />
            <token id="7" string="work" />
          </tokens>
        </chunking>
        <chunking id="9" string="be closing in on the molecular culprits behind the disease" type="VP">
          <tokens>
            <token id="13" string="be" />
            <token id="14" string="closing" />
            <token id="15" string="in" />
            <token id="16" string="on" />
            <token id="17" string="the" />
            <token id="18" string="molecular" />
            <token id="19" string="culprits" />
            <token id="20" string="behind" />
            <token id="21" string="the" />
            <token id="22" string="disease" />
          </tokens>
        </chunking>
        <chunking id="10" string="decades" type="NP">
          <tokens>
            <token id="4" string="decades" />
          </tokens>
        </chunking>
        <chunking id="11" string="detective work" type="NP">
          <tokens>
            <token id="6" string="detective" />
            <token id="7" string="work" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="11">appear</governor>
          <dependent id="1">Now</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">decades</governor>
          <dependent id="3">after</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">appear</governor>
          <dependent id="4">decades</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">work</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">work</governor>
          <dependent id="6">detective</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">decades</governor>
          <dependent id="7">work</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">sleuths</governor>
          <dependent id="9">medical</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">appear</governor>
          <dependent id="10">sleuths</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">appear</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">closing</governor>
          <dependent id="12">to</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="14">closing</governor>
          <dependent id="13">be</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="11">appear</governor>
          <dependent id="14">closing</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">culprits</governor>
          <dependent id="15">in</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">culprits</governor>
          <dependent id="16">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">culprits</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">culprits</governor>
          <dependent id="18">molecular</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">closing</governor>
          <dependent id="19">culprits</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">disease</governor>
          <dependent id="20">behind</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">disease</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">culprits</governor>
          <dependent id="22">disease</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Now" type="DATE" score="0.0">
          <tokens>
            <token id="1" string="Now" />
          </tokens>
        </entity>
        <entity id="2" string="disease" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="22" string="disease" />
          </tokens>
        </entity>
        <entity id="3" string="decades" type="DURATION" score="0.0">
          <tokens>
            <token id="4" string="decades" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>Their dogged pursuit won&amp;apost;t nail a public-health enemy No. 1 -- the disease is rare -- but it may pay off in a big way because the findings could shed light on more common killers, including Alzheimer&amp;apost;s disease.</content>
      <tokens>
        <token id="1" string="Their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="2" string="dogged" lemma="dogged" stem="dog" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="pursuit" lemma="pursuit" stem="pursuit" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="wo" lemma="will" stem="wo" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="nail" lemma="nail" stem="nail" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="public-health" lemma="public-health" stem="public-health" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="enemy" lemma="enemy" stem="enemi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="No." lemma="no." stem="no." pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="1" lemma="1" stem="1" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="12" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="disease" lemma="disease" stem="diseas" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="15" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="rare" lemma="rare" stem="rare" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="may" lemma="may" stem="mai" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="pay" lemma="pay" stem="pai" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="off" lemma="off" stem="off" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="big" lemma="big" stem="big" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="way" lemma="way" stem="wai" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="29" string="findings" lemma="finding" stem="find" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="30" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="shed" lemma="shed" stem="shed" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="light" lemma="light" stem="light" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="more" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="common" lemma="common" stem="common" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="killers" lemma="killer" stem="killer" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="including" lemma="include" stem="includ" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="Alzheimer" lemma="alzheimer" stem="alzheimer" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="true" is_refers="false" />
        <token id="40" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" ner="CAUSE_OF_DEATH" is_referenced="true" is_refers="false" />
        <token id="41" string="disease" lemma="disease" stem="diseas" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="true" is_refers="false" />
        <token id="42" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP$ Their) (JJ dogged) (NN pursuit)) (VP (MD wo) (RB n't) (VP (VB nail) (NP (NP (DT a) (JJ public-health) (NN enemy)) (ADJP (NN No.) (CD 1)))))) (PRN (: --) (S (NP (DT the) (NN disease)) (VP (VBZ is) (ADJP (JJ rare)))) (: --)) (CC but) (S (NP (PRP it)) (VP (MD may) (VP (VB pay) (PRT (RP off)) (PP (IN in) (NP (DT a) (JJ big) (NN way))) (SBAR (IN because) (S (NP (DT the) (NNS findings)) (VP (MD could) (VP (VB shed) (NP (NN light)) (PP (IN on) (NP (NP (JJR more) (JJ common) (NNS killers)) (, ,) (PP (VBG including) (NP (NP (NN Alzheimer) (POS 's)) (NN disease)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a public-health enemy" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="public-health" />
            <token id="9" string="enemy" />
          </tokens>
        </chunking>
        <chunking id="2" string="Alzheimer 's" type="NP">
          <tokens>
            <token id="39" string="Alzheimer" />
            <token id="40" string="'s" />
          </tokens>
        </chunking>
        <chunking id="3" string="wo n't nail a public-health enemy No. 1" type="VP">
          <tokens>
            <token id="4" string="wo" />
            <token id="5" string="n't" />
            <token id="6" string="nail" />
            <token id="7" string="a" />
            <token id="8" string="public-health" />
            <token id="9" string="enemy" />
            <token id="10" string="No." />
            <token id="11" string="1" />
          </tokens>
        </chunking>
        <chunking id="4" string="nail a public-health enemy No. 1" type="VP">
          <tokens>
            <token id="6" string="nail" />
            <token id="7" string="a" />
            <token id="8" string="public-health" />
            <token id="9" string="enemy" />
            <token id="10" string="No." />
            <token id="11" string="1" />
          </tokens>
        </chunking>
        <chunking id="5" string="No. 1" type="ADJP">
          <tokens>
            <token id="10" string="No." />
            <token id="11" string="1" />
          </tokens>
        </chunking>
        <chunking id="6" string="the findings" type="NP">
          <tokens>
            <token id="28" string="the" />
            <token id="29" string="findings" />
          </tokens>
        </chunking>
        <chunking id="7" string="more common killers , including Alzheimer 's disease" type="NP">
          <tokens>
            <token id="34" string="more" />
            <token id="35" string="common" />
            <token id="36" string="killers" />
            <token id="37" string="," />
            <token id="38" string="including" />
            <token id="39" string="Alzheimer" />
            <token id="40" string="'s" />
            <token id="41" string="disease" />
          </tokens>
        </chunking>
        <chunking id="8" string="may pay off in a big way because the findings could shed light on more common killers , including Alzheimer 's disease" type="VP">
          <tokens>
            <token id="20" string="may" />
            <token id="21" string="pay" />
            <token id="22" string="off" />
            <token id="23" string="in" />
            <token id="24" string="a" />
            <token id="25" string="big" />
            <token id="26" string="way" />
            <token id="27" string="because" />
            <token id="28" string="the" />
            <token id="29" string="findings" />
            <token id="30" string="could" />
            <token id="31" string="shed" />
            <token id="32" string="light" />
            <token id="33" string="on" />
            <token id="34" string="more" />
            <token id="35" string="common" />
            <token id="36" string="killers" />
            <token id="37" string="," />
            <token id="38" string="including" />
            <token id="39" string="Alzheimer" />
            <token id="40" string="'s" />
            <token id="41" string="disease" />
          </tokens>
        </chunking>
        <chunking id="9" string="shed light on more common killers , including Alzheimer 's disease" type="VP">
          <tokens>
            <token id="31" string="shed" />
            <token id="32" string="light" />
            <token id="33" string="on" />
            <token id="34" string="more" />
            <token id="35" string="common" />
            <token id="36" string="killers" />
            <token id="37" string="," />
            <token id="38" string="including" />
            <token id="39" string="Alzheimer" />
            <token id="40" string="'s" />
            <token id="41" string="disease" />
          </tokens>
        </chunking>
        <chunking id="10" string="more common killers" type="NP">
          <tokens>
            <token id="34" string="more" />
            <token id="35" string="common" />
            <token id="36" string="killers" />
          </tokens>
        </chunking>
        <chunking id="11" string="pay off in a big way because the findings could shed light on more common killers , including Alzheimer 's disease" type="VP">
          <tokens>
            <token id="21" string="pay" />
            <token id="22" string="off" />
            <token id="23" string="in" />
            <token id="24" string="a" />
            <token id="25" string="big" />
            <token id="26" string="way" />
            <token id="27" string="because" />
            <token id="28" string="the" />
            <token id="29" string="findings" />
            <token id="30" string="could" />
            <token id="31" string="shed" />
            <token id="32" string="light" />
            <token id="33" string="on" />
            <token id="34" string="more" />
            <token id="35" string="common" />
            <token id="36" string="killers" />
            <token id="37" string="," />
            <token id="38" string="including" />
            <token id="39" string="Alzheimer" />
            <token id="40" string="'s" />
            <token id="41" string="disease" />
          </tokens>
        </chunking>
        <chunking id="12" string="it" type="NP">
          <tokens>
            <token id="19" string="it" />
          </tokens>
        </chunking>
        <chunking id="13" string="a public-health enemy No. 1" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="public-health" />
            <token id="9" string="enemy" />
            <token id="10" string="No." />
            <token id="11" string="1" />
          </tokens>
        </chunking>
        <chunking id="14" string="the disease" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="disease" />
          </tokens>
        </chunking>
        <chunking id="15" string="a big way" type="NP">
          <tokens>
            <token id="24" string="a" />
            <token id="25" string="big" />
            <token id="26" string="way" />
          </tokens>
        </chunking>
        <chunking id="16" string="is rare" type="VP">
          <tokens>
            <token id="15" string="is" />
            <token id="16" string="rare" />
          </tokens>
        </chunking>
        <chunking id="17" string="rare" type="ADJP">
          <tokens>
            <token id="16" string="rare" />
          </tokens>
        </chunking>
        <chunking id="18" string="because the findings could shed light on more common killers , including Alzheimer 's disease" type="SBAR">
          <tokens>
            <token id="27" string="because" />
            <token id="28" string="the" />
            <token id="29" string="findings" />
            <token id="30" string="could" />
            <token id="31" string="shed" />
            <token id="32" string="light" />
            <token id="33" string="on" />
            <token id="34" string="more" />
            <token id="35" string="common" />
            <token id="36" string="killers" />
            <token id="37" string="," />
            <token id="38" string="including" />
            <token id="39" string="Alzheimer" />
            <token id="40" string="'s" />
            <token id="41" string="disease" />
          </tokens>
        </chunking>
        <chunking id="19" string="could shed light on more common killers , including Alzheimer 's disease" type="VP">
          <tokens>
            <token id="30" string="could" />
            <token id="31" string="shed" />
            <token id="32" string="light" />
            <token id="33" string="on" />
            <token id="34" string="more" />
            <token id="35" string="common" />
            <token id="36" string="killers" />
            <token id="37" string="," />
            <token id="38" string="including" />
            <token id="39" string="Alzheimer" />
            <token id="40" string="'s" />
            <token id="41" string="disease" />
          </tokens>
        </chunking>
        <chunking id="20" string="light" type="NP">
          <tokens>
            <token id="32" string="light" />
          </tokens>
        </chunking>
        <chunking id="21" string="Alzheimer 's disease" type="NP">
          <tokens>
            <token id="39" string="Alzheimer" />
            <token id="40" string="'s" />
            <token id="41" string="disease" />
          </tokens>
        </chunking>
        <chunking id="22" string="Their dogged pursuit" type="NP">
          <tokens>
            <token id="1" string="Their" />
            <token id="2" string="dogged" />
            <token id="3" string="pursuit" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="3">pursuit</governor>
          <dependent id="1">Their</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">pursuit</governor>
          <dependent id="2">dogged</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">nail</governor>
          <dependent id="3">pursuit</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">nail</governor>
          <dependent id="4">wo</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="6">nail</governor>
          <dependent id="5">n't</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">nail</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">enemy</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">enemy</governor>
          <dependent id="8">public-health</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">nail</governor>
          <dependent id="9">enemy</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">enemy</governor>
          <dependent id="10">No.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">No.</governor>
          <dependent id="11">1</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">disease</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">rare</governor>
          <dependent id="14">disease</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="16">rare</governor>
          <dependent id="15">is</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="6">nail</governor>
          <dependent id="16">rare</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">nail</governor>
          <dependent id="18">but</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">pay</governor>
          <dependent id="19">it</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="21">pay</governor>
          <dependent id="20">may</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">nail</governor>
          <dependent id="21">pay</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="21">pay</governor>
          <dependent id="22">off</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">way</governor>
          <dependent id="23">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">way</governor>
          <dependent id="24">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">way</governor>
          <dependent id="25">big</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">pay</governor>
          <dependent id="26">way</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="31">shed</governor>
          <dependent id="27">because</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">findings</governor>
          <dependent id="28">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="31">shed</governor>
          <dependent id="29">findings</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="31">shed</governor>
          <dependent id="30">could</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="21">pay</governor>
          <dependent id="31">shed</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="31">shed</governor>
          <dependent id="32">light</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">killers</governor>
          <dependent id="33">on</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="36">killers</governor>
          <dependent id="34">more</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="36">killers</governor>
          <dependent id="35">common</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">shed</governor>
          <dependent id="36">killers</dependent>
        </dependency>
        <dependency type="case">
          <governor id="41">disease</governor>
          <dependent id="38">including</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="41">disease</governor>
          <dependent id="39">Alzheimer</dependent>
        </dependency>
        <dependency type="case">
          <governor id="39">Alzheimer</governor>
          <dependent id="40">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="36">killers</governor>
          <dependent id="41">disease</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1" type="NUMBER" score="0.0">
          <tokens>
            <token id="11" string="1" />
          </tokens>
        </entity>
        <entity id="2" string="disease" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="14" string="disease" />
          </tokens>
        </entity>
        <entity id="3" string="Alzheimer 's disease" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="39" string="Alzheimer" />
            <token id="40" string="'s" />
            <token id="41" string="disease" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>The work also promises basic science breakthroughs.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="work" lemma="work" stem="work" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="promises" lemma="promise" stem="promis" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="basic" lemma="basic" stem="basic" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="science" lemma="science" stem="scienc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="breakthroughs" lemma="breakthrough" stem="breakthrough" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN work)) (ADVP (RB also)) (VP (VBZ promises) (NP (JJ basic) (NN science) (NNS breakthroughs))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="The work" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="work" />
          </tokens>
        </chunking>
        <chunking id="2" string="promises basic science breakthroughs" type="VP">
          <tokens>
            <token id="4" string="promises" />
            <token id="5" string="basic" />
            <token id="6" string="science" />
            <token id="7" string="breakthroughs" />
          </tokens>
        </chunking>
        <chunking id="3" string="basic science breakthroughs" type="NP">
          <tokens>
            <token id="5" string="basic" />
            <token id="6" string="science" />
            <token id="7" string="breakthroughs" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">work</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">promises</governor>
          <dependent id="2">work</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">promises</governor>
          <dependent id="3">also</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">promises</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">breakthroughs</governor>
          <dependent id="5">basic</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">breakthroughs</governor>
          <dependent id="6">science</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">promises</governor>
          <dependent id="7">breakthroughs</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="9" has_coreference="false">
      <content>Spongiform research already has raised questions about a cornerstone of biology and spawned a Nobel Prize.</content>
      <tokens>
        <token id="1" string="Spongiform" lemma="Spongiform" stem="spongiform" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="research" lemma="research" stem="research" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="already" lemma="already" stem="alreadi" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="raised" lemma="raise" stem="rais" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="questions" lemma="question" stem="question" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="cornerstone" lemma="cornerstone" stem="cornerston" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="biology" lemma="biology" stem="biologi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="spawned" lemma="spawn" stem="spawn" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="Nobel" lemma="Nobel" stem="nobel" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="16" string="Prize" lemma="Prize" stem="prize" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Spongiform) (NN research)) (ADVP (RB already)) (VP (VP (VBZ has) (VP (VBN raised) (NP (NNS questions)) (PP (IN about) (NP (NP (DT a) (NN cornerstone)) (PP (IN of) (NP (NN biology))))))) (CC and) (VP (VBD spawned) (NP (DT a) (NNP Nobel) (NNP Prize)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="biology" type="NP">
          <tokens>
            <token id="11" string="biology" />
          </tokens>
        </chunking>
        <chunking id="2" string="a cornerstone" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="cornerstone" />
          </tokens>
        </chunking>
        <chunking id="3" string="has raised questions about a cornerstone of biology" type="VP">
          <tokens>
            <token id="4" string="has" />
            <token id="5" string="raised" />
            <token id="6" string="questions" />
            <token id="7" string="about" />
            <token id="8" string="a" />
            <token id="9" string="cornerstone" />
            <token id="10" string="of" />
            <token id="11" string="biology" />
          </tokens>
        </chunking>
        <chunking id="4" string="a cornerstone of biology" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="cornerstone" />
            <token id="10" string="of" />
            <token id="11" string="biology" />
          </tokens>
        </chunking>
        <chunking id="5" string="Spongiform research" type="NP">
          <tokens>
            <token id="1" string="Spongiform" />
            <token id="2" string="research" />
          </tokens>
        </chunking>
        <chunking id="6" string="a Nobel Prize" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="Nobel" />
            <token id="16" string="Prize" />
          </tokens>
        </chunking>
        <chunking id="7" string="questions" type="NP">
          <tokens>
            <token id="6" string="questions" />
          </tokens>
        </chunking>
        <chunking id="8" string="spawned a Nobel Prize" type="VP">
          <tokens>
            <token id="13" string="spawned" />
            <token id="14" string="a" />
            <token id="15" string="Nobel" />
            <token id="16" string="Prize" />
          </tokens>
        </chunking>
        <chunking id="9" string="raised questions about a cornerstone of biology" type="VP">
          <tokens>
            <token id="5" string="raised" />
            <token id="6" string="questions" />
            <token id="7" string="about" />
            <token id="8" string="a" />
            <token id="9" string="cornerstone" />
            <token id="10" string="of" />
            <token id="11" string="biology" />
          </tokens>
        </chunking>
        <chunking id="10" string="has raised questions about a cornerstone of biology and spawned a Nobel Prize" type="VP">
          <tokens>
            <token id="4" string="has" />
            <token id="5" string="raised" />
            <token id="6" string="questions" />
            <token id="7" string="about" />
            <token id="8" string="a" />
            <token id="9" string="cornerstone" />
            <token id="10" string="of" />
            <token id="11" string="biology" />
            <token id="12" string="and" />
            <token id="13" string="spawned" />
            <token id="14" string="a" />
            <token id="15" string="Nobel" />
            <token id="16" string="Prize" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">research</governor>
          <dependent id="1">Spongiform</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">raised</governor>
          <dependent id="2">research</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">raised</governor>
          <dependent id="3">already</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">raised</governor>
          <dependent id="4">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">raised</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">raised</governor>
          <dependent id="6">questions</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">cornerstone</governor>
          <dependent id="7">about</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">cornerstone</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">raised</governor>
          <dependent id="9">cornerstone</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">biology</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">cornerstone</governor>
          <dependent id="11">biology</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">raised</governor>
          <dependent id="12">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">raised</governor>
          <dependent id="13">spawned</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">Prize</governor>
          <dependent id="14">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Prize</governor>
          <dependent id="15">Nobel</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">spawned</governor>
          <dependent id="16">Prize</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Nobel Prize" type="MISC" score="0.0">
          <tokens>
            <token id="15" string="Nobel" />
            <token id="16" string="Prize" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>The uncanny nature of the disorder sometimes grips scientists with a kind of obsessive fascination, notes NIH researcher D. Carleton Gajdusek.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="uncanny" lemma="uncanny" stem="uncanni" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="nature" lemma="nature" stem="natur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="disorder" lemma="disorder" stem="disord" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="sometimes" lemma="sometimes" stem="sometim" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="grips" lemma="grip" stem="grip" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="scientists" lemma="scientist" stem="scientist" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="kind" lemma="kind" stem="kind" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="obsessive" lemma="obsessive" stem="obsess" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="fascination" lemma="fascination" stem="fascin" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="notes" lemma="note" stem="note" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="NIH" lemma="NIH" stem="nih" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="researcher" lemma="researcher" stem="research" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="D." lemma="D." stem="d." pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="21" string="Carleton" lemma="Carleton" stem="carleton" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="22" string="Gajdusek" lemma="Gajdusek" stem="gajdusek" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (JJ uncanny) (NN nature)) (PP (IN of) (NP (NP (DT the) (NN disorder)) (ADVP (RB sometimes)))) (NP (NP (NNS grips) (NNS scientists)) (PP (IN with) (NP (NP (DT a) (NN kind)) (PP (IN of) (NP (JJ obsessive) (NN fascination)))))) (, ,)) (VP (VBZ notes) (NP (NNP NIH) (NN researcher) (NNP D.) (NNP Carleton) (NNP Gajdusek))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="The uncanny nature of the disorder sometimes grips scientists with a kind of obsessive fascination ," type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="uncanny" />
            <token id="3" string="nature" />
            <token id="4" string="of" />
            <token id="5" string="the" />
            <token id="6" string="disorder" />
            <token id="7" string="sometimes" />
            <token id="8" string="grips" />
            <token id="9" string="scientists" />
            <token id="10" string="with" />
            <token id="11" string="a" />
            <token id="12" string="kind" />
            <token id="13" string="of" />
            <token id="14" string="obsessive" />
            <token id="15" string="fascination" />
            <token id="16" string="," />
          </tokens>
        </chunking>
        <chunking id="2" string="a kind of obsessive fascination" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="kind" />
            <token id="13" string="of" />
            <token id="14" string="obsessive" />
            <token id="15" string="fascination" />
          </tokens>
        </chunking>
        <chunking id="3" string="NIH researcher D. Carleton Gajdusek" type="NP">
          <tokens>
            <token id="18" string="NIH" />
            <token id="19" string="researcher" />
            <token id="20" string="D." />
            <token id="21" string="Carleton" />
            <token id="22" string="Gajdusek" />
          </tokens>
        </chunking>
        <chunking id="4" string="the disorder sometimes" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="disorder" />
            <token id="7" string="sometimes" />
          </tokens>
        </chunking>
        <chunking id="5" string="notes NIH researcher D. Carleton Gajdusek" type="VP">
          <tokens>
            <token id="17" string="notes" />
            <token id="18" string="NIH" />
            <token id="19" string="researcher" />
            <token id="20" string="D." />
            <token id="21" string="Carleton" />
            <token id="22" string="Gajdusek" />
          </tokens>
        </chunking>
        <chunking id="6" string="a kind" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="kind" />
          </tokens>
        </chunking>
        <chunking id="7" string="grips scientists with a kind of obsessive fascination" type="NP">
          <tokens>
            <token id="8" string="grips" />
            <token id="9" string="scientists" />
            <token id="10" string="with" />
            <token id="11" string="a" />
            <token id="12" string="kind" />
            <token id="13" string="of" />
            <token id="14" string="obsessive" />
            <token id="15" string="fascination" />
          </tokens>
        </chunking>
        <chunking id="8" string="grips scientists" type="NP">
          <tokens>
            <token id="8" string="grips" />
            <token id="9" string="scientists" />
          </tokens>
        </chunking>
        <chunking id="9" string="The uncanny nature" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="uncanny" />
            <token id="3" string="nature" />
          </tokens>
        </chunking>
        <chunking id="10" string="obsessive fascination" type="NP">
          <tokens>
            <token id="14" string="obsessive" />
            <token id="15" string="fascination" />
          </tokens>
        </chunking>
        <chunking id="11" string="the disorder" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="disorder" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">nature</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">nature</governor>
          <dependent id="2">uncanny</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">notes</governor>
          <dependent id="3">nature</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">disorder</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">disorder</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">nature</governor>
          <dependent id="6">disorder</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">disorder</governor>
          <dependent id="7">sometimes</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">scientists</governor>
          <dependent id="8">grips</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="3">nature</governor>
          <dependent id="9">scientists</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">kind</governor>
          <dependent id="10">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">kind</governor>
          <dependent id="11">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">scientists</governor>
          <dependent id="12">kind</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">fascination</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">fascination</governor>
          <dependent id="14">obsessive</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">kind</governor>
          <dependent id="15">fascination</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="17">notes</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">Gajdusek</governor>
          <dependent id="18">NIH</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">Gajdusek</governor>
          <dependent id="19">researcher</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">Gajdusek</governor>
          <dependent id="20">D.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">Gajdusek</governor>
          <dependent id="21">Carleton</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">notes</governor>
          <dependent id="22">Gajdusek</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="D. Carleton Gajdusek" type="PERSON" score="0.0">
          <tokens>
            <token id="20" string="D." />
            <token id="21" string="Carleton" />
            <token id="22" string="Gajdusek" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>He should know, having chased spongiform leads around the globe for 33 years and won a Nobel Prize in the process.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="should" lemma="should" stem="should" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="know" lemma="know" stem="know" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="having" lemma="have" stem="have" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="chased" lemma="chase" stem="chase" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="spongiform" lemma="spongiform" stem="spongiform" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="leads" lemma="lead" stem="lead" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="around" lemma="around" stem="around" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="globe" lemma="globe" stem="globe" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="33" lemma="33" stem="33" pos="CD" type="Number" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="14" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="won" lemma="win" stem="won" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Nobel" lemma="Nobel" stem="nobel" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="19" string="Prize" lemma="Prize" stem="prize" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="20" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="process" lemma="process" stem="process" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (MD should) (VP (VB know) (, ,) (S (VP (VBG having) (VP (VBN chased) (SBAR (S (NP (NN spongiform)) (VP (VP (VBZ leads) (PP (IN around) (NP (NP (DT the) (NN globe)) (PP (IN for) (NP (CD 33) (NNS years)))))) (CC and) (VP (VBD won) (NP (DT a) (NNP Nobel) (NNP Prize)) (PP (IN in) (NP (DT the) (NN process)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="leads around the globe for 33 years" type="VP">
          <tokens>
            <token id="8" string="leads" />
            <token id="9" string="around" />
            <token id="10" string="the" />
            <token id="11" string="globe" />
            <token id="12" string="for" />
            <token id="13" string="33" />
            <token id="14" string="years" />
          </tokens>
        </chunking>
        <chunking id="2" string="should know , having chased spongiform leads around the globe for 33 years and won a Nobel Prize in the process" type="VP">
          <tokens>
            <token id="2" string="should" />
            <token id="3" string="know" />
            <token id="4" string="," />
            <token id="5" string="having" />
            <token id="6" string="chased" />
            <token id="7" string="spongiform" />
            <token id="8" string="leads" />
            <token id="9" string="around" />
            <token id="10" string="the" />
            <token id="11" string="globe" />
            <token id="12" string="for" />
            <token id="13" string="33" />
            <token id="14" string="years" />
            <token id="15" string="and" />
            <token id="16" string="won" />
            <token id="17" string="a" />
            <token id="18" string="Nobel" />
            <token id="19" string="Prize" />
            <token id="20" string="in" />
            <token id="21" string="the" />
            <token id="22" string="process" />
          </tokens>
        </chunking>
        <chunking id="3" string="won a Nobel Prize in the process" type="VP">
          <tokens>
            <token id="16" string="won" />
            <token id="17" string="a" />
            <token id="18" string="Nobel" />
            <token id="19" string="Prize" />
            <token id="20" string="in" />
            <token id="21" string="the" />
            <token id="22" string="process" />
          </tokens>
        </chunking>
        <chunking id="4" string="chased spongiform leads around the globe for 33 years and won a Nobel Prize in the process" type="VP">
          <tokens>
            <token id="6" string="chased" />
            <token id="7" string="spongiform" />
            <token id="8" string="leads" />
            <token id="9" string="around" />
            <token id="10" string="the" />
            <token id="11" string="globe" />
            <token id="12" string="for" />
            <token id="13" string="33" />
            <token id="14" string="years" />
            <token id="15" string="and" />
            <token id="16" string="won" />
            <token id="17" string="a" />
            <token id="18" string="Nobel" />
            <token id="19" string="Prize" />
            <token id="20" string="in" />
            <token id="21" string="the" />
            <token id="22" string="process" />
          </tokens>
        </chunking>
        <chunking id="5" string="leads around the globe for 33 years and won a Nobel Prize in the process" type="VP">
          <tokens>
            <token id="8" string="leads" />
            <token id="9" string="around" />
            <token id="10" string="the" />
            <token id="11" string="globe" />
            <token id="12" string="for" />
            <token id="13" string="33" />
            <token id="14" string="years" />
            <token id="15" string="and" />
            <token id="16" string="won" />
            <token id="17" string="a" />
            <token id="18" string="Nobel" />
            <token id="19" string="Prize" />
            <token id="20" string="in" />
            <token id="21" string="the" />
            <token id="22" string="process" />
          </tokens>
        </chunking>
        <chunking id="6" string="having chased spongiform leads around the globe for 33 years and won a Nobel Prize in the process" type="VP">
          <tokens>
            <token id="5" string="having" />
            <token id="6" string="chased" />
            <token id="7" string="spongiform" />
            <token id="8" string="leads" />
            <token id="9" string="around" />
            <token id="10" string="the" />
            <token id="11" string="globe" />
            <token id="12" string="for" />
            <token id="13" string="33" />
            <token id="14" string="years" />
            <token id="15" string="and" />
            <token id="16" string="won" />
            <token id="17" string="a" />
            <token id="18" string="Nobel" />
            <token id="19" string="Prize" />
            <token id="20" string="in" />
            <token id="21" string="the" />
            <token id="22" string="process" />
          </tokens>
        </chunking>
        <chunking id="7" string="know , having chased spongiform leads around the globe for 33 years and won a Nobel Prize in the process" type="VP">
          <tokens>
            <token id="3" string="know" />
            <token id="4" string="," />
            <token id="5" string="having" />
            <token id="6" string="chased" />
            <token id="7" string="spongiform" />
            <token id="8" string="leads" />
            <token id="9" string="around" />
            <token id="10" string="the" />
            <token id="11" string="globe" />
            <token id="12" string="for" />
            <token id="13" string="33" />
            <token id="14" string="years" />
            <token id="15" string="and" />
            <token id="16" string="won" />
            <token id="17" string="a" />
            <token id="18" string="Nobel" />
            <token id="19" string="Prize" />
            <token id="20" string="in" />
            <token id="21" string="the" />
            <token id="22" string="process" />
          </tokens>
        </chunking>
        <chunking id="8" string="the globe for 33 years" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="globe" />
            <token id="12" string="for" />
            <token id="13" string="33" />
            <token id="14" string="years" />
          </tokens>
        </chunking>
        <chunking id="9" string="the globe" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="globe" />
          </tokens>
        </chunking>
        <chunking id="10" string="the process" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="process" />
          </tokens>
        </chunking>
        <chunking id="11" string="spongiform" type="NP">
          <tokens>
            <token id="7" string="spongiform" />
          </tokens>
        </chunking>
        <chunking id="12" string="33 years" type="NP">
          <tokens>
            <token id="13" string="33" />
            <token id="14" string="years" />
          </tokens>
        </chunking>
        <chunking id="13" string="a Nobel Prize" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="Nobel" />
            <token id="19" string="Prize" />
          </tokens>
        </chunking>
        <chunking id="14" string="spongiform leads around the globe for 33 years and won a Nobel Prize in the process" type="SBAR">
          <tokens>
            <token id="7" string="spongiform" />
            <token id="8" string="leads" />
            <token id="9" string="around" />
            <token id="10" string="the" />
            <token id="11" string="globe" />
            <token id="12" string="for" />
            <token id="13" string="33" />
            <token id="14" string="years" />
            <token id="15" string="and" />
            <token id="16" string="won" />
            <token id="17" string="a" />
            <token id="18" string="Nobel" />
            <token id="19" string="Prize" />
            <token id="20" string="in" />
            <token id="21" string="the" />
            <token id="22" string="process" />
          </tokens>
        </chunking>
        <chunking id="15" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">know</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="3">know</governor>
          <dependent id="2">should</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">know</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">chased</governor>
          <dependent id="5">having</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">know</governor>
          <dependent id="6">chased</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">leads</governor>
          <dependent id="7">spongiform</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">chased</governor>
          <dependent id="8">leads</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">globe</governor>
          <dependent id="9">around</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">globe</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">leads</governor>
          <dependent id="11">globe</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">years</governor>
          <dependent id="12">for</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="14">years</governor>
          <dependent id="13">33</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">globe</governor>
          <dependent id="14">years</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">leads</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">leads</governor>
          <dependent id="16">won</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">Prize</governor>
          <dependent id="17">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">Prize</governor>
          <dependent id="18">Nobel</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">won</governor>
          <dependent id="19">Prize</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">process</governor>
          <dependent id="20">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">process</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">won</governor>
          <dependent id="22">process</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Nobel Prize" type="MISC" score="0.0">
          <tokens>
            <token id="18" string="Nobel" />
            <token id="19" string="Prize" />
          </tokens>
        </entity>
        <entity id="2" string="33 years" type="DURATION" score="0.0">
          <tokens>
            <token id="13" string="33" />
            <token id="14" string="years" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>Recently the fascination has taken on a more anxious cast as the disease has struck humans and animals with suspicious regularity in several places, underscoring a longstanding question: Do people get the disease from animals?</content>
      <tokens>
        <token id="1" string="Recently" lemma="recently" stem="recent" pos="RB" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="fascination" lemma="fascination" stem="fascin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="taken" lemma="take" stem="taken" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="anxious" lemma="anxious" stem="anxiou" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="cast" lemma="cast" stem="cast" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="disease" lemma="disease" stem="diseas" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="14" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="struck" lemma="strike" stem="struck" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="humans" lemma="human" stem="human" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="animals" lemma="animal" stem="anim" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="suspicious" lemma="suspicious" stem="suspici" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="regularity" lemma="regularity" stem="regular" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="several" lemma="several" stem="sever" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="places" lemma="place" stem="place" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="underscoring" lemma="underscore" stem="underscor" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="28" string="longstanding" lemma="longstanding" stem="longstand" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="29" string="question" lemma="question" stem="question" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="30" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="Do" lemma="do" stem="do" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="33" string="get" lemma="get" stem="get" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="disease" lemma="disease" stem="diseas" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="36" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="animals" lemma="animal" stem="anim" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="38" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Recently)) (NP (DT the) (NN fascination)) (VP (VBZ has) (VP (VBN taken) (PP (IN on) (NP (DT a) (ADJP (RBR more) (JJ anxious)) (NN cast))) (SBAR (IN as) (S (NP (DT the) (NN disease)) (VP (VBZ has) (VP (VBN struck) (NP (NNS humans) (CC and) (NNS animals)) (PP (IN with) (NP (NP (JJ suspicious) (NN regularity)) (PP (IN in) (NP (JJ several) (NNS places))))) (, ,) (S (VP (VBG underscoring) (NP (DT a) (JJ longstanding) (NN question)))))))) (: :) (SQ (VB Do) (NP (NNS people)) (VP (VB get) (NP (DT the) (NN disease)) (PP (IN from) (NP (NNS animals))))))) (. ?)))</syntactictree>
      <chunkings>
        <chunking id="1" string="get the disease from animals" type="VP">
          <tokens>
            <token id="33" string="get" />
            <token id="34" string="the" />
            <token id="35" string="disease" />
            <token id="36" string="from" />
            <token id="37" string="animals" />
          </tokens>
        </chunking>
        <chunking id="2" string="more anxious" type="ADJP">
          <tokens>
            <token id="8" string="more" />
            <token id="9" string="anxious" />
          </tokens>
        </chunking>
        <chunking id="3" string="as the disease has struck humans and animals with suspicious regularity in several places , underscoring a longstanding question" type="SBAR">
          <tokens>
            <token id="11" string="as" />
            <token id="12" string="the" />
            <token id="13" string="disease" />
            <token id="14" string="has" />
            <token id="15" string="struck" />
            <token id="16" string="humans" />
            <token id="17" string="and" />
            <token id="18" string="animals" />
            <token id="19" string="with" />
            <token id="20" string="suspicious" />
            <token id="21" string="regularity" />
            <token id="22" string="in" />
            <token id="23" string="several" />
            <token id="24" string="places" />
            <token id="25" string="," />
            <token id="26" string="underscoring" />
            <token id="27" string="a" />
            <token id="28" string="longstanding" />
            <token id="29" string="question" />
          </tokens>
        </chunking>
        <chunking id="4" string="has struck humans and animals with suspicious regularity in several places , underscoring a longstanding question" type="VP">
          <tokens>
            <token id="14" string="has" />
            <token id="15" string="struck" />
            <token id="16" string="humans" />
            <token id="17" string="and" />
            <token id="18" string="animals" />
            <token id="19" string="with" />
            <token id="20" string="suspicious" />
            <token id="21" string="regularity" />
            <token id="22" string="in" />
            <token id="23" string="several" />
            <token id="24" string="places" />
            <token id="25" string="," />
            <token id="26" string="underscoring" />
            <token id="27" string="a" />
            <token id="28" string="longstanding" />
            <token id="29" string="question" />
          </tokens>
        </chunking>
        <chunking id="5" string="a more anxious cast" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="more" />
            <token id="9" string="anxious" />
            <token id="10" string="cast" />
          </tokens>
        </chunking>
        <chunking id="6" string="underscoring a longstanding question" type="VP">
          <tokens>
            <token id="26" string="underscoring" />
            <token id="27" string="a" />
            <token id="28" string="longstanding" />
            <token id="29" string="question" />
          </tokens>
        </chunking>
        <chunking id="7" string="people" type="NP">
          <tokens>
            <token id="32" string="people" />
          </tokens>
        </chunking>
        <chunking id="8" string="taken on a more anxious cast as the disease has struck humans and animals with suspicious regularity in several places , underscoring a longstanding question : Do people get the disease from animals" type="VP">
          <tokens>
            <token id="5" string="taken" />
            <token id="6" string="on" />
            <token id="7" string="a" />
            <token id="8" string="more" />
            <token id="9" string="anxious" />
            <token id="10" string="cast" />
            <token id="11" string="as" />
            <token id="12" string="the" />
            <token id="13" string="disease" />
            <token id="14" string="has" />
            <token id="15" string="struck" />
            <token id="16" string="humans" />
            <token id="17" string="and" />
            <token id="18" string="animals" />
            <token id="19" string="with" />
            <token id="20" string="suspicious" />
            <token id="21" string="regularity" />
            <token id="22" string="in" />
            <token id="23" string="several" />
            <token id="24" string="places" />
            <token id="25" string="," />
            <token id="26" string="underscoring" />
            <token id="27" string="a" />
            <token id="28" string="longstanding" />
            <token id="29" string="question" />
            <token id="30" string=":" />
            <token id="31" string="Do" />
            <token id="32" string="people" />
            <token id="33" string="get" />
            <token id="34" string="the" />
            <token id="35" string="disease" />
            <token id="36" string="from" />
            <token id="37" string="animals" />
          </tokens>
        </chunking>
        <chunking id="9" string="the disease" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="disease" />
          </tokens>
        </chunking>
        <chunking id="10" string="suspicious regularity in several places" type="NP">
          <tokens>
            <token id="20" string="suspicious" />
            <token id="21" string="regularity" />
            <token id="22" string="in" />
            <token id="23" string="several" />
            <token id="24" string="places" />
          </tokens>
        </chunking>
        <chunking id="11" string="has taken on a more anxious cast as the disease has struck humans and animals with suspicious regularity in several places , underscoring a longstanding question : Do people get the disease from animals" type="VP">
          <tokens>
            <token id="4" string="has" />
            <token id="5" string="taken" />
            <token id="6" string="on" />
            <token id="7" string="a" />
            <token id="8" string="more" />
            <token id="9" string="anxious" />
            <token id="10" string="cast" />
            <token id="11" string="as" />
            <token id="12" string="the" />
            <token id="13" string="disease" />
            <token id="14" string="has" />
            <token id="15" string="struck" />
            <token id="16" string="humans" />
            <token id="17" string="and" />
            <token id="18" string="animals" />
            <token id="19" string="with" />
            <token id="20" string="suspicious" />
            <token id="21" string="regularity" />
            <token id="22" string="in" />
            <token id="23" string="several" />
            <token id="24" string="places" />
            <token id="25" string="," />
            <token id="26" string="underscoring" />
            <token id="27" string="a" />
            <token id="28" string="longstanding" />
            <token id="29" string="question" />
            <token id="30" string=":" />
            <token id="31" string="Do" />
            <token id="32" string="people" />
            <token id="33" string="get" />
            <token id="34" string="the" />
            <token id="35" string="disease" />
            <token id="36" string="from" />
            <token id="37" string="animals" />
          </tokens>
        </chunking>
        <chunking id="12" string="humans and animals" type="NP">
          <tokens>
            <token id="16" string="humans" />
            <token id="17" string="and" />
            <token id="18" string="animals" />
          </tokens>
        </chunking>
        <chunking id="13" string="the fascination" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="fascination" />
          </tokens>
        </chunking>
        <chunking id="14" string="struck humans and animals with suspicious regularity in several places , underscoring a longstanding question" type="VP">
          <tokens>
            <token id="15" string="struck" />
            <token id="16" string="humans" />
            <token id="17" string="and" />
            <token id="18" string="animals" />
            <token id="19" string="with" />
            <token id="20" string="suspicious" />
            <token id="21" string="regularity" />
            <token id="22" string="in" />
            <token id="23" string="several" />
            <token id="24" string="places" />
            <token id="25" string="," />
            <token id="26" string="underscoring" />
            <token id="27" string="a" />
            <token id="28" string="longstanding" />
            <token id="29" string="question" />
          </tokens>
        </chunking>
        <chunking id="15" string="several places" type="NP">
          <tokens>
            <token id="23" string="several" />
            <token id="24" string="places" />
          </tokens>
        </chunking>
        <chunking id="16" string="animals" type="NP">
          <tokens>
            <token id="37" string="animals" />
          </tokens>
        </chunking>
        <chunking id="17" string="suspicious regularity" type="NP">
          <tokens>
            <token id="20" string="suspicious" />
            <token id="21" string="regularity" />
          </tokens>
        </chunking>
        <chunking id="18" string="a longstanding question" type="NP">
          <tokens>
            <token id="27" string="a" />
            <token id="28" string="longstanding" />
            <token id="29" string="question" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="5">taken</governor>
          <dependent id="1">Recently</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">fascination</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">taken</governor>
          <dependent id="3">fascination</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">taken</governor>
          <dependent id="4">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">taken</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">cast</governor>
          <dependent id="6">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">cast</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">anxious</governor>
          <dependent id="8">more</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">cast</governor>
          <dependent id="9">anxious</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">taken</governor>
          <dependent id="10">cast</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">struck</governor>
          <dependent id="11">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">disease</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">struck</governor>
          <dependent id="13">disease</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="15">struck</governor>
          <dependent id="14">has</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="5">taken</governor>
          <dependent id="15">struck</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">struck</governor>
          <dependent id="16">humans</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="16">humans</governor>
          <dependent id="17">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">humans</governor>
          <dependent id="18">animals</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">regularity</governor>
          <dependent id="19">with</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">regularity</governor>
          <dependent id="20">suspicious</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">struck</governor>
          <dependent id="21">regularity</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">places</governor>
          <dependent id="22">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">places</governor>
          <dependent id="23">several</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">regularity</governor>
          <dependent id="24">places</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="15">struck</governor>
          <dependent id="26">underscoring</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">question</governor>
          <dependent id="27">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="29">question</governor>
          <dependent id="28">longstanding</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="26">underscoring</governor>
          <dependent id="29">question</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="33">get</governor>
          <dependent id="31">Do</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="33">get</governor>
          <dependent id="32">people</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="5">taken</governor>
          <dependent id="33">get</dependent>
        </dependency>
        <dependency type="det">
          <governor id="35">disease</governor>
          <dependent id="34">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="33">get</governor>
          <dependent id="35">disease</dependent>
        </dependency>
        <dependency type="case">
          <governor id="37">animals</governor>
          <dependent id="36">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="33">get</governor>
          <dependent id="37">animals</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="disease" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="13" string="disease" />
          </tokens>
        </entity>
        <entity id="2" string="Recently" type="DATE" score="0.0">
          <tokens>
            <token id="1" string="Recently" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>The question has burned with special intensity since scrapie, the form of the disease in sheep, jumped to British cattle a few years ago after they were fed ground-up parts of infected sheep.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="question" lemma="question" stem="question" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="burned" lemma="burn" stem="burn" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="special" lemma="special" stem="special" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="intensity" lemma="intensity" stem="intens" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="since" lemma="since" stem="sinc" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="scrapie" lemma="scrapie" stem="scrapi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="form" lemma="form" stem="form" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="disease" lemma="disease" stem="diseas" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="true" />
        <token id="16" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="sheep" lemma="sheep" stem="sheep" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="jumped" lemma="jump" stem="jump" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="British" lemma="british" stem="british" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="22" string="cattle" lemma="cattle" stem="cattl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="24" string="few" lemma="few" stem="few" pos="JJ" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="25" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="26" string="ago" lemma="ago" stem="ago" pos="RB" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="27" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="29" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="fed" lemma="feed" stem="fed" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="ground-up" lemma="ground-up" stem="ground-up" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="parts" lemma="part" stem="part" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="infected" lemma="infected" stem="infect" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="sheep" lemma="sheep" stem="sheep" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN question)) (VP (VBZ has) (VP (VBN burned) (PP (IN with) (NP (JJ special) (NN intensity))) (SBAR (IN since) (S (NP (NP (NN scrapie)) (, ,) (NP (NP (DT the) (NN form)) (PP (IN of) (NP (NP (DT the) (NN disease)) (PP (IN in) (NP (NN sheep)))))) (, ,)) (VP (VBD jumped) (PP (TO to) (NP (JJ British) (NNS cattle))) (ADVP (NP (DT a) (JJ few) (NNS years)) (RB ago)) (SBAR (IN after) (S (NP (PRP they)) (VP (VBD were) (VP (VBN fed) (NP (NP (JJ ground-up) (NNS parts)) (PP (IN of) (NP (JJ infected) (NN sheep))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="were fed ground-up parts of infected sheep" type="VP">
          <tokens>
            <token id="29" string="were" />
            <token id="30" string="fed" />
            <token id="31" string="ground-up" />
            <token id="32" string="parts" />
            <token id="33" string="of" />
            <token id="34" string="infected" />
            <token id="35" string="sheep" />
          </tokens>
        </chunking>
        <chunking id="2" string="special intensity" type="NP">
          <tokens>
            <token id="6" string="special" />
            <token id="7" string="intensity" />
          </tokens>
        </chunking>
        <chunking id="3" string="the form of the disease in sheep" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="form" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="disease" />
            <token id="16" string="in" />
            <token id="17" string="sheep" />
          </tokens>
        </chunking>
        <chunking id="4" string="has burned with special intensity since scrapie , the form of the disease in sheep , jumped to British cattle a few years ago after they were fed ground-up parts of infected sheep" type="VP">
          <tokens>
            <token id="3" string="has" />
            <token id="4" string="burned" />
            <token id="5" string="with" />
            <token id="6" string="special" />
            <token id="7" string="intensity" />
            <token id="8" string="since" />
            <token id="9" string="scrapie" />
            <token id="10" string="," />
            <token id="11" string="the" />
            <token id="12" string="form" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="disease" />
            <token id="16" string="in" />
            <token id="17" string="sheep" />
            <token id="18" string="," />
            <token id="19" string="jumped" />
            <token id="20" string="to" />
            <token id="21" string="British" />
            <token id="22" string="cattle" />
            <token id="23" string="a" />
            <token id="24" string="few" />
            <token id="25" string="years" />
            <token id="26" string="ago" />
            <token id="27" string="after" />
            <token id="28" string="they" />
            <token id="29" string="were" />
            <token id="30" string="fed" />
            <token id="31" string="ground-up" />
            <token id="32" string="parts" />
            <token id="33" string="of" />
            <token id="34" string="infected" />
            <token id="35" string="sheep" />
          </tokens>
        </chunking>
        <chunking id="5" string="a few years" type="NP">
          <tokens>
            <token id="23" string="a" />
            <token id="24" string="few" />
            <token id="25" string="years" />
          </tokens>
        </chunking>
        <chunking id="6" string="The question" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="question" />
          </tokens>
        </chunking>
        <chunking id="7" string="fed ground-up parts of infected sheep" type="VP">
          <tokens>
            <token id="30" string="fed" />
            <token id="31" string="ground-up" />
            <token id="32" string="parts" />
            <token id="33" string="of" />
            <token id="34" string="infected" />
            <token id="35" string="sheep" />
          </tokens>
        </chunking>
        <chunking id="8" string="since scrapie , the form of the disease in sheep , jumped to British cattle a few years ago after they were fed ground-up parts of infected sheep" type="SBAR">
          <tokens>
            <token id="8" string="since" />
            <token id="9" string="scrapie" />
            <token id="10" string="," />
            <token id="11" string="the" />
            <token id="12" string="form" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="disease" />
            <token id="16" string="in" />
            <token id="17" string="sheep" />
            <token id="18" string="," />
            <token id="19" string="jumped" />
            <token id="20" string="to" />
            <token id="21" string="British" />
            <token id="22" string="cattle" />
            <token id="23" string="a" />
            <token id="24" string="few" />
            <token id="25" string="years" />
            <token id="26" string="ago" />
            <token id="27" string="after" />
            <token id="28" string="they" />
            <token id="29" string="were" />
            <token id="30" string="fed" />
            <token id="31" string="ground-up" />
            <token id="32" string="parts" />
            <token id="33" string="of" />
            <token id="34" string="infected" />
            <token id="35" string="sheep" />
          </tokens>
        </chunking>
        <chunking id="9" string="the disease in sheep" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="disease" />
            <token id="16" string="in" />
            <token id="17" string="sheep" />
          </tokens>
        </chunking>
        <chunking id="10" string="after they were fed ground-up parts of infected sheep" type="SBAR">
          <tokens>
            <token id="27" string="after" />
            <token id="28" string="they" />
            <token id="29" string="were" />
            <token id="30" string="fed" />
            <token id="31" string="ground-up" />
            <token id="32" string="parts" />
            <token id="33" string="of" />
            <token id="34" string="infected" />
            <token id="35" string="sheep" />
          </tokens>
        </chunking>
        <chunking id="11" string="the form" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="form" />
          </tokens>
        </chunking>
        <chunking id="12" string="scrapie , the form of the disease in sheep ," type="NP">
          <tokens>
            <token id="9" string="scrapie" />
            <token id="10" string="," />
            <token id="11" string="the" />
            <token id="12" string="form" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="disease" />
            <token id="16" string="in" />
            <token id="17" string="sheep" />
            <token id="18" string="," />
          </tokens>
        </chunking>
        <chunking id="13" string="the disease" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="disease" />
          </tokens>
        </chunking>
        <chunking id="14" string="they" type="NP">
          <tokens>
            <token id="28" string="they" />
          </tokens>
        </chunking>
        <chunking id="15" string="British cattle" type="NP">
          <tokens>
            <token id="21" string="British" />
            <token id="22" string="cattle" />
          </tokens>
        </chunking>
        <chunking id="16" string="jumped to British cattle a few years ago after they were fed ground-up parts of infected sheep" type="VP">
          <tokens>
            <token id="19" string="jumped" />
            <token id="20" string="to" />
            <token id="21" string="British" />
            <token id="22" string="cattle" />
            <token id="23" string="a" />
            <token id="24" string="few" />
            <token id="25" string="years" />
            <token id="26" string="ago" />
            <token id="27" string="after" />
            <token id="28" string="they" />
            <token id="29" string="were" />
            <token id="30" string="fed" />
            <token id="31" string="ground-up" />
            <token id="32" string="parts" />
            <token id="33" string="of" />
            <token id="34" string="infected" />
            <token id="35" string="sheep" />
          </tokens>
        </chunking>
        <chunking id="17" string="infected sheep" type="NP">
          <tokens>
            <token id="34" string="infected" />
            <token id="35" string="sheep" />
          </tokens>
        </chunking>
        <chunking id="18" string="scrapie" type="NP">
          <tokens>
            <token id="9" string="scrapie" />
          </tokens>
        </chunking>
        <chunking id="19" string="ground-up parts of infected sheep" type="NP">
          <tokens>
            <token id="31" string="ground-up" />
            <token id="32" string="parts" />
            <token id="33" string="of" />
            <token id="34" string="infected" />
            <token id="35" string="sheep" />
          </tokens>
        </chunking>
        <chunking id="20" string="burned with special intensity since scrapie , the form of the disease in sheep , jumped to British cattle a few years ago after they were fed ground-up parts of infected sheep" type="VP">
          <tokens>
            <token id="4" string="burned" />
            <token id="5" string="with" />
            <token id="6" string="special" />
            <token id="7" string="intensity" />
            <token id="8" string="since" />
            <token id="9" string="scrapie" />
            <token id="10" string="," />
            <token id="11" string="the" />
            <token id="12" string="form" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="disease" />
            <token id="16" string="in" />
            <token id="17" string="sheep" />
            <token id="18" string="," />
            <token id="19" string="jumped" />
            <token id="20" string="to" />
            <token id="21" string="British" />
            <token id="22" string="cattle" />
            <token id="23" string="a" />
            <token id="24" string="few" />
            <token id="25" string="years" />
            <token id="26" string="ago" />
            <token id="27" string="after" />
            <token id="28" string="they" />
            <token id="29" string="were" />
            <token id="30" string="fed" />
            <token id="31" string="ground-up" />
            <token id="32" string="parts" />
            <token id="33" string="of" />
            <token id="34" string="infected" />
            <token id="35" string="sheep" />
          </tokens>
        </chunking>
        <chunking id="21" string="sheep" type="NP">
          <tokens>
            <token id="17" string="sheep" />
          </tokens>
        </chunking>
        <chunking id="22" string="ground-up parts" type="NP">
          <tokens>
            <token id="31" string="ground-up" />
            <token id="32" string="parts" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">question</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">burned</governor>
          <dependent id="2">question</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">burned</governor>
          <dependent id="3">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">burned</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">intensity</governor>
          <dependent id="5">with</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">intensity</governor>
          <dependent id="6">special</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">burned</governor>
          <dependent id="7">intensity</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">jumped</governor>
          <dependent id="8">since</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">jumped</governor>
          <dependent id="9">scrapie</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">form</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="9">scrapie</governor>
          <dependent id="12">form</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">disease</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">disease</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">form</governor>
          <dependent id="15">disease</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">sheep</governor>
          <dependent id="16">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">disease</governor>
          <dependent id="17">sheep</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">burned</governor>
          <dependent id="19">jumped</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">cattle</governor>
          <dependent id="20">to</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">cattle</governor>
          <dependent id="21">British</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">jumped</governor>
          <dependent id="22">cattle</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">years</governor>
          <dependent id="23">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">years</governor>
          <dependent id="24">few</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="26">ago</governor>
          <dependent id="25">years</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="19">jumped</governor>
          <dependent id="26">ago</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="30">fed</governor>
          <dependent id="27">after</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="30">fed</governor>
          <dependent id="28">they</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="30">fed</governor>
          <dependent id="29">were</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="19">jumped</governor>
          <dependent id="30">fed</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="32">parts</governor>
          <dependent id="31">ground-up</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="30">fed</governor>
          <dependent id="32">parts</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">sheep</governor>
          <dependent id="33">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="35">sheep</governor>
          <dependent id="34">infected</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="32">parts</governor>
          <dependent id="35">sheep</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="British" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="21" string="British" />
          </tokens>
        </entity>
        <entity id="2" string="disease" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="15" string="disease" />
          </tokens>
        </entity>
        <entity id="3" string="a few years ago" type="DATE" score="0.0">
          <tokens>
            <token id="23" string="a" />
            <token id="24" string="few" />
            <token id="25" string="years" />
            <token id="26" string="ago" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>About 20,000 British cattle have been destroyed since 1986 in hopes of eradicating the spongiform &amp;quot;mad cow&amp;quot; disease, which makes the animals jittery before they keel over.</content>
      <tokens>
        <token id="1" string="About" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="20,000" lemma="20,000" stem="20,000" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="3" string="British" lemma="british" stem="british" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="4" string="cattle" lemma="cattle" stem="cattl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="destroyed" lemma="destroy" stem="destroi" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="since" lemma="since" stem="sinc" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="1986" lemma="1986" stem="1986" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="10" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="hopes" lemma="hope" stem="hope" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="eradicating" lemma="eradicate" stem="erad" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="spongiform" lemma="spongiform" stem="spongiform" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="mad" lemma="mad" stem="mad" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="cow" lemma="cow" stem="cow" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="disease" lemma="disease" stem="diseas" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="true" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="23" string="makes" lemma="make" stem="make" pos="VBZ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="25" string="animals" lemma="animal" stem="anim" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="26" string="jittery" lemma="jittery" stem="jitteri" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="27" string="before" lemma="before" stem="befor" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="28" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="29" string="keel" lemma="keel" stem="keel" pos="VBP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="30" string="over" lemma="over" stem="over" pos="RP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="31" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (PP (IN About) (NP (CD 20,000) (JJ British) (NNS cattle))) (VP (VBP have) (VP (VBN been) (VP (VBN destroyed) (PP (IN since) (NP (CD 1986))) (PP (IN in) (NP (NP (NNS hopes)) (PP (IN of) (S (VP (VBG eradicating) (S (NP (DT the) (NN spongiform)) (`` ``) (ADJP (JJ mad))))))))))) (NP (NP (NN cow) ('' '') (NN disease)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ makes) (S (NP (DT the) (NNS animals)) (ADJP (JJ jittery)) (SBAR (IN before) (S (NP (PRP they)) (VP (VBP keel) (PRT (RP over)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="destroyed since 1986 in hopes of eradicating the spongiform `` mad" type="VP">
          <tokens>
            <token id="7" string="destroyed" />
            <token id="8" string="since" />
            <token id="9" string="1986" />
            <token id="10" string="in" />
            <token id="11" string="hopes" />
            <token id="12" string="of" />
            <token id="13" string="eradicating" />
            <token id="14" string="the" />
            <token id="15" string="spongiform" />
            <token id="16" string="&quot;" />
            <token id="17" string="mad" />
          </tokens>
        </chunking>
        <chunking id="2" string="which makes the animals jittery before they keel over" type="SBAR">
          <tokens>
            <token id="22" string="which" />
            <token id="23" string="makes" />
            <token id="24" string="the" />
            <token id="25" string="animals" />
            <token id="26" string="jittery" />
            <token id="27" string="before" />
            <token id="28" string="they" />
            <token id="29" string="keel" />
            <token id="30" string="over" />
          </tokens>
        </chunking>
        <chunking id="3" string="20,000 British cattle" type="NP">
          <tokens>
            <token id="2" string="20,000" />
            <token id="3" string="British" />
            <token id="4" string="cattle" />
          </tokens>
        </chunking>
        <chunking id="4" string="mad" type="ADJP">
          <tokens>
            <token id="17" string="mad" />
          </tokens>
        </chunking>
        <chunking id="5" string="the spongiform" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="spongiform" />
          </tokens>
        </chunking>
        <chunking id="6" string="the animals" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="animals" />
          </tokens>
        </chunking>
        <chunking id="7" string="have been destroyed since 1986 in hopes of eradicating the spongiform `` mad" type="VP">
          <tokens>
            <token id="5" string="have" />
            <token id="6" string="been" />
            <token id="7" string="destroyed" />
            <token id="8" string="since" />
            <token id="9" string="1986" />
            <token id="10" string="in" />
            <token id="11" string="hopes" />
            <token id="12" string="of" />
            <token id="13" string="eradicating" />
            <token id="14" string="the" />
            <token id="15" string="spongiform" />
            <token id="16" string="&quot;" />
            <token id="17" string="mad" />
          </tokens>
        </chunking>
        <chunking id="8" string="cow '' disease" type="NP">
          <tokens>
            <token id="18" string="cow" />
            <token id="19" string="&quot;" />
            <token id="20" string="disease" />
          </tokens>
        </chunking>
        <chunking id="9" string="before they keel over" type="SBAR">
          <tokens>
            <token id="27" string="before" />
            <token id="28" string="they" />
            <token id="29" string="keel" />
            <token id="30" string="over" />
          </tokens>
        </chunking>
        <chunking id="10" string="they" type="NP">
          <tokens>
            <token id="28" string="they" />
          </tokens>
        </chunking>
        <chunking id="11" string="1986" type="NP">
          <tokens>
            <token id="9" string="1986" />
          </tokens>
        </chunking>
        <chunking id="12" string="cow '' disease , which makes the animals jittery before they keel over" type="NP">
          <tokens>
            <token id="18" string="cow" />
            <token id="19" string="&quot;" />
            <token id="20" string="disease" />
            <token id="21" string="," />
            <token id="22" string="which" />
            <token id="23" string="makes" />
            <token id="24" string="the" />
            <token id="25" string="animals" />
            <token id="26" string="jittery" />
            <token id="27" string="before" />
            <token id="28" string="they" />
            <token id="29" string="keel" />
            <token id="30" string="over" />
          </tokens>
        </chunking>
        <chunking id="13" string="jittery" type="ADJP">
          <tokens>
            <token id="26" string="jittery" />
          </tokens>
        </chunking>
        <chunking id="14" string="hopes" type="NP">
          <tokens>
            <token id="11" string="hopes" />
          </tokens>
        </chunking>
        <chunking id="15" string="keel over" type="VP">
          <tokens>
            <token id="29" string="keel" />
            <token id="30" string="over" />
          </tokens>
        </chunking>
        <chunking id="16" string="been destroyed since 1986 in hopes of eradicating the spongiform `` mad" type="VP">
          <tokens>
            <token id="6" string="been" />
            <token id="7" string="destroyed" />
            <token id="8" string="since" />
            <token id="9" string="1986" />
            <token id="10" string="in" />
            <token id="11" string="hopes" />
            <token id="12" string="of" />
            <token id="13" string="eradicating" />
            <token id="14" string="the" />
            <token id="15" string="spongiform" />
            <token id="16" string="&quot;" />
            <token id="17" string="mad" />
          </tokens>
        </chunking>
        <chunking id="17" string="makes the animals jittery before they keel over" type="VP">
          <tokens>
            <token id="23" string="makes" />
            <token id="24" string="the" />
            <token id="25" string="animals" />
            <token id="26" string="jittery" />
            <token id="27" string="before" />
            <token id="28" string="they" />
            <token id="29" string="keel" />
            <token id="30" string="over" />
          </tokens>
        </chunking>
        <chunking id="18" string="hopes of eradicating the spongiform `` mad" type="NP">
          <tokens>
            <token id="11" string="hopes" />
            <token id="12" string="of" />
            <token id="13" string="eradicating" />
            <token id="14" string="the" />
            <token id="15" string="spongiform" />
            <token id="16" string="&quot;" />
            <token id="17" string="mad" />
          </tokens>
        </chunking>
        <chunking id="19" string="eradicating the spongiform `` mad" type="VP">
          <tokens>
            <token id="13" string="eradicating" />
            <token id="14" string="the" />
            <token id="15" string="spongiform" />
            <token id="16" string="&quot;" />
            <token id="17" string="mad" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">cattle</governor>
          <dependent id="1">About</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="4">cattle</governor>
          <dependent id="2">20,000</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">cattle</governor>
          <dependent id="3">British</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">destroyed</governor>
          <dependent id="4">cattle</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">destroyed</governor>
          <dependent id="5">have</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="7">destroyed</governor>
          <dependent id="6">been</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">destroyed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">1986</governor>
          <dependent id="8">since</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">destroyed</governor>
          <dependent id="9">1986</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">hopes</governor>
          <dependent id="10">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">destroyed</governor>
          <dependent id="11">hopes</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">eradicating</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="11">hopes</governor>
          <dependent id="13">eradicating</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">spongiform</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="17">mad</governor>
          <dependent id="15">spongiform</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="13">eradicating</governor>
          <dependent id="17">mad</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">disease</governor>
          <dependent id="18">cow</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="7">destroyed</governor>
          <dependent id="20">disease</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">makes</governor>
          <dependent id="22">which</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="20">disease</governor>
          <dependent id="23">makes</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">animals</governor>
          <dependent id="24">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">keel</governor>
          <dependent id="25">animals</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="29">keel</governor>
          <dependent id="26">jittery</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="29">keel</governor>
          <dependent id="27">before</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">keel</governor>
          <dependent id="28">they</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="23">makes</governor>
          <dependent id="29">keel</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="29">keel</governor>
          <dependent id="30">over</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1986" type="DATE" score="0.0">
          <tokens>
            <token id="9" string="1986" />
          </tokens>
        </entity>
        <entity id="2" string="British" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="3" string="British" />
          </tokens>
        </entity>
        <entity id="3" string="disease" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="20" string="disease" />
          </tokens>
        </entity>
        <entity id="4" string="20,000" type="NUMBER" score="0.0">
          <tokens>
            <token id="2" string="20,000" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>A few weeks ago, the first confirmed case of mad cow disease outside Britain turned up in Switzerland.</content>
      <tokens>
        <token id="1" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="2" string="few" lemma="few" stem="few" pos="JJ" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="weeks" lemma="week" stem="week" pos="NNS" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="4" string="ago" lemma="ago" stem="ago" pos="RB" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="true" is_refers="false" />
        <token id="8" string="confirmed" lemma="confirm" stem="confirm" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="mad" lemma="mad" stem="mad" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="cow" lemma="cow" stem="cow" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="disease" lemma="disease" stem="diseas" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="14" string="outside" lemma="outside" stem="outsid" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="Britain" lemma="Britain" stem="britain" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="16" string="turned" lemma="turn" stem="turn" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="Switzerland" lemma="Switzerland" stem="switzerland" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (NP (DT A) (JJ few) (NNS weeks)) (RB ago)) (, ,) (NP (DT the) (JJ first)) (VP (VBN confirmed) (NP (NP (NN case)) (PP (IN of) (NP (NP (JJ mad) (NN cow) (NN disease) (JJ outside) (NNP Britain)) (VP (VBD turned) (PRT (RP up)) (PP (IN in) (NP (NNP Switzerland)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="A few weeks" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="few" />
            <token id="3" string="weeks" />
          </tokens>
        </chunking>
        <chunking id="2" string="case" type="NP">
          <tokens>
            <token id="9" string="case" />
          </tokens>
        </chunking>
        <chunking id="3" string="mad cow disease outside Britain turned up in Switzerland" type="NP">
          <tokens>
            <token id="11" string="mad" />
            <token id="12" string="cow" />
            <token id="13" string="disease" />
            <token id="14" string="outside" />
            <token id="15" string="Britain" />
            <token id="16" string="turned" />
            <token id="17" string="up" />
            <token id="18" string="in" />
            <token id="19" string="Switzerland" />
          </tokens>
        </chunking>
        <chunking id="4" string="mad cow disease outside Britain" type="NP">
          <tokens>
            <token id="11" string="mad" />
            <token id="12" string="cow" />
            <token id="13" string="disease" />
            <token id="14" string="outside" />
            <token id="15" string="Britain" />
          </tokens>
        </chunking>
        <chunking id="5" string="turned up in Switzerland" type="VP">
          <tokens>
            <token id="16" string="turned" />
            <token id="17" string="up" />
            <token id="18" string="in" />
            <token id="19" string="Switzerland" />
          </tokens>
        </chunking>
        <chunking id="6" string="the first" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="first" />
          </tokens>
        </chunking>
        <chunking id="7" string="Switzerland" type="NP">
          <tokens>
            <token id="19" string="Switzerland" />
          </tokens>
        </chunking>
        <chunking id="8" string="confirmed case of mad cow disease outside Britain turned up in Switzerland" type="VP">
          <tokens>
            <token id="8" string="confirmed" />
            <token id="9" string="case" />
            <token id="10" string="of" />
            <token id="11" string="mad" />
            <token id="12" string="cow" />
            <token id="13" string="disease" />
            <token id="14" string="outside" />
            <token id="15" string="Britain" />
            <token id="16" string="turned" />
            <token id="17" string="up" />
            <token id="18" string="in" />
            <token id="19" string="Switzerland" />
          </tokens>
        </chunking>
        <chunking id="9" string="case of mad cow disease outside Britain turned up in Switzerland" type="NP">
          <tokens>
            <token id="9" string="case" />
            <token id="10" string="of" />
            <token id="11" string="mad" />
            <token id="12" string="cow" />
            <token id="13" string="disease" />
            <token id="14" string="outside" />
            <token id="15" string="Britain" />
            <token id="16" string="turned" />
            <token id="17" string="up" />
            <token id="18" string="in" />
            <token id="19" string="Switzerland" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">weeks</governor>
          <dependent id="1">A</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">weeks</governor>
          <dependent id="2">few</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="4">ago</governor>
          <dependent id="3">weeks</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">confirmed</governor>
          <dependent id="4">ago</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">first</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">confirmed</governor>
          <dependent id="7">first</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">confirmed</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">confirmed</governor>
          <dependent id="9">case</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">Britain</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">Britain</governor>
          <dependent id="11">mad</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Britain</governor>
          <dependent id="12">cow</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Britain</governor>
          <dependent id="13">disease</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">Britain</governor>
          <dependent id="14">outside</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">case</governor>
          <dependent id="15">Britain</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="15">Britain</governor>
          <dependent id="16">turned</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="16">turned</governor>
          <dependent id="17">up</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">Switzerland</governor>
          <dependent id="18">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">turned</governor>
          <dependent id="19">Switzerland</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="7" string="first" />
          </tokens>
        </entity>
        <entity id="2" string="disease" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="13" string="disease" />
          </tokens>
        </entity>
        <entity id="3" string="Britain" type="LOCATION" score="0.0">
          <tokens>
            <token id="15" string="Britain" />
          </tokens>
        </entity>
        <entity id="4" string="Switzerland" type="LOCATION" score="0.0">
          <tokens>
            <token id="19" string="Switzerland" />
          </tokens>
        </entity>
        <entity id="5" string="A few weeks ago" type="DATE" score="0.0">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="few" />
            <token id="3" string="weeks" />
            <token id="4" string="ago" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="16" has_coreference="false">
      <content>U.S. meat producers have reason to be anxious about this because the incidence of scrapie has been rising in American sheep since the mid-1980s, says Richard Marsh, a University of Wisconsin scrapie expert.</content>
      <tokens>
        <token id="1" string="U.S." lemma="U.S." stem="u.s." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="2" string="meat" lemma="meat" stem="meat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="producers" lemma="producer" stem="produc" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="reason" lemma="reason" stem="reason" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="anxious" lemma="anxious" stem="anxiou" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="incidence" lemma="incidence" stem="incid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="scrapie" lemma="scrapie" stem="scrapi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="rising" lemma="rise" stem="rise" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="American" lemma="american" stem="american" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="21" string="sheep" lemma="sheep" stem="sheep" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="since" lemma="since" stem="sinc" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="24" string="mid-1980s" lemma="mid-1980" stem="mid-1980" pos="NNS" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="25" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="Richard" lemma="Richard" stem="richard" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="28" string="Marsh" lemma="Marsh" stem="marsh" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="29" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="University" lemma="University" stem="univers" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="32" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="33" string="Wisconsin" lemma="Wisconsin" stem="wisconsin" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="34" string="scrapie" lemma="scrapie" stem="scrapi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="expert" lemma="expert" stem="expert" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (S (NP (NNP U.S.) (NN meat) (NNS producers)) (VP (VBP have) (NP (NN reason) (S (VP (TO to) (VP (VB be) (ADJP (JJ anxious) (PP (IN about) (NP (DT this)))) (SBAR (IN because) (S (NP (NP (DT the) (NN incidence)) (PP (IN of) (NP (NN scrapie)))) (VP (VBZ has) (VP (VBN been) (VP (VBG rising) (PP (IN in) (NP (NP (JJ American) (NN sheep)) (PP (IN since) (NP (DT the) (NNS mid-1980s)))))))))))))))) (, ,) (VP (VBZ says)) (NP (NP (NNP Richard) (NNP Marsh)) (, ,) (NP (DT a) (NAC (NNP University) (PP (IN of) (NP (NNP Wisconsin)))) (NN scrapie) (NN expert))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the incidence of scrapie" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="incidence" />
            <token id="14" string="of" />
            <token id="15" string="scrapie" />
          </tokens>
        </chunking>
        <chunking id="2" string="American sheep" type="NP">
          <tokens>
            <token id="20" string="American" />
            <token id="21" string="sheep" />
          </tokens>
        </chunking>
        <chunking id="3" string="because the incidence of scrapie has been rising in American sheep since the mid-1980s" type="SBAR">
          <tokens>
            <token id="11" string="because" />
            <token id="12" string="the" />
            <token id="13" string="incidence" />
            <token id="14" string="of" />
            <token id="15" string="scrapie" />
            <token id="16" string="has" />
            <token id="17" string="been" />
            <token id="18" string="rising" />
            <token id="19" string="in" />
            <token id="20" string="American" />
            <token id="21" string="sheep" />
            <token id="22" string="since" />
            <token id="23" string="the" />
            <token id="24" string="mid-1980s" />
          </tokens>
        </chunking>
        <chunking id="4" string="rising in American sheep since the mid-1980s" type="VP">
          <tokens>
            <token id="18" string="rising" />
            <token id="19" string="in" />
            <token id="20" string="American" />
            <token id="21" string="sheep" />
            <token id="22" string="since" />
            <token id="23" string="the" />
            <token id="24" string="mid-1980s" />
          </tokens>
        </chunking>
        <chunking id="5" string="the mid-1980s" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="mid-1980s" />
          </tokens>
        </chunking>
        <chunking id="6" string="this" type="NP">
          <tokens>
            <token id="10" string="this" />
          </tokens>
        </chunking>
        <chunking id="7" string="Richard Marsh" type="NP">
          <tokens>
            <token id="27" string="Richard" />
            <token id="28" string="Marsh" />
          </tokens>
        </chunking>
        <chunking id="8" string="a University of Wisconsin scrapie expert" type="NP">
          <tokens>
            <token id="30" string="a" />
            <token id="31" string="University" />
            <token id="32" string="of" />
            <token id="33" string="Wisconsin" />
            <token id="34" string="scrapie" />
            <token id="35" string="expert" />
          </tokens>
        </chunking>
        <chunking id="9" string="have reason to be anxious about this because the incidence of scrapie has been rising in American sheep since the mid-1980s" type="VP">
          <tokens>
            <token id="4" string="have" />
            <token id="5" string="reason" />
            <token id="6" string="to" />
            <token id="7" string="be" />
            <token id="8" string="anxious" />
            <token id="9" string="about" />
            <token id="10" string="this" />
            <token id="11" string="because" />
            <token id="12" string="the" />
            <token id="13" string="incidence" />
            <token id="14" string="of" />
            <token id="15" string="scrapie" />
            <token id="16" string="has" />
            <token id="17" string="been" />
            <token id="18" string="rising" />
            <token id="19" string="in" />
            <token id="20" string="American" />
            <token id="21" string="sheep" />
            <token id="22" string="since" />
            <token id="23" string="the" />
            <token id="24" string="mid-1980s" />
          </tokens>
        </chunking>
        <chunking id="10" string="been rising in American sheep since the mid-1980s" type="VP">
          <tokens>
            <token id="17" string="been" />
            <token id="18" string="rising" />
            <token id="19" string="in" />
            <token id="20" string="American" />
            <token id="21" string="sheep" />
            <token id="22" string="since" />
            <token id="23" string="the" />
            <token id="24" string="mid-1980s" />
          </tokens>
        </chunking>
        <chunking id="11" string="says" type="VP">
          <tokens>
            <token id="26" string="says" />
          </tokens>
        </chunking>
        <chunking id="12" string="American sheep since the mid-1980s" type="NP">
          <tokens>
            <token id="20" string="American" />
            <token id="21" string="sheep" />
            <token id="22" string="since" />
            <token id="23" string="the" />
            <token id="24" string="mid-1980s" />
          </tokens>
        </chunking>
        <chunking id="13" string="has been rising in American sheep since the mid-1980s" type="VP">
          <tokens>
            <token id="16" string="has" />
            <token id="17" string="been" />
            <token id="18" string="rising" />
            <token id="19" string="in" />
            <token id="20" string="American" />
            <token id="21" string="sheep" />
            <token id="22" string="since" />
            <token id="23" string="the" />
            <token id="24" string="mid-1980s" />
          </tokens>
        </chunking>
        <chunking id="14" string="reason to be anxious about this because the incidence of scrapie has been rising in American sheep since the mid-1980s" type="NP">
          <tokens>
            <token id="5" string="reason" />
            <token id="6" string="to" />
            <token id="7" string="be" />
            <token id="8" string="anxious" />
            <token id="9" string="about" />
            <token id="10" string="this" />
            <token id="11" string="because" />
            <token id="12" string="the" />
            <token id="13" string="incidence" />
            <token id="14" string="of" />
            <token id="15" string="scrapie" />
            <token id="16" string="has" />
            <token id="17" string="been" />
            <token id="18" string="rising" />
            <token id="19" string="in" />
            <token id="20" string="American" />
            <token id="21" string="sheep" />
            <token id="22" string="since" />
            <token id="23" string="the" />
            <token id="24" string="mid-1980s" />
          </tokens>
        </chunking>
        <chunking id="15" string="the incidence" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="incidence" />
          </tokens>
        </chunking>
        <chunking id="16" string="Richard Marsh , a University of Wisconsin scrapie expert" type="NP">
          <tokens>
            <token id="27" string="Richard" />
            <token id="28" string="Marsh" />
            <token id="29" string="," />
            <token id="30" string="a" />
            <token id="31" string="University" />
            <token id="32" string="of" />
            <token id="33" string="Wisconsin" />
            <token id="34" string="scrapie" />
            <token id="35" string="expert" />
          </tokens>
        </chunking>
        <chunking id="17" string="U.S. meat producers" type="NP">
          <tokens>
            <token id="1" string="U.S." />
            <token id="2" string="meat" />
            <token id="3" string="producers" />
          </tokens>
        </chunking>
        <chunking id="18" string="scrapie" type="NP">
          <tokens>
            <token id="15" string="scrapie" />
          </tokens>
        </chunking>
        <chunking id="19" string="to be anxious about this because the incidence of scrapie has been rising in American sheep since the mid-1980s" type="VP">
          <tokens>
            <token id="6" string="to" />
            <token id="7" string="be" />
            <token id="8" string="anxious" />
            <token id="9" string="about" />
            <token id="10" string="this" />
            <token id="11" string="because" />
            <token id="12" string="the" />
            <token id="13" string="incidence" />
            <token id="14" string="of" />
            <token id="15" string="scrapie" />
            <token id="16" string="has" />
            <token id="17" string="been" />
            <token id="18" string="rising" />
            <token id="19" string="in" />
            <token id="20" string="American" />
            <token id="21" string="sheep" />
            <token id="22" string="since" />
            <token id="23" string="the" />
            <token id="24" string="mid-1980s" />
          </tokens>
        </chunking>
        <chunking id="20" string="be anxious about this because the incidence of scrapie has been rising in American sheep since the mid-1980s" type="VP">
          <tokens>
            <token id="7" string="be" />
            <token id="8" string="anxious" />
            <token id="9" string="about" />
            <token id="10" string="this" />
            <token id="11" string="because" />
            <token id="12" string="the" />
            <token id="13" string="incidence" />
            <token id="14" string="of" />
            <token id="15" string="scrapie" />
            <token id="16" string="has" />
            <token id="17" string="been" />
            <token id="18" string="rising" />
            <token id="19" string="in" />
            <token id="20" string="American" />
            <token id="21" string="sheep" />
            <token id="22" string="since" />
            <token id="23" string="the" />
            <token id="24" string="mid-1980s" />
          </tokens>
        </chunking>
        <chunking id="21" string="anxious about this" type="ADJP">
          <tokens>
            <token id="8" string="anxious" />
            <token id="9" string="about" />
            <token id="10" string="this" />
          </tokens>
        </chunking>
        <chunking id="22" string="Wisconsin" type="NP">
          <tokens>
            <token id="33" string="Wisconsin" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">producers</governor>
          <dependent id="1">U.S.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">producers</governor>
          <dependent id="2">meat</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">have</governor>
          <dependent id="3">producers</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="26">says</governor>
          <dependent id="4">have</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">have</governor>
          <dependent id="5">reason</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">anxious</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="8">anxious</governor>
          <dependent id="7">be</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="5">reason</governor>
          <dependent id="8">anxious</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">this</governor>
          <dependent id="9">about</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">anxious</governor>
          <dependent id="10">this</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">rising</governor>
          <dependent id="11">because</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">incidence</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">rising</governor>
          <dependent id="13">incidence</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">scrapie</governor>
          <dependent id="14">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">incidence</governor>
          <dependent id="15">scrapie</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="18">rising</governor>
          <dependent id="16">has</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="18">rising</governor>
          <dependent id="17">been</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="8">anxious</governor>
          <dependent id="18">rising</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">sheep</governor>
          <dependent id="19">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">sheep</governor>
          <dependent id="20">American</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">rising</governor>
          <dependent id="21">sheep</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">mid-1980s</governor>
          <dependent id="22">since</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">mid-1980s</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">sheep</governor>
          <dependent id="24">mid-1980s</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="26">says</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">Marsh</governor>
          <dependent id="27">Richard</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">says</governor>
          <dependent id="28">Marsh</dependent>
        </dependency>
        <dependency type="det">
          <governor id="35">expert</governor>
          <dependent id="30">a</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="35">expert</governor>
          <dependent id="31">University</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">Wisconsin</governor>
          <dependent id="32">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">University</governor>
          <dependent id="33">Wisconsin</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="35">expert</governor>
          <dependent id="34">scrapie</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="28">Marsh</governor>
          <dependent id="35">expert</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="U.S." type="LOCATION" score="0.0">
          <tokens>
            <token id="1" string="U.S." />
          </tokens>
        </entity>
        <entity id="2" string="the mid-1980s" type="DATE" score="0.0">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="mid-1980s" />
          </tokens>
        </entity>
        <entity id="3" string="American" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="20" string="American" />
          </tokens>
        </entity>
        <entity id="4" string="University of Wisconsin" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="31" string="University" />
            <token id="32" string="of" />
            <token id="33" string="Wisconsin" />
          </tokens>
        </entity>
        <entity id="5" string="Richard Marsh" type="PERSON" score="0.0">
          <tokens>
            <token id="27" string="Richard" />
            <token id="28" string="Marsh" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="17" has_coreference="true">
      <content>Scientists agree, however, that the disease in animals probably poses little danger to people.</content>
      <tokens>
        <token id="1" string="Scientists" lemma="scientist" stem="scientist" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="2" string="agree" lemma="agree" stem="agre" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="however" lemma="however" stem="howev" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="disease" lemma="disease" stem="diseas" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="true" />
        <token id="9" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="animals" lemma="animal" stem="anim" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="probably" lemma="probably" stem="probabl" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="poses" lemma="pose" stem="pose" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="little" lemma="little" stem="littl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="danger" lemma="danger" stem="danger" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNS Scientists)) (VP (VBP agree) (, ,) (ADVP (RB however)) (, ,) (SBAR (IN that) (S (NP (NP (DT the) (NN disease)) (PP (IN in) (NP (NNS animals)))) (ADVP (RB probably)) (VP (VBZ poses) (NP (JJ little) (NN danger)) (PP (TO to) (NP (NNS people))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the disease" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="disease" />
          </tokens>
        </chunking>
        <chunking id="2" string="the disease in animals" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="disease" />
            <token id="9" string="in" />
            <token id="10" string="animals" />
          </tokens>
        </chunking>
        <chunking id="3" string="agree , however , that the disease in animals probably poses little danger to people" type="VP">
          <tokens>
            <token id="2" string="agree" />
            <token id="3" string="," />
            <token id="4" string="however" />
            <token id="5" string="," />
            <token id="6" string="that" />
            <token id="7" string="the" />
            <token id="8" string="disease" />
            <token id="9" string="in" />
            <token id="10" string="animals" />
            <token id="11" string="probably" />
            <token id="12" string="poses" />
            <token id="13" string="little" />
            <token id="14" string="danger" />
            <token id="15" string="to" />
            <token id="16" string="people" />
          </tokens>
        </chunking>
        <chunking id="4" string="that the disease in animals probably poses little danger to people" type="SBAR">
          <tokens>
            <token id="6" string="that" />
            <token id="7" string="the" />
            <token id="8" string="disease" />
            <token id="9" string="in" />
            <token id="10" string="animals" />
            <token id="11" string="probably" />
            <token id="12" string="poses" />
            <token id="13" string="little" />
            <token id="14" string="danger" />
            <token id="15" string="to" />
            <token id="16" string="people" />
          </tokens>
        </chunking>
        <chunking id="5" string="poses little danger to people" type="VP">
          <tokens>
            <token id="12" string="poses" />
            <token id="13" string="little" />
            <token id="14" string="danger" />
            <token id="15" string="to" />
            <token id="16" string="people" />
          </tokens>
        </chunking>
        <chunking id="6" string="Scientists" type="NP">
          <tokens>
            <token id="1" string="Scientists" />
          </tokens>
        </chunking>
        <chunking id="7" string="animals" type="NP">
          <tokens>
            <token id="10" string="animals" />
          </tokens>
        </chunking>
        <chunking id="8" string="little danger" type="NP">
          <tokens>
            <token id="13" string="little" />
            <token id="14" string="danger" />
          </tokens>
        </chunking>
        <chunking id="9" string="people" type="NP">
          <tokens>
            <token id="16" string="people" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">agree</governor>
          <dependent id="1">Scientists</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">agree</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="2">agree</governor>
          <dependent id="4">however</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">poses</governor>
          <dependent id="6">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">disease</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">poses</governor>
          <dependent id="8">disease</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">animals</governor>
          <dependent id="9">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">disease</governor>
          <dependent id="10">animals</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">poses</governor>
          <dependent id="11">probably</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">agree</governor>
          <dependent id="12">poses</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">danger</governor>
          <dependent id="13">little</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">poses</governor>
          <dependent id="14">danger</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">people</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">poses</governor>
          <dependent id="16">people</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="disease" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="8" string="disease" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="18" has_coreference="true">
      <content>Scrapie has existed for centuries and &amp;quot;the world is bathed&amp;quot; in its infectious agent, says Dr. Gajdusek.</content>
      <tokens>
        <token id="1" string="Scrapie" lemma="Scrapie" stem="scrapi" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="existed" lemma="exist" stem="exist" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="centuries" lemma="century" stem="centuri" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="6" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="bathed" lemma="bath" stem="bath" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="infectious" lemma="infectious" stem="infecti" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="agent" lemma="agent" stem="agent" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="Dr." lemma="Dr." stem="dr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="Gajdusek" lemma="Gajdusek" stem="gajdusek" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (S (S (NP (NNP Scrapie)) (VP (VBZ has) (VP (VBN existed) (PP (IN for) (NP (NNS centuries)))))) (CC and) (S (`` ``) (NP (DT the) (NN world)) (VP (VBZ is) (VP (VBN bathed) ('' '') (PP (IN in) (NP (PRP$ its) (JJ infectious) (NN agent))))))) (, ,) (VP (VBZ says)) (NP (NNP Dr.) (NNP Gajdusek)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="bathed '' in its infectious agent" type="VP">
          <tokens>
            <token id="11" string="bathed" />
            <token id="12" string="&quot;" />
            <token id="13" string="in" />
            <token id="14" string="its" />
            <token id="15" string="infectious" />
            <token id="16" string="agent" />
          </tokens>
        </chunking>
        <chunking id="2" string="centuries" type="NP">
          <tokens>
            <token id="5" string="centuries" />
          </tokens>
        </chunking>
        <chunking id="3" string="says" type="VP">
          <tokens>
            <token id="18" string="says" />
          </tokens>
        </chunking>
        <chunking id="4" string="Scrapie" type="NP">
          <tokens>
            <token id="1" string="Scrapie" />
          </tokens>
        </chunking>
        <chunking id="5" string="Dr. Gajdusek" type="NP">
          <tokens>
            <token id="19" string="Dr." />
            <token id="20" string="Gajdusek" />
          </tokens>
        </chunking>
        <chunking id="6" string="has existed for centuries" type="VP">
          <tokens>
            <token id="2" string="has" />
            <token id="3" string="existed" />
            <token id="4" string="for" />
            <token id="5" string="centuries" />
          </tokens>
        </chunking>
        <chunking id="7" string="existed for centuries" type="VP">
          <tokens>
            <token id="3" string="existed" />
            <token id="4" string="for" />
            <token id="5" string="centuries" />
          </tokens>
        </chunking>
        <chunking id="8" string="its infectious agent" type="NP">
          <tokens>
            <token id="14" string="its" />
            <token id="15" string="infectious" />
            <token id="16" string="agent" />
          </tokens>
        </chunking>
        <chunking id="9" string="the world" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="world" />
          </tokens>
        </chunking>
        <chunking id="10" string="is bathed '' in its infectious agent" type="VP">
          <tokens>
            <token id="10" string="is" />
            <token id="11" string="bathed" />
            <token id="12" string="&quot;" />
            <token id="13" string="in" />
            <token id="14" string="its" />
            <token id="15" string="infectious" />
            <token id="16" string="agent" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">existed</governor>
          <dependent id="1">Scrapie</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="3">existed</governor>
          <dependent id="2">has</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="18">says</governor>
          <dependent id="3">existed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">centuries</governor>
          <dependent id="4">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">existed</governor>
          <dependent id="5">centuries</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">existed</governor>
          <dependent id="6">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">world</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="11">bathed</governor>
          <dependent id="9">world</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="11">bathed</governor>
          <dependent id="10">is</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">existed</governor>
          <dependent id="11">bathed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">agent</governor>
          <dependent id="13">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="16">agent</governor>
          <dependent id="14">its</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">agent</governor>
          <dependent id="15">infectious</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">bathed</governor>
          <dependent id="16">agent</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="18">says</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">Gajdusek</governor>
          <dependent id="19">Dr.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">says</governor>
          <dependent id="20">Gajdusek</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="centuries" type="DURATION" score="0.0">
          <tokens>
            <token id="5" string="centuries" />
          </tokens>
        </entity>
        <entity id="2" string="Gajdusek" type="PERSON" score="0.0">
          <tokens>
            <token id="20" string="Gajdusek" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="19" has_coreference="true">
      <content>Yet sheep have never been strongly implicated in cases of the human form of the disease, Creutzfeldt-Jakob disease, or CJD.</content>
      <tokens>
        <token id="1" string="Yet" lemma="yet" stem="yet" pos="CC" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="sheep" lemma="sheep" stem="sheep" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="strongly" lemma="strongly" stem="strongli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="implicated" lemma="implicate" stem="implic" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="cases" lemma="case" stem="case" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="human" lemma="human" stem="human" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="form" lemma="form" stem="form" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="disease" lemma="disease" stem="diseas" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="true" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="Creutzfeldt-Jakob" lemma="creutzfeldt-jakob" stem="creutzfeldt-jakob" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="19" string="disease" lemma="disease" stem="diseas" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="true" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="CJD" lemma="CJD" stem="cjd" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC Yet) (NP (NN sheep)) (VP (VBP have) (ADVP (RB never)) (VP (VBN been) (VP (ADVP (RB strongly)) (VBN implicated) (PP (IN in) (NP (NP (NNS cases)) (PP (IN of) (NP (NP (DT the) (JJ human) (NN form)) (PP (IN of) (NP (NP (DT the) (NN disease)) (, ,) (NP (JJ Creutzfeldt-Jakob) (NN disease)) (, ,) (CC or) (NP (NNP CJD))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the disease" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="disease" />
          </tokens>
        </chunking>
        <chunking id="2" string="cases" type="NP">
          <tokens>
            <token id="9" string="cases" />
          </tokens>
        </chunking>
        <chunking id="3" string="the human form" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="human" />
            <token id="13" string="form" />
          </tokens>
        </chunking>
        <chunking id="4" string="Creutzfeldt-Jakob disease" type="NP">
          <tokens>
            <token id="18" string="Creutzfeldt-Jakob" />
            <token id="19" string="disease" />
          </tokens>
        </chunking>
        <chunking id="5" string="the disease , Creutzfeldt-Jakob disease , or CJD" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="disease" />
            <token id="17" string="," />
            <token id="18" string="Creutzfeldt-Jakob" />
            <token id="19" string="disease" />
            <token id="20" string="," />
            <token id="21" string="or" />
            <token id="22" string="CJD" />
          </tokens>
        </chunking>
        <chunking id="6" string="strongly implicated in cases of the human form of the disease , Creutzfeldt-Jakob disease , or CJD" type="VP">
          <tokens>
            <token id="6" string="strongly" />
            <token id="7" string="implicated" />
            <token id="8" string="in" />
            <token id="9" string="cases" />
            <token id="10" string="of" />
            <token id="11" string="the" />
            <token id="12" string="human" />
            <token id="13" string="form" />
            <token id="14" string="of" />
            <token id="15" string="the" />
            <token id="16" string="disease" />
            <token id="17" string="," />
            <token id="18" string="Creutzfeldt-Jakob" />
            <token id="19" string="disease" />
            <token id="20" string="," />
            <token id="21" string="or" />
            <token id="22" string="CJD" />
          </tokens>
        </chunking>
        <chunking id="7" string="cases of the human form of the disease , Creutzfeldt-Jakob disease , or CJD" type="NP">
          <tokens>
            <token id="9" string="cases" />
            <token id="10" string="of" />
            <token id="11" string="the" />
            <token id="12" string="human" />
            <token id="13" string="form" />
            <token id="14" string="of" />
            <token id="15" string="the" />
            <token id="16" string="disease" />
            <token id="17" string="," />
            <token id="18" string="Creutzfeldt-Jakob" />
            <token id="19" string="disease" />
            <token id="20" string="," />
            <token id="21" string="or" />
            <token id="22" string="CJD" />
          </tokens>
        </chunking>
        <chunking id="8" string="have never been strongly implicated in cases of the human form of the disease , Creutzfeldt-Jakob disease , or CJD" type="VP">
          <tokens>
            <token id="3" string="have" />
            <token id="4" string="never" />
            <token id="5" string="been" />
            <token id="6" string="strongly" />
            <token id="7" string="implicated" />
            <token id="8" string="in" />
            <token id="9" string="cases" />
            <token id="10" string="of" />
            <token id="11" string="the" />
            <token id="12" string="human" />
            <token id="13" string="form" />
            <token id="14" string="of" />
            <token id="15" string="the" />
            <token id="16" string="disease" />
            <token id="17" string="," />
            <token id="18" string="Creutzfeldt-Jakob" />
            <token id="19" string="disease" />
            <token id="20" string="," />
            <token id="21" string="or" />
            <token id="22" string="CJD" />
          </tokens>
        </chunking>
        <chunking id="9" string="been strongly implicated in cases of the human form of the disease , Creutzfeldt-Jakob disease , or CJD" type="VP">
          <tokens>
            <token id="5" string="been" />
            <token id="6" string="strongly" />
            <token id="7" string="implicated" />
            <token id="8" string="in" />
            <token id="9" string="cases" />
            <token id="10" string="of" />
            <token id="11" string="the" />
            <token id="12" string="human" />
            <token id="13" string="form" />
            <token id="14" string="of" />
            <token id="15" string="the" />
            <token id="16" string="disease" />
            <token id="17" string="," />
            <token id="18" string="Creutzfeldt-Jakob" />
            <token id="19" string="disease" />
            <token id="20" string="," />
            <token id="21" string="or" />
            <token id="22" string="CJD" />
          </tokens>
        </chunking>
        <chunking id="10" string="the human form of the disease , Creutzfeldt-Jakob disease , or CJD" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="human" />
            <token id="13" string="form" />
            <token id="14" string="of" />
            <token id="15" string="the" />
            <token id="16" string="disease" />
            <token id="17" string="," />
            <token id="18" string="Creutzfeldt-Jakob" />
            <token id="19" string="disease" />
            <token id="20" string="," />
            <token id="21" string="or" />
            <token id="22" string="CJD" />
          </tokens>
        </chunking>
        <chunking id="11" string="CJD" type="NP">
          <tokens>
            <token id="22" string="CJD" />
          </tokens>
        </chunking>
        <chunking id="12" string="sheep" type="NP">
          <tokens>
            <token id="2" string="sheep" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="7">implicated</governor>
          <dependent id="1">Yet</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="7">implicated</governor>
          <dependent id="2">sheep</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">implicated</governor>
          <dependent id="3">have</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="7">implicated</governor>
          <dependent id="4">never</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="7">implicated</governor>
          <dependent id="5">been</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">implicated</governor>
          <dependent id="6">strongly</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">implicated</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">cases</governor>
          <dependent id="8">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">implicated</governor>
          <dependent id="9">cases</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">form</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">form</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">form</governor>
          <dependent id="12">human</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">cases</governor>
          <dependent id="13">form</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">disease</governor>
          <dependent id="14">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">disease</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">form</governor>
          <dependent id="16">disease</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">disease</governor>
          <dependent id="18">Creutzfeldt-Jakob</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">disease</governor>
          <dependent id="19">disease</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="16">disease</governor>
          <dependent id="21">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">disease</governor>
          <dependent id="22">CJD</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="disease" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="16" string="disease" />
          </tokens>
        </entity>
        <entity id="2" string="Creutzfeldt-Jakob" type="MISC" score="0.0">
          <tokens>
            <token id="18" string="Creutzfeldt-Jakob" />
          </tokens>
        </entity>
        <entity id="3" string="CJD" type="MISC" score="0.0">
          <tokens>
            <token id="22" string="CJD" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="20" has_coreference="true">
      <content>At least not until the Poltar journalist and two other people died of CJD at about the same time in a rural, sheep-herding part of eastern Czechoslovakia.</content>
      <tokens>
        <token id="1" string="At" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="least" lemma="least" stem="least" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="until" lemma="until" stem="until" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Poltar" lemma="poltar" stem="poltar" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="7" string="journalist" lemma="journalist" stem="journalist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="10" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="died" lemma="die" stem="di" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="CJD" lemma="cjd" stem="cjd" pos="NN" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="15" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="same" lemma="same" stem="same" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="rural" lemma="rural" stem="rural" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="sheep-herding" lemma="sheep-herding" stem="sheep-herd" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="part" lemma="part" stem="part" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="eastern" lemma="eastern" stem="eastern" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="28" string="Czechoslovakia" lemma="Czechoslovakia" stem="czechoslovakia" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (FRAG (ADVP (IN At) (JJS least)) (RB not) (PP (IN until) (NP (NP (DT the) (JJ Poltar) (NN journalist)) (CC and) (NP (NP (CD two) (JJ other) (NNS people)) (SBAR (S (VP (VBD died) (PP (IN of) (NP (NN CJD))) (PP (IN at) (IN about) (NP (NP (DT the) (JJ same) (NN time)) (PP (IN in) (NP (NP (DT a) (JJ rural) (, ,) (JJ sheep-herding) (NN part)) (PP (IN of) (NP (JJ eastern) (NNP Czechoslovakia))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="two other people died of CJD at about the same time in a rural , sheep-herding part of eastern Czechoslovakia" type="NP">
          <tokens>
            <token id="9" string="two" />
            <token id="10" string="other" />
            <token id="11" string="people" />
            <token id="12" string="died" />
            <token id="13" string="of" />
            <token id="14" string="CJD" />
            <token id="15" string="at" />
            <token id="16" string="about" />
            <token id="17" string="the" />
            <token id="18" string="same" />
            <token id="19" string="time" />
            <token id="20" string="in" />
            <token id="21" string="a" />
            <token id="22" string="rural" />
            <token id="23" string="," />
            <token id="24" string="sheep-herding" />
            <token id="25" string="part" />
            <token id="26" string="of" />
            <token id="27" string="eastern" />
            <token id="28" string="Czechoslovakia" />
          </tokens>
        </chunking>
        <chunking id="2" string="died of CJD at about the same time in a rural , sheep-herding part of eastern Czechoslovakia" type="SBAR">
          <tokens>
            <token id="12" string="died" />
            <token id="13" string="of" />
            <token id="14" string="CJD" />
            <token id="15" string="at" />
            <token id="16" string="about" />
            <token id="17" string="the" />
            <token id="18" string="same" />
            <token id="19" string="time" />
            <token id="20" string="in" />
            <token id="21" string="a" />
            <token id="22" string="rural" />
            <token id="23" string="," />
            <token id="24" string="sheep-herding" />
            <token id="25" string="part" />
            <token id="26" string="of" />
            <token id="27" string="eastern" />
            <token id="28" string="Czechoslovakia" />
          </tokens>
        </chunking>
        <chunking id="3" string="eastern Czechoslovakia" type="NP">
          <tokens>
            <token id="27" string="eastern" />
            <token id="28" string="Czechoslovakia" />
          </tokens>
        </chunking>
        <chunking id="4" string="the Poltar journalist" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="Poltar" />
            <token id="7" string="journalist" />
          </tokens>
        </chunking>
        <chunking id="5" string="the same time in a rural , sheep-herding part of eastern Czechoslovakia" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="same" />
            <token id="19" string="time" />
            <token id="20" string="in" />
            <token id="21" string="a" />
            <token id="22" string="rural" />
            <token id="23" string="," />
            <token id="24" string="sheep-herding" />
            <token id="25" string="part" />
            <token id="26" string="of" />
            <token id="27" string="eastern" />
            <token id="28" string="Czechoslovakia" />
          </tokens>
        </chunking>
        <chunking id="6" string="the same time" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="same" />
            <token id="19" string="time" />
          </tokens>
        </chunking>
        <chunking id="7" string="a rural , sheep-herding part of eastern Czechoslovakia" type="NP">
          <tokens>
            <token id="21" string="a" />
            <token id="22" string="rural" />
            <token id="23" string="," />
            <token id="24" string="sheep-herding" />
            <token id="25" string="part" />
            <token id="26" string="of" />
            <token id="27" string="eastern" />
            <token id="28" string="Czechoslovakia" />
          </tokens>
        </chunking>
        <chunking id="8" string="two other people" type="NP">
          <tokens>
            <token id="9" string="two" />
            <token id="10" string="other" />
            <token id="11" string="people" />
          </tokens>
        </chunking>
        <chunking id="9" string="CJD" type="NP">
          <tokens>
            <token id="14" string="CJD" />
          </tokens>
        </chunking>
        <chunking id="10" string="a rural , sheep-herding part" type="NP">
          <tokens>
            <token id="21" string="a" />
            <token id="22" string="rural" />
            <token id="23" string="," />
            <token id="24" string="sheep-herding" />
            <token id="25" string="part" />
          </tokens>
        </chunking>
        <chunking id="11" string="the Poltar journalist and two other people died of CJD at about the same time in a rural , sheep-herding part of eastern Czechoslovakia" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="Poltar" />
            <token id="7" string="journalist" />
            <token id="8" string="and" />
            <token id="9" string="two" />
            <token id="10" string="other" />
            <token id="11" string="people" />
            <token id="12" string="died" />
            <token id="13" string="of" />
            <token id="14" string="CJD" />
            <token id="15" string="at" />
            <token id="16" string="about" />
            <token id="17" string="the" />
            <token id="18" string="same" />
            <token id="19" string="time" />
            <token id="20" string="in" />
            <token id="21" string="a" />
            <token id="22" string="rural" />
            <token id="23" string="," />
            <token id="24" string="sheep-herding" />
            <token id="25" string="part" />
            <token id="26" string="of" />
            <token id="27" string="eastern" />
            <token id="28" string="Czechoslovakia" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">least</governor>
          <dependent id="1">At</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="3">not</governor>
          <dependent id="2">least</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">not</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">journalist</governor>
          <dependent id="4">until</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">journalist</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">journalist</governor>
          <dependent id="6">Poltar</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">not</governor>
          <dependent id="7">journalist</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">journalist</governor>
          <dependent id="8">and</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="11">people</governor>
          <dependent id="9">two</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">people</governor>
          <dependent id="10">other</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">journalist</governor>
          <dependent id="11">people</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="11">people</governor>
          <dependent id="12">died</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">CJD</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">died</governor>
          <dependent id="14">CJD</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">time</governor>
          <dependent id="15">at</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">time</governor>
          <dependent id="16">about</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">time</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">time</governor>
          <dependent id="18">same</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">died</governor>
          <dependent id="19">time</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">part</governor>
          <dependent id="20">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">part</governor>
          <dependent id="21">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">part</governor>
          <dependent id="22">rural</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">part</governor>
          <dependent id="24">sheep-herding</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">time</governor>
          <dependent id="25">part</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">Czechoslovakia</governor>
          <dependent id="26">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">Czechoslovakia</governor>
          <dependent id="27">eastern</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">part</governor>
          <dependent id="28">Czechoslovakia</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Poltar" type="MISC" score="0.0">
          <tokens>
            <token id="6" string="Poltar" />
          </tokens>
        </entity>
        <entity id="2" string="Czechoslovakia" type="LOCATION" score="0.0">
          <tokens>
            <token id="28" string="Czechoslovakia" />
          </tokens>
        </entity>
        <entity id="3" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="9" string="two" />
          </tokens>
        </entity>
        <entity id="4" string="CJD" type="MISC" score="0.0">
          <tokens>
            <token id="14" string="CJD" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="21" has_coreference="true">
      <content>When Dr. Mitrova, a researcher at a Bratislava medical institute, heard of the unusual cluster of cases, she decided to investigate.</content>
      <tokens>
        <token id="1" string="When" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Dr." lemma="Dr." stem="dr." pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="Mitrova" lemma="Mitrova" stem="mitrova" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="researcher" lemma="researcher" stem="research" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="Bratislava" lemma="Bratislava" stem="bratislava" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="10" string="medical" lemma="medical" stem="medic" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="institute" lemma="institute" stem="institut" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="heard" lemma="hear" stem="heard" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="unusual" lemma="unusual" stem="unusu" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="cluster" lemma="cluster" stem="cluster" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="cases" lemma="case" stem="case" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="decided" lemma="decide" stem="decid" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="investigate" lemma="investigate" stem="investig" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (WHADVP (WRB When)) (S (NP (NP (NNP Dr.) (NNP Mitrova)) (, ,) (NP (NP (DT a) (NN researcher)) (PP (IN at) (NP (DT a) (NNP Bratislava) (JJ medical) (NN institute)))) (, ,)) (VP (VBN heard) (PP (IN of) (NP (NP (DT the) (JJ unusual) (NN cluster)) (PP (IN of) (NP (NNS cases)))))))) (, ,) (NP (PRP she)) (VP (VBD decided) (S (VP (TO to) (VP (VB investigate))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="to investigate" type="VP">
          <tokens>
            <token id="23" string="to" />
            <token id="24" string="investigate" />
          </tokens>
        </chunking>
        <chunking id="2" string="a Bratislava medical institute" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="Bratislava" />
            <token id="10" string="medical" />
            <token id="11" string="institute" />
          </tokens>
        </chunking>
        <chunking id="3" string="cases" type="NP">
          <tokens>
            <token id="19" string="cases" />
          </tokens>
        </chunking>
        <chunking id="4" string="the unusual cluster" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="unusual" />
            <token id="17" string="cluster" />
          </tokens>
        </chunking>
        <chunking id="5" string="a researcher at a Bratislava medical institute" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="researcher" />
            <token id="7" string="at" />
            <token id="8" string="a" />
            <token id="9" string="Bratislava" />
            <token id="10" string="medical" />
            <token id="11" string="institute" />
          </tokens>
        </chunking>
        <chunking id="6" string="investigate" type="VP">
          <tokens>
            <token id="24" string="investigate" />
          </tokens>
        </chunking>
        <chunking id="7" string="heard of the unusual cluster of cases" type="VP">
          <tokens>
            <token id="13" string="heard" />
            <token id="14" string="of" />
            <token id="15" string="the" />
            <token id="16" string="unusual" />
            <token id="17" string="cluster" />
            <token id="18" string="of" />
            <token id="19" string="cases" />
          </tokens>
        </chunking>
        <chunking id="8" string="Dr. Mitrova , a researcher at a Bratislava medical institute ," type="NP">
          <tokens>
            <token id="2" string="Dr." />
            <token id="3" string="Mitrova" />
            <token id="4" string="," />
            <token id="5" string="a" />
            <token id="6" string="researcher" />
            <token id="7" string="at" />
            <token id="8" string="a" />
            <token id="9" string="Bratislava" />
            <token id="10" string="medical" />
            <token id="11" string="institute" />
            <token id="12" string="," />
          </tokens>
        </chunking>
        <chunking id="9" string="she" type="NP">
          <tokens>
            <token id="21" string="she" />
          </tokens>
        </chunking>
        <chunking id="10" string="When Dr. Mitrova , a researcher at a Bratislava medical institute , heard of the unusual cluster of cases" type="SBAR">
          <tokens>
            <token id="1" string="When" />
            <token id="2" string="Dr." />
            <token id="3" string="Mitrova" />
            <token id="4" string="," />
            <token id="5" string="a" />
            <token id="6" string="researcher" />
            <token id="7" string="at" />
            <token id="8" string="a" />
            <token id="9" string="Bratislava" />
            <token id="10" string="medical" />
            <token id="11" string="institute" />
            <token id="12" string="," />
            <token id="13" string="heard" />
            <token id="14" string="of" />
            <token id="15" string="the" />
            <token id="16" string="unusual" />
            <token id="17" string="cluster" />
            <token id="18" string="of" />
            <token id="19" string="cases" />
          </tokens>
        </chunking>
        <chunking id="11" string="When" type="WHADVP">
          <tokens>
            <token id="1" string="When" />
          </tokens>
        </chunking>
        <chunking id="12" string="decided to investigate" type="VP">
          <tokens>
            <token id="22" string="decided" />
            <token id="23" string="to" />
            <token id="24" string="investigate" />
          </tokens>
        </chunking>
        <chunking id="13" string="Dr. Mitrova" type="NP">
          <tokens>
            <token id="2" string="Dr." />
            <token id="3" string="Mitrova" />
          </tokens>
        </chunking>
        <chunking id="14" string="a researcher" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="researcher" />
          </tokens>
        </chunking>
        <chunking id="15" string="the unusual cluster of cases" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="unusual" />
            <token id="17" string="cluster" />
            <token id="18" string="of" />
            <token id="19" string="cases" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="13">heard</governor>
          <dependent id="1">When</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Mitrova</governor>
          <dependent id="2">Dr.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">heard</governor>
          <dependent id="3">Mitrova</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">researcher</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="3">Mitrova</governor>
          <dependent id="6">researcher</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">institute</governor>
          <dependent id="7">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">institute</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">institute</governor>
          <dependent id="9">Bratislava</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">institute</governor>
          <dependent id="10">medical</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">researcher</governor>
          <dependent id="11">institute</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="22">decided</governor>
          <dependent id="13">heard</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">cluster</governor>
          <dependent id="14">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">cluster</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">cluster</governor>
          <dependent id="16">unusual</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">heard</governor>
          <dependent id="17">cluster</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">cases</governor>
          <dependent id="18">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">cluster</governor>
          <dependent id="19">cases</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">decided</governor>
          <dependent id="21">she</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="22">decided</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="24">investigate</governor>
          <dependent id="23">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="22">decided</governor>
          <dependent id="24">investigate</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Mitrova" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Mitrova" />
          </tokens>
        </entity>
        <entity id="2" string="Bratislava" type="LOCATION" score="0.0">
          <tokens>
            <token id="9" string="Bratislava" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="22" has_coreference="true">
      <content>From the first, one clue stood out like a bloodstain: &amp;quot;Almost all of the people are involved in raising and taking care of sheep,&amp;quot; she says.</content>
      <tokens>
        <token id="1" string="From" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="true" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="6" string="clue" lemma="clue" stem="clue" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="stood" lemma="stand" stem="stood" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="bloodstain" lemma="bloodstain" stem="bloodstain" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Almost" lemma="almost" stem="almost" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="involved" lemma="involve" stem="involv" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="raising" lemma="raise" stem="rais" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="taking" lemma="take" stem="take" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="care" lemma="care" stem="care" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="sheep" lemma="sheep" stem="sheep" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (PP (IN From) (NP (DT the) (JJ first))) (, ,) (NP (CD one) (NN clue)) (VP (VBD stood) (PRT (RP out)) (PP (IN like) (NP (DT a) (NN bloodstain))))) (: :) (S (`` ``) (S (NP (NP (RB Almost) (DT all)) (PP (IN of) (NP (DT the) (NNS people)))) (VP (VBP are) (ADJP (VBN involved) (PP (IN in) (S (VP (VBG raising) (CC and) (VBG taking) (NP (NP (NN care)) (PP (IN of) (NP (NN sheep)))))))))) (, ,) ('' '') (NP (PRP she)) (VP (VBZ says))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="raising and taking care of sheep" type="VP">
          <tokens>
            <token id="22" string="raising" />
            <token id="23" string="and" />
            <token id="24" string="taking" />
            <token id="25" string="care" />
            <token id="26" string="of" />
            <token id="27" string="sheep" />
          </tokens>
        </chunking>
        <chunking id="2" string="Almost all" type="NP">
          <tokens>
            <token id="14" string="Almost" />
            <token id="15" string="all" />
          </tokens>
        </chunking>
        <chunking id="3" string="one clue" type="NP">
          <tokens>
            <token id="5" string="one" />
            <token id="6" string="clue" />
          </tokens>
        </chunking>
        <chunking id="4" string="the people" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="people" />
          </tokens>
        </chunking>
        <chunking id="5" string="stood out like a bloodstain" type="VP">
          <tokens>
            <token id="7" string="stood" />
            <token id="8" string="out" />
            <token id="9" string="like" />
            <token id="10" string="a" />
            <token id="11" string="bloodstain" />
          </tokens>
        </chunking>
        <chunking id="6" string="a bloodstain" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="bloodstain" />
          </tokens>
        </chunking>
        <chunking id="7" string="she" type="NP">
          <tokens>
            <token id="30" string="she" />
          </tokens>
        </chunking>
        <chunking id="8" string="says" type="VP">
          <tokens>
            <token id="31" string="says" />
          </tokens>
        </chunking>
        <chunking id="9" string="care of sheep" type="NP">
          <tokens>
            <token id="25" string="care" />
            <token id="26" string="of" />
            <token id="27" string="sheep" />
          </tokens>
        </chunking>
        <chunking id="10" string="Almost all of the people" type="NP">
          <tokens>
            <token id="14" string="Almost" />
            <token id="15" string="all" />
            <token id="16" string="of" />
            <token id="17" string="the" />
            <token id="18" string="people" />
          </tokens>
        </chunking>
        <chunking id="11" string="are involved in raising and taking care of sheep" type="VP">
          <tokens>
            <token id="19" string="are" />
            <token id="20" string="involved" />
            <token id="21" string="in" />
            <token id="22" string="raising" />
            <token id="23" string="and" />
            <token id="24" string="taking" />
            <token id="25" string="care" />
            <token id="26" string="of" />
            <token id="27" string="sheep" />
          </tokens>
        </chunking>
        <chunking id="12" string="the first" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="first" />
          </tokens>
        </chunking>
        <chunking id="13" string="involved in raising and taking care of sheep" type="ADJP">
          <tokens>
            <token id="20" string="involved" />
            <token id="21" string="in" />
            <token id="22" string="raising" />
            <token id="23" string="and" />
            <token id="24" string="taking" />
            <token id="25" string="care" />
            <token id="26" string="of" />
            <token id="27" string="sheep" />
          </tokens>
        </chunking>
        <chunking id="14" string="care" type="NP">
          <tokens>
            <token id="25" string="care" />
          </tokens>
        </chunking>
        <chunking id="15" string="sheep" type="NP">
          <tokens>
            <token id="27" string="sheep" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">first</governor>
          <dependent id="1">From</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">first</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">stood</governor>
          <dependent id="3">first</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="6">clue</governor>
          <dependent id="5">one</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">stood</governor>
          <dependent id="6">clue</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">stood</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="7">stood</governor>
          <dependent id="8">out</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">bloodstain</governor>
          <dependent id="9">like</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">bloodstain</governor>
          <dependent id="10">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">stood</governor>
          <dependent id="11">bloodstain</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">all</governor>
          <dependent id="14">Almost</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="20">involved</governor>
          <dependent id="15">all</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">people</governor>
          <dependent id="16">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">people</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">all</governor>
          <dependent id="18">people</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="20">involved</governor>
          <dependent id="19">are</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="31">says</governor>
          <dependent id="20">involved</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">raising</governor>
          <dependent id="21">in</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="20">involved</governor>
          <dependent id="22">raising</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="22">raising</governor>
          <dependent id="23">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="22">raising</governor>
          <dependent id="24">taking</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">raising</governor>
          <dependent id="25">care</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">sheep</governor>
          <dependent id="26">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">care</governor>
          <dependent id="27">sheep</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="31">says</governor>
          <dependent id="30">she</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="7">stood</governor>
          <dependent id="31">says</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="3" string="first" />
          </tokens>
        </entity>
        <entity id="2" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="5" string="one" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="23" has_coreference="false">
      <content>The local cuisine includes a soup of sheep meat stewed in sheep milk.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="local" lemma="local" stem="local" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="cuisine" lemma="cuisine" stem="cuisin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="includes" lemma="include" stem="includ" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="soup" lemma="soup" stem="soup" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="sheep" lemma="sheep" stem="sheep" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="meat" lemma="meat" stem="meat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="stewed" lemma="stew" stem="stew" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="sheep" lemma="sheep" stem="sheep" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="milk" lemma="milk" stem="milk" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (JJ local) (NN cuisine)) (VP (VBZ includes) (NP (NP (DT a) (NN soup)) (PP (IN of) (NP (NP (NN sheep) (NN meat)) (VP (VBN stewed) (PP (IN in) (NP (NN sheep) (NN milk)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="stewed in sheep milk" type="VP">
          <tokens>
            <token id="10" string="stewed" />
            <token id="11" string="in" />
            <token id="12" string="sheep" />
            <token id="13" string="milk" />
          </tokens>
        </chunking>
        <chunking id="2" string="The local cuisine" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="local" />
            <token id="3" string="cuisine" />
          </tokens>
        </chunking>
        <chunking id="3" string="a soup of sheep meat stewed in sheep milk" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="soup" />
            <token id="7" string="of" />
            <token id="8" string="sheep" />
            <token id="9" string="meat" />
            <token id="10" string="stewed" />
            <token id="11" string="in" />
            <token id="12" string="sheep" />
            <token id="13" string="milk" />
          </tokens>
        </chunking>
        <chunking id="4" string="sheep meat" type="NP">
          <tokens>
            <token id="8" string="sheep" />
            <token id="9" string="meat" />
          </tokens>
        </chunking>
        <chunking id="5" string="sheep milk" type="NP">
          <tokens>
            <token id="12" string="sheep" />
            <token id="13" string="milk" />
          </tokens>
        </chunking>
        <chunking id="6" string="a soup" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="soup" />
          </tokens>
        </chunking>
        <chunking id="7" string="includes a soup of sheep meat stewed in sheep milk" type="VP">
          <tokens>
            <token id="4" string="includes" />
            <token id="5" string="a" />
            <token id="6" string="soup" />
            <token id="7" string="of" />
            <token id="8" string="sheep" />
            <token id="9" string="meat" />
            <token id="10" string="stewed" />
            <token id="11" string="in" />
            <token id="12" string="sheep" />
            <token id="13" string="milk" />
          </tokens>
        </chunking>
        <chunking id="8" string="sheep meat stewed in sheep milk" type="NP">
          <tokens>
            <token id="8" string="sheep" />
            <token id="9" string="meat" />
            <token id="10" string="stewed" />
            <token id="11" string="in" />
            <token id="12" string="sheep" />
            <token id="13" string="milk" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">cuisine</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">cuisine</governor>
          <dependent id="2">local</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">includes</governor>
          <dependent id="3">cuisine</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">includes</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">soup</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">includes</governor>
          <dependent id="6">soup</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">meat</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">meat</governor>
          <dependent id="8">sheep</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">soup</governor>
          <dependent id="9">meat</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="9">meat</governor>
          <dependent id="10">stewed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">milk</governor>
          <dependent id="11">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">milk</governor>
          <dependent id="12">sheep</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">stewed</governor>
          <dependent id="13">milk</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="24" has_coreference="true">
      <content>The area&amp;apost;s equivalent of chicken soup for colds is sheep brain fried in onions.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="area" lemma="area" stem="area" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="equivalent" lemma="equivalent" stem="equival" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="chicken" lemma="chicken" stem="chicken" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="soup" lemma="soup" stem="soup" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="colds" lemma="cold" stem="cold" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="sheep" lemma="sheep" stem="sheep" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="brain" lemma="brain" stem="brain" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="fried" lemma="fry" stem="fri" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="onions" lemma="onion" stem="onion" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NP (DT The) (NN area) (POS 's)) (NN equivalent)) (PP (IN of) (NP (NP (NN chicken) (NN soup)) (PP (IN for) (NP (NNS colds)))))) (VP (VBZ is) (NP (NP (NN sheep) (NN brain)) (SBAR (S (VP (VBD fried) (PP (IN in) (NP (NNS onions)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="onions" type="NP">
          <tokens>
            <token id="15" string="onions" />
          </tokens>
        </chunking>
        <chunking id="2" string="is sheep brain fried in onions" type="VP">
          <tokens>
            <token id="10" string="is" />
            <token id="11" string="sheep" />
            <token id="12" string="brain" />
            <token id="13" string="fried" />
            <token id="14" string="in" />
            <token id="15" string="onions" />
          </tokens>
        </chunking>
        <chunking id="3" string="The area 's equivalent of chicken soup for colds" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="area" />
            <token id="3" string="'s" />
            <token id="4" string="equivalent" />
            <token id="5" string="of" />
            <token id="6" string="chicken" />
            <token id="7" string="soup" />
            <token id="8" string="for" />
            <token id="9" string="colds" />
          </tokens>
        </chunking>
        <chunking id="4" string="chicken soup" type="NP">
          <tokens>
            <token id="6" string="chicken" />
            <token id="7" string="soup" />
          </tokens>
        </chunking>
        <chunking id="5" string="sheep brain fried in onions" type="NP">
          <tokens>
            <token id="11" string="sheep" />
            <token id="12" string="brain" />
            <token id="13" string="fried" />
            <token id="14" string="in" />
            <token id="15" string="onions" />
          </tokens>
        </chunking>
        <chunking id="6" string="sheep brain" type="NP">
          <tokens>
            <token id="11" string="sheep" />
            <token id="12" string="brain" />
          </tokens>
        </chunking>
        <chunking id="7" string="The area 's" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="area" />
            <token id="3" string="'s" />
          </tokens>
        </chunking>
        <chunking id="8" string="colds" type="NP">
          <tokens>
            <token id="9" string="colds" />
          </tokens>
        </chunking>
        <chunking id="9" string="fried in onions" type="SBAR">
          <tokens>
            <token id="13" string="fried" />
            <token id="14" string="in" />
            <token id="15" string="onions" />
          </tokens>
        </chunking>
        <chunking id="10" string="chicken soup for colds" type="NP">
          <tokens>
            <token id="6" string="chicken" />
            <token id="7" string="soup" />
            <token id="8" string="for" />
            <token id="9" string="colds" />
          </tokens>
        </chunking>
        <chunking id="11" string="The area 's equivalent" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="area" />
            <token id="3" string="'s" />
            <token id="4" string="equivalent" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">area</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">equivalent</governor>
          <dependent id="2">area</dependent>
        </dependency>
        <dependency type="case">
          <governor id="2">area</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">brain</governor>
          <dependent id="4">equivalent</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">soup</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">soup</governor>
          <dependent id="6">chicken</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">equivalent</governor>
          <dependent id="7">soup</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">colds</governor>
          <dependent id="8">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">soup</governor>
          <dependent id="9">colds</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="12">brain</governor>
          <dependent id="10">is</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">brain</governor>
          <dependent id="11">sheep</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">brain</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="12">brain</governor>
          <dependent id="13">fried</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">onions</governor>
          <dependent id="14">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">fried</governor>
          <dependent id="15">onions</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="25" has_coreference="false">
      <content>One CJD victim even slept with a pet sheep until age 13.</content>
      <tokens>
        <token id="1" string="One" lemma="one" stem="one" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="2" string="CJD" lemma="cjd" stem="cjd" pos="NN" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="3" string="victim" lemma="victim" stem="victim" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="slept" lemma="sleep" stem="slept" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="pet" lemma="pet" stem="pet" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="sheep" lemma="sheep" stem="sheep" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="until" lemma="until" stem="until" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="age" lemma="age" stem="ag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="13" lemma="13" stem="13" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (CD One) (NN CJD) (NN victim)) (ADVP (RB even)) (VP (VBD slept) (PP (IN with) (NP (DT a) (NN pet) (NN sheep))) (PP (IN until) (NP (NN age) (CD 13)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="One CJD victim" type="NP">
          <tokens>
            <token id="1" string="One" />
            <token id="2" string="CJD" />
            <token id="3" string="victim" />
          </tokens>
        </chunking>
        <chunking id="2" string="a pet sheep" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="pet" />
            <token id="9" string="sheep" />
          </tokens>
        </chunking>
        <chunking id="3" string="slept with a pet sheep until age 13" type="VP">
          <tokens>
            <token id="5" string="slept" />
            <token id="6" string="with" />
            <token id="7" string="a" />
            <token id="8" string="pet" />
            <token id="9" string="sheep" />
            <token id="10" string="until" />
            <token id="11" string="age" />
            <token id="12" string="13" />
          </tokens>
        </chunking>
        <chunking id="4" string="age 13" type="NP">
          <tokens>
            <token id="11" string="age" />
            <token id="12" string="13" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nummod">
          <governor id="3">victim</governor>
          <dependent id="1">One</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">victim</governor>
          <dependent id="2">CJD</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">slept</governor>
          <dependent id="3">victim</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">slept</governor>
          <dependent id="4">even</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">slept</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">sheep</governor>
          <dependent id="6">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">sheep</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">sheep</governor>
          <dependent id="8">pet</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">slept</governor>
          <dependent id="9">sheep</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">age</governor>
          <dependent id="10">until</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">slept</governor>
          <dependent id="11">age</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="11">age</governor>
          <dependent id="12">13</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="13" type="NUMBER" score="0.0">
          <tokens>
            <token id="12" string="13" />
          </tokens>
        </entity>
        <entity id="2" string="One" type="NUMBER" score="0.0">
          <tokens>
            <token id="1" string="One" />
          </tokens>
        </entity>
        <entity id="3" string="CJD" type="MISC" score="0.0">
          <tokens>
            <token id="2" string="CJD" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="26" has_coreference="false">
      <content>Now such coincidences seem like a serial killer&amp;apost;s pattern.</content>
      <tokens>
        <token id="1" string="Now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="2" string="such" lemma="such" stem="such" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="coincidences" lemma="coincidence" stem="coincid" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="seem" lemma="seem" stem="seem" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="serial" lemma="serial" stem="serial" pos="JJ" type="Word" isStopWord="false" ner="CRIMINAL_CHARGE" is_referenced="false" is_refers="false" />
        <token id="8" string="killer" lemma="killer" stem="killer" pos="NN" type="Word" isStopWord="false" ner="CRIMINAL_CHARGE" is_referenced="false" is_refers="false" />
        <token id="9" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="pattern" lemma="pattern" stem="pattern" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Now)) (NP (JJ such) (NNS coincidences)) (VP (VBP seem) (PP (IN like) (NP (NP (DT a) (JJ serial) (NN killer) (POS 's)) (NN pattern)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a serial killer 's pattern" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="serial" />
            <token id="8" string="killer" />
            <token id="9" string="'s" />
            <token id="10" string="pattern" />
          </tokens>
        </chunking>
        <chunking id="2" string="seem like a serial killer 's pattern" type="VP">
          <tokens>
            <token id="4" string="seem" />
            <token id="5" string="like" />
            <token id="6" string="a" />
            <token id="7" string="serial" />
            <token id="8" string="killer" />
            <token id="9" string="'s" />
            <token id="10" string="pattern" />
          </tokens>
        </chunking>
        <chunking id="3" string="such coincidences" type="NP">
          <tokens>
            <token id="2" string="such" />
            <token id="3" string="coincidences" />
          </tokens>
        </chunking>
        <chunking id="4" string="a serial killer 's" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="serial" />
            <token id="8" string="killer" />
            <token id="9" string="'s" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="4">seem</governor>
          <dependent id="1">Now</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">coincidences</governor>
          <dependent id="2">such</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">seem</governor>
          <dependent id="3">coincidences</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">seem</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">pattern</governor>
          <dependent id="5">like</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">killer</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">killer</governor>
          <dependent id="7">serial</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="10">pattern</governor>
          <dependent id="8">killer</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">killer</governor>
          <dependent id="9">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">seem</governor>
          <dependent id="10">pattern</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Now" type="DATE" score="0.0">
          <tokens>
            <token id="1" string="Now" />
          </tokens>
        </entity>
        <entity id="2" string="serial killer" type="CRIMINAL_CHARGE" score="0.0">
          <tokens>
            <token id="7" string="serial" />
            <token id="8" string="killer" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="27" has_coreference="true">
      <content>Against all odds, CJD has struck again and again in the same region, called Slovakia -- 69 times since 1975, mainly grouped in two areas.</content>
      <tokens>
        <token id="1" string="Against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="odds" lemma="odds" stem="odd" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="CJD" lemma="CJD" stem="cjd" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="6" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="struck" lemma="strike" stem="struck" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="again" lemma="again" stem="again" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="again" lemma="again" stem="again" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="same" lemma="same" stem="same" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="region" lemma="region" stem="region" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="called" lemma="call" stem="call" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="Slovakia" lemma="Slovakia" stem="slovakia" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="18" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="69" lemma="69" stem="69" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="20" string="times" lemma="time" stem="time" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="since" lemma="since" stem="sinc" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="1975" lemma="1975" stem="1975" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="mainly" lemma="mainly" stem="mainli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="grouped" lemma="group" stem="group" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="28" string="areas" lemma="area" stem="area" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN Against) (NP (DT all) (NNS odds))) (, ,) (NP (NNP CJD)) (VP (VBZ has) (VP (VBN struck) (ADVP (RB again) (CC and) (RB again)) (PP (IN in) (NP (NP (DT the) (JJ same) (NN region)) (, ,) (VP (VBN called) (NP (NP (NNP Slovakia)) (: --) (NP (NP (QP (CD 69) (NNS times))) (PP (IN since) (NP (CD 1975))) (, ,) (VP (ADVP (RB mainly)) (VBN grouped) (PP (IN in) (NP (CD two) (NNS areas))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the same region , called Slovakia -- 69 times since 1975 , mainly grouped in two areas" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="same" />
            <token id="14" string="region" />
            <token id="15" string="," />
            <token id="16" string="called" />
            <token id="17" string="Slovakia" />
            <token id="18" string="--" />
            <token id="19" string="69" />
            <token id="20" string="times" />
            <token id="21" string="since" />
            <token id="22" string="1975" />
            <token id="23" string="," />
            <token id="24" string="mainly" />
            <token id="25" string="grouped" />
            <token id="26" string="in" />
            <token id="27" string="two" />
            <token id="28" string="areas" />
          </tokens>
        </chunking>
        <chunking id="2" string="mainly grouped in two areas" type="VP">
          <tokens>
            <token id="24" string="mainly" />
            <token id="25" string="grouped" />
            <token id="26" string="in" />
            <token id="27" string="two" />
            <token id="28" string="areas" />
          </tokens>
        </chunking>
        <chunking id="3" string="Slovakia -- 69 times since 1975 , mainly grouped in two areas" type="NP">
          <tokens>
            <token id="17" string="Slovakia" />
            <token id="18" string="--" />
            <token id="19" string="69" />
            <token id="20" string="times" />
            <token id="21" string="since" />
            <token id="22" string="1975" />
            <token id="23" string="," />
            <token id="24" string="mainly" />
            <token id="25" string="grouped" />
            <token id="26" string="in" />
            <token id="27" string="two" />
            <token id="28" string="areas" />
          </tokens>
        </chunking>
        <chunking id="4" string="1975" type="NP">
          <tokens>
            <token id="22" string="1975" />
          </tokens>
        </chunking>
        <chunking id="5" string="all odds" type="NP">
          <tokens>
            <token id="2" string="all" />
            <token id="3" string="odds" />
          </tokens>
        </chunking>
        <chunking id="6" string="struck again and again in the same region , called Slovakia -- 69 times since 1975 , mainly grouped in two areas" type="VP">
          <tokens>
            <token id="7" string="struck" />
            <token id="8" string="again" />
            <token id="9" string="and" />
            <token id="10" string="again" />
            <token id="11" string="in" />
            <token id="12" string="the" />
            <token id="13" string="same" />
            <token id="14" string="region" />
            <token id="15" string="," />
            <token id="16" string="called" />
            <token id="17" string="Slovakia" />
            <token id="18" string="--" />
            <token id="19" string="69" />
            <token id="20" string="times" />
            <token id="21" string="since" />
            <token id="22" string="1975" />
            <token id="23" string="," />
            <token id="24" string="mainly" />
            <token id="25" string="grouped" />
            <token id="26" string="in" />
            <token id="27" string="two" />
            <token id="28" string="areas" />
          </tokens>
        </chunking>
        <chunking id="7" string="Slovakia" type="NP">
          <tokens>
            <token id="17" string="Slovakia" />
          </tokens>
        </chunking>
        <chunking id="8" string="two areas" type="NP">
          <tokens>
            <token id="27" string="two" />
            <token id="28" string="areas" />
          </tokens>
        </chunking>
        <chunking id="9" string="has struck again and again in the same region , called Slovakia -- 69 times since 1975 , mainly grouped in two areas" type="VP">
          <tokens>
            <token id="6" string="has" />
            <token id="7" string="struck" />
            <token id="8" string="again" />
            <token id="9" string="and" />
            <token id="10" string="again" />
            <token id="11" string="in" />
            <token id="12" string="the" />
            <token id="13" string="same" />
            <token id="14" string="region" />
            <token id="15" string="," />
            <token id="16" string="called" />
            <token id="17" string="Slovakia" />
            <token id="18" string="--" />
            <token id="19" string="69" />
            <token id="20" string="times" />
            <token id="21" string="since" />
            <token id="22" string="1975" />
            <token id="23" string="," />
            <token id="24" string="mainly" />
            <token id="25" string="grouped" />
            <token id="26" string="in" />
            <token id="27" string="two" />
            <token id="28" string="areas" />
          </tokens>
        </chunking>
        <chunking id="10" string="69 times since 1975 , mainly grouped in two areas" type="NP">
          <tokens>
            <token id="19" string="69" />
            <token id="20" string="times" />
            <token id="21" string="since" />
            <token id="22" string="1975" />
            <token id="23" string="," />
            <token id="24" string="mainly" />
            <token id="25" string="grouped" />
            <token id="26" string="in" />
            <token id="27" string="two" />
            <token id="28" string="areas" />
          </tokens>
        </chunking>
        <chunking id="11" string="69 times" type="NP">
          <tokens>
            <token id="19" string="69" />
            <token id="20" string="times" />
          </tokens>
        </chunking>
        <chunking id="12" string="the same region" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="same" />
            <token id="14" string="region" />
          </tokens>
        </chunking>
        <chunking id="13" string="CJD" type="NP">
          <tokens>
            <token id="5" string="CJD" />
          </tokens>
        </chunking>
        <chunking id="14" string="called Slovakia -- 69 times since 1975 , mainly grouped in two areas" type="VP">
          <tokens>
            <token id="16" string="called" />
            <token id="17" string="Slovakia" />
            <token id="18" string="--" />
            <token id="19" string="69" />
            <token id="20" string="times" />
            <token id="21" string="since" />
            <token id="22" string="1975" />
            <token id="23" string="," />
            <token id="24" string="mainly" />
            <token id="25" string="grouped" />
            <token id="26" string="in" />
            <token id="27" string="two" />
            <token id="28" string="areas" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">odds</governor>
          <dependent id="1">Against</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">odds</governor>
          <dependent id="2">all</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">struck</governor>
          <dependent id="3">odds</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">struck</governor>
          <dependent id="5">CJD</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">struck</governor>
          <dependent id="6">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">struck</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">struck</governor>
          <dependent id="8">again</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">again</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">again</governor>
          <dependent id="10">again</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">region</governor>
          <dependent id="11">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">region</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">region</governor>
          <dependent id="13">same</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">struck</governor>
          <dependent id="14">region</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="14">region</governor>
          <dependent id="16">called</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">called</governor>
          <dependent id="17">Slovakia</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">times</governor>
          <dependent id="19">69</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="17">Slovakia</governor>
          <dependent id="20">times</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">1975</governor>
          <dependent id="21">since</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">times</governor>
          <dependent id="22">1975</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="25">grouped</governor>
          <dependent id="24">mainly</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="20">times</governor>
          <dependent id="25">grouped</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">areas</governor>
          <dependent id="26">in</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="28">areas</governor>
          <dependent id="27">two</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">grouped</governor>
          <dependent id="28">areas</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="69" type="NUMBER" score="0.0">
          <tokens>
            <token id="19" string="69" />
          </tokens>
        </entity>
        <entity id="2" string="1975" type="DATE" score="0.0">
          <tokens>
            <token id="22" string="1975" />
          </tokens>
        </entity>
        <entity id="3" string="Slovakia" type="LOCATION" score="0.0">
          <tokens>
            <token id="17" string="Slovakia" />
          </tokens>
        </entity>
        <entity id="4" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="27" string="two" />
          </tokens>
        </entity>
        <entity id="5" string="CJD" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="5" string="CJD" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="28" has_coreference="false">
      <content>The outbreak has become something of an epidemic around the Orava area, where 26 cases have occurred since 1987, a rate hundreds of times higher than normal for CJD.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="outbreak" lemma="outbreak" stem="outbreak" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="become" lemma="become" stem="becom" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="something" lemma="something" stem="someth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="epidemic" lemma="epidemic" stem="epidem" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="around" lemma="around" stem="around" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Orava" lemma="Orava" stem="orava" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="12" string="area" lemma="area" stem="area" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="where" lemma="where" stem="where" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="26" lemma="26" stem="26" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="16" string="cases" lemma="case" stem="case" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="occurred" lemma="occur" stem="occur" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="since" lemma="since" stem="sinc" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="1987" lemma="1987" stem="1987" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="rate" lemma="rate" stem="rate" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="hundreds" lemma="hundred" stem="hundr" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="times" lemma="time" stem="time" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="higher" lemma="higher" stem="higher" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="normal" lemma="normal" stem="normal" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="CJD" lemma="CJD" stem="cjd" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN outbreak)) (VP (VBZ has) (VP (VBN become) (NP (NP (NN something)) (PP (IN of) (NP (NP (DT an) (ADJP (JJ epidemic) (PP (IN around) (NP (DT the) (NNP Orava)))) (NN area)) (, ,) (SBAR (WHADVP (WRB where)) (S (NP (CD 26) (NNS cases)) (VP (VBP have) (VP (VBN occurred) (PP (IN since) (NP (CD 1987))) (, ,) (ADVP (ADVP (NP (DT a) (NN rate) (QP (NNS hundreds) (IN of) (NNS times))) (JJR higher)) (PP (IN than) (NP (NP (JJ normal)) (PP (IN for) (NP (NNP CJD))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="normal for CJD" type="NP">
          <tokens>
            <token id="29" string="normal" />
            <token id="30" string="for" />
            <token id="31" string="CJD" />
          </tokens>
        </chunking>
        <chunking id="2" string="normal" type="NP">
          <tokens>
            <token id="29" string="normal" />
          </tokens>
        </chunking>
        <chunking id="3" string="26 cases" type="NP">
          <tokens>
            <token id="15" string="26" />
            <token id="16" string="cases" />
          </tokens>
        </chunking>
        <chunking id="4" string="the Orava" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="Orava" />
          </tokens>
        </chunking>
        <chunking id="5" string="something of an epidemic around the Orava area , where 26 cases have occurred since 1987 , a rate hundreds of times higher than normal for CJD" type="NP">
          <tokens>
            <token id="5" string="something" />
            <token id="6" string="of" />
            <token id="7" string="an" />
            <token id="8" string="epidemic" />
            <token id="9" string="around" />
            <token id="10" string="the" />
            <token id="11" string="Orava" />
            <token id="12" string="area" />
            <token id="13" string="," />
            <token id="14" string="where" />
            <token id="15" string="26" />
            <token id="16" string="cases" />
            <token id="17" string="have" />
            <token id="18" string="occurred" />
            <token id="19" string="since" />
            <token id="20" string="1987" />
            <token id="21" string="," />
            <token id="22" string="a" />
            <token id="23" string="rate" />
            <token id="24" string="hundreds" />
            <token id="25" string="of" />
            <token id="26" string="times" />
            <token id="27" string="higher" />
            <token id="28" string="than" />
            <token id="29" string="normal" />
            <token id="30" string="for" />
            <token id="31" string="CJD" />
          </tokens>
        </chunking>
        <chunking id="6" string="epidemic around the Orava" type="ADJP">
          <tokens>
            <token id="8" string="epidemic" />
            <token id="9" string="around" />
            <token id="10" string="the" />
            <token id="11" string="Orava" />
          </tokens>
        </chunking>
        <chunking id="7" string="an epidemic around the Orava area , where 26 cases have occurred since 1987 , a rate hundreds of times higher than normal for CJD" type="NP">
          <tokens>
            <token id="7" string="an" />
            <token id="8" string="epidemic" />
            <token id="9" string="around" />
            <token id="10" string="the" />
            <token id="11" string="Orava" />
            <token id="12" string="area" />
            <token id="13" string="," />
            <token id="14" string="where" />
            <token id="15" string="26" />
            <token id="16" string="cases" />
            <token id="17" string="have" />
            <token id="18" string="occurred" />
            <token id="19" string="since" />
            <token id="20" string="1987" />
            <token id="21" string="," />
            <token id="22" string="a" />
            <token id="23" string="rate" />
            <token id="24" string="hundreds" />
            <token id="25" string="of" />
            <token id="26" string="times" />
            <token id="27" string="higher" />
            <token id="28" string="than" />
            <token id="29" string="normal" />
            <token id="30" string="for" />
            <token id="31" string="CJD" />
          </tokens>
        </chunking>
        <chunking id="8" string="have occurred since 1987 , a rate hundreds of times higher than normal for CJD" type="VP">
          <tokens>
            <token id="17" string="have" />
            <token id="18" string="occurred" />
            <token id="19" string="since" />
            <token id="20" string="1987" />
            <token id="21" string="," />
            <token id="22" string="a" />
            <token id="23" string="rate" />
            <token id="24" string="hundreds" />
            <token id="25" string="of" />
            <token id="26" string="times" />
            <token id="27" string="higher" />
            <token id="28" string="than" />
            <token id="29" string="normal" />
            <token id="30" string="for" />
            <token id="31" string="CJD" />
          </tokens>
        </chunking>
        <chunking id="9" string="something" type="NP">
          <tokens>
            <token id="5" string="something" />
          </tokens>
        </chunking>
        <chunking id="10" string="an epidemic around the Orava area" type="NP">
          <tokens>
            <token id="7" string="an" />
            <token id="8" string="epidemic" />
            <token id="9" string="around" />
            <token id="10" string="the" />
            <token id="11" string="Orava" />
            <token id="12" string="area" />
          </tokens>
        </chunking>
        <chunking id="11" string="occurred since 1987 , a rate hundreds of times higher than normal for CJD" type="VP">
          <tokens>
            <token id="18" string="occurred" />
            <token id="19" string="since" />
            <token id="20" string="1987" />
            <token id="21" string="," />
            <token id="22" string="a" />
            <token id="23" string="rate" />
            <token id="24" string="hundreds" />
            <token id="25" string="of" />
            <token id="26" string="times" />
            <token id="27" string="higher" />
            <token id="28" string="than" />
            <token id="29" string="normal" />
            <token id="30" string="for" />
            <token id="31" string="CJD" />
          </tokens>
        </chunking>
        <chunking id="12" string="1987" type="NP">
          <tokens>
            <token id="20" string="1987" />
          </tokens>
        </chunking>
        <chunking id="13" string="where 26 cases have occurred since 1987 , a rate hundreds of times higher than normal for CJD" type="SBAR">
          <tokens>
            <token id="14" string="where" />
            <token id="15" string="26" />
            <token id="16" string="cases" />
            <token id="17" string="have" />
            <token id="18" string="occurred" />
            <token id="19" string="since" />
            <token id="20" string="1987" />
            <token id="21" string="," />
            <token id="22" string="a" />
            <token id="23" string="rate" />
            <token id="24" string="hundreds" />
            <token id="25" string="of" />
            <token id="26" string="times" />
            <token id="27" string="higher" />
            <token id="28" string="than" />
            <token id="29" string="normal" />
            <token id="30" string="for" />
            <token id="31" string="CJD" />
          </tokens>
        </chunking>
        <chunking id="14" string="become something of an epidemic around the Orava area , where 26 cases have occurred since 1987 , a rate hundreds of times higher than normal for CJD" type="VP">
          <tokens>
            <token id="4" string="become" />
            <token id="5" string="something" />
            <token id="6" string="of" />
            <token id="7" string="an" />
            <token id="8" string="epidemic" />
            <token id="9" string="around" />
            <token id="10" string="the" />
            <token id="11" string="Orava" />
            <token id="12" string="area" />
            <token id="13" string="," />
            <token id="14" string="where" />
            <token id="15" string="26" />
            <token id="16" string="cases" />
            <token id="17" string="have" />
            <token id="18" string="occurred" />
            <token id="19" string="since" />
            <token id="20" string="1987" />
            <token id="21" string="," />
            <token id="22" string="a" />
            <token id="23" string="rate" />
            <token id="24" string="hundreds" />
            <token id="25" string="of" />
            <token id="26" string="times" />
            <token id="27" string="higher" />
            <token id="28" string="than" />
            <token id="29" string="normal" />
            <token id="30" string="for" />
            <token id="31" string="CJD" />
          </tokens>
        </chunking>
        <chunking id="15" string="where" type="WHADVP">
          <tokens>
            <token id="14" string="where" />
          </tokens>
        </chunking>
        <chunking id="16" string="The outbreak" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="outbreak" />
          </tokens>
        </chunking>
        <chunking id="17" string="has become something of an epidemic around the Orava area , where 26 cases have occurred since 1987 , a rate hundreds of times higher than normal for CJD" type="VP">
          <tokens>
            <token id="3" string="has" />
            <token id="4" string="become" />
            <token id="5" string="something" />
            <token id="6" string="of" />
            <token id="7" string="an" />
            <token id="8" string="epidemic" />
            <token id="9" string="around" />
            <token id="10" string="the" />
            <token id="11" string="Orava" />
            <token id="12" string="area" />
            <token id="13" string="," />
            <token id="14" string="where" />
            <token id="15" string="26" />
            <token id="16" string="cases" />
            <token id="17" string="have" />
            <token id="18" string="occurred" />
            <token id="19" string="since" />
            <token id="20" string="1987" />
            <token id="21" string="," />
            <token id="22" string="a" />
            <token id="23" string="rate" />
            <token id="24" string="hundreds" />
            <token id="25" string="of" />
            <token id="26" string="times" />
            <token id="27" string="higher" />
            <token id="28" string="than" />
            <token id="29" string="normal" />
            <token id="30" string="for" />
            <token id="31" string="CJD" />
          </tokens>
        </chunking>
        <chunking id="18" string="a rate hundreds of times" type="NP">
          <tokens>
            <token id="22" string="a" />
            <token id="23" string="rate" />
            <token id="24" string="hundreds" />
            <token id="25" string="of" />
            <token id="26" string="times" />
          </tokens>
        </chunking>
        <chunking id="19" string="CJD" type="NP">
          <tokens>
            <token id="31" string="CJD" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">outbreak</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">become</governor>
          <dependent id="2">outbreak</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">become</governor>
          <dependent id="3">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">become</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">become</governor>
          <dependent id="5">something</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">area</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">area</governor>
          <dependent id="7">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">area</governor>
          <dependent id="8">epidemic</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Orava</governor>
          <dependent id="9">around</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">Orava</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">epidemic</governor>
          <dependent id="11">Orava</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">something</governor>
          <dependent id="12">area</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">occurred</governor>
          <dependent id="14">where</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="16">cases</governor>
          <dependent id="15">26</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">occurred</governor>
          <dependent id="16">cases</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="18">occurred</governor>
          <dependent id="17">have</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="12">area</governor>
          <dependent id="18">occurred</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">1987</governor>
          <dependent id="19">since</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">occurred</governor>
          <dependent id="20">1987</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">rate</governor>
          <dependent id="22">a</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="27">higher</governor>
          <dependent id="23">rate</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="26">times</governor>
          <dependent id="24">hundreds</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="26">times</governor>
          <dependent id="25">of</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="23">rate</governor>
          <dependent id="26">times</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">occurred</governor>
          <dependent id="27">higher</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">normal</governor>
          <dependent id="28">than</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">higher</governor>
          <dependent id="29">normal</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">CJD</governor>
          <dependent id="30">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">normal</governor>
          <dependent id="31">CJD</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1987" type="DATE" score="0.0">
          <tokens>
            <token id="20" string="1987" />
          </tokens>
        </entity>
        <entity id="2" string="26" type="NUMBER" score="0.0">
          <tokens>
            <token id="15" string="26" />
          </tokens>
        </entity>
        <entity id="3" string="Orava" type="LOCATION" score="0.0">
          <tokens>
            <token id="11" string="Orava" />
          </tokens>
        </entity>
        <entity id="4" string="CJD" type="MISC" score="0.0">
          <tokens>
            <token id="31" string="CJD" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="29" has_coreference="true">
      <content>Residents of the affected areas &amp;quot;are very afraid,&amp;quot; says Dr. Mitrova.</content>
      <tokens>
        <token id="1" string="Residents" lemma="resident" stem="resid" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="affected" lemma="affect" stem="affect" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="areas" lemma="area" stem="area" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="very" lemma="very" stem="veri" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="afraid" lemma="afraid" stem="afraid" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="Dr." lemma="Dr." stem="dr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="Mitrova" lemma="Mitrova" stem="mitrova" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (S (NP (NP (NNS Residents)) (PP (IN of) (NP (DT the) (VBN affected) (NNS areas)))) (`` ``) (VP (VBP are) (ADJP (RB very) (JJ afraid)))) (, ,) ('' '') (VP (VBZ says)) (NP (NNP Dr.) (NNP Mitrova)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Residents of the affected areas" type="NP">
          <tokens>
            <token id="1" string="Residents" />
            <token id="2" string="of" />
            <token id="3" string="the" />
            <token id="4" string="affected" />
            <token id="5" string="areas" />
          </tokens>
        </chunking>
        <chunking id="2" string="says" type="VP">
          <tokens>
            <token id="12" string="says" />
          </tokens>
        </chunking>
        <chunking id="3" string="very afraid" type="ADJP">
          <tokens>
            <token id="8" string="very" />
            <token id="9" string="afraid" />
          </tokens>
        </chunking>
        <chunking id="4" string="the affected areas" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="affected" />
            <token id="5" string="areas" />
          </tokens>
        </chunking>
        <chunking id="5" string="are very afraid" type="VP">
          <tokens>
            <token id="7" string="are" />
            <token id="8" string="very" />
            <token id="9" string="afraid" />
          </tokens>
        </chunking>
        <chunking id="6" string="Dr. Mitrova" type="NP">
          <tokens>
            <token id="13" string="Dr." />
            <token id="14" string="Mitrova" />
          </tokens>
        </chunking>
        <chunking id="7" string="Residents" type="NP">
          <tokens>
            <token id="1" string="Residents" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="9">afraid</governor>
          <dependent id="1">Residents</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">areas</governor>
          <dependent id="2">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">areas</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">areas</governor>
          <dependent id="4">affected</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Residents</governor>
          <dependent id="5">areas</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="9">afraid</governor>
          <dependent id="7">are</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">afraid</governor>
          <dependent id="8">very</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="12">says</governor>
          <dependent id="9">afraid</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">says</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Mitrova</governor>
          <dependent id="13">Dr.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">says</governor>
          <dependent id="14">Mitrova</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Mitrova" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Mitrova" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="30" has_coreference="false">
      <content>She has found evidence of scrapie in the area&amp;apost;s sheep.</content>
      <tokens>
        <token id="1" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="found" lemma="find" stem="found" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="evidence" lemma="evidence" stem="evid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="scrapie" lemma="scrapie" stem="scrapi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="area" lemma="area" stem="area" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="sheep" lemma="sheep" stem="sheep" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP She)) (VP (VBZ has) (VP (VBN found) (NP (NP (NN evidence)) (PP (IN of) (NP (NN scrapie)))) (PP (IN in) (NP (NP (DT the) (NN area) (POS 's)) (NN sheep))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the area 's" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="area" />
            <token id="10" string="'s" />
          </tokens>
        </chunking>
        <chunking id="2" string="evidence" type="NP">
          <tokens>
            <token id="4" string="evidence" />
          </tokens>
        </chunking>
        <chunking id="3" string="found evidence of scrapie in the area 's sheep" type="VP">
          <tokens>
            <token id="3" string="found" />
            <token id="4" string="evidence" />
            <token id="5" string="of" />
            <token id="6" string="scrapie" />
            <token id="7" string="in" />
            <token id="8" string="the" />
            <token id="9" string="area" />
            <token id="10" string="'s" />
            <token id="11" string="sheep" />
          </tokens>
        </chunking>
        <chunking id="4" string="has found evidence of scrapie in the area 's sheep" type="VP">
          <tokens>
            <token id="2" string="has" />
            <token id="3" string="found" />
            <token id="4" string="evidence" />
            <token id="5" string="of" />
            <token id="6" string="scrapie" />
            <token id="7" string="in" />
            <token id="8" string="the" />
            <token id="9" string="area" />
            <token id="10" string="'s" />
            <token id="11" string="sheep" />
          </tokens>
        </chunking>
        <chunking id="5" string="the area 's sheep" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="area" />
            <token id="10" string="'s" />
            <token id="11" string="sheep" />
          </tokens>
        </chunking>
        <chunking id="6" string="evidence of scrapie" type="NP">
          <tokens>
            <token id="4" string="evidence" />
            <token id="5" string="of" />
            <token id="6" string="scrapie" />
          </tokens>
        </chunking>
        <chunking id="7" string="scrapie" type="NP">
          <tokens>
            <token id="6" string="scrapie" />
          </tokens>
        </chunking>
        <chunking id="8" string="She" type="NP">
          <tokens>
            <token id="1" string="She" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">found</governor>
          <dependent id="1">She</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="3">found</governor>
          <dependent id="2">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">found</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">found</governor>
          <dependent id="4">evidence</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">scrapie</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">evidence</governor>
          <dependent id="6">scrapie</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">sheep</governor>
          <dependent id="7">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">area</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">sheep</governor>
          <dependent id="9">area</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">area</governor>
          <dependent id="10">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">found</governor>
          <dependent id="11">sheep</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="31" has_coreference="true">
      <content>Now villagers there call CJD &amp;quot;our sheep disease.&amp;quot;</content>
      <tokens>
        <token id="1" string="Now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="2" string="villagers" lemma="villager" stem="villag" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="there" lemma="there" stem="there" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="call" lemma="call" stem="call" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="CJD" lemma="CJD" stem="cjd" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="6" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="our" lemma="we" stem="our" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="sheep" lemma="sheep" stem="sheep" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="disease" lemma="disease" stem="diseas" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="true" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Now)) (NP (NNS villagers)) (ADVP (RB there)) (VP (VBP call) (S (NP (NNP CJD)) (`` ``) (NP (PRP$ our) (NN sheep) (NN disease)))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="our sheep disease" type="NP">
          <tokens>
            <token id="7" string="our" />
            <token id="8" string="sheep" />
            <token id="9" string="disease" />
          </tokens>
        </chunking>
        <chunking id="2" string="villagers" type="NP">
          <tokens>
            <token id="2" string="villagers" />
          </tokens>
        </chunking>
        <chunking id="3" string="call CJD `` our sheep disease" type="VP">
          <tokens>
            <token id="4" string="call" />
            <token id="5" string="CJD" />
            <token id="6" string="&quot;" />
            <token id="7" string="our" />
            <token id="8" string="sheep" />
            <token id="9" string="disease" />
          </tokens>
        </chunking>
        <chunking id="4" string="CJD" type="NP">
          <tokens>
            <token id="5" string="CJD" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="4">call</governor>
          <dependent id="1">Now</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">call</governor>
          <dependent id="2">villagers</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">call</governor>
          <dependent id="3">there</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">call</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="9">disease</governor>
          <dependent id="5">CJD</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="9">disease</governor>
          <dependent id="7">our</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">disease</governor>
          <dependent id="8">sheep</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">call</governor>
          <dependent id="9">disease</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Now" type="DATE" score="0.0">
          <tokens>
            <token id="1" string="Now" />
          </tokens>
        </entity>
        <entity id="2" string="disease" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="9" string="disease" />
          </tokens>
        </entity>
        <entity id="3" string="CJD" type="MISC" score="0.0">
          <tokens>
            <token id="5" string="CJD" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="32" has_coreference="true">
      <content>That&amp;apost;s a leap of folklore, though, and the sheep link may well turn out to be false, cautions Dr. Mitrova.</content>
      <tokens>
        <token id="1" string="That" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="leap" lemma="leap" stem="leap" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="folklore" lemma="folklore" stem="folklor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="though" lemma="though" stem="though" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="sheep" lemma="sheep" stem="sheep" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="link" lemma="link" stem="link" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="may" lemma="may" stem="mai" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="well" lemma="well" stem="well" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="turn" lemma="turn" stem="turn" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="false" lemma="false" stem="fals" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="cautions" lemma="caution" stem="caution" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="Dr." lemma="Dr." stem="dr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="24" string="Mitrova" lemma="Mitrova" stem="mitrova" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (S (S (NP (DT That)) (VP (VBZ 's) (NP (NP (DT a) (NN leap)) (PP (IN of) (NP (NN folklore)))) (, ,) (ADVP (RB though)))) (, ,) (CC and) (S (NP (DT the) (NN sheep) (NN link)) (VP (MD may) (ADVP (RB well)) (VP (VB turn) (PRT (RP out)) (S (VP (TO to) (VP (VB be) (ADJP (JJ false))))))))) (, ,) (VP (VBZ cautions)) (NP (NNP Dr.) (NNP Mitrova)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="That" type="NP">
          <tokens>
            <token id="1" string="That" />
          </tokens>
        </chunking>
        <chunking id="2" string="false" type="ADJP">
          <tokens>
            <token id="20" string="false" />
          </tokens>
        </chunking>
        <chunking id="3" string="may well turn out to be false" type="VP">
          <tokens>
            <token id="14" string="may" />
            <token id="15" string="well" />
            <token id="16" string="turn" />
            <token id="17" string="out" />
            <token id="18" string="to" />
            <token id="19" string="be" />
            <token id="20" string="false" />
          </tokens>
        </chunking>
        <chunking id="4" string="be false" type="VP">
          <tokens>
            <token id="19" string="be" />
            <token id="20" string="false" />
          </tokens>
        </chunking>
        <chunking id="5" string="cautions" type="VP">
          <tokens>
            <token id="22" string="cautions" />
          </tokens>
        </chunking>
        <chunking id="6" string="'s a leap of folklore , though" type="VP">
          <tokens>
            <token id="2" string="'s" />
            <token id="3" string="a" />
            <token id="4" string="leap" />
            <token id="5" string="of" />
            <token id="6" string="folklore" />
            <token id="7" string="," />
            <token id="8" string="though" />
          </tokens>
        </chunking>
        <chunking id="7" string="folklore" type="NP">
          <tokens>
            <token id="6" string="folklore" />
          </tokens>
        </chunking>
        <chunking id="8" string="Dr. Mitrova" type="NP">
          <tokens>
            <token id="23" string="Dr." />
            <token id="24" string="Mitrova" />
          </tokens>
        </chunking>
        <chunking id="9" string="a leap of folklore" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="leap" />
            <token id="5" string="of" />
            <token id="6" string="folklore" />
          </tokens>
        </chunking>
        <chunking id="10" string="turn out to be false" type="VP">
          <tokens>
            <token id="16" string="turn" />
            <token id="17" string="out" />
            <token id="18" string="to" />
            <token id="19" string="be" />
            <token id="20" string="false" />
          </tokens>
        </chunking>
        <chunking id="11" string="the sheep link" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="sheep" />
            <token id="13" string="link" />
          </tokens>
        </chunking>
        <chunking id="12" string="a leap" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="leap" />
          </tokens>
        </chunking>
        <chunking id="13" string="to be false" type="VP">
          <tokens>
            <token id="18" string="to" />
            <token id="19" string="be" />
            <token id="20" string="false" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">leap</governor>
          <dependent id="1">That</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">leap</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">leap</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="22">cautions</governor>
          <dependent id="4">leap</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">folklore</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">leap</governor>
          <dependent id="6">folklore</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">leap</governor>
          <dependent id="8">though</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">leap</governor>
          <dependent id="10">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">link</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">link</governor>
          <dependent id="12">sheep</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">turn</governor>
          <dependent id="13">link</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">turn</governor>
          <dependent id="14">may</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">turn</governor>
          <dependent id="15">well</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">leap</governor>
          <dependent id="16">turn</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="16">turn</governor>
          <dependent id="17">out</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="20">false</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="20">false</governor>
          <dependent id="19">be</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="16">turn</governor>
          <dependent id="20">false</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="22">cautions</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">Mitrova</governor>
          <dependent id="23">Dr.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">cautions</governor>
          <dependent id="24">Mitrova</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Mitrova" type="PERSON" score="0.0">
          <tokens>
            <token id="24" string="Mitrova" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="33" has_coreference="true">
      <content>Indeed, CJD is a nefarious trickster; the first reported case of the disease, which entered medical texts in the 1920s, really wasn&amp;apost;t CJD after all, scientists now believe.</content>
      <tokens>
        <token id="1" string="Indeed" lemma="indeed" stem="indeed" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="CJD" lemma="cjd" stem="cjd" pos="NN" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="4" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="nefarious" lemma="nefarious" stem="nefari" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="trickster" lemma="trickster" stem="trickster" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="first" lemma="first" stem="first" pos="RB" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="true" is_refers="true" />
        <token id="11" string="reported" lemma="report" stem="report" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="disease" lemma="disease" stem="diseas" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="true" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="entered" lemma="enter" stem="enter" pos="VBD" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="medical" lemma="medical" stem="medic" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="texts" lemma="text" stem="text" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="23" string="1920s" lemma="1920s" stem="1920" pos="CD" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="really" lemma="really" stem="realli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="CJD" lemma="cjd" stem="cjd" pos="VBN" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="29" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="scientists" lemma="scientist" stem="scientist" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="33" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="34" string="believe" lemma="believe" stem="believ" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Indeed)) (PRN (, ,) (S (NP (NN CJD)) (VP (VBZ is) (NP (NP (DT a) (JJ nefarious) (NN trickster)) (: ;) (S (NP (NP (DT the) (ADJP (ADVP (RB first)) (VBN reported)) (NN case)) (PP (IN of) (NP (DT the) (NN disease))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBD entered) (NP (JJ medical) (NNS texts)) (PP (IN in) (NP (DT the) (CD 1920s)))))) (, ,)) (ADVP (RB really)) (VP (VBD was) (RB n't) (VP (VBN CJD) (PP (IN after) (NP (DT all))))))))) (, ,)) (NP (NNS scientists)) (ADVP (RB now)) (VP (VBP believe)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="all" type="NP">
          <tokens>
            <token id="30" string="all" />
          </tokens>
        </chunking>
        <chunking id="2" string="CJD after all" type="VP">
          <tokens>
            <token id="28" string="CJD" />
            <token id="29" string="after" />
            <token id="30" string="all" />
          </tokens>
        </chunking>
        <chunking id="3" string="the 1920s" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="1920s" />
          </tokens>
        </chunking>
        <chunking id="4" string="is a nefarious trickster ; the first reported case of the disease , which entered medical texts in the 1920s , really was n't CJD after all" type="VP">
          <tokens>
            <token id="4" string="is" />
            <token id="5" string="a" />
            <token id="6" string="nefarious" />
            <token id="7" string="trickster" />
            <token id="8" string=";" />
            <token id="9" string="the" />
            <token id="10" string="first" />
            <token id="11" string="reported" />
            <token id="12" string="case" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="disease" />
            <token id="16" string="," />
            <token id="17" string="which" />
            <token id="18" string="entered" />
            <token id="19" string="medical" />
            <token id="20" string="texts" />
            <token id="21" string="in" />
            <token id="22" string="the" />
            <token id="23" string="1920s" />
            <token id="24" string="," />
            <token id="25" string="really" />
            <token id="26" string="was" />
            <token id="27" string="n't" />
            <token id="28" string="CJD" />
            <token id="29" string="after" />
            <token id="30" string="all" />
          </tokens>
        </chunking>
        <chunking id="5" string="believe" type="VP">
          <tokens>
            <token id="34" string="believe" />
          </tokens>
        </chunking>
        <chunking id="6" string="the first reported case of the disease , which entered medical texts in the 1920s ," type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="first" />
            <token id="11" string="reported" />
            <token id="12" string="case" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="disease" />
            <token id="16" string="," />
            <token id="17" string="which" />
            <token id="18" string="entered" />
            <token id="19" string="medical" />
            <token id="20" string="texts" />
            <token id="21" string="in" />
            <token id="22" string="the" />
            <token id="23" string="1920s" />
            <token id="24" string="," />
          </tokens>
        </chunking>
        <chunking id="7" string="the first reported case" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="first" />
            <token id="11" string="reported" />
            <token id="12" string="case" />
          </tokens>
        </chunking>
        <chunking id="8" string="the disease" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="disease" />
          </tokens>
        </chunking>
        <chunking id="9" string="a nefarious trickster ; the first reported case of the disease , which entered medical texts in the 1920s , really was n't CJD after all" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="nefarious" />
            <token id="7" string="trickster" />
            <token id="8" string=";" />
            <token id="9" string="the" />
            <token id="10" string="first" />
            <token id="11" string="reported" />
            <token id="12" string="case" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="disease" />
            <token id="16" string="," />
            <token id="17" string="which" />
            <token id="18" string="entered" />
            <token id="19" string="medical" />
            <token id="20" string="texts" />
            <token id="21" string="in" />
            <token id="22" string="the" />
            <token id="23" string="1920s" />
            <token id="24" string="," />
            <token id="25" string="really" />
            <token id="26" string="was" />
            <token id="27" string="n't" />
            <token id="28" string="CJD" />
            <token id="29" string="after" />
            <token id="30" string="all" />
          </tokens>
        </chunking>
        <chunking id="10" string="scientists" type="NP">
          <tokens>
            <token id="32" string="scientists" />
          </tokens>
        </chunking>
        <chunking id="11" string="was n't CJD after all" type="VP">
          <tokens>
            <token id="26" string="was" />
            <token id="27" string="n't" />
            <token id="28" string="CJD" />
            <token id="29" string="after" />
            <token id="30" string="all" />
          </tokens>
        </chunking>
        <chunking id="12" string="first reported" type="ADJP">
          <tokens>
            <token id="10" string="first" />
            <token id="11" string="reported" />
          </tokens>
        </chunking>
        <chunking id="13" string="which entered medical texts in the 1920s" type="SBAR">
          <tokens>
            <token id="17" string="which" />
            <token id="18" string="entered" />
            <token id="19" string="medical" />
            <token id="20" string="texts" />
            <token id="21" string="in" />
            <token id="22" string="the" />
            <token id="23" string="1920s" />
          </tokens>
        </chunking>
        <chunking id="14" string="entered medical texts in the 1920s" type="VP">
          <tokens>
            <token id="18" string="entered" />
            <token id="19" string="medical" />
            <token id="20" string="texts" />
            <token id="21" string="in" />
            <token id="22" string="the" />
            <token id="23" string="1920s" />
          </tokens>
        </chunking>
        <chunking id="15" string="a nefarious trickster" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="nefarious" />
            <token id="7" string="trickster" />
          </tokens>
        </chunking>
        <chunking id="16" string="medical texts" type="NP">
          <tokens>
            <token id="19" string="medical" />
            <token id="20" string="texts" />
          </tokens>
        </chunking>
        <chunking id="17" string="CJD" type="NP">
          <tokens>
            <token id="3" string="CJD" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="34">believe</governor>
          <dependent id="1">Indeed</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">trickster</governor>
          <dependent id="3">CJD</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">trickster</governor>
          <dependent id="4">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">trickster</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">trickster</governor>
          <dependent id="6">nefarious</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="34">believe</governor>
          <dependent id="7">trickster</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">case</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">reported</governor>
          <dependent id="10">first</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">case</governor>
          <dependent id="11">reported</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="28">CJD</governor>
          <dependent id="12">case</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">disease</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">disease</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">case</governor>
          <dependent id="15">disease</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">entered</governor>
          <dependent id="17">which</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="12">case</governor>
          <dependent id="18">entered</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">texts</governor>
          <dependent id="19">medical</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">entered</governor>
          <dependent id="20">texts</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">1920s</governor>
          <dependent id="21">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">1920s</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">entered</governor>
          <dependent id="23">1920s</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="28">CJD</governor>
          <dependent id="25">really</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="28">CJD</governor>
          <dependent id="26">was</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="28">CJD</governor>
          <dependent id="27">n't</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="7">trickster</governor>
          <dependent id="28">CJD</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">all</governor>
          <dependent id="29">after</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">CJD</governor>
          <dependent id="30">all</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="34">believe</governor>
          <dependent id="32">scientists</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="34">believe</governor>
          <dependent id="33">now</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="34">believe</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="10" string="first" />
          </tokens>
        </entity>
        <entity id="2" string="disease" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="15" string="disease" />
          </tokens>
        </entity>
        <entity id="3" string="now" type="DATE" score="0.0">
          <tokens>
            <token id="33" string="now" />
          </tokens>
        </entity>
        <entity id="4" string="the 1920s" type="DATE" score="0.0">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="1920s" />
          </tokens>
        </entity>
        <entity id="5" string="CJD" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="3" string="CJD" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="34" has_coreference="true">
      <content>And it usually strikes so rarely and randomly -- killing about one in a million people world-wide each year -- that scientists didn&amp;apost;t even begin to suspect it was infectious until 1957.</content>
      <tokens>
        <token id="1" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="usually" lemma="usually" stem="usual" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="strikes" lemma="strike" stem="strike" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="so" lemma="so" stem="so" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="rarely" lemma="rarely" stem="rare" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="randomly" lemma="randomly" stem="randomli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="killing" lemma="kill" stem="kill" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="13" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="million" lemma="million" stem="million" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="16" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="world-wide" lemma="world-wide" stem="world-wid" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="each" lemma="each" stem="each" pos="DT" type="Word" isStopWord="true" ner="SET" is_referenced="true" is_refers="false" />
        <token id="19" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="SET" is_referenced="true" is_refers="false" />
        <token id="20" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="scientists" lemma="scientist" stem="scientist" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="23" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="begin" lemma="begin" stem="begin" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="suspect" lemma="suspect" stem="suspect" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="30" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="infectious" lemma="infectious" stem="infecti" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="until" lemma="until" stem="until" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="1957" lemma="1957" stem="1957" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="34" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC And) (NP (PRP it)) (VP (VP (ADVP (RB usually)) (VBZ strikes) (ADVP (RB so)) (ADVP (ADVP (RB rarely)) (CC and) (ADVP (RB randomly)))) (PRN (: --) (S (VP (VBG killing) (PP (IN about) (NP (NP (CD one)) (PP (IN in) (NP (QP (DT a) (CD million)) (NNS people))))) (NP-TMP (ADVP (JJ world-wide)) (DT each) (NN year)))) (: --)) (SBAR (IN that) (S (NP (NNS scientists)) (VP (VBD did) (RB n't) (ADVP (RB even)) (VP (VB begin) (S (VP (TO to) (VP (VB suspect) (SBAR (S (NP (PRP it)) (VP (VBD was) (ADJP (JJ infectious) (PP (IN until) (NP (CD 1957))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="usually strikes so rarely and randomly -- killing about one in a million people world-wide each year -- that scientists did n't even begin to suspect it was infectious until 1957" type="VP">
          <tokens>
            <token id="3" string="usually" />
            <token id="4" string="strikes" />
            <token id="5" string="so" />
            <token id="6" string="rarely" />
            <token id="7" string="and" />
            <token id="8" string="randomly" />
            <token id="9" string="--" />
            <token id="10" string="killing" />
            <token id="11" string="about" />
            <token id="12" string="one" />
            <token id="13" string="in" />
            <token id="14" string="a" />
            <token id="15" string="million" />
            <token id="16" string="people" />
            <token id="17" string="world-wide" />
            <token id="18" string="each" />
            <token id="19" string="year" />
            <token id="20" string="--" />
            <token id="21" string="that" />
            <token id="22" string="scientists" />
            <token id="23" string="did" />
            <token id="24" string="n't" />
            <token id="25" string="even" />
            <token id="26" string="begin" />
            <token id="27" string="to" />
            <token id="28" string="suspect" />
            <token id="29" string="it" />
            <token id="30" string="was" />
            <token id="31" string="infectious" />
            <token id="32" string="until" />
            <token id="33" string="1957" />
          </tokens>
        </chunking>
        <chunking id="2" string="a million people" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="million" />
            <token id="16" string="people" />
          </tokens>
        </chunking>
        <chunking id="3" string="killing about one in a million people world-wide each year" type="VP">
          <tokens>
            <token id="10" string="killing" />
            <token id="11" string="about" />
            <token id="12" string="one" />
            <token id="13" string="in" />
            <token id="14" string="a" />
            <token id="15" string="million" />
            <token id="16" string="people" />
            <token id="17" string="world-wide" />
            <token id="18" string="each" />
            <token id="19" string="year" />
          </tokens>
        </chunking>
        <chunking id="4" string="one" type="NP">
          <tokens>
            <token id="12" string="one" />
          </tokens>
        </chunking>
        <chunking id="5" string="to suspect it was infectious until 1957" type="VP">
          <tokens>
            <token id="27" string="to" />
            <token id="28" string="suspect" />
            <token id="29" string="it" />
            <token id="30" string="was" />
            <token id="31" string="infectious" />
            <token id="32" string="until" />
            <token id="33" string="1957" />
          </tokens>
        </chunking>
        <chunking id="6" string="usually strikes so rarely and randomly" type="VP">
          <tokens>
            <token id="3" string="usually" />
            <token id="4" string="strikes" />
            <token id="5" string="so" />
            <token id="6" string="rarely" />
            <token id="7" string="and" />
            <token id="8" string="randomly" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="2" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="scientists" type="NP">
          <tokens>
            <token id="22" string="scientists" />
          </tokens>
        </chunking>
        <chunking id="9" string="did n't even begin to suspect it was infectious until 1957" type="VP">
          <tokens>
            <token id="23" string="did" />
            <token id="24" string="n't" />
            <token id="25" string="even" />
            <token id="26" string="begin" />
            <token id="27" string="to" />
            <token id="28" string="suspect" />
            <token id="29" string="it" />
            <token id="30" string="was" />
            <token id="31" string="infectious" />
            <token id="32" string="until" />
            <token id="33" string="1957" />
          </tokens>
        </chunking>
        <chunking id="10" string="was infectious until 1957" type="VP">
          <tokens>
            <token id="30" string="was" />
            <token id="31" string="infectious" />
            <token id="32" string="until" />
            <token id="33" string="1957" />
          </tokens>
        </chunking>
        <chunking id="11" string="that scientists did n't even begin to suspect it was infectious until 1957" type="SBAR">
          <tokens>
            <token id="21" string="that" />
            <token id="22" string="scientists" />
            <token id="23" string="did" />
            <token id="24" string="n't" />
            <token id="25" string="even" />
            <token id="26" string="begin" />
            <token id="27" string="to" />
            <token id="28" string="suspect" />
            <token id="29" string="it" />
            <token id="30" string="was" />
            <token id="31" string="infectious" />
            <token id="32" string="until" />
            <token id="33" string="1957" />
          </tokens>
        </chunking>
        <chunking id="12" string="it was infectious until 1957" type="SBAR">
          <tokens>
            <token id="29" string="it" />
            <token id="30" string="was" />
            <token id="31" string="infectious" />
            <token id="32" string="until" />
            <token id="33" string="1957" />
          </tokens>
        </chunking>
        <chunking id="13" string="infectious until 1957" type="ADJP">
          <tokens>
            <token id="31" string="infectious" />
            <token id="32" string="until" />
            <token id="33" string="1957" />
          </tokens>
        </chunking>
        <chunking id="14" string="begin to suspect it was infectious until 1957" type="VP">
          <tokens>
            <token id="26" string="begin" />
            <token id="27" string="to" />
            <token id="28" string="suspect" />
            <token id="29" string="it" />
            <token id="30" string="was" />
            <token id="31" string="infectious" />
            <token id="32" string="until" />
            <token id="33" string="1957" />
          </tokens>
        </chunking>
        <chunking id="15" string="one in a million people" type="NP">
          <tokens>
            <token id="12" string="one" />
            <token id="13" string="in" />
            <token id="14" string="a" />
            <token id="15" string="million" />
            <token id="16" string="people" />
          </tokens>
        </chunking>
        <chunking id="16" string="suspect it was infectious until 1957" type="VP">
          <tokens>
            <token id="28" string="suspect" />
            <token id="29" string="it" />
            <token id="30" string="was" />
            <token id="31" string="infectious" />
            <token id="32" string="until" />
            <token id="33" string="1957" />
          </tokens>
        </chunking>
        <chunking id="17" string="1957" type="NP">
          <tokens>
            <token id="33" string="1957" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="4">strikes</governor>
          <dependent id="1">And</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">strikes</governor>
          <dependent id="2">it</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">strikes</governor>
          <dependent id="3">usually</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">strikes</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">strikes</governor>
          <dependent id="5">so</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">and</governor>
          <dependent id="6">rarely</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">strikes</governor>
          <dependent id="7">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">and</governor>
          <dependent id="8">randomly</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="4">strikes</governor>
          <dependent id="10">killing</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">one</governor>
          <dependent id="11">about</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">killing</governor>
          <dependent id="12">one</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">people</governor>
          <dependent id="13">in</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">million</governor>
          <dependent id="14">a</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="16">people</governor>
          <dependent id="15">million</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">one</governor>
          <dependent id="16">people</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="19">year</governor>
          <dependent id="17">world-wide</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">year</governor>
          <dependent id="18">each</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="10">killing</governor>
          <dependent id="19">year</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="26">begin</governor>
          <dependent id="21">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">begin</governor>
          <dependent id="22">scientists</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="26">begin</governor>
          <dependent id="23">did</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="26">begin</governor>
          <dependent id="24">n't</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="26">begin</governor>
          <dependent id="25">even</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">strikes</governor>
          <dependent id="26">begin</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="28">suspect</governor>
          <dependent id="27">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="26">begin</governor>
          <dependent id="28">suspect</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="31">infectious</governor>
          <dependent id="29">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="31">infectious</governor>
          <dependent id="30">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="28">suspect</governor>
          <dependent id="31">infectious</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">1957</governor>
          <dependent id="32">until</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">infectious</governor>
          <dependent id="33">1957</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="million" type="NUMBER" score="0.0">
          <tokens>
            <token id="15" string="million" />
          </tokens>
        </entity>
        <entity id="2" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="12" string="one" />
          </tokens>
        </entity>
        <entity id="3" string="each year" type="SET" score="0.0">
          <tokens>
            <token id="18" string="each" />
            <token id="19" string="year" />
          </tokens>
        </entity>
        <entity id="4" string="1957" type="DATE" score="0.0">
          <tokens>
            <token id="33" string="1957" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="35" has_coreference="true">
      <content>That year, the NIH&amp;apost;s Dr. Gajdusek, then a young scientist casting about for big questions, planned a trip to Papua New Guinea to visit a friend.</content>
      <tokens>
        <token id="1" string="That" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="true" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="5" string="NIH" lemma="NIH" stem="nih" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="6" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="7" string="Dr." lemma="Dr." stem="dr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="Gajdusek" lemma="Gajdusek" stem="gajdusek" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="young" lemma="young" stem="young" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="scientist" lemma="scientist" stem="scientist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="casting" lemma="cast" stem="cast" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="big" lemma="big" stem="big" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="18" string="questions" lemma="question" stem="question" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="planned" lemma="plan" stem="plan" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="trip" lemma="trip" stem="trip" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="Papua" lemma="Papua" stem="papua" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="25" string="New" lemma="New" stem="new" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="26" string="Guinea" lemma="Guinea" stem="guinea" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="27" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="visit" lemma="visit" stem="visit" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="friend" lemma="friend" stem="friend" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP-TMP (DT That) (NN year)) (, ,) (NP (NP (NP (DT the) (NNP NIH) (POS 's)) (NNP Dr.) (NNP Gajdusek)) (, ,) (NP (NP (RB then) (DT a) (JJ young) (NN scientist)) (VP (VBG casting) (IN about) (PP (IN for) (NP (JJ big) (NNS questions))))) (, ,)) (VP (VBD planned) (NP (DT a) (NN trip)) (PP (TO to) (NP (NNP Papua) (NNP New) (NNP Guinea))) (S (VP (TO to) (VP (VB visit) (NP (DT a) (NN friend)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="planned a trip to Papua New Guinea to visit a friend" type="VP">
          <tokens>
            <token id="20" string="planned" />
            <token id="21" string="a" />
            <token id="22" string="trip" />
            <token id="23" string="to" />
            <token id="24" string="Papua" />
            <token id="25" string="New" />
            <token id="26" string="Guinea" />
            <token id="27" string="to" />
            <token id="28" string="visit" />
            <token id="29" string="a" />
            <token id="30" string="friend" />
          </tokens>
        </chunking>
        <chunking id="2" string="a friend" type="NP">
          <tokens>
            <token id="29" string="a" />
            <token id="30" string="friend" />
          </tokens>
        </chunking>
        <chunking id="3" string="then a young scientist" type="NP">
          <tokens>
            <token id="10" string="then" />
            <token id="11" string="a" />
            <token id="12" string="young" />
            <token id="13" string="scientist" />
          </tokens>
        </chunking>
        <chunking id="4" string="Papua New Guinea" type="NP">
          <tokens>
            <token id="24" string="Papua" />
            <token id="25" string="New" />
            <token id="26" string="Guinea" />
          </tokens>
        </chunking>
        <chunking id="5" string="the NIH 's Dr. Gajdusek" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="NIH" />
            <token id="6" string="'s" />
            <token id="7" string="Dr." />
            <token id="8" string="Gajdusek" />
          </tokens>
        </chunking>
        <chunking id="6" string="big questions" type="NP">
          <tokens>
            <token id="17" string="big" />
            <token id="18" string="questions" />
          </tokens>
        </chunking>
        <chunking id="7" string="visit a friend" type="VP">
          <tokens>
            <token id="28" string="visit" />
            <token id="29" string="a" />
            <token id="30" string="friend" />
          </tokens>
        </chunking>
        <chunking id="8" string="then a young scientist casting about for big questions" type="NP">
          <tokens>
            <token id="10" string="then" />
            <token id="11" string="a" />
            <token id="12" string="young" />
            <token id="13" string="scientist" />
            <token id="14" string="casting" />
            <token id="15" string="about" />
            <token id="16" string="for" />
            <token id="17" string="big" />
            <token id="18" string="questions" />
          </tokens>
        </chunking>
        <chunking id="9" string="casting about for big questions" type="VP">
          <tokens>
            <token id="14" string="casting" />
            <token id="15" string="about" />
            <token id="16" string="for" />
            <token id="17" string="big" />
            <token id="18" string="questions" />
          </tokens>
        </chunking>
        <chunking id="10" string="to visit a friend" type="VP">
          <tokens>
            <token id="27" string="to" />
            <token id="28" string="visit" />
            <token id="29" string="a" />
            <token id="30" string="friend" />
          </tokens>
        </chunking>
        <chunking id="11" string="the NIH 's Dr. Gajdusek , then a young scientist casting about for big questions ," type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="NIH" />
            <token id="6" string="'s" />
            <token id="7" string="Dr." />
            <token id="8" string="Gajdusek" />
            <token id="9" string="," />
            <token id="10" string="then" />
            <token id="11" string="a" />
            <token id="12" string="young" />
            <token id="13" string="scientist" />
            <token id="14" string="casting" />
            <token id="15" string="about" />
            <token id="16" string="for" />
            <token id="17" string="big" />
            <token id="18" string="questions" />
            <token id="19" string="," />
          </tokens>
        </chunking>
        <chunking id="12" string="a trip" type="NP">
          <tokens>
            <token id="21" string="a" />
            <token id="22" string="trip" />
          </tokens>
        </chunking>
        <chunking id="13" string="the NIH 's" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="NIH" />
            <token id="6" string="'s" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">year</governor>
          <dependent id="1">That</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="20">planned</governor>
          <dependent id="2">year</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">NIH</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">Gajdusek</governor>
          <dependent id="5">NIH</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">NIH</governor>
          <dependent id="6">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">Gajdusek</governor>
          <dependent id="7">Dr.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">planned</governor>
          <dependent id="8">Gajdusek</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">scientist</governor>
          <dependent id="10">then</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">scientist</governor>
          <dependent id="11">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">scientist</governor>
          <dependent id="12">young</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="8">Gajdusek</governor>
          <dependent id="13">scientist</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="13">scientist</governor>
          <dependent id="14">casting</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="14">casting</governor>
          <dependent id="15">about</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">questions</governor>
          <dependent id="16">for</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">questions</governor>
          <dependent id="17">big</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">casting</governor>
          <dependent id="18">questions</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="20">planned</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">trip</governor>
          <dependent id="21">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">planned</governor>
          <dependent id="22">trip</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">Guinea</governor>
          <dependent id="23">to</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">Guinea</governor>
          <dependent id="24">Papua</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">Guinea</governor>
          <dependent id="25">New</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">planned</governor>
          <dependent id="26">Guinea</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="28">visit</governor>
          <dependent id="27">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="20">planned</governor>
          <dependent id="28">visit</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">friend</governor>
          <dependent id="29">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="28">visit</governor>
          <dependent id="30">friend</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="year" type="DURATION" score="0.0">
          <tokens>
            <token id="2" string="year" />
          </tokens>
        </entity>
        <entity id="2" string="Papua New Guinea" type="LOCATION" score="0.0">
          <tokens>
            <token id="24" string="Papua" />
            <token id="25" string="New" />
            <token id="26" string="Guinea" />
          </tokens>
        </entity>
        <entity id="3" string="NIH" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="5" string="NIH" />
          </tokens>
        </entity>
        <entity id="4" string="Gajdusek" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Gajdusek" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="36" has_coreference="true">
      <content>He never arrived.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="arrived" lemma="arrive" stem="arriv" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (ADVP (RB never)) (VP (VBD arrived)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="arrived" type="VP">
          <tokens>
            <token id="3" string="arrived" />
          </tokens>
        </chunking>
        <chunking id="2" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">arrived</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="3">arrived</governor>
          <dependent id="2">never</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">arrived</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="37" has_coreference="true">
      <content>En route, he heard that a primitive New Guinea tribe, the Fore, were dying in droves from an unknown brain disorder they called kuru, &amp;quot;the shivering disease,&amp;quot; because it started with tremors.</content>
      <tokens>
        <token id="1" string="En" lemma="en" stem="en" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="route" lemma="route" stem="rout" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="heard" lemma="hear" stem="heard" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="primitive" lemma="primitive" stem="primit" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="New" lemma="New" stem="new" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="true" />
        <token id="10" string="Guinea" lemma="Guinea" stem="guinea" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="true" />
        <token id="11" string="tribe" lemma="tribe" stem="tribe" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Fore" lemma="fore" stem="fore" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="dying" lemma="die" stem="dy" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="droves" lemma="drove" stem="drove" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="unknown" lemma="unknown" stem="unknown" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="brain" lemma="brain" stem="brain" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="disorder" lemma="disorder" stem="disord" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="called" lemma="call" stem="call" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="kuru" lemma="kuru" stem="kuru" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="shivering" lemma="shiver" stem="shiver" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="disease" lemma="disease" stem="diseas" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="33" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="started" lemma="start" stem="start" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="tremors" lemma="tremor" stem="tremor" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN En) (NP (NN route))) (, ,) (NP (PRP he)) (VP (VBD heard) (SBAR (IN that) (S (NP (NP (DT a) (JJ primitive) (NNP New) (NNP Guinea) (NN tribe)) (, ,) (NP (DT the) (NN Fore)) (, ,)) (VP (VBD were) (VP (VBG dying) (PP (IN in) (NP (NNS droves))) (PP (IN from) (NP (NP (DT an) (JJ unknown) (NN brain) (NN disorder)) (SBAR (S (NP (PRP they)) (VP (VBD called) (NP (NN kuru)) (, ,) (S (`` ``) (NP (DT the) (VBG shivering) (NN disease)))))))))))) (, ,) ('' '') (SBAR (IN because) (S (NP (PRP it)) (VP (VBD started) (PP (IN with) (NP (NNS tremors))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="heard that a primitive New Guinea tribe , the Fore , were dying in droves from an unknown brain disorder they called kuru , `` the shivering disease , '' because it started with tremors" type="VP">
          <tokens>
            <token id="5" string="heard" />
            <token id="6" string="that" />
            <token id="7" string="a" />
            <token id="8" string="primitive" />
            <token id="9" string="New" />
            <token id="10" string="Guinea" />
            <token id="11" string="tribe" />
            <token id="12" string="," />
            <token id="13" string="the" />
            <token id="14" string="Fore" />
            <token id="15" string="," />
            <token id="16" string="were" />
            <token id="17" string="dying" />
            <token id="18" string="in" />
            <token id="19" string="droves" />
            <token id="20" string="from" />
            <token id="21" string="an" />
            <token id="22" string="unknown" />
            <token id="23" string="brain" />
            <token id="24" string="disorder" />
            <token id="25" string="they" />
            <token id="26" string="called" />
            <token id="27" string="kuru" />
            <token id="28" string="," />
            <token id="29" string="&quot;" />
            <token id="30" string="the" />
            <token id="31" string="shivering" />
            <token id="32" string="disease" />
            <token id="33" string="," />
            <token id="34" string="&quot;" />
            <token id="35" string="because" />
            <token id="36" string="it" />
            <token id="37" string="started" />
            <token id="38" string="with" />
            <token id="39" string="tremors" />
          </tokens>
        </chunking>
        <chunking id="2" string="dying in droves from an unknown brain disorder they called kuru , `` the shivering disease" type="VP">
          <tokens>
            <token id="17" string="dying" />
            <token id="18" string="in" />
            <token id="19" string="droves" />
            <token id="20" string="from" />
            <token id="21" string="an" />
            <token id="22" string="unknown" />
            <token id="23" string="brain" />
            <token id="24" string="disorder" />
            <token id="25" string="they" />
            <token id="26" string="called" />
            <token id="27" string="kuru" />
            <token id="28" string="," />
            <token id="29" string="&quot;" />
            <token id="30" string="the" />
            <token id="31" string="shivering" />
            <token id="32" string="disease" />
          </tokens>
        </chunking>
        <chunking id="3" string="they called kuru , `` the shivering disease" type="SBAR">
          <tokens>
            <token id="25" string="they" />
            <token id="26" string="called" />
            <token id="27" string="kuru" />
            <token id="28" string="," />
            <token id="29" string="&quot;" />
            <token id="30" string="the" />
            <token id="31" string="shivering" />
            <token id="32" string="disease" />
          </tokens>
        </chunking>
        <chunking id="4" string="because it started with tremors" type="SBAR">
          <tokens>
            <token id="35" string="because" />
            <token id="36" string="it" />
            <token id="37" string="started" />
            <token id="38" string="with" />
            <token id="39" string="tremors" />
          </tokens>
        </chunking>
        <chunking id="5" string="the Fore" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="Fore" />
          </tokens>
        </chunking>
        <chunking id="6" string="it" type="NP">
          <tokens>
            <token id="36" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="a primitive New Guinea tribe" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="primitive" />
            <token id="9" string="New" />
            <token id="10" string="Guinea" />
            <token id="11" string="tribe" />
          </tokens>
        </chunking>
        <chunking id="8" string="that a primitive New Guinea tribe , the Fore , were dying in droves from an unknown brain disorder they called kuru , `` the shivering disease" type="SBAR">
          <tokens>
            <token id="6" string="that" />
            <token id="7" string="a" />
            <token id="8" string="primitive" />
            <token id="9" string="New" />
            <token id="10" string="Guinea" />
            <token id="11" string="tribe" />
            <token id="12" string="," />
            <token id="13" string="the" />
            <token id="14" string="Fore" />
            <token id="15" string="," />
            <token id="16" string="were" />
            <token id="17" string="dying" />
            <token id="18" string="in" />
            <token id="19" string="droves" />
            <token id="20" string="from" />
            <token id="21" string="an" />
            <token id="22" string="unknown" />
            <token id="23" string="brain" />
            <token id="24" string="disorder" />
            <token id="25" string="they" />
            <token id="26" string="called" />
            <token id="27" string="kuru" />
            <token id="28" string="," />
            <token id="29" string="&quot;" />
            <token id="30" string="the" />
            <token id="31" string="shivering" />
            <token id="32" string="disease" />
          </tokens>
        </chunking>
        <chunking id="9" string="were dying in droves from an unknown brain disorder they called kuru , `` the shivering disease" type="VP">
          <tokens>
            <token id="16" string="were" />
            <token id="17" string="dying" />
            <token id="18" string="in" />
            <token id="19" string="droves" />
            <token id="20" string="from" />
            <token id="21" string="an" />
            <token id="22" string="unknown" />
            <token id="23" string="brain" />
            <token id="24" string="disorder" />
            <token id="25" string="they" />
            <token id="26" string="called" />
            <token id="27" string="kuru" />
            <token id="28" string="," />
            <token id="29" string="&quot;" />
            <token id="30" string="the" />
            <token id="31" string="shivering" />
            <token id="32" string="disease" />
          </tokens>
        </chunking>
        <chunking id="10" string="an unknown brain disorder" type="NP">
          <tokens>
            <token id="21" string="an" />
            <token id="22" string="unknown" />
            <token id="23" string="brain" />
            <token id="24" string="disorder" />
          </tokens>
        </chunking>
        <chunking id="11" string="they" type="NP">
          <tokens>
            <token id="25" string="they" />
          </tokens>
        </chunking>
        <chunking id="12" string="route" type="NP">
          <tokens>
            <token id="2" string="route" />
          </tokens>
        </chunking>
        <chunking id="13" string="tremors" type="NP">
          <tokens>
            <token id="39" string="tremors" />
          </tokens>
        </chunking>
        <chunking id="14" string="started with tremors" type="VP">
          <tokens>
            <token id="37" string="started" />
            <token id="38" string="with" />
            <token id="39" string="tremors" />
          </tokens>
        </chunking>
        <chunking id="15" string="the shivering disease" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="shivering" />
            <token id="32" string="disease" />
          </tokens>
        </chunking>
        <chunking id="16" string="he" type="NP">
          <tokens>
            <token id="4" string="he" />
          </tokens>
        </chunking>
        <chunking id="17" string="a primitive New Guinea tribe , the Fore ," type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="primitive" />
            <token id="9" string="New" />
            <token id="10" string="Guinea" />
            <token id="11" string="tribe" />
            <token id="12" string="," />
            <token id="13" string="the" />
            <token id="14" string="Fore" />
            <token id="15" string="," />
          </tokens>
        </chunking>
        <chunking id="18" string="called kuru , `` the shivering disease" type="VP">
          <tokens>
            <token id="26" string="called" />
            <token id="27" string="kuru" />
            <token id="28" string="," />
            <token id="29" string="&quot;" />
            <token id="30" string="the" />
            <token id="31" string="shivering" />
            <token id="32" string="disease" />
          </tokens>
        </chunking>
        <chunking id="19" string="droves" type="NP">
          <tokens>
            <token id="19" string="droves" />
          </tokens>
        </chunking>
        <chunking id="20" string="an unknown brain disorder they called kuru , `` the shivering disease" type="NP">
          <tokens>
            <token id="21" string="an" />
            <token id="22" string="unknown" />
            <token id="23" string="brain" />
            <token id="24" string="disorder" />
            <token id="25" string="they" />
            <token id="26" string="called" />
            <token id="27" string="kuru" />
            <token id="28" string="," />
            <token id="29" string="&quot;" />
            <token id="30" string="the" />
            <token id="31" string="shivering" />
            <token id="32" string="disease" />
          </tokens>
        </chunking>
        <chunking id="21" string="kuru" type="NP">
          <tokens>
            <token id="27" string="kuru" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">route</governor>
          <dependent id="1">En</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">heard</governor>
          <dependent id="2">route</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">heard</governor>
          <dependent id="4">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">heard</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">dying</governor>
          <dependent id="6">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">tribe</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">tribe</governor>
          <dependent id="8">primitive</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">tribe</governor>
          <dependent id="9">New</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">tribe</governor>
          <dependent id="10">Guinea</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">dying</governor>
          <dependent id="11">tribe</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">Fore</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="11">tribe</governor>
          <dependent id="14">Fore</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="17">dying</governor>
          <dependent id="16">were</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">heard</governor>
          <dependent id="17">dying</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">droves</governor>
          <dependent id="18">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">dying</governor>
          <dependent id="19">droves</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">disorder</governor>
          <dependent id="20">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">disorder</governor>
          <dependent id="21">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">disorder</governor>
          <dependent id="22">unknown</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">disorder</governor>
          <dependent id="23">brain</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">dying</governor>
          <dependent id="24">disorder</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">called</governor>
          <dependent id="25">they</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="24">disorder</governor>
          <dependent id="26">called</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="26">called</governor>
          <dependent id="27">kuru</dependent>
        </dependency>
        <dependency type="det">
          <governor id="32">disease</governor>
          <dependent id="30">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="32">disease</governor>
          <dependent id="31">shivering</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="26">called</governor>
          <dependent id="32">disease</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="37">started</governor>
          <dependent id="35">because</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="37">started</governor>
          <dependent id="36">it</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="5">heard</governor>
          <dependent id="37">started</dependent>
        </dependency>
        <dependency type="case">
          <governor id="39">tremors</governor>
          <dependent id="38">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="37">started</governor>
          <dependent id="39">tremors</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="New Guinea" type="LOCATION" score="0.0">
          <tokens>
            <token id="9" string="New" />
            <token id="10" string="Guinea" />
          </tokens>
        </entity>
        <entity id="2" string="disease" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="32" string="disease" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="38" has_coreference="true">
      <content>Fascinated, he dropped everything, plunged into the backwoods with a local doctor and took charge of investigating the affair, to the great annoyance of Australian authorities then overseeing the area.</content>
      <tokens>
        <token id="1" string="Fascinated" lemma="fascinate" stem="fascin" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="dropped" lemma="drop" stem="drop" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="everything" lemma="everything" stem="everyth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="plunged" lemma="plunge" stem="plung" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="backwoods" lemma="backwoods" stem="backwood" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="local" lemma="local" stem="local" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="doctor" lemma="doctor" stem="doctor" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="took" lemma="take" stem="took" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="charge" lemma="charge" stem="charg" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="investigating" lemma="investigate" stem="investig" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="affair" lemma="affair" stem="affair" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="great" lemma="great" stem="great" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="annoyance" lemma="annoyance" stem="annoy" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="Australian" lemma="australian" stem="australian" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="29" string="authorities" lemma="authority" stem="author" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="overseeing" lemma="oversee" stem="overse" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="33" string="area" lemma="area" stem="area" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="34" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (VBN Fascinated))) (, ,) (NP (PRP he)) (VP (VP (VBD dropped) (NP (NN everything))) (, ,) (VP (VBD plunged) (PP (IN into) (NP (DT the) (NNS backwoods))) (PP (IN with) (NP (DT a) (JJ local) (NN doctor)))) (CC and) (VP (VBD took) (NP (NP (NN charge)) (PP (IN of) (S (VP (VBG investigating) (NP (DT the) (NN affair)))))) (, ,) (PP (TO to) (NP (NP (DT the) (JJ great) (NN annoyance)) (PP (IN of) (NP (NP (JJ Australian) (NNS authorities)) (VP (ADVP (RB then)) (VBG overseeing) (NP (DT the) (NN area))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the area" type="NP">
          <tokens>
            <token id="32" string="the" />
            <token id="33" string="area" />
          </tokens>
        </chunking>
        <chunking id="2" string="a local doctor" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="local" />
            <token id="14" string="doctor" />
          </tokens>
        </chunking>
        <chunking id="3" string="charge" type="NP">
          <tokens>
            <token id="17" string="charge" />
          </tokens>
        </chunking>
        <chunking id="4" string="plunged into the backwoods with a local doctor" type="VP">
          <tokens>
            <token id="7" string="plunged" />
            <token id="8" string="into" />
            <token id="9" string="the" />
            <token id="10" string="backwoods" />
            <token id="11" string="with" />
            <token id="12" string="a" />
            <token id="13" string="local" />
            <token id="14" string="doctor" />
          </tokens>
        </chunking>
        <chunking id="5" string="the great annoyance" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="great" />
            <token id="26" string="annoyance" />
          </tokens>
        </chunking>
        <chunking id="6" string="investigating the affair" type="VP">
          <tokens>
            <token id="19" string="investigating" />
            <token id="20" string="the" />
            <token id="21" string="affair" />
          </tokens>
        </chunking>
        <chunking id="7" string="charge of investigating the affair" type="NP">
          <tokens>
            <token id="17" string="charge" />
            <token id="18" string="of" />
            <token id="19" string="investigating" />
            <token id="20" string="the" />
            <token id="21" string="affair" />
          </tokens>
        </chunking>
        <chunking id="8" string="dropped everything" type="VP">
          <tokens>
            <token id="4" string="dropped" />
            <token id="5" string="everything" />
          </tokens>
        </chunking>
        <chunking id="9" string="the affair" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="affair" />
          </tokens>
        </chunking>
        <chunking id="10" string="dropped everything , plunged into the backwoods with a local doctor and took charge of investigating the affair , to the great annoyance of Australian authorities then overseeing the area" type="VP">
          <tokens>
            <token id="4" string="dropped" />
            <token id="5" string="everything" />
            <token id="6" string="," />
            <token id="7" string="plunged" />
            <token id="8" string="into" />
            <token id="9" string="the" />
            <token id="10" string="backwoods" />
            <token id="11" string="with" />
            <token id="12" string="a" />
            <token id="13" string="local" />
            <token id="14" string="doctor" />
            <token id="15" string="and" />
            <token id="16" string="took" />
            <token id="17" string="charge" />
            <token id="18" string="of" />
            <token id="19" string="investigating" />
            <token id="20" string="the" />
            <token id="21" string="affair" />
            <token id="22" string="," />
            <token id="23" string="to" />
            <token id="24" string="the" />
            <token id="25" string="great" />
            <token id="26" string="annoyance" />
            <token id="27" string="of" />
            <token id="28" string="Australian" />
            <token id="29" string="authorities" />
            <token id="30" string="then" />
            <token id="31" string="overseeing" />
            <token id="32" string="the" />
            <token id="33" string="area" />
          </tokens>
        </chunking>
        <chunking id="11" string="the great annoyance of Australian authorities then overseeing the area" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="great" />
            <token id="26" string="annoyance" />
            <token id="27" string="of" />
            <token id="28" string="Australian" />
            <token id="29" string="authorities" />
            <token id="30" string="then" />
            <token id="31" string="overseeing" />
            <token id="32" string="the" />
            <token id="33" string="area" />
          </tokens>
        </chunking>
        <chunking id="12" string="Australian authorities" type="NP">
          <tokens>
            <token id="28" string="Australian" />
            <token id="29" string="authorities" />
          </tokens>
        </chunking>
        <chunking id="13" string="took charge of investigating the affair , to the great annoyance of Australian authorities then overseeing the area" type="VP">
          <tokens>
            <token id="16" string="took" />
            <token id="17" string="charge" />
            <token id="18" string="of" />
            <token id="19" string="investigating" />
            <token id="20" string="the" />
            <token id="21" string="affair" />
            <token id="22" string="," />
            <token id="23" string="to" />
            <token id="24" string="the" />
            <token id="25" string="great" />
            <token id="26" string="annoyance" />
            <token id="27" string="of" />
            <token id="28" string="Australian" />
            <token id="29" string="authorities" />
            <token id="30" string="then" />
            <token id="31" string="overseeing" />
            <token id="32" string="the" />
            <token id="33" string="area" />
          </tokens>
        </chunking>
        <chunking id="14" string="then overseeing the area" type="VP">
          <tokens>
            <token id="30" string="then" />
            <token id="31" string="overseeing" />
            <token id="32" string="the" />
            <token id="33" string="area" />
          </tokens>
        </chunking>
        <chunking id="15" string="the backwoods" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="backwoods" />
          </tokens>
        </chunking>
        <chunking id="16" string="Fascinated" type="VP">
          <tokens>
            <token id="1" string="Fascinated" />
          </tokens>
        </chunking>
        <chunking id="17" string="he" type="NP">
          <tokens>
            <token id="3" string="he" />
          </tokens>
        </chunking>
        <chunking id="18" string="everything" type="NP">
          <tokens>
            <token id="5" string="everything" />
          </tokens>
        </chunking>
        <chunking id="19" string="Australian authorities then overseeing the area" type="NP">
          <tokens>
            <token id="28" string="Australian" />
            <token id="29" string="authorities" />
            <token id="30" string="then" />
            <token id="31" string="overseeing" />
            <token id="32" string="the" />
            <token id="33" string="area" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advcl">
          <governor id="4">dropped</governor>
          <dependent id="1">Fascinated</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">dropped</governor>
          <dependent id="3">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">dropped</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">dropped</governor>
          <dependent id="5">everything</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">dropped</governor>
          <dependent id="7">plunged</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">backwoods</governor>
          <dependent id="8">into</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">backwoods</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">plunged</governor>
          <dependent id="10">backwoods</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">doctor</governor>
          <dependent id="11">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">doctor</governor>
          <dependent id="12">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">doctor</governor>
          <dependent id="13">local</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">plunged</governor>
          <dependent id="14">doctor</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">dropped</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">dropped</governor>
          <dependent id="16">took</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">took</governor>
          <dependent id="17">charge</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">investigating</governor>
          <dependent id="18">of</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="17">charge</governor>
          <dependent id="19">investigating</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">affair</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">investigating</governor>
          <dependent id="21">affair</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">annoyance</governor>
          <dependent id="23">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">annoyance</governor>
          <dependent id="24">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">annoyance</governor>
          <dependent id="25">great</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">took</governor>
          <dependent id="26">annoyance</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">authorities</governor>
          <dependent id="27">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="29">authorities</governor>
          <dependent id="28">Australian</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">annoyance</governor>
          <dependent id="29">authorities</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="31">overseeing</governor>
          <dependent id="30">then</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="29">authorities</governor>
          <dependent id="31">overseeing</dependent>
        </dependency>
        <dependency type="det">
          <governor id="33">area</governor>
          <dependent id="32">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="31">overseeing</governor>
          <dependent id="33">area</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Australian" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="28" string="Australian" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="39" has_coreference="true">
      <content>&amp;quot;Gajdusek . . . has an intelligence quotient up in the 180s and the emotional immaturity of a 15-year-old,&amp;quot; one of his mentors warned the Australians in a letter, and &amp;quot;won&amp;apost;t let danger, physical difficulty, or other people&amp;apost;s feelings interfere in the least with what he wants to do.&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="Gajdusek" lemma="Gajdusek" stem="gajdusek" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string=". . ." lemma="..." stem=". . ." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="intelligence" lemma="intelligence" stem="intellig" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="quotient" lemma="quotient" stem="quotient" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="up" lemma="up" stem="up" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="180s" lemma="180" stem="180" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="emotional" lemma="emotional" stem="emot" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="immaturity" lemma="immaturity" stem="immatur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="15-year-old" lemma="15-year-old" stem="15-year-old" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="22" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="mentors" lemma="mentor" stem="mentor" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="warned" lemma="warn" stem="warn" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="Australians" lemma="Australians" stem="australian" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="28" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="letter" lemma="letter" stem="letter" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="wo" lemma="will" stem="wo" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="let" lemma="let" stem="let" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="danger" lemma="danger" stem="danger" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="physical" lemma="physical" stem="physic" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="difficulty" lemma="difficulty" stem="difficulti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="45" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="46" string="feelings" lemma="feeling" stem="feel" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="47" string="interfere" lemma="interfere" stem="interfer" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="48" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="49" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="50" string="least" lemma="least" stem="least" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="51" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="52" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="53" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="54" string="wants" lemma="want" stem="want" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="55" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="56" string="do" lemma="do" stem="do" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="57" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="58" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (`` ``) (NNP Gajdusek)) (: ...) (S (VP (VP (VBZ has) (NP (NP (DT an) (NN intelligence) (NN quotient)) (ADVP (RB up) (PP (IN in) (NP (NP (DT the) (NNS 180s)) (CC and) (NP (DT the) (JJ emotional) (NN immaturity))))) (PP (IN of) (NP (DT a) (JJ 15-year-old))))) (PRN (, ,) ('' '') (S (NP (NP (CD one)) (PP (IN of) (NP (PRP$ his) (NNS mentors)))) (VP (VBD warned) (NP (DT the) (NNPS Australians)) (PP (IN in) (NP (DT a) (NN letter))))) (, ,)) (CC and) (`` ``) (VP (MD wo) (RB n't) (VP (VB let) (NP (NP (NN danger)) (, ,) (NP (JJ physical) (NN difficulty)) (, ,) (CC or) (NP (NP (JJ other) (NNS people) (POS 's)) (NNS feelings))))))) (VP (VBP interfere) (PP (IN in) (NP (NP (DT the) (JJS least)) (PP (IN with) (SBAR (WHNP (WP what)) (S (NP (PRP he)) (VP (VBZ wants) (S (VP (TO to) (VP (VB do))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="a 15-year-old" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="15-year-old" />
          </tokens>
        </chunking>
        <chunking id="2" string="wants to do" type="VP">
          <tokens>
            <token id="54" string="wants" />
            <token id="55" string="to" />
            <token id="56" string="do" />
          </tokens>
        </chunking>
        <chunking id="3" string="wo n't let danger , physical difficulty , or other people 's feelings" type="VP">
          <tokens>
            <token id="34" string="wo" />
            <token id="35" string="n't" />
            <token id="36" string="let" />
            <token id="37" string="danger" />
            <token id="38" string="," />
            <token id="39" string="physical" />
            <token id="40" string="difficulty" />
            <token id="41" string="," />
            <token id="42" string="or" />
            <token id="43" string="other" />
            <token id="44" string="people" />
            <token id="45" string="'s" />
            <token id="46" string="feelings" />
          </tokens>
        </chunking>
        <chunking id="4" string="one" type="NP">
          <tokens>
            <token id="21" string="one" />
          </tokens>
        </chunking>
        <chunking id="5" string="one of his mentors" type="NP">
          <tokens>
            <token id="21" string="one" />
            <token id="22" string="of" />
            <token id="23" string="his" />
            <token id="24" string="mentors" />
          </tokens>
        </chunking>
        <chunking id="6" string="the least with what he wants to do" type="NP">
          <tokens>
            <token id="49" string="the" />
            <token id="50" string="least" />
            <token id="51" string="with" />
            <token id="52" string="what" />
            <token id="53" string="he" />
            <token id="54" string="wants" />
            <token id="55" string="to" />
            <token id="56" string="do" />
          </tokens>
        </chunking>
        <chunking id="7" string="a letter" type="NP">
          <tokens>
            <token id="29" string="a" />
            <token id="30" string="letter" />
          </tokens>
        </chunking>
        <chunking id="8" string="the Australians" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="Australians" />
          </tokens>
        </chunking>
        <chunking id="9" string="`` Gajdusek" type="NP">
          <tokens>
            <token id="1" string="&quot;" />
            <token id="2" string="Gajdusek" />
          </tokens>
        </chunking>
        <chunking id="10" string="the 180s and the emotional immaturity" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="180s" />
            <token id="12" string="and" />
            <token id="13" string="the" />
            <token id="14" string="emotional" />
            <token id="15" string="immaturity" />
          </tokens>
        </chunking>
        <chunking id="11" string="the least" type="NP">
          <tokens>
            <token id="49" string="the" />
            <token id="50" string="least" />
          </tokens>
        </chunking>
        <chunking id="12" string="the 180s" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="180s" />
          </tokens>
        </chunking>
        <chunking id="13" string="he" type="NP">
          <tokens>
            <token id="53" string="he" />
          </tokens>
        </chunking>
        <chunking id="14" string="interfere in the least with what he wants to do" type="VP">
          <tokens>
            <token id="47" string="interfere" />
            <token id="48" string="in" />
            <token id="49" string="the" />
            <token id="50" string="least" />
            <token id="51" string="with" />
            <token id="52" string="what" />
            <token id="53" string="he" />
            <token id="54" string="wants" />
            <token id="55" string="to" />
            <token id="56" string="do" />
          </tokens>
        </chunking>
        <chunking id="15" string="danger , physical difficulty , or other people 's feelings" type="NP">
          <tokens>
            <token id="37" string="danger" />
            <token id="38" string="," />
            <token id="39" string="physical" />
            <token id="40" string="difficulty" />
            <token id="41" string="," />
            <token id="42" string="or" />
            <token id="43" string="other" />
            <token id="44" string="people" />
            <token id="45" string="'s" />
            <token id="46" string="feelings" />
          </tokens>
        </chunking>
        <chunking id="16" string="physical difficulty" type="NP">
          <tokens>
            <token id="39" string="physical" />
            <token id="40" string="difficulty" />
          </tokens>
        </chunking>
        <chunking id="17" string="warned the Australians in a letter" type="VP">
          <tokens>
            <token id="25" string="warned" />
            <token id="26" string="the" />
            <token id="27" string="Australians" />
            <token id="28" string="in" />
            <token id="29" string="a" />
            <token id="30" string="letter" />
          </tokens>
        </chunking>
        <chunking id="18" string="what he wants to do" type="SBAR">
          <tokens>
            <token id="52" string="what" />
            <token id="53" string="he" />
            <token id="54" string="wants" />
            <token id="55" string="to" />
            <token id="56" string="do" />
          </tokens>
        </chunking>
        <chunking id="19" string="other people 's feelings" type="NP">
          <tokens>
            <token id="43" string="other" />
            <token id="44" string="people" />
            <token id="45" string="'s" />
            <token id="46" string="feelings" />
          </tokens>
        </chunking>
        <chunking id="20" string="let danger , physical difficulty , or other people 's feelings" type="VP">
          <tokens>
            <token id="36" string="let" />
            <token id="37" string="danger" />
            <token id="38" string="," />
            <token id="39" string="physical" />
            <token id="40" string="difficulty" />
            <token id="41" string="," />
            <token id="42" string="or" />
            <token id="43" string="other" />
            <token id="44" string="people" />
            <token id="45" string="'s" />
            <token id="46" string="feelings" />
          </tokens>
        </chunking>
        <chunking id="21" string="an intelligence quotient" type="NP">
          <tokens>
            <token id="5" string="an" />
            <token id="6" string="intelligence" />
            <token id="7" string="quotient" />
          </tokens>
        </chunking>
        <chunking id="22" string="do" type="VP">
          <tokens>
            <token id="56" string="do" />
          </tokens>
        </chunking>
        <chunking id="23" string="danger" type="NP">
          <tokens>
            <token id="37" string="danger" />
          </tokens>
        </chunking>
        <chunking id="24" string="his mentors" type="NP">
          <tokens>
            <token id="23" string="his" />
            <token id="24" string="mentors" />
          </tokens>
        </chunking>
        <chunking id="25" string="has an intelligence quotient up in the 180s and the emotional immaturity of a 15-year-old , '' one of his mentors warned the Australians in a letter , and `` wo n't let danger , physical difficulty , or other people 's feelings" type="VP">
          <tokens>
            <token id="4" string="has" />
            <token id="5" string="an" />
            <token id="6" string="intelligence" />
            <token id="7" string="quotient" />
            <token id="8" string="up" />
            <token id="9" string="in" />
            <token id="10" string="the" />
            <token id="11" string="180s" />
            <token id="12" string="and" />
            <token id="13" string="the" />
            <token id="14" string="emotional" />
            <token id="15" string="immaturity" />
            <token id="16" string="of" />
            <token id="17" string="a" />
            <token id="18" string="15-year-old" />
            <token id="19" string="," />
            <token id="20" string="&quot;" />
            <token id="21" string="one" />
            <token id="22" string="of" />
            <token id="23" string="his" />
            <token id="24" string="mentors" />
            <token id="25" string="warned" />
            <token id="26" string="the" />
            <token id="27" string="Australians" />
            <token id="28" string="in" />
            <token id="29" string="a" />
            <token id="30" string="letter" />
            <token id="31" string="," />
            <token id="32" string="and" />
            <token id="33" string="&quot;" />
            <token id="34" string="wo" />
            <token id="35" string="n't" />
            <token id="36" string="let" />
            <token id="37" string="danger" />
            <token id="38" string="," />
            <token id="39" string="physical" />
            <token id="40" string="difficulty" />
            <token id="41" string="," />
            <token id="42" string="or" />
            <token id="43" string="other" />
            <token id="44" string="people" />
            <token id="45" string="'s" />
            <token id="46" string="feelings" />
          </tokens>
        </chunking>
        <chunking id="26" string="to do" type="VP">
          <tokens>
            <token id="55" string="to" />
            <token id="56" string="do" />
          </tokens>
        </chunking>
        <chunking id="27" string="has an intelligence quotient up in the 180s and the emotional immaturity of a 15-year-old" type="VP">
          <tokens>
            <token id="4" string="has" />
            <token id="5" string="an" />
            <token id="6" string="intelligence" />
            <token id="7" string="quotient" />
            <token id="8" string="up" />
            <token id="9" string="in" />
            <token id="10" string="the" />
            <token id="11" string="180s" />
            <token id="12" string="and" />
            <token id="13" string="the" />
            <token id="14" string="emotional" />
            <token id="15" string="immaturity" />
            <token id="16" string="of" />
            <token id="17" string="a" />
            <token id="18" string="15-year-old" />
          </tokens>
        </chunking>
        <chunking id="28" string="an intelligence quotient up in the 180s and the emotional immaturity of a 15-year-old" type="NP">
          <tokens>
            <token id="5" string="an" />
            <token id="6" string="intelligence" />
            <token id="7" string="quotient" />
            <token id="8" string="up" />
            <token id="9" string="in" />
            <token id="10" string="the" />
            <token id="11" string="180s" />
            <token id="12" string="and" />
            <token id="13" string="the" />
            <token id="14" string="emotional" />
            <token id="15" string="immaturity" />
            <token id="16" string="of" />
            <token id="17" string="a" />
            <token id="18" string="15-year-old" />
          </tokens>
        </chunking>
        <chunking id="29" string="the emotional immaturity" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="emotional" />
            <token id="15" string="immaturity" />
          </tokens>
        </chunking>
        <chunking id="30" string="other people 's" type="NP">
          <tokens>
            <token id="43" string="other" />
            <token id="44" string="people" />
            <token id="45" string="'s" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="47">interfere</governor>
          <dependent id="2">Gajdusek</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="47">interfere</governor>
          <dependent id="4">has</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">quotient</governor>
          <dependent id="5">an</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">quotient</governor>
          <dependent id="6">intelligence</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">has</governor>
          <dependent id="7">quotient</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">quotient</governor>
          <dependent id="8">up</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">180s</governor>
          <dependent id="9">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">180s</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">up</governor>
          <dependent id="11">180s</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="11">180s</governor>
          <dependent id="12">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">immaturity</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">immaturity</governor>
          <dependent id="14">emotional</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">180s</governor>
          <dependent id="15">immaturity</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">15-year-old</governor>
          <dependent id="16">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">15-year-old</governor>
          <dependent id="17">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">quotient</governor>
          <dependent id="18">15-year-old</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">warned</governor>
          <dependent id="21">one</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">mentors</governor>
          <dependent id="22">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="24">mentors</governor>
          <dependent id="23">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">one</governor>
          <dependent id="24">mentors</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="4">has</governor>
          <dependent id="25">warned</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">Australians</governor>
          <dependent id="26">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="25">warned</governor>
          <dependent id="27">Australians</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">letter</governor>
          <dependent id="28">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">letter</governor>
          <dependent id="29">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">warned</governor>
          <dependent id="30">letter</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">has</governor>
          <dependent id="32">and</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="36">let</governor>
          <dependent id="34">wo</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="36">let</governor>
          <dependent id="35">n't</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">has</governor>
          <dependent id="36">let</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="36">let</governor>
          <dependent id="37">danger</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="40">difficulty</governor>
          <dependent id="39">physical</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="37">danger</governor>
          <dependent id="40">difficulty</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="37">danger</governor>
          <dependent id="42">or</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="44">people</governor>
          <dependent id="43">other</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="46">feelings</governor>
          <dependent id="44">people</dependent>
        </dependency>
        <dependency type="case">
          <governor id="44">people</governor>
          <dependent id="45">'s</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="37">danger</governor>
          <dependent id="46">feelings</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="47">interfere</dependent>
        </dependency>
        <dependency type="case">
          <governor id="50">least</governor>
          <dependent id="48">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="50">least</governor>
          <dependent id="49">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="47">interfere</governor>
          <dependent id="50">least</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="54">wants</governor>
          <dependent id="51">with</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="54">wants</governor>
          <dependent id="52">what</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="54">wants</governor>
          <dependent id="53">he</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="50">least</governor>
          <dependent id="54">wants</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="56">do</governor>
          <dependent id="55">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="54">wants</governor>
          <dependent id="56">do</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Australians" type="MISC" score="0.0">
          <tokens>
            <token id="27" string="Australians" />
          </tokens>
        </entity>
        <entity id="2" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="21" string="one" />
          </tokens>
        </entity>
        <entity id="3" string="15-year-old" type="DURATION" score="0.0">
          <tokens>
            <token id="18" string="15-year-old" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="40" has_coreference="true">
      <content>In short, he was perfect for the job.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="short" lemma="short" stem="short" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="perfect" lemma="perfect" stem="perfect" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="job" lemma="job" stem="job" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (ADJP (JJ short))) (, ,) (NP (PRP he)) (VP (VBD was) (ADJP (JJ perfect) (PP (IN for) (NP (DT the) (NN job))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="perfect for the job" type="ADJP">
          <tokens>
            <token id="6" string="perfect" />
            <token id="7" string="for" />
            <token id="8" string="the" />
            <token id="9" string="job" />
          </tokens>
        </chunking>
        <chunking id="2" string="the job" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="job" />
          </tokens>
        </chunking>
        <chunking id="3" string="he" type="NP">
          <tokens>
            <token id="4" string="he" />
          </tokens>
        </chunking>
        <chunking id="4" string="was perfect for the job" type="VP">
          <tokens>
            <token id="5" string="was" />
            <token id="6" string="perfect" />
            <token id="7" string="for" />
            <token id="8" string="the" />
            <token id="9" string="job" />
          </tokens>
        </chunking>
        <chunking id="5" string="short" type="ADJP">
          <tokens>
            <token id="2" string="short" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">short</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="6">perfect</governor>
          <dependent id="2">short</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">perfect</governor>
          <dependent id="4">he</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">perfect</governor>
          <dependent id="5">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">perfect</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">job</governor>
          <dependent id="7">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">job</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">perfect</governor>
          <dependent id="9">job</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="41" has_coreference="true">
      <content>Soon kuru victims&amp;apost; brains started issuing from the heart of darkness to distant medical centers, compliments of Dr. Gajdusek.</content>
      <tokens>
        <token id="1" string="Soon" lemma="soon" stem="soon" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="kuru" lemma="kuru" stem="kuru" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="victims" lemma="victim" stem="victim" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="brains" lemma="brain" stem="brain" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="started" lemma="start" stem="start" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="issuing" lemma="issue" stem="issu" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="heart" lemma="heart" stem="heart" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="darkness" lemma="darkness" stem="dark" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="distant" lemma="distant" stem="distant" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="medical" lemma="medical" stem="medic" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="centers" lemma="center" stem="center" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="compliments" lemma="compliment" stem="compliment" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="Dr." lemma="Dr." stem="dr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="21" string="Gajdusek" lemma="Gajdusek" stem="gajdusek" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Soon)) (NP (NP (NN kuru) (NNS victims) (POS ')) (NNS brains)) (VP (VBD started) (S (VP (VBG issuing) (PP (IN from) (NP (NP (DT the) (NN heart)) (PP (IN of) (NP (NN darkness))))) (PP (TO to) (NP (NP (JJ distant) (JJ medical) (NNS centers)) (, ,) (NP (NP (NNS compliments)) (PP (IN of) (NP (NNP Dr.) (NNP Gajdusek))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="distant medical centers" type="NP">
          <tokens>
            <token id="14" string="distant" />
            <token id="15" string="medical" />
            <token id="16" string="centers" />
          </tokens>
        </chunking>
        <chunking id="2" string="the heart" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="heart" />
          </tokens>
        </chunking>
        <chunking id="3" string="the heart of darkness" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="heart" />
            <token id="11" string="of" />
            <token id="12" string="darkness" />
          </tokens>
        </chunking>
        <chunking id="4" string="kuru victims ' brains" type="NP">
          <tokens>
            <token id="2" string="kuru" />
            <token id="3" string="victims" />
            <token id="4" string="'" />
            <token id="5" string="brains" />
          </tokens>
        </chunking>
        <chunking id="5" string="distant medical centers , compliments of Dr. Gajdusek" type="NP">
          <tokens>
            <token id="14" string="distant" />
            <token id="15" string="medical" />
            <token id="16" string="centers" />
            <token id="17" string="," />
            <token id="18" string="compliments" />
            <token id="19" string="of" />
            <token id="20" string="Dr." />
            <token id="21" string="Gajdusek" />
          </tokens>
        </chunking>
        <chunking id="6" string="compliments" type="NP">
          <tokens>
            <token id="18" string="compliments" />
          </tokens>
        </chunking>
        <chunking id="7" string="Dr. Gajdusek" type="NP">
          <tokens>
            <token id="20" string="Dr." />
            <token id="21" string="Gajdusek" />
          </tokens>
        </chunking>
        <chunking id="8" string="started issuing from the heart of darkness to distant medical centers , compliments of Dr. Gajdusek" type="VP">
          <tokens>
            <token id="6" string="started" />
            <token id="7" string="issuing" />
            <token id="8" string="from" />
            <token id="9" string="the" />
            <token id="10" string="heart" />
            <token id="11" string="of" />
            <token id="12" string="darkness" />
            <token id="13" string="to" />
            <token id="14" string="distant" />
            <token id="15" string="medical" />
            <token id="16" string="centers" />
            <token id="17" string="," />
            <token id="18" string="compliments" />
            <token id="19" string="of" />
            <token id="20" string="Dr." />
            <token id="21" string="Gajdusek" />
          </tokens>
        </chunking>
        <chunking id="9" string="compliments of Dr. Gajdusek" type="NP">
          <tokens>
            <token id="18" string="compliments" />
            <token id="19" string="of" />
            <token id="20" string="Dr." />
            <token id="21" string="Gajdusek" />
          </tokens>
        </chunking>
        <chunking id="10" string="issuing from the heart of darkness to distant medical centers , compliments of Dr. Gajdusek" type="VP">
          <tokens>
            <token id="7" string="issuing" />
            <token id="8" string="from" />
            <token id="9" string="the" />
            <token id="10" string="heart" />
            <token id="11" string="of" />
            <token id="12" string="darkness" />
            <token id="13" string="to" />
            <token id="14" string="distant" />
            <token id="15" string="medical" />
            <token id="16" string="centers" />
            <token id="17" string="," />
            <token id="18" string="compliments" />
            <token id="19" string="of" />
            <token id="20" string="Dr." />
            <token id="21" string="Gajdusek" />
          </tokens>
        </chunking>
        <chunking id="11" string="darkness" type="NP">
          <tokens>
            <token id="12" string="darkness" />
          </tokens>
        </chunking>
        <chunking id="12" string="kuru victims '" type="NP">
          <tokens>
            <token id="2" string="kuru" />
            <token id="3" string="victims" />
            <token id="4" string="'" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="6">started</governor>
          <dependent id="1">Soon</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">victims</governor>
          <dependent id="2">kuru</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">brains</governor>
          <dependent id="3">victims</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">victims</governor>
          <dependent id="4">'</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">started</governor>
          <dependent id="5">brains</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">started</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">started</governor>
          <dependent id="7">issuing</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">heart</governor>
          <dependent id="8">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">heart</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">issuing</governor>
          <dependent id="10">heart</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">darkness</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">heart</governor>
          <dependent id="12">darkness</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">centers</governor>
          <dependent id="13">to</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">centers</governor>
          <dependent id="14">distant</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">centers</governor>
          <dependent id="15">medical</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">issuing</governor>
          <dependent id="16">centers</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="16">centers</governor>
          <dependent id="18">compliments</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">Gajdusek</governor>
          <dependent id="19">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">Gajdusek</governor>
          <dependent id="20">Dr.</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">compliments</governor>
          <dependent id="21">Gajdusek</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Gajdusek" type="PERSON" score="0.0">
          <tokens>
            <token id="21" string="Gajdusek" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="42" has_coreference="true">
      <content>He swapped axes and salt for autopsy rights, dissecting one victim with a carving knife by lantern-light in a native hut during a howling storm, according to his letters home.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="swapped" lemma="swap" stem="swap" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="axes" lemma="axis" stem="ax" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="salt" lemma="salt" stem="salt" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="autopsy" lemma="autopsy" stem="autopsi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="rights" lemma="rights" stem="right" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="dissecting" lemma="dissect" stem="dissect" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="12" string="victim" lemma="victim" stem="victim" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="carving" lemma="carve" stem="carv" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="knife" lemma="knife" stem="knife" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="lantern-light" lemma="lantern-light" stem="lantern-light" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="native" lemma="native" stem="nativ" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="hut" lemma="hut" stem="hut" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="during" lemma="during" stem="dure" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="howling" lemma="howling" stem="howl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="storm" lemma="storm" stem="storm" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="27" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="according" lemma="accord" stem="accord" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="letters" lemma="letter" stem="letter" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="home" lemma="home" stem="home" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VBD swapped) (NP (NNS axes) (CC and) (NN salt)) (PP (IN for) (NP (NN autopsy) (NNS rights))) (, ,) (S (VP (VBG dissecting) (NP (NP (CD one) (NN victim)) (PP (IN with) (NP (DT a) (S (VP (VBG carving) (NP (NN knife)) (PP (IN by) (NP (NP (NN lantern-light)) (PP (IN in) (NP (DT a) (JJ native) (NN hut))))) (PP (IN during) (NP (DT a) (JJ howling) (NN storm))) (, ,) (PP (VBG according) (PP (TO to) (NP (PRP$ his) (NNS letters)))))) (NN home))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="his letters" type="NP">
          <tokens>
            <token id="30" string="his" />
            <token id="31" string="letters" />
          </tokens>
        </chunking>
        <chunking id="2" string="autopsy rights" type="NP">
          <tokens>
            <token id="7" string="autopsy" />
            <token id="8" string="rights" />
          </tokens>
        </chunking>
        <chunking id="3" string="carving knife by lantern-light in a native hut during a howling storm , according to his letters" type="VP">
          <tokens>
            <token id="15" string="carving" />
            <token id="16" string="knife" />
            <token id="17" string="by" />
            <token id="18" string="lantern-light" />
            <token id="19" string="in" />
            <token id="20" string="a" />
            <token id="21" string="native" />
            <token id="22" string="hut" />
            <token id="23" string="during" />
            <token id="24" string="a" />
            <token id="25" string="howling" />
            <token id="26" string="storm" />
            <token id="27" string="," />
            <token id="28" string="according" />
            <token id="29" string="to" />
            <token id="30" string="his" />
            <token id="31" string="letters" />
          </tokens>
        </chunking>
        <chunking id="4" string="a native hut" type="NP">
          <tokens>
            <token id="20" string="a" />
            <token id="21" string="native" />
            <token id="22" string="hut" />
          </tokens>
        </chunking>
        <chunking id="5" string="dissecting one victim with a carving knife by lantern-light in a native hut during a howling storm , according to his letters home" type="VP">
          <tokens>
            <token id="10" string="dissecting" />
            <token id="11" string="one" />
            <token id="12" string="victim" />
            <token id="13" string="with" />
            <token id="14" string="a" />
            <token id="15" string="carving" />
            <token id="16" string="knife" />
            <token id="17" string="by" />
            <token id="18" string="lantern-light" />
            <token id="19" string="in" />
            <token id="20" string="a" />
            <token id="21" string="native" />
            <token id="22" string="hut" />
            <token id="23" string="during" />
            <token id="24" string="a" />
            <token id="25" string="howling" />
            <token id="26" string="storm" />
            <token id="27" string="," />
            <token id="28" string="according" />
            <token id="29" string="to" />
            <token id="30" string="his" />
            <token id="31" string="letters" />
            <token id="32" string="home" />
          </tokens>
        </chunking>
        <chunking id="6" string="one victim with a carving knife by lantern-light in a native hut during a howling storm , according to his letters home" type="NP">
          <tokens>
            <token id="11" string="one" />
            <token id="12" string="victim" />
            <token id="13" string="with" />
            <token id="14" string="a" />
            <token id="15" string="carving" />
            <token id="16" string="knife" />
            <token id="17" string="by" />
            <token id="18" string="lantern-light" />
            <token id="19" string="in" />
            <token id="20" string="a" />
            <token id="21" string="native" />
            <token id="22" string="hut" />
            <token id="23" string="during" />
            <token id="24" string="a" />
            <token id="25" string="howling" />
            <token id="26" string="storm" />
            <token id="27" string="," />
            <token id="28" string="according" />
            <token id="29" string="to" />
            <token id="30" string="his" />
            <token id="31" string="letters" />
            <token id="32" string="home" />
          </tokens>
        </chunking>
        <chunking id="7" string="swapped axes and salt for autopsy rights , dissecting one victim with a carving knife by lantern-light in a native hut during a howling storm , according to his letters home" type="VP">
          <tokens>
            <token id="2" string="swapped" />
            <token id="3" string="axes" />
            <token id="4" string="and" />
            <token id="5" string="salt" />
            <token id="6" string="for" />
            <token id="7" string="autopsy" />
            <token id="8" string="rights" />
            <token id="9" string="," />
            <token id="10" string="dissecting" />
            <token id="11" string="one" />
            <token id="12" string="victim" />
            <token id="13" string="with" />
            <token id="14" string="a" />
            <token id="15" string="carving" />
            <token id="16" string="knife" />
            <token id="17" string="by" />
            <token id="18" string="lantern-light" />
            <token id="19" string="in" />
            <token id="20" string="a" />
            <token id="21" string="native" />
            <token id="22" string="hut" />
            <token id="23" string="during" />
            <token id="24" string="a" />
            <token id="25" string="howling" />
            <token id="26" string="storm" />
            <token id="27" string="," />
            <token id="28" string="according" />
            <token id="29" string="to" />
            <token id="30" string="his" />
            <token id="31" string="letters" />
            <token id="32" string="home" />
          </tokens>
        </chunking>
        <chunking id="8" string="lantern-light" type="NP">
          <tokens>
            <token id="18" string="lantern-light" />
          </tokens>
        </chunking>
        <chunking id="9" string="a howling storm" type="NP">
          <tokens>
            <token id="24" string="a" />
            <token id="25" string="howling" />
            <token id="26" string="storm" />
          </tokens>
        </chunking>
        <chunking id="10" string="one victim" type="NP">
          <tokens>
            <token id="11" string="one" />
            <token id="12" string="victim" />
          </tokens>
        </chunking>
        <chunking id="11" string="lantern-light in a native hut" type="NP">
          <tokens>
            <token id="18" string="lantern-light" />
            <token id="19" string="in" />
            <token id="20" string="a" />
            <token id="21" string="native" />
            <token id="22" string="hut" />
          </tokens>
        </chunking>
        <chunking id="12" string="knife" type="NP">
          <tokens>
            <token id="16" string="knife" />
          </tokens>
        </chunking>
        <chunking id="13" string="axes and salt" type="NP">
          <tokens>
            <token id="3" string="axes" />
            <token id="4" string="and" />
            <token id="5" string="salt" />
          </tokens>
        </chunking>
        <chunking id="14" string="a carving knife by lantern-light in a native hut during a howling storm , according to his letters home" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="carving" />
            <token id="16" string="knife" />
            <token id="17" string="by" />
            <token id="18" string="lantern-light" />
            <token id="19" string="in" />
            <token id="20" string="a" />
            <token id="21" string="native" />
            <token id="22" string="hut" />
            <token id="23" string="during" />
            <token id="24" string="a" />
            <token id="25" string="howling" />
            <token id="26" string="storm" />
            <token id="27" string="," />
            <token id="28" string="according" />
            <token id="29" string="to" />
            <token id="30" string="his" />
            <token id="31" string="letters" />
            <token id="32" string="home" />
          </tokens>
        </chunking>
        <chunking id="15" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">swapped</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">swapped</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">swapped</governor>
          <dependent id="3">axes</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">axes</governor>
          <dependent id="4">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">axes</governor>
          <dependent id="5">salt</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">rights</governor>
          <dependent id="6">for</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">rights</governor>
          <dependent id="7">autopsy</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">swapped</governor>
          <dependent id="8">rights</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="2">swapped</governor>
          <dependent id="10">dissecting</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="12">victim</governor>
          <dependent id="11">one</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">dissecting</governor>
          <dependent id="12">victim</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">home</governor>
          <dependent id="13">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="32">home</governor>
          <dependent id="14">a</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="32">home</governor>
          <dependent id="15">carving</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">carving</governor>
          <dependent id="16">knife</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">lantern-light</governor>
          <dependent id="17">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">carving</governor>
          <dependent id="18">lantern-light</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">hut</governor>
          <dependent id="19">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">hut</governor>
          <dependent id="20">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">hut</governor>
          <dependent id="21">native</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">lantern-light</governor>
          <dependent id="22">hut</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">storm</governor>
          <dependent id="23">during</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">storm</governor>
          <dependent id="24">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">storm</governor>
          <dependent id="25">howling</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">carving</governor>
          <dependent id="26">storm</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">letters</governor>
          <dependent id="28">according</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="28">according</governor>
          <dependent id="29">to</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="31">letters</governor>
          <dependent id="30">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">carving</governor>
          <dependent id="31">letters</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">victim</governor>
          <dependent id="32">home</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="storm" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="26" string="storm" />
          </tokens>
        </entity>
        <entity id="2" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="11" string="one" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="43" has_coreference="true">
      <content>He and the local doctor, Vincent Zigas, tried everything from tranquilizers to hormones on kuru patients.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="local" lemma="local" stem="local" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="doctor" lemma="doctor" stem="doctor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Vincent" lemma="Vincent" stem="vincent" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="8" string="Zigas" lemma="Zigas" stem="ziga" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="tried" lemma="try" stem="tri" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="everything" lemma="everything" stem="everyth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="tranquilizers" lemma="tranquilizer" stem="tranquil" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="hormones" lemma="hormone" stem="hormon" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="kuru" lemma="kuru" stem="kuru" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="patients" lemma="patient" stem="patient" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NP (PRP He)) (CC and) (NP (DT the) (JJ local) (NN doctor))) (, ,) (NP (NNP Vincent) (NNP Zigas)) (, ,)) (VP (VBD tried) (NP (NN everything)) (PP (IN from) (NP (NNS tranquilizers))) (PP (TO to) (NP (NP (NNS hormones)) (PP (IN on) (NP (NN kuru) (NNS patients)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="hormones on kuru patients" type="NP">
          <tokens>
            <token id="15" string="hormones" />
            <token id="16" string="on" />
            <token id="17" string="kuru" />
            <token id="18" string="patients" />
          </tokens>
        </chunking>
        <chunking id="2" string="the local doctor" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="local" />
            <token id="5" string="doctor" />
          </tokens>
        </chunking>
        <chunking id="3" string="tried everything from tranquilizers to hormones on kuru patients" type="VP">
          <tokens>
            <token id="10" string="tried" />
            <token id="11" string="everything" />
            <token id="12" string="from" />
            <token id="13" string="tranquilizers" />
            <token id="14" string="to" />
            <token id="15" string="hormones" />
            <token id="16" string="on" />
            <token id="17" string="kuru" />
            <token id="18" string="patients" />
          </tokens>
        </chunking>
        <chunking id="4" string="kuru patients" type="NP">
          <tokens>
            <token id="17" string="kuru" />
            <token id="18" string="patients" />
          </tokens>
        </chunking>
        <chunking id="5" string="hormones" type="NP">
          <tokens>
            <token id="15" string="hormones" />
          </tokens>
        </chunking>
        <chunking id="6" string="He and the local doctor , Vincent Zigas ," type="NP">
          <tokens>
            <token id="1" string="He" />
            <token id="2" string="and" />
            <token id="3" string="the" />
            <token id="4" string="local" />
            <token id="5" string="doctor" />
            <token id="6" string="," />
            <token id="7" string="Vincent" />
            <token id="8" string="Zigas" />
            <token id="9" string="," />
          </tokens>
        </chunking>
        <chunking id="7" string="He and the local doctor" type="NP">
          <tokens>
            <token id="1" string="He" />
            <token id="2" string="and" />
            <token id="3" string="the" />
            <token id="4" string="local" />
            <token id="5" string="doctor" />
          </tokens>
        </chunking>
        <chunking id="8" string="tranquilizers" type="NP">
          <tokens>
            <token id="13" string="tranquilizers" />
          </tokens>
        </chunking>
        <chunking id="9" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="10" string="Vincent Zigas" type="NP">
          <tokens>
            <token id="7" string="Vincent" />
            <token id="8" string="Zigas" />
          </tokens>
        </chunking>
        <chunking id="11" string="everything" type="NP">
          <tokens>
            <token id="11" string="everything" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="10">tried</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="1">He</governor>
          <dependent id="2">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">doctor</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">doctor</governor>
          <dependent id="4">local</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="1">He</governor>
          <dependent id="5">doctor</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">Zigas</governor>
          <dependent id="7">Vincent</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="1">He</governor>
          <dependent id="8">Zigas</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">tried</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">tried</governor>
          <dependent id="11">everything</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">tranquilizers</governor>
          <dependent id="12">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">tried</governor>
          <dependent id="13">tranquilizers</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">hormones</governor>
          <dependent id="14">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">tried</governor>
          <dependent id="15">hormones</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">patients</governor>
          <dependent id="16">on</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">patients</governor>
          <dependent id="17">kuru</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">hormones</governor>
          <dependent id="18">patients</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Vincent Zigas" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Vincent" />
            <token id="8" string="Zigas" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="44" has_coreference="false">
      <content>Nothing helped.</content>
      <tokens>
        <token id="1" string="Nothing" lemma="nothing" stem="noth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="helped" lemma="help" stem="help" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NN Nothing)) (VP (VBD helped)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="helped" type="VP">
          <tokens>
            <token id="2" string="helped" />
          </tokens>
        </chunking>
        <chunking id="2" string="Nothing" type="NP">
          <tokens>
            <token id="1" string="Nothing" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">helped</governor>
          <dependent id="1">Nothing</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">helped</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="45" has_coreference="false">
      <content>The cause remained elusive.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="cause" lemma="cause" stem="caus" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="remained" lemma="remain" stem="remain" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="elusive" lemma="elusive" stem="elus" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN cause)) (VP (VBD remained) (ADJP (JJ elusive))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="remained elusive" type="VP">
          <tokens>
            <token id="3" string="remained" />
            <token id="4" string="elusive" />
          </tokens>
        </chunking>
        <chunking id="2" string="elusive" type="ADJP">
          <tokens>
            <token id="4" string="elusive" />
          </tokens>
        </chunking>
        <chunking id="3" string="The cause" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="cause" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">cause</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">remained</governor>
          <dependent id="2">cause</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">remained</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">remained</governor>
          <dependent id="4">elusive</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="46" has_coreference="true">
      <content>Two years later, William Hadlow, a U.S. veterinarian, saw a picture of one of the kuru brains in a medical journal and was struck by its spongy appearance.</content>
      <tokens>
        <token id="1" string="Two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="2" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="3" string="later" lemma="later" stem="later" pos="RB" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="William" lemma="William" stem="william" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="6" string="Hadlow" lemma="Hadlow" stem="hadlow" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="U.S." lemma="U.S." stem="u.s." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="10" string="veterinarian" lemma="veterinarian" stem="veterinarian" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="saw" lemma="see" stem="saw" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="picture" lemma="picture" stem="pictur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="17" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="kuru" lemma="kuru" stem="kuru" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="brains" lemma="brain" stem="brain" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="medical" lemma="medical" stem="medic" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="journal" lemma="journal" stem="journal" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="struck" lemma="strike" stem="struck" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="spongy" lemma="spongy" stem="spongi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="appearance" lemma="appearance" stem="appear" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (NP (CD Two) (NNS years)) (RB later)) (, ,) (NP (NP (NNP William) (NNP Hadlow)) (, ,) (NP (DT a) (NNP U.S.) (NN veterinarian)) (, ,)) (VP (VP (VBD saw) (NP (NP (DT a) (NN picture)) (PP (IN of) (NP (CD one))) (PP (IN of) (NP (DT the) (NN kuru) (NNS brains)))) (PP (IN in) (NP (DT a) (JJ medical) (NN journal)))) (CC and) (VP (VBD was) (VP (VBN struck) (PP (IN by) (NP (PRP$ its) (JJ spongy) (NN appearance)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="struck by its spongy appearance" type="VP">
          <tokens>
            <token id="27" string="struck" />
            <token id="28" string="by" />
            <token id="29" string="its" />
            <token id="30" string="spongy" />
            <token id="31" string="appearance" />
          </tokens>
        </chunking>
        <chunking id="2" string="one" type="NP">
          <tokens>
            <token id="16" string="one" />
          </tokens>
        </chunking>
        <chunking id="3" string="a U.S. veterinarian" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="U.S." />
            <token id="10" string="veterinarian" />
          </tokens>
        </chunking>
        <chunking id="4" string="Two years" type="NP">
          <tokens>
            <token id="1" string="Two" />
            <token id="2" string="years" />
          </tokens>
        </chunking>
        <chunking id="5" string="William Hadlow" type="NP">
          <tokens>
            <token id="5" string="William" />
            <token id="6" string="Hadlow" />
          </tokens>
        </chunking>
        <chunking id="6" string="a picture of one of the kuru brains" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="picture" />
            <token id="15" string="of" />
            <token id="16" string="one" />
            <token id="17" string="of" />
            <token id="18" string="the" />
            <token id="19" string="kuru" />
            <token id="20" string="brains" />
          </tokens>
        </chunking>
        <chunking id="7" string="William Hadlow , a U.S. veterinarian ," type="NP">
          <tokens>
            <token id="5" string="William" />
            <token id="6" string="Hadlow" />
            <token id="7" string="," />
            <token id="8" string="a" />
            <token id="9" string="U.S." />
            <token id="10" string="veterinarian" />
            <token id="11" string="," />
          </tokens>
        </chunking>
        <chunking id="8" string="the kuru brains" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="kuru" />
            <token id="20" string="brains" />
          </tokens>
        </chunking>
        <chunking id="9" string="saw a picture of one of the kuru brains in a medical journal" type="VP">
          <tokens>
            <token id="12" string="saw" />
            <token id="13" string="a" />
            <token id="14" string="picture" />
            <token id="15" string="of" />
            <token id="16" string="one" />
            <token id="17" string="of" />
            <token id="18" string="the" />
            <token id="19" string="kuru" />
            <token id="20" string="brains" />
            <token id="21" string="in" />
            <token id="22" string="a" />
            <token id="23" string="medical" />
            <token id="24" string="journal" />
          </tokens>
        </chunking>
        <chunking id="10" string="a medical journal" type="NP">
          <tokens>
            <token id="22" string="a" />
            <token id="23" string="medical" />
            <token id="24" string="journal" />
          </tokens>
        </chunking>
        <chunking id="11" string="was struck by its spongy appearance" type="VP">
          <tokens>
            <token id="26" string="was" />
            <token id="27" string="struck" />
            <token id="28" string="by" />
            <token id="29" string="its" />
            <token id="30" string="spongy" />
            <token id="31" string="appearance" />
          </tokens>
        </chunking>
        <chunking id="12" string="its spongy appearance" type="NP">
          <tokens>
            <token id="29" string="its" />
            <token id="30" string="spongy" />
            <token id="31" string="appearance" />
          </tokens>
        </chunking>
        <chunking id="13" string="a picture" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="picture" />
          </tokens>
        </chunking>
        <chunking id="14" string="saw a picture of one of the kuru brains in a medical journal and was struck by its spongy appearance" type="VP">
          <tokens>
            <token id="12" string="saw" />
            <token id="13" string="a" />
            <token id="14" string="picture" />
            <token id="15" string="of" />
            <token id="16" string="one" />
            <token id="17" string="of" />
            <token id="18" string="the" />
            <token id="19" string="kuru" />
            <token id="20" string="brains" />
            <token id="21" string="in" />
            <token id="22" string="a" />
            <token id="23" string="medical" />
            <token id="24" string="journal" />
            <token id="25" string="and" />
            <token id="26" string="was" />
            <token id="27" string="struck" />
            <token id="28" string="by" />
            <token id="29" string="its" />
            <token id="30" string="spongy" />
            <token id="31" string="appearance" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nummod">
          <governor id="2">years</governor>
          <dependent id="1">Two</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="3">later</governor>
          <dependent id="2">years</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">saw</governor>
          <dependent id="3">later</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Hadlow</governor>
          <dependent id="5">William</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">saw</governor>
          <dependent id="6">Hadlow</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">veterinarian</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">veterinarian</governor>
          <dependent id="9">U.S.</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="6">Hadlow</governor>
          <dependent id="10">veterinarian</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">saw</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">picture</governor>
          <dependent id="13">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">saw</governor>
          <dependent id="14">picture</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">one</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">picture</governor>
          <dependent id="16">one</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">brains</governor>
          <dependent id="17">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">brains</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">brains</governor>
          <dependent id="19">kuru</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">picture</governor>
          <dependent id="20">brains</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">journal</governor>
          <dependent id="21">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">journal</governor>
          <dependent id="22">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">journal</governor>
          <dependent id="23">medical</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">saw</governor>
          <dependent id="24">journal</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="12">saw</governor>
          <dependent id="25">and</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="27">struck</governor>
          <dependent id="26">was</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">saw</governor>
          <dependent id="27">struck</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">appearance</governor>
          <dependent id="28">by</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="31">appearance</governor>
          <dependent id="29">its</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="31">appearance</governor>
          <dependent id="30">spongy</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">struck</governor>
          <dependent id="31">appearance</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Two years later" type="DATE" score="0.0">
          <tokens>
            <token id="1" string="Two" />
            <token id="2" string="years" />
            <token id="3" string="later" />
          </tokens>
        </entity>
        <entity id="2" string="U.S." type="LOCATION" score="0.0">
          <tokens>
            <token id="9" string="U.S." />
          </tokens>
        </entity>
        <entity id="3" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="16" string="one" />
          </tokens>
        </entity>
        <entity id="4" string="William Hadlow" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="William" />
            <token id="6" string="Hadlow" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="47" has_coreference="true">
      <content>He had seen that look before in scrapie, the sheep disease, and put in a call to the NIH.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="seen" lemma="see" stem="seen" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="look" lemma="look" stem="look" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="before" lemma="before" stem="befor" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="scrapie" lemma="scrapie" stem="scrapi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="sheep" lemma="sheep" stem="sheep" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="disease" lemma="disease" stem="diseas" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="true" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="put" lemma="put" stem="put" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="call" lemma="call" stem="call" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="NIH" lemma="NIH" stem="nih" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VBD had) (VP (VP (VBN seen) (SBAR (IN that) (S (NP (NN look)) (PP (IN before) (PP (IN in) (NP (NP (NN scrapie)) (, ,) (NP (DT the) (NN sheep) (NN disease)) (, ,))))))) (CC and) (VP (VB put) (PP (IN in) (NP (DT a) (NN call))) (PP (TO to) (NP (DT the) (NNP NIH)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="had seen that look before in scrapie , the sheep disease , and put in a call to the NIH" type="VP">
          <tokens>
            <token id="2" string="had" />
            <token id="3" string="seen" />
            <token id="4" string="that" />
            <token id="5" string="look" />
            <token id="6" string="before" />
            <token id="7" string="in" />
            <token id="8" string="scrapie" />
            <token id="9" string="," />
            <token id="10" string="the" />
            <token id="11" string="sheep" />
            <token id="12" string="disease" />
            <token id="13" string="," />
            <token id="14" string="and" />
            <token id="15" string="put" />
            <token id="16" string="in" />
            <token id="17" string="a" />
            <token id="18" string="call" />
            <token id="19" string="to" />
            <token id="20" string="the" />
            <token id="21" string="NIH" />
          </tokens>
        </chunking>
        <chunking id="2" string="the sheep disease" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="sheep" />
            <token id="12" string="disease" />
          </tokens>
        </chunking>
        <chunking id="3" string="scrapie , the sheep disease ," type="NP">
          <tokens>
            <token id="8" string="scrapie" />
            <token id="9" string="," />
            <token id="10" string="the" />
            <token id="11" string="sheep" />
            <token id="12" string="disease" />
            <token id="13" string="," />
          </tokens>
        </chunking>
        <chunking id="4" string="put in a call to the NIH" type="VP">
          <tokens>
            <token id="15" string="put" />
            <token id="16" string="in" />
            <token id="17" string="a" />
            <token id="18" string="call" />
            <token id="19" string="to" />
            <token id="20" string="the" />
            <token id="21" string="NIH" />
          </tokens>
        </chunking>
        <chunking id="5" string="that look before in scrapie , the sheep disease ," type="SBAR">
          <tokens>
            <token id="4" string="that" />
            <token id="5" string="look" />
            <token id="6" string="before" />
            <token id="7" string="in" />
            <token id="8" string="scrapie" />
            <token id="9" string="," />
            <token id="10" string="the" />
            <token id="11" string="sheep" />
            <token id="12" string="disease" />
            <token id="13" string="," />
          </tokens>
        </chunking>
        <chunking id="6" string="the NIH" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="NIH" />
          </tokens>
        </chunking>
        <chunking id="7" string="seen that look before in scrapie , the sheep disease ," type="VP">
          <tokens>
            <token id="3" string="seen" />
            <token id="4" string="that" />
            <token id="5" string="look" />
            <token id="6" string="before" />
            <token id="7" string="in" />
            <token id="8" string="scrapie" />
            <token id="9" string="," />
            <token id="10" string="the" />
            <token id="11" string="sheep" />
            <token id="12" string="disease" />
            <token id="13" string="," />
          </tokens>
        </chunking>
        <chunking id="8" string="seen that look before in scrapie , the sheep disease , and put in a call to the NIH" type="VP">
          <tokens>
            <token id="3" string="seen" />
            <token id="4" string="that" />
            <token id="5" string="look" />
            <token id="6" string="before" />
            <token id="7" string="in" />
            <token id="8" string="scrapie" />
            <token id="9" string="," />
            <token id="10" string="the" />
            <token id="11" string="sheep" />
            <token id="12" string="disease" />
            <token id="13" string="," />
            <token id="14" string="and" />
            <token id="15" string="put" />
            <token id="16" string="in" />
            <token id="17" string="a" />
            <token id="18" string="call" />
            <token id="19" string="to" />
            <token id="20" string="the" />
            <token id="21" string="NIH" />
          </tokens>
        </chunking>
        <chunking id="9" string="a call" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="call" />
          </tokens>
        </chunking>
        <chunking id="10" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="11" string="look" type="NP">
          <tokens>
            <token id="5" string="look" />
          </tokens>
        </chunking>
        <chunking id="12" string="scrapie" type="NP">
          <tokens>
            <token id="8" string="scrapie" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">seen</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="3">seen</governor>
          <dependent id="2">had</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">seen</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">look</governor>
          <dependent id="4">that</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="3">seen</governor>
          <dependent id="5">look</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">scrapie</governor>
          <dependent id="6">before</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">scrapie</governor>
          <dependent id="7">in</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="5">look</governor>
          <dependent id="8">scrapie</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">disease</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">disease</governor>
          <dependent id="11">sheep</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="8">scrapie</governor>
          <dependent id="12">disease</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">seen</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">seen</governor>
          <dependent id="15">put</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">call</governor>
          <dependent id="16">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">call</governor>
          <dependent id="17">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">put</governor>
          <dependent id="18">call</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">NIH</governor>
          <dependent id="19">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">NIH</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">put</governor>
          <dependent id="21">NIH</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="disease" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="12" string="disease" />
          </tokens>
        </entity>
        <entity id="2" string="NIH" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="21" string="NIH" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="48" has_coreference="true">
      <content>Another link fell into place when Igor Klatzo, an NIH scientist, noticed kuru brains resembled ones from CJD victims.</content>
      <tokens>
        <token id="1" string="Another" lemma="another" stem="another" pos="DT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="link" lemma="link" stem="link" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="fell" lemma="fall" stem="fell" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="place" lemma="place" stem="place" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Igor" lemma="Igor" stem="igor" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="8" string="Klatzo" lemma="Klatzo" stem="klatzo" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="NIH" lemma="NIH" stem="nih" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="12" string="scientist" lemma="scientist" stem="scientist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="noticed" lemma="notice" stem="notic" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="kuru" lemma="kuru" stem="kuru" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="brains" lemma="brain" stem="brain" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="resembled" lemma="resemble" stem="resembl" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="ones" lemma="one" stem="on" pos="NNS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="CJD" lemma="cjd" stem="cjd" pos="NN" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="21" string="victims" lemma="victim" stem="victim" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT Another) (NN link)) (VP (VBD fell) (PP (IN into) (NP (NN place))) (SBAR (WHADVP (WRB when)) (S (NP (NP (NNP Igor) (NNP Klatzo)) (, ,) (NP (DT an) (NNP NIH) (NN scientist)) (, ,)) (VP (VBD noticed) (SBAR (S (NP (NN kuru) (NNS brains)) (VP (VBD resembled) (NP (NNS ones)) (PP (IN from) (NP (NN CJD) (NNS victims)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="fell into place when Igor Klatzo , an NIH scientist , noticed kuru brains resembled ones from CJD victims" type="VP">
          <tokens>
            <token id="3" string="fell" />
            <token id="4" string="into" />
            <token id="5" string="place" />
            <token id="6" string="when" />
            <token id="7" string="Igor" />
            <token id="8" string="Klatzo" />
            <token id="9" string="," />
            <token id="10" string="an" />
            <token id="11" string="NIH" />
            <token id="12" string="scientist" />
            <token id="13" string="," />
            <token id="14" string="noticed" />
            <token id="15" string="kuru" />
            <token id="16" string="brains" />
            <token id="17" string="resembled" />
            <token id="18" string="ones" />
            <token id="19" string="from" />
            <token id="20" string="CJD" />
            <token id="21" string="victims" />
          </tokens>
        </chunking>
        <chunking id="2" string="an NIH scientist" type="NP">
          <tokens>
            <token id="10" string="an" />
            <token id="11" string="NIH" />
            <token id="12" string="scientist" />
          </tokens>
        </chunking>
        <chunking id="3" string="noticed kuru brains resembled ones from CJD victims" type="VP">
          <tokens>
            <token id="14" string="noticed" />
            <token id="15" string="kuru" />
            <token id="16" string="brains" />
            <token id="17" string="resembled" />
            <token id="18" string="ones" />
            <token id="19" string="from" />
            <token id="20" string="CJD" />
            <token id="21" string="victims" />
          </tokens>
        </chunking>
        <chunking id="4" string="kuru brains resembled ones from CJD victims" type="SBAR">
          <tokens>
            <token id="15" string="kuru" />
            <token id="16" string="brains" />
            <token id="17" string="resembled" />
            <token id="18" string="ones" />
            <token id="19" string="from" />
            <token id="20" string="CJD" />
            <token id="21" string="victims" />
          </tokens>
        </chunking>
        <chunking id="5" string="when" type="WHADVP">
          <tokens>
            <token id="6" string="when" />
          </tokens>
        </chunking>
        <chunking id="6" string="kuru brains" type="NP">
          <tokens>
            <token id="15" string="kuru" />
            <token id="16" string="brains" />
          </tokens>
        </chunking>
        <chunking id="7" string="Igor Klatzo , an NIH scientist ," type="NP">
          <tokens>
            <token id="7" string="Igor" />
            <token id="8" string="Klatzo" />
            <token id="9" string="," />
            <token id="10" string="an" />
            <token id="11" string="NIH" />
            <token id="12" string="scientist" />
            <token id="13" string="," />
          </tokens>
        </chunking>
        <chunking id="8" string="Another link" type="NP">
          <tokens>
            <token id="1" string="Another" />
            <token id="2" string="link" />
          </tokens>
        </chunking>
        <chunking id="9" string="when Igor Klatzo , an NIH scientist , noticed kuru brains resembled ones from CJD victims" type="SBAR">
          <tokens>
            <token id="6" string="when" />
            <token id="7" string="Igor" />
            <token id="8" string="Klatzo" />
            <token id="9" string="," />
            <token id="10" string="an" />
            <token id="11" string="NIH" />
            <token id="12" string="scientist" />
            <token id="13" string="," />
            <token id="14" string="noticed" />
            <token id="15" string="kuru" />
            <token id="16" string="brains" />
            <token id="17" string="resembled" />
            <token id="18" string="ones" />
            <token id="19" string="from" />
            <token id="20" string="CJD" />
            <token id="21" string="victims" />
          </tokens>
        </chunking>
        <chunking id="10" string="resembled ones from CJD victims" type="VP">
          <tokens>
            <token id="17" string="resembled" />
            <token id="18" string="ones" />
            <token id="19" string="from" />
            <token id="20" string="CJD" />
            <token id="21" string="victims" />
          </tokens>
        </chunking>
        <chunking id="11" string="ones" type="NP">
          <tokens>
            <token id="18" string="ones" />
          </tokens>
        </chunking>
        <chunking id="12" string="CJD victims" type="NP">
          <tokens>
            <token id="20" string="CJD" />
            <token id="21" string="victims" />
          </tokens>
        </chunking>
        <chunking id="13" string="place" type="NP">
          <tokens>
            <token id="5" string="place" />
          </tokens>
        </chunking>
        <chunking id="14" string="Igor Klatzo" type="NP">
          <tokens>
            <token id="7" string="Igor" />
            <token id="8" string="Klatzo" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">link</governor>
          <dependent id="1">Another</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">fell</governor>
          <dependent id="2">link</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">fell</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">place</governor>
          <dependent id="4">into</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">fell</governor>
          <dependent id="5">place</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">noticed</governor>
          <dependent id="6">when</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">Klatzo</governor>
          <dependent id="7">Igor</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">noticed</governor>
          <dependent id="8">Klatzo</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">scientist</governor>
          <dependent id="10">an</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">scientist</governor>
          <dependent id="11">NIH</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="8">Klatzo</governor>
          <dependent id="12">scientist</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">fell</governor>
          <dependent id="14">noticed</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">brains</governor>
          <dependent id="15">kuru</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">resembled</governor>
          <dependent id="16">brains</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="14">noticed</governor>
          <dependent id="17">resembled</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="17">resembled</governor>
          <dependent id="18">ones</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">victims</governor>
          <dependent id="19">from</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">victims</governor>
          <dependent id="20">CJD</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">resembled</governor>
          <dependent id="21">victims</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="NIH" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="11" string="NIH" />
          </tokens>
        </entity>
        <entity id="2" string="CJD" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="20" string="CJD" />
          </tokens>
        </entity>
        <entity id="3" string="Igor Klatzo" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Igor" />
            <token id="8" string="Klatzo" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="49" has_coreference="true">
      <content>Based on the clues, Dr. Gajdusek, back at NIH, led studies in the 1960s showing kuru, CJD and scrapie to be essentially the same infectious disease, studies that won the 1976 Nobel Prize for medicine.</content>
      <tokens>
        <token id="1" string="Based" lemma="base" stem="base" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="clues" lemma="clue" stem="clue" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Dr." lemma="Dr." stem="dr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="Gajdusek" lemma="Gajdusek" stem="gajdusek" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="back" lemma="back" stem="back" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="NIH" lemma="NIH" stem="nih" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="led" lemma="lead" stem="led" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="studies" lemma="study" stem="studi" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="17" string="1960s" lemma="1960" stem="1960" pos="NNS" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="18" string="showing" lemma="show" stem="show" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="kuru" lemma="kuru" stem="kuru" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="CJD" lemma="cjd" stem="cjd" pos="NN" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="22" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="scrapie" lemma="scrapie" stem="scrapi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="essentially" lemma="essentially" stem="essenti" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="same" lemma="same" stem="same" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="infectious" lemma="infectious" stem="infecti" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="disease" lemma="disease" stem="diseas" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="31" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="studies" lemma="study" stem="studi" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="won" lemma="win" stem="won" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="1976" lemma="1976" stem="1976" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="37" string="Nobel" lemma="Nobel" stem="nobel" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="38" string="Prize" lemma="Prize" stem="prize" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="39" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="medicine" lemma="medicine" stem="medicin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (VBN Based) (PP (IN on) (NP (DT the) (NNS clues)))) (, ,) (NP (NP (NNP Dr.) (NNP Gajdusek)) (, ,) (ADVP (RB back) (PP (IN at) (NP (NNP NIH)))) (, ,)) (VP (VBD led) (NP (NNS studies)) (PP (IN in) (NP (NP (DT the) (NNS 1960s)) (VP (VBG showing) (NP (NN kuru) (, ,) (NN CJD) (CC and) (NN scrapie)) (S (VP (TO to) (VP (VB be) (NP (RB essentially) (NP (DT the) (JJ same) (JJ infectious) (NN disease)) (, ,) (NP (NP (NNS studies)) (SBAR (WHNP (WDT that)) (S (VP (VBD won) (NP (DT the) (CD 1976) (NNP Nobel) (NNP Prize)) (PP (IN for) (NP (NN medicine))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="kuru , CJD and scrapie" type="NP">
          <tokens>
            <token id="19" string="kuru" />
            <token id="20" string="," />
            <token id="21" string="CJD" />
            <token id="22" string="and" />
            <token id="23" string="scrapie" />
          </tokens>
        </chunking>
        <chunking id="2" string="Dr. Gajdusek" type="NP">
          <tokens>
            <token id="6" string="Dr." />
            <token id="7" string="Gajdusek" />
          </tokens>
        </chunking>
        <chunking id="3" string="studies that won the 1976 Nobel Prize for medicine" type="NP">
          <tokens>
            <token id="32" string="studies" />
            <token id="33" string="that" />
            <token id="34" string="won" />
            <token id="35" string="the" />
            <token id="36" string="1976" />
            <token id="37" string="Nobel" />
            <token id="38" string="Prize" />
            <token id="39" string="for" />
            <token id="40" string="medicine" />
          </tokens>
        </chunking>
        <chunking id="4" string="be essentially the same infectious disease , studies that won the 1976 Nobel Prize for medicine" type="VP">
          <tokens>
            <token id="25" string="be" />
            <token id="26" string="essentially" />
            <token id="27" string="the" />
            <token id="28" string="same" />
            <token id="29" string="infectious" />
            <token id="30" string="disease" />
            <token id="31" string="," />
            <token id="32" string="studies" />
            <token id="33" string="that" />
            <token id="34" string="won" />
            <token id="35" string="the" />
            <token id="36" string="1976" />
            <token id="37" string="Nobel" />
            <token id="38" string="Prize" />
            <token id="39" string="for" />
            <token id="40" string="medicine" />
          </tokens>
        </chunking>
        <chunking id="5" string="medicine" type="NP">
          <tokens>
            <token id="40" string="medicine" />
          </tokens>
        </chunking>
        <chunking id="6" string="that won the 1976 Nobel Prize for medicine" type="SBAR">
          <tokens>
            <token id="33" string="that" />
            <token id="34" string="won" />
            <token id="35" string="the" />
            <token id="36" string="1976" />
            <token id="37" string="Nobel" />
            <token id="38" string="Prize" />
            <token id="39" string="for" />
            <token id="40" string="medicine" />
          </tokens>
        </chunking>
        <chunking id="7" string="the 1960s showing kuru , CJD and scrapie to be essentially the same infectious disease , studies that won the 1976 Nobel Prize for medicine" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="1960s" />
            <token id="18" string="showing" />
            <token id="19" string="kuru" />
            <token id="20" string="," />
            <token id="21" string="CJD" />
            <token id="22" string="and" />
            <token id="23" string="scrapie" />
            <token id="24" string="to" />
            <token id="25" string="be" />
            <token id="26" string="essentially" />
            <token id="27" string="the" />
            <token id="28" string="same" />
            <token id="29" string="infectious" />
            <token id="30" string="disease" />
            <token id="31" string="," />
            <token id="32" string="studies" />
            <token id="33" string="that" />
            <token id="34" string="won" />
            <token id="35" string="the" />
            <token id="36" string="1976" />
            <token id="37" string="Nobel" />
            <token id="38" string="Prize" />
            <token id="39" string="for" />
            <token id="40" string="medicine" />
          </tokens>
        </chunking>
        <chunking id="8" string="the 1976 Nobel Prize" type="NP">
          <tokens>
            <token id="35" string="the" />
            <token id="36" string="1976" />
            <token id="37" string="Nobel" />
            <token id="38" string="Prize" />
          </tokens>
        </chunking>
        <chunking id="9" string="NIH" type="NP">
          <tokens>
            <token id="11" string="NIH" />
          </tokens>
        </chunking>
        <chunking id="10" string="essentially the same infectious disease , studies that won the 1976 Nobel Prize for medicine" type="NP">
          <tokens>
            <token id="26" string="essentially" />
            <token id="27" string="the" />
            <token id="28" string="same" />
            <token id="29" string="infectious" />
            <token id="30" string="disease" />
            <token id="31" string="," />
            <token id="32" string="studies" />
            <token id="33" string="that" />
            <token id="34" string="won" />
            <token id="35" string="the" />
            <token id="36" string="1976" />
            <token id="37" string="Nobel" />
            <token id="38" string="Prize" />
            <token id="39" string="for" />
            <token id="40" string="medicine" />
          </tokens>
        </chunking>
        <chunking id="11" string="showing kuru , CJD and scrapie to be essentially the same infectious disease , studies that won the 1976 Nobel Prize for medicine" type="VP">
          <tokens>
            <token id="18" string="showing" />
            <token id="19" string="kuru" />
            <token id="20" string="," />
            <token id="21" string="CJD" />
            <token id="22" string="and" />
            <token id="23" string="scrapie" />
            <token id="24" string="to" />
            <token id="25" string="be" />
            <token id="26" string="essentially" />
            <token id="27" string="the" />
            <token id="28" string="same" />
            <token id="29" string="infectious" />
            <token id="30" string="disease" />
            <token id="31" string="," />
            <token id="32" string="studies" />
            <token id="33" string="that" />
            <token id="34" string="won" />
            <token id="35" string="the" />
            <token id="36" string="1976" />
            <token id="37" string="Nobel" />
            <token id="38" string="Prize" />
            <token id="39" string="for" />
            <token id="40" string="medicine" />
          </tokens>
        </chunking>
        <chunking id="12" string="Dr. Gajdusek , back at NIH ," type="NP">
          <tokens>
            <token id="6" string="Dr." />
            <token id="7" string="Gajdusek" />
            <token id="8" string="," />
            <token id="9" string="back" />
            <token id="10" string="at" />
            <token id="11" string="NIH" />
            <token id="12" string="," />
          </tokens>
        </chunking>
        <chunking id="13" string="the clues" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="clues" />
          </tokens>
        </chunking>
        <chunking id="14" string="studies" type="NP">
          <tokens>
            <token id="14" string="studies" />
          </tokens>
        </chunking>
        <chunking id="15" string="the 1960s" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="1960s" />
          </tokens>
        </chunking>
        <chunking id="16" string="won the 1976 Nobel Prize for medicine" type="VP">
          <tokens>
            <token id="34" string="won" />
            <token id="35" string="the" />
            <token id="36" string="1976" />
            <token id="37" string="Nobel" />
            <token id="38" string="Prize" />
            <token id="39" string="for" />
            <token id="40" string="medicine" />
          </tokens>
        </chunking>
        <chunking id="17" string="led studies in the 1960s showing kuru , CJD and scrapie to be essentially the same infectious disease , studies that won the 1976 Nobel Prize for medicine" type="VP">
          <tokens>
            <token id="13" string="led" />
            <token id="14" string="studies" />
            <token id="15" string="in" />
            <token id="16" string="the" />
            <token id="17" string="1960s" />
            <token id="18" string="showing" />
            <token id="19" string="kuru" />
            <token id="20" string="," />
            <token id="21" string="CJD" />
            <token id="22" string="and" />
            <token id="23" string="scrapie" />
            <token id="24" string="to" />
            <token id="25" string="be" />
            <token id="26" string="essentially" />
            <token id="27" string="the" />
            <token id="28" string="same" />
            <token id="29" string="infectious" />
            <token id="30" string="disease" />
            <token id="31" string="," />
            <token id="32" string="studies" />
            <token id="33" string="that" />
            <token id="34" string="won" />
            <token id="35" string="the" />
            <token id="36" string="1976" />
            <token id="37" string="Nobel" />
            <token id="38" string="Prize" />
            <token id="39" string="for" />
            <token id="40" string="medicine" />
          </tokens>
        </chunking>
        <chunking id="18" string="to be essentially the same infectious disease , studies that won the 1976 Nobel Prize for medicine" type="VP">
          <tokens>
            <token id="24" string="to" />
            <token id="25" string="be" />
            <token id="26" string="essentially" />
            <token id="27" string="the" />
            <token id="28" string="same" />
            <token id="29" string="infectious" />
            <token id="30" string="disease" />
            <token id="31" string="," />
            <token id="32" string="studies" />
            <token id="33" string="that" />
            <token id="34" string="won" />
            <token id="35" string="the" />
            <token id="36" string="1976" />
            <token id="37" string="Nobel" />
            <token id="38" string="Prize" />
            <token id="39" string="for" />
            <token id="40" string="medicine" />
          </tokens>
        </chunking>
        <chunking id="19" string="the same infectious disease" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="same" />
            <token id="29" string="infectious" />
            <token id="30" string="disease" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">clues</governor>
          <dependent id="1">Based</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="1">Based</governor>
          <dependent id="2">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">clues</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="13">led</governor>
          <dependent id="4">clues</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Gajdusek</governor>
          <dependent id="6">Dr.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">led</governor>
          <dependent id="7">Gajdusek</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">Gajdusek</governor>
          <dependent id="9">back</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">NIH</governor>
          <dependent id="10">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">back</governor>
          <dependent id="11">NIH</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">led</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">led</governor>
          <dependent id="14">studies</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">1960s</governor>
          <dependent id="15">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">1960s</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">led</governor>
          <dependent id="17">1960s</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="17">1960s</governor>
          <dependent id="18">showing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">showing</governor>
          <dependent id="19">kuru</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="19">kuru</governor>
          <dependent id="21">CJD</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="19">kuru</governor>
          <dependent id="22">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="19">kuru</governor>
          <dependent id="23">scrapie</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="30">disease</governor>
          <dependent id="24">to</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="30">disease</governor>
          <dependent id="25">be</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="30">disease</governor>
          <dependent id="26">essentially</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">disease</governor>
          <dependent id="27">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="30">disease</governor>
          <dependent id="28">same</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="30">disease</governor>
          <dependent id="29">infectious</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="18">showing</governor>
          <dependent id="30">disease</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="30">disease</governor>
          <dependent id="32">studies</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="34">won</governor>
          <dependent id="33">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="32">studies</governor>
          <dependent id="34">won</dependent>
        </dependency>
        <dependency type="det">
          <governor id="38">Prize</governor>
          <dependent id="35">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="38">Prize</governor>
          <dependent id="36">1976</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="38">Prize</governor>
          <dependent id="37">Nobel</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="34">won</governor>
          <dependent id="38">Prize</dependent>
        </dependency>
        <dependency type="case">
          <governor id="40">medicine</governor>
          <dependent id="39">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="34">won</governor>
          <dependent id="40">medicine</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1976" type="DATE" score="0.0">
          <tokens>
            <token id="36" string="1976" />
          </tokens>
        </entity>
        <entity id="2" string="Nobel Prize" type="MISC" score="0.0">
          <tokens>
            <token id="37" string="Nobel" />
            <token id="38" string="Prize" />
          </tokens>
        </entity>
        <entity id="3" string="disease" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="30" string="disease" />
          </tokens>
        </entity>
        <entity id="4" string="the 1960s" type="DATE" score="0.0">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="1960s" />
          </tokens>
        </entity>
        <entity id="5" string="NIH" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="11" string="NIH" />
          </tokens>
        </entity>
        <entity id="6" string="CJD" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="21" string="CJD" />
          </tokens>
        </entity>
        <entity id="7" string="Gajdusek" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Gajdusek" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="50" has_coreference="true">
      <content>The discoveries confirmed a long-suspected connection: The kuru outbreak sprang from a Fore mourning ritual, in which relatives ate their deceased kin&amp;apost;s lightly cooked, and often kuru-infected, brains.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="discoveries" lemma="discovery" stem="discoveri" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="confirmed" lemma="confirm" stem="confirm" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="long-suspected" lemma="long-suspected" stem="long-suspect" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="connection" lemma="connection" stem="connect" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="kuru" lemma="kuru" stem="kuru" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="outbreak" lemma="outbreak" stem="outbreak" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="sprang" lemma="spring" stem="sprang" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Fore" lemma="fore" stem="fore" pos="NN" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="15" string="mourning" lemma="mourning" stem="mourn" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="ritual" lemma="ritual" stem="ritual" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="relatives" lemma="relative" stem="rel" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="ate" lemma="eat" stem="at" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="deceased" lemma="deceased" stem="deceas" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="kin" lemma="kin" stem="kin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="lightly" lemma="lightly" stem="lightli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="cooked" lemma="cook" stem="cook" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="often" lemma="often" stem="often" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="kuru-infected" lemma="kuru-infected" stem="kuru-infect" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="brains" lemma="brain" stem="brain" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="34" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (DT The) (NNS discoveries)) (VP (VBD confirmed) (NP (DT a) (JJ long-suspected) (NN connection)))) (: :) (S (NP (DT The) (NN kuru) (NN outbreak)) (VP (VBD sprang) (PP (IN from) (NP (NP (NP (DT a) (NN Fore)) (PP (NN mourning) (NP (NN ritual))) (, ,) (SBAR (WHPP (IN in) (WHNP (WDT which))) (S (NP (NNS relatives)) (VP (VBD ate) (SBAR (S (NP (NP (PRP$ their) (JJ deceased) (NN kin)) (POS 's)) (VP (ADVP (RB lightly)) (VBN cooked)))))))) (, ,) (CC and) (NP (NP (RB often) (JJ kuru-infected)) (, ,) (NP (NNS brains))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="confirmed a long-suspected connection" type="VP">
          <tokens>
            <token id="3" string="confirmed" />
            <token id="4" string="a" />
            <token id="5" string="long-suspected" />
            <token id="6" string="connection" />
          </tokens>
        </chunking>
        <chunking id="2" string="a Fore mourning ritual , in which relatives ate their deceased kin 's lightly cooked" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="Fore" />
            <token id="15" string="mourning" />
            <token id="16" string="ritual" />
            <token id="17" string="," />
            <token id="18" string="in" />
            <token id="19" string="which" />
            <token id="20" string="relatives" />
            <token id="21" string="ate" />
            <token id="22" string="their" />
            <token id="23" string="deceased" />
            <token id="24" string="kin" />
            <token id="25" string="'s" />
            <token id="26" string="lightly" />
            <token id="27" string="cooked" />
          </tokens>
        </chunking>
        <chunking id="3" string="The discoveries" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="discoveries" />
          </tokens>
        </chunking>
        <chunking id="4" string="ritual" type="NP">
          <tokens>
            <token id="16" string="ritual" />
          </tokens>
        </chunking>
        <chunking id="5" string="often kuru-infected" type="NP">
          <tokens>
            <token id="30" string="often" />
            <token id="31" string="kuru-infected" />
          </tokens>
        </chunking>
        <chunking id="6" string="in which relatives ate their deceased kin 's lightly cooked" type="SBAR">
          <tokens>
            <token id="18" string="in" />
            <token id="19" string="which" />
            <token id="20" string="relatives" />
            <token id="21" string="ate" />
            <token id="22" string="their" />
            <token id="23" string="deceased" />
            <token id="24" string="kin" />
            <token id="25" string="'s" />
            <token id="26" string="lightly" />
            <token id="27" string="cooked" />
          </tokens>
        </chunking>
        <chunking id="7" string="their deceased kin 's" type="NP">
          <tokens>
            <token id="22" string="their" />
            <token id="23" string="deceased" />
            <token id="24" string="kin" />
            <token id="25" string="'s" />
          </tokens>
        </chunking>
        <chunking id="8" string="a long-suspected connection" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="long-suspected" />
            <token id="6" string="connection" />
          </tokens>
        </chunking>
        <chunking id="9" string="sprang from a Fore mourning ritual , in which relatives ate their deceased kin 's lightly cooked , and often kuru-infected , brains" type="VP">
          <tokens>
            <token id="11" string="sprang" />
            <token id="12" string="from" />
            <token id="13" string="a" />
            <token id="14" string="Fore" />
            <token id="15" string="mourning" />
            <token id="16" string="ritual" />
            <token id="17" string="," />
            <token id="18" string="in" />
            <token id="19" string="which" />
            <token id="20" string="relatives" />
            <token id="21" string="ate" />
            <token id="22" string="their" />
            <token id="23" string="deceased" />
            <token id="24" string="kin" />
            <token id="25" string="'s" />
            <token id="26" string="lightly" />
            <token id="27" string="cooked" />
            <token id="28" string="," />
            <token id="29" string="and" />
            <token id="30" string="often" />
            <token id="31" string="kuru-infected" />
            <token id="32" string="," />
            <token id="33" string="brains" />
          </tokens>
        </chunking>
        <chunking id="10" string="relatives" type="NP">
          <tokens>
            <token id="20" string="relatives" />
          </tokens>
        </chunking>
        <chunking id="11" string="The kuru outbreak" type="NP">
          <tokens>
            <token id="8" string="The" />
            <token id="9" string="kuru" />
            <token id="10" string="outbreak" />
          </tokens>
        </chunking>
        <chunking id="12" string="lightly cooked" type="VP">
          <tokens>
            <token id="26" string="lightly" />
            <token id="27" string="cooked" />
          </tokens>
        </chunking>
        <chunking id="13" string="a Fore mourning ritual , in which relatives ate their deceased kin 's lightly cooked , and often kuru-infected , brains" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="Fore" />
            <token id="15" string="mourning" />
            <token id="16" string="ritual" />
            <token id="17" string="," />
            <token id="18" string="in" />
            <token id="19" string="which" />
            <token id="20" string="relatives" />
            <token id="21" string="ate" />
            <token id="22" string="their" />
            <token id="23" string="deceased" />
            <token id="24" string="kin" />
            <token id="25" string="'s" />
            <token id="26" string="lightly" />
            <token id="27" string="cooked" />
            <token id="28" string="," />
            <token id="29" string="and" />
            <token id="30" string="often" />
            <token id="31" string="kuru-infected" />
            <token id="32" string="," />
            <token id="33" string="brains" />
          </tokens>
        </chunking>
        <chunking id="14" string="a Fore" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="Fore" />
          </tokens>
        </chunking>
        <chunking id="15" string="their deceased kin" type="NP">
          <tokens>
            <token id="22" string="their" />
            <token id="23" string="deceased" />
            <token id="24" string="kin" />
          </tokens>
        </chunking>
        <chunking id="16" string="brains" type="NP">
          <tokens>
            <token id="33" string="brains" />
          </tokens>
        </chunking>
        <chunking id="17" string="their deceased kin 's lightly cooked" type="SBAR">
          <tokens>
            <token id="22" string="their" />
            <token id="23" string="deceased" />
            <token id="24" string="kin" />
            <token id="25" string="'s" />
            <token id="26" string="lightly" />
            <token id="27" string="cooked" />
          </tokens>
        </chunking>
        <chunking id="18" string="ate their deceased kin 's lightly cooked" type="VP">
          <tokens>
            <token id="21" string="ate" />
            <token id="22" string="their" />
            <token id="23" string="deceased" />
            <token id="24" string="kin" />
            <token id="25" string="'s" />
            <token id="26" string="lightly" />
            <token id="27" string="cooked" />
          </tokens>
        </chunking>
        <chunking id="19" string="often kuru-infected , brains" type="NP">
          <tokens>
            <token id="30" string="often" />
            <token id="31" string="kuru-infected" />
            <token id="32" string="," />
            <token id="33" string="brains" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">discoveries</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">confirmed</governor>
          <dependent id="2">discoveries</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">confirmed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">connection</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">connection</governor>
          <dependent id="5">long-suspected</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">confirmed</governor>
          <dependent id="6">connection</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">outbreak</governor>
          <dependent id="8">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">outbreak</governor>
          <dependent id="9">kuru</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">sprang</governor>
          <dependent id="10">outbreak</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="3">confirmed</governor>
          <dependent id="11">sprang</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">Fore</governor>
          <dependent id="12">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">Fore</governor>
          <dependent id="13">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">sprang</governor>
          <dependent id="14">Fore</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="16">ritual</governor>
          <dependent id="15">mourning</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">Fore</governor>
          <dependent id="16">ritual</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">which</governor>
          <dependent id="18">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">ate</governor>
          <dependent id="19">which</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">ate</governor>
          <dependent id="20">relatives</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="14">Fore</governor>
          <dependent id="21">ate</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="24">kin</governor>
          <dependent id="22">their</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">kin</governor>
          <dependent id="23">deceased</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">cooked</governor>
          <dependent id="24">kin</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">kin</governor>
          <dependent id="25">'s</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="27">cooked</governor>
          <dependent id="26">lightly</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="21">ate</governor>
          <dependent id="27">cooked</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="14">Fore</governor>
          <dependent id="29">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="31">kuru-infected</governor>
          <dependent id="30">often</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">Fore</governor>
          <dependent id="31">kuru-infected</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="31">kuru-infected</governor>
          <dependent id="33">brains</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Fore" type="MISC" score="0.0">
          <tokens>
            <token id="14" string="Fore" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="51" has_coreference="true">
      <content>But the infectious agent continued to baffle scientists.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="infectious" lemma="infectious" stem="infecti" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="agent" lemma="agent" stem="agent" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="continued" lemma="continue" stem="continu" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="baffle" lemma="baffle" stem="baffl" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="scientists" lemma="scientist" stem="scientist" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (DT the) (JJ infectious) (NN agent)) (VP (VBD continued) (S (VP (TO to) (VP (VB baffle) (NP (NNS scientists)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="scientists" type="NP">
          <tokens>
            <token id="8" string="scientists" />
          </tokens>
        </chunking>
        <chunking id="2" string="the infectious agent" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="infectious" />
            <token id="4" string="agent" />
          </tokens>
        </chunking>
        <chunking id="3" string="to baffle scientists" type="VP">
          <tokens>
            <token id="6" string="to" />
            <token id="7" string="baffle" />
            <token id="8" string="scientists" />
          </tokens>
        </chunking>
        <chunking id="4" string="continued to baffle scientists" type="VP">
          <tokens>
            <token id="5" string="continued" />
            <token id="6" string="to" />
            <token id="7" string="baffle" />
            <token id="8" string="scientists" />
          </tokens>
        </chunking>
        <chunking id="5" string="baffle scientists" type="VP">
          <tokens>
            <token id="7" string="baffle" />
            <token id="8" string="scientists" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="5">continued</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">agent</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">agent</governor>
          <dependent id="3">infectious</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">continued</governor>
          <dependent id="4">agent</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">continued</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">baffle</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">continued</governor>
          <dependent id="7">baffle</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">baffle</governor>
          <dependent id="8">scientists</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="52" has_coreference="true">
      <content>It somehow could hide in the brain for decades without causing the usual signs of infection, such as fever.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="somehow" lemma="somehow" stem="somehow" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="hide" lemma="hide" stem="hide" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="brain" lemma="brain" stem="brain" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="decades" lemma="decade" stem="decad" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="true" />
        <token id="10" string="without" lemma="without" stem="without" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="causing" lemma="cause" stem="caus" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="usual" lemma="usual" stem="usual" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="signs" lemma="sign" stem="sign" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="infection" lemma="infection" stem="infect" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="such" lemma="such" stem="such" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="fever" lemma="fever" stem="fever" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP It)) (ADVP (RB somehow)) (VP (MD could) (VP (VB hide) (PP (IN in) (NP (NP (DT the) (NN brain)) (PP (IN for) (NP (NNS decades))))) (PP (IN without) (S (VP (VBG causing) (NP (NP (DT the) (JJ usual) (NNS signs)) (PP (IN of) (NP (NN infection))) (, ,) (PP (JJ such) (IN as) (NP (NN fever))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the usual signs of infection , such as fever" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="usual" />
            <token id="14" string="signs" />
            <token id="15" string="of" />
            <token id="16" string="infection" />
            <token id="17" string="," />
            <token id="18" string="such" />
            <token id="19" string="as" />
            <token id="20" string="fever" />
          </tokens>
        </chunking>
        <chunking id="2" string="could hide in the brain for decades without causing the usual signs of infection , such as fever" type="VP">
          <tokens>
            <token id="3" string="could" />
            <token id="4" string="hide" />
            <token id="5" string="in" />
            <token id="6" string="the" />
            <token id="7" string="brain" />
            <token id="8" string="for" />
            <token id="9" string="decades" />
            <token id="10" string="without" />
            <token id="11" string="causing" />
            <token id="12" string="the" />
            <token id="13" string="usual" />
            <token id="14" string="signs" />
            <token id="15" string="of" />
            <token id="16" string="infection" />
            <token id="17" string="," />
            <token id="18" string="such" />
            <token id="19" string="as" />
            <token id="20" string="fever" />
          </tokens>
        </chunking>
        <chunking id="3" string="the brain" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="brain" />
          </tokens>
        </chunking>
        <chunking id="4" string="the usual signs" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="usual" />
            <token id="14" string="signs" />
          </tokens>
        </chunking>
        <chunking id="5" string="infection" type="NP">
          <tokens>
            <token id="16" string="infection" />
          </tokens>
        </chunking>
        <chunking id="6" string="the brain for decades" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="brain" />
            <token id="8" string="for" />
            <token id="9" string="decades" />
          </tokens>
        </chunking>
        <chunking id="7" string="hide in the brain for decades without causing the usual signs of infection , such as fever" type="VP">
          <tokens>
            <token id="4" string="hide" />
            <token id="5" string="in" />
            <token id="6" string="the" />
            <token id="7" string="brain" />
            <token id="8" string="for" />
            <token id="9" string="decades" />
            <token id="10" string="without" />
            <token id="11" string="causing" />
            <token id="12" string="the" />
            <token id="13" string="usual" />
            <token id="14" string="signs" />
            <token id="15" string="of" />
            <token id="16" string="infection" />
            <token id="17" string="," />
            <token id="18" string="such" />
            <token id="19" string="as" />
            <token id="20" string="fever" />
          </tokens>
        </chunking>
        <chunking id="8" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="9" string="decades" type="NP">
          <tokens>
            <token id="9" string="decades" />
          </tokens>
        </chunking>
        <chunking id="10" string="causing the usual signs of infection , such as fever" type="VP">
          <tokens>
            <token id="11" string="causing" />
            <token id="12" string="the" />
            <token id="13" string="usual" />
            <token id="14" string="signs" />
            <token id="15" string="of" />
            <token id="16" string="infection" />
            <token id="17" string="," />
            <token id="18" string="such" />
            <token id="19" string="as" />
            <token id="20" string="fever" />
          </tokens>
        </chunking>
        <chunking id="11" string="fever" type="NP">
          <tokens>
            <token id="20" string="fever" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">hide</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">hide</governor>
          <dependent id="2">somehow</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">hide</governor>
          <dependent id="3">could</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">hide</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">brain</governor>
          <dependent id="5">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">brain</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">hide</governor>
          <dependent id="7">brain</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">decades</governor>
          <dependent id="8">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">brain</governor>
          <dependent id="9">decades</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">causing</governor>
          <dependent id="10">without</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">hide</governor>
          <dependent id="11">causing</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">signs</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">signs</governor>
          <dependent id="13">usual</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">causing</governor>
          <dependent id="14">signs</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">infection</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">signs</governor>
          <dependent id="16">infection</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">fever</governor>
          <dependent id="18">such</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="18">such</governor>
          <dependent id="19">as</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">signs</governor>
          <dependent id="20">fever</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="infection" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="16" string="infection" />
          </tokens>
        </entity>
        <entity id="2" string="decades" type="DURATION" score="0.0">
          <tokens>
            <token id="9" string="decades" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="53" has_coreference="true">
      <content>Brain tissue of infected animals could transmit the disease when injected into different animals&amp;apost; brains, yet microscopes revealed no signs of infectious microbes.</content>
      <tokens>
        <token id="1" string="Brain" lemma="brain" stem="brain" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="tissue" lemma="tissue" stem="tissu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="infected" lemma="infected" stem="infect" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="animals" lemma="animal" stem="anim" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="transmit" lemma="transmit" stem="transmit" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="disease" lemma="disease" stem="diseas" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="10" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="injected" lemma="inject" stem="inject" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="different" lemma="different" stem="differ" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="animals" lemma="animal" stem="anim" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="brains" lemma="brain" stem="brain" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="yet" lemma="yet" stem="yet" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="microscopes" lemma="microscope" stem="microscop" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="revealed" lemma="reveal" stem="reveal" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="signs" lemma="sign" stem="sign" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="infectious" lemma="infectious" stem="infecti" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="microbes" lemma="microbe" stem="microb" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (NN Brain) (NN tissue)) (PP (IN of) (NP (JJ infected) (NNS animals)))) (VP (MD could) (VP (VB transmit) (NP (DT the) (NN disease)) (SBAR (WHADVP (WRB when)) (S (VP (VBN injected) (PP (IN into) (NP (NP (JJ different) (NNS animals) (POS ')) (NNS brains))))))))) (, ,) (RB yet) (S (NP (NNS microscopes)) (VP (VBD revealed) (NP (NP (DT no) (NNS signs)) (PP (IN of) (NP (JJ infectious) (NNS microbes)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="different animals ' brains" type="NP">
          <tokens>
            <token id="13" string="different" />
            <token id="14" string="animals" />
            <token id="15" string="'" />
            <token id="16" string="brains" />
          </tokens>
        </chunking>
        <chunking id="2" string="could transmit the disease when injected into different animals ' brains" type="VP">
          <tokens>
            <token id="6" string="could" />
            <token id="7" string="transmit" />
            <token id="8" string="the" />
            <token id="9" string="disease" />
            <token id="10" string="when" />
            <token id="11" string="injected" />
            <token id="12" string="into" />
            <token id="13" string="different" />
            <token id="14" string="animals" />
            <token id="15" string="'" />
            <token id="16" string="brains" />
          </tokens>
        </chunking>
        <chunking id="3" string="no signs" type="NP">
          <tokens>
            <token id="21" string="no" />
            <token id="22" string="signs" />
          </tokens>
        </chunking>
        <chunking id="4" string="when injected into different animals ' brains" type="SBAR">
          <tokens>
            <token id="10" string="when" />
            <token id="11" string="injected" />
            <token id="12" string="into" />
            <token id="13" string="different" />
            <token id="14" string="animals" />
            <token id="15" string="'" />
            <token id="16" string="brains" />
          </tokens>
        </chunking>
        <chunking id="5" string="revealed no signs of infectious microbes" type="VP">
          <tokens>
            <token id="20" string="revealed" />
            <token id="21" string="no" />
            <token id="22" string="signs" />
            <token id="23" string="of" />
            <token id="24" string="infectious" />
            <token id="25" string="microbes" />
          </tokens>
        </chunking>
        <chunking id="6" string="infectious microbes" type="NP">
          <tokens>
            <token id="24" string="infectious" />
            <token id="25" string="microbes" />
          </tokens>
        </chunking>
        <chunking id="7" string="no signs of infectious microbes" type="NP">
          <tokens>
            <token id="21" string="no" />
            <token id="22" string="signs" />
            <token id="23" string="of" />
            <token id="24" string="infectious" />
            <token id="25" string="microbes" />
          </tokens>
        </chunking>
        <chunking id="8" string="Brain tissue" type="NP">
          <tokens>
            <token id="1" string="Brain" />
            <token id="2" string="tissue" />
          </tokens>
        </chunking>
        <chunking id="9" string="infected animals" type="NP">
          <tokens>
            <token id="4" string="infected" />
            <token id="5" string="animals" />
          </tokens>
        </chunking>
        <chunking id="10" string="when" type="WHADVP">
          <tokens>
            <token id="10" string="when" />
          </tokens>
        </chunking>
        <chunking id="11" string="the disease" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="disease" />
          </tokens>
        </chunking>
        <chunking id="12" string="injected into different animals ' brains" type="VP">
          <tokens>
            <token id="11" string="injected" />
            <token id="12" string="into" />
            <token id="13" string="different" />
            <token id="14" string="animals" />
            <token id="15" string="'" />
            <token id="16" string="brains" />
          </tokens>
        </chunking>
        <chunking id="13" string="different animals '" type="NP">
          <tokens>
            <token id="13" string="different" />
            <token id="14" string="animals" />
            <token id="15" string="'" />
          </tokens>
        </chunking>
        <chunking id="14" string="Brain tissue of infected animals" type="NP">
          <tokens>
            <token id="1" string="Brain" />
            <token id="2" string="tissue" />
            <token id="3" string="of" />
            <token id="4" string="infected" />
            <token id="5" string="animals" />
          </tokens>
        </chunking>
        <chunking id="15" string="microscopes" type="NP">
          <tokens>
            <token id="19" string="microscopes" />
          </tokens>
        </chunking>
        <chunking id="16" string="transmit the disease when injected into different animals ' brains" type="VP">
          <tokens>
            <token id="7" string="transmit" />
            <token id="8" string="the" />
            <token id="9" string="disease" />
            <token id="10" string="when" />
            <token id="11" string="injected" />
            <token id="12" string="into" />
            <token id="13" string="different" />
            <token id="14" string="animals" />
            <token id="15" string="'" />
            <token id="16" string="brains" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">tissue</governor>
          <dependent id="1">Brain</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">transmit</governor>
          <dependent id="2">tissue</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">animals</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">animals</governor>
          <dependent id="4">infected</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">tissue</governor>
          <dependent id="5">animals</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">transmit</governor>
          <dependent id="6">could</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">transmit</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">disease</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">transmit</governor>
          <dependent id="9">disease</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">injected</governor>
          <dependent id="10">when</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="7">transmit</governor>
          <dependent id="11">injected</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">brains</governor>
          <dependent id="12">into</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">animals</governor>
          <dependent id="13">different</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="16">brains</governor>
          <dependent id="14">animals</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">animals</governor>
          <dependent id="15">'</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">injected</governor>
          <dependent id="16">brains</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">transmit</governor>
          <dependent id="18">yet</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">revealed</governor>
          <dependent id="19">microscopes</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="7">transmit</governor>
          <dependent id="20">revealed</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="22">signs</governor>
          <dependent id="21">no</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">revealed</governor>
          <dependent id="22">signs</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">microbes</governor>
          <dependent id="23">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">microbes</governor>
          <dependent id="24">infectious</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">signs</governor>
          <dependent id="25">microbes</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="disease" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="9" string="disease" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="54" has_coreference="true">
      <content>And why did the agent sporadically appear in people with no known exposure?</content>
      <tokens>
        <token id="1" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="why" lemma="why" stem="why" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="agent" lemma="agent" stem="agent" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="sporadically" lemma="sporadically" stem="sporad" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="appear" lemma="appear" stem="appear" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="known" lemma="known" stem="known" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="exposure" lemma="exposure" stem="exposur" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SBARQ (CC And) (WHADVP (WRB why)) (SQ (VBD did) (NP (DT the) (NN agent)) (VP (ADVP (RB sporadically)) (VBP appear) (PP (IN in) (NP (NP (NNS people)) (PP (IN with) (NP (DT no) (JJ known) (NN exposure))))))) (. ?)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the agent" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="agent" />
          </tokens>
        </chunking>
        <chunking id="2" string="why" type="WHADVP">
          <tokens>
            <token id="2" string="why" />
          </tokens>
        </chunking>
        <chunking id="3" string="people" type="NP">
          <tokens>
            <token id="9" string="people" />
          </tokens>
        </chunking>
        <chunking id="4" string="no known exposure" type="NP">
          <tokens>
            <token id="11" string="no" />
            <token id="12" string="known" />
            <token id="13" string="exposure" />
          </tokens>
        </chunking>
        <chunking id="5" string="sporadically appear in people with no known exposure" type="VP">
          <tokens>
            <token id="6" string="sporadically" />
            <token id="7" string="appear" />
            <token id="8" string="in" />
            <token id="9" string="people" />
            <token id="10" string="with" />
            <token id="11" string="no" />
            <token id="12" string="known" />
            <token id="13" string="exposure" />
          </tokens>
        </chunking>
        <chunking id="6" string="people with no known exposure" type="NP">
          <tokens>
            <token id="9" string="people" />
            <token id="10" string="with" />
            <token id="11" string="no" />
            <token id="12" string="known" />
            <token id="13" string="exposure" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="7">appear</governor>
          <dependent id="1">And</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">appear</governor>
          <dependent id="2">why</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">appear</governor>
          <dependent id="3">did</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">agent</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">appear</governor>
          <dependent id="5">agent</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">appear</governor>
          <dependent id="6">sporadically</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">appear</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">people</governor>
          <dependent id="8">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">appear</governor>
          <dependent id="9">people</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">exposure</governor>
          <dependent id="10">with</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="13">exposure</governor>
          <dependent id="11">no</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">exposure</governor>
          <dependent id="12">known</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">people</governor>
          <dependent id="13">exposure</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="55" has_coreference="true">
      <content>It seemed like &amp;quot;biological spontaneous combustion,&amp;quot; says NIH researcher Paul Brown.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="seemed" lemma="seem" stem="seem" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="biological" lemma="biological" stem="biolog" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="spontaneous" lemma="spontaneous" stem="spontan" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="combustion" lemma="combustion" stem="combust" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="NIH" lemma="NIH" stem="nih" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="12" string="researcher" lemma="researcher" stem="research" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="Paul" lemma="Paul" stem="paul" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="14" string="Brown" lemma="Brown" stem="brown" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (S (NP (PRP It)) (VP (VBD seemed) (PP (IN like) (`` ``) (NP (JJ biological) (JJ spontaneous) (NN combustion))))) (, ,) ('' '') (VP (VBZ says)) (NP (NNP NIH) (NN researcher) (NNP Paul) (NNP Brown)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="biological spontaneous combustion" type="NP">
          <tokens>
            <token id="5" string="biological" />
            <token id="6" string="spontaneous" />
            <token id="7" string="combustion" />
          </tokens>
        </chunking>
        <chunking id="2" string="says" type="VP">
          <tokens>
            <token id="10" string="says" />
          </tokens>
        </chunking>
        <chunking id="3" string="seemed like `` biological spontaneous combustion" type="VP">
          <tokens>
            <token id="2" string="seemed" />
            <token id="3" string="like" />
            <token id="4" string="&quot;" />
            <token id="5" string="biological" />
            <token id="6" string="spontaneous" />
            <token id="7" string="combustion" />
          </tokens>
        </chunking>
        <chunking id="4" string="NIH researcher Paul Brown" type="NP">
          <tokens>
            <token id="11" string="NIH" />
            <token id="12" string="researcher" />
            <token id="13" string="Paul" />
            <token id="14" string="Brown" />
          </tokens>
        </chunking>
        <chunking id="5" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">seemed</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">says</governor>
          <dependent id="2">seemed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">combustion</governor>
          <dependent id="3">like</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">combustion</governor>
          <dependent id="5">biological</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">combustion</governor>
          <dependent id="6">spontaneous</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">seemed</governor>
          <dependent id="7">combustion</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">says</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Brown</governor>
          <dependent id="11">NIH</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Brown</governor>
          <dependent id="12">researcher</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Brown</governor>
          <dependent id="13">Paul</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">says</governor>
          <dependent id="14">Brown</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Paul Brown" type="PERSON" score="0.0">
          <tokens>
            <token id="13" string="Paul" />
            <token id="14" string="Brown" />
          </tokens>
        </entity>
        <entity id="2" string="NIH" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="11" string="NIH" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="56" has_coreference="true">
      <content>In the early 1980s, scientists discovered that CJD, like Alzheimer&amp;apost;s disease, often gums up the brain with a kind of junk, or &amp;quot;amyloid,&amp;quot; protein.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="early" lemma="early" stem="earli" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="4" string="1980s" lemma="1980s" stem="1980" pos="CD" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="scientists" lemma="scientist" stem="scientist" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="discovered" lemma="discover" stem="discov" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="CJD" lemma="CJD" stem="cjd" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="Alzheimer" lemma="Alzheimer" stem="alzheimer" pos="NNP" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="13" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="14" string="disease" lemma="disease" stem="diseas" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="often" lemma="often" stem="often" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="gums" lemma="gum" stem="gum" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="up" lemma="up" stem="up" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="brain" lemma="brain" stem="brain" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="23" string="kind" lemma="kind" stem="kind" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="25" string="junk" lemma="junk" stem="junk" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="26" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="27" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="28" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="29" string="amyloid" lemma="amyloid" stem="amyloid" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="30" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="31" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="32" string="protein" lemma="protein" stem="protein" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (DT the) (JJ early) (CD 1980s))) (, ,) (NP (NNS scientists)) (VP (VBD discovered) (SBAR (IN that) (FRAG (NP (NNP CJD)))) (, ,) (PP (IN like) (NP (NP (NNP Alzheimer) (POS 's)) (NN disease) (PRN (, ,) (ADVP (RB often)) (NP (NP (NNS gums)) (PP (IN up) (NP (NP (DT the) (NN brain)) (PP (IN with) (NP (NP (DT a) (NN kind)) (PP (IN of) (NP (NP (NN junk)) (PRN (, ,) (CC or) (`` ``) (NP (NN amyloid)) (, ,) ('' '')))))))))) (NN protein)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the brain" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="brain" />
          </tokens>
        </chunking>
        <chunking id="2" string="Alzheimer 's" type="NP">
          <tokens>
            <token id="12" string="Alzheimer" />
            <token id="13" string="'s" />
          </tokens>
        </chunking>
        <chunking id="3" string="gums" type="NP">
          <tokens>
            <token id="17" string="gums" />
          </tokens>
        </chunking>
        <chunking id="4" string="Alzheimer 's disease , often gums up the brain with a kind of junk , or `` amyloid , '' protein" type="NP">
          <tokens>
            <token id="12" string="Alzheimer" />
            <token id="13" string="'s" />
            <token id="14" string="disease" />
            <token id="15" string="," />
            <token id="16" string="often" />
            <token id="17" string="gums" />
            <token id="18" string="up" />
            <token id="19" string="the" />
            <token id="20" string="brain" />
            <token id="21" string="with" />
            <token id="22" string="a" />
            <token id="23" string="kind" />
            <token id="24" string="of" />
            <token id="25" string="junk" />
            <token id="26" string="," />
            <token id="27" string="or" />
            <token id="28" string="&quot;" />
            <token id="29" string="amyloid" />
            <token id="30" string="," />
            <token id="31" string="&quot;" />
            <token id="32" string="protein" />
          </tokens>
        </chunking>
        <chunking id="5" string="discovered that CJD , like Alzheimer 's disease , often gums up the brain with a kind of junk , or `` amyloid , '' protein" type="VP">
          <tokens>
            <token id="7" string="discovered" />
            <token id="8" string="that" />
            <token id="9" string="CJD" />
            <token id="10" string="," />
            <token id="11" string="like" />
            <token id="12" string="Alzheimer" />
            <token id="13" string="'s" />
            <token id="14" string="disease" />
            <token id="15" string="," />
            <token id="16" string="often" />
            <token id="17" string="gums" />
            <token id="18" string="up" />
            <token id="19" string="the" />
            <token id="20" string="brain" />
            <token id="21" string="with" />
            <token id="22" string="a" />
            <token id="23" string="kind" />
            <token id="24" string="of" />
            <token id="25" string="junk" />
            <token id="26" string="," />
            <token id="27" string="or" />
            <token id="28" string="&quot;" />
            <token id="29" string="amyloid" />
            <token id="30" string="," />
            <token id="31" string="&quot;" />
            <token id="32" string="protein" />
          </tokens>
        </chunking>
        <chunking id="6" string="a kind" type="NP">
          <tokens>
            <token id="22" string="a" />
            <token id="23" string="kind" />
          </tokens>
        </chunking>
        <chunking id="7" string="the early 1980s" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="early" />
            <token id="4" string="1980s" />
          </tokens>
        </chunking>
        <chunking id="8" string="that CJD" type="SBAR">
          <tokens>
            <token id="8" string="that" />
            <token id="9" string="CJD" />
          </tokens>
        </chunking>
        <chunking id="9" string="gums up the brain with a kind of junk , or `` amyloid , ''" type="NP">
          <tokens>
            <token id="17" string="gums" />
            <token id="18" string="up" />
            <token id="19" string="the" />
            <token id="20" string="brain" />
            <token id="21" string="with" />
            <token id="22" string="a" />
            <token id="23" string="kind" />
            <token id="24" string="of" />
            <token id="25" string="junk" />
            <token id="26" string="," />
            <token id="27" string="or" />
            <token id="28" string="&quot;" />
            <token id="29" string="amyloid" />
            <token id="30" string="," />
            <token id="31" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="10" string="amyloid" type="NP">
          <tokens>
            <token id="29" string="amyloid" />
          </tokens>
        </chunking>
        <chunking id="11" string="scientists" type="NP">
          <tokens>
            <token id="6" string="scientists" />
          </tokens>
        </chunking>
        <chunking id="12" string="junk" type="NP">
          <tokens>
            <token id="25" string="junk" />
          </tokens>
        </chunking>
        <chunking id="13" string="a kind of junk , or `` amyloid , ''" type="NP">
          <tokens>
            <token id="22" string="a" />
            <token id="23" string="kind" />
            <token id="24" string="of" />
            <token id="25" string="junk" />
            <token id="26" string="," />
            <token id="27" string="or" />
            <token id="28" string="&quot;" />
            <token id="29" string="amyloid" />
            <token id="30" string="," />
            <token id="31" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="14" string="junk , or `` amyloid , ''" type="NP">
          <tokens>
            <token id="25" string="junk" />
            <token id="26" string="," />
            <token id="27" string="or" />
            <token id="28" string="&quot;" />
            <token id="29" string="amyloid" />
            <token id="30" string="," />
            <token id="31" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="15" string="CJD" type="NP">
          <tokens>
            <token id="9" string="CJD" />
          </tokens>
        </chunking>
        <chunking id="16" string="the brain with a kind of junk , or `` amyloid , ''" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="brain" />
            <token id="21" string="with" />
            <token id="22" string="a" />
            <token id="23" string="kind" />
            <token id="24" string="of" />
            <token id="25" string="junk" />
            <token id="26" string="," />
            <token id="27" string="or" />
            <token id="28" string="&quot;" />
            <token id="29" string="amyloid" />
            <token id="30" string="," />
            <token id="31" string="&quot;" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">1980s</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">1980s</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">1980s</governor>
          <dependent id="3">early</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">discovered</governor>
          <dependent id="4">1980s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">discovered</governor>
          <dependent id="6">scientists</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">discovered</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">CJD</governor>
          <dependent id="8">that</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="7">discovered</governor>
          <dependent id="9">CJD</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">protein</governor>
          <dependent id="11">like</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="32">protein</governor>
          <dependent id="12">Alzheimer</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">Alzheimer</governor>
          <dependent id="13">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="32">protein</governor>
          <dependent id="14">disease</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="17">gums</governor>
          <dependent id="16">often</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="32">protein</governor>
          <dependent id="17">gums</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">brain</governor>
          <dependent id="18">up</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">brain</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">gums</governor>
          <dependent id="20">brain</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">kind</governor>
          <dependent id="21">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">kind</governor>
          <dependent id="22">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">brain</governor>
          <dependent id="23">kind</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">junk</governor>
          <dependent id="24">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">kind</governor>
          <dependent id="25">junk</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="29">amyloid</governor>
          <dependent id="27">or</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="25">junk</governor>
          <dependent id="29">amyloid</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">discovered</governor>
          <dependent id="32">protein</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="the early 1980s" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="early" />
            <token id="4" string="1980s" />
          </tokens>
        </entity>
        <entity id="2" string="Alzheimer 's disease" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="12" string="Alzheimer" />
            <token id="13" string="'s" />
            <token id="14" string="disease" />
          </tokens>
        </entity>
        <entity id="3" string="CJD" type="MISC" score="0.0">
          <tokens>
            <token id="9" string="CJD" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="57" has_coreference="true">
      <content>Further studies showed the junk mainly contains a botched form of a naturally occurring brain protein, sometimes called a prion.</content>
      <tokens>
        <token id="1" string="Further" lemma="further" stem="further" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="studies" lemma="study" stem="studi" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="showed" lemma="show" stem="show" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="junk" lemma="junk" stem="junk" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="mainly" lemma="mainly" stem="mainli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="contains" lemma="contain" stem="contain" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="botched" lemma="botched" stem="botch" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="form" lemma="form" stem="form" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="naturally" lemma="naturally" stem="natur" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="occurring" lemma="occur" stem="occur" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="brain" lemma="brain" stem="brain" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="protein" lemma="protein" stem="protein" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="sometimes" lemma="sometimes" stem="sometim" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="called" lemma="call" stem="call" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="prion" lemma="prion" stem="prion" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (JJ Further) (NNS studies)) (VP (VBD showed) (SBAR (S (NP (DT the) (NN junk)) (VP (VP (ADVP (RB mainly)) (VBZ contains) (NP (NP (DT a) (JJ botched) (NN form)) (PP (IN of) (NP (DT a) (ADJP (RB naturally) (VBG occurring)) (NN brain) (NN protein))))) (, ,) (ADVP (RB sometimes)) (VP (VBD called) (NP (DT a) (NN prion))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a prion" type="NP">
          <tokens>
            <token id="20" string="a" />
            <token id="21" string="prion" />
          </tokens>
        </chunking>
        <chunking id="2" string="showed the junk mainly contains a botched form of a naturally occurring brain protein , sometimes called a prion" type="VP">
          <tokens>
            <token id="3" string="showed" />
            <token id="4" string="the" />
            <token id="5" string="junk" />
            <token id="6" string="mainly" />
            <token id="7" string="contains" />
            <token id="8" string="a" />
            <token id="9" string="botched" />
            <token id="10" string="form" />
            <token id="11" string="of" />
            <token id="12" string="a" />
            <token id="13" string="naturally" />
            <token id="14" string="occurring" />
            <token id="15" string="brain" />
            <token id="16" string="protein" />
            <token id="17" string="," />
            <token id="18" string="sometimes" />
            <token id="19" string="called" />
            <token id="20" string="a" />
            <token id="21" string="prion" />
          </tokens>
        </chunking>
        <chunking id="3" string="the junk mainly contains a botched form of a naturally occurring brain protein , sometimes called a prion" type="SBAR">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="junk" />
            <token id="6" string="mainly" />
            <token id="7" string="contains" />
            <token id="8" string="a" />
            <token id="9" string="botched" />
            <token id="10" string="form" />
            <token id="11" string="of" />
            <token id="12" string="a" />
            <token id="13" string="naturally" />
            <token id="14" string="occurring" />
            <token id="15" string="brain" />
            <token id="16" string="protein" />
            <token id="17" string="," />
            <token id="18" string="sometimes" />
            <token id="19" string="called" />
            <token id="20" string="a" />
            <token id="21" string="prion" />
          </tokens>
        </chunking>
        <chunking id="4" string="mainly contains a botched form of a naturally occurring brain protein" type="VP">
          <tokens>
            <token id="6" string="mainly" />
            <token id="7" string="contains" />
            <token id="8" string="a" />
            <token id="9" string="botched" />
            <token id="10" string="form" />
            <token id="11" string="of" />
            <token id="12" string="a" />
            <token id="13" string="naturally" />
            <token id="14" string="occurring" />
            <token id="15" string="brain" />
            <token id="16" string="protein" />
          </tokens>
        </chunking>
        <chunking id="5" string="a naturally occurring brain protein" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="naturally" />
            <token id="14" string="occurring" />
            <token id="15" string="brain" />
            <token id="16" string="protein" />
          </tokens>
        </chunking>
        <chunking id="6" string="the junk" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="junk" />
          </tokens>
        </chunking>
        <chunking id="7" string="naturally occurring" type="ADJP">
          <tokens>
            <token id="13" string="naturally" />
            <token id="14" string="occurring" />
          </tokens>
        </chunking>
        <chunking id="8" string="Further studies" type="NP">
          <tokens>
            <token id="1" string="Further" />
            <token id="2" string="studies" />
          </tokens>
        </chunking>
        <chunking id="9" string="mainly contains a botched form of a naturally occurring brain protein , sometimes called a prion" type="VP">
          <tokens>
            <token id="6" string="mainly" />
            <token id="7" string="contains" />
            <token id="8" string="a" />
            <token id="9" string="botched" />
            <token id="10" string="form" />
            <token id="11" string="of" />
            <token id="12" string="a" />
            <token id="13" string="naturally" />
            <token id="14" string="occurring" />
            <token id="15" string="brain" />
            <token id="16" string="protein" />
            <token id="17" string="," />
            <token id="18" string="sometimes" />
            <token id="19" string="called" />
            <token id="20" string="a" />
            <token id="21" string="prion" />
          </tokens>
        </chunking>
        <chunking id="10" string="called a prion" type="VP">
          <tokens>
            <token id="19" string="called" />
            <token id="20" string="a" />
            <token id="21" string="prion" />
          </tokens>
        </chunking>
        <chunking id="11" string="a botched form" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="botched" />
            <token id="10" string="form" />
          </tokens>
        </chunking>
        <chunking id="12" string="a botched form of a naturally occurring brain protein" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="botched" />
            <token id="10" string="form" />
            <token id="11" string="of" />
            <token id="12" string="a" />
            <token id="13" string="naturally" />
            <token id="14" string="occurring" />
            <token id="15" string="brain" />
            <token id="16" string="protein" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="2">studies</governor>
          <dependent id="1">Further</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">showed</governor>
          <dependent id="2">studies</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">showed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">junk</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">contains</governor>
          <dependent id="5">junk</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">contains</governor>
          <dependent id="6">mainly</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">showed</governor>
          <dependent id="7">contains</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">form</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">form</governor>
          <dependent id="9">botched</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">contains</governor>
          <dependent id="10">form</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">protein</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">protein</governor>
          <dependent id="12">a</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">occurring</governor>
          <dependent id="13">naturally</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">protein</governor>
          <dependent id="14">occurring</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">protein</governor>
          <dependent id="15">brain</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">form</governor>
          <dependent id="16">protein</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="19">called</governor>
          <dependent id="18">sometimes</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="7">contains</governor>
          <dependent id="19">called</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">prion</governor>
          <dependent id="20">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">called</governor>
          <dependent id="21">prion</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="58" has_coreference="true">
      <content>Many scientists now believe it&amp;apost;s the culprit.</content>
      <tokens>
        <token id="1" string="Many" lemma="many" stem="mani" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="scientists" lemma="scientist" stem="scientist" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="4" string="believe" lemma="believe" stem="believ" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="culprit" lemma="culprit" stem="culprit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (JJ Many) (NNS scientists)) (ADVP (RB now)) (VP (VBP believe) (SBAR (S (NP (PRP it)) (VP (VBZ 's) (NP (DT the) (NN culprit)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the culprit" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="culprit" />
          </tokens>
        </chunking>
        <chunking id="2" string="it 's the culprit" type="SBAR">
          <tokens>
            <token id="5" string="it" />
            <token id="6" string="'s" />
            <token id="7" string="the" />
            <token id="8" string="culprit" />
          </tokens>
        </chunking>
        <chunking id="3" string="Many scientists" type="NP">
          <tokens>
            <token id="1" string="Many" />
            <token id="2" string="scientists" />
          </tokens>
        </chunking>
        <chunking id="4" string="believe it 's the culprit" type="VP">
          <tokens>
            <token id="4" string="believe" />
            <token id="5" string="it" />
            <token id="6" string="'s" />
            <token id="7" string="the" />
            <token id="8" string="culprit" />
          </tokens>
        </chunking>
        <chunking id="5" string="it" type="NP">
          <tokens>
            <token id="5" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="'s the culprit" type="VP">
          <tokens>
            <token id="6" string="'s" />
            <token id="7" string="the" />
            <token id="8" string="culprit" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="2">scientists</governor>
          <dependent id="1">Many</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">believe</governor>
          <dependent id="2">scientists</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">believe</governor>
          <dependent id="3">now</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">believe</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">culprit</governor>
          <dependent id="5">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="8">culprit</governor>
          <dependent id="6">'s</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">culprit</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">believe</governor>
          <dependent id="8">culprit</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="now" type="DATE" score="0.0">
          <tokens>
            <token id="3" string="now" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="59" has_coreference="true">
      <content>But their theory entails a biologically weird premise: that the altered protein replicates itself without the aid of genetic material, the basis of all known reproduction.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="theory" lemma="theory" stem="theori" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="entails" lemma="entail" stem="entail" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="biologically" lemma="biologically" stem="biolog" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="weird" lemma="weird" stem="weird" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="premise" lemma="premise" stem="premis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="altered" lemma="altered" stem="alter" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="protein" lemma="protein" stem="protein" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="replicates" lemma="replicate" stem="replic" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="itself" lemma="itself" stem="itself" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="without" lemma="without" stem="without" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="aid" lemma="aid" stem="aid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="genetic" lemma="genetic" stem="genet" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="material" lemma="material" stem="materi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="basis" lemma="basis" stem="basi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="known" lemma="know" stem="known" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="reproduction" lemma="reproduction" stem="reproduct" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (PRP$ their) (NN theory)) (VP (VBZ entails) (NP (NP (DT a) (ADJP (RB biologically) (JJ weird)) (NN premise)) (: :) (SBAR (IN that) (S (NP (DT the) (JJ altered) (NN protein)) (VP (VBZ replicates) (NP (PRP itself)) (PP (IN without) (NP (NP (DT the) (NN aid)) (PP (IN of) (NP (JJ genetic) (NN material))))) (, ,) (NP (NP (DT the) (NN basis)) (PP (IN of) (NP (DT all) (VBN known) (NN reproduction))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a biologically weird premise" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="biologically" />
            <token id="7" string="weird" />
            <token id="8" string="premise" />
          </tokens>
        </chunking>
        <chunking id="2" string="the altered protein" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="altered" />
            <token id="13" string="protein" />
          </tokens>
        </chunking>
        <chunking id="3" string="replicates itself without the aid of genetic material , the basis of all known reproduction" type="VP">
          <tokens>
            <token id="14" string="replicates" />
            <token id="15" string="itself" />
            <token id="16" string="without" />
            <token id="17" string="the" />
            <token id="18" string="aid" />
            <token id="19" string="of" />
            <token id="20" string="genetic" />
            <token id="21" string="material" />
            <token id="22" string="," />
            <token id="23" string="the" />
            <token id="24" string="basis" />
            <token id="25" string="of" />
            <token id="26" string="all" />
            <token id="27" string="known" />
            <token id="28" string="reproduction" />
          </tokens>
        </chunking>
        <chunking id="4" string="biologically weird" type="ADJP">
          <tokens>
            <token id="6" string="biologically" />
            <token id="7" string="weird" />
          </tokens>
        </chunking>
        <chunking id="5" string="the aid" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="aid" />
          </tokens>
        </chunking>
        <chunking id="6" string="a biologically weird premise : that the altered protein replicates itself without the aid of genetic material , the basis of all known reproduction" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="biologically" />
            <token id="7" string="weird" />
            <token id="8" string="premise" />
            <token id="9" string=":" />
            <token id="10" string="that" />
            <token id="11" string="the" />
            <token id="12" string="altered" />
            <token id="13" string="protein" />
            <token id="14" string="replicates" />
            <token id="15" string="itself" />
            <token id="16" string="without" />
            <token id="17" string="the" />
            <token id="18" string="aid" />
            <token id="19" string="of" />
            <token id="20" string="genetic" />
            <token id="21" string="material" />
            <token id="22" string="," />
            <token id="23" string="the" />
            <token id="24" string="basis" />
            <token id="25" string="of" />
            <token id="26" string="all" />
            <token id="27" string="known" />
            <token id="28" string="reproduction" />
          </tokens>
        </chunking>
        <chunking id="7" string="that the altered protein replicates itself without the aid of genetic material , the basis of all known reproduction" type="SBAR">
          <tokens>
            <token id="10" string="that" />
            <token id="11" string="the" />
            <token id="12" string="altered" />
            <token id="13" string="protein" />
            <token id="14" string="replicates" />
            <token id="15" string="itself" />
            <token id="16" string="without" />
            <token id="17" string="the" />
            <token id="18" string="aid" />
            <token id="19" string="of" />
            <token id="20" string="genetic" />
            <token id="21" string="material" />
            <token id="22" string="," />
            <token id="23" string="the" />
            <token id="24" string="basis" />
            <token id="25" string="of" />
            <token id="26" string="all" />
            <token id="27" string="known" />
            <token id="28" string="reproduction" />
          </tokens>
        </chunking>
        <chunking id="8" string="entails a biologically weird premise : that the altered protein replicates itself without the aid of genetic material , the basis of all known reproduction" type="VP">
          <tokens>
            <token id="4" string="entails" />
            <token id="5" string="a" />
            <token id="6" string="biologically" />
            <token id="7" string="weird" />
            <token id="8" string="premise" />
            <token id="9" string=":" />
            <token id="10" string="that" />
            <token id="11" string="the" />
            <token id="12" string="altered" />
            <token id="13" string="protein" />
            <token id="14" string="replicates" />
            <token id="15" string="itself" />
            <token id="16" string="without" />
            <token id="17" string="the" />
            <token id="18" string="aid" />
            <token id="19" string="of" />
            <token id="20" string="genetic" />
            <token id="21" string="material" />
            <token id="22" string="," />
            <token id="23" string="the" />
            <token id="24" string="basis" />
            <token id="25" string="of" />
            <token id="26" string="all" />
            <token id="27" string="known" />
            <token id="28" string="reproduction" />
          </tokens>
        </chunking>
        <chunking id="9" string="their theory" type="NP">
          <tokens>
            <token id="2" string="their" />
            <token id="3" string="theory" />
          </tokens>
        </chunking>
        <chunking id="10" string="the basis" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="basis" />
          </tokens>
        </chunking>
        <chunking id="11" string="itself" type="NP">
          <tokens>
            <token id="15" string="itself" />
          </tokens>
        </chunking>
        <chunking id="12" string="the aid of genetic material" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="aid" />
            <token id="19" string="of" />
            <token id="20" string="genetic" />
            <token id="21" string="material" />
          </tokens>
        </chunking>
        <chunking id="13" string="all known reproduction" type="NP">
          <tokens>
            <token id="26" string="all" />
            <token id="27" string="known" />
            <token id="28" string="reproduction" />
          </tokens>
        </chunking>
        <chunking id="14" string="genetic material" type="NP">
          <tokens>
            <token id="20" string="genetic" />
            <token id="21" string="material" />
          </tokens>
        </chunking>
        <chunking id="15" string="the basis of all known reproduction" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="basis" />
            <token id="25" string="of" />
            <token id="26" string="all" />
            <token id="27" string="known" />
            <token id="28" string="reproduction" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="4">entails</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="3">theory</governor>
          <dependent id="2">their</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">entails</governor>
          <dependent id="3">theory</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">entails</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">premise</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">weird</governor>
          <dependent id="6">biologically</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">premise</governor>
          <dependent id="7">weird</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">entails</governor>
          <dependent id="8">premise</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">replicates</governor>
          <dependent id="10">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">protein</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">protein</governor>
          <dependent id="12">altered</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">replicates</governor>
          <dependent id="13">protein</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="8">premise</governor>
          <dependent id="14">replicates</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">replicates</governor>
          <dependent id="15">itself</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">aid</governor>
          <dependent id="16">without</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">aid</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">replicates</governor>
          <dependent id="18">aid</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">material</governor>
          <dependent id="19">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">material</governor>
          <dependent id="20">genetic</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">aid</governor>
          <dependent id="21">material</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">basis</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">replicates</governor>
          <dependent id="24">basis</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">reproduction</governor>
          <dependent id="25">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">reproduction</governor>
          <dependent id="26">all</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">reproduction</governor>
          <dependent id="27">known</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">basis</governor>
          <dependent id="28">reproduction</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="60" has_coreference="true">
      <content>If they&amp;apost;re right, such self-replicating proteins might be representatives of an ancient twilight zone between life and nonlife-evolution&amp;apost;s bridge between molecules and microbes.</content>
      <tokens>
        <token id="1" string="If" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="'re" lemma="be" stem="'re" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="right" lemma="right" stem="right" pos="RB" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="such" lemma="such" stem="such" pos="JJ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="self-replicating" lemma="self-replicating" stem="self-repl" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="proteins" lemma="protein" stem="protein" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="might" lemma="might" stem="might" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="representatives" lemma="representative" stem="repres" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="ancient" lemma="ancient" stem="ancient" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="twilight" lemma="twilight" stem="twilight" pos="NN" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="16" string="zone" lemma="zone" stem="zone" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="between" lemma="between" stem="between" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="life" lemma="life" stem="life" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="nonlife-evolution" lemma="nonlife-evolution" stem="nonlife-evolut" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="bridge" lemma="bridge" stem="bridg" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="between" lemma="between" stem="between" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="molecules" lemma="molecule" stem="molecul" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="microbes" lemma="microbe" stem="microb" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN If) (S (NP (PRP they)) (VP (VBP 're) (ADJP (RB right))))) (, ,) (NP (JJ such) (JJ self-replicating) (NNS proteins)) (VP (MD might) (VP (VB be) (NP (NP (NNS representatives)) (PP (IN of) (NP (NP (NP (DT an) (JJ ancient) (NN twilight) (NN zone)) (PP (IN between) (NP (NN life)))) (CC and) (NP (NP (NP (NN nonlife-evolution) (POS 's)) (NN bridge)) (PP (IN between) (NP (NNS molecules) (CC and) (NNS microbes))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="representatives of an ancient twilight zone between life and nonlife-evolution 's bridge between molecules and microbes" type="NP">
          <tokens>
            <token id="11" string="representatives" />
            <token id="12" string="of" />
            <token id="13" string="an" />
            <token id="14" string="ancient" />
            <token id="15" string="twilight" />
            <token id="16" string="zone" />
            <token id="17" string="between" />
            <token id="18" string="life" />
            <token id="19" string="and" />
            <token id="20" string="nonlife-evolution" />
            <token id="21" string="'s" />
            <token id="22" string="bridge" />
            <token id="23" string="between" />
            <token id="24" string="molecules" />
            <token id="25" string="and" />
            <token id="26" string="microbes" />
          </tokens>
        </chunking>
        <chunking id="2" string="be representatives of an ancient twilight zone between life and nonlife-evolution 's bridge between molecules and microbes" type="VP">
          <tokens>
            <token id="10" string="be" />
            <token id="11" string="representatives" />
            <token id="12" string="of" />
            <token id="13" string="an" />
            <token id="14" string="ancient" />
            <token id="15" string="twilight" />
            <token id="16" string="zone" />
            <token id="17" string="between" />
            <token id="18" string="life" />
            <token id="19" string="and" />
            <token id="20" string="nonlife-evolution" />
            <token id="21" string="'s" />
            <token id="22" string="bridge" />
            <token id="23" string="between" />
            <token id="24" string="molecules" />
            <token id="25" string="and" />
            <token id="26" string="microbes" />
          </tokens>
        </chunking>
        <chunking id="3" string="life" type="NP">
          <tokens>
            <token id="18" string="life" />
          </tokens>
        </chunking>
        <chunking id="4" string="nonlife-evolution 's bridge" type="NP">
          <tokens>
            <token id="20" string="nonlife-evolution" />
            <token id="21" string="'s" />
            <token id="22" string="bridge" />
          </tokens>
        </chunking>
        <chunking id="5" string="an ancient twilight zone" type="NP">
          <tokens>
            <token id="13" string="an" />
            <token id="14" string="ancient" />
            <token id="15" string="twilight" />
            <token id="16" string="zone" />
          </tokens>
        </chunking>
        <chunking id="6" string="right" type="ADJP">
          <tokens>
            <token id="4" string="right" />
          </tokens>
        </chunking>
        <chunking id="7" string="If they 're right" type="SBAR">
          <tokens>
            <token id="1" string="If" />
            <token id="2" string="they" />
            <token id="3" string="'re" />
            <token id="4" string="right" />
          </tokens>
        </chunking>
        <chunking id="8" string="'re right" type="VP">
          <tokens>
            <token id="3" string="'re" />
            <token id="4" string="right" />
          </tokens>
        </chunking>
        <chunking id="9" string="an ancient twilight zone between life" type="NP">
          <tokens>
            <token id="13" string="an" />
            <token id="14" string="ancient" />
            <token id="15" string="twilight" />
            <token id="16" string="zone" />
            <token id="17" string="between" />
            <token id="18" string="life" />
          </tokens>
        </chunking>
        <chunking id="10" string="nonlife-evolution 's" type="NP">
          <tokens>
            <token id="20" string="nonlife-evolution" />
            <token id="21" string="'s" />
          </tokens>
        </chunking>
        <chunking id="11" string="they" type="NP">
          <tokens>
            <token id="2" string="they" />
          </tokens>
        </chunking>
        <chunking id="12" string="molecules and microbes" type="NP">
          <tokens>
            <token id="24" string="molecules" />
            <token id="25" string="and" />
            <token id="26" string="microbes" />
          </tokens>
        </chunking>
        <chunking id="13" string="nonlife-evolution 's bridge between molecules and microbes" type="NP">
          <tokens>
            <token id="20" string="nonlife-evolution" />
            <token id="21" string="'s" />
            <token id="22" string="bridge" />
            <token id="23" string="between" />
            <token id="24" string="molecules" />
            <token id="25" string="and" />
            <token id="26" string="microbes" />
          </tokens>
        </chunking>
        <chunking id="14" string="such self-replicating proteins" type="NP">
          <tokens>
            <token id="6" string="such" />
            <token id="7" string="self-replicating" />
            <token id="8" string="proteins" />
          </tokens>
        </chunking>
        <chunking id="15" string="an ancient twilight zone between life and nonlife-evolution 's bridge between molecules and microbes" type="NP">
          <tokens>
            <token id="13" string="an" />
            <token id="14" string="ancient" />
            <token id="15" string="twilight" />
            <token id="16" string="zone" />
            <token id="17" string="between" />
            <token id="18" string="life" />
            <token id="19" string="and" />
            <token id="20" string="nonlife-evolution" />
            <token id="21" string="'s" />
            <token id="22" string="bridge" />
            <token id="23" string="between" />
            <token id="24" string="molecules" />
            <token id="25" string="and" />
            <token id="26" string="microbes" />
          </tokens>
        </chunking>
        <chunking id="16" string="might be representatives of an ancient twilight zone between life and nonlife-evolution 's bridge between molecules and microbes" type="VP">
          <tokens>
            <token id="9" string="might" />
            <token id="10" string="be" />
            <token id="11" string="representatives" />
            <token id="12" string="of" />
            <token id="13" string="an" />
            <token id="14" string="ancient" />
            <token id="15" string="twilight" />
            <token id="16" string="zone" />
            <token id="17" string="between" />
            <token id="18" string="life" />
            <token id="19" string="and" />
            <token id="20" string="nonlife-evolution" />
            <token id="21" string="'s" />
            <token id="22" string="bridge" />
            <token id="23" string="between" />
            <token id="24" string="molecules" />
            <token id="25" string="and" />
            <token id="26" string="microbes" />
          </tokens>
        </chunking>
        <chunking id="17" string="representatives" type="NP">
          <tokens>
            <token id="11" string="representatives" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="4">right</governor>
          <dependent id="1">If</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">right</governor>
          <dependent id="2">they</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">right</governor>
          <dependent id="3">'re</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="11">representatives</governor>
          <dependent id="4">right</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">proteins</governor>
          <dependent id="6">such</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">proteins</governor>
          <dependent id="7">self-replicating</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">representatives</governor>
          <dependent id="8">proteins</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">representatives</governor>
          <dependent id="9">might</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="11">representatives</governor>
          <dependent id="10">be</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">representatives</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">zone</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">zone</governor>
          <dependent id="13">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">zone</governor>
          <dependent id="14">ancient</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">zone</governor>
          <dependent id="15">twilight</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">representatives</governor>
          <dependent id="16">zone</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">life</governor>
          <dependent id="17">between</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">zone</governor>
          <dependent id="18">life</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="16">zone</governor>
          <dependent id="19">and</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="22">bridge</governor>
          <dependent id="20">nonlife-evolution</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">nonlife-evolution</governor>
          <dependent id="21">'s</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">zone</governor>
          <dependent id="22">bridge</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">molecules</governor>
          <dependent id="23">between</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">bridge</governor>
          <dependent id="24">molecules</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="24">molecules</governor>
          <dependent id="25">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="24">molecules</governor>
          <dependent id="26">microbes</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="twilight" type="TIME" score="0.0">
          <tokens>
            <token id="15" string="twilight" />
          </tokens>
        </entity>
        <entity id="2" string="right" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="4" string="right" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="61" has_coreference="true">
      <content>When formed in a brain cell, a molecule of such stuff might be &amp;quot;like a bad apple in a barrel converting all the other apples,&amp;quot; says the NIH&amp;apost;s Dr. Brown.</content>
      <tokens>
        <token id="1" string="When" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="formed" lemma="form" stem="form" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="brain" lemma="brain" stem="brain" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="cell" lemma="cell" stem="cell" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="molecule" lemma="molecule" stem="molecul" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="such" lemma="such" stem="such" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="stuff" lemma="stuff" stem="stuff" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="might" lemma="might" stem="might" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="bad" lemma="bad" stem="bad" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="apple" lemma="apple" stem="appl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="barrel" lemma="barrel" stem="barrel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="converting" lemma="convert" stem="convert" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="all" lemma="all" stem="all" pos="PDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="apples" lemma="apple" stem="appl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="32" string="NIH" lemma="NIH" stem="nih" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="33" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="34" string="Dr." lemma="Dr." stem="dr." pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="35" string="Brown" lemma="Brown" stem="brown" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="36" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (S (SBAR (WHADVP (WRB When)) (S (VP (VBN formed) (PP (IN in) (NP (DT a) (NN brain) (NN cell)))))) (, ,) (NP (NP (DT a) (NN molecule)) (PP (IN of) (NP (JJ such) (NN stuff)))) (VP (MD might) (VP (VB be) (`` ``) (PP (IN like) (NP (NP (DT a) (JJ bad) (NN apple)) (PP (IN in) (NP (NP (DT a) (NN barrel)) (VP (VBG converting) (NP (PDT all) (DT the) (JJ other) (NNS apples)))))))))) (, ,) ('' '') (VP (VBZ says)) (NP (NP (DT the) (NNP NIH) (POS 's)) (NNP Dr.) (NNP Brown)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="When formed in a brain cell" type="SBAR">
          <tokens>
            <token id="1" string="When" />
            <token id="2" string="formed" />
            <token id="3" string="in" />
            <token id="4" string="a" />
            <token id="5" string="brain" />
            <token id="6" string="cell" />
          </tokens>
        </chunking>
        <chunking id="2" string="a barrel converting all the other apples" type="NP">
          <tokens>
            <token id="21" string="a" />
            <token id="22" string="barrel" />
            <token id="23" string="converting" />
            <token id="24" string="all" />
            <token id="25" string="the" />
            <token id="26" string="other" />
            <token id="27" string="apples" />
          </tokens>
        </chunking>
        <chunking id="3" string="a bad apple in a barrel converting all the other apples" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="bad" />
            <token id="19" string="apple" />
            <token id="20" string="in" />
            <token id="21" string="a" />
            <token id="22" string="barrel" />
            <token id="23" string="converting" />
            <token id="24" string="all" />
            <token id="25" string="the" />
            <token id="26" string="other" />
            <token id="27" string="apples" />
          </tokens>
        </chunking>
        <chunking id="4" string="formed in a brain cell" type="VP">
          <tokens>
            <token id="2" string="formed" />
            <token id="3" string="in" />
            <token id="4" string="a" />
            <token id="5" string="brain" />
            <token id="6" string="cell" />
          </tokens>
        </chunking>
        <chunking id="5" string="a barrel" type="NP">
          <tokens>
            <token id="21" string="a" />
            <token id="22" string="barrel" />
          </tokens>
        </chunking>
        <chunking id="6" string="be `` like a bad apple in a barrel converting all the other apples" type="VP">
          <tokens>
            <token id="14" string="be" />
            <token id="15" string="&quot;" />
            <token id="16" string="like" />
            <token id="17" string="a" />
            <token id="18" string="bad" />
            <token id="19" string="apple" />
            <token id="20" string="in" />
            <token id="21" string="a" />
            <token id="22" string="barrel" />
            <token id="23" string="converting" />
            <token id="24" string="all" />
            <token id="25" string="the" />
            <token id="26" string="other" />
            <token id="27" string="apples" />
          </tokens>
        </chunking>
        <chunking id="7" string="a brain cell" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="brain" />
            <token id="6" string="cell" />
          </tokens>
        </chunking>
        <chunking id="8" string="a molecule of such stuff" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="molecule" />
            <token id="10" string="of" />
            <token id="11" string="such" />
            <token id="12" string="stuff" />
          </tokens>
        </chunking>
        <chunking id="9" string="a bad apple" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="bad" />
            <token id="19" string="apple" />
          </tokens>
        </chunking>
        <chunking id="10" string="When" type="WHADVP">
          <tokens>
            <token id="1" string="When" />
          </tokens>
        </chunking>
        <chunking id="11" string="all the other apples" type="NP">
          <tokens>
            <token id="24" string="all" />
            <token id="25" string="the" />
            <token id="26" string="other" />
            <token id="27" string="apples" />
          </tokens>
        </chunking>
        <chunking id="12" string="says" type="VP">
          <tokens>
            <token id="30" string="says" />
          </tokens>
        </chunking>
        <chunking id="13" string="converting all the other apples" type="VP">
          <tokens>
            <token id="23" string="converting" />
            <token id="24" string="all" />
            <token id="25" string="the" />
            <token id="26" string="other" />
            <token id="27" string="apples" />
          </tokens>
        </chunking>
        <chunking id="14" string="the NIH 's Dr. Brown" type="NP">
          <tokens>
            <token id="31" string="the" />
            <token id="32" string="NIH" />
            <token id="33" string="'s" />
            <token id="34" string="Dr." />
            <token id="35" string="Brown" />
          </tokens>
        </chunking>
        <chunking id="15" string="a molecule" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="molecule" />
          </tokens>
        </chunking>
        <chunking id="16" string="might be `` like a bad apple in a barrel converting all the other apples" type="VP">
          <tokens>
            <token id="13" string="might" />
            <token id="14" string="be" />
            <token id="15" string="&quot;" />
            <token id="16" string="like" />
            <token id="17" string="a" />
            <token id="18" string="bad" />
            <token id="19" string="apple" />
            <token id="20" string="in" />
            <token id="21" string="a" />
            <token id="22" string="barrel" />
            <token id="23" string="converting" />
            <token id="24" string="all" />
            <token id="25" string="the" />
            <token id="26" string="other" />
            <token id="27" string="apples" />
          </tokens>
        </chunking>
        <chunking id="17" string="such stuff" type="NP">
          <tokens>
            <token id="11" string="such" />
            <token id="12" string="stuff" />
          </tokens>
        </chunking>
        <chunking id="18" string="the NIH 's" type="NP">
          <tokens>
            <token id="31" string="the" />
            <token id="32" string="NIH" />
            <token id="33" string="'s" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="2">formed</governor>
          <dependent id="1">When</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="19">apple</governor>
          <dependent id="2">formed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">cell</governor>
          <dependent id="3">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">cell</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">cell</governor>
          <dependent id="5">brain</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">formed</governor>
          <dependent id="6">cell</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">molecule</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">apple</governor>
          <dependent id="9">molecule</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">stuff</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">stuff</governor>
          <dependent id="11">such</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">molecule</governor>
          <dependent id="12">stuff</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="19">apple</governor>
          <dependent id="13">might</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="19">apple</governor>
          <dependent id="14">be</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">apple</governor>
          <dependent id="16">like</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">apple</governor>
          <dependent id="17">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">apple</governor>
          <dependent id="18">bad</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="30">says</governor>
          <dependent id="19">apple</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">barrel</governor>
          <dependent id="20">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">barrel</governor>
          <dependent id="21">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">apple</governor>
          <dependent id="22">barrel</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="22">barrel</governor>
          <dependent id="23">converting</dependent>
        </dependency>
        <dependency type="det:predet">
          <governor id="27">apples</governor>
          <dependent id="24">all</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">apples</governor>
          <dependent id="25">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="27">apples</governor>
          <dependent id="26">other</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="23">converting</governor>
          <dependent id="27">apples</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="30">says</dependent>
        </dependency>
        <dependency type="det">
          <governor id="32">NIH</governor>
          <dependent id="31">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="35">Brown</governor>
          <dependent id="32">NIH</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">NIH</governor>
          <dependent id="33">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="35">Brown</governor>
          <dependent id="34">Dr.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="30">says</governor>
          <dependent id="35">Brown</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Brown" type="PERSON" score="0.0">
          <tokens>
            <token id="35" string="Brown" />
          </tokens>
        </entity>
        <entity id="2" string="NIH" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="32" string="NIH" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="62" has_coreference="false">
      <content>A hot question: Does the amyloid in Alzheimer&amp;apost;s disease form similarly?</content>
      <tokens>
        <token id="1" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="hot" lemma="hot" stem="hot" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="question" lemma="question" stem="question" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Does" lemma="do" stem="doe" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="amyloid" lemma="amyloid" stem="amyloid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Alzheimer" lemma="alzheimer" stem="alzheimer" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="10" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="11" string="disease" lemma="disease" stem="diseas" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="12" string="form" lemma="form" stem="form" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="similarly" lemma="similarly" stem="similarli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (FRAG (NP (DT A) (JJ hot) (NN question)) (: :) (S (VP (VBZ Does) (NP (NP (DT the) (NN amyloid)) (PP (IN in) (NP (NP (NN Alzheimer) (POS 's)) (NN disease) (NN form)))) (ADVP (RB similarly)))) (. ?)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Alzheimer 's" type="NP">
          <tokens>
            <token id="9" string="Alzheimer" />
            <token id="10" string="'s" />
          </tokens>
        </chunking>
        <chunking id="2" string="Does the amyloid in Alzheimer 's disease form similarly" type="VP">
          <tokens>
            <token id="5" string="Does" />
            <token id="6" string="the" />
            <token id="7" string="amyloid" />
            <token id="8" string="in" />
            <token id="9" string="Alzheimer" />
            <token id="10" string="'s" />
            <token id="11" string="disease" />
            <token id="12" string="form" />
            <token id="13" string="similarly" />
          </tokens>
        </chunking>
        <chunking id="3" string="Alzheimer 's disease form" type="NP">
          <tokens>
            <token id="9" string="Alzheimer" />
            <token id="10" string="'s" />
            <token id="11" string="disease" />
            <token id="12" string="form" />
          </tokens>
        </chunking>
        <chunking id="4" string="A hot question" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="hot" />
            <token id="3" string="question" />
          </tokens>
        </chunking>
        <chunking id="5" string="the amyloid in Alzheimer 's disease form" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="amyloid" />
            <token id="8" string="in" />
            <token id="9" string="Alzheimer" />
            <token id="10" string="'s" />
            <token id="11" string="disease" />
            <token id="12" string="form" />
          </tokens>
        </chunking>
        <chunking id="6" string="the amyloid" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="amyloid" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">question</governor>
          <dependent id="1">A</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">question</governor>
          <dependent id="2">hot</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">question</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="3">question</governor>
          <dependent id="5">Does</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">amyloid</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">Does</governor>
          <dependent id="7">amyloid</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">form</governor>
          <dependent id="8">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="12">form</governor>
          <dependent id="9">Alzheimer</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Alzheimer</governor>
          <dependent id="10">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">form</governor>
          <dependent id="11">disease</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">amyloid</governor>
          <dependent id="12">form</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">Does</governor>
          <dependent id="13">similarly</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Alzheimer 's disease" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="9" string="Alzheimer" />
            <token id="10" string="'s" />
            <token id="11" string="disease" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="63" has_coreference="true">
      <content>All this, however, doesn&amp;apost;t explain what happened after Dr. Brown baked isolates of the disease agent for an hour at 680 degrees Fahrenheit, a temperature that melts proteins.</content>
      <tokens>
        <token id="1" string="All" lemma="all" stem="all" pos="PDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="however" lemma="however" stem="howev" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="does" lemma="do" stem="doe" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="explain" lemma="explain" stem="explain" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="happened" lemma="happen" stem="happen" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Dr." lemma="Dr." stem="dr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="Brown" lemma="Brown" stem="brown" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="14" string="baked" lemma="baked" stem="bake" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="isolates" lemma="isolate" stem="isol" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="disease" lemma="disease" stem="diseas" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="true" is_refers="false" />
        <token id="19" string="agent" lemma="agent" stem="agent" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="22" string="hour" lemma="hour" stem="hour" pos="NN" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="23" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="24" string="680" lemma="680" stem="680" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="25" string="degrees" lemma="degree" stem="degre" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="26" string="Fahrenheit" lemma="fahrenheit" stem="fahrenheit" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="27" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="28" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="29" string="temperature" lemma="temperature" stem="temperatur" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="30" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="31" string="melts" lemma="melt" stem="melt" pos="VBZ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="32" string="proteins" lemma="protein" stem="protein" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PDT All) (DT this)) (, ,) (ADVP (RB however)) (, ,) (VP (VBZ does) (RB n't) (VP (VB explain) (SBAR (WHNP (WP what)) (S (VP (VBD happened) (PP (IN after) (NP (NNP Dr.) (NNP Brown))) (NP (NP (JJ baked) (NNS isolates)) (PP (IN of) (NP (NP (DT the) (NN disease) (NN agent)) (PP (IN for) (NP (NP (QP (DT an) (NN hour) (IN at) (CD 680)) (NNS degrees) (NN Fahrenheit)) (, ,) (NP (NP (DT a) (NN temperature)) (SBAR (WHNP (WDT that)) (S (VP (VBZ melts) (NP (NNS proteins)))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="an hour at 680 degrees Fahrenheit" type="NP">
          <tokens>
            <token id="21" string="an" />
            <token id="22" string="hour" />
            <token id="23" string="at" />
            <token id="24" string="680" />
            <token id="25" string="degrees" />
            <token id="26" string="Fahrenheit" />
          </tokens>
        </chunking>
        <chunking id="2" string="the disease agent" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="disease" />
            <token id="19" string="agent" />
          </tokens>
        </chunking>
        <chunking id="3" string="a temperature that melts proteins" type="NP">
          <tokens>
            <token id="28" string="a" />
            <token id="29" string="temperature" />
            <token id="30" string="that" />
            <token id="31" string="melts" />
            <token id="32" string="proteins" />
          </tokens>
        </chunking>
        <chunking id="4" string="proteins" type="NP">
          <tokens>
            <token id="32" string="proteins" />
          </tokens>
        </chunking>
        <chunking id="5" string="baked isolates" type="NP">
          <tokens>
            <token id="14" string="baked" />
            <token id="15" string="isolates" />
          </tokens>
        </chunking>
        <chunking id="6" string="explain what happened after Dr. Brown baked isolates of the disease agent for an hour at 680 degrees Fahrenheit , a temperature that melts proteins" type="VP">
          <tokens>
            <token id="8" string="explain" />
            <token id="9" string="what" />
            <token id="10" string="happened" />
            <token id="11" string="after" />
            <token id="12" string="Dr." />
            <token id="13" string="Brown" />
            <token id="14" string="baked" />
            <token id="15" string="isolates" />
            <token id="16" string="of" />
            <token id="17" string="the" />
            <token id="18" string="disease" />
            <token id="19" string="agent" />
            <token id="20" string="for" />
            <token id="21" string="an" />
            <token id="22" string="hour" />
            <token id="23" string="at" />
            <token id="24" string="680" />
            <token id="25" string="degrees" />
            <token id="26" string="Fahrenheit" />
            <token id="27" string="," />
            <token id="28" string="a" />
            <token id="29" string="temperature" />
            <token id="30" string="that" />
            <token id="31" string="melts" />
            <token id="32" string="proteins" />
          </tokens>
        </chunking>
        <chunking id="7" string="All this" type="NP">
          <tokens>
            <token id="1" string="All" />
            <token id="2" string="this" />
          </tokens>
        </chunking>
        <chunking id="8" string="happened after Dr. Brown baked isolates of the disease agent for an hour at 680 degrees Fahrenheit , a temperature that melts proteins" type="VP">
          <tokens>
            <token id="10" string="happened" />
            <token id="11" string="after" />
            <token id="12" string="Dr." />
            <token id="13" string="Brown" />
            <token id="14" string="baked" />
            <token id="15" string="isolates" />
            <token id="16" string="of" />
            <token id="17" string="the" />
            <token id="18" string="disease" />
            <token id="19" string="agent" />
            <token id="20" string="for" />
            <token id="21" string="an" />
            <token id="22" string="hour" />
            <token id="23" string="at" />
            <token id="24" string="680" />
            <token id="25" string="degrees" />
            <token id="26" string="Fahrenheit" />
            <token id="27" string="," />
            <token id="28" string="a" />
            <token id="29" string="temperature" />
            <token id="30" string="that" />
            <token id="31" string="melts" />
            <token id="32" string="proteins" />
          </tokens>
        </chunking>
        <chunking id="9" string="Dr. Brown" type="NP">
          <tokens>
            <token id="12" string="Dr." />
            <token id="13" string="Brown" />
          </tokens>
        </chunking>
        <chunking id="10" string="baked isolates of the disease agent for an hour at 680 degrees Fahrenheit , a temperature that melts proteins" type="NP">
          <tokens>
            <token id="14" string="baked" />
            <token id="15" string="isolates" />
            <token id="16" string="of" />
            <token id="17" string="the" />
            <token id="18" string="disease" />
            <token id="19" string="agent" />
            <token id="20" string="for" />
            <token id="21" string="an" />
            <token id="22" string="hour" />
            <token id="23" string="at" />
            <token id="24" string="680" />
            <token id="25" string="degrees" />
            <token id="26" string="Fahrenheit" />
            <token id="27" string="," />
            <token id="28" string="a" />
            <token id="29" string="temperature" />
            <token id="30" string="that" />
            <token id="31" string="melts" />
            <token id="32" string="proteins" />
          </tokens>
        </chunking>
        <chunking id="11" string="a temperature" type="NP">
          <tokens>
            <token id="28" string="a" />
            <token id="29" string="temperature" />
          </tokens>
        </chunking>
        <chunking id="12" string="that melts proteins" type="SBAR">
          <tokens>
            <token id="30" string="that" />
            <token id="31" string="melts" />
            <token id="32" string="proteins" />
          </tokens>
        </chunking>
        <chunking id="13" string="an hour at 680 degrees Fahrenheit , a temperature that melts proteins" type="NP">
          <tokens>
            <token id="21" string="an" />
            <token id="22" string="hour" />
            <token id="23" string="at" />
            <token id="24" string="680" />
            <token id="25" string="degrees" />
            <token id="26" string="Fahrenheit" />
            <token id="27" string="," />
            <token id="28" string="a" />
            <token id="29" string="temperature" />
            <token id="30" string="that" />
            <token id="31" string="melts" />
            <token id="32" string="proteins" />
          </tokens>
        </chunking>
        <chunking id="14" string="melts proteins" type="VP">
          <tokens>
            <token id="31" string="melts" />
            <token id="32" string="proteins" />
          </tokens>
        </chunking>
        <chunking id="15" string="does n't explain what happened after Dr. Brown baked isolates of the disease agent for an hour at 680 degrees Fahrenheit , a temperature that melts proteins" type="VP">
          <tokens>
            <token id="6" string="does" />
            <token id="7" string="n't" />
            <token id="8" string="explain" />
            <token id="9" string="what" />
            <token id="10" string="happened" />
            <token id="11" string="after" />
            <token id="12" string="Dr." />
            <token id="13" string="Brown" />
            <token id="14" string="baked" />
            <token id="15" string="isolates" />
            <token id="16" string="of" />
            <token id="17" string="the" />
            <token id="18" string="disease" />
            <token id="19" string="agent" />
            <token id="20" string="for" />
            <token id="21" string="an" />
            <token id="22" string="hour" />
            <token id="23" string="at" />
            <token id="24" string="680" />
            <token id="25" string="degrees" />
            <token id="26" string="Fahrenheit" />
            <token id="27" string="," />
            <token id="28" string="a" />
            <token id="29" string="temperature" />
            <token id="30" string="that" />
            <token id="31" string="melts" />
            <token id="32" string="proteins" />
          </tokens>
        </chunking>
        <chunking id="16" string="what happened after Dr. Brown baked isolates of the disease agent for an hour at 680 degrees Fahrenheit , a temperature that melts proteins" type="SBAR">
          <tokens>
            <token id="9" string="what" />
            <token id="10" string="happened" />
            <token id="11" string="after" />
            <token id="12" string="Dr." />
            <token id="13" string="Brown" />
            <token id="14" string="baked" />
            <token id="15" string="isolates" />
            <token id="16" string="of" />
            <token id="17" string="the" />
            <token id="18" string="disease" />
            <token id="19" string="agent" />
            <token id="20" string="for" />
            <token id="21" string="an" />
            <token id="22" string="hour" />
            <token id="23" string="at" />
            <token id="24" string="680" />
            <token id="25" string="degrees" />
            <token id="26" string="Fahrenheit" />
            <token id="27" string="," />
            <token id="28" string="a" />
            <token id="29" string="temperature" />
            <token id="30" string="that" />
            <token id="31" string="melts" />
            <token id="32" string="proteins" />
          </tokens>
        </chunking>
        <chunking id="17" string="the disease agent for an hour at 680 degrees Fahrenheit , a temperature that melts proteins" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="disease" />
            <token id="19" string="agent" />
            <token id="20" string="for" />
            <token id="21" string="an" />
            <token id="22" string="hour" />
            <token id="23" string="at" />
            <token id="24" string="680" />
            <token id="25" string="degrees" />
            <token id="26" string="Fahrenheit" />
            <token id="27" string="," />
            <token id="28" string="a" />
            <token id="29" string="temperature" />
            <token id="30" string="that" />
            <token id="31" string="melts" />
            <token id="32" string="proteins" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det:predet">
          <governor id="2">this</governor>
          <dependent id="1">All</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">explain</governor>
          <dependent id="2">this</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">explain</governor>
          <dependent id="4">however</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">explain</governor>
          <dependent id="6">does</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="8">explain</governor>
          <dependent id="7">n't</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">explain</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">happened</governor>
          <dependent id="9">what</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="8">explain</governor>
          <dependent id="10">happened</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Brown</governor>
          <dependent id="11">after</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Brown</governor>
          <dependent id="12">Dr.</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">happened</governor>
          <dependent id="13">Brown</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">isolates</governor>
          <dependent id="14">baked</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">happened</governor>
          <dependent id="15">isolates</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">agent</governor>
          <dependent id="16">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">agent</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">agent</governor>
          <dependent id="18">disease</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">isolates</governor>
          <dependent id="19">agent</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">Fahrenheit</governor>
          <dependent id="20">for</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="22">hour</governor>
          <dependent id="21">an</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="26">Fahrenheit</governor>
          <dependent id="22">hour</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="22">hour</governor>
          <dependent id="23">at</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">hour</governor>
          <dependent id="24">680</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">Fahrenheit</governor>
          <dependent id="25">degrees</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">agent</governor>
          <dependent id="26">Fahrenheit</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">temperature</governor>
          <dependent id="28">a</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="26">Fahrenheit</governor>
          <dependent id="29">temperature</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="31">melts</governor>
          <dependent id="30">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="29">temperature</governor>
          <dependent id="31">melts</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="31">melts</governor>
          <dependent id="32">proteins</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Brown" type="PERSON" score="0.0">
          <tokens>
            <token id="13" string="Brown" />
          </tokens>
        </entity>
        <entity id="2" string="an hour" type="DURATION" score="0.0">
          <tokens>
            <token id="21" string="an" />
            <token id="22" string="hour" />
          </tokens>
        </entity>
        <entity id="3" string="disease" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="18" string="disease" />
          </tokens>
        </entity>
        <entity id="4" string="680" type="NUMBER" score="0.0">
          <tokens>
            <token id="24" string="680" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="64" has_coreference="true">
      <content>He injected the ashy residue into animals&amp;apost; brains, expecting nothing to happen.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="injected" lemma="inject" stem="inject" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="ashy" lemma="ashy" stem="ashi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="residue" lemma="residue" stem="residu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="animals" lemma="animal" stem="anim" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="brains" lemma="brain" stem="brain" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="expecting" lemma="expect" stem="expect" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="nothing" lemma="nothing" stem="noth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="happen" lemma="happen" stem="happen" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VBD injected) (NP (DT the) (NN ashy) (NN residue)) (PP (IN into) (NP (NP (NNS animals) (POS ')) (NNS brains))) (, ,) (S (VP (VBG expecting) (NP (NN nothing)) (S (VP (TO to) (VP (VB happen))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="injected the ashy residue into animals ' brains , expecting nothing to happen" type="VP">
          <tokens>
            <token id="2" string="injected" />
            <token id="3" string="the" />
            <token id="4" string="ashy" />
            <token id="5" string="residue" />
            <token id="6" string="into" />
            <token id="7" string="animals" />
            <token id="8" string="'" />
            <token id="9" string="brains" />
            <token id="10" string="," />
            <token id="11" string="expecting" />
            <token id="12" string="nothing" />
            <token id="13" string="to" />
            <token id="14" string="happen" />
          </tokens>
        </chunking>
        <chunking id="2" string="happen" type="VP">
          <tokens>
            <token id="14" string="happen" />
          </tokens>
        </chunking>
        <chunking id="3" string="nothing" type="NP">
          <tokens>
            <token id="12" string="nothing" />
          </tokens>
        </chunking>
        <chunking id="4" string="animals ' brains" type="NP">
          <tokens>
            <token id="7" string="animals" />
            <token id="8" string="'" />
            <token id="9" string="brains" />
          </tokens>
        </chunking>
        <chunking id="5" string="to happen" type="VP">
          <tokens>
            <token id="13" string="to" />
            <token id="14" string="happen" />
          </tokens>
        </chunking>
        <chunking id="6" string="animals '" type="NP">
          <tokens>
            <token id="7" string="animals" />
            <token id="8" string="'" />
          </tokens>
        </chunking>
        <chunking id="7" string="expecting nothing to happen" type="VP">
          <tokens>
            <token id="11" string="expecting" />
            <token id="12" string="nothing" />
            <token id="13" string="to" />
            <token id="14" string="happen" />
          </tokens>
        </chunking>
        <chunking id="8" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="9" string="the ashy residue" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="ashy" />
            <token id="5" string="residue" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">injected</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">injected</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">residue</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">residue</governor>
          <dependent id="4">ashy</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">injected</governor>
          <dependent id="5">residue</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">brains</governor>
          <dependent id="6">into</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="9">brains</governor>
          <dependent id="7">animals</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">animals</governor>
          <dependent id="8">'</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">injected</governor>
          <dependent id="9">brains</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="2">injected</governor>
          <dependent id="11">expecting</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">expecting</governor>
          <dependent id="12">nothing</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">happen</governor>
          <dependent id="13">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="11">expecting</governor>
          <dependent id="14">happen</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="65" has_coreference="true">
      <content>But a few of them got spongiform disease.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="few" lemma="few" stem="few" pos="JJ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="6" string="got" lemma="get" stem="got" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="spongiform" lemma="spongiform" stem="spongiform" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="disease" lemma="disease" stem="diseas" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (NP (DT a) (JJ few)) (PP (IN of) (NP (PRP them)))) (VP (VBD got) (NP (JJ spongiform) (NN disease))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="spongiform disease" type="NP">
          <tokens>
            <token id="7" string="spongiform" />
            <token id="8" string="disease" />
          </tokens>
        </chunking>
        <chunking id="2" string="got spongiform disease" type="VP">
          <tokens>
            <token id="6" string="got" />
            <token id="7" string="spongiform" />
            <token id="8" string="disease" />
          </tokens>
        </chunking>
        <chunking id="3" string="them" type="NP">
          <tokens>
            <token id="5" string="them" />
          </tokens>
        </chunking>
        <chunking id="4" string="a few of them" type="NP">
          <tokens>
            <token id="2" string="a" />
            <token id="3" string="few" />
            <token id="4" string="of" />
            <token id="5" string="them" />
          </tokens>
        </chunking>
        <chunking id="5" string="a few" type="NP">
          <tokens>
            <token id="2" string="a" />
            <token id="3" string="few" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="6">got</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">few</governor>
          <dependent id="2">a</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">got</governor>
          <dependent id="3">few</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">them</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">few</governor>
          <dependent id="5">them</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">got</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">disease</governor>
          <dependent id="7">spongiform</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">got</governor>
          <dependent id="8">disease</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="disease" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="8" string="disease" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="66" has_coreference="true">
      <content>He also buried isolates in his garden for three years and found they remained infectious.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="buried" lemma="bury" stem="buri" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="isolates" lemma="isolate" stem="isol" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="garden" lemma="garden" stem="garden" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="three" lemma="three" stem="three" pos="CD" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="10" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="found" lemma="find" stem="found" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="remained" lemma="remain" stem="remain" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="infectious" lemma="infectious" stem="infecti" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (ADVP (RB also)) (VP (VP (VBD buried) (NP (NNS isolates)) (PP (IN in) (NP (NP (PRP$ his) (NN garden)) (PP (IN for) (NP (CD three) (NNS years)))))) (CC and) (VP (VBN found) (SBAR (S (NP (PRP they)) (VP (VBD remained) (NP (JJ infectious))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="infectious" type="NP">
          <tokens>
            <token id="15" string="infectious" />
          </tokens>
        </chunking>
        <chunking id="2" string="his garden for three years" type="NP">
          <tokens>
            <token id="6" string="his" />
            <token id="7" string="garden" />
            <token id="8" string="for" />
            <token id="9" string="three" />
            <token id="10" string="years" />
          </tokens>
        </chunking>
        <chunking id="3" string="they" type="NP">
          <tokens>
            <token id="13" string="they" />
          </tokens>
        </chunking>
        <chunking id="4" string="buried isolates in his garden for three years and found they remained infectious" type="VP">
          <tokens>
            <token id="3" string="buried" />
            <token id="4" string="isolates" />
            <token id="5" string="in" />
            <token id="6" string="his" />
            <token id="7" string="garden" />
            <token id="8" string="for" />
            <token id="9" string="three" />
            <token id="10" string="years" />
            <token id="11" string="and" />
            <token id="12" string="found" />
            <token id="13" string="they" />
            <token id="14" string="remained" />
            <token id="15" string="infectious" />
          </tokens>
        </chunking>
        <chunking id="5" string="three years" type="NP">
          <tokens>
            <token id="9" string="three" />
            <token id="10" string="years" />
          </tokens>
        </chunking>
        <chunking id="6" string="found they remained infectious" type="VP">
          <tokens>
            <token id="12" string="found" />
            <token id="13" string="they" />
            <token id="14" string="remained" />
            <token id="15" string="infectious" />
          </tokens>
        </chunking>
        <chunking id="7" string="isolates" type="NP">
          <tokens>
            <token id="4" string="isolates" />
          </tokens>
        </chunking>
        <chunking id="8" string="his garden" type="NP">
          <tokens>
            <token id="6" string="his" />
            <token id="7" string="garden" />
          </tokens>
        </chunking>
        <chunking id="9" string="buried isolates in his garden for three years" type="VP">
          <tokens>
            <token id="3" string="buried" />
            <token id="4" string="isolates" />
            <token id="5" string="in" />
            <token id="6" string="his" />
            <token id="7" string="garden" />
            <token id="8" string="for" />
            <token id="9" string="three" />
            <token id="10" string="years" />
          </tokens>
        </chunking>
        <chunking id="10" string="remained infectious" type="VP">
          <tokens>
            <token id="14" string="remained" />
            <token id="15" string="infectious" />
          </tokens>
        </chunking>
        <chunking id="11" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="12" string="they remained infectious" type="SBAR">
          <tokens>
            <token id="13" string="they" />
            <token id="14" string="remained" />
            <token id="15" string="infectious" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">buried</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">buried</governor>
          <dependent id="2">also</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">buried</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">buried</governor>
          <dependent id="4">isolates</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">garden</governor>
          <dependent id="5">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="7">garden</governor>
          <dependent id="6">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">buried</governor>
          <dependent id="7">garden</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">years</governor>
          <dependent id="8">for</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="10">years</governor>
          <dependent id="9">three</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">garden</governor>
          <dependent id="10">years</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">buried</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">buried</governor>
          <dependent id="12">found</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">remained</governor>
          <dependent id="13">they</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="12">found</governor>
          <dependent id="14">remained</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="14">remained</governor>
          <dependent id="15">infectious</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="three years" type="DURATION" score="0.0">
          <tokens>
            <token id="9" string="three" />
            <token id="10" string="years" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="67" has_coreference="true">
      <content>The results may be &amp;quot;very disquieting,&amp;quot; he says, to British farmers, who have been burning and burying mad cow corpses.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="results" lemma="result" stem="result" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="may" lemma="may" stem="mai" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="very" lemma="very" stem="veri" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="disquieting" lemma="disquieting" stem="disquiet" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="British" lemma="british" stem="british" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="15" string="farmers" lemma="farmer" stem="farmer" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="burning" lemma="burn" stem="burn" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="burying" lemma="bury" stem="buri" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="mad" lemma="mad" stem="mad" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="cow" lemma="cow" stem="cow" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="corpses" lemma="corpse" stem="corps" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (DT The) (NNS results)) (VP (MD may) (VP (VB be) (`` ``) (ADJP (RB very) (JJ disquieting))))) (, ,) ('' '') (NP (PRP he)) (VP (VBZ says) (, ,) (PP (TO to) (NP (NP (JJ British) (NNS farmers)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBP have) (VP (VBN been) (VP (VBG burning) (CC and) (VBG burying) (NP (JJ mad) (NN cow) (NNS corpses)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="British farmers , who have been burning and burying mad cow corpses" type="NP">
          <tokens>
            <token id="14" string="British" />
            <token id="15" string="farmers" />
            <token id="16" string="," />
            <token id="17" string="who" />
            <token id="18" string="have" />
            <token id="19" string="been" />
            <token id="20" string="burning" />
            <token id="21" string="and" />
            <token id="22" string="burying" />
            <token id="23" string="mad" />
            <token id="24" string="cow" />
            <token id="25" string="corpses" />
          </tokens>
        </chunking>
        <chunking id="2" string="burning and burying mad cow corpses" type="VP">
          <tokens>
            <token id="20" string="burning" />
            <token id="21" string="and" />
            <token id="22" string="burying" />
            <token id="23" string="mad" />
            <token id="24" string="cow" />
            <token id="25" string="corpses" />
          </tokens>
        </chunking>
        <chunking id="3" string="be `` very disquieting" type="VP">
          <tokens>
            <token id="4" string="be" />
            <token id="5" string="&quot;" />
            <token id="6" string="very" />
            <token id="7" string="disquieting" />
          </tokens>
        </chunking>
        <chunking id="4" string="very disquieting" type="ADJP">
          <tokens>
            <token id="6" string="very" />
            <token id="7" string="disquieting" />
          </tokens>
        </chunking>
        <chunking id="5" string="who have been burning and burying mad cow corpses" type="SBAR">
          <tokens>
            <token id="17" string="who" />
            <token id="18" string="have" />
            <token id="19" string="been" />
            <token id="20" string="burning" />
            <token id="21" string="and" />
            <token id="22" string="burying" />
            <token id="23" string="mad" />
            <token id="24" string="cow" />
            <token id="25" string="corpses" />
          </tokens>
        </chunking>
        <chunking id="6" string="mad cow corpses" type="NP">
          <tokens>
            <token id="23" string="mad" />
            <token id="24" string="cow" />
            <token id="25" string="corpses" />
          </tokens>
        </chunking>
        <chunking id="7" string="been burning and burying mad cow corpses" type="VP">
          <tokens>
            <token id="19" string="been" />
            <token id="20" string="burning" />
            <token id="21" string="and" />
            <token id="22" string="burying" />
            <token id="23" string="mad" />
            <token id="24" string="cow" />
            <token id="25" string="corpses" />
          </tokens>
        </chunking>
        <chunking id="8" string="The results" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="results" />
          </tokens>
        </chunking>
        <chunking id="9" string="British farmers" type="NP">
          <tokens>
            <token id="14" string="British" />
            <token id="15" string="farmers" />
          </tokens>
        </chunking>
        <chunking id="10" string="may be `` very disquieting" type="VP">
          <tokens>
            <token id="3" string="may" />
            <token id="4" string="be" />
            <token id="5" string="&quot;" />
            <token id="6" string="very" />
            <token id="7" string="disquieting" />
          </tokens>
        </chunking>
        <chunking id="11" string="he" type="NP">
          <tokens>
            <token id="10" string="he" />
          </tokens>
        </chunking>
        <chunking id="12" string="says , to British farmers , who have been burning and burying mad cow corpses" type="VP">
          <tokens>
            <token id="11" string="says" />
            <token id="12" string="," />
            <token id="13" string="to" />
            <token id="14" string="British" />
            <token id="15" string="farmers" />
            <token id="16" string="," />
            <token id="17" string="who" />
            <token id="18" string="have" />
            <token id="19" string="been" />
            <token id="20" string="burning" />
            <token id="21" string="and" />
            <token id="22" string="burying" />
            <token id="23" string="mad" />
            <token id="24" string="cow" />
            <token id="25" string="corpses" />
          </tokens>
        </chunking>
        <chunking id="13" string="have been burning and burying mad cow corpses" type="VP">
          <tokens>
            <token id="18" string="have" />
            <token id="19" string="been" />
            <token id="20" string="burning" />
            <token id="21" string="and" />
            <token id="22" string="burying" />
            <token id="23" string="mad" />
            <token id="24" string="cow" />
            <token id="25" string="corpses" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">results</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">disquieting</governor>
          <dependent id="2">results</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">disquieting</governor>
          <dependent id="3">may</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">disquieting</governor>
          <dependent id="4">be</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">disquieting</governor>
          <dependent id="6">very</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">says</governor>
          <dependent id="7">disquieting</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">says</governor>
          <dependent id="10">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">says</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">farmers</governor>
          <dependent id="13">to</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">farmers</governor>
          <dependent id="14">British</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">says</governor>
          <dependent id="15">farmers</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">burning</governor>
          <dependent id="17">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="20">burning</governor>
          <dependent id="18">have</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="20">burning</governor>
          <dependent id="19">been</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="15">farmers</governor>
          <dependent id="20">burning</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="20">burning</governor>
          <dependent id="21">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="20">burning</governor>
          <dependent id="22">burying</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">corpses</governor>
          <dependent id="23">mad</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">corpses</governor>
          <dependent id="24">cow</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">burning</governor>
          <dependent id="25">corpses</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="British" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="14" string="British" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="68" has_coreference="true">
      <content>Still, Dr. Brown and other scientists aren&amp;apost;t much worried about mad cows because their animal studies show spongiform disease is very hard to transmit orally.</content>
      <tokens>
        <token id="1" string="Still" lemma="still" stem="still" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Dr." lemma="Dr." stem="dr." pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="4" string="Brown" lemma="Brown" stem="brown" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="5" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="scientists" lemma="scientist" stem="scientist" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="much" lemma="much" stem="much" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="worried" lemma="worry" stem="worri" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="mad" lemma="mad" stem="mad" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="cows" lemma="cow" stem="cow" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="animal" lemma="animal" stem="anim" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="studies" lemma="study" stem="studi" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="show" lemma="show" stem="show" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="spongiform" lemma="spongiform" stem="spongiform" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="disease" lemma="disease" stem="diseas" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="22" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="very" lemma="very" stem="veri" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="hard" lemma="hard" stem="hard" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="transmit" lemma="transmit" stem="transmit" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="orally" lemma="orally" stem="oral" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Still)) (, ,) (NP (NP (NNP Dr.) (NNP Brown)) (CC and) (NP (JJ other) (NNS scientists))) (VP (VBP are) (RB n't) (ADJP (RB much) (VBN worried) (PP (IN about) (NP (JJ mad) (NNS cows))) (SBAR (IN because) (S (NP (PRP$ their) (NN animal) (NNS studies)) (VP (VBP show) (SBAR (S (NP (JJ spongiform) (NN disease)) (VP (VBZ is) (ADJP (RB very) (JJ hard)) (S (VP (TO to) (VP (VB transmit) (ADVP (RB orally))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="much worried about mad cows because their animal studies show spongiform disease is very hard to transmit orally" type="ADJP">
          <tokens>
            <token id="10" string="much" />
            <token id="11" string="worried" />
            <token id="12" string="about" />
            <token id="13" string="mad" />
            <token id="14" string="cows" />
            <token id="15" string="because" />
            <token id="16" string="their" />
            <token id="17" string="animal" />
            <token id="18" string="studies" />
            <token id="19" string="show" />
            <token id="20" string="spongiform" />
            <token id="21" string="disease" />
            <token id="22" string="is" />
            <token id="23" string="very" />
            <token id="24" string="hard" />
            <token id="25" string="to" />
            <token id="26" string="transmit" />
            <token id="27" string="orally" />
          </tokens>
        </chunking>
        <chunking id="2" string="is very hard to transmit orally" type="VP">
          <tokens>
            <token id="22" string="is" />
            <token id="23" string="very" />
            <token id="24" string="hard" />
            <token id="25" string="to" />
            <token id="26" string="transmit" />
            <token id="27" string="orally" />
          </tokens>
        </chunking>
        <chunking id="3" string="transmit orally" type="VP">
          <tokens>
            <token id="26" string="transmit" />
            <token id="27" string="orally" />
          </tokens>
        </chunking>
        <chunking id="4" string="very hard" type="ADJP">
          <tokens>
            <token id="23" string="very" />
            <token id="24" string="hard" />
          </tokens>
        </chunking>
        <chunking id="5" string="spongiform disease is very hard to transmit orally" type="SBAR">
          <tokens>
            <token id="20" string="spongiform" />
            <token id="21" string="disease" />
            <token id="22" string="is" />
            <token id="23" string="very" />
            <token id="24" string="hard" />
            <token id="25" string="to" />
            <token id="26" string="transmit" />
            <token id="27" string="orally" />
          </tokens>
        </chunking>
        <chunking id="6" string="mad cows" type="NP">
          <tokens>
            <token id="13" string="mad" />
            <token id="14" string="cows" />
          </tokens>
        </chunking>
        <chunking id="7" string="because their animal studies show spongiform disease is very hard to transmit orally" type="SBAR">
          <tokens>
            <token id="15" string="because" />
            <token id="16" string="their" />
            <token id="17" string="animal" />
            <token id="18" string="studies" />
            <token id="19" string="show" />
            <token id="20" string="spongiform" />
            <token id="21" string="disease" />
            <token id="22" string="is" />
            <token id="23" string="very" />
            <token id="24" string="hard" />
            <token id="25" string="to" />
            <token id="26" string="transmit" />
            <token id="27" string="orally" />
          </tokens>
        </chunking>
        <chunking id="8" string="Dr. Brown and other scientists" type="NP">
          <tokens>
            <token id="3" string="Dr." />
            <token id="4" string="Brown" />
            <token id="5" string="and" />
            <token id="6" string="other" />
            <token id="7" string="scientists" />
          </tokens>
        </chunking>
        <chunking id="9" string="to transmit orally" type="VP">
          <tokens>
            <token id="25" string="to" />
            <token id="26" string="transmit" />
            <token id="27" string="orally" />
          </tokens>
        </chunking>
        <chunking id="10" string="Dr. Brown" type="NP">
          <tokens>
            <token id="3" string="Dr." />
            <token id="4" string="Brown" />
          </tokens>
        </chunking>
        <chunking id="11" string="are n't much worried about mad cows because their animal studies show spongiform disease is very hard to transmit orally" type="VP">
          <tokens>
            <token id="8" string="are" />
            <token id="9" string="n't" />
            <token id="10" string="much" />
            <token id="11" string="worried" />
            <token id="12" string="about" />
            <token id="13" string="mad" />
            <token id="14" string="cows" />
            <token id="15" string="because" />
            <token id="16" string="their" />
            <token id="17" string="animal" />
            <token id="18" string="studies" />
            <token id="19" string="show" />
            <token id="20" string="spongiform" />
            <token id="21" string="disease" />
            <token id="22" string="is" />
            <token id="23" string="very" />
            <token id="24" string="hard" />
            <token id="25" string="to" />
            <token id="26" string="transmit" />
            <token id="27" string="orally" />
          </tokens>
        </chunking>
        <chunking id="12" string="spongiform disease" type="NP">
          <tokens>
            <token id="20" string="spongiform" />
            <token id="21" string="disease" />
          </tokens>
        </chunking>
        <chunking id="13" string="their animal studies" type="NP">
          <tokens>
            <token id="16" string="their" />
            <token id="17" string="animal" />
            <token id="18" string="studies" />
          </tokens>
        </chunking>
        <chunking id="14" string="show spongiform disease is very hard to transmit orally" type="VP">
          <tokens>
            <token id="19" string="show" />
            <token id="20" string="spongiform" />
            <token id="21" string="disease" />
            <token id="22" string="is" />
            <token id="23" string="very" />
            <token id="24" string="hard" />
            <token id="25" string="to" />
            <token id="26" string="transmit" />
            <token id="27" string="orally" />
          </tokens>
        </chunking>
        <chunking id="15" string="other scientists" type="NP">
          <tokens>
            <token id="6" string="other" />
            <token id="7" string="scientists" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="11">worried</governor>
          <dependent id="1">Still</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">Brown</governor>
          <dependent id="3">Dr.</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="11">worried</governor>
          <dependent id="4">Brown</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">Brown</governor>
          <dependent id="5">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">scientists</governor>
          <dependent id="6">other</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">Brown</governor>
          <dependent id="7">scientists</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="11">worried</governor>
          <dependent id="8">are</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="11">worried</governor>
          <dependent id="9">n't</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">worried</governor>
          <dependent id="10">much</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">worried</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">cows</governor>
          <dependent id="12">about</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">cows</governor>
          <dependent id="13">mad</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">worried</governor>
          <dependent id="14">cows</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">show</governor>
          <dependent id="15">because</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="18">studies</governor>
          <dependent id="16">their</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">studies</governor>
          <dependent id="17">animal</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">show</governor>
          <dependent id="18">studies</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">worried</governor>
          <dependent id="19">show</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">disease</governor>
          <dependent id="20">spongiform</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">hard</governor>
          <dependent id="21">disease</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="24">hard</governor>
          <dependent id="22">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="24">hard</governor>
          <dependent id="23">very</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="19">show</governor>
          <dependent id="24">hard</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="26">transmit</governor>
          <dependent id="25">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="24">hard</governor>
          <dependent id="26">transmit</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="26">transmit</governor>
          <dependent id="27">orally</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Brown" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Brown" />
          </tokens>
        </entity>
        <entity id="2" string="disease" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="21" string="disease" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="69" has_coreference="true">
      <content>Eating huge doses of the agent is required.</content>
      <tokens>
        <token id="1" string="Eating" lemma="Eating" stem="eate" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="huge" lemma="huge" stem="huge" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="doses" lemma="dose" stem="dose" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="agent" lemma="agent" stem="agent" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="required" lemma="require" stem="requir" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Eating) (JJ huge) (NNS doses)) (PP (IN of) (NP (DT the) (NN agent)))) (VP (VBZ is) (VP (VBN required))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Eating huge doses of the agent" type="NP">
          <tokens>
            <token id="1" string="Eating" />
            <token id="2" string="huge" />
            <token id="3" string="doses" />
            <token id="4" string="of" />
            <token id="5" string="the" />
            <token id="6" string="agent" />
          </tokens>
        </chunking>
        <chunking id="2" string="the agent" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="agent" />
          </tokens>
        </chunking>
        <chunking id="3" string="is required" type="VP">
          <tokens>
            <token id="7" string="is" />
            <token id="8" string="required" />
          </tokens>
        </chunking>
        <chunking id="4" string="Eating huge doses" type="NP">
          <tokens>
            <token id="1" string="Eating" />
            <token id="2" string="huge" />
            <token id="3" string="doses" />
          </tokens>
        </chunking>
        <chunking id="5" string="required" type="VP">
          <tokens>
            <token id="8" string="required" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">doses</governor>
          <dependent id="1">Eating</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">doses</governor>
          <dependent id="2">huge</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="8">required</governor>
          <dependent id="3">doses</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">agent</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">agent</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">doses</governor>
          <dependent id="6">agent</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="8">required</governor>
          <dependent id="7">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">required</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="70" has_coreference="true">
      <content>Perhaps the mad cows got such doses &amp;quot;every time they went to the feedbag,&amp;quot; says Dr. Brown.</content>
      <tokens>
        <token id="1" string="Perhaps" lemma="perhaps" stem="perhap" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="mad" lemma="mad" stem="mad" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="cows" lemma="cow" stem="cow" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="got" lemma="get" stem="got" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="such" lemma="such" stem="such" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="doses" lemma="dose" stem="dose" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="every" lemma="every" stem="everi" pos="DT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="went" lemma="go" stem="went" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="feedbag" lemma="feedbag" stem="feedbag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="Dr." lemma="Dr." stem="dr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="Brown" lemma="Brown" stem="brown" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (S (ADVP (RB Perhaps)) (NP (DT the) (JJ mad) (NNS cows)) (VP (VBD got) (NP (NP (JJ such) (NNS doses)) (`` ``) (NP (NP (DT every) (NN time)) (SBAR (S (NP (PRP they)) (VP (VBD went) (PP (TO to) (NP (DT the) (NN feedbag)))))))))) (, ,) ('' '') (VP (VBZ says)) (NP (NNP Dr.) (NNP Brown)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="such doses `` every time they went to the feedbag" type="NP">
          <tokens>
            <token id="6" string="such" />
            <token id="7" string="doses" />
            <token id="8" string="&quot;" />
            <token id="9" string="every" />
            <token id="10" string="time" />
            <token id="11" string="they" />
            <token id="12" string="went" />
            <token id="13" string="to" />
            <token id="14" string="the" />
            <token id="15" string="feedbag" />
          </tokens>
        </chunking>
        <chunking id="2" string="they" type="NP">
          <tokens>
            <token id="11" string="they" />
          </tokens>
        </chunking>
        <chunking id="3" string="Dr. Brown" type="NP">
          <tokens>
            <token id="19" string="Dr." />
            <token id="20" string="Brown" />
          </tokens>
        </chunking>
        <chunking id="4" string="every time they went to the feedbag" type="NP">
          <tokens>
            <token id="9" string="every" />
            <token id="10" string="time" />
            <token id="11" string="they" />
            <token id="12" string="went" />
            <token id="13" string="to" />
            <token id="14" string="the" />
            <token id="15" string="feedbag" />
          </tokens>
        </chunking>
        <chunking id="5" string="says" type="VP">
          <tokens>
            <token id="18" string="says" />
          </tokens>
        </chunking>
        <chunking id="6" string="got such doses `` every time they went to the feedbag" type="VP">
          <tokens>
            <token id="5" string="got" />
            <token id="6" string="such" />
            <token id="7" string="doses" />
            <token id="8" string="&quot;" />
            <token id="9" string="every" />
            <token id="10" string="time" />
            <token id="11" string="they" />
            <token id="12" string="went" />
            <token id="13" string="to" />
            <token id="14" string="the" />
            <token id="15" string="feedbag" />
          </tokens>
        </chunking>
        <chunking id="7" string="every time" type="NP">
          <tokens>
            <token id="9" string="every" />
            <token id="10" string="time" />
          </tokens>
        </chunking>
        <chunking id="8" string="they went to the feedbag" type="SBAR">
          <tokens>
            <token id="11" string="they" />
            <token id="12" string="went" />
            <token id="13" string="to" />
            <token id="14" string="the" />
            <token id="15" string="feedbag" />
          </tokens>
        </chunking>
        <chunking id="9" string="the feedbag" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="feedbag" />
          </tokens>
        </chunking>
        <chunking id="10" string="the mad cows" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="mad" />
            <token id="4" string="cows" />
          </tokens>
        </chunking>
        <chunking id="11" string="went to the feedbag" type="VP">
          <tokens>
            <token id="12" string="went" />
            <token id="13" string="to" />
            <token id="14" string="the" />
            <token id="15" string="feedbag" />
          </tokens>
        </chunking>
        <chunking id="12" string="such doses" type="NP">
          <tokens>
            <token id="6" string="such" />
            <token id="7" string="doses" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="5">got</governor>
          <dependent id="1">Perhaps</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">cows</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">cows</governor>
          <dependent id="3">mad</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">got</governor>
          <dependent id="4">cows</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="18">says</governor>
          <dependent id="5">got</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">doses</governor>
          <dependent id="6">such</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">got</governor>
          <dependent id="7">doses</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">time</governor>
          <dependent id="9">every</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="7">doses</governor>
          <dependent id="10">time</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">went</governor>
          <dependent id="11">they</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="10">time</governor>
          <dependent id="12">went</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">feedbag</governor>
          <dependent id="13">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">feedbag</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">went</governor>
          <dependent id="15">feedbag</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="18">says</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">Brown</governor>
          <dependent id="19">Dr.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">says</governor>
          <dependent id="20">Brown</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Brown" type="PERSON" score="0.0">
          <tokens>
            <token id="20" string="Brown" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="71" has_coreference="true">
      <content>Kuru victims apparently consumed similar mega-doses.</content>
      <tokens>
        <token id="1" string="Kuru" lemma="Kuru" stem="kuru" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="2" string="victims" lemma="victim" stem="victim" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="apparently" lemma="apparently" stem="appar" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="consumed" lemma="consume" stem="consum" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="similar" lemma="similar" stem="similar" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="mega-doses" lemma="mega-dose" stem="mega-dos" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Kuru) (NNS victims)) (ADVP (RB apparently)) (VP (VBN consumed) (NP (JJ similar) (NNS mega-doses))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Kuru victims" type="NP">
          <tokens>
            <token id="1" string="Kuru" />
            <token id="2" string="victims" />
          </tokens>
        </chunking>
        <chunking id="2" string="consumed similar mega-doses" type="VP">
          <tokens>
            <token id="4" string="consumed" />
            <token id="5" string="similar" />
            <token id="6" string="mega-doses" />
          </tokens>
        </chunking>
        <chunking id="3" string="similar mega-doses" type="NP">
          <tokens>
            <token id="5" string="similar" />
            <token id="6" string="mega-doses" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">victims</governor>
          <dependent id="1">Kuru</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">consumed</governor>
          <dependent id="2">victims</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">consumed</governor>
          <dependent id="3">apparently</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">consumed</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">mega-doses</governor>
          <dependent id="5">similar</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">consumed</governor>
          <dependent id="6">mega-doses</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="72" has_coreference="false">
      <content>And so may have Max.</content>
      <tokens>
        <token id="1" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="so" lemma="so" stem="so" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="may" lemma="may" stem="mai" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Max" lemma="Max" stem="max" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC And) (RB so) (VP (MD may) (VP (VB have) (NP (NNP Max)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Max" type="NP">
          <tokens>
            <token id="5" string="Max" />
          </tokens>
        </chunking>
        <chunking id="2" string="may have Max" type="VP">
          <tokens>
            <token id="3" string="may" />
            <token id="4" string="have" />
            <token id="5" string="Max" />
          </tokens>
        </chunking>
        <chunking id="3" string="have Max" type="VP">
          <tokens>
            <token id="4" string="have" />
            <token id="5" string="Max" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="4">have</governor>
          <dependent id="1">And</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">have</governor>
          <dependent id="2">so</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">have</governor>
          <dependent id="3">may</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">have</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">have</governor>
          <dependent id="5">Max</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Max" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Max" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="73" has_coreference="true">
      <content>He was a Siamese cat in Bristol, England, that died last spring.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="Siamese" lemma="Siamese" stem="siames" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="true" />
        <token id="5" string="cat" lemma="cat" stem="cat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="Bristol" lemma="Bristol" stem="bristol" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="England" lemma="England" stem="england" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="died" lemma="die" stem="di" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="14" string="spring" lemma="spring" stem="spring" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VBD was) (NP (NP (DT a) (NNP Siamese) (NN cat)) (PP (IN in) (NP (NP (NNP Bristol) (, ,) (NNP England)) (, ,) (SBAR (WHNP (IN that)) (S (VP (VBD died) (NP-TMP (JJ last) (NN spring))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Bristol , England" type="NP">
          <tokens>
            <token id="7" string="Bristol" />
            <token id="8" string="," />
            <token id="9" string="England" />
          </tokens>
        </chunking>
        <chunking id="2" string="a Siamese cat" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="Siamese" />
            <token id="5" string="cat" />
          </tokens>
        </chunking>
        <chunking id="3" string="Bristol , England , that died last spring" type="NP">
          <tokens>
            <token id="7" string="Bristol" />
            <token id="8" string="," />
            <token id="9" string="England" />
            <token id="10" string="," />
            <token id="11" string="that" />
            <token id="12" string="died" />
            <token id="13" string="last" />
            <token id="14" string="spring" />
          </tokens>
        </chunking>
        <chunking id="4" string="that died last spring" type="SBAR">
          <tokens>
            <token id="11" string="that" />
            <token id="12" string="died" />
            <token id="13" string="last" />
            <token id="14" string="spring" />
          </tokens>
        </chunking>
        <chunking id="5" string="a Siamese cat in Bristol , England , that died last spring" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="Siamese" />
            <token id="5" string="cat" />
            <token id="6" string="in" />
            <token id="7" string="Bristol" />
            <token id="8" string="," />
            <token id="9" string="England" />
            <token id="10" string="," />
            <token id="11" string="that" />
            <token id="12" string="died" />
            <token id="13" string="last" />
            <token id="14" string="spring" />
          </tokens>
        </chunking>
        <chunking id="6" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="7" string="died last spring" type="VP">
          <tokens>
            <token id="12" string="died" />
            <token id="13" string="last" />
            <token id="14" string="spring" />
          </tokens>
        </chunking>
        <chunking id="8" string="was a Siamese cat in Bristol , England , that died last spring" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="a" />
            <token id="4" string="Siamese" />
            <token id="5" string="cat" />
            <token id="6" string="in" />
            <token id="7" string="Bristol" />
            <token id="8" string="," />
            <token id="9" string="England" />
            <token id="10" string="," />
            <token id="11" string="that" />
            <token id="12" string="died" />
            <token id="13" string="last" />
            <token id="14" string="spring" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">cat</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">cat</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">cat</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">cat</governor>
          <dependent id="4">Siamese</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">cat</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">England</governor>
          <dependent id="6">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">England</governor>
          <dependent id="7">Bristol</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">cat</governor>
          <dependent id="9">England</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">died</governor>
          <dependent id="11">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="9">England</governor>
          <dependent id="12">died</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">spring</governor>
          <dependent id="13">last</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="12">died</governor>
          <dependent id="14">spring</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Bristol" type="LOCATION" score="0.0">
          <tokens>
            <token id="7" string="Bristol" />
          </tokens>
        </entity>
        <entity id="2" string="Siamese" type="MISC" score="0.0">
          <tokens>
            <token id="4" string="Siamese" />
          </tokens>
        </entity>
        <entity id="3" string="England" type="LOCATION" score="0.0">
          <tokens>
            <token id="9" string="England" />
          </tokens>
        </entity>
        <entity id="4" string="last spring" type="DATE" score="0.0">
          <tokens>
            <token id="13" string="last" />
            <token id="14" string="spring" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="74" has_coreference="true">
      <content>Examining his brain, a veterinarian found a telltale sponginess, sparking another round of panic in the U.K. about spongiform disease.</content>
      <tokens>
        <token id="1" string="Examining" lemma="examine" stem="examin" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="brain" lemma="brain" stem="brain" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="veterinarian" lemma="veterinarian" stem="veterinarian" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="found" lemma="find" stem="found" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="telltale" lemma="telltale" stem="telltal" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="sponginess" lemma="sponginess" stem="spongi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="sparking" lemma="spark" stem="spark" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="another" lemma="another" stem="anoth" pos="DT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="round" lemma="round" stem="round" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="panic" lemma="panic" stem="panic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="U.K." lemma="U.K." stem="u.k." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="20" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="spongiform" lemma="spongiform" stem="spongiform" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="disease" lemma="disease" stem="diseas" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (VBG Examining) (NP (PRP$ his) (NN brain)))) (, ,) (NP (DT a) (NN veterinarian)) (VP (VBD found) (NP (DT a) (JJ telltale) (NN sponginess)) (, ,) (S (VP (VBG sparking) (NP (NP (DT another) (NN round)) (PP (IN of) (NP (NP (NN panic)) (PP (IN in) (NP (DT the) (NNP U.K.)))))) (PP (IN about) (NP (JJ spongiform) (NN disease)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="found a telltale sponginess , sparking another round of panic in the U.K. about spongiform disease" type="VP">
          <tokens>
            <token id="7" string="found" />
            <token id="8" string="a" />
            <token id="9" string="telltale" />
            <token id="10" string="sponginess" />
            <token id="11" string="," />
            <token id="12" string="sparking" />
            <token id="13" string="another" />
            <token id="14" string="round" />
            <token id="15" string="of" />
            <token id="16" string="panic" />
            <token id="17" string="in" />
            <token id="18" string="the" />
            <token id="19" string="U.K." />
            <token id="20" string="about" />
            <token id="21" string="spongiform" />
            <token id="22" string="disease" />
          </tokens>
        </chunking>
        <chunking id="2" string="Examining his brain" type="VP">
          <tokens>
            <token id="1" string="Examining" />
            <token id="2" string="his" />
            <token id="3" string="brain" />
          </tokens>
        </chunking>
        <chunking id="3" string="a telltale sponginess" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="telltale" />
            <token id="10" string="sponginess" />
          </tokens>
        </chunking>
        <chunking id="4" string="spongiform disease" type="NP">
          <tokens>
            <token id="21" string="spongiform" />
            <token id="22" string="disease" />
          </tokens>
        </chunking>
        <chunking id="5" string="another round" type="NP">
          <tokens>
            <token id="13" string="another" />
            <token id="14" string="round" />
          </tokens>
        </chunking>
        <chunking id="6" string="his brain" type="NP">
          <tokens>
            <token id="2" string="his" />
            <token id="3" string="brain" />
          </tokens>
        </chunking>
        <chunking id="7" string="sparking another round of panic in the U.K. about spongiform disease" type="VP">
          <tokens>
            <token id="12" string="sparking" />
            <token id="13" string="another" />
            <token id="14" string="round" />
            <token id="15" string="of" />
            <token id="16" string="panic" />
            <token id="17" string="in" />
            <token id="18" string="the" />
            <token id="19" string="U.K." />
            <token id="20" string="about" />
            <token id="21" string="spongiform" />
            <token id="22" string="disease" />
          </tokens>
        </chunking>
        <chunking id="8" string="panic" type="NP">
          <tokens>
            <token id="16" string="panic" />
          </tokens>
        </chunking>
        <chunking id="9" string="the U.K." type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="U.K." />
          </tokens>
        </chunking>
        <chunking id="10" string="a veterinarian" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="veterinarian" />
          </tokens>
        </chunking>
        <chunking id="11" string="another round of panic in the U.K." type="NP">
          <tokens>
            <token id="13" string="another" />
            <token id="14" string="round" />
            <token id="15" string="of" />
            <token id="16" string="panic" />
            <token id="17" string="in" />
            <token id="18" string="the" />
            <token id="19" string="U.K." />
          </tokens>
        </chunking>
        <chunking id="12" string="panic in the U.K." type="NP">
          <tokens>
            <token id="16" string="panic" />
            <token id="17" string="in" />
            <token id="18" string="the" />
            <token id="19" string="U.K." />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advcl">
          <governor id="7">found</governor>
          <dependent id="1">Examining</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="3">brain</governor>
          <dependent id="2">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="1">Examining</governor>
          <dependent id="3">brain</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">veterinarian</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">found</governor>
          <dependent id="6">veterinarian</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">found</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">sponginess</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">sponginess</governor>
          <dependent id="9">telltale</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">found</governor>
          <dependent id="10">sponginess</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="7">found</governor>
          <dependent id="12">sparking</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">round</governor>
          <dependent id="13">another</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">sparking</governor>
          <dependent id="14">round</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">panic</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">round</governor>
          <dependent id="16">panic</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">U.K.</governor>
          <dependent id="17">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">U.K.</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">panic</governor>
          <dependent id="19">U.K.</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">disease</governor>
          <dependent id="20">about</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">disease</governor>
          <dependent id="21">spongiform</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">sparking</governor>
          <dependent id="22">disease</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="disease" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="22" string="disease" />
          </tokens>
        </entity>
        <entity id="2" string="U.K." type="LOCATION" score="0.0">
          <tokens>
            <token id="19" string="U.K." />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="75" has_coreference="true">
      <content>Now more than 10 British cats have died of it, suggesting brains from infected sheep or cows got into cat food.</content>
      <tokens>
        <token id="1" string="Now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="2" string="more" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="10" lemma="10" stem="10" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="5" string="British" lemma="british" stem="british" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="6" string="cats" lemma="cat" stem="cat" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="died" lemma="die" stem="di" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="suggesting" lemma="suggest" stem="suggest" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="brains" lemma="brain" stem="brain" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="infected" lemma="infected" stem="infect" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="sheep" lemma="sheep" stem="sheep" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="cows" lemma="cow" stem="cow" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="19" string="got" lemma="get" stem="got" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="cat" lemma="cat" stem="cat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="food" lemma="food" stem="food" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (ADVP (RB Now)) (NP (QP (JJR more) (IN than) (CD 10)) (JJ British) (NNS cats)) (VP (VBP have) (VP (VBN died) (PP (IN of) (NP (PRP it))) (, ,) (S (VP (VBG suggesting) (NP (NNS brains)) (PP (IN from) (NP (JJ infected) (NN sheep)))))))) (CC or) (S (NP (NNS cows)) (VP (VBD got) (PP (IN into) (NP (NN cat) (NN food))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="cat food" type="NP">
          <tokens>
            <token id="21" string="cat" />
            <token id="22" string="food" />
          </tokens>
        </chunking>
        <chunking id="2" string="brains" type="NP">
          <tokens>
            <token id="13" string="brains" />
          </tokens>
        </chunking>
        <chunking id="3" string="suggesting brains from infected sheep" type="VP">
          <tokens>
            <token id="12" string="suggesting" />
            <token id="13" string="brains" />
            <token id="14" string="from" />
            <token id="15" string="infected" />
            <token id="16" string="sheep" />
          </tokens>
        </chunking>
        <chunking id="4" string="infected sheep" type="NP">
          <tokens>
            <token id="15" string="infected" />
            <token id="16" string="sheep" />
          </tokens>
        </chunking>
        <chunking id="5" string="more than 10 British cats" type="NP">
          <tokens>
            <token id="2" string="more" />
            <token id="3" string="than" />
            <token id="4" string="10" />
            <token id="5" string="British" />
            <token id="6" string="cats" />
          </tokens>
        </chunking>
        <chunking id="6" string="cows" type="NP">
          <tokens>
            <token id="18" string="cows" />
          </tokens>
        </chunking>
        <chunking id="7" string="died of it , suggesting brains from infected sheep" type="VP">
          <tokens>
            <token id="8" string="died" />
            <token id="9" string="of" />
            <token id="10" string="it" />
            <token id="11" string="," />
            <token id="12" string="suggesting" />
            <token id="13" string="brains" />
            <token id="14" string="from" />
            <token id="15" string="infected" />
            <token id="16" string="sheep" />
          </tokens>
        </chunking>
        <chunking id="8" string="it" type="NP">
          <tokens>
            <token id="10" string="it" />
          </tokens>
        </chunking>
        <chunking id="9" string="have died of it , suggesting brains from infected sheep" type="VP">
          <tokens>
            <token id="7" string="have" />
            <token id="8" string="died" />
            <token id="9" string="of" />
            <token id="10" string="it" />
            <token id="11" string="," />
            <token id="12" string="suggesting" />
            <token id="13" string="brains" />
            <token id="14" string="from" />
            <token id="15" string="infected" />
            <token id="16" string="sheep" />
          </tokens>
        </chunking>
        <chunking id="10" string="got into cat food" type="VP">
          <tokens>
            <token id="19" string="got" />
            <token id="20" string="into" />
            <token id="21" string="cat" />
            <token id="22" string="food" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="8">died</governor>
          <dependent id="1">Now</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">10</governor>
          <dependent id="2">more</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="2">more</governor>
          <dependent id="3">than</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="6">cats</governor>
          <dependent id="4">10</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">cats</governor>
          <dependent id="5">British</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">died</governor>
          <dependent id="6">cats</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">died</governor>
          <dependent id="7">have</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">died</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">it</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">died</governor>
          <dependent id="10">it</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="8">died</governor>
          <dependent id="12">suggesting</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">suggesting</governor>
          <dependent id="13">brains</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">sheep</governor>
          <dependent id="14">from</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">sheep</governor>
          <dependent id="15">infected</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">suggesting</governor>
          <dependent id="16">sheep</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">died</governor>
          <dependent id="17">or</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">got</governor>
          <dependent id="18">cows</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">died</governor>
          <dependent id="19">got</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">food</governor>
          <dependent id="20">into</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">food</governor>
          <dependent id="21">cat</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">got</governor>
          <dependent id="22">food</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="British" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="5" string="British" />
          </tokens>
        </entity>
        <entity id="2" string="Now" type="DATE" score="0.0">
          <tokens>
            <token id="1" string="Now" />
          </tokens>
        </entity>
        <entity id="3" string="10" type="NUMBER" score="0.0">
          <tokens>
            <token id="4" string="10" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="76" has_coreference="false">
      <content>Meanwhile, yet another spongiform outbreak has occurred, this time among northeastern Pennsylvanians.</content>
      <tokens>
        <token id="1" string="Meanwhile" lemma="meanwhile" stem="meanwhil" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="yet" lemma="yet" stem="yet" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="another" lemma="another" stem="anoth" pos="DT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="spongiform" lemma="spongiform" stem="spongiform" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="outbreak" lemma="outbreak" stem="outbreak" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="occurred" lemma="occur" stem="occur" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="among" lemma="among" stem="among" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="northeastern" lemma="northeastern" stem="northeastern" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="Pennsylvanians" lemma="Pennsylvanians" stem="pennsylvanian" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Meanwhile)) (, ,) (NP (RB yet) (DT another) (JJ spongiform) (NN outbreak)) (VP (VP (VBZ has) (VP (VBN occurred))) (, ,) (NP (NP (DT this) (NN time)) (PP (IN among) (NP (JJ northeastern) (NNPS Pennsylvanians))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="yet another spongiform outbreak" type="NP">
          <tokens>
            <token id="3" string="yet" />
            <token id="4" string="another" />
            <token id="5" string="spongiform" />
            <token id="6" string="outbreak" />
          </tokens>
        </chunking>
        <chunking id="2" string="northeastern Pennsylvanians" type="NP">
          <tokens>
            <token id="13" string="northeastern" />
            <token id="14" string="Pennsylvanians" />
          </tokens>
        </chunking>
        <chunking id="3" string="occurred" type="VP">
          <tokens>
            <token id="8" string="occurred" />
          </tokens>
        </chunking>
        <chunking id="4" string="this time among northeastern Pennsylvanians" type="NP">
          <tokens>
            <token id="10" string="this" />
            <token id="11" string="time" />
            <token id="12" string="among" />
            <token id="13" string="northeastern" />
            <token id="14" string="Pennsylvanians" />
          </tokens>
        </chunking>
        <chunking id="5" string="has occurred" type="VP">
          <tokens>
            <token id="7" string="has" />
            <token id="8" string="occurred" />
          </tokens>
        </chunking>
        <chunking id="6" string="has occurred , this time among northeastern Pennsylvanians" type="VP">
          <tokens>
            <token id="7" string="has" />
            <token id="8" string="occurred" />
            <token id="9" string="," />
            <token id="10" string="this" />
            <token id="11" string="time" />
            <token id="12" string="among" />
            <token id="13" string="northeastern" />
            <token id="14" string="Pennsylvanians" />
          </tokens>
        </chunking>
        <chunking id="7" string="this time" type="NP">
          <tokens>
            <token id="10" string="this" />
            <token id="11" string="time" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="8">occurred</governor>
          <dependent id="1">Meanwhile</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">outbreak</governor>
          <dependent id="3">yet</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">outbreak</governor>
          <dependent id="4">another</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">outbreak</governor>
          <dependent id="5">spongiform</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">occurred</governor>
          <dependent id="6">outbreak</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">occurred</governor>
          <dependent id="7">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">occurred</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">time</governor>
          <dependent id="10">this</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">occurred</governor>
          <dependent id="11">time</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">Pennsylvanians</governor>
          <dependent id="12">among</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">Pennsylvanians</governor>
          <dependent id="13">northeastern</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">time</governor>
          <dependent id="14">Pennsylvanians</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Pennsylvanians" type="MISC" score="0.0">
          <tokens>
            <token id="14" string="Pennsylvanians" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="77" has_coreference="false">
      <content>The cluster of more than a dozen CJD cases &amp;quot;isn&amp;apost;t an epidemic&amp;quot; and appears to have topped out in 1989, says Brian Little, an Allentown neuropathologist leading a study of it.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="cluster" lemma="cluster" stem="cluster" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="more" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="dozen" lemma="dozen" stem="dozen" pos="NN" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="8" string="CJD" lemma="cjd" stem="cjd" pos="NN" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="9" string="cases" lemma="case" stem="case" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="epidemic" lemma="epidemic" stem="epidem" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="appears" lemma="appear" stem="appear" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="topped" lemma="top" stem="top" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="1989" lemma="1989" stem="1989" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="Brian" lemma="Brian" stem="brian" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="27" string="Little" lemma="Little" stem="littl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="28" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="Allentown" lemma="Allentown" stem="allentown" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="31" string="neuropathologist" lemma="neuropathologist" stem="neuropathologist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="leading" lemma="lead" stem="lead" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="study" lemma="study" stem="studi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (S (NP (NP (DT The) (NN cluster)) (PP (IN of) (NP (QP (JJR more) (IN than) (DT a) (NN dozen)) (NN CJD) (NNS cases)))) (`` ``) (VP (VP (VBZ is) (RB n't) (NP (DT an) (JJ epidemic))) ('' '') (CC and) (VP (VBZ appears) (S (VP (TO to) (VP (VB have) (VP (VBN topped) (PRT (RP out)) (PP (IN in) (NP (CD 1989)))))))))) (, ,) (VP (VBZ says)) (NP (NP (NNP Brian) (NNP Little)) (, ,) (NP (NP (DT an) (NNP Allentown) (NN neuropathologist)) (VP (VBG leading) (NP (NP (DT a) (NN study)) (PP (IN of) (NP (PRP it))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Brian Little" type="NP">
          <tokens>
            <token id="26" string="Brian" />
            <token id="27" string="Little" />
          </tokens>
        </chunking>
        <chunking id="2" string="is n't an epidemic" type="VP">
          <tokens>
            <token id="11" string="is" />
            <token id="12" string="n't" />
            <token id="13" string="an" />
            <token id="14" string="epidemic" />
          </tokens>
        </chunking>
        <chunking id="3" string="an epidemic" type="NP">
          <tokens>
            <token id="13" string="an" />
            <token id="14" string="epidemic" />
          </tokens>
        </chunking>
        <chunking id="4" string="it" type="NP">
          <tokens>
            <token id="36" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="The cluster" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="cluster" />
          </tokens>
        </chunking>
        <chunking id="6" string="a study" type="NP">
          <tokens>
            <token id="33" string="a" />
            <token id="34" string="study" />
          </tokens>
        </chunking>
        <chunking id="7" string="more than a dozen CJD cases" type="NP">
          <tokens>
            <token id="4" string="more" />
            <token id="5" string="than" />
            <token id="6" string="a" />
            <token id="7" string="dozen" />
            <token id="8" string="CJD" />
            <token id="9" string="cases" />
          </tokens>
        </chunking>
        <chunking id="8" string="have topped out in 1989" type="VP">
          <tokens>
            <token id="19" string="have" />
            <token id="20" string="topped" />
            <token id="21" string="out" />
            <token id="22" string="in" />
            <token id="23" string="1989" />
          </tokens>
        </chunking>
        <chunking id="9" string="a study of it" type="NP">
          <tokens>
            <token id="33" string="a" />
            <token id="34" string="study" />
            <token id="35" string="of" />
            <token id="36" string="it" />
          </tokens>
        </chunking>
        <chunking id="10" string="appears to have topped out in 1989" type="VP">
          <tokens>
            <token id="17" string="appears" />
            <token id="18" string="to" />
            <token id="19" string="have" />
            <token id="20" string="topped" />
            <token id="21" string="out" />
            <token id="22" string="in" />
            <token id="23" string="1989" />
          </tokens>
        </chunking>
        <chunking id="11" string="says" type="VP">
          <tokens>
            <token id="25" string="says" />
          </tokens>
        </chunking>
        <chunking id="12" string="to have topped out in 1989" type="VP">
          <tokens>
            <token id="18" string="to" />
            <token id="19" string="have" />
            <token id="20" string="topped" />
            <token id="21" string="out" />
            <token id="22" string="in" />
            <token id="23" string="1989" />
          </tokens>
        </chunking>
        <chunking id="13" string="an Allentown neuropathologist leading a study of it" type="NP">
          <tokens>
            <token id="29" string="an" />
            <token id="30" string="Allentown" />
            <token id="31" string="neuropathologist" />
            <token id="32" string="leading" />
            <token id="33" string="a" />
            <token id="34" string="study" />
            <token id="35" string="of" />
            <token id="36" string="it" />
          </tokens>
        </chunking>
        <chunking id="14" string="Brian Little , an Allentown neuropathologist leading a study of it" type="NP">
          <tokens>
            <token id="26" string="Brian" />
            <token id="27" string="Little" />
            <token id="28" string="," />
            <token id="29" string="an" />
            <token id="30" string="Allentown" />
            <token id="31" string="neuropathologist" />
            <token id="32" string="leading" />
            <token id="33" string="a" />
            <token id="34" string="study" />
            <token id="35" string="of" />
            <token id="36" string="it" />
          </tokens>
        </chunking>
        <chunking id="15" string="is n't an epidemic '' and appears to have topped out in 1989" type="VP">
          <tokens>
            <token id="11" string="is" />
            <token id="12" string="n't" />
            <token id="13" string="an" />
            <token id="14" string="epidemic" />
            <token id="15" string="&quot;" />
            <token id="16" string="and" />
            <token id="17" string="appears" />
            <token id="18" string="to" />
            <token id="19" string="have" />
            <token id="20" string="topped" />
            <token id="21" string="out" />
            <token id="22" string="in" />
            <token id="23" string="1989" />
          </tokens>
        </chunking>
        <chunking id="16" string="leading a study of it" type="VP">
          <tokens>
            <token id="32" string="leading" />
            <token id="33" string="a" />
            <token id="34" string="study" />
            <token id="35" string="of" />
            <token id="36" string="it" />
          </tokens>
        </chunking>
        <chunking id="17" string="an Allentown neuropathologist" type="NP">
          <tokens>
            <token id="29" string="an" />
            <token id="30" string="Allentown" />
            <token id="31" string="neuropathologist" />
          </tokens>
        </chunking>
        <chunking id="18" string="The cluster of more than a dozen CJD cases" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="cluster" />
            <token id="3" string="of" />
            <token id="4" string="more" />
            <token id="5" string="than" />
            <token id="6" string="a" />
            <token id="7" string="dozen" />
            <token id="8" string="CJD" />
            <token id="9" string="cases" />
          </tokens>
        </chunking>
        <chunking id="19" string="topped out in 1989" type="VP">
          <tokens>
            <token id="20" string="topped" />
            <token id="21" string="out" />
            <token id="22" string="in" />
            <token id="23" string="1989" />
          </tokens>
        </chunking>
        <chunking id="20" string="1989" type="NP">
          <tokens>
            <token id="23" string="1989" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">cluster</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">epidemic</governor>
          <dependent id="2">cluster</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">cases</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">dozen</governor>
          <dependent id="4">more</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="4">more</governor>
          <dependent id="5">than</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">dozen</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="9">cases</governor>
          <dependent id="7">dozen</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">cases</governor>
          <dependent id="8">CJD</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">cluster</governor>
          <dependent id="9">cases</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="14">epidemic</governor>
          <dependent id="11">is</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="14">epidemic</governor>
          <dependent id="12">n't</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">epidemic</governor>
          <dependent id="13">an</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="25">says</governor>
          <dependent id="14">epidemic</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="14">epidemic</governor>
          <dependent id="16">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">epidemic</governor>
          <dependent id="17">appears</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="20">topped</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="20">topped</governor>
          <dependent id="19">have</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="17">appears</governor>
          <dependent id="20">topped</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="20">topped</governor>
          <dependent id="21">out</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">1989</governor>
          <dependent id="22">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">topped</governor>
          <dependent id="23">1989</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="25">says</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">Little</governor>
          <dependent id="26">Brian</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">says</governor>
          <dependent id="27">Little</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">neuropathologist</governor>
          <dependent id="29">an</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">neuropathologist</governor>
          <dependent id="30">Allentown</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="27">Little</governor>
          <dependent id="31">neuropathologist</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="31">neuropathologist</governor>
          <dependent id="32">leading</dependent>
        </dependency>
        <dependency type="det">
          <governor id="34">study</governor>
          <dependent id="33">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="32">leading</governor>
          <dependent id="34">study</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">it</governor>
          <dependent id="35">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="34">study</governor>
          <dependent id="36">it</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="dozen" type="NUMBER" score="0.0">
          <tokens>
            <token id="7" string="dozen" />
          </tokens>
        </entity>
        <entity id="2" string="Allentown" type="LOCATION" score="0.0">
          <tokens>
            <token id="30" string="Allentown" />
          </tokens>
        </entity>
        <entity id="3" string="Brian Little" type="PERSON" score="0.0">
          <tokens>
            <token id="26" string="Brian" />
            <token id="27" string="Little" />
          </tokens>
        </entity>
        <entity id="4" string="CJD" type="MISC" score="0.0">
          <tokens>
            <token id="8" string="CJD" />
          </tokens>
        </entity>
        <entity id="5" string="1989" type="DATE" score="0.0">
          <tokens>
            <token id="23" string="1989" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="78" has_coreference="false">
      <content>But it is worrisome because, like the Slovakian outbreak, it suggests a common underlying cause that could strike again.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="worrisome" lemma="worrisome" stem="worrisom" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="Slovakian" lemma="slovakian" stem="slovakian" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="true" is_refers="false" />
        <token id="10" string="outbreak" lemma="outbreak" stem="outbreak" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="suggests" lemma="suggest" stem="suggest" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="common" lemma="common" stem="common" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="underlying" lemma="underlie" stem="underli" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="cause" lemma="cause" stem="caus" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="strike" lemma="strike" stem="strike" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="again" lemma="again" stem="again" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (PRP it)) (VP (VBZ is) (ADJP (JJ worrisome)) (SBAR (IN because) (S (, ,) (PP (IN like) (NP (DT the) (JJ Slovakian) (NN outbreak))) (, ,) (NP (PRP it)) (VP (VBZ suggests) (NP (NP (DT a) (JJ common) (VBG underlying) (NN cause)) (SBAR (WHNP (WDT that)) (S (VP (MD could) (VP (VB strike) (ADVP (RB again))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="suggests a common underlying cause that could strike again" type="VP">
          <tokens>
            <token id="13" string="suggests" />
            <token id="14" string="a" />
            <token id="15" string="common" />
            <token id="16" string="underlying" />
            <token id="17" string="cause" />
            <token id="18" string="that" />
            <token id="19" string="could" />
            <token id="20" string="strike" />
            <token id="21" string="again" />
          </tokens>
        </chunking>
        <chunking id="2" string="because , like the Slovakian outbreak , it suggests a common underlying cause that could strike again" type="SBAR">
          <tokens>
            <token id="5" string="because" />
            <token id="6" string="," />
            <token id="7" string="like" />
            <token id="8" string="the" />
            <token id="9" string="Slovakian" />
            <token id="10" string="outbreak" />
            <token id="11" string="," />
            <token id="12" string="it" />
            <token id="13" string="suggests" />
            <token id="14" string="a" />
            <token id="15" string="common" />
            <token id="16" string="underlying" />
            <token id="17" string="cause" />
            <token id="18" string="that" />
            <token id="19" string="could" />
            <token id="20" string="strike" />
            <token id="21" string="again" />
          </tokens>
        </chunking>
        <chunking id="3" string="the Slovakian outbreak" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="Slovakian" />
            <token id="10" string="outbreak" />
          </tokens>
        </chunking>
        <chunking id="4" string="is worrisome because , like the Slovakian outbreak , it suggests a common underlying cause that could strike again" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="worrisome" />
            <token id="5" string="because" />
            <token id="6" string="," />
            <token id="7" string="like" />
            <token id="8" string="the" />
            <token id="9" string="Slovakian" />
            <token id="10" string="outbreak" />
            <token id="11" string="," />
            <token id="12" string="it" />
            <token id="13" string="suggests" />
            <token id="14" string="a" />
            <token id="15" string="common" />
            <token id="16" string="underlying" />
            <token id="17" string="cause" />
            <token id="18" string="that" />
            <token id="19" string="could" />
            <token id="20" string="strike" />
            <token id="21" string="again" />
          </tokens>
        </chunking>
        <chunking id="5" string="that could strike again" type="SBAR">
          <tokens>
            <token id="18" string="that" />
            <token id="19" string="could" />
            <token id="20" string="strike" />
            <token id="21" string="again" />
          </tokens>
        </chunking>
        <chunking id="6" string="a common underlying cause that could strike again" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="common" />
            <token id="16" string="underlying" />
            <token id="17" string="cause" />
            <token id="18" string="that" />
            <token id="19" string="could" />
            <token id="20" string="strike" />
            <token id="21" string="again" />
          </tokens>
        </chunking>
        <chunking id="7" string="strike again" type="VP">
          <tokens>
            <token id="20" string="strike" />
            <token id="21" string="again" />
          </tokens>
        </chunking>
        <chunking id="8" string="it" type="NP">
          <tokens>
            <token id="2" string="it" />
          </tokens>
        </chunking>
        <chunking id="9" string="worrisome" type="ADJP">
          <tokens>
            <token id="4" string="worrisome" />
          </tokens>
        </chunking>
        <chunking id="10" string="a common underlying cause" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="common" />
            <token id="16" string="underlying" />
            <token id="17" string="cause" />
          </tokens>
        </chunking>
        <chunking id="11" string="could strike again" type="VP">
          <tokens>
            <token id="19" string="could" />
            <token id="20" string="strike" />
            <token id="21" string="again" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="4">worrisome</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">worrisome</governor>
          <dependent id="2">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">worrisome</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">worrisome</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">suggests</governor>
          <dependent id="5">because</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">outbreak</governor>
          <dependent id="7">like</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">outbreak</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">outbreak</governor>
          <dependent id="9">Slovakian</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">suggests</governor>
          <dependent id="10">outbreak</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">suggests</governor>
          <dependent id="12">it</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">worrisome</governor>
          <dependent id="13">suggests</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">cause</governor>
          <dependent id="14">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">cause</governor>
          <dependent id="15">common</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">cause</governor>
          <dependent id="16">underlying</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">suggests</governor>
          <dependent id="17">cause</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">strike</governor>
          <dependent id="18">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="20">strike</governor>
          <dependent id="19">could</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="17">cause</governor>
          <dependent id="20">strike</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="20">strike</governor>
          <dependent id="21">again</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Slovakian" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="9" string="Slovakian" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="79" has_coreference="true">
      <content>During the past few months, the NIH team, working with Dr. Mitrova, has found a thread that for the first time may link many such CJD cases.</content>
      <tokens>
        <token id="1" string="During" lemma="during" stem="dure" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="3" string="past" lemma="past" stem="past" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="4" string="few" lemma="few" stem="few" pos="JJ" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="5" string="months" lemma="month" stem="month" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="NIH" lemma="NIH" stem="nih" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="9" string="team" lemma="team" stem="team" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="working" lemma="work" stem="work" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Dr." lemma="Dr." stem="dr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="Mitrova" lemma="Mitrova" stem="mitrova" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="found" lemma="find" stem="found" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="thread" lemma="thread" stem="thread" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="true" />
        <token id="24" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="may" lemma="may" stem="mai" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="link" lemma="link" stem="link" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="many" lemma="many" stem="mani" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="such" lemma="such" stem="such" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="CJD" lemma="cjd" stem="cjd" pos="NN" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="30" string="cases" lemma="case" stem="case" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN During) (NP (DT the) (JJ past) (JJ few) (NNS months))) (, ,) (NP (NP (DT the) (NNP NIH) (NN team)) (, ,) (VP (VBG working) (PP (IN with) (NP (NNP Dr.) (NNP Mitrova)))) (, ,)) (VP (VBZ has) (VP (VBN found) (NP (DT a) (NN thread)) (SBAR (IN that) (IN for) (S (NP (DT the) (JJ first) (NN time)) (VP (MD may) (VP (VB link) (NP (JJ many) (JJ such) (NN CJD) (NNS cases)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="has found a thread that for the first time may link many such CJD cases" type="VP">
          <tokens>
            <token id="16" string="has" />
            <token id="17" string="found" />
            <token id="18" string="a" />
            <token id="19" string="thread" />
            <token id="20" string="that" />
            <token id="21" string="for" />
            <token id="22" string="the" />
            <token id="23" string="first" />
            <token id="24" string="time" />
            <token id="25" string="may" />
            <token id="26" string="link" />
            <token id="27" string="many" />
            <token id="28" string="such" />
            <token id="29" string="CJD" />
            <token id="30" string="cases" />
          </tokens>
        </chunking>
        <chunking id="2" string="may link many such CJD cases" type="VP">
          <tokens>
            <token id="25" string="may" />
            <token id="26" string="link" />
            <token id="27" string="many" />
            <token id="28" string="such" />
            <token id="29" string="CJD" />
            <token id="30" string="cases" />
          </tokens>
        </chunking>
        <chunking id="3" string="the NIH team , working with Dr. Mitrova ," type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="NIH" />
            <token id="9" string="team" />
            <token id="10" string="," />
            <token id="11" string="working" />
            <token id="12" string="with" />
            <token id="13" string="Dr." />
            <token id="14" string="Mitrova" />
            <token id="15" string="," />
          </tokens>
        </chunking>
        <chunking id="4" string="that for the first time may link many such CJD cases" type="SBAR">
          <tokens>
            <token id="20" string="that" />
            <token id="21" string="for" />
            <token id="22" string="the" />
            <token id="23" string="first" />
            <token id="24" string="time" />
            <token id="25" string="may" />
            <token id="26" string="link" />
            <token id="27" string="many" />
            <token id="28" string="such" />
            <token id="29" string="CJD" />
            <token id="30" string="cases" />
          </tokens>
        </chunking>
        <chunking id="5" string="the past few months" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="past" />
            <token id="4" string="few" />
            <token id="5" string="months" />
          </tokens>
        </chunking>
        <chunking id="6" string="a thread" type="NP">
          <tokens>
            <token id="18" string="a" />
            <token id="19" string="thread" />
          </tokens>
        </chunking>
        <chunking id="7" string="the first time" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="first" />
            <token id="24" string="time" />
          </tokens>
        </chunking>
        <chunking id="8" string="working with Dr. Mitrova" type="VP">
          <tokens>
            <token id="11" string="working" />
            <token id="12" string="with" />
            <token id="13" string="Dr." />
            <token id="14" string="Mitrova" />
          </tokens>
        </chunking>
        <chunking id="9" string="Dr. Mitrova" type="NP">
          <tokens>
            <token id="13" string="Dr." />
            <token id="14" string="Mitrova" />
          </tokens>
        </chunking>
        <chunking id="10" string="found a thread that for the first time may link many such CJD cases" type="VP">
          <tokens>
            <token id="17" string="found" />
            <token id="18" string="a" />
            <token id="19" string="thread" />
            <token id="20" string="that" />
            <token id="21" string="for" />
            <token id="22" string="the" />
            <token id="23" string="first" />
            <token id="24" string="time" />
            <token id="25" string="may" />
            <token id="26" string="link" />
            <token id="27" string="many" />
            <token id="28" string="such" />
            <token id="29" string="CJD" />
            <token id="30" string="cases" />
          </tokens>
        </chunking>
        <chunking id="11" string="many such CJD cases" type="NP">
          <tokens>
            <token id="27" string="many" />
            <token id="28" string="such" />
            <token id="29" string="CJD" />
            <token id="30" string="cases" />
          </tokens>
        </chunking>
        <chunking id="12" string="the NIH team" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="NIH" />
            <token id="9" string="team" />
          </tokens>
        </chunking>
        <chunking id="13" string="link many such CJD cases" type="VP">
          <tokens>
            <token id="26" string="link" />
            <token id="27" string="many" />
            <token id="28" string="such" />
            <token id="29" string="CJD" />
            <token id="30" string="cases" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="5">months</governor>
          <dependent id="1">During</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">months</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">months</governor>
          <dependent id="3">past</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">months</governor>
          <dependent id="4">few</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">found</governor>
          <dependent id="5">months</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">team</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">team</governor>
          <dependent id="8">NIH</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">found</governor>
          <dependent id="9">team</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="9">team</governor>
          <dependent id="11">working</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">Mitrova</governor>
          <dependent id="12">with</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Mitrova</governor>
          <dependent id="13">Dr.</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">working</governor>
          <dependent id="14">Mitrova</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="17">found</governor>
          <dependent id="16">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="17">found</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">thread</governor>
          <dependent id="18">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">found</governor>
          <dependent id="19">thread</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="26">link</governor>
          <dependent id="20">that</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="26">link</governor>
          <dependent id="21">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">time</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">time</governor>
          <dependent id="23">first</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">link</governor>
          <dependent id="24">time</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="26">link</governor>
          <dependent id="25">may</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="17">found</governor>
          <dependent id="26">link</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="30">cases</governor>
          <dependent id="27">many</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="30">cases</governor>
          <dependent id="28">such</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="30">cases</governor>
          <dependent id="29">CJD</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="26">link</governor>
          <dependent id="30">cases</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="23" string="first" />
          </tokens>
        </entity>
        <entity id="2" string="Mitrova" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Mitrova" />
          </tokens>
        </entity>
        <entity id="3" string="NIH" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="8" string="NIH" />
          </tokens>
        </entity>
        <entity id="4" string="CJD" type="MISC" score="0.0">
          <tokens>
            <token id="29" string="CJD" />
          </tokens>
        </entity>
        <entity id="5" string="the past few months" type="DURATION" score="0.0">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="past" />
            <token id="4" string="few" />
            <token id="5" string="months" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="80" has_coreference="true">
      <content>The discovery began when the scientists ferreted out a genetic defect in two U.S. brothers who had died of CJD.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="discovery" lemma="discovery" stem="discoveri" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="began" lemma="begin" stem="began" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="scientists" lemma="scientist" stem="scientist" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="ferreted" lemma="ferret" stem="ferret" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="genetic" lemma="genetic" stem="genet" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="defect" lemma="defect" stem="defect" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="14" string="U.S." lemma="U.S." stem="u.s." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="15" string="brothers" lemma="brother" stem="brother" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="died" lemma="die" stem="di" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="CJD" lemma="CJD" stem="cjd" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN discovery)) (VP (VBD began) (SBAR (WHADVP (WRB when)) (S (NP (DT the) (NNS scientists)) (VP (VBD ferreted) (PRT (RP out)) (NP (NP (DT a) (JJ genetic) (NN defect)) (PP (IN in) (NP (CD two) (NNP U.S.) (NNS brothers))) (SBAR (WHNP (WP who)) (S (VP (VBD had) (VP (VBN died) (PP (IN of) (NP (NNP CJD)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="began when the scientists ferreted out a genetic defect in two U.S. brothers who had died of CJD" type="VP">
          <tokens>
            <token id="3" string="began" />
            <token id="4" string="when" />
            <token id="5" string="the" />
            <token id="6" string="scientists" />
            <token id="7" string="ferreted" />
            <token id="8" string="out" />
            <token id="9" string="a" />
            <token id="10" string="genetic" />
            <token id="11" string="defect" />
            <token id="12" string="in" />
            <token id="13" string="two" />
            <token id="14" string="U.S." />
            <token id="15" string="brothers" />
            <token id="16" string="who" />
            <token id="17" string="had" />
            <token id="18" string="died" />
            <token id="19" string="of" />
            <token id="20" string="CJD" />
          </tokens>
        </chunking>
        <chunking id="2" string="had died of CJD" type="VP">
          <tokens>
            <token id="17" string="had" />
            <token id="18" string="died" />
            <token id="19" string="of" />
            <token id="20" string="CJD" />
          </tokens>
        </chunking>
        <chunking id="3" string="when the scientists ferreted out a genetic defect in two U.S. brothers who had died of CJD" type="SBAR">
          <tokens>
            <token id="4" string="when" />
            <token id="5" string="the" />
            <token id="6" string="scientists" />
            <token id="7" string="ferreted" />
            <token id="8" string="out" />
            <token id="9" string="a" />
            <token id="10" string="genetic" />
            <token id="11" string="defect" />
            <token id="12" string="in" />
            <token id="13" string="two" />
            <token id="14" string="U.S." />
            <token id="15" string="brothers" />
            <token id="16" string="who" />
            <token id="17" string="had" />
            <token id="18" string="died" />
            <token id="19" string="of" />
            <token id="20" string="CJD" />
          </tokens>
        </chunking>
        <chunking id="4" string="two U.S. brothers" type="NP">
          <tokens>
            <token id="13" string="two" />
            <token id="14" string="U.S." />
            <token id="15" string="brothers" />
          </tokens>
        </chunking>
        <chunking id="5" string="a genetic defect in two U.S. brothers who had died of CJD" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="genetic" />
            <token id="11" string="defect" />
            <token id="12" string="in" />
            <token id="13" string="two" />
            <token id="14" string="U.S." />
            <token id="15" string="brothers" />
            <token id="16" string="who" />
            <token id="17" string="had" />
            <token id="18" string="died" />
            <token id="19" string="of" />
            <token id="20" string="CJD" />
          </tokens>
        </chunking>
        <chunking id="6" string="died of CJD" type="VP">
          <tokens>
            <token id="18" string="died" />
            <token id="19" string="of" />
            <token id="20" string="CJD" />
          </tokens>
        </chunking>
        <chunking id="7" string="who had died of CJD" type="SBAR">
          <tokens>
            <token id="16" string="who" />
            <token id="17" string="had" />
            <token id="18" string="died" />
            <token id="19" string="of" />
            <token id="20" string="CJD" />
          </tokens>
        </chunking>
        <chunking id="8" string="when" type="WHADVP">
          <tokens>
            <token id="4" string="when" />
          </tokens>
        </chunking>
        <chunking id="9" string="a genetic defect" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="genetic" />
            <token id="11" string="defect" />
          </tokens>
        </chunking>
        <chunking id="10" string="The discovery" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="discovery" />
          </tokens>
        </chunking>
        <chunking id="11" string="ferreted out a genetic defect in two U.S. brothers who had died of CJD" type="VP">
          <tokens>
            <token id="7" string="ferreted" />
            <token id="8" string="out" />
            <token id="9" string="a" />
            <token id="10" string="genetic" />
            <token id="11" string="defect" />
            <token id="12" string="in" />
            <token id="13" string="two" />
            <token id="14" string="U.S." />
            <token id="15" string="brothers" />
            <token id="16" string="who" />
            <token id="17" string="had" />
            <token id="18" string="died" />
            <token id="19" string="of" />
            <token id="20" string="CJD" />
          </tokens>
        </chunking>
        <chunking id="12" string="the scientists" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="scientists" />
          </tokens>
        </chunking>
        <chunking id="13" string="CJD" type="NP">
          <tokens>
            <token id="20" string="CJD" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">discovery</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">began</governor>
          <dependent id="2">discovery</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">began</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">ferreted</governor>
          <dependent id="4">when</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">scientists</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">ferreted</governor>
          <dependent id="6">scientists</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">began</governor>
          <dependent id="7">ferreted</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="7">ferreted</governor>
          <dependent id="8">out</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">defect</governor>
          <dependent id="9">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">defect</governor>
          <dependent id="10">genetic</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">ferreted</governor>
          <dependent id="11">defect</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">brothers</governor>
          <dependent id="12">in</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="15">brothers</governor>
          <dependent id="13">two</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">brothers</governor>
          <dependent id="14">U.S.</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">defect</governor>
          <dependent id="15">brothers</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">died</governor>
          <dependent id="16">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="18">died</governor>
          <dependent id="17">had</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="11">defect</governor>
          <dependent id="18">died</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">CJD</governor>
          <dependent id="19">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">died</governor>
          <dependent id="20">CJD</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="U.S." type="LOCATION" score="0.0">
          <tokens>
            <token id="14" string="U.S." />
          </tokens>
        </entity>
        <entity id="2" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="13" string="two" />
          </tokens>
        </entity>
        <entity id="3" string="CJD" type="MISC" score="0.0">
          <tokens>
            <token id="20" string="CJD" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="81" has_coreference="true">
      <content>In itself, that was nothing new.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="itself" lemma="itself" stem="itself" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="nothing" lemma="nothing" stem="noth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="new" lemma="new" stem="new" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (PRP itself))) (, ,) (NP (DT that)) (VP (VBD was) (ADJP (NN nothing) (JJ new))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="that" type="NP">
          <tokens>
            <token id="4" string="that" />
          </tokens>
        </chunking>
        <chunking id="2" string="itself" type="NP">
          <tokens>
            <token id="2" string="itself" />
          </tokens>
        </chunking>
        <chunking id="3" string="nothing new" type="ADJP">
          <tokens>
            <token id="6" string="nothing" />
            <token id="7" string="new" />
          </tokens>
        </chunking>
        <chunking id="4" string="was nothing new" type="VP">
          <tokens>
            <token id="5" string="was" />
            <token id="6" string="nothing" />
            <token id="7" string="new" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">itself</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">new</governor>
          <dependent id="2">itself</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">new</governor>
          <dependent id="4">that</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">new</governor>
          <dependent id="5">was</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="7">new</governor>
          <dependent id="6">nothing</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">new</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="82" has_coreference="true">
      <content>Scientists have long known that CJD runs in some families and therefore suspected a genetic problem.</content>
      <tokens>
        <token id="1" string="Scientists" lemma="scientist" stem="scientist" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="2" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="long" lemma="long" stem="long" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="known" lemma="know" stem="known" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="CJD" lemma="CJD" stem="cjd" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="7" string="runs" lemma="run" stem="run" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="families" lemma="family" stem="famili" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="therefore" lemma="therefore" stem="therefor" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="suspected" lemma="suspect" stem="suspect" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="genetic" lemma="genetic" stem="genet" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="problem" lemma="problem" stem="problem" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNS Scientists)) (VP (VBP have) (ADVP (RB long)) (VP (VP (VBN known) (SBAR (IN that) (S (NP (NNP CJD)) (VP (VBZ runs) (PP (IN in) (NP (DT some) (NNS families))))))) (CC and) (VP (ADVP (RB therefore)) (VBN suspected) (NP (DT a) (JJ genetic) (NN problem))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="known that CJD runs in some families and therefore suspected a genetic problem" type="VP">
          <tokens>
            <token id="4" string="known" />
            <token id="5" string="that" />
            <token id="6" string="CJD" />
            <token id="7" string="runs" />
            <token id="8" string="in" />
            <token id="9" string="some" />
            <token id="10" string="families" />
            <token id="11" string="and" />
            <token id="12" string="therefore" />
            <token id="13" string="suspected" />
            <token id="14" string="a" />
            <token id="15" string="genetic" />
            <token id="16" string="problem" />
          </tokens>
        </chunking>
        <chunking id="2" string="therefore suspected a genetic problem" type="VP">
          <tokens>
            <token id="12" string="therefore" />
            <token id="13" string="suspected" />
            <token id="14" string="a" />
            <token id="15" string="genetic" />
            <token id="16" string="problem" />
          </tokens>
        </chunking>
        <chunking id="3" string="some families" type="NP">
          <tokens>
            <token id="9" string="some" />
            <token id="10" string="families" />
          </tokens>
        </chunking>
        <chunking id="4" string="a genetic problem" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="genetic" />
            <token id="16" string="problem" />
          </tokens>
        </chunking>
        <chunking id="5" string="runs in some families" type="VP">
          <tokens>
            <token id="7" string="runs" />
            <token id="8" string="in" />
            <token id="9" string="some" />
            <token id="10" string="families" />
          </tokens>
        </chunking>
        <chunking id="6" string="Scientists" type="NP">
          <tokens>
            <token id="1" string="Scientists" />
          </tokens>
        </chunking>
        <chunking id="7" string="that CJD runs in some families" type="SBAR">
          <tokens>
            <token id="5" string="that" />
            <token id="6" string="CJD" />
            <token id="7" string="runs" />
            <token id="8" string="in" />
            <token id="9" string="some" />
            <token id="10" string="families" />
          </tokens>
        </chunking>
        <chunking id="8" string="known that CJD runs in some families" type="VP">
          <tokens>
            <token id="4" string="known" />
            <token id="5" string="that" />
            <token id="6" string="CJD" />
            <token id="7" string="runs" />
            <token id="8" string="in" />
            <token id="9" string="some" />
            <token id="10" string="families" />
          </tokens>
        </chunking>
        <chunking id="9" string="CJD" type="NP">
          <tokens>
            <token id="6" string="CJD" />
          </tokens>
        </chunking>
        <chunking id="10" string="have long known that CJD runs in some families and therefore suspected a genetic problem" type="VP">
          <tokens>
            <token id="2" string="have" />
            <token id="3" string="long" />
            <token id="4" string="known" />
            <token id="5" string="that" />
            <token id="6" string="CJD" />
            <token id="7" string="runs" />
            <token id="8" string="in" />
            <token id="9" string="some" />
            <token id="10" string="families" />
            <token id="11" string="and" />
            <token id="12" string="therefore" />
            <token id="13" string="suspected" />
            <token id="14" string="a" />
            <token id="15" string="genetic" />
            <token id="16" string="problem" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">known</governor>
          <dependent id="1">Scientists</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">known</governor>
          <dependent id="2">have</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">known</governor>
          <dependent id="3">long</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">known</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">runs</governor>
          <dependent id="5">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">runs</governor>
          <dependent id="6">CJD</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">known</governor>
          <dependent id="7">runs</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">families</governor>
          <dependent id="8">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">families</governor>
          <dependent id="9">some</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">runs</governor>
          <dependent id="10">families</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">known</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">suspected</governor>
          <dependent id="12">therefore</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">known</governor>
          <dependent id="13">suspected</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">problem</governor>
          <dependent id="14">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">problem</governor>
          <dependent id="15">genetic</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">suspected</governor>
          <dependent id="16">problem</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="CJD" type="MISC" score="0.0">
          <tokens>
            <token id="6" string="CJD" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="83" has_coreference="true">
      <content>But Dr. Brown&amp;apost;s excitement grew when three other, unrelated CJD victims were found to carry the same genetic defect.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Dr." lemma="Dr." stem="dr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="Brown" lemma="Brown" stem="brown" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="4" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="excitement" lemma="excitement" stem="excit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="grew" lemma="grow" stem="grew" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="three" lemma="three" stem="three" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="9" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="unrelated" lemma="unrelated" stem="unrel" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="CJD" lemma="cjd" stem="cjd" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="victims" lemma="victim" stem="victim" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="found" lemma="find" stem="found" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="carry" lemma="carry" stem="carri" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="same" lemma="same" stem="same" pos="JJ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="genetic" lemma="genetic" stem="genet" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="defect" lemma="defect" stem="defect" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (NP (NNP Dr.) (NNP Brown) (POS 's)) (NN excitement)) (VP (VBD grew) (SBAR (WHADVP (WRB when)) (S (NP (CD three) (ADJP (JJ other) (, ,) (JJ unrelated)) (NN CJD) (NNS victims)) (VP (VBD were) (VP (VBN found) (S (VP (TO to) (VP (VB carry) (NP (DT the) (JJ same) (JJ genetic) (NN defect)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Dr. Brown 's" type="NP">
          <tokens>
            <token id="2" string="Dr." />
            <token id="3" string="Brown" />
            <token id="4" string="'s" />
          </tokens>
        </chunking>
        <chunking id="2" string="were found to carry the same genetic defect" type="VP">
          <tokens>
            <token id="14" string="were" />
            <token id="15" string="found" />
            <token id="16" string="to" />
            <token id="17" string="carry" />
            <token id="18" string="the" />
            <token id="19" string="same" />
            <token id="20" string="genetic" />
            <token id="21" string="defect" />
          </tokens>
        </chunking>
        <chunking id="3" string="the same genetic defect" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="same" />
            <token id="20" string="genetic" />
            <token id="21" string="defect" />
          </tokens>
        </chunking>
        <chunking id="4" string="Dr. Brown 's excitement" type="NP">
          <tokens>
            <token id="2" string="Dr." />
            <token id="3" string="Brown" />
            <token id="4" string="'s" />
            <token id="5" string="excitement" />
          </tokens>
        </chunking>
        <chunking id="5" string="other , unrelated" type="ADJP">
          <tokens>
            <token id="9" string="other" />
            <token id="10" string="," />
            <token id="11" string="unrelated" />
          </tokens>
        </chunking>
        <chunking id="6" string="carry the same genetic defect" type="VP">
          <tokens>
            <token id="17" string="carry" />
            <token id="18" string="the" />
            <token id="19" string="same" />
            <token id="20" string="genetic" />
            <token id="21" string="defect" />
          </tokens>
        </chunking>
        <chunking id="7" string="grew when three other , unrelated CJD victims were found to carry the same genetic defect" type="VP">
          <tokens>
            <token id="6" string="grew" />
            <token id="7" string="when" />
            <token id="8" string="three" />
            <token id="9" string="other" />
            <token id="10" string="," />
            <token id="11" string="unrelated" />
            <token id="12" string="CJD" />
            <token id="13" string="victims" />
            <token id="14" string="were" />
            <token id="15" string="found" />
            <token id="16" string="to" />
            <token id="17" string="carry" />
            <token id="18" string="the" />
            <token id="19" string="same" />
            <token id="20" string="genetic" />
            <token id="21" string="defect" />
          </tokens>
        </chunking>
        <chunking id="8" string="found to carry the same genetic defect" type="VP">
          <tokens>
            <token id="15" string="found" />
            <token id="16" string="to" />
            <token id="17" string="carry" />
            <token id="18" string="the" />
            <token id="19" string="same" />
            <token id="20" string="genetic" />
            <token id="21" string="defect" />
          </tokens>
        </chunking>
        <chunking id="9" string="to carry the same genetic defect" type="VP">
          <tokens>
            <token id="16" string="to" />
            <token id="17" string="carry" />
            <token id="18" string="the" />
            <token id="19" string="same" />
            <token id="20" string="genetic" />
            <token id="21" string="defect" />
          </tokens>
        </chunking>
        <chunking id="10" string="when three other , unrelated CJD victims were found to carry the same genetic defect" type="SBAR">
          <tokens>
            <token id="7" string="when" />
            <token id="8" string="three" />
            <token id="9" string="other" />
            <token id="10" string="," />
            <token id="11" string="unrelated" />
            <token id="12" string="CJD" />
            <token id="13" string="victims" />
            <token id="14" string="were" />
            <token id="15" string="found" />
            <token id="16" string="to" />
            <token id="17" string="carry" />
            <token id="18" string="the" />
            <token id="19" string="same" />
            <token id="20" string="genetic" />
            <token id="21" string="defect" />
          </tokens>
        </chunking>
        <chunking id="11" string="when" type="WHADVP">
          <tokens>
            <token id="7" string="when" />
          </tokens>
        </chunking>
        <chunking id="12" string="three other , unrelated CJD victims" type="NP">
          <tokens>
            <token id="8" string="three" />
            <token id="9" string="other" />
            <token id="10" string="," />
            <token id="11" string="unrelated" />
            <token id="12" string="CJD" />
            <token id="13" string="victims" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="6">grew</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Brown</governor>
          <dependent id="2">Dr.</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">excitement</governor>
          <dependent id="3">Brown</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">Brown</governor>
          <dependent id="4">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">grew</governor>
          <dependent id="5">excitement</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">grew</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">found</governor>
          <dependent id="7">when</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="13">victims</governor>
          <dependent id="8">three</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">unrelated</governor>
          <dependent id="9">other</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">victims</governor>
          <dependent id="11">unrelated</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">victims</governor>
          <dependent id="12">CJD</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="15">found</governor>
          <dependent id="13">victims</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="15">found</governor>
          <dependent id="14">were</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="6">grew</governor>
          <dependent id="15">found</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">carry</governor>
          <dependent id="16">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="15">found</governor>
          <dependent id="17">carry</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">defect</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">defect</governor>
          <dependent id="19">same</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">defect</governor>
          <dependent id="20">genetic</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">carry</governor>
          <dependent id="21">defect</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Brown" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Brown" />
          </tokens>
        </entity>
        <entity id="2" string="three" type="NUMBER" score="0.0">
          <tokens>
            <token id="8" string="three" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="84" has_coreference="true">
      <content>&amp;quot;On a flyer,&amp;quot; he says, &amp;quot;I called relatives of the victims and struck gold.&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="On" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="flyer" lemma="flyer" stem="flyer" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="called" lemma="call" stem="call" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="relatives" lemma="relative" stem="rel" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="victims" lemma="victim" stem="victim" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="struck" lemma="strike" stem="struck" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="gold" lemma="gold" stem="gold" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (PP (IN On) (NP (DT a) (NN flyer))) (PRN (, ,) ('' '') (S (NP (PRP he)) (VP (VBZ says))) (, ,)) (`` ``) (NP (PRP I)) (VP (VP (VBD called) (NP (NP (NNS relatives)) (PP (IN of) (NP (DT the) (NNS victims))))) (CC and) (VP (VBD struck) (NP (NN gold)))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="says" type="VP">
          <tokens>
            <token id="8" string="says" />
          </tokens>
        </chunking>
        <chunking id="2" string="a flyer" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="flyer" />
          </tokens>
        </chunking>
        <chunking id="3" string="I" type="NP">
          <tokens>
            <token id="11" string="I" />
          </tokens>
        </chunking>
        <chunking id="4" string="called relatives of the victims" type="VP">
          <tokens>
            <token id="12" string="called" />
            <token id="13" string="relatives" />
            <token id="14" string="of" />
            <token id="15" string="the" />
            <token id="16" string="victims" />
          </tokens>
        </chunking>
        <chunking id="5" string="the victims" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="victims" />
          </tokens>
        </chunking>
        <chunking id="6" string="struck gold" type="VP">
          <tokens>
            <token id="18" string="struck" />
            <token id="19" string="gold" />
          </tokens>
        </chunking>
        <chunking id="7" string="he" type="NP">
          <tokens>
            <token id="7" string="he" />
          </tokens>
        </chunking>
        <chunking id="8" string="called relatives of the victims and struck gold" type="VP">
          <tokens>
            <token id="12" string="called" />
            <token id="13" string="relatives" />
            <token id="14" string="of" />
            <token id="15" string="the" />
            <token id="16" string="victims" />
            <token id="17" string="and" />
            <token id="18" string="struck" />
            <token id="19" string="gold" />
          </tokens>
        </chunking>
        <chunking id="9" string="relatives of the victims" type="NP">
          <tokens>
            <token id="13" string="relatives" />
            <token id="14" string="of" />
            <token id="15" string="the" />
            <token id="16" string="victims" />
          </tokens>
        </chunking>
        <chunking id="10" string="relatives" type="NP">
          <tokens>
            <token id="13" string="relatives" />
          </tokens>
        </chunking>
        <chunking id="11" string="gold" type="NP">
          <tokens>
            <token id="19" string="gold" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">flyer</governor>
          <dependent id="2">On</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">flyer</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">called</governor>
          <dependent id="4">flyer</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">says</governor>
          <dependent id="7">he</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="12">called</governor>
          <dependent id="8">says</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">called</governor>
          <dependent id="11">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">called</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">called</governor>
          <dependent id="13">relatives</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">victims</governor>
          <dependent id="14">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">victims</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">relatives</governor>
          <dependent id="16">victims</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="12">called</governor>
          <dependent id="17">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">called</governor>
          <dependent id="18">struck</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">struck</governor>
          <dependent id="19">gold</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="85" has_coreference="true">
      <content>They were all of Eastern European descent, suggesting people of similar ancestry might carry the gene.</content>
      <tokens>
        <token id="1" string="They" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Eastern" lemma="eastern" stem="eastern" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="6" string="European" lemma="european" stem="european" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="7" string="descent" lemma="descent" stem="descent" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="suggesting" lemma="suggest" stem="suggest" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="similar" lemma="similar" stem="similar" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="ancestry" lemma="ancestry" stem="ancestri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="might" lemma="might" stem="might" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="carry" lemma="carry" stem="carri" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="gene" lemma="gene" stem="gene" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP They)) (VP (VBD were) (NP (NP (DT all)) (PP (IN of) (NP (JJ Eastern) (JJ European) (NN descent)))) (, ,) (S (VP (VBG suggesting) (SBAR (S (NP (NP (NNS people)) (PP (IN of) (NP (JJ similar) (NN ancestry)))) (VP (MD might) (VP (VB carry) (NP (DT the) (NN gene))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="They" type="NP">
          <tokens>
            <token id="1" string="They" />
          </tokens>
        </chunking>
        <chunking id="2" string="all" type="NP">
          <tokens>
            <token id="3" string="all" />
          </tokens>
        </chunking>
        <chunking id="3" string="people of similar ancestry might carry the gene" type="SBAR">
          <tokens>
            <token id="10" string="people" />
            <token id="11" string="of" />
            <token id="12" string="similar" />
            <token id="13" string="ancestry" />
            <token id="14" string="might" />
            <token id="15" string="carry" />
            <token id="16" string="the" />
            <token id="17" string="gene" />
          </tokens>
        </chunking>
        <chunking id="4" string="were all of Eastern European descent , suggesting people of similar ancestry might carry the gene" type="VP">
          <tokens>
            <token id="2" string="were" />
            <token id="3" string="all" />
            <token id="4" string="of" />
            <token id="5" string="Eastern" />
            <token id="6" string="European" />
            <token id="7" string="descent" />
            <token id="8" string="," />
            <token id="9" string="suggesting" />
            <token id="10" string="people" />
            <token id="11" string="of" />
            <token id="12" string="similar" />
            <token id="13" string="ancestry" />
            <token id="14" string="might" />
            <token id="15" string="carry" />
            <token id="16" string="the" />
            <token id="17" string="gene" />
          </tokens>
        </chunking>
        <chunking id="5" string="suggesting people of similar ancestry might carry the gene" type="VP">
          <tokens>
            <token id="9" string="suggesting" />
            <token id="10" string="people" />
            <token id="11" string="of" />
            <token id="12" string="similar" />
            <token id="13" string="ancestry" />
            <token id="14" string="might" />
            <token id="15" string="carry" />
            <token id="16" string="the" />
            <token id="17" string="gene" />
          </tokens>
        </chunking>
        <chunking id="6" string="similar ancestry" type="NP">
          <tokens>
            <token id="12" string="similar" />
            <token id="13" string="ancestry" />
          </tokens>
        </chunking>
        <chunking id="7" string="Eastern European descent" type="NP">
          <tokens>
            <token id="5" string="Eastern" />
            <token id="6" string="European" />
            <token id="7" string="descent" />
          </tokens>
        </chunking>
        <chunking id="8" string="people" type="NP">
          <tokens>
            <token id="10" string="people" />
          </tokens>
        </chunking>
        <chunking id="9" string="might carry the gene" type="VP">
          <tokens>
            <token id="14" string="might" />
            <token id="15" string="carry" />
            <token id="16" string="the" />
            <token id="17" string="gene" />
          </tokens>
        </chunking>
        <chunking id="10" string="carry the gene" type="VP">
          <tokens>
            <token id="15" string="carry" />
            <token id="16" string="the" />
            <token id="17" string="gene" />
          </tokens>
        </chunking>
        <chunking id="11" string="people of similar ancestry" type="NP">
          <tokens>
            <token id="10" string="people" />
            <token id="11" string="of" />
            <token id="12" string="similar" />
            <token id="13" string="ancestry" />
          </tokens>
        </chunking>
        <chunking id="12" string="all of Eastern European descent" type="NP">
          <tokens>
            <token id="3" string="all" />
            <token id="4" string="of" />
            <token id="5" string="Eastern" />
            <token id="6" string="European" />
            <token id="7" string="descent" />
          </tokens>
        </chunking>
        <chunking id="13" string="the gene" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="gene" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">all</governor>
          <dependent id="1">They</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="3">all</governor>
          <dependent id="2">were</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">all</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">descent</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">descent</governor>
          <dependent id="5">Eastern</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">descent</governor>
          <dependent id="6">European</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">all</governor>
          <dependent id="7">descent</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">all</governor>
          <dependent id="9">suggesting</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">carry</governor>
          <dependent id="10">people</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">ancestry</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">ancestry</governor>
          <dependent id="12">similar</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">people</governor>
          <dependent id="13">ancestry</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="15">carry</governor>
          <dependent id="14">might</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="9">suggesting</governor>
          <dependent id="15">carry</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">gene</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">carry</governor>
          <dependent id="17">gene</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Eastern European" type="MISC" score="0.0">
          <tokens>
            <token id="5" string="Eastern" />
            <token id="6" string="European" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="86" has_coreference="true">
      <content>Drs. Brown and Gajdusek knew just where to look for such people.</content>
      <tokens>
        <token id="1" string="Drs." lemma="Drs." stem="drs." pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="Brown" lemma="Brown" stem="brown" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="3" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="Gajdusek" lemma="Gajdusek" stem="gajdusek" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="5" string="knew" lemma="know" stem="knew" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="where" lemma="where" stem="where" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="look" lemma="look" stem="look" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="such" lemma="such" stem="such" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Drs.) (NNP Brown) (CC and) (NNP Gajdusek)) (VP (VBD knew) (SBAR (RB just) (WHADVP (WRB where)) (S (VP (TO to) (VP (VB look) (PP (IN for) (NP (JJ such) (NNS people)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="look for such people" type="VP">
          <tokens>
            <token id="9" string="look" />
            <token id="10" string="for" />
            <token id="11" string="such" />
            <token id="12" string="people" />
          </tokens>
        </chunking>
        <chunking id="2" string="such people" type="NP">
          <tokens>
            <token id="11" string="such" />
            <token id="12" string="people" />
          </tokens>
        </chunking>
        <chunking id="3" string="just where to look for such people" type="SBAR">
          <tokens>
            <token id="6" string="just" />
            <token id="7" string="where" />
            <token id="8" string="to" />
            <token id="9" string="look" />
            <token id="10" string="for" />
            <token id="11" string="such" />
            <token id="12" string="people" />
          </tokens>
        </chunking>
        <chunking id="4" string="to look for such people" type="VP">
          <tokens>
            <token id="8" string="to" />
            <token id="9" string="look" />
            <token id="10" string="for" />
            <token id="11" string="such" />
            <token id="12" string="people" />
          </tokens>
        </chunking>
        <chunking id="5" string="Drs. Brown and Gajdusek" type="NP">
          <tokens>
            <token id="1" string="Drs." />
            <token id="2" string="Brown" />
            <token id="3" string="and" />
            <token id="4" string="Gajdusek" />
          </tokens>
        </chunking>
        <chunking id="6" string="knew just where to look for such people" type="VP">
          <tokens>
            <token id="5" string="knew" />
            <token id="6" string="just" />
            <token id="7" string="where" />
            <token id="8" string="to" />
            <token id="9" string="look" />
            <token id="10" string="for" />
            <token id="11" string="such" />
            <token id="12" string="people" />
          </tokens>
        </chunking>
        <chunking id="7" string="where" type="WHADVP">
          <tokens>
            <token id="7" string="where" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Brown</governor>
          <dependent id="1">Drs.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">knew</governor>
          <dependent id="2">Brown</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">Brown</governor>
          <dependent id="3">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">Brown</governor>
          <dependent id="4">Gajdusek</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">knew</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">look</governor>
          <dependent id="6">just</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">look</governor>
          <dependent id="7">where</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">look</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">knew</governor>
          <dependent id="9">look</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">people</governor>
          <dependent id="10">for</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">people</governor>
          <dependent id="11">such</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">look</governor>
          <dependent id="12">people</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Brown" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Brown" />
          </tokens>
        </entity>
        <entity id="2" string="Gajdusek" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Gajdusek" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="87" has_coreference="true">
      <content>They grabbed a plane for Czechoslovakia.</content>
      <tokens>
        <token id="1" string="They" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="grabbed" lemma="grab" stem="grab" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="plane" lemma="plane" stem="plane" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Czechoslovakia" lemma="Czechoslovakia" stem="czechoslovakia" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="7" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP They)) (VP (VBD grabbed) (NP (DT a) (NN plane)) (PP (IN for) (NP (NNP Czechoslovakia)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="They" type="NP">
          <tokens>
            <token id="1" string="They" />
          </tokens>
        </chunking>
        <chunking id="2" string="a plane" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="plane" />
          </tokens>
        </chunking>
        <chunking id="3" string="Czechoslovakia" type="NP">
          <tokens>
            <token id="6" string="Czechoslovakia" />
          </tokens>
        </chunking>
        <chunking id="4" string="grabbed a plane for Czechoslovakia" type="VP">
          <tokens>
            <token id="2" string="grabbed" />
            <token id="3" string="a" />
            <token id="4" string="plane" />
            <token id="5" string="for" />
            <token id="6" string="Czechoslovakia" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">grabbed</governor>
          <dependent id="1">They</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">grabbed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">plane</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">grabbed</governor>
          <dependent id="4">plane</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">Czechoslovakia</governor>
          <dependent id="5">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">grabbed</governor>
          <dependent id="6">Czechoslovakia</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Czechoslovakia" type="LOCATION" score="0.0">
          <tokens>
            <token id="6" string="Czechoslovakia" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="88" has_coreference="true">
      <content>Since then, the team has confirmed that many of the Slovakian CJD victims, and a cluster of Libyan-born Jews whose tissues were preserved, carried the defect.</content>
      <tokens>
        <token id="1" string="Since" lemma="since" stem="sinc" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="team" lemma="team" stem="team" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="confirmed" lemma="confirm" stem="confirm" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="many" lemma="many" stem="mani" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Slovakian" lemma="slovakian" stem="slovakian" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="13" string="CJD" lemma="cjd" stem="cjd" pos="NN" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="14" string="victims" lemma="victim" stem="victim" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="cluster" lemma="cluster" stem="cluster" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="Libyan-born" lemma="libyan-born" stem="libyan-born" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="21" string="Jews" lemma="Jews" stem="jew" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="22" string="whose" lemma="whose" stem="whose" pos="WP$" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="tissues" lemma="tissue" stem="tissu" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="preserved" lemma="preserve" stem="preserv" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="carried" lemma="carry" stem="carri" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="29" string="defect" lemma="defect" stem="defect" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN Since) (NP (RB then))) (, ,) (NP (DT the) (NN team)) (VP (VBZ has) (VP (VBN confirmed) (SBAR (IN that) (S (NP (NP (NP (JJ many)) (PP (IN of) (NP (DT the) (JJ Slovakian) (NN CJD) (NNS victims)))) (, ,) (CC and) (NP (NP (DT a) (NN cluster)) (PP (IN of) (NP (JJ Libyan-born) (NNPS Jews))) (SBAR (WHNP (WP$ whose) (NNS tissues)) (S (VP (VBD were) (VP (VBN preserved)))))) (, ,)) (VP (VBD carried) (NP (DT the) (NN defect))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="has confirmed that many of the Slovakian CJD victims , and a cluster of Libyan-born Jews whose tissues were preserved , carried the defect" type="VP">
          <tokens>
            <token id="6" string="has" />
            <token id="7" string="confirmed" />
            <token id="8" string="that" />
            <token id="9" string="many" />
            <token id="10" string="of" />
            <token id="11" string="the" />
            <token id="12" string="Slovakian" />
            <token id="13" string="CJD" />
            <token id="14" string="victims" />
            <token id="15" string="," />
            <token id="16" string="and" />
            <token id="17" string="a" />
            <token id="18" string="cluster" />
            <token id="19" string="of" />
            <token id="20" string="Libyan-born" />
            <token id="21" string="Jews" />
            <token id="22" string="whose" />
            <token id="23" string="tissues" />
            <token id="24" string="were" />
            <token id="25" string="preserved" />
            <token id="26" string="," />
            <token id="27" string="carried" />
            <token id="28" string="the" />
            <token id="29" string="defect" />
          </tokens>
        </chunking>
        <chunking id="2" string="many of the Slovakian CJD victims , and a cluster of Libyan-born Jews whose tissues were preserved ," type="NP">
          <tokens>
            <token id="9" string="many" />
            <token id="10" string="of" />
            <token id="11" string="the" />
            <token id="12" string="Slovakian" />
            <token id="13" string="CJD" />
            <token id="14" string="victims" />
            <token id="15" string="," />
            <token id="16" string="and" />
            <token id="17" string="a" />
            <token id="18" string="cluster" />
            <token id="19" string="of" />
            <token id="20" string="Libyan-born" />
            <token id="21" string="Jews" />
            <token id="22" string="whose" />
            <token id="23" string="tissues" />
            <token id="24" string="were" />
            <token id="25" string="preserved" />
            <token id="26" string="," />
          </tokens>
        </chunking>
        <chunking id="3" string="the Slovakian CJD victims" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="Slovakian" />
            <token id="13" string="CJD" />
            <token id="14" string="victims" />
          </tokens>
        </chunking>
        <chunking id="4" string="confirmed that many of the Slovakian CJD victims , and a cluster of Libyan-born Jews whose tissues were preserved , carried the defect" type="VP">
          <tokens>
            <token id="7" string="confirmed" />
            <token id="8" string="that" />
            <token id="9" string="many" />
            <token id="10" string="of" />
            <token id="11" string="the" />
            <token id="12" string="Slovakian" />
            <token id="13" string="CJD" />
            <token id="14" string="victims" />
            <token id="15" string="," />
            <token id="16" string="and" />
            <token id="17" string="a" />
            <token id="18" string="cluster" />
            <token id="19" string="of" />
            <token id="20" string="Libyan-born" />
            <token id="21" string="Jews" />
            <token id="22" string="whose" />
            <token id="23" string="tissues" />
            <token id="24" string="were" />
            <token id="25" string="preserved" />
            <token id="26" string="," />
            <token id="27" string="carried" />
            <token id="28" string="the" />
            <token id="29" string="defect" />
          </tokens>
        </chunking>
        <chunking id="5" string="were preserved" type="VP">
          <tokens>
            <token id="24" string="were" />
            <token id="25" string="preserved" />
          </tokens>
        </chunking>
        <chunking id="6" string="the team" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="team" />
          </tokens>
        </chunking>
        <chunking id="7" string="the defect" type="NP">
          <tokens>
            <token id="28" string="the" />
            <token id="29" string="defect" />
          </tokens>
        </chunking>
        <chunking id="8" string="then" type="NP">
          <tokens>
            <token id="2" string="then" />
          </tokens>
        </chunking>
        <chunking id="9" string="many" type="NP">
          <tokens>
            <token id="9" string="many" />
          </tokens>
        </chunking>
        <chunking id="10" string="whose tissues were preserved" type="SBAR">
          <tokens>
            <token id="22" string="whose" />
            <token id="23" string="tissues" />
            <token id="24" string="were" />
            <token id="25" string="preserved" />
          </tokens>
        </chunking>
        <chunking id="11" string="a cluster" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="cluster" />
          </tokens>
        </chunking>
        <chunking id="12" string="Libyan-born Jews" type="NP">
          <tokens>
            <token id="20" string="Libyan-born" />
            <token id="21" string="Jews" />
          </tokens>
        </chunking>
        <chunking id="13" string="that many of the Slovakian CJD victims , and a cluster of Libyan-born Jews whose tissues were preserved , carried the defect" type="SBAR">
          <tokens>
            <token id="8" string="that" />
            <token id="9" string="many" />
            <token id="10" string="of" />
            <token id="11" string="the" />
            <token id="12" string="Slovakian" />
            <token id="13" string="CJD" />
            <token id="14" string="victims" />
            <token id="15" string="," />
            <token id="16" string="and" />
            <token id="17" string="a" />
            <token id="18" string="cluster" />
            <token id="19" string="of" />
            <token id="20" string="Libyan-born" />
            <token id="21" string="Jews" />
            <token id="22" string="whose" />
            <token id="23" string="tissues" />
            <token id="24" string="were" />
            <token id="25" string="preserved" />
            <token id="26" string="," />
            <token id="27" string="carried" />
            <token id="28" string="the" />
            <token id="29" string="defect" />
          </tokens>
        </chunking>
        <chunking id="14" string="a cluster of Libyan-born Jews whose tissues were preserved" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="cluster" />
            <token id="19" string="of" />
            <token id="20" string="Libyan-born" />
            <token id="21" string="Jews" />
            <token id="22" string="whose" />
            <token id="23" string="tissues" />
            <token id="24" string="were" />
            <token id="25" string="preserved" />
          </tokens>
        </chunking>
        <chunking id="15" string="preserved" type="VP">
          <tokens>
            <token id="25" string="preserved" />
          </tokens>
        </chunking>
        <chunking id="16" string="carried the defect" type="VP">
          <tokens>
            <token id="27" string="carried" />
            <token id="28" string="the" />
            <token id="29" string="defect" />
          </tokens>
        </chunking>
        <chunking id="17" string="many of the Slovakian CJD victims" type="NP">
          <tokens>
            <token id="9" string="many" />
            <token id="10" string="of" />
            <token id="11" string="the" />
            <token id="12" string="Slovakian" />
            <token id="13" string="CJD" />
            <token id="14" string="victims" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">then</governor>
          <dependent id="1">Since</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">confirmed</governor>
          <dependent id="2">then</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">team</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">confirmed</governor>
          <dependent id="5">team</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">confirmed</governor>
          <dependent id="6">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">confirmed</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="27">carried</governor>
          <dependent id="8">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">carried</governor>
          <dependent id="9">many</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">victims</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">victims</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">victims</governor>
          <dependent id="12">Slovakian</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">victims</governor>
          <dependent id="13">CJD</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">many</governor>
          <dependent id="14">victims</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">many</governor>
          <dependent id="16">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">cluster</governor>
          <dependent id="17">a</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">many</governor>
          <dependent id="18">cluster</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">Jews</governor>
          <dependent id="19">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">Jews</governor>
          <dependent id="20">Libyan-born</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">cluster</governor>
          <dependent id="21">Jews</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="23">tissues</governor>
          <dependent id="22">whose</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="25">preserved</governor>
          <dependent id="23">tissues</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="25">preserved</governor>
          <dependent id="24">were</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="18">cluster</governor>
          <dependent id="25">preserved</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">confirmed</governor>
          <dependent id="27">carried</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">defect</governor>
          <dependent id="28">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="27">carried</governor>
          <dependent id="29">defect</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Libyan-born Jews" type="MISC" score="0.0">
          <tokens>
            <token id="20" string="Libyan-born" />
            <token id="21" string="Jews" />
          </tokens>
        </entity>
        <entity id="2" string="Slovakian" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="12" string="Slovakian" />
          </tokens>
        </entity>
        <entity id="3" string="CJD" type="MISC" score="0.0">
          <tokens>
            <token id="13" string="CJD" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="89" has_coreference="true">
      <content>The findings suggest one of two things: Either the defect alone produces the deadly agent or it predisposes its carriers to get CJD when they are exposed to the agent.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="findings" lemma="finding" stem="find" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="suggest" lemma="suggest" stem="suggest" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="7" string="things" lemma="thing" stem="thing" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Either" lemma="either" stem="either" pos="CC" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="defect" lemma="defect" stem="defect" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="alone" lemma="alone" stem="alon" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="produces" lemma="produce" stem="produc" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="deadly" lemma="deadly" stem="deadli" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="agent" lemma="agent" stem="agent" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="predisposes" lemma="predispose" stem="predispos" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="21" string="carriers" lemma="carrier" stem="carrier" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="get" lemma="get" stem="get" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="CJD" lemma="CJD" stem="cjd" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="true" />
        <token id="25" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="26" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="27" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="28" string="exposed" lemma="expose" stem="expos" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="29" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="30" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="31" string="agent" lemma="agent" stem="agent" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (DT The) (NNS findings)) (VP (VBP suggest) (NP (NP (CD one)) (PP (IN of) (NP (CD two) (NNS things)))))) (: :) (S (CC Either) (S (NP (DT the) (NN defect)) (ADVP (RB alone)) (VP (VBZ produces) (NP (DT the) (JJ deadly) (NN agent)))) (CC or) (S (NP (PRP it)) (VP (VBZ predisposes) (NP (PRP$ its) (NNS carriers)) (S (VP (TO to) (VP (VB get) (NP (NP (NNP CJD)) (SBAR (WHADVP (WRB when)) (S (NP (PRP they)) (VP (VBP are) (VP (VBN exposed) (PP (TO to) (NP (DT the) (NN agent)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="when they are exposed to the agent" type="SBAR">
          <tokens>
            <token id="25" string="when" />
            <token id="26" string="they" />
            <token id="27" string="are" />
            <token id="28" string="exposed" />
            <token id="29" string="to" />
            <token id="30" string="the" />
            <token id="31" string="agent" />
          </tokens>
        </chunking>
        <chunking id="2" string="the agent" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="agent" />
          </tokens>
        </chunking>
        <chunking id="3" string="one" type="NP">
          <tokens>
            <token id="4" string="one" />
          </tokens>
        </chunking>
        <chunking id="4" string="two things" type="NP">
          <tokens>
            <token id="6" string="two" />
            <token id="7" string="things" />
          </tokens>
        </chunking>
        <chunking id="5" string="CJD when they are exposed to the agent" type="NP">
          <tokens>
            <token id="24" string="CJD" />
            <token id="25" string="when" />
            <token id="26" string="they" />
            <token id="27" string="are" />
            <token id="28" string="exposed" />
            <token id="29" string="to" />
            <token id="30" string="the" />
            <token id="31" string="agent" />
          </tokens>
        </chunking>
        <chunking id="6" string="exposed to the agent" type="VP">
          <tokens>
            <token id="28" string="exposed" />
            <token id="29" string="to" />
            <token id="30" string="the" />
            <token id="31" string="agent" />
          </tokens>
        </chunking>
        <chunking id="7" string="its carriers" type="NP">
          <tokens>
            <token id="20" string="its" />
            <token id="21" string="carriers" />
          </tokens>
        </chunking>
        <chunking id="8" string="the defect" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="defect" />
          </tokens>
        </chunking>
        <chunking id="9" string="it" type="NP">
          <tokens>
            <token id="18" string="it" />
          </tokens>
        </chunking>
        <chunking id="10" string="one of two things" type="NP">
          <tokens>
            <token id="4" string="one" />
            <token id="5" string="of" />
            <token id="6" string="two" />
            <token id="7" string="things" />
          </tokens>
        </chunking>
        <chunking id="11" string="predisposes its carriers to get CJD when they are exposed to the agent" type="VP">
          <tokens>
            <token id="19" string="predisposes" />
            <token id="20" string="its" />
            <token id="21" string="carriers" />
            <token id="22" string="to" />
            <token id="23" string="get" />
            <token id="24" string="CJD" />
            <token id="25" string="when" />
            <token id="26" string="they" />
            <token id="27" string="are" />
            <token id="28" string="exposed" />
            <token id="29" string="to" />
            <token id="30" string="the" />
            <token id="31" string="agent" />
          </tokens>
        </chunking>
        <chunking id="12" string="when" type="WHADVP">
          <tokens>
            <token id="25" string="when" />
          </tokens>
        </chunking>
        <chunking id="13" string="The findings" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="findings" />
          </tokens>
        </chunking>
        <chunking id="14" string="they" type="NP">
          <tokens>
            <token id="26" string="they" />
          </tokens>
        </chunking>
        <chunking id="15" string="to get CJD when they are exposed to the agent" type="VP">
          <tokens>
            <token id="22" string="to" />
            <token id="23" string="get" />
            <token id="24" string="CJD" />
            <token id="25" string="when" />
            <token id="26" string="they" />
            <token id="27" string="are" />
            <token id="28" string="exposed" />
            <token id="29" string="to" />
            <token id="30" string="the" />
            <token id="31" string="agent" />
          </tokens>
        </chunking>
        <chunking id="16" string="get CJD when they are exposed to the agent" type="VP">
          <tokens>
            <token id="23" string="get" />
            <token id="24" string="CJD" />
            <token id="25" string="when" />
            <token id="26" string="they" />
            <token id="27" string="are" />
            <token id="28" string="exposed" />
            <token id="29" string="to" />
            <token id="30" string="the" />
            <token id="31" string="agent" />
          </tokens>
        </chunking>
        <chunking id="17" string="suggest one of two things" type="VP">
          <tokens>
            <token id="3" string="suggest" />
            <token id="4" string="one" />
            <token id="5" string="of" />
            <token id="6" string="two" />
            <token id="7" string="things" />
          </tokens>
        </chunking>
        <chunking id="18" string="produces the deadly agent" type="VP">
          <tokens>
            <token id="13" string="produces" />
            <token id="14" string="the" />
            <token id="15" string="deadly" />
            <token id="16" string="agent" />
          </tokens>
        </chunking>
        <chunking id="19" string="the deadly agent" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="deadly" />
            <token id="16" string="agent" />
          </tokens>
        </chunking>
        <chunking id="20" string="are exposed to the agent" type="VP">
          <tokens>
            <token id="27" string="are" />
            <token id="28" string="exposed" />
            <token id="29" string="to" />
            <token id="30" string="the" />
            <token id="31" string="agent" />
          </tokens>
        </chunking>
        <chunking id="21" string="CJD" type="NP">
          <tokens>
            <token id="24" string="CJD" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">findings</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">suggest</governor>
          <dependent id="2">findings</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">suggest</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">suggest</governor>
          <dependent id="4">one</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">things</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="7">things</governor>
          <dependent id="6">two</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">one</governor>
          <dependent id="7">things</dependent>
        </dependency>
        <dependency type="cc:preconj">
          <governor id="13">produces</governor>
          <dependent id="9">Either</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">defect</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">produces</governor>
          <dependent id="11">defect</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">produces</governor>
          <dependent id="12">alone</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="3">suggest</governor>
          <dependent id="13">produces</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">agent</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">agent</governor>
          <dependent id="15">deadly</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">produces</governor>
          <dependent id="16">agent</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">produces</governor>
          <dependent id="17">or</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">predisposes</governor>
          <dependent id="18">it</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">produces</governor>
          <dependent id="19">predisposes</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="21">carriers</governor>
          <dependent id="20">its</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">predisposes</governor>
          <dependent id="21">carriers</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="23">get</governor>
          <dependent id="22">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="19">predisposes</governor>
          <dependent id="23">get</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="23">get</governor>
          <dependent id="24">CJD</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="28">exposed</governor>
          <dependent id="25">when</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="28">exposed</governor>
          <dependent id="26">they</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="28">exposed</governor>
          <dependent id="27">are</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="24">CJD</governor>
          <dependent id="28">exposed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">agent</governor>
          <dependent id="29">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">agent</governor>
          <dependent id="30">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">exposed</governor>
          <dependent id="31">agent</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="4" string="one" />
          </tokens>
        </entity>
        <entity id="2" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="6" string="two" />
          </tokens>
        </entity>
        <entity id="3" string="CJD" type="MISC" score="0.0">
          <tokens>
            <token id="24" string="CJD" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="90" has_coreference="false">
      <content>The findings have opened the door for early diagnosis and possible prevention of CJD.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="findings" lemma="finding" stem="find" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="opened" lemma="open" stem="open" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="door" lemma="door" stem="door" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="early" lemma="early" stem="earli" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="diagnosis" lemma="diagnosis" stem="diagnosi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="possible" lemma="possible" stem="possibl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="prevention" lemma="prevention" stem="prevent" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="CJD" lemma="CJD" stem="cjd" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NNS findings)) (VP (VBP have) (VP (VBN opened) (NP (NP (NP (DT the) (NN door)) (PP (IN for) (NP (JJ early) (NN diagnosis)))) (CC and) (NP (NP (JJ possible) (NN prevention)) (PP (IN of) (NP (NNP CJD))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="The findings" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="findings" />
          </tokens>
        </chunking>
        <chunking id="2" string="opened the door for early diagnosis and possible prevention of CJD" type="VP">
          <tokens>
            <token id="4" string="opened" />
            <token id="5" string="the" />
            <token id="6" string="door" />
            <token id="7" string="for" />
            <token id="8" string="early" />
            <token id="9" string="diagnosis" />
            <token id="10" string="and" />
            <token id="11" string="possible" />
            <token id="12" string="prevention" />
            <token id="13" string="of" />
            <token id="14" string="CJD" />
          </tokens>
        </chunking>
        <chunking id="3" string="the door" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="door" />
          </tokens>
        </chunking>
        <chunking id="4" string="early diagnosis" type="NP">
          <tokens>
            <token id="8" string="early" />
            <token id="9" string="diagnosis" />
          </tokens>
        </chunking>
        <chunking id="5" string="possible prevention" type="NP">
          <tokens>
            <token id="11" string="possible" />
            <token id="12" string="prevention" />
          </tokens>
        </chunking>
        <chunking id="6" string="have opened the door for early diagnosis and possible prevention of CJD" type="VP">
          <tokens>
            <token id="3" string="have" />
            <token id="4" string="opened" />
            <token id="5" string="the" />
            <token id="6" string="door" />
            <token id="7" string="for" />
            <token id="8" string="early" />
            <token id="9" string="diagnosis" />
            <token id="10" string="and" />
            <token id="11" string="possible" />
            <token id="12" string="prevention" />
            <token id="13" string="of" />
            <token id="14" string="CJD" />
          </tokens>
        </chunking>
        <chunking id="7" string="the door for early diagnosis and possible prevention of CJD" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="door" />
            <token id="7" string="for" />
            <token id="8" string="early" />
            <token id="9" string="diagnosis" />
            <token id="10" string="and" />
            <token id="11" string="possible" />
            <token id="12" string="prevention" />
            <token id="13" string="of" />
            <token id="14" string="CJD" />
          </tokens>
        </chunking>
        <chunking id="8" string="possible prevention of CJD" type="NP">
          <tokens>
            <token id="11" string="possible" />
            <token id="12" string="prevention" />
            <token id="13" string="of" />
            <token id="14" string="CJD" />
          </tokens>
        </chunking>
        <chunking id="9" string="CJD" type="NP">
          <tokens>
            <token id="14" string="CJD" />
          </tokens>
        </chunking>
        <chunking id="10" string="the door for early diagnosis" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="door" />
            <token id="7" string="for" />
            <token id="8" string="early" />
            <token id="9" string="diagnosis" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">findings</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">opened</governor>
          <dependent id="2">findings</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">opened</governor>
          <dependent id="3">have</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">opened</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">door</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">opened</governor>
          <dependent id="6">door</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">diagnosis</governor>
          <dependent id="7">for</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">diagnosis</governor>
          <dependent id="8">early</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">door</governor>
          <dependent id="9">diagnosis</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">door</governor>
          <dependent id="10">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">prevention</governor>
          <dependent id="11">possible</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">door</governor>
          <dependent id="12">prevention</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">CJD</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">prevention</governor>
          <dependent id="14">CJD</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="CJD" type="MISC" score="0.0">
          <tokens>
            <token id="14" string="CJD" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="91" has_coreference="true">
      <content>But they also have introduced a new riddle, says Dr. Gajdusek: Why has the genetic defect, which has apparently existed for decades in some Eastern Europeans, turned deadly only in the past 15 years or so?</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="introduced" lemma="introduce" stem="introduc" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="new" lemma="new" stem="new" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="riddle" lemma="riddle" stem="riddl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="Dr." lemma="Dr." stem="dr." pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="Gajdusek" lemma="Gajdusek" stem="gajdusek" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="13" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="Why" lemma="why" stem="why" pos="WRB" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="17" string="genetic" lemma="genetic" stem="genet" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="18" string="defect" lemma="defect" stem="defect" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="apparently" lemma="apparently" stem="appar" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="existed" lemma="exist" stem="exist" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="25" string="decades" lemma="decade" stem="decad" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="26" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="27" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="28" string="Eastern" lemma="Eastern" stem="eastern" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="29" string="Europeans" lemma="Europeans" stem="european" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="30" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="31" string="turned" lemma="turn" stem="turn" pos="VBD" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="32" string="deadly" lemma="deadly" stem="deadli" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="33" string="only" lemma="only" stem="onli" pos="RB" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="34" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="35" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="36" string="past" lemma="past" stem="past" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="37" string="15" lemma="15" stem="15" pos="CD" type="Number" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="38" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="39" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="40" string="so" lemma="so" stem="so" pos="RB" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="41" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (S (CC But) (NP (PRP they)) (ADVP (RB also)) (VP (VBP have) (VP (VBN introduced) (NP (DT a) (JJ new) (NN riddle))))) (, ,) (VP (VBZ says)) (NP (NP (NNP Dr.) (NNP Gajdusek)) (: :) (SBAR (WHADVP (WRB Why)) (S (VP (VBZ has) (NP (NP (DT the) (JJ genetic) (NN defect)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ has) (ADVP (RB apparently)) (VP (VBN existed) (SBAR (IN for) (S (NP (NP (NNS decades)) (PP (IN in) (NP (DT some) (NNP Eastern) (NNPS Europeans)))) (, ,) (VP (VBD turned) (ADJP (JJ deadly)) (ADVP (RB only)) (PP (IN in) (NP (DT the) (JJ past) (CD 15) (NNS years))))) (CC or) (RB so))))))))))) (. ?)))</syntactictree>
      <chunkings>
        <chunking id="1" string="has the genetic defect , which has apparently existed for decades in some Eastern Europeans , turned deadly only in the past 15 years or so" type="VP">
          <tokens>
            <token id="15" string="has" />
            <token id="16" string="the" />
            <token id="17" string="genetic" />
            <token id="18" string="defect" />
            <token id="19" string="," />
            <token id="20" string="which" />
            <token id="21" string="has" />
            <token id="22" string="apparently" />
            <token id="23" string="existed" />
            <token id="24" string="for" />
            <token id="25" string="decades" />
            <token id="26" string="in" />
            <token id="27" string="some" />
            <token id="28" string="Eastern" />
            <token id="29" string="Europeans" />
            <token id="30" string="," />
            <token id="31" string="turned" />
            <token id="32" string="deadly" />
            <token id="33" string="only" />
            <token id="34" string="in" />
            <token id="35" string="the" />
            <token id="36" string="past" />
            <token id="37" string="15" />
            <token id="38" string="years" />
            <token id="39" string="or" />
            <token id="40" string="so" />
          </tokens>
        </chunking>
        <chunking id="2" string="Why has the genetic defect , which has apparently existed for decades in some Eastern Europeans , turned deadly only in the past 15 years or so" type="SBAR">
          <tokens>
            <token id="14" string="Why" />
            <token id="15" string="has" />
            <token id="16" string="the" />
            <token id="17" string="genetic" />
            <token id="18" string="defect" />
            <token id="19" string="," />
            <token id="20" string="which" />
            <token id="21" string="has" />
            <token id="22" string="apparently" />
            <token id="23" string="existed" />
            <token id="24" string="for" />
            <token id="25" string="decades" />
            <token id="26" string="in" />
            <token id="27" string="some" />
            <token id="28" string="Eastern" />
            <token id="29" string="Europeans" />
            <token id="30" string="," />
            <token id="31" string="turned" />
            <token id="32" string="deadly" />
            <token id="33" string="only" />
            <token id="34" string="in" />
            <token id="35" string="the" />
            <token id="36" string="past" />
            <token id="37" string="15" />
            <token id="38" string="years" />
            <token id="39" string="or" />
            <token id="40" string="so" />
          </tokens>
        </chunking>
        <chunking id="3" string="Dr. Gajdusek" type="NP">
          <tokens>
            <token id="11" string="Dr." />
            <token id="12" string="Gajdusek" />
          </tokens>
        </chunking>
        <chunking id="4" string="Why" type="WHADVP">
          <tokens>
            <token id="14" string="Why" />
          </tokens>
        </chunking>
        <chunking id="5" string="a new riddle" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="new" />
            <token id="8" string="riddle" />
          </tokens>
        </chunking>
        <chunking id="6" string="the past 15 years" type="NP">
          <tokens>
            <token id="35" string="the" />
            <token id="36" string="past" />
            <token id="37" string="15" />
            <token id="38" string="years" />
          </tokens>
        </chunking>
        <chunking id="7" string="the genetic defect" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="genetic" />
            <token id="18" string="defect" />
          </tokens>
        </chunking>
        <chunking id="8" string="has apparently existed for decades in some Eastern Europeans , turned deadly only in the past 15 years or so" type="VP">
          <tokens>
            <token id="21" string="has" />
            <token id="22" string="apparently" />
            <token id="23" string="existed" />
            <token id="24" string="for" />
            <token id="25" string="decades" />
            <token id="26" string="in" />
            <token id="27" string="some" />
            <token id="28" string="Eastern" />
            <token id="29" string="Europeans" />
            <token id="30" string="," />
            <token id="31" string="turned" />
            <token id="32" string="deadly" />
            <token id="33" string="only" />
            <token id="34" string="in" />
            <token id="35" string="the" />
            <token id="36" string="past" />
            <token id="37" string="15" />
            <token id="38" string="years" />
            <token id="39" string="or" />
            <token id="40" string="so" />
          </tokens>
        </chunking>
        <chunking id="9" string="they" type="NP">
          <tokens>
            <token id="2" string="they" />
          </tokens>
        </chunking>
        <chunking id="10" string="have introduced a new riddle" type="VP">
          <tokens>
            <token id="4" string="have" />
            <token id="5" string="introduced" />
            <token id="6" string="a" />
            <token id="7" string="new" />
            <token id="8" string="riddle" />
          </tokens>
        </chunking>
        <chunking id="11" string="for decades in some Eastern Europeans , turned deadly only in the past 15 years or so" type="SBAR">
          <tokens>
            <token id="24" string="for" />
            <token id="25" string="decades" />
            <token id="26" string="in" />
            <token id="27" string="some" />
            <token id="28" string="Eastern" />
            <token id="29" string="Europeans" />
            <token id="30" string="," />
            <token id="31" string="turned" />
            <token id="32" string="deadly" />
            <token id="33" string="only" />
            <token id="34" string="in" />
            <token id="35" string="the" />
            <token id="36" string="past" />
            <token id="37" string="15" />
            <token id="38" string="years" />
            <token id="39" string="or" />
            <token id="40" string="so" />
          </tokens>
        </chunking>
        <chunking id="12" string="deadly" type="ADJP">
          <tokens>
            <token id="32" string="deadly" />
          </tokens>
        </chunking>
        <chunking id="13" string="says" type="VP">
          <tokens>
            <token id="10" string="says" />
          </tokens>
        </chunking>
        <chunking id="14" string="Dr. Gajdusek : Why has the genetic defect , which has apparently existed for decades in some Eastern Europeans , turned deadly only in the past 15 years or so" type="NP">
          <tokens>
            <token id="11" string="Dr." />
            <token id="12" string="Gajdusek" />
            <token id="13" string=":" />
            <token id="14" string="Why" />
            <token id="15" string="has" />
            <token id="16" string="the" />
            <token id="17" string="genetic" />
            <token id="18" string="defect" />
            <token id="19" string="," />
            <token id="20" string="which" />
            <token id="21" string="has" />
            <token id="22" string="apparently" />
            <token id="23" string="existed" />
            <token id="24" string="for" />
            <token id="25" string="decades" />
            <token id="26" string="in" />
            <token id="27" string="some" />
            <token id="28" string="Eastern" />
            <token id="29" string="Europeans" />
            <token id="30" string="," />
            <token id="31" string="turned" />
            <token id="32" string="deadly" />
            <token id="33" string="only" />
            <token id="34" string="in" />
            <token id="35" string="the" />
            <token id="36" string="past" />
            <token id="37" string="15" />
            <token id="38" string="years" />
            <token id="39" string="or" />
            <token id="40" string="so" />
          </tokens>
        </chunking>
        <chunking id="15" string="existed for decades in some Eastern Europeans , turned deadly only in the past 15 years or so" type="VP">
          <tokens>
            <token id="23" string="existed" />
            <token id="24" string="for" />
            <token id="25" string="decades" />
            <token id="26" string="in" />
            <token id="27" string="some" />
            <token id="28" string="Eastern" />
            <token id="29" string="Europeans" />
            <token id="30" string="," />
            <token id="31" string="turned" />
            <token id="32" string="deadly" />
            <token id="33" string="only" />
            <token id="34" string="in" />
            <token id="35" string="the" />
            <token id="36" string="past" />
            <token id="37" string="15" />
            <token id="38" string="years" />
            <token id="39" string="or" />
            <token id="40" string="so" />
          </tokens>
        </chunking>
        <chunking id="16" string="introduced a new riddle" type="VP">
          <tokens>
            <token id="5" string="introduced" />
            <token id="6" string="a" />
            <token id="7" string="new" />
            <token id="8" string="riddle" />
          </tokens>
        </chunking>
        <chunking id="17" string="which has apparently existed for decades in some Eastern Europeans , turned deadly only in the past 15 years or so" type="SBAR">
          <tokens>
            <token id="20" string="which" />
            <token id="21" string="has" />
            <token id="22" string="apparently" />
            <token id="23" string="existed" />
            <token id="24" string="for" />
            <token id="25" string="decades" />
            <token id="26" string="in" />
            <token id="27" string="some" />
            <token id="28" string="Eastern" />
            <token id="29" string="Europeans" />
            <token id="30" string="," />
            <token id="31" string="turned" />
            <token id="32" string="deadly" />
            <token id="33" string="only" />
            <token id="34" string="in" />
            <token id="35" string="the" />
            <token id="36" string="past" />
            <token id="37" string="15" />
            <token id="38" string="years" />
            <token id="39" string="or" />
            <token id="40" string="so" />
          </tokens>
        </chunking>
        <chunking id="18" string="the genetic defect , which has apparently existed for decades in some Eastern Europeans , turned deadly only in the past 15 years or so" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="genetic" />
            <token id="18" string="defect" />
            <token id="19" string="," />
            <token id="20" string="which" />
            <token id="21" string="has" />
            <token id="22" string="apparently" />
            <token id="23" string="existed" />
            <token id="24" string="for" />
            <token id="25" string="decades" />
            <token id="26" string="in" />
            <token id="27" string="some" />
            <token id="28" string="Eastern" />
            <token id="29" string="Europeans" />
            <token id="30" string="," />
            <token id="31" string="turned" />
            <token id="32" string="deadly" />
            <token id="33" string="only" />
            <token id="34" string="in" />
            <token id="35" string="the" />
            <token id="36" string="past" />
            <token id="37" string="15" />
            <token id="38" string="years" />
            <token id="39" string="or" />
            <token id="40" string="so" />
          </tokens>
        </chunking>
        <chunking id="19" string="decades" type="NP">
          <tokens>
            <token id="25" string="decades" />
          </tokens>
        </chunking>
        <chunking id="20" string="decades in some Eastern Europeans" type="NP">
          <tokens>
            <token id="25" string="decades" />
            <token id="26" string="in" />
            <token id="27" string="some" />
            <token id="28" string="Eastern" />
            <token id="29" string="Europeans" />
          </tokens>
        </chunking>
        <chunking id="21" string="some Eastern Europeans" type="NP">
          <tokens>
            <token id="27" string="some" />
            <token id="28" string="Eastern" />
            <token id="29" string="Europeans" />
          </tokens>
        </chunking>
        <chunking id="22" string="turned deadly only in the past 15 years" type="VP">
          <tokens>
            <token id="31" string="turned" />
            <token id="32" string="deadly" />
            <token id="33" string="only" />
            <token id="34" string="in" />
            <token id="35" string="the" />
            <token id="36" string="past" />
            <token id="37" string="15" />
            <token id="38" string="years" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="5">introduced</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">introduced</governor>
          <dependent id="2">they</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">introduced</governor>
          <dependent id="3">also</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">introduced</governor>
          <dependent id="4">have</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">says</governor>
          <dependent id="5">introduced</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">riddle</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">riddle</governor>
          <dependent id="7">new</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">introduced</governor>
          <dependent id="8">riddle</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">says</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Gajdusek</governor>
          <dependent id="11">Dr.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">says</governor>
          <dependent id="12">Gajdusek</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">has</governor>
          <dependent id="14">Why</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="12">Gajdusek</governor>
          <dependent id="15">has</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">defect</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">defect</governor>
          <dependent id="17">genetic</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">has</governor>
          <dependent id="18">defect</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">existed</governor>
          <dependent id="20">which</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="23">existed</governor>
          <dependent id="21">has</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="23">existed</governor>
          <dependent id="22">apparently</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="18">defect</governor>
          <dependent id="23">existed</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="31">turned</governor>
          <dependent id="24">for</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="31">turned</governor>
          <dependent id="25">decades</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">Europeans</governor>
          <dependent id="26">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">Europeans</governor>
          <dependent id="27">some</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="29">Europeans</governor>
          <dependent id="28">Eastern</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">decades</governor>
          <dependent id="29">Europeans</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="23">existed</governor>
          <dependent id="31">turned</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="31">turned</governor>
          <dependent id="32">deadly</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="31">turned</governor>
          <dependent id="33">only</dependent>
        </dependency>
        <dependency type="case">
          <governor id="38">years</governor>
          <dependent id="34">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="38">years</governor>
          <dependent id="35">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="38">years</governor>
          <dependent id="36">past</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="38">years</governor>
          <dependent id="37">15</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">turned</governor>
          <dependent id="38">years</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="31">turned</governor>
          <dependent id="39">or</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="31">turned</governor>
          <dependent id="40">so</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Eastern Europeans" type="MISC" score="0.0">
          <tokens>
            <token id="28" string="Eastern" />
            <token id="29" string="Europeans" />
          </tokens>
        </entity>
        <entity id="2" string="the past 15 years" type="DURATION" score="0.0">
          <tokens>
            <token id="35" string="the" />
            <token id="36" string="past" />
            <token id="37" string="15" />
            <token id="38" string="years" />
          </tokens>
        </entity>
        <entity id="3" string="decades" type="DURATION" score="0.0">
          <tokens>
            <token id="25" string="decades" />
          </tokens>
        </entity>
        <entity id="4" string="Gajdusek" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Gajdusek" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="92" has_coreference="true">
      <content>&amp;quot;Essentially, we&amp;apost;re stuck with another paradox,&amp;quot; he adds.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Essentially" lemma="essentially" stem="essential" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="'re" lemma="be" stem="'re" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="stuck" lemma="stick" stem="stuck" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="another" lemma="another" stem="anoth" pos="DT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="paradox" lemma="paradox" stem="paradox" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="adds" lemma="add" stem="add" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (ADVP (RB Essentially)) (, ,) (NP (PRP we)) (VP (VBP 're) (VP (VBN stuck) (PP (IN with) (NP (DT another) (NN paradox)))))) (, ,) ('' '') (NP (PRP he)) (VP (VBZ adds)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="another paradox" type="NP">
          <tokens>
            <token id="8" string="another" />
            <token id="9" string="paradox" />
          </tokens>
        </chunking>
        <chunking id="2" string="he" type="NP">
          <tokens>
            <token id="12" string="he" />
          </tokens>
        </chunking>
        <chunking id="3" string="adds" type="VP">
          <tokens>
            <token id="13" string="adds" />
          </tokens>
        </chunking>
        <chunking id="4" string="we" type="NP">
          <tokens>
            <token id="4" string="we" />
          </tokens>
        </chunking>
        <chunking id="5" string="stuck with another paradox" type="VP">
          <tokens>
            <token id="6" string="stuck" />
            <token id="7" string="with" />
            <token id="8" string="another" />
            <token id="9" string="paradox" />
          </tokens>
        </chunking>
        <chunking id="6" string="'re stuck with another paradox" type="VP">
          <tokens>
            <token id="5" string="'re" />
            <token id="6" string="stuck" />
            <token id="7" string="with" />
            <token id="8" string="another" />
            <token id="9" string="paradox" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="6">stuck</governor>
          <dependent id="2">Essentially</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="6">stuck</governor>
          <dependent id="4">we</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="6">stuck</governor>
          <dependent id="5">'re</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="13">adds</governor>
          <dependent id="6">stuck</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">paradox</governor>
          <dependent id="7">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">paradox</governor>
          <dependent id="8">another</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">stuck</governor>
          <dependent id="9">paradox</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">adds</governor>
          <dependent id="12">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">adds</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="93" has_coreference="false">
      <content>&amp;quot;But there&amp;apost;s nothing else worth working on in science.&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="nothing" lemma="nothing" stem="noth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="else" lemma="else" stem="els" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="worth" lemma="worth" stem="worth" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="working" lemma="work" stem="work" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="science" lemma="science" stem="scienc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (CC But) (NP (EX there)) (VP (VBZ 's) (ADJP (NN nothing) (JJ else)) (PP (JJ worth) (S (VP (VBG working) (PP (IN on) (PP (IN in) (NP (NN science)))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="there" type="NP">
          <tokens>
            <token id="3" string="there" />
          </tokens>
        </chunking>
        <chunking id="2" string="science" type="NP">
          <tokens>
            <token id="11" string="science" />
          </tokens>
        </chunking>
        <chunking id="3" string="'s nothing else worth working on in science" type="VP">
          <tokens>
            <token id="4" string="'s" />
            <token id="5" string="nothing" />
            <token id="6" string="else" />
            <token id="7" string="worth" />
            <token id="8" string="working" />
            <token id="9" string="on" />
            <token id="10" string="in" />
            <token id="11" string="science" />
          </tokens>
        </chunking>
        <chunking id="4" string="nothing else" type="ADJP">
          <tokens>
            <token id="5" string="nothing" />
            <token id="6" string="else" />
          </tokens>
        </chunking>
        <chunking id="5" string="working on in science" type="VP">
          <tokens>
            <token id="8" string="working" />
            <token id="9" string="on" />
            <token id="10" string="in" />
            <token id="11" string="science" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="4">'s</governor>
          <dependent id="2">But</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="4">'s</governor>
          <dependent id="3">there</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">'s</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="6">else</governor>
          <dependent id="5">nothing</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">'s</governor>
          <dependent id="6">else</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">working</governor>
          <dependent id="7">worth</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">'s</governor>
          <dependent id="8">working</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">science</governor>
          <dependent id="9">on</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">science</governor>
          <dependent id="10">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">working</governor>
          <dependent id="11">science</dependent>
        </dependency>
      </dependencies>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="1" type="PROPER">
      <referenced ids_tokens="34" string="Max" id_sentence="1" />
      <mentions>
        <mention ids_tokens="1" string="He" id_sentence="73" />
        <mention ids_tokens="3-14" string="a Siamese cat in Bristol , England , that died last spring" id_sentence="73" />
        <mention ids_tokens="2" string="his" id_sentence="74" />
      </mentions>
    </coreference>
    <coreference id="2" type="NOMINAL">
      <referenced ids_tokens="27-28-29" string="ancient life forms" id_sentence="1" />
      <mentions>
        <mention ids_tokens="13-14" string="mad cows" id_sentence="68" />
        <mention ids_tokens="2-4" string="the mad cows" id_sentence="70" />
        <mention ids_tokens="18" string="cows" id_sentence="75" />
      </mentions>
    </coreference>
    <coreference id="3" type="NOMINAL">
      <referenced ids_tokens="20-21" string="its carriers" id_sentence="89" />
      <mentions>
        <mention ids_tokens="2" string="they" id_sentence="91" />
        <mention ids_tokens="4" string="we" id_sentence="92" />
      </mentions>
    </coreference>
    <coreference id="4" type="NOMINAL">
      <referenced ids_tokens="14-15-16" string="a single disorder" id_sentence="2" />
      <mentions>
        <mention ids_tokens="5-7" string="the disorder sometimes" id_sentence="10" />
      </mentions>
    </coreference>
    <coreference id="5" type="PROPER">
      <referenced ids_tokens="4-5-6-7" string="decades of detective work" id_sentence="6" />
      <mentions>
        <mention ids_tokens="9" string="decades" id_sentence="52" />
      </mentions>
    </coreference>
    <coreference id="6" type="NOMINAL">
      <referenced ids_tokens="6-7" string="detective work" id_sentence="6" />
      <mentions>
        <mention ids_tokens="1-2" string="The work" id_sentence="8" />
      </mentions>
    </coreference>
    <coreference id="7" type="PROPER">
      <referenced ids_tokens="11-12-13-14-15-16-17-18-19-20-21-22-23-24-25-26-27-28-29-30-31-32-33-34-35-36-37-38-39-40" string="Dr. Gajdusek : Why has the genetic defect , which has apparently existed for decades in some Eastern Europeans , turned deadly only in the past 15 years or so" id_sentence="91" />
      <mentions>
        <mention ids_tokens="12" string="he" id_sentence="92" />
      </mentions>
    </coreference>
    <coreference id="8" type="NOMINAL">
      <referenced ids_tokens="9-10" string="medical sleuths" id_sentence="6" />
      <mentions>
        <mention ids_tokens="1" string="Their" id_sentence="7" />
      </mentions>
    </coreference>
    <coreference id="14" type="NOMINAL">
      <referenced ids_tokens="8-9-10-11-12-13-14-15" string="grips scientists with a kind of obsessive fascination" id_sentence="10" />
      <mentions>
        <mention ids_tokens="1" string="Scientists" id_sentence="17" />
        <mention ids_tokens="32" string="scientists" id_sentence="33" />
        <mention ids_tokens="22" string="scientists" id_sentence="34" />
        <mention ids_tokens="8" string="scientists" id_sentence="51" />
        <mention ids_tokens="6" string="scientists" id_sentence="56" />
        <mention ids_tokens="1" string="Scientists" id_sentence="82" />
      </mentions>
    </coreference>
    <coreference id="15" type="PROPER">
      <referenced ids_tokens="18-19-20-21-22" string="NIH researcher D. Carleton Gajdusek" id_sentence="10" />
      <mentions>
        <mention ids_tokens="1" string="He" id_sentence="11" />
        <mention ids_tokens="19-20" string="Dr. Gajdusek" id_sentence="18" />
        <mention ids_tokens="4-18" string="the NIH's Dr. Gajdusek , then a young scientist casting about for big questions" id_sentence="35" />
        <mention ids_tokens="4-8" string="the NIH's Dr. Gajdusek" id_sentence="35" />
        <mention ids_tokens="8" string="Gajdusek" id_sentence="35" />
        <mention ids_tokens="10-18" string="then a young scientist casting about for big questions" id_sentence="35" />
        <mention ids_tokens="1" string="He" id_sentence="36" />
        <mention ids_tokens="4" string="he" id_sentence="37" />
        <mention ids_tokens="3" string="he" id_sentence="38" />
        <mention ids_tokens="1-2" string="&quot; Gajdusek" id_sentence="39" />
        <mention ids_tokens="53" string="he" id_sentence="39" />
        <mention ids_tokens="4" string="he" id_sentence="40" />
        <mention ids_tokens="20-21" string="Dr. Gajdusek" id_sentence="41" />
        <mention ids_tokens="1" string="He" id_sentence="42" />
        <mention ids_tokens="1" string="He" id_sentence="43" />
        <mention ids_tokens="6-11" string="Dr. Gajdusek , back at NIH" id_sentence="49" />
        <mention ids_tokens="6-7" string="Dr. Gajdusek" id_sentence="49" />
        <mention ids_tokens="7" string="Gajdusek" id_sentence="49" />
        <mention ids_tokens="4" string="Gajdusek" id_sentence="86" />
      </mentions>
    </coreference>
    <coreference id="16" type="LIST">
      <referenced ids_tokens="16-17-18" string="humans and animals" id_sentence="12" />
      <mentions>
        <mention ids_tokens="28" string="they" id_sentence="13" />
        <mention ids_tokens="28" string="they" id_sentence="14" />
      </mentions>
    </coreference>
    <coreference id="17" type="NOMINAL">
      <referenced ids_tokens="27-28-29" string="a longstanding question" id_sentence="12" />
      <mentions>
        <mention ids_tokens="1-2" string="The question" id_sentence="13" />
      </mentions>
    </coreference>
    <coreference id="19" type="NOMINAL">
      <referenced ids_tokens="24-25" string="the animals" id_sentence="14" />
      <mentions>
        <mention ids_tokens="37" string="animals" id_sentence="12" />
        <mention ids_tokens="10" string="animals" id_sentence="17" />
      </mentions>
    </coreference>
    <coreference id="20" type="PROPER">
      <referenced ids_tokens="1" string="Scrapie" id_sentence="18" />
      <mentions>
        <mention ids_tokens="9-17" string="scrapie , the form of the disease in sheep" id_sentence="13" />
        <mention ids_tokens="11-17" string="the form of the disease in sheep" id_sentence="13" />
        <mention ids_tokens="8-12" string="scrapie , the sheep disease" id_sentence="47" />
      </mentions>
    </coreference>
    <coreference id="21" type="PROPER">
      <referenced ids_tokens="7-8-9" string="our sheep disease" id_sentence="31" />
      <mentions>
        <mention ids_tokens="14-17" string="the disease in sheep" id_sentence="13" />
        <mention ids_tokens="10-12" string="the sheep disease" id_sentence="47" />
      </mentions>
    </coreference>
    <coreference id="22" type="PROPER">
      <referenced ids_tokens="18-19-20-21-22-23-24-25-26-27-28-29-30" string="cow &quot; disease , which makes the animals jittery before they keel over" id_sentence="14" />
      <mentions>
        <mention ids_tokens="7-10" string="the disease in animals" id_sentence="17" />
      </mentions>
    </coreference>
    <coreference id="23" type="PROPER">
      <referenced ids_tokens="6-7" string="the first" id_sentence="15" />
      <mentions>
        <mention ids_tokens="3" string="first" id_sentence="22" />
        <mention ids_tokens="10" string="first" id_sentence="33" />
        <mention ids_tokens="23" string="first" id_sentence="79" />
      </mentions>
    </coreference>
    <coreference id="25" type="NOMINAL">
      <referenced ids_tokens="14-15-16" string="its infectious agent" id_sentence="18" />
      <mentions>
        <mention ids_tokens="2-4" string="the infectious agent" id_sentence="51" />
        <mention ids_tokens="4-5" string="the agent" id_sentence="54" />
        <mention ids_tokens="5-6" string="the agent" id_sentence="69" />
        <mention ids_tokens="30-31" string="the agent" id_sentence="89" />
      </mentions>
    </coreference>
    <coreference id="26" type="PROPER">
      <referenced ids_tokens="5" string="CJD" id_sentence="27" />
      <mentions>
        <mention ids_tokens="1" string="That" id_sentence="32" />
        <mention ids_tokens="3-6" string="a leap of folklore" id_sentence="32" />
        <mention ids_tokens="24-31" string="CJD when they are exposed to the agent" id_sentence="89" />
      </mentions>
    </coreference>
    <coreference id="27" type="NOMINAL">
      <referenced ids_tokens="9-10-11-12-13-14-15-16-17-18-19-20-21-22" string="cases of the human form of the disease , Creutzfeldt-Jakob disease , or CJD" id_sentence="19" />
      <mentions>
        <mention ids_tokens="19" string="cases" id_sentence="21" />
      </mentions>
    </coreference>
    <coreference id="28" type="PROPER">
      <referenced ids_tokens="6" string="Poltar" id_sentence="20" />
      <mentions>
        <mention ids_tokens="21" string="she" id_sentence="21" />
      </mentions>
    </coreference>
    <coreference id="30" type="PROPER">
      <referenced ids_tokens="27-28" string="eastern Czechoslovakia" id_sentence="20" />
      <mentions>
        <mention ids_tokens="6" string="Czechoslovakia" id_sentence="87" />
      </mentions>
    </coreference>
    <coreference id="31" type="PROPER">
      <referenced ids_tokens="2-3-4-5-6-7-8-9-10-11" string="Dr. Mitrova , a researcher at a Bratislava medical institute" id_sentence="21" />
      <mentions>
        <mention ids_tokens="13-14" string="Dr. Mitrova" id_sentence="29" />
        <mention ids_tokens="23-24" string="Dr. Mitrova" id_sentence="32" />
        <mention ids_tokens="13-14" string="Dr. Mitrova" id_sentence="79" />
        <mention ids_tokens="14" string="Mitrova" id_sentence="79" />
      </mentions>
    </coreference>
    <coreference id="34" type="NOMINAL">
      <referenced ids_tokens="1-2-3" string="The area 's" id_sentence="24" />
      <mentions>
        <mention ids_tokens="32-33" string="the area" id_sentence="38" />
      </mentions>
    </coreference>
    <coreference id="36" type="NOMINAL">
      <referenced ids_tokens="9-10-11-12-13-14-15-16-17-18-19-20-21-22-23" string="the first reported case of the disease , which entered medical texts in the 1920s" id_sentence="33" />
      <mentions>
        <mention ids_tokens="2" string="it" id_sentence="34" />
        <mention ids_tokens="29" string="it" id_sentence="34" />
      </mentions>
    </coreference>
    <coreference id="37" type="PROPER">
      <referenced ids_tokens="17-18-19" string="world-wide each year" id_sentence="34" />
      <mentions>
        <mention ids_tokens="1-2" string="That year" id_sentence="35" />
      </mentions>
    </coreference>
    <coreference id="38" type="PROPER">
      <referenced ids_tokens="24-25-26" string="Papua New Guinea" id_sentence="35" />
      <mentions>
        <mention ids_tokens="9-10" string="New Guinea" id_sentence="37" />
      </mentions>
    </coreference>
    <coreference id="39" type="PROPER">
      <referenced ids_tokens="4-5-6" string="the NIH 's" id_sentence="35" />
      <mentions>
        <mention ids_tokens="20-21" string="the NIH" id_sentence="47" />
        <mention ids_tokens="11" string="NIH" id_sentence="48" />
        <mention ids_tokens="11" string="NIH" id_sentence="49" />
        <mention ids_tokens="11" string="NIH" id_sentence="55" />
        <mention ids_tokens="8" string="NIH" id_sentence="79" />
      </mentions>
    </coreference>
    <coreference id="42" type="NOMINAL">
      <referenced ids_tokens="12-13-14" string="a local doctor" id_sentence="38" />
      <mentions>
        <mention ids_tokens="3-5" string="the local doctor" id_sentence="43" />
      </mentions>
    </coreference>
    <coreference id="43" type="NOMINAL">
      <referenced ids_tokens="2-3-4-5" string="kuru victims ' brains" id_sentence="41" />
      <mentions>
        <mention ids_tokens="15-16" string="kuru brains" id_sentence="48" />
        <mention ids_tokens="33" string="brains" id_sentence="50" />
        <mention ids_tokens="13" string="brains" id_sentence="75" />
      </mentions>
    </coreference>
    <coreference id="44" type="NOMINAL">
      <referenced ids_tokens="2-3-4" string="kuru victims '" id_sentence="41" />
      <mentions>
        <mention ids_tokens="1-2" string="Kuru victims" id_sentence="71" />
      </mentions>
    </coreference>
    <coreference id="47" type="PROPER">
      <referenced ids_tokens="5-6" string="William Hadlow" id_sentence="46" />
      <mentions>
        <mention ids_tokens="1" string="He" id_sentence="47" />
      </mentions>
    </coreference>
    <coreference id="51" type="NOMINAL">
      <referenced ids_tokens="4-5-6" string="a long-suspected connection" id_sentence="50" />
      <mentions>
        <mention ids_tokens="1" string="It" id_sentence="52" />
      </mentions>
    </coreference>
    <coreference id="53" type="NOMINAL">
      <referenced ids_tokens="13-14-15-16" string="different animals ' brains" id_sentence="53" />
      <mentions>
        <mention ids_tokens="7-9" string="animals' brains" id_sentence="64" />
      </mentions>
    </coreference>
    <coreference id="54" type="NOMINAL">
      <referenced ids_tokens="13-14-15" string="different animals '" id_sentence="53" />
      <mentions>
        <mention ids_tokens="7-8" string="animals'" id_sentence="64" />
      </mentions>
    </coreference>
    <coreference id="55" type="NOMINAL">
      <referenced ids_tokens="11-12-13" string="no known exposure" id_sentence="54" />
      <mentions>
        <mention ids_tokens="1" string="It" id_sentence="55" />
      </mentions>
    </coreference>
    <coreference id="56" type="PROPER">
      <referenced ids_tokens="31-32-33-34-35" string="the NIH 's Dr. Brown" id_sentence="61" />
      <mentions>
        <mention ids_tokens="11-14" string="NIH researcher Paul Brown" id_sentence="55" />
        <mention ids_tokens="12-13" string="Dr. Brown" id_sentence="63" />
        <mention ids_tokens="1" string="He" id_sentence="64" />
        <mention ids_tokens="3-4" string="Dr. Brown" id_sentence="68" />
        <mention ids_tokens="4" string="Brown" id_sentence="68" />
        <mention ids_tokens="19-20" string="Dr. Brown" id_sentence="70" />
        <mention ids_tokens="2-4" string="Dr. Brown's" id_sentence="83" />
        <mention ids_tokens="7" string="he" id_sentence="84" />
        <mention ids_tokens="2" string="Brown" id_sentence="86" />
      </mentions>
    </coreference>
    <coreference id="57" type="NOMINAL">
      <referenced ids_tokens="19-20-21-22-23-24-25-26-27-28-29-30-31" string="the brain with a kind of junk , or &quot; amyloid , &quot;" id_sentence="56" />
      <mentions>
        <mention ids_tokens="2-3" string="his brain" id_sentence="74" />
      </mentions>
    </coreference>
    <coreference id="58" type="NOMINAL">
      <referenced ids_tokens="4-5" string="the junk" id_sentence="57" />
      <mentions>
        <mention ids_tokens="25-31" string="junk , or &quot; amyloid , &quot;" id_sentence="56" />
        <mention ids_tokens="5" string="it" id_sentence="58" />
      </mentions>
    </coreference>
    <coreference id="59" type="NOMINAL">
      <referenced ids_tokens="1-2" string="Many scientists" id_sentence="58" />
      <mentions>
        <mention ids_tokens="2" string="their" id_sentence="59" />
        <mention ids_tokens="2" string="they" id_sentence="60" />
      </mentions>
    </coreference>
    <coreference id="61" type="NOMINAL">
      <referenced ids_tokens="6-7-8" string="such self-replicating proteins" id_sentence="60" />
      <mentions>
        <mention ids_tokens="32" string="proteins" id_sentence="63" />
      </mentions>
    </coreference>
    <coreference id="62" type="NOMINAL">
      <referenced ids_tokens="14-15-16-17-18-19-20-21-22-23-24-25-26-27-28-29-30-31-32" string="baked isolates of the disease agent for an hour at 680 degrees Fahrenheit , a temperature that melts proteins" id_sentence="63" />
      <mentions>
        <mention ids_tokens="5" string="them" id_sentence="65" />
        <mention ids_tokens="4" string="isolates" id_sentence="66" />
        <mention ids_tokens="13" string="they" id_sentence="66" />
      </mentions>
    </coreference>
    <coreference id="64" type="NOMINAL">
      <referenced ids_tokens="2-3-4-5" string="a few of them" id_sentence="65" />
      <mentions>
        <mention ids_tokens="1" string="He" id_sentence="66" />
        <mention ids_tokens="6" string="his" id_sentence="66" />
        <mention ids_tokens="10" string="he" id_sentence="67" />
      </mentions>
    </coreference>
    <coreference id="65" type="LIST">
      <referenced ids_tokens="3-4-5-6-7" string="Dr. Brown and other scientists" id_sentence="68" />
      <mentions>
        <mention ids_tokens="11" string="they" id_sentence="70" />
      </mentions>
    </coreference>
    <coreference id="66" type="NOMINAL">
      <referenced ids_tokens="6-7" string="other scientists" id_sentence="68" />
      <mentions>
        <mention ids_tokens="5-6" string="the scientists" id_sentence="80" />
      </mentions>
    </coreference>
    <coreference id="72" type="NOMINAL">
      <referenced ids_tokens="7-8-9" string="the NIH team" id_sentence="79" />
      <mentions>
        <mention ids_tokens="4-5" string="the team" id_sentence="88" />
      </mentions>
    </coreference>
    <coreference id="73" type="NOMINAL">
      <referenced ids_tokens="1-2" string="The discovery" id_sentence="80" />
      <mentions>
        <mention ids_tokens="2" string="itself" id_sentence="81" />
        <mention ids_tokens="4" string="that" id_sentence="81" />
      </mentions>
    </coreference>
    <coreference id="74" type="NOMINAL">
      <referenced ids_tokens="9-10-11-12-13-14-15-16-17-18-19-20" string="a genetic defect in two U.S. brothers who had died of CJD" id_sentence="80" />
      <mentions>
        <mention ids_tokens="16-18" string="the genetic defect" id_sentence="91" />
      </mentions>
    </coreference>
    <coreference id="75" type="NOMINAL">
      <referenced ids_tokens="8-9-10-11-12-13" string="three other , unrelated CJD victims" id_sentence="83" />
      <mentions>
        <mention ids_tokens="11" string="I" id_sentence="84" />
        <mention ids_tokens="15-16" string="the victims" id_sentence="84" />
        <mention ids_tokens="1" string="They" id_sentence="85" />
      </mentions>
    </coreference>
    <coreference id="76" type="NOMINAL">
      <referenced ids_tokens="18-19-20-21" string="the same genetic defect" id_sentence="83" />
      <mentions>
        <mention ids_tokens="28-29" string="the defect" id_sentence="88" />
        <mention ids_tokens="10-11" string="the defect" id_sentence="89" />
        <mention ids_tokens="18" string="it" id_sentence="89" />
        <mention ids_tokens="20" string="its" id_sentence="89" />
      </mentions>
    </coreference>
    <coreference id="77" type="LIST">
      <referenced ids_tokens="1-2-3-4" string="Drs. Brown and Gajdusek" id_sentence="86" />
      <mentions>
        <mention ids_tokens="1" string="They" id_sentence="87" />
      </mentions>
    </coreference>
  </coreferences>
</document>
