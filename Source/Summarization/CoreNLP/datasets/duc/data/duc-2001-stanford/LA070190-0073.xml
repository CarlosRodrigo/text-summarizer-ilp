<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="LA070190-0073">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>Tetsuya Theodore Fujita saw his only natural tornado near Denver in 1982.</content>
      <tokens>
        <token id="1" string="Tetsuya" lemma="Tetsuya" stem="tetsuya" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="Theodore" lemma="Theodore" stem="theodor" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="Fujita" lemma="Fujita" stem="fujita" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="4" string="saw" lemma="see" stem="saw" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="only" lemma="only" stem="onli" pos="JJ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="natural" lemma="natural" stem="natur" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="tornado" lemma="tornado" stem="tornado" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="true" is_refers="false" />
        <token id="9" string="near" lemma="near" stem="near" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="Denver" lemma="Denver" stem="denver" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="11" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="1982" lemma="1982" stem="1982" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Tetsuya) (NNP Theodore) (NNP Fujita)) (VP (VBD saw) (NP (PRP$ his) (JJ only) (JJ natural) (NN tornado)) (PP (IN near) (NP (NNP Denver))) (PP (IN in) (NP (CD 1982)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="his only natural tornado" type="NP">
          <tokens>
            <token id="5" string="his" />
            <token id="6" string="only" />
            <token id="7" string="natural" />
            <token id="8" string="tornado" />
          </tokens>
        </chunking>
        <chunking id="2" string="1982" type="NP">
          <tokens>
            <token id="12" string="1982" />
          </tokens>
        </chunking>
        <chunking id="3" string="Tetsuya Theodore Fujita" type="NP">
          <tokens>
            <token id="1" string="Tetsuya" />
            <token id="2" string="Theodore" />
            <token id="3" string="Fujita" />
          </tokens>
        </chunking>
        <chunking id="4" string="Denver" type="NP">
          <tokens>
            <token id="10" string="Denver" />
          </tokens>
        </chunking>
        <chunking id="5" string="saw his only natural tornado near Denver in 1982" type="VP">
          <tokens>
            <token id="4" string="saw" />
            <token id="5" string="his" />
            <token id="6" string="only" />
            <token id="7" string="natural" />
            <token id="8" string="tornado" />
            <token id="9" string="near" />
            <token id="10" string="Denver" />
            <token id="11" string="in" />
            <token id="12" string="1982" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">Fujita</governor>
          <dependent id="1">Tetsuya</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Fujita</governor>
          <dependent id="2">Theodore</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">saw</governor>
          <dependent id="3">Fujita</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">saw</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">tornado</governor>
          <dependent id="5">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">tornado</governor>
          <dependent id="6">only</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">tornado</governor>
          <dependent id="7">natural</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">saw</governor>
          <dependent id="8">tornado</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">Denver</governor>
          <dependent id="9">near</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">saw</governor>
          <dependent id="10">Denver</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">1982</governor>
          <dependent id="11">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">saw</governor>
          <dependent id="12">1982</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="tornado" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="8" string="tornado" />
          </tokens>
        </entity>
        <entity id="2" string="1982" type="DATE" score="0.0">
          <tokens>
            <token id="12" string="1982" />
          </tokens>
        </entity>
        <entity id="3" string="Tetsuya Theodore Fujita" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Tetsuya" />
            <token id="2" string="Theodore" />
            <token id="3" string="Fujita" />
          </tokens>
        </entity>
        <entity id="4" string="Denver" type="LOCATION" score="0.0">
          <tokens>
            <token id="10" string="Denver" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>&amp;quot;It was like meeting my lover,&amp;quot; he says.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="meeting" lemma="meeting" stem="meet" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="my" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="7" string="lover" lemma="lover" stem="lover" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP It)) (VP (VBD was) (PP (IN like) (NP (NN meeting) (PRP$ my) (NN lover))))) (, ,) ('' '') (NP (PRP he)) (VP (VBZ says)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="says" type="VP">
          <tokens>
            <token id="11" string="says" />
          </tokens>
        </chunking>
        <chunking id="2" string="It" type="NP">
          <tokens>
            <token id="2" string="It" />
          </tokens>
        </chunking>
        <chunking id="3" string="meeting my lover" type="NP">
          <tokens>
            <token id="5" string="meeting" />
            <token id="6" string="my" />
            <token id="7" string="lover" />
          </tokens>
        </chunking>
        <chunking id="4" string="was like meeting my lover" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="like" />
            <token id="5" string="meeting" />
            <token id="6" string="my" />
            <token id="7" string="lover" />
          </tokens>
        </chunking>
        <chunking id="5" string="he" type="NP">
          <tokens>
            <token id="10" string="he" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="7">lover</governor>
          <dependent id="2">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">lover</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">lover</governor>
          <dependent id="4">like</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">lover</governor>
          <dependent id="5">meeting</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="7">lover</governor>
          <dependent id="6">my</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">says</governor>
          <dependent id="7">lover</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">says</governor>
          <dependent id="10">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">says</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>&amp;quot;Since then, my passion really went up,&amp;quot; said Fujita, a professor of geophysical science who has been studying tornadoes for 42 years and is considered one of the world&amp;apost;s foremost authorities on the violent storms.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Since" lemma="since" stem="sinc" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="my" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="passion" lemma="passion" stem="passion" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="really" lemma="really" stem="realli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="went" lemma="go" stem="went" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="up" lemma="up" stem="up" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="Fujita" lemma="Fujita" stem="fujita" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="professor" lemma="professor" stem="professor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="geophysical" lemma="geophysical" stem="geophys" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="19" string="science" lemma="science" stem="scienc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="studying" lemma="study" stem="studi" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="24" string="tornadoes" lemma="tornado" stem="tornado" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="25" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="26" string="42" lemma="42" stem="42" pos="CD" type="Number" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="true" />
        <token id="27" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="true" />
        <token id="28" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="29" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="30" string="considered" lemma="consider" stem="consid" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="31" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="true" />
        <token id="32" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="33" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="34" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="35" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="36" string="foremost" lemma="foremost" stem="foremost" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="37" string="authorities" lemma="authority" stem="author" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="38" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="39" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="40" string="violent" lemma="violent" stem="violent" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="41" string="storms" lemma="storm" stem="storm" pos="NNS" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="true" />
        <token id="42" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (PP (IN Since) (NP (RB then))) (, ,) (NP (PRP$ my) (NN passion)) (ADVP (RB really)) (VP (VBD went) (ADVP (RB up)))) (, ,) ('' '') (VP (VBD said)) (NP (NP (NNP Fujita)) (, ,) (NP (NP (DT a) (NN professor)) (PP (IN of) (NP (JJ geophysical) (NN science))) (SBAR (WHNP (WP who)) (S (VP (VP (VBZ has) (VP (VBN been) (VP (VBG studying) (NP (NP (NNS tornadoes)) (PP (IN for) (NP (CD 42) (NNS years))))))) (CC and) (VP (VBZ is) (VP (VBN considered) (NP (NP (CD one)) (PP (IN of) (NP (NP (DT the) (NN world) (POS 's)) (JJ foremost) (NNS authorities)))) (PP (IN on) (NP (DT the) (JJ violent) (NNS storms)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="went up" type="VP">
          <tokens>
            <token id="8" string="went" />
            <token id="9" string="up" />
          </tokens>
        </chunking>
        <chunking id="2" string="tornadoes" type="NP">
          <tokens>
            <token id="24" string="tornadoes" />
          </tokens>
        </chunking>
        <chunking id="3" string="one" type="NP">
          <tokens>
            <token id="31" string="one" />
          </tokens>
        </chunking>
        <chunking id="4" string="a professor of geophysical science who has been studying tornadoes for 42 years and is considered one of the world 's foremost authorities on the violent storms" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="professor" />
            <token id="17" string="of" />
            <token id="18" string="geophysical" />
            <token id="19" string="science" />
            <token id="20" string="who" />
            <token id="21" string="has" />
            <token id="22" string="been" />
            <token id="23" string="studying" />
            <token id="24" string="tornadoes" />
            <token id="25" string="for" />
            <token id="26" string="42" />
            <token id="27" string="years" />
            <token id="28" string="and" />
            <token id="29" string="is" />
            <token id="30" string="considered" />
            <token id="31" string="one" />
            <token id="32" string="of" />
            <token id="33" string="the" />
            <token id="34" string="world" />
            <token id="35" string="'s" />
            <token id="36" string="foremost" />
            <token id="37" string="authorities" />
            <token id="38" string="on" />
            <token id="39" string="the" />
            <token id="40" string="violent" />
            <token id="41" string="storms" />
          </tokens>
        </chunking>
        <chunking id="5" string="been studying tornadoes for 42 years" type="VP">
          <tokens>
            <token id="22" string="been" />
            <token id="23" string="studying" />
            <token id="24" string="tornadoes" />
            <token id="25" string="for" />
            <token id="26" string="42" />
            <token id="27" string="years" />
          </tokens>
        </chunking>
        <chunking id="6" string="tornadoes for 42 years" type="NP">
          <tokens>
            <token id="24" string="tornadoes" />
            <token id="25" string="for" />
            <token id="26" string="42" />
            <token id="27" string="years" />
          </tokens>
        </chunking>
        <chunking id="7" string="the world 's foremost authorities" type="NP">
          <tokens>
            <token id="33" string="the" />
            <token id="34" string="world" />
            <token id="35" string="'s" />
            <token id="36" string="foremost" />
            <token id="37" string="authorities" />
          </tokens>
        </chunking>
        <chunking id="8" string="then" type="NP">
          <tokens>
            <token id="3" string="then" />
          </tokens>
        </chunking>
        <chunking id="9" string="geophysical science" type="NP">
          <tokens>
            <token id="18" string="geophysical" />
            <token id="19" string="science" />
          </tokens>
        </chunking>
        <chunking id="10" string="is considered one of the world 's foremost authorities on the violent storms" type="VP">
          <tokens>
            <token id="29" string="is" />
            <token id="30" string="considered" />
            <token id="31" string="one" />
            <token id="32" string="of" />
            <token id="33" string="the" />
            <token id="34" string="world" />
            <token id="35" string="'s" />
            <token id="36" string="foremost" />
            <token id="37" string="authorities" />
            <token id="38" string="on" />
            <token id="39" string="the" />
            <token id="40" string="violent" />
            <token id="41" string="storms" />
          </tokens>
        </chunking>
        <chunking id="11" string="studying tornadoes for 42 years" type="VP">
          <tokens>
            <token id="23" string="studying" />
            <token id="24" string="tornadoes" />
            <token id="25" string="for" />
            <token id="26" string="42" />
            <token id="27" string="years" />
          </tokens>
        </chunking>
        <chunking id="12" string="the violent storms" type="NP">
          <tokens>
            <token id="39" string="the" />
            <token id="40" string="violent" />
            <token id="41" string="storms" />
          </tokens>
        </chunking>
        <chunking id="13" string="my passion" type="NP">
          <tokens>
            <token id="5" string="my" />
            <token id="6" string="passion" />
          </tokens>
        </chunking>
        <chunking id="14" string="Fujita" type="NP">
          <tokens>
            <token id="13" string="Fujita" />
          </tokens>
        </chunking>
        <chunking id="15" string="one of the world 's foremost authorities" type="NP">
          <tokens>
            <token id="31" string="one" />
            <token id="32" string="of" />
            <token id="33" string="the" />
            <token id="34" string="world" />
            <token id="35" string="'s" />
            <token id="36" string="foremost" />
            <token id="37" string="authorities" />
          </tokens>
        </chunking>
        <chunking id="16" string="who has been studying tornadoes for 42 years and is considered one of the world 's foremost authorities on the violent storms" type="SBAR">
          <tokens>
            <token id="20" string="who" />
            <token id="21" string="has" />
            <token id="22" string="been" />
            <token id="23" string="studying" />
            <token id="24" string="tornadoes" />
            <token id="25" string="for" />
            <token id="26" string="42" />
            <token id="27" string="years" />
            <token id="28" string="and" />
            <token id="29" string="is" />
            <token id="30" string="considered" />
            <token id="31" string="one" />
            <token id="32" string="of" />
            <token id="33" string="the" />
            <token id="34" string="world" />
            <token id="35" string="'s" />
            <token id="36" string="foremost" />
            <token id="37" string="authorities" />
            <token id="38" string="on" />
            <token id="39" string="the" />
            <token id="40" string="violent" />
            <token id="41" string="storms" />
          </tokens>
        </chunking>
        <chunking id="17" string="Fujita , a professor of geophysical science who has been studying tornadoes for 42 years and is considered one of the world 's foremost authorities on the violent storms" type="NP">
          <tokens>
            <token id="13" string="Fujita" />
            <token id="14" string="," />
            <token id="15" string="a" />
            <token id="16" string="professor" />
            <token id="17" string="of" />
            <token id="18" string="geophysical" />
            <token id="19" string="science" />
            <token id="20" string="who" />
            <token id="21" string="has" />
            <token id="22" string="been" />
            <token id="23" string="studying" />
            <token id="24" string="tornadoes" />
            <token id="25" string="for" />
            <token id="26" string="42" />
            <token id="27" string="years" />
            <token id="28" string="and" />
            <token id="29" string="is" />
            <token id="30" string="considered" />
            <token id="31" string="one" />
            <token id="32" string="of" />
            <token id="33" string="the" />
            <token id="34" string="world" />
            <token id="35" string="'s" />
            <token id="36" string="foremost" />
            <token id="37" string="authorities" />
            <token id="38" string="on" />
            <token id="39" string="the" />
            <token id="40" string="violent" />
            <token id="41" string="storms" />
          </tokens>
        </chunking>
        <chunking id="18" string="42 years" type="NP">
          <tokens>
            <token id="26" string="42" />
            <token id="27" string="years" />
          </tokens>
        </chunking>
        <chunking id="19" string="considered one of the world 's foremost authorities on the violent storms" type="VP">
          <tokens>
            <token id="30" string="considered" />
            <token id="31" string="one" />
            <token id="32" string="of" />
            <token id="33" string="the" />
            <token id="34" string="world" />
            <token id="35" string="'s" />
            <token id="36" string="foremost" />
            <token id="37" string="authorities" />
            <token id="38" string="on" />
            <token id="39" string="the" />
            <token id="40" string="violent" />
            <token id="41" string="storms" />
          </tokens>
        </chunking>
        <chunking id="20" string="a professor" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="professor" />
          </tokens>
        </chunking>
        <chunking id="21" string="said" type="VP">
          <tokens>
            <token id="12" string="said" />
          </tokens>
        </chunking>
        <chunking id="22" string="has been studying tornadoes for 42 years" type="VP">
          <tokens>
            <token id="21" string="has" />
            <token id="22" string="been" />
            <token id="23" string="studying" />
            <token id="24" string="tornadoes" />
            <token id="25" string="for" />
            <token id="26" string="42" />
            <token id="27" string="years" />
          </tokens>
        </chunking>
        <chunking id="23" string="has been studying tornadoes for 42 years and is considered one of the world 's foremost authorities on the violent storms" type="VP">
          <tokens>
            <token id="21" string="has" />
            <token id="22" string="been" />
            <token id="23" string="studying" />
            <token id="24" string="tornadoes" />
            <token id="25" string="for" />
            <token id="26" string="42" />
            <token id="27" string="years" />
            <token id="28" string="and" />
            <token id="29" string="is" />
            <token id="30" string="considered" />
            <token id="31" string="one" />
            <token id="32" string="of" />
            <token id="33" string="the" />
            <token id="34" string="world" />
            <token id="35" string="'s" />
            <token id="36" string="foremost" />
            <token id="37" string="authorities" />
            <token id="38" string="on" />
            <token id="39" string="the" />
            <token id="40" string="violent" />
            <token id="41" string="storms" />
          </tokens>
        </chunking>
        <chunking id="24" string="the world 's" type="NP">
          <tokens>
            <token id="33" string="the" />
            <token id="34" string="world" />
            <token id="35" string="'s" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">then</governor>
          <dependent id="2">Since</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">went</governor>
          <dependent id="3">then</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="6">passion</governor>
          <dependent id="5">my</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">went</governor>
          <dependent id="6">passion</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">went</governor>
          <dependent id="7">really</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="12">said</governor>
          <dependent id="8">went</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">went</governor>
          <dependent id="9">up</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">said</governor>
          <dependent id="13">Fujita</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">professor</governor>
          <dependent id="15">a</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="13">Fujita</governor>
          <dependent id="16">professor</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">science</governor>
          <dependent id="17">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">science</governor>
          <dependent id="18">geophysical</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">professor</governor>
          <dependent id="19">science</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">studying</governor>
          <dependent id="20">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="23">studying</governor>
          <dependent id="21">has</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="23">studying</governor>
          <dependent id="22">been</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="16">professor</governor>
          <dependent id="23">studying</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="23">studying</governor>
          <dependent id="24">tornadoes</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">years</governor>
          <dependent id="25">for</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="27">years</governor>
          <dependent id="26">42</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">tornadoes</governor>
          <dependent id="27">years</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="23">studying</governor>
          <dependent id="28">and</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="30">considered</governor>
          <dependent id="29">is</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="23">studying</governor>
          <dependent id="30">considered</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="30">considered</governor>
          <dependent id="31">one</dependent>
        </dependency>
        <dependency type="case">
          <governor id="37">authorities</governor>
          <dependent id="32">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="34">world</governor>
          <dependent id="33">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="37">authorities</governor>
          <dependent id="34">world</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">world</governor>
          <dependent id="35">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="37">authorities</governor>
          <dependent id="36">foremost</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">one</governor>
          <dependent id="37">authorities</dependent>
        </dependency>
        <dependency type="case">
          <governor id="41">storms</governor>
          <dependent id="38">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="41">storms</governor>
          <dependent id="39">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="41">storms</governor>
          <dependent id="40">violent</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">considered</governor>
          <dependent id="41">storms</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="31" string="one" />
          </tokens>
        </entity>
        <entity id="2" string="42 years" type="DURATION" score="0.0">
          <tokens>
            <token id="26" string="42" />
            <token id="27" string="years" />
          </tokens>
        </entity>
        <entity id="3" string="storms" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="41" string="storms" />
          </tokens>
        </entity>
        <entity id="4" string="Fujita" type="PERSON" score="0.0">
          <tokens>
            <token id="13" string="Fujita" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>Fujita, 69, spends much of his time in his lab at the University of Chicago creating tornadoes for research.</content>
      <tokens>
        <token id="1" string="Fujita" lemma="Fujita" stem="fujita" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="69" lemma="69" stem="69" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="true" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="spends" lemma="spend" stem="spend" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="much" lemma="much" stem="much" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="lab" lemma="lab" stem="lab" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="University" lemma="University" stem="univers" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="16" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="17" string="Chicago" lemma="Chicago" stem="chicago" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="18" string="creating" lemma="create" stem="creat" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="tornadoes" lemma="tornado" stem="tornado" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="research" lemma="research" stem="research" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Fujita)) (, ,) (NP (CD 69)) (, ,)) (VP (VBZ spends) (NP (NP (RB much)) (PP (IN of) (NP (NP (PRP$ his) (NN time)) (PP (IN in) (NP (PRP$ his) (NN lab)))))) (PP (IN at) (S (NP (NP (DT the) (NNP University)) (PP (IN of) (NP (NNP Chicago)))) (VP (VBG creating) (NP (NNS tornadoes)) (PP (IN for) (NP (NN research))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="spends much of his time in his lab at the University of Chicago creating tornadoes for research" type="VP">
          <tokens>
            <token id="5" string="spends" />
            <token id="6" string="much" />
            <token id="7" string="of" />
            <token id="8" string="his" />
            <token id="9" string="time" />
            <token id="10" string="in" />
            <token id="11" string="his" />
            <token id="12" string="lab" />
            <token id="13" string="at" />
            <token id="14" string="the" />
            <token id="15" string="University" />
            <token id="16" string="of" />
            <token id="17" string="Chicago" />
            <token id="18" string="creating" />
            <token id="19" string="tornadoes" />
            <token id="20" string="for" />
            <token id="21" string="research" />
          </tokens>
        </chunking>
        <chunking id="2" string="69" type="NP">
          <tokens>
            <token id="3" string="69" />
          </tokens>
        </chunking>
        <chunking id="3" string="the University of Chicago" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="University" />
            <token id="16" string="of" />
            <token id="17" string="Chicago" />
          </tokens>
        </chunking>
        <chunking id="4" string="Fujita , 69 ," type="NP">
          <tokens>
            <token id="1" string="Fujita" />
            <token id="2" string="," />
            <token id="3" string="69" />
            <token id="4" string="," />
          </tokens>
        </chunking>
        <chunking id="5" string="tornadoes" type="NP">
          <tokens>
            <token id="19" string="tornadoes" />
          </tokens>
        </chunking>
        <chunking id="6" string="his time" type="NP">
          <tokens>
            <token id="8" string="his" />
            <token id="9" string="time" />
          </tokens>
        </chunking>
        <chunking id="7" string="Chicago" type="NP">
          <tokens>
            <token id="17" string="Chicago" />
          </tokens>
        </chunking>
        <chunking id="8" string="his lab" type="NP">
          <tokens>
            <token id="11" string="his" />
            <token id="12" string="lab" />
          </tokens>
        </chunking>
        <chunking id="9" string="much of his time in his lab" type="NP">
          <tokens>
            <token id="6" string="much" />
            <token id="7" string="of" />
            <token id="8" string="his" />
            <token id="9" string="time" />
            <token id="10" string="in" />
            <token id="11" string="his" />
            <token id="12" string="lab" />
          </tokens>
        </chunking>
        <chunking id="10" string="Fujita" type="NP">
          <tokens>
            <token id="1" string="Fujita" />
          </tokens>
        </chunking>
        <chunking id="11" string="research" type="NP">
          <tokens>
            <token id="21" string="research" />
          </tokens>
        </chunking>
        <chunking id="12" string="his time in his lab" type="NP">
          <tokens>
            <token id="8" string="his" />
            <token id="9" string="time" />
            <token id="10" string="in" />
            <token id="11" string="his" />
            <token id="12" string="lab" />
          </tokens>
        </chunking>
        <chunking id="13" string="creating tornadoes for research" type="VP">
          <tokens>
            <token id="18" string="creating" />
            <token id="19" string="tornadoes" />
            <token id="20" string="for" />
            <token id="21" string="research" />
          </tokens>
        </chunking>
        <chunking id="14" string="the University" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="University" />
          </tokens>
        </chunking>
        <chunking id="15" string="much" type="NP">
          <tokens>
            <token id="6" string="much" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">spends</governor>
          <dependent id="1">Fujita</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="1">Fujita</governor>
          <dependent id="3">69</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">spends</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">spends</governor>
          <dependent id="6">much</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">time</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="9">time</governor>
          <dependent id="8">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">much</governor>
          <dependent id="9">time</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">lab</governor>
          <dependent id="10">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="12">lab</governor>
          <dependent id="11">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">time</governor>
          <dependent id="12">lab</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">creating</governor>
          <dependent id="13">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">University</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">creating</governor>
          <dependent id="15">University</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">Chicago</governor>
          <dependent id="16">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">University</governor>
          <dependent id="17">Chicago</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="5">spends</governor>
          <dependent id="18">creating</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">creating</governor>
          <dependent id="19">tornadoes</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">research</governor>
          <dependent id="20">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">creating</governor>
          <dependent id="21">research</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="University of Chicago" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="15" string="University" />
            <token id="16" string="of" />
            <token id="17" string="Chicago" />
          </tokens>
        </entity>
        <entity id="2" string="69" type="NUMBER" score="0.0">
          <tokens>
            <token id="3" string="69" />
          </tokens>
        </entity>
        <entity id="3" string="Fujita" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Fujita" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>He creates tornadoes over a large fan, which makes a swirling motion; another fan above simulates a low-pressure system by adding an updraft to the mix.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="creates" lemma="create" stem="creat" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="tornadoes" lemma="tornado" stem="tornado" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="over" lemma="over" stem="over" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="large" lemma="large" stem="larg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="fan" lemma="fan" stem="fan" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="makes" lemma="make" stem="make" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="swirling" lemma="swirl" stem="swirl" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="motion" lemma="motion" stem="motion" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="another" lemma="another" stem="anoth" pos="DT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="fan" lemma="fan" stem="fan" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="above" lemma="above" stem="abov" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="simulates" lemma="simulate" stem="simul" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="low-pressure" lemma="low-pressure" stem="low-pressur" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="system" lemma="system" stem="system" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="adding" lemma="add" stem="ad" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="updraft" lemma="updraft" stem="updraft" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="mix" lemma="mix" stem="mix" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP He)) (VP (VBZ creates) (NP (NP (NNS tornadoes)) (PP (IN over) (NP (NP (DT a) (JJ large) (NN fan)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ makes) (NP (DT a) (VBG swirling) (NN motion)))))))))) (: ;) (S (NP (DT another) (NN fan)) (VP (ADVP (IN above)) (VBZ simulates) (NP (DT a) (JJ low-pressure) (NN system)) (PP (IN by) (S (VP (VBG adding) (NP (DT an) (NN updraft)) (PP (TO to) (NP (DT the) (NN mix)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a large fan , which makes a swirling motion" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="large" />
            <token id="7" string="fan" />
            <token id="8" string="," />
            <token id="9" string="which" />
            <token id="10" string="makes" />
            <token id="11" string="a" />
            <token id="12" string="swirling" />
            <token id="13" string="motion" />
          </tokens>
        </chunking>
        <chunking id="2" string="a large fan" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="large" />
            <token id="7" string="fan" />
          </tokens>
        </chunking>
        <chunking id="3" string="which makes a swirling motion" type="SBAR">
          <tokens>
            <token id="9" string="which" />
            <token id="10" string="makes" />
            <token id="11" string="a" />
            <token id="12" string="swirling" />
            <token id="13" string="motion" />
          </tokens>
        </chunking>
        <chunking id="4" string="a swirling motion" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="swirling" />
            <token id="13" string="motion" />
          </tokens>
        </chunking>
        <chunking id="5" string="above simulates a low-pressure system by adding an updraft to the mix" type="VP">
          <tokens>
            <token id="17" string="above" />
            <token id="18" string="simulates" />
            <token id="19" string="a" />
            <token id="20" string="low-pressure" />
            <token id="21" string="system" />
            <token id="22" string="by" />
            <token id="23" string="adding" />
            <token id="24" string="an" />
            <token id="25" string="updraft" />
            <token id="26" string="to" />
            <token id="27" string="the" />
            <token id="28" string="mix" />
          </tokens>
        </chunking>
        <chunking id="6" string="tornadoes" type="NP">
          <tokens>
            <token id="3" string="tornadoes" />
          </tokens>
        </chunking>
        <chunking id="7" string="tornadoes over a large fan , which makes a swirling motion" type="NP">
          <tokens>
            <token id="3" string="tornadoes" />
            <token id="4" string="over" />
            <token id="5" string="a" />
            <token id="6" string="large" />
            <token id="7" string="fan" />
            <token id="8" string="," />
            <token id="9" string="which" />
            <token id="10" string="makes" />
            <token id="11" string="a" />
            <token id="12" string="swirling" />
            <token id="13" string="motion" />
          </tokens>
        </chunking>
        <chunking id="8" string="the mix" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="mix" />
          </tokens>
        </chunking>
        <chunking id="9" string="adding an updraft to the mix" type="VP">
          <tokens>
            <token id="23" string="adding" />
            <token id="24" string="an" />
            <token id="25" string="updraft" />
            <token id="26" string="to" />
            <token id="27" string="the" />
            <token id="28" string="mix" />
          </tokens>
        </chunking>
        <chunking id="10" string="makes a swirling motion" type="VP">
          <tokens>
            <token id="10" string="makes" />
            <token id="11" string="a" />
            <token id="12" string="swirling" />
            <token id="13" string="motion" />
          </tokens>
        </chunking>
        <chunking id="11" string="another fan" type="NP">
          <tokens>
            <token id="15" string="another" />
            <token id="16" string="fan" />
          </tokens>
        </chunking>
        <chunking id="12" string="creates tornadoes over a large fan , which makes a swirling motion" type="VP">
          <tokens>
            <token id="2" string="creates" />
            <token id="3" string="tornadoes" />
            <token id="4" string="over" />
            <token id="5" string="a" />
            <token id="6" string="large" />
            <token id="7" string="fan" />
            <token id="8" string="," />
            <token id="9" string="which" />
            <token id="10" string="makes" />
            <token id="11" string="a" />
            <token id="12" string="swirling" />
            <token id="13" string="motion" />
          </tokens>
        </chunking>
        <chunking id="13" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="14" string="an updraft" type="NP">
          <tokens>
            <token id="24" string="an" />
            <token id="25" string="updraft" />
          </tokens>
        </chunking>
        <chunking id="15" string="a low-pressure system" type="NP">
          <tokens>
            <token id="19" string="a" />
            <token id="20" string="low-pressure" />
            <token id="21" string="system" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">creates</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">creates</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">creates</governor>
          <dependent id="3">tornadoes</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">fan</governor>
          <dependent id="4">over</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">fan</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">fan</governor>
          <dependent id="6">large</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">tornadoes</governor>
          <dependent id="7">fan</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">makes</governor>
          <dependent id="9">which</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="7">fan</governor>
          <dependent id="10">makes</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">motion</governor>
          <dependent id="11">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">motion</governor>
          <dependent id="12">swirling</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">makes</governor>
          <dependent id="13">motion</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">fan</governor>
          <dependent id="15">another</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">simulates</governor>
          <dependent id="16">fan</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">simulates</governor>
          <dependent id="17">above</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="2">creates</governor>
          <dependent id="18">simulates</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">system</governor>
          <dependent id="19">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">system</governor>
          <dependent id="20">low-pressure</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">simulates</governor>
          <dependent id="21">system</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="23">adding</governor>
          <dependent id="22">by</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="18">simulates</governor>
          <dependent id="23">adding</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">updraft</governor>
          <dependent id="24">an</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="23">adding</governor>
          <dependent id="25">updraft</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">mix</governor>
          <dependent id="26">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">mix</governor>
          <dependent id="27">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">adding</governor>
          <dependent id="28">mix</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>With a bit of steam added to make the phenomenon visible, he creates twisters six to eight feet tall.</content>
      <tokens>
        <token id="1" string="With" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="bit" lemma="bit" stem="bit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="steam" lemma="steam" stem="steam" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="added" lemma="add" stem="ad" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="make" lemma="make" stem="make" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="phenomenon" lemma="phenomenon" stem="phenomenon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="visible" lemma="visible" stem="visibl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="creates" lemma="create" stem="creat" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="twisters" lemma="twister" stem="twister" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="six" lemma="six" stem="six" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="17" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="eight" lemma="eight" stem="eight" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="19" string="feet" lemma="foot" stem="feet" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="tall" lemma="tall" stem="tall" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN With) (S (NP (NP (DT a) (NN bit)) (PP (IN of) (NP (NN steam)))) (VP (VBD added) (S (VP (TO to) (VP (VB make) (S (NP (DT the) (NN phenomenon)) (ADJP (JJ visible))))))))) (, ,) (NP (PRP he)) (VP (VBZ creates) (NP (NP (NNS twisters)) (ADJP (NP (QP (CD six) (TO to) (CD eight)) (NNS feet)) (JJ tall)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="visible" type="ADJP">
          <tokens>
            <token id="11" string="visible" />
          </tokens>
        </chunking>
        <chunking id="2" string="creates twisters six to eight feet tall" type="VP">
          <tokens>
            <token id="14" string="creates" />
            <token id="15" string="twisters" />
            <token id="16" string="six" />
            <token id="17" string="to" />
            <token id="18" string="eight" />
            <token id="19" string="feet" />
            <token id="20" string="tall" />
          </tokens>
        </chunking>
        <chunking id="3" string="steam" type="NP">
          <tokens>
            <token id="5" string="steam" />
          </tokens>
        </chunking>
        <chunking id="4" string="to make the phenomenon visible" type="VP">
          <tokens>
            <token id="7" string="to" />
            <token id="8" string="make" />
            <token id="9" string="the" />
            <token id="10" string="phenomenon" />
            <token id="11" string="visible" />
          </tokens>
        </chunking>
        <chunking id="5" string="six to eight feet" type="NP">
          <tokens>
            <token id="16" string="six" />
            <token id="17" string="to" />
            <token id="18" string="eight" />
            <token id="19" string="feet" />
          </tokens>
        </chunking>
        <chunking id="6" string="the phenomenon" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="phenomenon" />
          </tokens>
        </chunking>
        <chunking id="7" string="With a bit of steam added to make the phenomenon visible" type="SBAR">
          <tokens>
            <token id="1" string="With" />
            <token id="2" string="a" />
            <token id="3" string="bit" />
            <token id="4" string="of" />
            <token id="5" string="steam" />
            <token id="6" string="added" />
            <token id="7" string="to" />
            <token id="8" string="make" />
            <token id="9" string="the" />
            <token id="10" string="phenomenon" />
            <token id="11" string="visible" />
          </tokens>
        </chunking>
        <chunking id="8" string="a bit of steam" type="NP">
          <tokens>
            <token id="2" string="a" />
            <token id="3" string="bit" />
            <token id="4" string="of" />
            <token id="5" string="steam" />
          </tokens>
        </chunking>
        <chunking id="9" string="a bit" type="NP">
          <tokens>
            <token id="2" string="a" />
            <token id="3" string="bit" />
          </tokens>
        </chunking>
        <chunking id="10" string="six to eight feet tall" type="ADJP">
          <tokens>
            <token id="16" string="six" />
            <token id="17" string="to" />
            <token id="18" string="eight" />
            <token id="19" string="feet" />
            <token id="20" string="tall" />
          </tokens>
        </chunking>
        <chunking id="11" string="twisters six to eight feet tall" type="NP">
          <tokens>
            <token id="15" string="twisters" />
            <token id="16" string="six" />
            <token id="17" string="to" />
            <token id="18" string="eight" />
            <token id="19" string="feet" />
            <token id="20" string="tall" />
          </tokens>
        </chunking>
        <chunking id="12" string="make the phenomenon visible" type="VP">
          <tokens>
            <token id="8" string="make" />
            <token id="9" string="the" />
            <token id="10" string="phenomenon" />
            <token id="11" string="visible" />
          </tokens>
        </chunking>
        <chunking id="13" string="twisters" type="NP">
          <tokens>
            <token id="15" string="twisters" />
          </tokens>
        </chunking>
        <chunking id="14" string="he" type="NP">
          <tokens>
            <token id="13" string="he" />
          </tokens>
        </chunking>
        <chunking id="15" string="added to make the phenomenon visible" type="VP">
          <tokens>
            <token id="6" string="added" />
            <token id="7" string="to" />
            <token id="8" string="make" />
            <token id="9" string="the" />
            <token id="10" string="phenomenon" />
            <token id="11" string="visible" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="6">added</governor>
          <dependent id="1">With</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">bit</governor>
          <dependent id="2">a</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">added</governor>
          <dependent id="3">bit</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">steam</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">bit</governor>
          <dependent id="5">steam</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="14">creates</governor>
          <dependent id="6">added</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">make</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">added</governor>
          <dependent id="8">make</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">phenomenon</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">visible</governor>
          <dependent id="10">phenomenon</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="8">make</governor>
          <dependent id="11">visible</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">creates</governor>
          <dependent id="13">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">creates</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">creates</governor>
          <dependent id="15">twisters</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">eight</governor>
          <dependent id="16">six</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="18">eight</governor>
          <dependent id="17">to</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="19">feet</governor>
          <dependent id="18">eight</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="20">tall</governor>
          <dependent id="19">feet</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">twisters</governor>
          <dependent id="20">tall</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="six" type="NUMBER" score="0.0">
          <tokens>
            <token id="16" string="six" />
          </tokens>
        </entity>
        <entity id="2" string="eight" type="NUMBER" score="0.0">
          <tokens>
            <token id="18" string="eight" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>The miniature versions are as impossible to redirect or squelch as their full-size cousins, he says.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="miniature" lemma="miniature" stem="miniatur" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="versions" lemma="version" stem="version" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="impossible" lemma="impossible" stem="imposs" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="redirect" lemma="redirect" stem="redirect" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="squelch" lemma="squelch" stem="squelch" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="13" string="full-size" lemma="full-size" stem="full-siz" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="cousins" lemma="cousin" stem="cousin" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (DT The) (JJ miniature) (NNS versions)) (VP (VBP are) (ADVP (IN as)) (ADJP (JJ impossible) (S (VP (TO to) (VP (VB redirect) (CC or) (VB squelch) (PP (IN as) (NP (PRP$ their) (JJ full-size) (NNS cousins))))))))) (, ,) (NP (PRP he)) (VP (VBZ says)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="impossible to redirect or squelch as their full-size cousins" type="ADJP">
          <tokens>
            <token id="6" string="impossible" />
            <token id="7" string="to" />
            <token id="8" string="redirect" />
            <token id="9" string="or" />
            <token id="10" string="squelch" />
            <token id="11" string="as" />
            <token id="12" string="their" />
            <token id="13" string="full-size" />
            <token id="14" string="cousins" />
          </tokens>
        </chunking>
        <chunking id="2" string="says" type="VP">
          <tokens>
            <token id="17" string="says" />
          </tokens>
        </chunking>
        <chunking id="3" string="their full-size cousins" type="NP">
          <tokens>
            <token id="12" string="their" />
            <token id="13" string="full-size" />
            <token id="14" string="cousins" />
          </tokens>
        </chunking>
        <chunking id="4" string="are as impossible to redirect or squelch as their full-size cousins" type="VP">
          <tokens>
            <token id="4" string="are" />
            <token id="5" string="as" />
            <token id="6" string="impossible" />
            <token id="7" string="to" />
            <token id="8" string="redirect" />
            <token id="9" string="or" />
            <token id="10" string="squelch" />
            <token id="11" string="as" />
            <token id="12" string="their" />
            <token id="13" string="full-size" />
            <token id="14" string="cousins" />
          </tokens>
        </chunking>
        <chunking id="5" string="to redirect or squelch as their full-size cousins" type="VP">
          <tokens>
            <token id="7" string="to" />
            <token id="8" string="redirect" />
            <token id="9" string="or" />
            <token id="10" string="squelch" />
            <token id="11" string="as" />
            <token id="12" string="their" />
            <token id="13" string="full-size" />
            <token id="14" string="cousins" />
          </tokens>
        </chunking>
        <chunking id="6" string="redirect or squelch as their full-size cousins" type="VP">
          <tokens>
            <token id="8" string="redirect" />
            <token id="9" string="or" />
            <token id="10" string="squelch" />
            <token id="11" string="as" />
            <token id="12" string="their" />
            <token id="13" string="full-size" />
            <token id="14" string="cousins" />
          </tokens>
        </chunking>
        <chunking id="7" string="he" type="NP">
          <tokens>
            <token id="16" string="he" />
          </tokens>
        </chunking>
        <chunking id="8" string="The miniature versions" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="miniature" />
            <token id="3" string="versions" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">versions</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">versions</governor>
          <dependent id="2">miniature</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">impossible</governor>
          <dependent id="3">versions</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">impossible</governor>
          <dependent id="4">are</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">impossible</governor>
          <dependent id="5">as</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="17">says</governor>
          <dependent id="6">impossible</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">redirect</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">impossible</governor>
          <dependent id="8">redirect</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">redirect</governor>
          <dependent id="9">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">redirect</governor>
          <dependent id="10">squelch</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">cousins</governor>
          <dependent id="11">as</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="14">cousins</governor>
          <dependent id="12">their</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">cousins</governor>
          <dependent id="13">full-size</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">redirect</governor>
          <dependent id="14">cousins</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">says</governor>
          <dependent id="16">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="17">says</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>He has tried by crawling right up next to them and using rulers or books to change their direction.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="tried" lemma="try" stem="tri" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="crawling" lemma="crawl" stem="crawl" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="right" lemma="right" stem="right" pos="NN" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="7" string="up" lemma="up" stem="up" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="next" lemma="next" stem="next" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="using" lemma="use" stem="us" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="rulers" lemma="ruler" stem="ruler" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="books" lemma="book" stem="book" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="change" lemma="change" stem="chang" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="direction" lemma="direction" stem="direct" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VBZ has) (VP (VBN tried) (PP (IN by) (S (VP (VP (VBG crawling) (ADVP (ADVP (NN right) (IN up)) (JJ next)) (PP (TO to) (NP (PRP them)))) (CC and) (VP (VBG using) (NP (NNS rulers) (CC or) (NNS books)) (S (VP (TO to) (VP (VB change) (NP (PRP$ their) (NN direction))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="rulers or books" type="NP">
          <tokens>
            <token id="13" string="rulers" />
            <token id="14" string="or" />
            <token id="15" string="books" />
          </tokens>
        </chunking>
        <chunking id="2" string="their direction" type="NP">
          <tokens>
            <token id="18" string="their" />
            <token id="19" string="direction" />
          </tokens>
        </chunking>
        <chunking id="3" string="tried by crawling right up next to them and using rulers or books to change their direction" type="VP">
          <tokens>
            <token id="3" string="tried" />
            <token id="4" string="by" />
            <token id="5" string="crawling" />
            <token id="6" string="right" />
            <token id="7" string="up" />
            <token id="8" string="next" />
            <token id="9" string="to" />
            <token id="10" string="them" />
            <token id="11" string="and" />
            <token id="12" string="using" />
            <token id="13" string="rulers" />
            <token id="14" string="or" />
            <token id="15" string="books" />
            <token id="16" string="to" />
            <token id="17" string="change" />
            <token id="18" string="their" />
            <token id="19" string="direction" />
          </tokens>
        </chunking>
        <chunking id="4" string="crawling right up next to them and using rulers or books to change their direction" type="VP">
          <tokens>
            <token id="5" string="crawling" />
            <token id="6" string="right" />
            <token id="7" string="up" />
            <token id="8" string="next" />
            <token id="9" string="to" />
            <token id="10" string="them" />
            <token id="11" string="and" />
            <token id="12" string="using" />
            <token id="13" string="rulers" />
            <token id="14" string="or" />
            <token id="15" string="books" />
            <token id="16" string="to" />
            <token id="17" string="change" />
            <token id="18" string="their" />
            <token id="19" string="direction" />
          </tokens>
        </chunking>
        <chunking id="5" string="change their direction" type="VP">
          <tokens>
            <token id="17" string="change" />
            <token id="18" string="their" />
            <token id="19" string="direction" />
          </tokens>
        </chunking>
        <chunking id="6" string="using rulers or books to change their direction" type="VP">
          <tokens>
            <token id="12" string="using" />
            <token id="13" string="rulers" />
            <token id="14" string="or" />
            <token id="15" string="books" />
            <token id="16" string="to" />
            <token id="17" string="change" />
            <token id="18" string="their" />
            <token id="19" string="direction" />
          </tokens>
        </chunking>
        <chunking id="7" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="8" string="has tried by crawling right up next to them and using rulers or books to change their direction" type="VP">
          <tokens>
            <token id="2" string="has" />
            <token id="3" string="tried" />
            <token id="4" string="by" />
            <token id="5" string="crawling" />
            <token id="6" string="right" />
            <token id="7" string="up" />
            <token id="8" string="next" />
            <token id="9" string="to" />
            <token id="10" string="them" />
            <token id="11" string="and" />
            <token id="12" string="using" />
            <token id="13" string="rulers" />
            <token id="14" string="or" />
            <token id="15" string="books" />
            <token id="16" string="to" />
            <token id="17" string="change" />
            <token id="18" string="their" />
            <token id="19" string="direction" />
          </tokens>
        </chunking>
        <chunking id="9" string="them" type="NP">
          <tokens>
            <token id="10" string="them" />
          </tokens>
        </chunking>
        <chunking id="10" string="crawling right up next to them" type="VP">
          <tokens>
            <token id="5" string="crawling" />
            <token id="6" string="right" />
            <token id="7" string="up" />
            <token id="8" string="next" />
            <token id="9" string="to" />
            <token id="10" string="them" />
          </tokens>
        </chunking>
        <chunking id="11" string="to change their direction" type="VP">
          <tokens>
            <token id="16" string="to" />
            <token id="17" string="change" />
            <token id="18" string="their" />
            <token id="19" string="direction" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">tried</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="3">tried</governor>
          <dependent id="2">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">tried</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">crawling</governor>
          <dependent id="4">by</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">tried</governor>
          <dependent id="5">crawling</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">next</governor>
          <dependent id="6">right</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">right</governor>
          <dependent id="7">up</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">crawling</governor>
          <dependent id="8">next</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">them</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">crawling</governor>
          <dependent id="10">them</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">crawling</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">crawling</governor>
          <dependent id="12">using</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">using</governor>
          <dependent id="13">rulers</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">rulers</governor>
          <dependent id="14">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">rulers</governor>
          <dependent id="15">books</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">change</governor>
          <dependent id="16">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="12">using</governor>
          <dependent id="17">change</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="19">direction</governor>
          <dependent id="18">their</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">change</governor>
          <dependent id="19">direction</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="right" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="6" string="right" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>Fujita came to the United States from Japan in 1953, partly because there are so many tornadoes in this country.</content>
      <tokens>
        <token id="1" string="Fujita" lemma="Fujita" stem="fujita" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="came" lemma="come" stem="came" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="United" lemma="United" stem="unite" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="6" string="States" lemma="States" stem="state" pos="NNPS" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="7" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Japan" lemma="Japan" stem="japan" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="9" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="1953" lemma="1953" stem="1953" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="partly" lemma="partly" stem="partli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="so" lemma="so" stem="so" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="many" lemma="many" stem="mani" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="tornadoes" lemma="tornado" stem="tornado" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="country" lemma="country" stem="countri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Fujita)) (VP (VBD came) (PP (TO to) (NP (DT the) (NNP United) (NNPS States))) (PP (IN from) (NP (NP (NNP Japan)) (PP (IN in) (NP (CD 1953))))) (, ,) (SBAR (RB partly) (IN because) (S (NP (EX there)) (VP (VBP are) (ADVP (RB so)) (NP (NP (JJ many) (NNS tornadoes)) (PP (IN in) (NP (DT this) (NN country)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the United States" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="United" />
            <token id="6" string="States" />
          </tokens>
        </chunking>
        <chunking id="2" string="partly because there are so many tornadoes in this country" type="SBAR">
          <tokens>
            <token id="12" string="partly" />
            <token id="13" string="because" />
            <token id="14" string="there" />
            <token id="15" string="are" />
            <token id="16" string="so" />
            <token id="17" string="many" />
            <token id="18" string="tornadoes" />
            <token id="19" string="in" />
            <token id="20" string="this" />
            <token id="21" string="country" />
          </tokens>
        </chunking>
        <chunking id="3" string="there" type="NP">
          <tokens>
            <token id="14" string="there" />
          </tokens>
        </chunking>
        <chunking id="4" string="1953" type="NP">
          <tokens>
            <token id="10" string="1953" />
          </tokens>
        </chunking>
        <chunking id="5" string="this country" type="NP">
          <tokens>
            <token id="20" string="this" />
            <token id="21" string="country" />
          </tokens>
        </chunking>
        <chunking id="6" string="came to the United States from Japan in 1953 , partly because there are so many tornadoes in this country" type="VP">
          <tokens>
            <token id="2" string="came" />
            <token id="3" string="to" />
            <token id="4" string="the" />
            <token id="5" string="United" />
            <token id="6" string="States" />
            <token id="7" string="from" />
            <token id="8" string="Japan" />
            <token id="9" string="in" />
            <token id="10" string="1953" />
            <token id="11" string="," />
            <token id="12" string="partly" />
            <token id="13" string="because" />
            <token id="14" string="there" />
            <token id="15" string="are" />
            <token id="16" string="so" />
            <token id="17" string="many" />
            <token id="18" string="tornadoes" />
            <token id="19" string="in" />
            <token id="20" string="this" />
            <token id="21" string="country" />
          </tokens>
        </chunking>
        <chunking id="7" string="Japan" type="NP">
          <tokens>
            <token id="8" string="Japan" />
          </tokens>
        </chunking>
        <chunking id="8" string="are so many tornadoes in this country" type="VP">
          <tokens>
            <token id="15" string="are" />
            <token id="16" string="so" />
            <token id="17" string="many" />
            <token id="18" string="tornadoes" />
            <token id="19" string="in" />
            <token id="20" string="this" />
            <token id="21" string="country" />
          </tokens>
        </chunking>
        <chunking id="9" string="many tornadoes in this country" type="NP">
          <tokens>
            <token id="17" string="many" />
            <token id="18" string="tornadoes" />
            <token id="19" string="in" />
            <token id="20" string="this" />
            <token id="21" string="country" />
          </tokens>
        </chunking>
        <chunking id="10" string="many tornadoes" type="NP">
          <tokens>
            <token id="17" string="many" />
            <token id="18" string="tornadoes" />
          </tokens>
        </chunking>
        <chunking id="11" string="Japan in 1953" type="NP">
          <tokens>
            <token id="8" string="Japan" />
            <token id="9" string="in" />
            <token id="10" string="1953" />
          </tokens>
        </chunking>
        <chunking id="12" string="Fujita" type="NP">
          <tokens>
            <token id="1" string="Fujita" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">came</governor>
          <dependent id="1">Fujita</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">came</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">States</governor>
          <dependent id="3">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">States</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">States</governor>
          <dependent id="5">United</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">came</governor>
          <dependent id="6">States</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">Japan</governor>
          <dependent id="7">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">came</governor>
          <dependent id="8">Japan</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">1953</governor>
          <dependent id="9">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">Japan</governor>
          <dependent id="10">1953</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">are</governor>
          <dependent id="12">partly</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">are</governor>
          <dependent id="13">because</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="15">are</governor>
          <dependent id="14">there</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="2">came</governor>
          <dependent id="15">are</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">are</governor>
          <dependent id="16">so</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">tornadoes</governor>
          <dependent id="17">many</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">are</governor>
          <dependent id="18">tornadoes</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">country</governor>
          <dependent id="19">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">country</governor>
          <dependent id="20">this</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">tornadoes</governor>
          <dependent id="21">country</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1953" type="DATE" score="0.0">
          <tokens>
            <token id="10" string="1953" />
          </tokens>
        </entity>
        <entity id="2" string="United States" type="LOCATION" score="0.0">
          <tokens>
            <token id="5" string="United" />
            <token id="6" string="States" />
          </tokens>
        </entity>
        <entity id="3" string="Japan" type="LOCATION" score="0.0">
          <tokens>
            <token id="8" string="Japan" />
          </tokens>
        </entity>
        <entity id="4" string="Fujita" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Fujita" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>&amp;quot;Tornadoes are very rare in Japan,&amp;quot; Fujita said.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Tornadoes" lemma="tornado" stem="tornado" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="very" lemma="very" stem="veri" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="rare" lemma="rare" stem="rare" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Japan" lemma="Japan" stem="japan" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Fujita" lemma="Fujita" stem="fujita" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="11" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (NNS Tornadoes)) (VP (VBP are) (ADJP (RB very) (JJ rare) (PP (IN in) (NP (NNP Japan)))))) (, ,) ('' '') (NP (NNP Fujita)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Japan" type="NP">
          <tokens>
            <token id="7" string="Japan" />
          </tokens>
        </chunking>
        <chunking id="2" string="Tornadoes" type="NP">
          <tokens>
            <token id="2" string="Tornadoes" />
          </tokens>
        </chunking>
        <chunking id="3" string="are very rare in Japan" type="VP">
          <tokens>
            <token id="3" string="are" />
            <token id="4" string="very" />
            <token id="5" string="rare" />
            <token id="6" string="in" />
            <token id="7" string="Japan" />
          </tokens>
        </chunking>
        <chunking id="4" string="very rare in Japan" type="ADJP">
          <tokens>
            <token id="4" string="very" />
            <token id="5" string="rare" />
            <token id="6" string="in" />
            <token id="7" string="Japan" />
          </tokens>
        </chunking>
        <chunking id="5" string="said" type="VP">
          <tokens>
            <token id="11" string="said" />
          </tokens>
        </chunking>
        <chunking id="6" string="Fujita" type="NP">
          <tokens>
            <token id="10" string="Fujita" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">rare</governor>
          <dependent id="2">Tornadoes</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">rare</governor>
          <dependent id="3">are</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">rare</governor>
          <dependent id="4">very</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">said</governor>
          <dependent id="5">rare</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">Japan</governor>
          <dependent id="6">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">rare</governor>
          <dependent id="7">Japan</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">said</governor>
          <dependent id="10">Fujita</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Japan" type="LOCATION" score="0.0">
          <tokens>
            <token id="7" string="Japan" />
          </tokens>
        </entity>
        <entity id="2" string="Fujita" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Fujita" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>&amp;quot;They have about 10 to 15 a year.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="They" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="about" lemma="about" stem="about" pos="RB" type="Word" isStopWord="true" ner="TIME" is_referenced="true" is_refers="false" />
        <token id="5" string="10" lemma="10" stem="10" pos="CD" type="Number" isStopWord="false" ner="TIME" is_referenced="true" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" ner="TIME" is_referenced="true" is_refers="false" />
        <token id="7" string="15" lemma="15" stem="15" pos="CD" type="Number" isStopWord="false" ner="TIME" is_referenced="true" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="9" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP They)) (VP (VBP have) (NP (NP (QP (RB about) (CD 10) (TO to) (CD 15))) (NP (DT a) (NN year)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="They" type="NP">
          <tokens>
            <token id="2" string="They" />
          </tokens>
        </chunking>
        <chunking id="2" string="about 10 to 15" type="NP">
          <tokens>
            <token id="4" string="about" />
            <token id="5" string="10" />
            <token id="6" string="to" />
            <token id="7" string="15" />
          </tokens>
        </chunking>
        <chunking id="3" string="have about 10 to 15 a year" type="VP">
          <tokens>
            <token id="3" string="have" />
            <token id="4" string="about" />
            <token id="5" string="10" />
            <token id="6" string="to" />
            <token id="7" string="15" />
            <token id="8" string="a" />
            <token id="9" string="year" />
          </tokens>
        </chunking>
        <chunking id="4" string="about 10 to 15 a year" type="NP">
          <tokens>
            <token id="4" string="about" />
            <token id="5" string="10" />
            <token id="6" string="to" />
            <token id="7" string="15" />
            <token id="8" string="a" />
            <token id="9" string="year" />
          </tokens>
        </chunking>
        <chunking id="5" string="a year" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="year" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">have</governor>
          <dependent id="2">They</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">have</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">15</governor>
          <dependent id="4">about</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">15</governor>
          <dependent id="5">10</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="7">15</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">have</governor>
          <dependent id="7">15</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">year</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="7">15</governor>
          <dependent id="9">year</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="about 10 to 15" type="TIME" score="0.0">
          <tokens>
            <token id="4" string="about" />
            <token id="5" string="10" />
            <token id="6" string="to" />
            <token id="7" string="15" />
          </tokens>
        </entity>
        <entity id="2" string="a year" type="DURATION" score="0.0">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="year" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>But one occurred within about 15 miles of my hometown.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="3" string="occurred" lemma="occur" stem="occur" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="within" lemma="within" stem="within" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="about" lemma="about" stem="about" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="15" lemma="15" stem="15" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="true" />
        <token id="7" string="miles" lemma="mile" stem="mile" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="my" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="hometown" lemma="hometown" stem="hometown" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (CD one)) (VP (VBD occurred) (PP (IN within) (NP (NP (QP (RB about) (CD 15)) (NNS miles)) (PP (IN of) (NP (PRP$ my) (NN hometown)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="one" type="NP">
          <tokens>
            <token id="2" string="one" />
          </tokens>
        </chunking>
        <chunking id="2" string="about 15 miles" type="NP">
          <tokens>
            <token id="5" string="about" />
            <token id="6" string="15" />
            <token id="7" string="miles" />
          </tokens>
        </chunking>
        <chunking id="3" string="about 15 miles of my hometown" type="NP">
          <tokens>
            <token id="5" string="about" />
            <token id="6" string="15" />
            <token id="7" string="miles" />
            <token id="8" string="of" />
            <token id="9" string="my" />
            <token id="10" string="hometown" />
          </tokens>
        </chunking>
        <chunking id="4" string="my hometown" type="NP">
          <tokens>
            <token id="9" string="my" />
            <token id="10" string="hometown" />
          </tokens>
        </chunking>
        <chunking id="5" string="occurred within about 15 miles of my hometown" type="VP">
          <tokens>
            <token id="3" string="occurred" />
            <token id="4" string="within" />
            <token id="5" string="about" />
            <token id="6" string="15" />
            <token id="7" string="miles" />
            <token id="8" string="of" />
            <token id="9" string="my" />
            <token id="10" string="hometown" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="3">occurred</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">occurred</governor>
          <dependent id="2">one</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">occurred</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">miles</governor>
          <dependent id="4">within</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">15</governor>
          <dependent id="5">about</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="7">miles</governor>
          <dependent id="6">15</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">occurred</governor>
          <dependent id="7">miles</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">hometown</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="10">hometown</governor>
          <dependent id="9">my</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">miles</governor>
          <dependent id="10">hometown</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="15" type="NUMBER" score="0.0">
          <tokens>
            <token id="6" string="15" />
          </tokens>
        </entity>
        <entity id="2" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="2" string="one" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>I was quite impressed with the localized severity of the wind.&amp;quot;</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="quite" lemma="quite" stem="quit" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="impressed" lemma="impressed" stem="impress" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="localized" lemma="localized" stem="local" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="severity" lemma="severity" stem="sever" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="wind" lemma="wind" stem="wind" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (VP (VBD was) (ADJP (RB quite) (JJ impressed)) (PP (IN with) (NP (NP (DT the) (ADJP (JJ localized)) (NN severity)) (PP (IN of) (NP (DT the) (NN wind)))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="the localized severity of the wind" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="localized" />
            <token id="8" string="severity" />
            <token id="9" string="of" />
            <token id="10" string="the" />
            <token id="11" string="wind" />
          </tokens>
        </chunking>
        <chunking id="2" string="the wind" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="wind" />
          </tokens>
        </chunking>
        <chunking id="3" string="quite impressed" type="ADJP">
          <tokens>
            <token id="3" string="quite" />
            <token id="4" string="impressed" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="localized" type="ADJP">
          <tokens>
            <token id="7" string="localized" />
          </tokens>
        </chunking>
        <chunking id="6" string="was quite impressed with the localized severity of the wind" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="quite" />
            <token id="4" string="impressed" />
            <token id="5" string="with" />
            <token id="6" string="the" />
            <token id="7" string="localized" />
            <token id="8" string="severity" />
            <token id="9" string="of" />
            <token id="10" string="the" />
            <token id="11" string="wind" />
          </tokens>
        </chunking>
        <chunking id="7" string="the localized severity" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="localized" />
            <token id="8" string="severity" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">impressed</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">impressed</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">impressed</governor>
          <dependent id="3">quite</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">impressed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">severity</governor>
          <dependent id="5">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">severity</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">severity</governor>
          <dependent id="7">localized</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">impressed</governor>
          <dependent id="8">severity</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">wind</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">wind</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">severity</governor>
          <dependent id="11">wind</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>When he saw his first tornado, he and a team of scientists were studying wind shear and its effect on aircraft.</content>
      <tokens>
        <token id="1" string="When" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="saw" lemma="see" stem="saw" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="true" is_refers="false" />
        <token id="6" string="tornado" lemma="tornado" stem="tornado" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="true" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="team" lemma="team" stem="team" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="scientists" lemma="scientist" stem="scientist" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="studying" lemma="study" stem="studi" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="wind" lemma="wind" stem="wind" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="shear" lemma="shear" stem="shear" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="effect" lemma="effect" stem="effect" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="aircraft" lemma="aircraft" stem="aircraft" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (WHADVP (WRB When)) (S (NP (PRP he)) (VP (VBD saw) (NP (PRP$ his) (JJ first) (NN tornado))))) (, ,) (NP (NP (PRP he)) (CC and) (NP (NP (DT a) (NN team)) (PP (IN of) (NP (NNS scientists))))) (VP (VBD were) (VP (VBG studying) (NP (NP (NN wind) (NN shear)) (CC and) (NP (PRP$ its) (NN effect))) (PP (IN on) (NP (NN aircraft))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="were studying wind shear and its effect on aircraft" type="VP">
          <tokens>
            <token id="14" string="were" />
            <token id="15" string="studying" />
            <token id="16" string="wind" />
            <token id="17" string="shear" />
            <token id="18" string="and" />
            <token id="19" string="its" />
            <token id="20" string="effect" />
            <token id="21" string="on" />
            <token id="22" string="aircraft" />
          </tokens>
        </chunking>
        <chunking id="2" string="saw his first tornado" type="VP">
          <tokens>
            <token id="3" string="saw" />
            <token id="4" string="his" />
            <token id="5" string="first" />
            <token id="6" string="tornado" />
          </tokens>
        </chunking>
        <chunking id="3" string="When he saw his first tornado" type="SBAR">
          <tokens>
            <token id="1" string="When" />
            <token id="2" string="he" />
            <token id="3" string="saw" />
            <token id="4" string="his" />
            <token id="5" string="first" />
            <token id="6" string="tornado" />
          </tokens>
        </chunking>
        <chunking id="4" string="a team" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="team" />
          </tokens>
        </chunking>
        <chunking id="5" string="aircraft" type="NP">
          <tokens>
            <token id="22" string="aircraft" />
          </tokens>
        </chunking>
        <chunking id="6" string="studying wind shear and its effect on aircraft" type="VP">
          <tokens>
            <token id="15" string="studying" />
            <token id="16" string="wind" />
            <token id="17" string="shear" />
            <token id="18" string="and" />
            <token id="19" string="its" />
            <token id="20" string="effect" />
            <token id="21" string="on" />
            <token id="22" string="aircraft" />
          </tokens>
        </chunking>
        <chunking id="7" string="wind shear and its effect" type="NP">
          <tokens>
            <token id="16" string="wind" />
            <token id="17" string="shear" />
            <token id="18" string="and" />
            <token id="19" string="its" />
            <token id="20" string="effect" />
          </tokens>
        </chunking>
        <chunking id="8" string="wind shear" type="NP">
          <tokens>
            <token id="16" string="wind" />
            <token id="17" string="shear" />
          </tokens>
        </chunking>
        <chunking id="9" string="When" type="WHADVP">
          <tokens>
            <token id="1" string="When" />
          </tokens>
        </chunking>
        <chunking id="10" string="his first tornado" type="NP">
          <tokens>
            <token id="4" string="his" />
            <token id="5" string="first" />
            <token id="6" string="tornado" />
          </tokens>
        </chunking>
        <chunking id="11" string="scientists" type="NP">
          <tokens>
            <token id="13" string="scientists" />
          </tokens>
        </chunking>
        <chunking id="12" string="he and a team of scientists" type="NP">
          <tokens>
            <token id="8" string="he" />
            <token id="9" string="and" />
            <token id="10" string="a" />
            <token id="11" string="team" />
            <token id="12" string="of" />
            <token id="13" string="scientists" />
          </tokens>
        </chunking>
        <chunking id="13" string="a team of scientists" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="team" />
            <token id="12" string="of" />
            <token id="13" string="scientists" />
          </tokens>
        </chunking>
        <chunking id="14" string="he" type="NP">
          <tokens>
            <token id="2" string="he" />
          </tokens>
        </chunking>
        <chunking id="15" string="its effect" type="NP">
          <tokens>
            <token id="19" string="its" />
            <token id="20" string="effect" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="3">saw</governor>
          <dependent id="1">When</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">saw</governor>
          <dependent id="2">he</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="15">studying</governor>
          <dependent id="3">saw</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="6">tornado</governor>
          <dependent id="4">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">tornado</governor>
          <dependent id="5">first</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">saw</governor>
          <dependent id="6">tornado</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">studying</governor>
          <dependent id="8">he</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">he</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">team</governor>
          <dependent id="10">a</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">he</governor>
          <dependent id="11">team</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">scientists</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">team</governor>
          <dependent id="13">scientists</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="15">studying</governor>
          <dependent id="14">were</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">studying</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">shear</governor>
          <dependent id="16">wind</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">studying</governor>
          <dependent id="17">shear</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="17">shear</governor>
          <dependent id="18">and</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="20">effect</governor>
          <dependent id="19">its</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">shear</governor>
          <dependent id="20">effect</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">aircraft</governor>
          <dependent id="21">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">studying</governor>
          <dependent id="22">aircraft</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="5" string="first" />
          </tokens>
        </entity>
        <entity id="2" string="tornado" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="6" string="tornado" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>&amp;quot;It&amp;apost;s a beautiful thing,&amp;quot; Fujita said.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="beautiful" lemma="beautiful" stem="beauti" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="thing" lemma="thing" stem="thing" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Fujita" lemma="Fujita" stem="fujita" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="10" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP It)) (VP (VBZ 's) (NP (DT a) (JJ beautiful) (NN thing)))) (, ,) ('' '') (NP (NNP Fujita)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="'s a beautiful thing" type="VP">
          <tokens>
            <token id="3" string="'s" />
            <token id="4" string="a" />
            <token id="5" string="beautiful" />
            <token id="6" string="thing" />
          </tokens>
        </chunking>
        <chunking id="2" string="a beautiful thing" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="beautiful" />
            <token id="6" string="thing" />
          </tokens>
        </chunking>
        <chunking id="3" string="It" type="NP">
          <tokens>
            <token id="2" string="It" />
          </tokens>
        </chunking>
        <chunking id="4" string="said" type="VP">
          <tokens>
            <token id="10" string="said" />
          </tokens>
        </chunking>
        <chunking id="5" string="Fujita" type="NP">
          <tokens>
            <token id="9" string="Fujita" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="6">thing</governor>
          <dependent id="2">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">thing</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">thing</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">thing</governor>
          <dependent id="5">beautiful</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">said</governor>
          <dependent id="6">thing</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">said</governor>
          <dependent id="9">Fujita</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Fujita" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="Fujita" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>&amp;quot;Of course, I was 20 miles away from that one.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="course" lemma="course" stem="cours" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="20" lemma="20" stem="20" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="8" string="miles" lemma="mile" stem="mile" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="away" lemma="away" stem="awai" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (PP (IN Of) (NP (NN course))) (, ,) (NP (PRP I)) (VP (VBD was) (ADVP (NP (CD 20) (NNS miles)) (RB away)) (PP (IN from) (NP (DT that) (CD one)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="that one" type="NP">
          <tokens>
            <token id="11" string="that" />
            <token id="12" string="one" />
          </tokens>
        </chunking>
        <chunking id="2" string="course" type="NP">
          <tokens>
            <token id="3" string="course" />
          </tokens>
        </chunking>
        <chunking id="3" string="I" type="NP">
          <tokens>
            <token id="5" string="I" />
          </tokens>
        </chunking>
        <chunking id="4" string="20 miles" type="NP">
          <tokens>
            <token id="7" string="20" />
            <token id="8" string="miles" />
          </tokens>
        </chunking>
        <chunking id="5" string="was 20 miles away from that one" type="VP">
          <tokens>
            <token id="6" string="was" />
            <token id="7" string="20" />
            <token id="8" string="miles" />
            <token id="9" string="away" />
            <token id="10" string="from" />
            <token id="11" string="that" />
            <token id="12" string="one" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">course</governor>
          <dependent id="2">Of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">one</governor>
          <dependent id="3">course</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">one</governor>
          <dependent id="5">I</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="12">one</governor>
          <dependent id="6">was</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="8">miles</governor>
          <dependent id="7">20</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="9">away</governor>
          <dependent id="8">miles</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">one</governor>
          <dependent id="9">away</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">one</governor>
          <dependent id="10">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">one</governor>
          <dependent id="11">that</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">one</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="12" string="one" />
          </tokens>
        </entity>
        <entity id="2" string="20" type="NUMBER" score="0.0">
          <tokens>
            <token id="7" string="20" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="17" has_coreference="true">
      <content>&amp;quot;If you&amp;apost;re in it,&amp;quot; he added, &amp;quot;it&amp;apost;s a terrible thing.&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="If" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="'re" lemma="be" stem="'re" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="added" lemma="add" stem="ad" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="terrible" lemma="terrible" stem="terribl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="thing" lemma="thing" stem="thing" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (SBAR (IN If) (S (NP (PRP you)) (VP (VBP 're) (PP (IN in) (NP (PRP it)))))) (PRN (, ,) ('' '') (S (NP (PRP he)) (VP (VBD added))) (, ,)) (`` ``) (NP (PRP it)) (VP (VBZ 's) (NP (DT a) (JJ terrible) (NN thing))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="'re in it" type="VP">
          <tokens>
            <token id="4" string="'re" />
            <token id="5" string="in" />
            <token id="6" string="it" />
          </tokens>
        </chunking>
        <chunking id="2" string="a terrible thing" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="terrible" />
            <token id="17" string="thing" />
          </tokens>
        </chunking>
        <chunking id="3" string="'s a terrible thing" type="VP">
          <tokens>
            <token id="14" string="'s" />
            <token id="15" string="a" />
            <token id="16" string="terrible" />
            <token id="17" string="thing" />
          </tokens>
        </chunking>
        <chunking id="4" string="If you 're in it" type="SBAR">
          <tokens>
            <token id="2" string="If" />
            <token id="3" string="you" />
            <token id="4" string="'re" />
            <token id="5" string="in" />
            <token id="6" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="it" type="NP">
          <tokens>
            <token id="6" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="added" type="VP">
          <tokens>
            <token id="10" string="added" />
          </tokens>
        </chunking>
        <chunking id="7" string="he" type="NP">
          <tokens>
            <token id="9" string="he" />
          </tokens>
        </chunking>
        <chunking id="8" string="you" type="NP">
          <tokens>
            <token id="3" string="you" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="6">it</governor>
          <dependent id="2">If</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">it</governor>
          <dependent id="3">you</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">it</governor>
          <dependent id="4">'re</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">it</governor>
          <dependent id="5">in</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="17">thing</governor>
          <dependent id="6">it</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">added</governor>
          <dependent id="9">he</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="17">thing</governor>
          <dependent id="10">added</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">thing</governor>
          <dependent id="13">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="17">thing</governor>
          <dependent id="14">'s</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">thing</governor>
          <dependent id="15">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">thing</governor>
          <dependent id="16">terrible</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="17">thing</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="18" has_coreference="true">
      <content>Forecasters still have trouble predicting tornadoes.</content>
      <tokens>
        <token id="1" string="Forecasters" lemma="forecaster" stem="forecast" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="still" lemma="still" stem="still" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="trouble" lemma="trouble" stem="troubl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="predicting" lemma="predict" stem="predict" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="tornadoes" lemma="tornado" stem="tornado" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNS Forecasters)) (ADVP (RB still)) (VP (VBP have) (NP (NP (NN trouble)) (VP (VBG predicting) (NP (NNS tornadoes))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Forecasters" type="NP">
          <tokens>
            <token id="1" string="Forecasters" />
          </tokens>
        </chunking>
        <chunking id="2" string="trouble predicting tornadoes" type="NP">
          <tokens>
            <token id="4" string="trouble" />
            <token id="5" string="predicting" />
            <token id="6" string="tornadoes" />
          </tokens>
        </chunking>
        <chunking id="3" string="tornadoes" type="NP">
          <tokens>
            <token id="6" string="tornadoes" />
          </tokens>
        </chunking>
        <chunking id="4" string="have trouble predicting tornadoes" type="VP">
          <tokens>
            <token id="3" string="have" />
            <token id="4" string="trouble" />
            <token id="5" string="predicting" />
            <token id="6" string="tornadoes" />
          </tokens>
        </chunking>
        <chunking id="5" string="predicting tornadoes" type="VP">
          <tokens>
            <token id="5" string="predicting" />
            <token id="6" string="tornadoes" />
          </tokens>
        </chunking>
        <chunking id="6" string="trouble" type="NP">
          <tokens>
            <token id="4" string="trouble" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">have</governor>
          <dependent id="1">Forecasters</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">have</governor>
          <dependent id="2">still</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">have</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">have</governor>
          <dependent id="4">trouble</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="4">trouble</governor>
          <dependent id="5">predicting</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">predicting</governor>
          <dependent id="6">tornadoes</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="19" has_coreference="true">
      <content>But Fujita has helped define the conditions most likely to spawn them.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Fujita" lemma="Fujita" stem="fujita" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="helped" lemma="help" stem="help" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="define" lemma="define" stem="defin" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="conditions" lemma="condition" stem="condit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="most" lemma="most" stem="most" pos="RBS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="likely" lemma="likely" stem="like" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="spawn" lemma="spawn" stem="spawn" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (NNP Fujita)) (VP (VBZ has) (VP (VBN helped) (S (VP (VB define) (NP (NP (DT the) (NNS conditions)) (ADJP (RBS most) (JJ likely) (S (VP (TO to) (VP (VB spawn) (NP (PRP them))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the conditions most likely to spawn them" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="conditions" />
            <token id="8" string="most" />
            <token id="9" string="likely" />
            <token id="10" string="to" />
            <token id="11" string="spawn" />
            <token id="12" string="them" />
          </tokens>
        </chunking>
        <chunking id="2" string="define the conditions most likely to spawn them" type="VP">
          <tokens>
            <token id="5" string="define" />
            <token id="6" string="the" />
            <token id="7" string="conditions" />
            <token id="8" string="most" />
            <token id="9" string="likely" />
            <token id="10" string="to" />
            <token id="11" string="spawn" />
            <token id="12" string="them" />
          </tokens>
        </chunking>
        <chunking id="3" string="spawn them" type="VP">
          <tokens>
            <token id="11" string="spawn" />
            <token id="12" string="them" />
          </tokens>
        </chunking>
        <chunking id="4" string="to spawn them" type="VP">
          <tokens>
            <token id="10" string="to" />
            <token id="11" string="spawn" />
            <token id="12" string="them" />
          </tokens>
        </chunking>
        <chunking id="5" string="helped define the conditions most likely to spawn them" type="VP">
          <tokens>
            <token id="4" string="helped" />
            <token id="5" string="define" />
            <token id="6" string="the" />
            <token id="7" string="conditions" />
            <token id="8" string="most" />
            <token id="9" string="likely" />
            <token id="10" string="to" />
            <token id="11" string="spawn" />
            <token id="12" string="them" />
          </tokens>
        </chunking>
        <chunking id="6" string="the conditions" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="conditions" />
          </tokens>
        </chunking>
        <chunking id="7" string="has helped define the conditions most likely to spawn them" type="VP">
          <tokens>
            <token id="3" string="has" />
            <token id="4" string="helped" />
            <token id="5" string="define" />
            <token id="6" string="the" />
            <token id="7" string="conditions" />
            <token id="8" string="most" />
            <token id="9" string="likely" />
            <token id="10" string="to" />
            <token id="11" string="spawn" />
            <token id="12" string="them" />
          </tokens>
        </chunking>
        <chunking id="8" string="most likely to spawn them" type="ADJP">
          <tokens>
            <token id="8" string="most" />
            <token id="9" string="likely" />
            <token id="10" string="to" />
            <token id="11" string="spawn" />
            <token id="12" string="them" />
          </tokens>
        </chunking>
        <chunking id="9" string="them" type="NP">
          <tokens>
            <token id="12" string="them" />
          </tokens>
        </chunking>
        <chunking id="10" string="Fujita" type="NP">
          <tokens>
            <token id="2" string="Fujita" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="4">helped</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">helped</governor>
          <dependent id="2">Fujita</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">helped</governor>
          <dependent id="3">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">helped</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">helped</governor>
          <dependent id="5">define</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">conditions</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">define</governor>
          <dependent id="7">conditions</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">likely</governor>
          <dependent id="8">most</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">conditions</governor>
          <dependent id="9">likely</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">spawn</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="9">likely</governor>
          <dependent id="11">spawn</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">spawn</governor>
          <dependent id="12">them</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Fujita" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Fujita" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="20" has_coreference="true">
      <content>Groups of thunderstorms are not as likely to spawn tornadoes as single, large storms because multiple storms in the same area compete.</content>
      <tokens>
        <token id="1" string="Groups" lemma="group" stem="group" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="thunderstorms" lemma="thunderstorm" stem="thunderstorm" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="as" lemma="as" stem="a" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="likely" lemma="likely" stem="like" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="spawn" lemma="spawn" stem="spawn" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="tornadoes" lemma="tornado" stem="tornado" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="single" lemma="single" stem="singl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="large" lemma="large" stem="larg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="storms" lemma="storm" stem="storm" pos="NNS" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="16" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="multiple" lemma="multiple" stem="multipl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="storms" lemma="storm" stem="storm" pos="NNS" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="19" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="same" lemma="same" stem="same" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="area" lemma="area" stem="area" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="compete" lemma="compete" stem="compet" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNS Groups)) (PP (IN of) (NP (NNS thunderstorms)))) (VP (VBP are) (RB not) (ADJP (RB as) (JJ likely)) (S (VP (TO to) (VP (VB spawn) (NP (NNS tornadoes)) (PP (IN as) (NP (JJ single) (, ,) (JJ large) (NNS storms)))))) (SBAR (IN because) (S (NP (NP (JJ multiple) (NNS storms)) (PP (IN in) (NP (DT the) (JJ same) (NN area)))) (VP (VBP compete))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="spawn tornadoes as single , large storms" type="VP">
          <tokens>
            <token id="9" string="spawn" />
            <token id="10" string="tornadoes" />
            <token id="11" string="as" />
            <token id="12" string="single" />
            <token id="13" string="," />
            <token id="14" string="large" />
            <token id="15" string="storms" />
          </tokens>
        </chunking>
        <chunking id="2" string="compete" type="VP">
          <tokens>
            <token id="23" string="compete" />
          </tokens>
        </chunking>
        <chunking id="3" string="the same area" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="same" />
            <token id="22" string="area" />
          </tokens>
        </chunking>
        <chunking id="4" string="tornadoes" type="NP">
          <tokens>
            <token id="10" string="tornadoes" />
          </tokens>
        </chunking>
        <chunking id="5" string="Groups of thunderstorms" type="NP">
          <tokens>
            <token id="1" string="Groups" />
            <token id="2" string="of" />
            <token id="3" string="thunderstorms" />
          </tokens>
        </chunking>
        <chunking id="6" string="thunderstorms" type="NP">
          <tokens>
            <token id="3" string="thunderstorms" />
          </tokens>
        </chunking>
        <chunking id="7" string="are not as likely to spawn tornadoes as single , large storms because multiple storms in the same area compete" type="VP">
          <tokens>
            <token id="4" string="are" />
            <token id="5" string="not" />
            <token id="6" string="as" />
            <token id="7" string="likely" />
            <token id="8" string="to" />
            <token id="9" string="spawn" />
            <token id="10" string="tornadoes" />
            <token id="11" string="as" />
            <token id="12" string="single" />
            <token id="13" string="," />
            <token id="14" string="large" />
            <token id="15" string="storms" />
            <token id="16" string="because" />
            <token id="17" string="multiple" />
            <token id="18" string="storms" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="same" />
            <token id="22" string="area" />
            <token id="23" string="compete" />
          </tokens>
        </chunking>
        <chunking id="8" string="to spawn tornadoes as single , large storms" type="VP">
          <tokens>
            <token id="8" string="to" />
            <token id="9" string="spawn" />
            <token id="10" string="tornadoes" />
            <token id="11" string="as" />
            <token id="12" string="single" />
            <token id="13" string="," />
            <token id="14" string="large" />
            <token id="15" string="storms" />
          </tokens>
        </chunking>
        <chunking id="9" string="as likely" type="ADJP">
          <tokens>
            <token id="6" string="as" />
            <token id="7" string="likely" />
          </tokens>
        </chunking>
        <chunking id="10" string="single , large storms" type="NP">
          <tokens>
            <token id="12" string="single" />
            <token id="13" string="," />
            <token id="14" string="large" />
            <token id="15" string="storms" />
          </tokens>
        </chunking>
        <chunking id="11" string="because multiple storms in the same area compete" type="SBAR">
          <tokens>
            <token id="16" string="because" />
            <token id="17" string="multiple" />
            <token id="18" string="storms" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="same" />
            <token id="22" string="area" />
            <token id="23" string="compete" />
          </tokens>
        </chunking>
        <chunking id="12" string="Groups" type="NP">
          <tokens>
            <token id="1" string="Groups" />
          </tokens>
        </chunking>
        <chunking id="13" string="multiple storms" type="NP">
          <tokens>
            <token id="17" string="multiple" />
            <token id="18" string="storms" />
          </tokens>
        </chunking>
        <chunking id="14" string="multiple storms in the same area" type="NP">
          <tokens>
            <token id="17" string="multiple" />
            <token id="18" string="storms" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="same" />
            <token id="22" string="area" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="7">likely</governor>
          <dependent id="1">Groups</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">thunderstorms</governor>
          <dependent id="2">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Groups</governor>
          <dependent id="3">thunderstorms</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">likely</governor>
          <dependent id="4">are</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="7">likely</governor>
          <dependent id="5">not</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">likely</governor>
          <dependent id="6">as</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">likely</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">spawn</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="7">likely</governor>
          <dependent id="9">spawn</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">spawn</governor>
          <dependent id="10">tornadoes</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">storms</governor>
          <dependent id="11">as</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">storms</governor>
          <dependent id="12">single</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">storms</governor>
          <dependent id="14">large</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">spawn</governor>
          <dependent id="15">storms</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="23">compete</governor>
          <dependent id="16">because</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">storms</governor>
          <dependent id="17">multiple</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">compete</governor>
          <dependent id="18">storms</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">area</governor>
          <dependent id="19">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">area</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">area</governor>
          <dependent id="21">same</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">storms</governor>
          <dependent id="22">area</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="7">likely</governor>
          <dependent id="23">compete</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="storms" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="15" string="storms" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="21" has_coreference="true">
      <content>&amp;quot;Each one tries to rotate, but they all can&amp;apost;t.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Each" lemma="each" stem="each" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="4" string="tries" lemma="try" stem="tri" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="rotate" lemma="rotate" stem="rotat" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="ca" lemma="can" stem="ca" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (DT Each) (CD one)) (VP (VBZ tries) (S (VP (TO to) (VP (VB rotate)))))) (, ,) (CC but) (S (NP (PRP they)) (ADVP (DT all)) (VP (MD ca) (RB n't))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="rotate" type="VP">
          <tokens>
            <token id="6" string="rotate" />
          </tokens>
        </chunking>
        <chunking id="2" string="Each one" type="NP">
          <tokens>
            <token id="2" string="Each" />
            <token id="3" string="one" />
          </tokens>
        </chunking>
        <chunking id="3" string="they" type="NP">
          <tokens>
            <token id="9" string="they" />
          </tokens>
        </chunking>
        <chunking id="4" string="to rotate" type="VP">
          <tokens>
            <token id="5" string="to" />
            <token id="6" string="rotate" />
          </tokens>
        </chunking>
        <chunking id="5" string="tries to rotate" type="VP">
          <tokens>
            <token id="4" string="tries" />
            <token id="5" string="to" />
            <token id="6" string="rotate" />
          </tokens>
        </chunking>
        <chunking id="6" string="ca n't" type="VP">
          <tokens>
            <token id="11" string="ca" />
            <token id="12" string="n't" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">one</governor>
          <dependent id="2">Each</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">tries</governor>
          <dependent id="3">one</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">tries</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">rotate</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">tries</governor>
          <dependent id="6">rotate</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">tries</governor>
          <dependent id="8">but</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">ca</governor>
          <dependent id="9">they</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">ca</governor>
          <dependent id="10">all</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">tries</governor>
          <dependent id="11">ca</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="11">ca</governor>
          <dependent id="12">n't</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="3" string="one" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="22" has_coreference="true">
      <content>They&amp;apost;re just like human beings: The rich may become richer and the poor may get poorer.&amp;quot;</content>
      <tokens>
        <token id="1" string="They" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="'re" lemma="be" stem="'re" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="human" lemma="human" stem="human" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="beings" lemma="being" stem="be" pos="NNS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="rich" lemma="rich" stem="rich" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="may" lemma="may" stem="mai" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="become" lemma="become" stem="becom" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="richer" lemma="richer" stem="richer" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="poor" lemma="poor" stem="poor" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="may" lemma="may" stem="mai" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="get" lemma="get" stem="get" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="poorer" lemma="poorer" stem="poorer" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP They)) (VP (VBP 're) (ADVP (RB just)) (PP (IN like) (NP (JJ human) (NNS beings))))) (: :) (S (NP (DT The) (JJ rich)) (VP (MD may) (VP (VB become) (NP (JJR richer))))) (CC and) (S (NP (DT the) (JJ poor)) (VP (MD may) (VP (VB get) (NP (JJR poorer))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="They" type="NP">
          <tokens>
            <token id="1" string="They" />
          </tokens>
        </chunking>
        <chunking id="2" string="the poor" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="poor" />
          </tokens>
        </chunking>
        <chunking id="3" string="poorer" type="NP">
          <tokens>
            <token id="18" string="poorer" />
          </tokens>
        </chunking>
        <chunking id="4" string="get poorer" type="VP">
          <tokens>
            <token id="17" string="get" />
            <token id="18" string="poorer" />
          </tokens>
        </chunking>
        <chunking id="5" string="The rich" type="NP">
          <tokens>
            <token id="8" string="The" />
            <token id="9" string="rich" />
          </tokens>
        </chunking>
        <chunking id="6" string="become richer" type="VP">
          <tokens>
            <token id="11" string="become" />
            <token id="12" string="richer" />
          </tokens>
        </chunking>
        <chunking id="7" string="richer" type="NP">
          <tokens>
            <token id="12" string="richer" />
          </tokens>
        </chunking>
        <chunking id="8" string="'re just like human beings" type="VP">
          <tokens>
            <token id="2" string="'re" />
            <token id="3" string="just" />
            <token id="4" string="like" />
            <token id="5" string="human" />
            <token id="6" string="beings" />
          </tokens>
        </chunking>
        <chunking id="9" string="may become richer" type="VP">
          <tokens>
            <token id="10" string="may" />
            <token id="11" string="become" />
            <token id="12" string="richer" />
          </tokens>
        </chunking>
        <chunking id="10" string="human beings" type="NP">
          <tokens>
            <token id="5" string="human" />
            <token id="6" string="beings" />
          </tokens>
        </chunking>
        <chunking id="11" string="may get poorer" type="VP">
          <tokens>
            <token id="16" string="may" />
            <token id="17" string="get" />
            <token id="18" string="poorer" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="6">beings</governor>
          <dependent id="1">They</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">beings</governor>
          <dependent id="2">'re</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">beings</governor>
          <dependent id="3">just</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">beings</governor>
          <dependent id="4">like</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">beings</governor>
          <dependent id="5">human</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">beings</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">rich</governor>
          <dependent id="8">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">become</governor>
          <dependent id="9">rich</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">become</governor>
          <dependent id="10">may</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">beings</governor>
          <dependent id="11">become</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="11">become</governor>
          <dependent id="12">richer</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">beings</governor>
          <dependent id="13">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">poor</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">get</governor>
          <dependent id="15">poor</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="17">get</governor>
          <dependent id="16">may</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">beings</governor>
          <dependent id="17">get</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">get</governor>
          <dependent id="18">poorer</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="23" has_coreference="true">
      <content>Fujita also discovered that most strong tornadoes are actually six or seven small twisters he calls suction vortices, rotating around the center of a larger tornado.</content>
      <tokens>
        <token id="1" string="Fujita" lemma="Fujita" stem="fujita" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="discovered" lemma="discover" stem="discov" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="most" lemma="most" stem="most" pos="JJS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="strong" lemma="strong" stem="strong" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="tornadoes" lemma="tornado" stem="tornado" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="actually" lemma="actually" stem="actual" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="six" lemma="six" stem="six" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="11" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="seven" lemma="seven" stem="seven" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="13" string="small" lemma="small" stem="small" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="twisters" lemma="twister" stem="twister" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="calls" lemma="call" stem="call" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="suction" lemma="suction" stem="suction" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="vortices" lemma="vortex" stem="vortic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="rotating" lemma="rotate" stem="rotat" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="around" lemma="around" stem="around" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="center" lemma="center" stem="center" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="larger" lemma="larger" stem="larger" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="tornado" lemma="tornado" stem="tornado" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Fujita)) (ADVP (RB also)) (VP (VBD discovered) (SBAR (IN that) (S (NP (JJS most) (JJ strong) (NNS tornadoes)) (VP (VBP are) (ADVP (RB actually)) (NP (NP (QP (CD six) (CC or) (CD seven)) (JJ small) (NNS twisters)) (SBAR (S (NP (PRP he)) (VP (VBZ calls) (NP (NP (NN suction) (NNS vortices)) (, ,) (NP (NP (VBG rotating)) (PP (IN around) (NP (NP (DT the) (NN center)) (PP (IN of) (NP (DT a) (JJR larger) (NN tornado))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="discovered that most strong tornadoes are actually six or seven small twisters he calls suction vortices , rotating around the center of a larger tornado" type="VP">
          <tokens>
            <token id="3" string="discovered" />
            <token id="4" string="that" />
            <token id="5" string="most" />
            <token id="6" string="strong" />
            <token id="7" string="tornadoes" />
            <token id="8" string="are" />
            <token id="9" string="actually" />
            <token id="10" string="six" />
            <token id="11" string="or" />
            <token id="12" string="seven" />
            <token id="13" string="small" />
            <token id="14" string="twisters" />
            <token id="15" string="he" />
            <token id="16" string="calls" />
            <token id="17" string="suction" />
            <token id="18" string="vortices" />
            <token id="19" string="," />
            <token id="20" string="rotating" />
            <token id="21" string="around" />
            <token id="22" string="the" />
            <token id="23" string="center" />
            <token id="24" string="of" />
            <token id="25" string="a" />
            <token id="26" string="larger" />
            <token id="27" string="tornado" />
          </tokens>
        </chunking>
        <chunking id="2" string="are actually six or seven small twisters he calls suction vortices , rotating around the center of a larger tornado" type="VP">
          <tokens>
            <token id="8" string="are" />
            <token id="9" string="actually" />
            <token id="10" string="six" />
            <token id="11" string="or" />
            <token id="12" string="seven" />
            <token id="13" string="small" />
            <token id="14" string="twisters" />
            <token id="15" string="he" />
            <token id="16" string="calls" />
            <token id="17" string="suction" />
            <token id="18" string="vortices" />
            <token id="19" string="," />
            <token id="20" string="rotating" />
            <token id="21" string="around" />
            <token id="22" string="the" />
            <token id="23" string="center" />
            <token id="24" string="of" />
            <token id="25" string="a" />
            <token id="26" string="larger" />
            <token id="27" string="tornado" />
          </tokens>
        </chunking>
        <chunking id="3" string="suction vortices" type="NP">
          <tokens>
            <token id="17" string="suction" />
            <token id="18" string="vortices" />
          </tokens>
        </chunking>
        <chunking id="4" string="suction vortices , rotating around the center of a larger tornado" type="NP">
          <tokens>
            <token id="17" string="suction" />
            <token id="18" string="vortices" />
            <token id="19" string="," />
            <token id="20" string="rotating" />
            <token id="21" string="around" />
            <token id="22" string="the" />
            <token id="23" string="center" />
            <token id="24" string="of" />
            <token id="25" string="a" />
            <token id="26" string="larger" />
            <token id="27" string="tornado" />
          </tokens>
        </chunking>
        <chunking id="5" string="the center" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="center" />
          </tokens>
        </chunking>
        <chunking id="6" string="rotating" type="NP">
          <tokens>
            <token id="20" string="rotating" />
          </tokens>
        </chunking>
        <chunking id="7" string="the center of a larger tornado" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="center" />
            <token id="24" string="of" />
            <token id="25" string="a" />
            <token id="26" string="larger" />
            <token id="27" string="tornado" />
          </tokens>
        </chunking>
        <chunking id="8" string="Fujita" type="NP">
          <tokens>
            <token id="1" string="Fujita" />
          </tokens>
        </chunking>
        <chunking id="9" string="he calls suction vortices , rotating around the center of a larger tornado" type="SBAR">
          <tokens>
            <token id="15" string="he" />
            <token id="16" string="calls" />
            <token id="17" string="suction" />
            <token id="18" string="vortices" />
            <token id="19" string="," />
            <token id="20" string="rotating" />
            <token id="21" string="around" />
            <token id="22" string="the" />
            <token id="23" string="center" />
            <token id="24" string="of" />
            <token id="25" string="a" />
            <token id="26" string="larger" />
            <token id="27" string="tornado" />
          </tokens>
        </chunking>
        <chunking id="10" string="most strong tornadoes" type="NP">
          <tokens>
            <token id="5" string="most" />
            <token id="6" string="strong" />
            <token id="7" string="tornadoes" />
          </tokens>
        </chunking>
        <chunking id="11" string="six or seven small twisters" type="NP">
          <tokens>
            <token id="10" string="six" />
            <token id="11" string="or" />
            <token id="12" string="seven" />
            <token id="13" string="small" />
            <token id="14" string="twisters" />
          </tokens>
        </chunking>
        <chunking id="12" string="rotating around the center of a larger tornado" type="NP">
          <tokens>
            <token id="20" string="rotating" />
            <token id="21" string="around" />
            <token id="22" string="the" />
            <token id="23" string="center" />
            <token id="24" string="of" />
            <token id="25" string="a" />
            <token id="26" string="larger" />
            <token id="27" string="tornado" />
          </tokens>
        </chunking>
        <chunking id="13" string="that most strong tornadoes are actually six or seven small twisters he calls suction vortices , rotating around the center of a larger tornado" type="SBAR">
          <tokens>
            <token id="4" string="that" />
            <token id="5" string="most" />
            <token id="6" string="strong" />
            <token id="7" string="tornadoes" />
            <token id="8" string="are" />
            <token id="9" string="actually" />
            <token id="10" string="six" />
            <token id="11" string="or" />
            <token id="12" string="seven" />
            <token id="13" string="small" />
            <token id="14" string="twisters" />
            <token id="15" string="he" />
            <token id="16" string="calls" />
            <token id="17" string="suction" />
            <token id="18" string="vortices" />
            <token id="19" string="," />
            <token id="20" string="rotating" />
            <token id="21" string="around" />
            <token id="22" string="the" />
            <token id="23" string="center" />
            <token id="24" string="of" />
            <token id="25" string="a" />
            <token id="26" string="larger" />
            <token id="27" string="tornado" />
          </tokens>
        </chunking>
        <chunking id="14" string="six or seven small twisters he calls suction vortices , rotating around the center of a larger tornado" type="NP">
          <tokens>
            <token id="10" string="six" />
            <token id="11" string="or" />
            <token id="12" string="seven" />
            <token id="13" string="small" />
            <token id="14" string="twisters" />
            <token id="15" string="he" />
            <token id="16" string="calls" />
            <token id="17" string="suction" />
            <token id="18" string="vortices" />
            <token id="19" string="," />
            <token id="20" string="rotating" />
            <token id="21" string="around" />
            <token id="22" string="the" />
            <token id="23" string="center" />
            <token id="24" string="of" />
            <token id="25" string="a" />
            <token id="26" string="larger" />
            <token id="27" string="tornado" />
          </tokens>
        </chunking>
        <chunking id="15" string="he" type="NP">
          <tokens>
            <token id="15" string="he" />
          </tokens>
        </chunking>
        <chunking id="16" string="calls suction vortices , rotating around the center of a larger tornado" type="VP">
          <tokens>
            <token id="16" string="calls" />
            <token id="17" string="suction" />
            <token id="18" string="vortices" />
            <token id="19" string="," />
            <token id="20" string="rotating" />
            <token id="21" string="around" />
            <token id="22" string="the" />
            <token id="23" string="center" />
            <token id="24" string="of" />
            <token id="25" string="a" />
            <token id="26" string="larger" />
            <token id="27" string="tornado" />
          </tokens>
        </chunking>
        <chunking id="17" string="a larger tornado" type="NP">
          <tokens>
            <token id="25" string="a" />
            <token id="26" string="larger" />
            <token id="27" string="tornado" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">discovered</governor>
          <dependent id="1">Fujita</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">discovered</governor>
          <dependent id="2">also</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">discovered</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">twisters</governor>
          <dependent id="4">that</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">tornadoes</governor>
          <dependent id="5">most</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">tornadoes</governor>
          <dependent id="6">strong</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">twisters</governor>
          <dependent id="7">tornadoes</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="14">twisters</governor>
          <dependent id="8">are</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">twisters</governor>
          <dependent id="9">actually</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="14">twisters</governor>
          <dependent id="10">six</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">six</governor>
          <dependent id="11">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">six</governor>
          <dependent id="12">seven</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">twisters</governor>
          <dependent id="13">small</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">discovered</governor>
          <dependent id="14">twisters</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">calls</governor>
          <dependent id="15">he</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="14">twisters</governor>
          <dependent id="16">calls</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">vortices</governor>
          <dependent id="17">suction</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">calls</governor>
          <dependent id="18">vortices</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="18">vortices</governor>
          <dependent id="20">rotating</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">center</governor>
          <dependent id="21">around</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">center</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">rotating</governor>
          <dependent id="23">center</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">tornado</governor>
          <dependent id="24">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">tornado</governor>
          <dependent id="25">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="27">tornado</governor>
          <dependent id="26">larger</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">center</governor>
          <dependent id="27">tornado</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="six" type="NUMBER" score="0.0">
          <tokens>
            <token id="10" string="six" />
          </tokens>
        </entity>
        <entity id="2" string="tornado" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="27" string="tornado" />
          </tokens>
        </entity>
        <entity id="3" string="seven" type="NUMBER" score="0.0">
          <tokens>
            <token id="12" string="seven" />
          </tokens>
        </entity>
        <entity id="4" string="Fujita" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Fujita" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="24" has_coreference="true">
      <content>&amp;quot;A suction vortex can pick up a car or a small house or something, but when you&amp;apost;re standing right next to it you can be completely safe.&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="suction" lemma="suction" stem="suction" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="vortex" lemma="vortex" stem="vortex" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="pick" lemma="pick" stem="pick" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="car" lemma="car" stem="car" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="small" lemma="small" stem="small" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="house" lemma="house" stem="hous" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="something" lemma="something" stem="someth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="'re" lemma="be" stem="'re" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="standing" lemma="stand" stem="stand" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="right" lemma="right" stem="right" pos="RB" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="true" is_refers="false" />
        <token id="23" string="next" lemma="next" stem="next" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="completely" lemma="completely" stem="complet" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="safe" lemma="safe" stem="safe" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (DT A) (NN suction) (NN vortex)) (VP (MD can) (VP (VB pick) (PRT (RP up)) (NP (NP (DT a) (NN car)) (CC or) (NP (DT a) (JJ small) (NN house) (CC or) (NN something)))))) (, ,) (CC but) (S (SBAR (WHADVP (WRB when)) (S (NP (PRP you)) (VP (VBP 're) (VP (VBG standing) (ADVP (RB right) (JJ next)) (PP (TO to) (NP (PRP it))))))) (NP (PRP you)) (VP (MD can) (VP (VB be) (ADJP (RB completely) (JJ safe))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="'re standing right next to it" type="VP">
          <tokens>
            <token id="20" string="'re" />
            <token id="21" string="standing" />
            <token id="22" string="right" />
            <token id="23" string="next" />
            <token id="24" string="to" />
            <token id="25" string="it" />
          </tokens>
        </chunking>
        <chunking id="2" string="be completely safe" type="VP">
          <tokens>
            <token id="28" string="be" />
            <token id="29" string="completely" />
            <token id="30" string="safe" />
          </tokens>
        </chunking>
        <chunking id="3" string="it" type="NP">
          <tokens>
            <token id="25" string="it" />
          </tokens>
        </chunking>
        <chunking id="4" string="a car or a small house or something" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="car" />
            <token id="10" string="or" />
            <token id="11" string="a" />
            <token id="12" string="small" />
            <token id="13" string="house" />
            <token id="14" string="or" />
            <token id="15" string="something" />
          </tokens>
        </chunking>
        <chunking id="5" string="when" type="WHADVP">
          <tokens>
            <token id="18" string="when" />
          </tokens>
        </chunking>
        <chunking id="6" string="completely safe" type="ADJP">
          <tokens>
            <token id="29" string="completely" />
            <token id="30" string="safe" />
          </tokens>
        </chunking>
        <chunking id="7" string="can pick up a car or a small house or something" type="VP">
          <tokens>
            <token id="5" string="can" />
            <token id="6" string="pick" />
            <token id="7" string="up" />
            <token id="8" string="a" />
            <token id="9" string="car" />
            <token id="10" string="or" />
            <token id="11" string="a" />
            <token id="12" string="small" />
            <token id="13" string="house" />
            <token id="14" string="or" />
            <token id="15" string="something" />
          </tokens>
        </chunking>
        <chunking id="8" string="standing right next to it" type="VP">
          <tokens>
            <token id="21" string="standing" />
            <token id="22" string="right" />
            <token id="23" string="next" />
            <token id="24" string="to" />
            <token id="25" string="it" />
          </tokens>
        </chunking>
        <chunking id="9" string="a car" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="car" />
          </tokens>
        </chunking>
        <chunking id="10" string="pick up a car or a small house or something" type="VP">
          <tokens>
            <token id="6" string="pick" />
            <token id="7" string="up" />
            <token id="8" string="a" />
            <token id="9" string="car" />
            <token id="10" string="or" />
            <token id="11" string="a" />
            <token id="12" string="small" />
            <token id="13" string="house" />
            <token id="14" string="or" />
            <token id="15" string="something" />
          </tokens>
        </chunking>
        <chunking id="11" string="a small house or something" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="small" />
            <token id="13" string="house" />
            <token id="14" string="or" />
            <token id="15" string="something" />
          </tokens>
        </chunking>
        <chunking id="12" string="A suction vortex" type="NP">
          <tokens>
            <token id="2" string="A" />
            <token id="3" string="suction" />
            <token id="4" string="vortex" />
          </tokens>
        </chunking>
        <chunking id="13" string="when you 're standing right next to it" type="SBAR">
          <tokens>
            <token id="18" string="when" />
            <token id="19" string="you" />
            <token id="20" string="'re" />
            <token id="21" string="standing" />
            <token id="22" string="right" />
            <token id="23" string="next" />
            <token id="24" string="to" />
            <token id="25" string="it" />
          </tokens>
        </chunking>
        <chunking id="14" string="can be completely safe" type="VP">
          <tokens>
            <token id="27" string="can" />
            <token id="28" string="be" />
            <token id="29" string="completely" />
            <token id="30" string="safe" />
          </tokens>
        </chunking>
        <chunking id="15" string="you" type="NP">
          <tokens>
            <token id="19" string="you" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="4">vortex</governor>
          <dependent id="2">A</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">vortex</governor>
          <dependent id="3">suction</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">pick</governor>
          <dependent id="4">vortex</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">pick</governor>
          <dependent id="5">can</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">pick</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="6">pick</governor>
          <dependent id="7">up</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">car</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">pick</governor>
          <dependent id="9">car</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">car</governor>
          <dependent id="10">or</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">house</governor>
          <dependent id="11">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">house</governor>
          <dependent id="12">small</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">car</governor>
          <dependent id="13">house</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">house</governor>
          <dependent id="14">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">house</governor>
          <dependent id="15">something</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">pick</governor>
          <dependent id="17">but</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="21">standing</governor>
          <dependent id="18">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">standing</governor>
          <dependent id="19">you</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="21">standing</governor>
          <dependent id="20">'re</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="30">safe</governor>
          <dependent id="21">standing</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="23">next</governor>
          <dependent id="22">right</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="21">standing</governor>
          <dependent id="23">next</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">it</governor>
          <dependent id="24">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">standing</governor>
          <dependent id="25">it</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="30">safe</governor>
          <dependent id="26">you</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="30">safe</governor>
          <dependent id="27">can</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="30">safe</governor>
          <dependent id="28">be</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="30">safe</governor>
          <dependent id="29">completely</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">pick</governor>
          <dependent id="30">safe</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="right" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="22" string="right" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="25" has_coreference="true">
      <content>He has studied tornadoes that have dropped houses into lakes, made off with one car and left another right next to it untouched, and moved whole flocks of cows and sheep -- which lived through the experience.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="studied" lemma="study" stem="studi" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="tornadoes" lemma="tornado" stem="tornado" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="dropped" lemma="drop" stem="drop" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="houses" lemma="house" stem="hous" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="lakes" lemma="lake" stem="lake" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="made" lemma="make" stem="made" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="off" lemma="off" stem="off" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="16" string="car" lemma="car" stem="car" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="left" lemma="leave" stem="left" pos="VBD" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="19" string="another" lemma="another" stem="anoth" pos="DT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="right" lemma="right" stem="right" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="21" string="next" lemma="next" stem="next" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="untouched" lemma="untouch" stem="untouch" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="moved" lemma="move" stem="move" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="whole" lemma="whole" stem="whole" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="flocks" lemma="flock" stem="flock" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="cows" lemma="cow" stem="cow" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="sheep" lemma="sheep" stem="sheep" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="lived" lemma="live" stem="live" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="experience" lemma="experience" stem="experi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VBZ has) (VP (VBN studied) (NP (NP (NNS tornadoes)) (SBAR (WHNP (WDT that)) (S (VP (VP (VBP have) (VP (VBN dropped) (NP (NNS houses)) (PP (IN into) (NP (NNS lakes))))) (, ,) (VP (VBD made) (PRT (RP off)) (PP (IN with) (NP (CD one) (NN car)))) (CC and) (VP (VBD left) (SBAR (S (NP (NP (DT another) (JJ right) (JJ next)) (PP (TO to) (NP (PRP it)))) (VP (VP (VBD untouched)) (, ,) (CC and) (VP (VBD moved) (NP (NP (JJ whole) (NNS flocks)) (PP (IN of) (NP (NNS cows) (CC and) (NN sheep)))))))))))) (: --) (SBAR (WHNP (WDT which)) (S (VP (VBD lived) (PP (IN through) (NP (DT the) (NN experience))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="tornadoes" type="NP">
          <tokens>
            <token id="4" string="tornadoes" />
          </tokens>
        </chunking>
        <chunking id="2" string="has studied tornadoes that have dropped houses into lakes , made off with one car and left another right next to it untouched , and moved whole flocks of cows and sheep -- which lived through the experience" type="VP">
          <tokens>
            <token id="2" string="has" />
            <token id="3" string="studied" />
            <token id="4" string="tornadoes" />
            <token id="5" string="that" />
            <token id="6" string="have" />
            <token id="7" string="dropped" />
            <token id="8" string="houses" />
            <token id="9" string="into" />
            <token id="10" string="lakes" />
            <token id="11" string="," />
            <token id="12" string="made" />
            <token id="13" string="off" />
            <token id="14" string="with" />
            <token id="15" string="one" />
            <token id="16" string="car" />
            <token id="17" string="and" />
            <token id="18" string="left" />
            <token id="19" string="another" />
            <token id="20" string="right" />
            <token id="21" string="next" />
            <token id="22" string="to" />
            <token id="23" string="it" />
            <token id="24" string="untouched" />
            <token id="25" string="," />
            <token id="26" string="and" />
            <token id="27" string="moved" />
            <token id="28" string="whole" />
            <token id="29" string="flocks" />
            <token id="30" string="of" />
            <token id="31" string="cows" />
            <token id="32" string="and" />
            <token id="33" string="sheep" />
            <token id="34" string="--" />
            <token id="35" string="which" />
            <token id="36" string="lived" />
            <token id="37" string="through" />
            <token id="38" string="the" />
            <token id="39" string="experience" />
          </tokens>
        </chunking>
        <chunking id="3" string="another right next to it untouched , and moved whole flocks of cows and sheep" type="SBAR">
          <tokens>
            <token id="19" string="another" />
            <token id="20" string="right" />
            <token id="21" string="next" />
            <token id="22" string="to" />
            <token id="23" string="it" />
            <token id="24" string="untouched" />
            <token id="25" string="," />
            <token id="26" string="and" />
            <token id="27" string="moved" />
            <token id="28" string="whole" />
            <token id="29" string="flocks" />
            <token id="30" string="of" />
            <token id="31" string="cows" />
            <token id="32" string="and" />
            <token id="33" string="sheep" />
          </tokens>
        </chunking>
        <chunking id="4" string="it" type="NP">
          <tokens>
            <token id="23" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="cows and sheep" type="NP">
          <tokens>
            <token id="31" string="cows" />
            <token id="32" string="and" />
            <token id="33" string="sheep" />
          </tokens>
        </chunking>
        <chunking id="6" string="tornadoes that have dropped houses into lakes , made off with one car and left another right next to it untouched , and moved whole flocks of cows and sheep -- which lived through the experience" type="NP">
          <tokens>
            <token id="4" string="tornadoes" />
            <token id="5" string="that" />
            <token id="6" string="have" />
            <token id="7" string="dropped" />
            <token id="8" string="houses" />
            <token id="9" string="into" />
            <token id="10" string="lakes" />
            <token id="11" string="," />
            <token id="12" string="made" />
            <token id="13" string="off" />
            <token id="14" string="with" />
            <token id="15" string="one" />
            <token id="16" string="car" />
            <token id="17" string="and" />
            <token id="18" string="left" />
            <token id="19" string="another" />
            <token id="20" string="right" />
            <token id="21" string="next" />
            <token id="22" string="to" />
            <token id="23" string="it" />
            <token id="24" string="untouched" />
            <token id="25" string="," />
            <token id="26" string="and" />
            <token id="27" string="moved" />
            <token id="28" string="whole" />
            <token id="29" string="flocks" />
            <token id="30" string="of" />
            <token id="31" string="cows" />
            <token id="32" string="and" />
            <token id="33" string="sheep" />
            <token id="34" string="--" />
            <token id="35" string="which" />
            <token id="36" string="lived" />
            <token id="37" string="through" />
            <token id="38" string="the" />
            <token id="39" string="experience" />
          </tokens>
        </chunking>
        <chunking id="7" string="dropped houses into lakes" type="VP">
          <tokens>
            <token id="7" string="dropped" />
            <token id="8" string="houses" />
            <token id="9" string="into" />
            <token id="10" string="lakes" />
          </tokens>
        </chunking>
        <chunking id="8" string="have dropped houses into lakes , made off with one car and left another right next to it untouched , and moved whole flocks of cows and sheep" type="VP">
          <tokens>
            <token id="6" string="have" />
            <token id="7" string="dropped" />
            <token id="8" string="houses" />
            <token id="9" string="into" />
            <token id="10" string="lakes" />
            <token id="11" string="," />
            <token id="12" string="made" />
            <token id="13" string="off" />
            <token id="14" string="with" />
            <token id="15" string="one" />
            <token id="16" string="car" />
            <token id="17" string="and" />
            <token id="18" string="left" />
            <token id="19" string="another" />
            <token id="20" string="right" />
            <token id="21" string="next" />
            <token id="22" string="to" />
            <token id="23" string="it" />
            <token id="24" string="untouched" />
            <token id="25" string="," />
            <token id="26" string="and" />
            <token id="27" string="moved" />
            <token id="28" string="whole" />
            <token id="29" string="flocks" />
            <token id="30" string="of" />
            <token id="31" string="cows" />
            <token id="32" string="and" />
            <token id="33" string="sheep" />
          </tokens>
        </chunking>
        <chunking id="9" string="one car" type="NP">
          <tokens>
            <token id="15" string="one" />
            <token id="16" string="car" />
          </tokens>
        </chunking>
        <chunking id="10" string="have dropped houses into lakes" type="VP">
          <tokens>
            <token id="6" string="have" />
            <token id="7" string="dropped" />
            <token id="8" string="houses" />
            <token id="9" string="into" />
            <token id="10" string="lakes" />
          </tokens>
        </chunking>
        <chunking id="11" string="untouched , and moved whole flocks of cows and sheep" type="VP">
          <tokens>
            <token id="24" string="untouched" />
            <token id="25" string="," />
            <token id="26" string="and" />
            <token id="27" string="moved" />
            <token id="28" string="whole" />
            <token id="29" string="flocks" />
            <token id="30" string="of" />
            <token id="31" string="cows" />
            <token id="32" string="and" />
            <token id="33" string="sheep" />
          </tokens>
        </chunking>
        <chunking id="12" string="the experience" type="NP">
          <tokens>
            <token id="38" string="the" />
            <token id="39" string="experience" />
          </tokens>
        </chunking>
        <chunking id="13" string="another right next to it" type="NP">
          <tokens>
            <token id="19" string="another" />
            <token id="20" string="right" />
            <token id="21" string="next" />
            <token id="22" string="to" />
            <token id="23" string="it" />
          </tokens>
        </chunking>
        <chunking id="14" string="left another right next to it untouched , and moved whole flocks of cows and sheep" type="VP">
          <tokens>
            <token id="18" string="left" />
            <token id="19" string="another" />
            <token id="20" string="right" />
            <token id="21" string="next" />
            <token id="22" string="to" />
            <token id="23" string="it" />
            <token id="24" string="untouched" />
            <token id="25" string="," />
            <token id="26" string="and" />
            <token id="27" string="moved" />
            <token id="28" string="whole" />
            <token id="29" string="flocks" />
            <token id="30" string="of" />
            <token id="31" string="cows" />
            <token id="32" string="and" />
            <token id="33" string="sheep" />
          </tokens>
        </chunking>
        <chunking id="15" string="which lived through the experience" type="SBAR">
          <tokens>
            <token id="35" string="which" />
            <token id="36" string="lived" />
            <token id="37" string="through" />
            <token id="38" string="the" />
            <token id="39" string="experience" />
          </tokens>
        </chunking>
        <chunking id="16" string="lived through the experience" type="VP">
          <tokens>
            <token id="36" string="lived" />
            <token id="37" string="through" />
            <token id="38" string="the" />
            <token id="39" string="experience" />
          </tokens>
        </chunking>
        <chunking id="17" string="that have dropped houses into lakes , made off with one car and left another right next to it untouched , and moved whole flocks of cows and sheep" type="SBAR">
          <tokens>
            <token id="5" string="that" />
            <token id="6" string="have" />
            <token id="7" string="dropped" />
            <token id="8" string="houses" />
            <token id="9" string="into" />
            <token id="10" string="lakes" />
            <token id="11" string="," />
            <token id="12" string="made" />
            <token id="13" string="off" />
            <token id="14" string="with" />
            <token id="15" string="one" />
            <token id="16" string="car" />
            <token id="17" string="and" />
            <token id="18" string="left" />
            <token id="19" string="another" />
            <token id="20" string="right" />
            <token id="21" string="next" />
            <token id="22" string="to" />
            <token id="23" string="it" />
            <token id="24" string="untouched" />
            <token id="25" string="," />
            <token id="26" string="and" />
            <token id="27" string="moved" />
            <token id="28" string="whole" />
            <token id="29" string="flocks" />
            <token id="30" string="of" />
            <token id="31" string="cows" />
            <token id="32" string="and" />
            <token id="33" string="sheep" />
          </tokens>
        </chunking>
        <chunking id="18" string="whole flocks of cows and sheep" type="NP">
          <tokens>
            <token id="28" string="whole" />
            <token id="29" string="flocks" />
            <token id="30" string="of" />
            <token id="31" string="cows" />
            <token id="32" string="and" />
            <token id="33" string="sheep" />
          </tokens>
        </chunking>
        <chunking id="19" string="untouched" type="VP">
          <tokens>
            <token id="24" string="untouched" />
          </tokens>
        </chunking>
        <chunking id="20" string="made off with one car" type="VP">
          <tokens>
            <token id="12" string="made" />
            <token id="13" string="off" />
            <token id="14" string="with" />
            <token id="15" string="one" />
            <token id="16" string="car" />
          </tokens>
        </chunking>
        <chunking id="21" string="studied tornadoes that have dropped houses into lakes , made off with one car and left another right next to it untouched , and moved whole flocks of cows and sheep -- which lived through the experience" type="VP">
          <tokens>
            <token id="3" string="studied" />
            <token id="4" string="tornadoes" />
            <token id="5" string="that" />
            <token id="6" string="have" />
            <token id="7" string="dropped" />
            <token id="8" string="houses" />
            <token id="9" string="into" />
            <token id="10" string="lakes" />
            <token id="11" string="," />
            <token id="12" string="made" />
            <token id="13" string="off" />
            <token id="14" string="with" />
            <token id="15" string="one" />
            <token id="16" string="car" />
            <token id="17" string="and" />
            <token id="18" string="left" />
            <token id="19" string="another" />
            <token id="20" string="right" />
            <token id="21" string="next" />
            <token id="22" string="to" />
            <token id="23" string="it" />
            <token id="24" string="untouched" />
            <token id="25" string="," />
            <token id="26" string="and" />
            <token id="27" string="moved" />
            <token id="28" string="whole" />
            <token id="29" string="flocks" />
            <token id="30" string="of" />
            <token id="31" string="cows" />
            <token id="32" string="and" />
            <token id="33" string="sheep" />
            <token id="34" string="--" />
            <token id="35" string="which" />
            <token id="36" string="lived" />
            <token id="37" string="through" />
            <token id="38" string="the" />
            <token id="39" string="experience" />
          </tokens>
        </chunking>
        <chunking id="22" string="another right next" type="NP">
          <tokens>
            <token id="19" string="another" />
            <token id="20" string="right" />
            <token id="21" string="next" />
          </tokens>
        </chunking>
        <chunking id="23" string="whole flocks" type="NP">
          <tokens>
            <token id="28" string="whole" />
            <token id="29" string="flocks" />
          </tokens>
        </chunking>
        <chunking id="24" string="moved whole flocks of cows and sheep" type="VP">
          <tokens>
            <token id="27" string="moved" />
            <token id="28" string="whole" />
            <token id="29" string="flocks" />
            <token id="30" string="of" />
            <token id="31" string="cows" />
            <token id="32" string="and" />
            <token id="33" string="sheep" />
          </tokens>
        </chunking>
        <chunking id="25" string="houses" type="NP">
          <tokens>
            <token id="8" string="houses" />
          </tokens>
        </chunking>
        <chunking id="26" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="27" string="lakes" type="NP">
          <tokens>
            <token id="10" string="lakes" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">studied</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="3">studied</governor>
          <dependent id="2">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">studied</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">studied</governor>
          <dependent id="4">tornadoes</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">dropped</governor>
          <dependent id="5">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">dropped</governor>
          <dependent id="6">have</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="4">tornadoes</governor>
          <dependent id="7">dropped</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">dropped</governor>
          <dependent id="8">houses</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">lakes</governor>
          <dependent id="9">into</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">dropped</governor>
          <dependent id="10">lakes</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">dropped</governor>
          <dependent id="12">made</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="12">made</governor>
          <dependent id="13">off</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">car</governor>
          <dependent id="14">with</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="16">car</governor>
          <dependent id="15">one</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">made</governor>
          <dependent id="16">car</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">dropped</governor>
          <dependent id="17">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">dropped</governor>
          <dependent id="18">left</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">it</governor>
          <dependent id="19">another</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">it</governor>
          <dependent id="20">right</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">it</governor>
          <dependent id="21">next</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="21">next</governor>
          <dependent id="22">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">untouched</governor>
          <dependent id="23">it</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="18">left</governor>
          <dependent id="24">untouched</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="24">untouched</governor>
          <dependent id="26">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="24">untouched</governor>
          <dependent id="27">moved</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="29">flocks</governor>
          <dependent id="28">whole</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="27">moved</governor>
          <dependent id="29">flocks</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">cows</governor>
          <dependent id="30">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">flocks</governor>
          <dependent id="31">cows</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="31">cows</governor>
          <dependent id="32">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="31">cows</governor>
          <dependent id="33">sheep</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="36">lived</governor>
          <dependent id="35">which</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="4">tornadoes</governor>
          <dependent id="36">lived</dependent>
        </dependency>
        <dependency type="case">
          <governor id="39">experience</governor>
          <dependent id="37">through</dependent>
        </dependency>
        <dependency type="det">
          <governor id="39">experience</governor>
          <dependent id="38">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="36">lived</governor>
          <dependent id="39">experience</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="15" string="one" />
          </tokens>
        </entity>
        <entity id="2" string="left" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="18" string="left" />
          </tokens>
        </entity>
        <entity id="3" string="right" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="20" string="right" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="26" has_coreference="true">
      <content>He also developed the Fujita scale for measuring the strength of tornadoes.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="developed" lemma="develop" stem="develop" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="Fujita" lemma="Fujita" stem="fujita" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="6" string="scale" lemma="scale" stem="scale" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="measuring" lemma="measure" stem="measur" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="strength" lemma="strength" stem="strength" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="tornadoes" lemma="tornado" stem="tornado" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (ADVP (RB also)) (VP (VBD developed) (NP (DT the) (NNP Fujita) (NN scale)) (PP (IN for) (S (VP (VBG measuring) (NP (NP (DT the) (NN strength)) (PP (IN of) (NP (NNS tornadoes)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the Fujita scale" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="Fujita" />
            <token id="6" string="scale" />
          </tokens>
        </chunking>
        <chunking id="2" string="developed the Fujita scale for measuring the strength of tornadoes" type="VP">
          <tokens>
            <token id="3" string="developed" />
            <token id="4" string="the" />
            <token id="5" string="Fujita" />
            <token id="6" string="scale" />
            <token id="7" string="for" />
            <token id="8" string="measuring" />
            <token id="9" string="the" />
            <token id="10" string="strength" />
            <token id="11" string="of" />
            <token id="12" string="tornadoes" />
          </tokens>
        </chunking>
        <chunking id="3" string="tornadoes" type="NP">
          <tokens>
            <token id="12" string="tornadoes" />
          </tokens>
        </chunking>
        <chunking id="4" string="the strength" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="strength" />
          </tokens>
        </chunking>
        <chunking id="5" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="6" string="measuring the strength of tornadoes" type="VP">
          <tokens>
            <token id="8" string="measuring" />
            <token id="9" string="the" />
            <token id="10" string="strength" />
            <token id="11" string="of" />
            <token id="12" string="tornadoes" />
          </tokens>
        </chunking>
        <chunking id="7" string="the strength of tornadoes" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="strength" />
            <token id="11" string="of" />
            <token id="12" string="tornadoes" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">developed</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">developed</governor>
          <dependent id="2">also</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">developed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">scale</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">scale</governor>
          <dependent id="5">Fujita</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">developed</governor>
          <dependent id="6">scale</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">measuring</governor>
          <dependent id="7">for</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">developed</governor>
          <dependent id="8">measuring</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">strength</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">measuring</governor>
          <dependent id="10">strength</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">tornadoes</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">strength</governor>
          <dependent id="12">tornadoes</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Fujita" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Fujita" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="27" has_coreference="true">
      <content>It runs from zero -- a tornado that might break twigs on trees -- to five -- a twister that can rip houses from their foundations.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="runs" lemma="run" stem="run" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="zero" lemma="zero" stem="zero" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="5" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="tornado" lemma="tornado" stem="tornado" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="8" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="might" lemma="might" stem="might" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="break" lemma="break" stem="break" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="twigs" lemma="twig" stem="twig" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="trees" lemma="tree" stem="tree" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="five" lemma="five" stem="five" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="17" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="twister" lemma="twister" stem="twister" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="rip" lemma="rip" stem="rip" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="houses" lemma="house" stem="hous" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="foundations" lemma="foundation" stem="foundat" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP It)) (VP (VBZ runs) (PP (IN from) (NP (NP (CD zero)) (PRN (: --) (NP (NP (DT a) (NN tornado)) (SBAR (WHNP (WDT that)) (S (VP (MD might) (VP (VB break) (NP (NNS twigs)) (PP (IN on) (NP (NNS trees))) (: --) (PP (TO to) (NP (CD five)))))))) (: --)) (NP (NP (DT a) (NN twister)) (SBAR (WHNP (WDT that)) (S (VP (MD can) (VP (VB rip) (NP (NNS houses)) (PP (IN from) (NP (PRP$ their) (NNS foundations))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a twister" type="NP">
          <tokens>
            <token id="18" string="a" />
            <token id="19" string="twister" />
          </tokens>
        </chunking>
        <chunking id="2" string="their foundations" type="NP">
          <tokens>
            <token id="25" string="their" />
            <token id="26" string="foundations" />
          </tokens>
        </chunking>
        <chunking id="3" string="a twister that can rip houses from their foundations" type="NP">
          <tokens>
            <token id="18" string="a" />
            <token id="19" string="twister" />
            <token id="20" string="that" />
            <token id="21" string="can" />
            <token id="22" string="rip" />
            <token id="23" string="houses" />
            <token id="24" string="from" />
            <token id="25" string="their" />
            <token id="26" string="foundations" />
          </tokens>
        </chunking>
        <chunking id="4" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="5" string="twigs" type="NP">
          <tokens>
            <token id="11" string="twigs" />
          </tokens>
        </chunking>
        <chunking id="6" string="trees" type="NP">
          <tokens>
            <token id="13" string="trees" />
          </tokens>
        </chunking>
        <chunking id="7" string="that might break twigs on trees -- to five" type="SBAR">
          <tokens>
            <token id="8" string="that" />
            <token id="9" string="might" />
            <token id="10" string="break" />
            <token id="11" string="twigs" />
            <token id="12" string="on" />
            <token id="13" string="trees" />
            <token id="14" string="--" />
            <token id="15" string="to" />
            <token id="16" string="five" />
          </tokens>
        </chunking>
        <chunking id="8" string="can rip houses from their foundations" type="VP">
          <tokens>
            <token id="21" string="can" />
            <token id="22" string="rip" />
            <token id="23" string="houses" />
            <token id="24" string="from" />
            <token id="25" string="their" />
            <token id="26" string="foundations" />
          </tokens>
        </chunking>
        <chunking id="9" string="that can rip houses from their foundations" type="SBAR">
          <tokens>
            <token id="20" string="that" />
            <token id="21" string="can" />
            <token id="22" string="rip" />
            <token id="23" string="houses" />
            <token id="24" string="from" />
            <token id="25" string="their" />
            <token id="26" string="foundations" />
          </tokens>
        </chunking>
        <chunking id="10" string="zero -- a tornado that might break twigs on trees -- to five -- a twister that can rip houses from their foundations" type="NP">
          <tokens>
            <token id="4" string="zero" />
            <token id="5" string="--" />
            <token id="6" string="a" />
            <token id="7" string="tornado" />
            <token id="8" string="that" />
            <token id="9" string="might" />
            <token id="10" string="break" />
            <token id="11" string="twigs" />
            <token id="12" string="on" />
            <token id="13" string="trees" />
            <token id="14" string="--" />
            <token id="15" string="to" />
            <token id="16" string="five" />
            <token id="17" string="--" />
            <token id="18" string="a" />
            <token id="19" string="twister" />
            <token id="20" string="that" />
            <token id="21" string="can" />
            <token id="22" string="rip" />
            <token id="23" string="houses" />
            <token id="24" string="from" />
            <token id="25" string="their" />
            <token id="26" string="foundations" />
          </tokens>
        </chunking>
        <chunking id="11" string="houses" type="NP">
          <tokens>
            <token id="23" string="houses" />
          </tokens>
        </chunking>
        <chunking id="12" string="a tornado that might break twigs on trees -- to five" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="tornado" />
            <token id="8" string="that" />
            <token id="9" string="might" />
            <token id="10" string="break" />
            <token id="11" string="twigs" />
            <token id="12" string="on" />
            <token id="13" string="trees" />
            <token id="14" string="--" />
            <token id="15" string="to" />
            <token id="16" string="five" />
          </tokens>
        </chunking>
        <chunking id="13" string="runs from zero -- a tornado that might break twigs on trees -- to five -- a twister that can rip houses from their foundations" type="VP">
          <tokens>
            <token id="2" string="runs" />
            <token id="3" string="from" />
            <token id="4" string="zero" />
            <token id="5" string="--" />
            <token id="6" string="a" />
            <token id="7" string="tornado" />
            <token id="8" string="that" />
            <token id="9" string="might" />
            <token id="10" string="break" />
            <token id="11" string="twigs" />
            <token id="12" string="on" />
            <token id="13" string="trees" />
            <token id="14" string="--" />
            <token id="15" string="to" />
            <token id="16" string="five" />
            <token id="17" string="--" />
            <token id="18" string="a" />
            <token id="19" string="twister" />
            <token id="20" string="that" />
            <token id="21" string="can" />
            <token id="22" string="rip" />
            <token id="23" string="houses" />
            <token id="24" string="from" />
            <token id="25" string="their" />
            <token id="26" string="foundations" />
          </tokens>
        </chunking>
        <chunking id="14" string="might break twigs on trees -- to five" type="VP">
          <tokens>
            <token id="9" string="might" />
            <token id="10" string="break" />
            <token id="11" string="twigs" />
            <token id="12" string="on" />
            <token id="13" string="trees" />
            <token id="14" string="--" />
            <token id="15" string="to" />
            <token id="16" string="five" />
          </tokens>
        </chunking>
        <chunking id="15" string="break twigs on trees -- to five" type="VP">
          <tokens>
            <token id="10" string="break" />
            <token id="11" string="twigs" />
            <token id="12" string="on" />
            <token id="13" string="trees" />
            <token id="14" string="--" />
            <token id="15" string="to" />
            <token id="16" string="five" />
          </tokens>
        </chunking>
        <chunking id="16" string="rip houses from their foundations" type="VP">
          <tokens>
            <token id="22" string="rip" />
            <token id="23" string="houses" />
            <token id="24" string="from" />
            <token id="25" string="their" />
            <token id="26" string="foundations" />
          </tokens>
        </chunking>
        <chunking id="17" string="five" type="NP">
          <tokens>
            <token id="16" string="five" />
          </tokens>
        </chunking>
        <chunking id="18" string="zero" type="NP">
          <tokens>
            <token id="4" string="zero" />
          </tokens>
        </chunking>
        <chunking id="19" string="a tornado" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="tornado" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">runs</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">runs</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">zero</governor>
          <dependent id="3">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">runs</governor>
          <dependent id="4">zero</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">tornado</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="4">zero</governor>
          <dependent id="7">tornado</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">break</governor>
          <dependent id="8">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="10">break</governor>
          <dependent id="9">might</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="7">tornado</governor>
          <dependent id="10">break</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">break</governor>
          <dependent id="11">twigs</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">trees</governor>
          <dependent id="12">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">break</governor>
          <dependent id="13">trees</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">five</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">break</governor>
          <dependent id="16">five</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">twister</governor>
          <dependent id="18">a</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="4">zero</governor>
          <dependent id="19">twister</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">rip</governor>
          <dependent id="20">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="22">rip</governor>
          <dependent id="21">can</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="19">twister</governor>
          <dependent id="22">rip</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">rip</governor>
          <dependent id="23">houses</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">foundations</governor>
          <dependent id="24">from</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="26">foundations</governor>
          <dependent id="25">their</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">rip</governor>
          <dependent id="26">foundations</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="tornado" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="7" string="tornado" />
          </tokens>
        </entity>
        <entity id="2" string="five" type="NUMBER" score="0.0">
          <tokens>
            <token id="16" string="five" />
          </tokens>
        </entity>
        <entity id="3" string="zero" type="NUMBER" score="0.0">
          <tokens>
            <token id="4" string="zero" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="28" has_coreference="true">
      <content>But Fujita considers his work on other air movements called downbursts and microbursts among his most significant achievements.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Fujita" lemma="Fujita" stem="fujita" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="considers" lemma="consider" stem="consid" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="work" lemma="work" stem="work" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="air" lemma="air" stem="air" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="movements" lemma="movement" stem="movement" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="called" lemma="call" stem="call" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="downbursts" lemma="downburst" stem="downburst" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="microbursts" lemma="microburst" stem="microburst" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="among" lemma="among" stem="among" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="most" lemma="most" stem="most" pos="RBS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="significant" lemma="significant" stem="signific" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="achievements" lemma="achievement" stem="achiev" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (NNP Fujita)) (VP (VBZ considers) (NP (PRP$ his) (NN work)) (PP (IN on) (NP (NP (JJ other) (NN air) (NNS movements)) (VP (VBN called) (NP (NNS downbursts) (CC and) (NNS microbursts)) (PP (IN among) (NP (PRP$ his) (RBS most) (JJ significant) (NNS achievements))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="other air movements" type="NP">
          <tokens>
            <token id="7" string="other" />
            <token id="8" string="air" />
            <token id="9" string="movements" />
          </tokens>
        </chunking>
        <chunking id="2" string="his most significant achievements" type="NP">
          <tokens>
            <token id="15" string="his" />
            <token id="16" string="most" />
            <token id="17" string="significant" />
            <token id="18" string="achievements" />
          </tokens>
        </chunking>
        <chunking id="3" string="called downbursts and microbursts among his most significant achievements" type="VP">
          <tokens>
            <token id="10" string="called" />
            <token id="11" string="downbursts" />
            <token id="12" string="and" />
            <token id="13" string="microbursts" />
            <token id="14" string="among" />
            <token id="15" string="his" />
            <token id="16" string="most" />
            <token id="17" string="significant" />
            <token id="18" string="achievements" />
          </tokens>
        </chunking>
        <chunking id="4" string="other air movements called downbursts and microbursts among his most significant achievements" type="NP">
          <tokens>
            <token id="7" string="other" />
            <token id="8" string="air" />
            <token id="9" string="movements" />
            <token id="10" string="called" />
            <token id="11" string="downbursts" />
            <token id="12" string="and" />
            <token id="13" string="microbursts" />
            <token id="14" string="among" />
            <token id="15" string="his" />
            <token id="16" string="most" />
            <token id="17" string="significant" />
            <token id="18" string="achievements" />
          </tokens>
        </chunking>
        <chunking id="5" string="considers his work on other air movements called downbursts and microbursts among his most significant achievements" type="VP">
          <tokens>
            <token id="3" string="considers" />
            <token id="4" string="his" />
            <token id="5" string="work" />
            <token id="6" string="on" />
            <token id="7" string="other" />
            <token id="8" string="air" />
            <token id="9" string="movements" />
            <token id="10" string="called" />
            <token id="11" string="downbursts" />
            <token id="12" string="and" />
            <token id="13" string="microbursts" />
            <token id="14" string="among" />
            <token id="15" string="his" />
            <token id="16" string="most" />
            <token id="17" string="significant" />
            <token id="18" string="achievements" />
          </tokens>
        </chunking>
        <chunking id="6" string="his work" type="NP">
          <tokens>
            <token id="4" string="his" />
            <token id="5" string="work" />
          </tokens>
        </chunking>
        <chunking id="7" string="Fujita" type="NP">
          <tokens>
            <token id="2" string="Fujita" />
          </tokens>
        </chunking>
        <chunking id="8" string="downbursts and microbursts" type="NP">
          <tokens>
            <token id="11" string="downbursts" />
            <token id="12" string="and" />
            <token id="13" string="microbursts" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="3">considers</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">considers</governor>
          <dependent id="2">Fujita</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">considers</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">work</governor>
          <dependent id="4">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">considers</governor>
          <dependent id="5">work</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">movements</governor>
          <dependent id="6">on</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">movements</governor>
          <dependent id="7">other</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">movements</governor>
          <dependent id="8">air</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">considers</governor>
          <dependent id="9">movements</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="9">movements</governor>
          <dependent id="10">called</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">called</governor>
          <dependent id="11">downbursts</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="11">downbursts</governor>
          <dependent id="12">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">downbursts</governor>
          <dependent id="13">microbursts</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">achievements</governor>
          <dependent id="14">among</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="18">achievements</governor>
          <dependent id="15">his</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">achievements</governor>
          <dependent id="16">most</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">achievements</governor>
          <dependent id="17">significant</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">called</governor>
          <dependent id="18">achievements</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Fujita" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Fujita" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="29" has_coreference="true">
      <content>Downbursts are powerful drafts of air moving down from a thunderstorm cloud.</content>
      <tokens>
        <token id="1" string="Downbursts" lemma="downburst" stem="downburst" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="powerful" lemma="powerful" stem="power" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="drafts" lemma="draft" stem="draft" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="air" lemma="air" stem="air" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="moving" lemma="move" stem="move" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="down" lemma="down" stem="down" pos="RP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="thunderstorm" lemma="thunderstorm" stem="thunderstorm" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="cloud" lemma="cloud" stem="cloud" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNS Downbursts)) (VP (VBP are) (NP (NP (JJ powerful) (NNS drafts)) (PP (IN of) (NP (NP (NN air)) (VP (VBG moving) (PRT (RP down)) (PP (IN from) (NP (DT a) (NN thunderstorm) (NN cloud)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="moving down from a thunderstorm cloud" type="VP">
          <tokens>
            <token id="7" string="moving" />
            <token id="8" string="down" />
            <token id="9" string="from" />
            <token id="10" string="a" />
            <token id="11" string="thunderstorm" />
            <token id="12" string="cloud" />
          </tokens>
        </chunking>
        <chunking id="2" string="a thunderstorm cloud" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="thunderstorm" />
            <token id="12" string="cloud" />
          </tokens>
        </chunking>
        <chunking id="3" string="powerful drafts of air moving down from a thunderstorm cloud" type="NP">
          <tokens>
            <token id="3" string="powerful" />
            <token id="4" string="drafts" />
            <token id="5" string="of" />
            <token id="6" string="air" />
            <token id="7" string="moving" />
            <token id="8" string="down" />
            <token id="9" string="from" />
            <token id="10" string="a" />
            <token id="11" string="thunderstorm" />
            <token id="12" string="cloud" />
          </tokens>
        </chunking>
        <chunking id="4" string="air moving down from a thunderstorm cloud" type="NP">
          <tokens>
            <token id="6" string="air" />
            <token id="7" string="moving" />
            <token id="8" string="down" />
            <token id="9" string="from" />
            <token id="10" string="a" />
            <token id="11" string="thunderstorm" />
            <token id="12" string="cloud" />
          </tokens>
        </chunking>
        <chunking id="5" string="air" type="NP">
          <tokens>
            <token id="6" string="air" />
          </tokens>
        </chunking>
        <chunking id="6" string="are powerful drafts of air moving down from a thunderstorm cloud" type="VP">
          <tokens>
            <token id="2" string="are" />
            <token id="3" string="powerful" />
            <token id="4" string="drafts" />
            <token id="5" string="of" />
            <token id="6" string="air" />
            <token id="7" string="moving" />
            <token id="8" string="down" />
            <token id="9" string="from" />
            <token id="10" string="a" />
            <token id="11" string="thunderstorm" />
            <token id="12" string="cloud" />
          </tokens>
        </chunking>
        <chunking id="7" string="Downbursts" type="NP">
          <tokens>
            <token id="1" string="Downbursts" />
          </tokens>
        </chunking>
        <chunking id="8" string="powerful drafts" type="NP">
          <tokens>
            <token id="3" string="powerful" />
            <token id="4" string="drafts" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">drafts</governor>
          <dependent id="1">Downbursts</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">drafts</governor>
          <dependent id="2">are</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">drafts</governor>
          <dependent id="3">powerful</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">drafts</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">air</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">drafts</governor>
          <dependent id="6">air</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="6">air</governor>
          <dependent id="7">moving</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="7">moving</governor>
          <dependent id="8">down</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">cloud</governor>
          <dependent id="9">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">cloud</governor>
          <dependent id="10">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">cloud</governor>
          <dependent id="11">thunderstorm</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">moving</governor>
          <dependent id="12">cloud</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="30" has_coreference="false">
      <content>Scientists long thought the drafts dissipated before reaching the ground.</content>
      <tokens>
        <token id="1" string="Scientists" lemma="scientist" stem="scientist" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="long" lemma="long" stem="long" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="thought" lemma="think" stem="thought" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="drafts" lemma="draft" stem="draft" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="dissipated" lemma="dissipate" stem="dissip" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="before" lemma="before" stem="befor" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="reaching" lemma="reach" stem="reach" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="ground" lemma="ground" stem="ground" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNS Scientists)) (ADVP (RB long)) (VP (VBD thought) (NP (NP (DT the) (NNS drafts)) (VP (VBN dissipated) (PP (IN before) (S (VP (VBG reaching) (NP (DT the) (NN ground)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="thought the drafts dissipated before reaching the ground" type="VP">
          <tokens>
            <token id="3" string="thought" />
            <token id="4" string="the" />
            <token id="5" string="drafts" />
            <token id="6" string="dissipated" />
            <token id="7" string="before" />
            <token id="8" string="reaching" />
            <token id="9" string="the" />
            <token id="10" string="ground" />
          </tokens>
        </chunking>
        <chunking id="2" string="dissipated before reaching the ground" type="VP">
          <tokens>
            <token id="6" string="dissipated" />
            <token id="7" string="before" />
            <token id="8" string="reaching" />
            <token id="9" string="the" />
            <token id="10" string="ground" />
          </tokens>
        </chunking>
        <chunking id="3" string="the ground" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="ground" />
          </tokens>
        </chunking>
        <chunking id="4" string="Scientists" type="NP">
          <tokens>
            <token id="1" string="Scientists" />
          </tokens>
        </chunking>
        <chunking id="5" string="the drafts dissipated before reaching the ground" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="drafts" />
            <token id="6" string="dissipated" />
            <token id="7" string="before" />
            <token id="8" string="reaching" />
            <token id="9" string="the" />
            <token id="10" string="ground" />
          </tokens>
        </chunking>
        <chunking id="6" string="the drafts" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="drafts" />
          </tokens>
        </chunking>
        <chunking id="7" string="reaching the ground" type="VP">
          <tokens>
            <token id="8" string="reaching" />
            <token id="9" string="the" />
            <token id="10" string="ground" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">thought</governor>
          <dependent id="1">Scientists</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">thought</governor>
          <dependent id="2">long</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">thought</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">drafts</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">thought</governor>
          <dependent id="5">drafts</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="5">drafts</governor>
          <dependent id="6">dissipated</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">reaching</governor>
          <dependent id="7">before</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="6">dissipated</governor>
          <dependent id="8">reaching</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">ground</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">reaching</governor>
          <dependent id="10">ground</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="31" has_coreference="true">
      <content>Microbursts are smaller versions of downbursts, but are more dangerous because they give pilots less time to react, Fujita said.</content>
      <tokens>
        <token id="1" string="Microbursts" lemma="microburst" stem="microburst" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="smaller" lemma="smaller" stem="smaller" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="versions" lemma="version" stem="version" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="downbursts" lemma="downburst" stem="downburst" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="dangerous" lemma="dangerous" stem="danger" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="give" lemma="give" stem="give" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="pilots" lemma="pilot" stem="pilot" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="less" lemma="less" stem="less" pos="JJR" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="react" lemma="react" stem="react" pos="VB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="Fujita" lemma="Fujita" stem="fujita" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="22" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NNS Microbursts)) (VP (VP (VBP are) (NP (NP (JJR smaller) (NNS versions)) (PP (IN of) (NP (NNS downbursts))))) (, ,) (CC but) (VP (VBP are) (ADJP (ADJP (RBR more) (JJ dangerous)) (SBAR (IN because) (S (NP (PRP they)) (VP (VBP give) (NP (NNS pilots)) (NP (JJR less) (NN time) (S (VP (TO to) (VP (VB react)))))))))))) (, ,) (NP (NNP Fujita)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="downbursts" type="NP">
          <tokens>
            <token id="6" string="downbursts" />
          </tokens>
        </chunking>
        <chunking id="2" string="because they give pilots less time to react" type="SBAR">
          <tokens>
            <token id="12" string="because" />
            <token id="13" string="they" />
            <token id="14" string="give" />
            <token id="15" string="pilots" />
            <token id="16" string="less" />
            <token id="17" string="time" />
            <token id="18" string="to" />
            <token id="19" string="react" />
          </tokens>
        </chunking>
        <chunking id="3" string="pilots" type="NP">
          <tokens>
            <token id="15" string="pilots" />
          </tokens>
        </chunking>
        <chunking id="4" string="smaller versions" type="NP">
          <tokens>
            <token id="3" string="smaller" />
            <token id="4" string="versions" />
          </tokens>
        </chunking>
        <chunking id="5" string="more dangerous because they give pilots less time to react" type="ADJP">
          <tokens>
            <token id="10" string="more" />
            <token id="11" string="dangerous" />
            <token id="12" string="because" />
            <token id="13" string="they" />
            <token id="14" string="give" />
            <token id="15" string="pilots" />
            <token id="16" string="less" />
            <token id="17" string="time" />
            <token id="18" string="to" />
            <token id="19" string="react" />
          </tokens>
        </chunking>
        <chunking id="6" string="smaller versions of downbursts" type="NP">
          <tokens>
            <token id="3" string="smaller" />
            <token id="4" string="versions" />
            <token id="5" string="of" />
            <token id="6" string="downbursts" />
          </tokens>
        </chunking>
        <chunking id="7" string="react" type="VP">
          <tokens>
            <token id="19" string="react" />
          </tokens>
        </chunking>
        <chunking id="8" string="Microbursts" type="NP">
          <tokens>
            <token id="1" string="Microbursts" />
          </tokens>
        </chunking>
        <chunking id="9" string="Fujita" type="NP">
          <tokens>
            <token id="21" string="Fujita" />
          </tokens>
        </chunking>
        <chunking id="10" string="are more dangerous because they give pilots less time to react" type="VP">
          <tokens>
            <token id="9" string="are" />
            <token id="10" string="more" />
            <token id="11" string="dangerous" />
            <token id="12" string="because" />
            <token id="13" string="they" />
            <token id="14" string="give" />
            <token id="15" string="pilots" />
            <token id="16" string="less" />
            <token id="17" string="time" />
            <token id="18" string="to" />
            <token id="19" string="react" />
          </tokens>
        </chunking>
        <chunking id="11" string="they" type="NP">
          <tokens>
            <token id="13" string="they" />
          </tokens>
        </chunking>
        <chunking id="12" string="give pilots less time to react" type="VP">
          <tokens>
            <token id="14" string="give" />
            <token id="15" string="pilots" />
            <token id="16" string="less" />
            <token id="17" string="time" />
            <token id="18" string="to" />
            <token id="19" string="react" />
          </tokens>
        </chunking>
        <chunking id="13" string="less time to react" type="NP">
          <tokens>
            <token id="16" string="less" />
            <token id="17" string="time" />
            <token id="18" string="to" />
            <token id="19" string="react" />
          </tokens>
        </chunking>
        <chunking id="14" string="to react" type="VP">
          <tokens>
            <token id="18" string="to" />
            <token id="19" string="react" />
          </tokens>
        </chunking>
        <chunking id="15" string="are smaller versions of downbursts , but are more dangerous because they give pilots less time to react" type="VP">
          <tokens>
            <token id="2" string="are" />
            <token id="3" string="smaller" />
            <token id="4" string="versions" />
            <token id="5" string="of" />
            <token id="6" string="downbursts" />
            <token id="7" string="," />
            <token id="8" string="but" />
            <token id="9" string="are" />
            <token id="10" string="more" />
            <token id="11" string="dangerous" />
            <token id="12" string="because" />
            <token id="13" string="they" />
            <token id="14" string="give" />
            <token id="15" string="pilots" />
            <token id="16" string="less" />
            <token id="17" string="time" />
            <token id="18" string="to" />
            <token id="19" string="react" />
          </tokens>
        </chunking>
        <chunking id="16" string="more dangerous" type="ADJP">
          <tokens>
            <token id="10" string="more" />
            <token id="11" string="dangerous" />
          </tokens>
        </chunking>
        <chunking id="17" string="are smaller versions of downbursts" type="VP">
          <tokens>
            <token id="2" string="are" />
            <token id="3" string="smaller" />
            <token id="4" string="versions" />
            <token id="5" string="of" />
            <token id="6" string="downbursts" />
          </tokens>
        </chunking>
        <chunking id="18" string="said" type="VP">
          <tokens>
            <token id="22" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">versions</governor>
          <dependent id="1">Microbursts</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">versions</governor>
          <dependent id="2">are</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">versions</governor>
          <dependent id="3">smaller</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="22">said</governor>
          <dependent id="4">versions</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">downbursts</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">versions</governor>
          <dependent id="6">downbursts</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">versions</governor>
          <dependent id="8">but</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="11">dangerous</governor>
          <dependent id="9">are</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">dangerous</governor>
          <dependent id="10">more</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">versions</governor>
          <dependent id="11">dangerous</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">give</governor>
          <dependent id="12">because</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">give</governor>
          <dependent id="13">they</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">dangerous</governor>
          <dependent id="14">give</dependent>
        </dependency>
        <dependency type="iobj">
          <governor id="14">give</governor>
          <dependent id="15">pilots</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">time</governor>
          <dependent id="16">less</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">give</governor>
          <dependent id="17">time</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">react</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="17">time</governor>
          <dependent id="19">react</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">said</governor>
          <dependent id="21">Fujita</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="22">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Fujita" type="PERSON" score="0.0">
          <tokens>
            <token id="21" string="Fujita" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="32" has_coreference="true">
      <content>The National Transportation Safety Board has cited microbursts, a term coined by Fujita, as the cause of 17 aircraft accidents in the last 15 years, causing 577 fatalities.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="National" lemma="National" stem="nation" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="3" string="Transportation" lemma="Transportation" stem="transport" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="4" string="Safety" lemma="Safety" stem="safeti" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="5" string="Board" lemma="Board" stem="board" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="6" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="cited" lemma="cite" stem="cite" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="microbursts" lemma="microburst" stem="microburst" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="term" lemma="term" stem="term" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="coined" lemma="coin" stem="coin" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Fujita" lemma="Fujita" stem="fujita" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="cause" lemma="cause" stem="caus" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="17" lemma="17" stem="17" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="21" string="aircraft" lemma="aircraft" stem="aircraft" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="accidents" lemma="accident" stem="accid" pos="NNS" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="23" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="25" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="26" string="15" lemma="15" stem="15" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="27" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="28" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="causing" lemma="cause" stem="caus" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="577" lemma="577" stem="577" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="31" string="fatalities" lemma="fatality" stem="fatal" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NNP National) (NNP Transportation) (NNP Safety) (NNP Board)) (VP (VBZ has) (VP (VBN cited) (NP (NP (NNS microbursts)) (, ,) (NP (NP (DT a) (NN term)) (VP (VBN coined) (PP (IN by) (NP (NNP Fujita))) (, ,) (PP (IN as) (NP (NP (DT the) (NN cause)) (PP (IN of) (NP (NP (CD 17) (NN aircraft) (NNS accidents)) (PP (IN in) (NP (DT the) (JJ last) (CD 15) (NNS years))))))) (, ,) (S (VP (VBG causing) (NP (CD 577) (NNS fatalities))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the cause of 17 aircraft accidents in the last 15 years" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="cause" />
            <token id="19" string="of" />
            <token id="20" string="17" />
            <token id="21" string="aircraft" />
            <token id="22" string="accidents" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="last" />
            <token id="26" string="15" />
            <token id="27" string="years" />
          </tokens>
        </chunking>
        <chunking id="2" string="The National Transportation Safety Board" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="National" />
            <token id="3" string="Transportation" />
            <token id="4" string="Safety" />
            <token id="5" string="Board" />
          </tokens>
        </chunking>
        <chunking id="3" string="causing 577 fatalities" type="VP">
          <tokens>
            <token id="29" string="causing" />
            <token id="30" string="577" />
            <token id="31" string="fatalities" />
          </tokens>
        </chunking>
        <chunking id="4" string="577 fatalities" type="NP">
          <tokens>
            <token id="30" string="577" />
            <token id="31" string="fatalities" />
          </tokens>
        </chunking>
        <chunking id="5" string="cited microbursts , a term coined by Fujita , as the cause of 17 aircraft accidents in the last 15 years , causing 577 fatalities" type="VP">
          <tokens>
            <token id="7" string="cited" />
            <token id="8" string="microbursts" />
            <token id="9" string="," />
            <token id="10" string="a" />
            <token id="11" string="term" />
            <token id="12" string="coined" />
            <token id="13" string="by" />
            <token id="14" string="Fujita" />
            <token id="15" string="," />
            <token id="16" string="as" />
            <token id="17" string="the" />
            <token id="18" string="cause" />
            <token id="19" string="of" />
            <token id="20" string="17" />
            <token id="21" string="aircraft" />
            <token id="22" string="accidents" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="last" />
            <token id="26" string="15" />
            <token id="27" string="years" />
            <token id="28" string="," />
            <token id="29" string="causing" />
            <token id="30" string="577" />
            <token id="31" string="fatalities" />
          </tokens>
        </chunking>
        <chunking id="6" string="microbursts" type="NP">
          <tokens>
            <token id="8" string="microbursts" />
          </tokens>
        </chunking>
        <chunking id="7" string="coined by Fujita , as the cause of 17 aircraft accidents in the last 15 years , causing 577 fatalities" type="VP">
          <tokens>
            <token id="12" string="coined" />
            <token id="13" string="by" />
            <token id="14" string="Fujita" />
            <token id="15" string="," />
            <token id="16" string="as" />
            <token id="17" string="the" />
            <token id="18" string="cause" />
            <token id="19" string="of" />
            <token id="20" string="17" />
            <token id="21" string="aircraft" />
            <token id="22" string="accidents" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="last" />
            <token id="26" string="15" />
            <token id="27" string="years" />
            <token id="28" string="," />
            <token id="29" string="causing" />
            <token id="30" string="577" />
            <token id="31" string="fatalities" />
          </tokens>
        </chunking>
        <chunking id="8" string="Fujita" type="NP">
          <tokens>
            <token id="14" string="Fujita" />
          </tokens>
        </chunking>
        <chunking id="9" string="17 aircraft accidents" type="NP">
          <tokens>
            <token id="20" string="17" />
            <token id="21" string="aircraft" />
            <token id="22" string="accidents" />
          </tokens>
        </chunking>
        <chunking id="10" string="the last 15 years" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="last" />
            <token id="26" string="15" />
            <token id="27" string="years" />
          </tokens>
        </chunking>
        <chunking id="11" string="17 aircraft accidents in the last 15 years" type="NP">
          <tokens>
            <token id="20" string="17" />
            <token id="21" string="aircraft" />
            <token id="22" string="accidents" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="last" />
            <token id="26" string="15" />
            <token id="27" string="years" />
          </tokens>
        </chunking>
        <chunking id="12" string="microbursts , a term coined by Fujita , as the cause of 17 aircraft accidents in the last 15 years , causing 577 fatalities" type="NP">
          <tokens>
            <token id="8" string="microbursts" />
            <token id="9" string="," />
            <token id="10" string="a" />
            <token id="11" string="term" />
            <token id="12" string="coined" />
            <token id="13" string="by" />
            <token id="14" string="Fujita" />
            <token id="15" string="," />
            <token id="16" string="as" />
            <token id="17" string="the" />
            <token id="18" string="cause" />
            <token id="19" string="of" />
            <token id="20" string="17" />
            <token id="21" string="aircraft" />
            <token id="22" string="accidents" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="last" />
            <token id="26" string="15" />
            <token id="27" string="years" />
            <token id="28" string="," />
            <token id="29" string="causing" />
            <token id="30" string="577" />
            <token id="31" string="fatalities" />
          </tokens>
        </chunking>
        <chunking id="13" string="the cause" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="cause" />
          </tokens>
        </chunking>
        <chunking id="14" string="a term" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="term" />
          </tokens>
        </chunking>
        <chunking id="15" string="a term coined by Fujita , as the cause of 17 aircraft accidents in the last 15 years , causing 577 fatalities" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="term" />
            <token id="12" string="coined" />
            <token id="13" string="by" />
            <token id="14" string="Fujita" />
            <token id="15" string="," />
            <token id="16" string="as" />
            <token id="17" string="the" />
            <token id="18" string="cause" />
            <token id="19" string="of" />
            <token id="20" string="17" />
            <token id="21" string="aircraft" />
            <token id="22" string="accidents" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="last" />
            <token id="26" string="15" />
            <token id="27" string="years" />
            <token id="28" string="," />
            <token id="29" string="causing" />
            <token id="30" string="577" />
            <token id="31" string="fatalities" />
          </tokens>
        </chunking>
        <chunking id="16" string="has cited microbursts , a term coined by Fujita , as the cause of 17 aircraft accidents in the last 15 years , causing 577 fatalities" type="VP">
          <tokens>
            <token id="6" string="has" />
            <token id="7" string="cited" />
            <token id="8" string="microbursts" />
            <token id="9" string="," />
            <token id="10" string="a" />
            <token id="11" string="term" />
            <token id="12" string="coined" />
            <token id="13" string="by" />
            <token id="14" string="Fujita" />
            <token id="15" string="," />
            <token id="16" string="as" />
            <token id="17" string="the" />
            <token id="18" string="cause" />
            <token id="19" string="of" />
            <token id="20" string="17" />
            <token id="21" string="aircraft" />
            <token id="22" string="accidents" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="last" />
            <token id="26" string="15" />
            <token id="27" string="years" />
            <token id="28" string="," />
            <token id="29" string="causing" />
            <token id="30" string="577" />
            <token id="31" string="fatalities" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="5">Board</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Board</governor>
          <dependent id="2">National</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Board</governor>
          <dependent id="3">Transportation</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Board</governor>
          <dependent id="4">Safety</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">cited</governor>
          <dependent id="5">Board</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">cited</governor>
          <dependent id="6">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">cited</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">cited</governor>
          <dependent id="8">microbursts</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">term</governor>
          <dependent id="10">a</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="8">microbursts</governor>
          <dependent id="11">term</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="11">term</governor>
          <dependent id="12">coined</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">Fujita</governor>
          <dependent id="13">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">coined</governor>
          <dependent id="14">Fujita</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">cause</governor>
          <dependent id="16">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">cause</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">coined</governor>
          <dependent id="18">cause</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">accidents</governor>
          <dependent id="19">of</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="22">accidents</governor>
          <dependent id="20">17</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">accidents</governor>
          <dependent id="21">aircraft</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">cause</governor>
          <dependent id="22">accidents</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">years</governor>
          <dependent id="23">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">years</governor>
          <dependent id="24">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="27">years</governor>
          <dependent id="25">last</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="27">years</governor>
          <dependent id="26">15</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">accidents</governor>
          <dependent id="27">years</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="12">coined</governor>
          <dependent id="29">causing</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="31">fatalities</governor>
          <dependent id="30">577</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="29">causing</governor>
          <dependent id="31">fatalities</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="the" type="DURATION" score="0.0">
          <tokens>
            <token id="24" string="the" />
          </tokens>
        </entity>
        <entity id="2" string="577" type="NUMBER" score="0.0">
          <tokens>
            <token id="30" string="577" />
          </tokens>
        </entity>
        <entity id="3" string="17" type="NUMBER" score="0.0">
          <tokens>
            <token id="20" string="17" />
          </tokens>
        </entity>
        <entity id="4" string="National Transportation Safety Board" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="2" string="National" />
            <token id="3" string="Transportation" />
            <token id="4" string="Safety" />
            <token id="5" string="Board" />
          </tokens>
        </entity>
        <entity id="5" string="accidents" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="22" string="accidents" />
          </tokens>
        </entity>
        <entity id="6" string="last 15 years" type="DATE" score="0.0">
          <tokens>
            <token id="25" string="last" />
            <token id="26" string="15" />
            <token id="27" string="years" />
          </tokens>
        </entity>
        <entity id="7" string="Fujita" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Fujita" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="33" has_coreference="true">
      <content>Among them was the 1985 crash of a Delta L-1011 in Dallas that killed 137 people.</content>
      <tokens>
        <token id="1" string="Among" lemma="among" stem="among" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="1985" lemma="1985" stem="1985" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="6" string="crash" lemma="crash" stem="crash" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Delta" lemma="delta" stem="delta" pos="NN" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="10" string="L-1011" lemma="l-1011" stem="l-1011" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Dallas" lemma="Dallas" stem="dalla" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="13" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="killed" lemma="kill" stem="kill" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="137" lemma="137" stem="137" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="16" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (PP (IN Among) (NP (PRP them))) (VP (VBD was)) (NP (NP (DT the) (CD 1985) (NN crash)) (PP (IN of) (NP (DT a) (NN Delta) (NN L-1011))) (PP (IN in) (NP (NNP Dallas))) (SBAR (WHNP (WDT that)) (S (VP (VBD killed) (NP (CD 137) (NNS people)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="killed 137 people" type="VP">
          <tokens>
            <token id="14" string="killed" />
            <token id="15" string="137" />
            <token id="16" string="people" />
          </tokens>
        </chunking>
        <chunking id="2" string="137 people" type="NP">
          <tokens>
            <token id="15" string="137" />
            <token id="16" string="people" />
          </tokens>
        </chunking>
        <chunking id="3" string="was" type="VP">
          <tokens>
            <token id="3" string="was" />
          </tokens>
        </chunking>
        <chunking id="4" string="the 1985 crash" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="1985" />
            <token id="6" string="crash" />
          </tokens>
        </chunking>
        <chunking id="5" string="a Delta L-1011" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="Delta" />
            <token id="10" string="L-1011" />
          </tokens>
        </chunking>
        <chunking id="6" string="them" type="NP">
          <tokens>
            <token id="2" string="them" />
          </tokens>
        </chunking>
        <chunking id="7" string="Dallas" type="NP">
          <tokens>
            <token id="12" string="Dallas" />
          </tokens>
        </chunking>
        <chunking id="8" string="the 1985 crash of a Delta L-1011 in Dallas that killed 137 people" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="1985" />
            <token id="6" string="crash" />
            <token id="7" string="of" />
            <token id="8" string="a" />
            <token id="9" string="Delta" />
            <token id="10" string="L-1011" />
            <token id="11" string="in" />
            <token id="12" string="Dallas" />
            <token id="13" string="that" />
            <token id="14" string="killed" />
            <token id="15" string="137" />
            <token id="16" string="people" />
          </tokens>
        </chunking>
        <chunking id="9" string="that killed 137 people" type="SBAR">
          <tokens>
            <token id="13" string="that" />
            <token id="14" string="killed" />
            <token id="15" string="137" />
            <token id="16" string="people" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">them</governor>
          <dependent id="1">Among</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">was</governor>
          <dependent id="2">them</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">crash</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="6">crash</governor>
          <dependent id="5">1985</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">was</governor>
          <dependent id="6">crash</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">L-1011</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">L-1011</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">L-1011</governor>
          <dependent id="9">Delta</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">crash</governor>
          <dependent id="10">L-1011</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">Dallas</governor>
          <dependent id="11">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">crash</governor>
          <dependent id="12">Dallas</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">killed</governor>
          <dependent id="13">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="6">crash</governor>
          <dependent id="14">killed</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="16">people</governor>
          <dependent id="15">137</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">killed</governor>
          <dependent id="16">people</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1985" type="DATE" score="0.0">
          <tokens>
            <token id="5" string="1985" />
          </tokens>
        </entity>
        <entity id="2" string="137" type="NUMBER" score="0.0">
          <tokens>
            <token id="15" string="137" />
          </tokens>
        </entity>
        <entity id="3" string="Delta" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="9" string="Delta" />
          </tokens>
        </entity>
        <entity id="4" string="Dallas" type="LOCATION" score="0.0">
          <tokens>
            <token id="12" string="Dallas" />
          </tokens>
        </entity>
        <entity id="5" string="crash" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="6" string="crash" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="34" has_coreference="false">
      <content>A downburst also was implicated in the collapse of a wall at a school in Newburgh, N.Y., that killed nine children.</content>
      <tokens>
        <token id="1" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="downburst" lemma="downburst" stem="downburst" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="implicated" lemma="implicate" stem="implic" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="collapse" lemma="collapse" stem="collaps" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="wall" lemma="wall" stem="wall" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="school" lemma="school" stem="school" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="Newburgh" lemma="Newburgh" stem="newburgh" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="N.Y." lemma="N.Y." stem="n.y." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="killed" lemma="kill" stem="kill" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="nine" lemma="nine" stem="nine" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="23" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT A) (NN downburst)) (ADVP (RB also)) (VP (VBD was) (VP (VBN implicated) (PP (IN in) (NP (NP (DT the) (NN collapse)) (PP (IN of) (NP (DT a) (NN wall))))) (PP (IN at) (NP (NP (DT a) (NN school)) (PP (IN in) (NP (NP (NNP Newburgh) (, ,) (NNP N.Y.)) (, ,) (SBAR (WHNP (WDT that)) (S (VP (VBD killed) (NP (CD nine) (NNS children))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the collapse of a wall" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="collapse" />
            <token id="9" string="of" />
            <token id="10" string="a" />
            <token id="11" string="wall" />
          </tokens>
        </chunking>
        <chunking id="2" string="a school in Newburgh , N.Y. , that killed nine children" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="school" />
            <token id="15" string="in" />
            <token id="16" string="Newburgh" />
            <token id="17" string="," />
            <token id="18" string="N.Y." />
            <token id="19" string="," />
            <token id="20" string="that" />
            <token id="21" string="killed" />
            <token id="22" string="nine" />
            <token id="23" string="children" />
          </tokens>
        </chunking>
        <chunking id="3" string="implicated in the collapse of a wall at a school in Newburgh , N.Y. , that killed nine children" type="VP">
          <tokens>
            <token id="5" string="implicated" />
            <token id="6" string="in" />
            <token id="7" string="the" />
            <token id="8" string="collapse" />
            <token id="9" string="of" />
            <token id="10" string="a" />
            <token id="11" string="wall" />
            <token id="12" string="at" />
            <token id="13" string="a" />
            <token id="14" string="school" />
            <token id="15" string="in" />
            <token id="16" string="Newburgh" />
            <token id="17" string="," />
            <token id="18" string="N.Y." />
            <token id="19" string="," />
            <token id="20" string="that" />
            <token id="21" string="killed" />
            <token id="22" string="nine" />
            <token id="23" string="children" />
          </tokens>
        </chunking>
        <chunking id="4" string="a wall" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="wall" />
          </tokens>
        </chunking>
        <chunking id="5" string="a school" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="school" />
          </tokens>
        </chunking>
        <chunking id="6" string="Newburgh , N.Y. , that killed nine children" type="NP">
          <tokens>
            <token id="16" string="Newburgh" />
            <token id="17" string="," />
            <token id="18" string="N.Y." />
            <token id="19" string="," />
            <token id="20" string="that" />
            <token id="21" string="killed" />
            <token id="22" string="nine" />
            <token id="23" string="children" />
          </tokens>
        </chunking>
        <chunking id="7" string="Newburgh , N.Y." type="NP">
          <tokens>
            <token id="16" string="Newburgh" />
            <token id="17" string="," />
            <token id="18" string="N.Y." />
          </tokens>
        </chunking>
        <chunking id="8" string="nine children" type="NP">
          <tokens>
            <token id="22" string="nine" />
            <token id="23" string="children" />
          </tokens>
        </chunking>
        <chunking id="9" string="A downburst" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="downburst" />
          </tokens>
        </chunking>
        <chunking id="10" string="was implicated in the collapse of a wall at a school in Newburgh , N.Y. , that killed nine children" type="VP">
          <tokens>
            <token id="4" string="was" />
            <token id="5" string="implicated" />
            <token id="6" string="in" />
            <token id="7" string="the" />
            <token id="8" string="collapse" />
            <token id="9" string="of" />
            <token id="10" string="a" />
            <token id="11" string="wall" />
            <token id="12" string="at" />
            <token id="13" string="a" />
            <token id="14" string="school" />
            <token id="15" string="in" />
            <token id="16" string="Newburgh" />
            <token id="17" string="," />
            <token id="18" string="N.Y." />
            <token id="19" string="," />
            <token id="20" string="that" />
            <token id="21" string="killed" />
            <token id="22" string="nine" />
            <token id="23" string="children" />
          </tokens>
        </chunking>
        <chunking id="11" string="the collapse" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="collapse" />
          </tokens>
        </chunking>
        <chunking id="12" string="that killed nine children" type="SBAR">
          <tokens>
            <token id="20" string="that" />
            <token id="21" string="killed" />
            <token id="22" string="nine" />
            <token id="23" string="children" />
          </tokens>
        </chunking>
        <chunking id="13" string="killed nine children" type="VP">
          <tokens>
            <token id="21" string="killed" />
            <token id="22" string="nine" />
            <token id="23" string="children" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">downburst</governor>
          <dependent id="1">A</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="5">implicated</governor>
          <dependent id="2">downburst</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">implicated</governor>
          <dependent id="3">also</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="5">implicated</governor>
          <dependent id="4">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">implicated</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">collapse</governor>
          <dependent id="6">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">collapse</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">implicated</governor>
          <dependent id="8">collapse</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">wall</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">wall</governor>
          <dependent id="10">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">collapse</governor>
          <dependent id="11">wall</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">school</governor>
          <dependent id="12">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">school</governor>
          <dependent id="13">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">implicated</governor>
          <dependent id="14">school</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">N.Y.</governor>
          <dependent id="15">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">N.Y.</governor>
          <dependent id="16">Newburgh</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">school</governor>
          <dependent id="18">N.Y.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">killed</governor>
          <dependent id="20">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="18">N.Y.</governor>
          <dependent id="21">killed</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="23">children</governor>
          <dependent id="22">nine</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">killed</governor>
          <dependent id="23">children</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="N.Y." type="LOCATION" score="0.0">
          <tokens>
            <token id="18" string="N.Y." />
          </tokens>
        </entity>
        <entity id="2" string="Newburgh" type="LOCATION" score="0.0">
          <tokens>
            <token id="16" string="Newburgh" />
          </tokens>
        </entity>
        <entity id="3" string="nine" type="NUMBER" score="0.0">
          <tokens>
            <token id="22" string="nine" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="35" has_coreference="true">
      <content>Fujita&amp;apost;s work helped persuade the Federal Aviation Administation to begin installing a new radar system at 47 major airports beginning in the early 1990s.</content>
      <tokens>
        <token id="1" string="Fujita" lemma="Fujita" stem="fujita" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="work" lemma="work" stem="work" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="helped" lemma="help" stem="help" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="persuade" lemma="persuade" stem="persuad" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Federal" lemma="Federal" stem="feder" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="8" string="Aviation" lemma="Aviation" stem="aviation" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="9" string="Administation" lemma="Administation" stem="administ" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="begin" lemma="begin" stem="begin" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="installing" lemma="install" stem="instal" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="new" lemma="new" stem="new" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="radar" lemma="radar" stem="radar" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="system" lemma="system" stem="system" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="47" lemma="47" stem="47" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="19" string="major" lemma="major" stem="major" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="airports" lemma="airport" stem="airport" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="beginning" lemma="begin" stem="begin" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="24" string="early" lemma="early" stem="earli" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="25" string="1990s" lemma="1990s" stem="1990" pos="CD" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Fujita) (POS 's)) (NN work)) (VP (VBD helped) (VP (VB persuade) (S (NP (DT the) (NNP Federal) (NNP Aviation) (NNP Administation)) (VP (TO to) (VP (VB begin) (S (VP (VBG installing) (NP (DT a) (JJ new) (NN radar) (NN system)) (PP (IN at) (NP (NP (CD 47) (JJ major) (NNS airports)) (VP (VBG beginning) (PP (IN in) (NP (DT the) (JJ early) (CD 1990s))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Fujita 's" type="NP">
          <tokens>
            <token id="1" string="Fujita" />
            <token id="2" string="'s" />
          </tokens>
        </chunking>
        <chunking id="2" string="a new radar system" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="new" />
            <token id="15" string="radar" />
            <token id="16" string="system" />
          </tokens>
        </chunking>
        <chunking id="3" string="to begin installing a new radar system at 47 major airports beginning in the early 1990s" type="VP">
          <tokens>
            <token id="10" string="to" />
            <token id="11" string="begin" />
            <token id="12" string="installing" />
            <token id="13" string="a" />
            <token id="14" string="new" />
            <token id="15" string="radar" />
            <token id="16" string="system" />
            <token id="17" string="at" />
            <token id="18" string="47" />
            <token id="19" string="major" />
            <token id="20" string="airports" />
            <token id="21" string="beginning" />
            <token id="22" string="in" />
            <token id="23" string="the" />
            <token id="24" string="early" />
            <token id="25" string="1990s" />
          </tokens>
        </chunking>
        <chunking id="4" string="the early 1990s" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="early" />
            <token id="25" string="1990s" />
          </tokens>
        </chunking>
        <chunking id="5" string="begin installing a new radar system at 47 major airports beginning in the early 1990s" type="VP">
          <tokens>
            <token id="11" string="begin" />
            <token id="12" string="installing" />
            <token id="13" string="a" />
            <token id="14" string="new" />
            <token id="15" string="radar" />
            <token id="16" string="system" />
            <token id="17" string="at" />
            <token id="18" string="47" />
            <token id="19" string="major" />
            <token id="20" string="airports" />
            <token id="21" string="beginning" />
            <token id="22" string="in" />
            <token id="23" string="the" />
            <token id="24" string="early" />
            <token id="25" string="1990s" />
          </tokens>
        </chunking>
        <chunking id="6" string="the Federal Aviation Administation" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="Federal" />
            <token id="8" string="Aviation" />
            <token id="9" string="Administation" />
          </tokens>
        </chunking>
        <chunking id="7" string="47 major airports" type="NP">
          <tokens>
            <token id="18" string="47" />
            <token id="19" string="major" />
            <token id="20" string="airports" />
          </tokens>
        </chunking>
        <chunking id="8" string="persuade the Federal Aviation Administation to begin installing a new radar system at 47 major airports beginning in the early 1990s" type="VP">
          <tokens>
            <token id="5" string="persuade" />
            <token id="6" string="the" />
            <token id="7" string="Federal" />
            <token id="8" string="Aviation" />
            <token id="9" string="Administation" />
            <token id="10" string="to" />
            <token id="11" string="begin" />
            <token id="12" string="installing" />
            <token id="13" string="a" />
            <token id="14" string="new" />
            <token id="15" string="radar" />
            <token id="16" string="system" />
            <token id="17" string="at" />
            <token id="18" string="47" />
            <token id="19" string="major" />
            <token id="20" string="airports" />
            <token id="21" string="beginning" />
            <token id="22" string="in" />
            <token id="23" string="the" />
            <token id="24" string="early" />
            <token id="25" string="1990s" />
          </tokens>
        </chunking>
        <chunking id="9" string="Fujita 's work" type="NP">
          <tokens>
            <token id="1" string="Fujita" />
            <token id="2" string="'s" />
            <token id="3" string="work" />
          </tokens>
        </chunking>
        <chunking id="10" string="installing a new radar system at 47 major airports beginning in the early 1990s" type="VP">
          <tokens>
            <token id="12" string="installing" />
            <token id="13" string="a" />
            <token id="14" string="new" />
            <token id="15" string="radar" />
            <token id="16" string="system" />
            <token id="17" string="at" />
            <token id="18" string="47" />
            <token id="19" string="major" />
            <token id="20" string="airports" />
            <token id="21" string="beginning" />
            <token id="22" string="in" />
            <token id="23" string="the" />
            <token id="24" string="early" />
            <token id="25" string="1990s" />
          </tokens>
        </chunking>
        <chunking id="11" string="47 major airports beginning in the early 1990s" type="NP">
          <tokens>
            <token id="18" string="47" />
            <token id="19" string="major" />
            <token id="20" string="airports" />
            <token id="21" string="beginning" />
            <token id="22" string="in" />
            <token id="23" string="the" />
            <token id="24" string="early" />
            <token id="25" string="1990s" />
          </tokens>
        </chunking>
        <chunking id="12" string="beginning in the early 1990s" type="VP">
          <tokens>
            <token id="21" string="beginning" />
            <token id="22" string="in" />
            <token id="23" string="the" />
            <token id="24" string="early" />
            <token id="25" string="1990s" />
          </tokens>
        </chunking>
        <chunking id="13" string="helped persuade the Federal Aviation Administation to begin installing a new radar system at 47 major airports beginning in the early 1990s" type="VP">
          <tokens>
            <token id="4" string="helped" />
            <token id="5" string="persuade" />
            <token id="6" string="the" />
            <token id="7" string="Federal" />
            <token id="8" string="Aviation" />
            <token id="9" string="Administation" />
            <token id="10" string="to" />
            <token id="11" string="begin" />
            <token id="12" string="installing" />
            <token id="13" string="a" />
            <token id="14" string="new" />
            <token id="15" string="radar" />
            <token id="16" string="system" />
            <token id="17" string="at" />
            <token id="18" string="47" />
            <token id="19" string="major" />
            <token id="20" string="airports" />
            <token id="21" string="beginning" />
            <token id="22" string="in" />
            <token id="23" string="the" />
            <token id="24" string="early" />
            <token id="25" string="1990s" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="3">work</governor>
          <dependent id="1">Fujita</dependent>
        </dependency>
        <dependency type="case">
          <governor id="1">Fujita</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">helped</governor>
          <dependent id="3">work</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">helped</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">helped</governor>
          <dependent id="5">persuade</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">Administation</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Administation</governor>
          <dependent id="7">Federal</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Administation</governor>
          <dependent id="8">Aviation</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">persuade</governor>
          <dependent id="9">Administation</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">begin</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">persuade</governor>
          <dependent id="11">begin</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="11">begin</governor>
          <dependent id="12">installing</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">system</governor>
          <dependent id="13">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">system</governor>
          <dependent id="14">new</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">system</governor>
          <dependent id="15">radar</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">installing</governor>
          <dependent id="16">system</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">airports</governor>
          <dependent id="17">at</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="20">airports</governor>
          <dependent id="18">47</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">airports</governor>
          <dependent id="19">major</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">installing</governor>
          <dependent id="20">airports</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="20">airports</governor>
          <dependent id="21">beginning</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">1990s</governor>
          <dependent id="22">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">1990s</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">1990s</governor>
          <dependent id="24">early</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">beginning</governor>
          <dependent id="25">1990s</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="47" type="NUMBER" score="0.0">
          <tokens>
            <token id="18" string="47" />
          </tokens>
        </entity>
        <entity id="2" string="the early 1990s" type="DATE" score="0.0">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="early" />
            <token id="25" string="1990s" />
          </tokens>
        </entity>
        <entity id="3" string="Fujita" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Fujita" />
          </tokens>
        </entity>
        <entity id="4" string="Federal Aviation Administation" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="7" string="Federal" />
            <token id="8" string="Aviation" />
            <token id="9" string="Administation" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="36" has_coreference="true">
      <content>The Doppler radar system was credited with helping three jetliners at Denver&amp;apost;s airport avoid potentially catastrophic microbursts last year.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Doppler" lemma="Doppler" stem="doppler" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="3" string="radar" lemma="radar" stem="radar" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="system" lemma="system" stem="system" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="credited" lemma="credit" stem="credit" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="helping" lemma="help" stem="help" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="three" lemma="three" stem="three" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="10" string="jetliners" lemma="jetliner" stem="jetlin" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Denver" lemma="Denver" stem="denver" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="13" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="airport" lemma="airport" stem="airport" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="avoid" lemma="avoid" stem="avoid" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="potentially" lemma="potentially" stem="potenti" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="catastrophic" lemma="catastrophic" stem="catastroph" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="microbursts" lemma="microburst" stem="microburst" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="20" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NNP Doppler) (NN radar) (NN system)) (VP (VBD was) (VP (VBN credited) (PP (IN with) (S (VP (VBG helping) (S (NP (NP (CD three) (NNS jetliners)) (PP (IN at) (NP (NP (NNP Denver) (POS 's)) (NN airport)))) (VP (VB avoid) (NP (NP (ADJP (RB potentially) (JJ catastrophic)) (NNS microbursts)) (NP-TMP (JJ last) (NN year)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Denver 's" type="NP">
          <tokens>
            <token id="12" string="Denver" />
            <token id="13" string="'s" />
          </tokens>
        </chunking>
        <chunking id="2" string="credited with helping three jetliners at Denver 's airport avoid potentially catastrophic microbursts last year" type="VP">
          <tokens>
            <token id="6" string="credited" />
            <token id="7" string="with" />
            <token id="8" string="helping" />
            <token id="9" string="three" />
            <token id="10" string="jetliners" />
            <token id="11" string="at" />
            <token id="12" string="Denver" />
            <token id="13" string="'s" />
            <token id="14" string="airport" />
            <token id="15" string="avoid" />
            <token id="16" string="potentially" />
            <token id="17" string="catastrophic" />
            <token id="18" string="microbursts" />
            <token id="19" string="last" />
            <token id="20" string="year" />
          </tokens>
        </chunking>
        <chunking id="3" string="helping three jetliners at Denver 's airport avoid potentially catastrophic microbursts last year" type="VP">
          <tokens>
            <token id="8" string="helping" />
            <token id="9" string="three" />
            <token id="10" string="jetliners" />
            <token id="11" string="at" />
            <token id="12" string="Denver" />
            <token id="13" string="'s" />
            <token id="14" string="airport" />
            <token id="15" string="avoid" />
            <token id="16" string="potentially" />
            <token id="17" string="catastrophic" />
            <token id="18" string="microbursts" />
            <token id="19" string="last" />
            <token id="20" string="year" />
          </tokens>
        </chunking>
        <chunking id="4" string="three jetliners" type="NP">
          <tokens>
            <token id="9" string="three" />
            <token id="10" string="jetliners" />
          </tokens>
        </chunking>
        <chunking id="5" string="potentially catastrophic microbursts" type="NP">
          <tokens>
            <token id="16" string="potentially" />
            <token id="17" string="catastrophic" />
            <token id="18" string="microbursts" />
          </tokens>
        </chunking>
        <chunking id="6" string="Denver 's airport" type="NP">
          <tokens>
            <token id="12" string="Denver" />
            <token id="13" string="'s" />
            <token id="14" string="airport" />
          </tokens>
        </chunking>
        <chunking id="7" string="avoid potentially catastrophic microbursts last year" type="VP">
          <tokens>
            <token id="15" string="avoid" />
            <token id="16" string="potentially" />
            <token id="17" string="catastrophic" />
            <token id="18" string="microbursts" />
            <token id="19" string="last" />
            <token id="20" string="year" />
          </tokens>
        </chunking>
        <chunking id="8" string="potentially catastrophic microbursts last year" type="NP">
          <tokens>
            <token id="16" string="potentially" />
            <token id="17" string="catastrophic" />
            <token id="18" string="microbursts" />
            <token id="19" string="last" />
            <token id="20" string="year" />
          </tokens>
        </chunking>
        <chunking id="9" string="potentially catastrophic" type="ADJP">
          <tokens>
            <token id="16" string="potentially" />
            <token id="17" string="catastrophic" />
          </tokens>
        </chunking>
        <chunking id="10" string="three jetliners at Denver 's airport" type="NP">
          <tokens>
            <token id="9" string="three" />
            <token id="10" string="jetliners" />
            <token id="11" string="at" />
            <token id="12" string="Denver" />
            <token id="13" string="'s" />
            <token id="14" string="airport" />
          </tokens>
        </chunking>
        <chunking id="11" string="was credited with helping three jetliners at Denver 's airport avoid potentially catastrophic microbursts last year" type="VP">
          <tokens>
            <token id="5" string="was" />
            <token id="6" string="credited" />
            <token id="7" string="with" />
            <token id="8" string="helping" />
            <token id="9" string="three" />
            <token id="10" string="jetliners" />
            <token id="11" string="at" />
            <token id="12" string="Denver" />
            <token id="13" string="'s" />
            <token id="14" string="airport" />
            <token id="15" string="avoid" />
            <token id="16" string="potentially" />
            <token id="17" string="catastrophic" />
            <token id="18" string="microbursts" />
            <token id="19" string="last" />
            <token id="20" string="year" />
          </tokens>
        </chunking>
        <chunking id="12" string="The Doppler radar system" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Doppler" />
            <token id="3" string="radar" />
            <token id="4" string="system" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="4">system</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">system</governor>
          <dependent id="2">Doppler</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">system</governor>
          <dependent id="3">radar</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="6">credited</governor>
          <dependent id="4">system</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="6">credited</governor>
          <dependent id="5">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">credited</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">helping</governor>
          <dependent id="7">with</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="6">credited</governor>
          <dependent id="8">helping</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="10">jetliners</governor>
          <dependent id="9">three</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">avoid</governor>
          <dependent id="10">jetliners</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">airport</governor>
          <dependent id="11">at</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="14">airport</governor>
          <dependent id="12">Denver</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">Denver</governor>
          <dependent id="13">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">jetliners</governor>
          <dependent id="14">airport</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="8">helping</governor>
          <dependent id="15">avoid</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="17">catastrophic</governor>
          <dependent id="16">potentially</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">microbursts</governor>
          <dependent id="17">catastrophic</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">avoid</governor>
          <dependent id="18">microbursts</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">year</governor>
          <dependent id="19">last</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="18">microbursts</governor>
          <dependent id="20">year</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Denver" type="LOCATION" score="0.0">
          <tokens>
            <token id="12" string="Denver" />
          </tokens>
        </entity>
        <entity id="2" string="Doppler" type="MISC" score="0.0">
          <tokens>
            <token id="2" string="Doppler" />
          </tokens>
        </entity>
        <entity id="3" string="last year" type="DATE" score="0.0">
          <tokens>
            <token id="19" string="last" />
            <token id="20" string="year" />
          </tokens>
        </entity>
        <entity id="4" string="three" type="NUMBER" score="0.0">
          <tokens>
            <token id="9" string="three" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="37" has_coreference="true">
      <content>Fujita retires from teaching this year, but will continue his research at the university.</content>
      <tokens>
        <token id="1" string="Fujita" lemma="Fujita" stem="fujita" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="retires" lemma="retire" stem="retir" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="teaching" lemma="teach" stem="teach" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="6" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="continue" lemma="continue" stem="continu" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="research" lemma="research" stem="research" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="university" lemma="university" stem="univers" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Fujita)) (VP (VP (VBZ retires) (PP (IN from) (S (VP (VBG teaching) (NP (DT this) (NN year)))))) (, ,) (CC but) (VP (MD will) (VP (VB continue) (NP (PRP$ his) (NN research)) (PP (IN at) (NP (DT the) (NN university)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="will continue his research at the university" type="VP">
          <tokens>
            <token id="9" string="will" />
            <token id="10" string="continue" />
            <token id="11" string="his" />
            <token id="12" string="research" />
            <token id="13" string="at" />
            <token id="14" string="the" />
            <token id="15" string="university" />
          </tokens>
        </chunking>
        <chunking id="2" string="his research" type="NP">
          <tokens>
            <token id="11" string="his" />
            <token id="12" string="research" />
          </tokens>
        </chunking>
        <chunking id="3" string="retires from teaching this year" type="VP">
          <tokens>
            <token id="2" string="retires" />
            <token id="3" string="from" />
            <token id="4" string="teaching" />
            <token id="5" string="this" />
            <token id="6" string="year" />
          </tokens>
        </chunking>
        <chunking id="4" string="the university" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="university" />
          </tokens>
        </chunking>
        <chunking id="5" string="continue his research at the university" type="VP">
          <tokens>
            <token id="10" string="continue" />
            <token id="11" string="his" />
            <token id="12" string="research" />
            <token id="13" string="at" />
            <token id="14" string="the" />
            <token id="15" string="university" />
          </tokens>
        </chunking>
        <chunking id="6" string="retires from teaching this year , but will continue his research at the university" type="VP">
          <tokens>
            <token id="2" string="retires" />
            <token id="3" string="from" />
            <token id="4" string="teaching" />
            <token id="5" string="this" />
            <token id="6" string="year" />
            <token id="7" string="," />
            <token id="8" string="but" />
            <token id="9" string="will" />
            <token id="10" string="continue" />
            <token id="11" string="his" />
            <token id="12" string="research" />
            <token id="13" string="at" />
            <token id="14" string="the" />
            <token id="15" string="university" />
          </tokens>
        </chunking>
        <chunking id="7" string="teaching this year" type="VP">
          <tokens>
            <token id="4" string="teaching" />
            <token id="5" string="this" />
            <token id="6" string="year" />
          </tokens>
        </chunking>
        <chunking id="8" string="this year" type="NP">
          <tokens>
            <token id="5" string="this" />
            <token id="6" string="year" />
          </tokens>
        </chunking>
        <chunking id="9" string="Fujita" type="NP">
          <tokens>
            <token id="1" string="Fujita" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">retires</governor>
          <dependent id="1">Fujita</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">retires</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="4">teaching</governor>
          <dependent id="3">from</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="2">retires</governor>
          <dependent id="4">teaching</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">year</governor>
          <dependent id="5">this</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="4">teaching</governor>
          <dependent id="6">year</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">retires</governor>
          <dependent id="8">but</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="10">continue</governor>
          <dependent id="9">will</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">retires</governor>
          <dependent id="10">continue</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="12">research</governor>
          <dependent id="11">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">continue</governor>
          <dependent id="12">research</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">university</governor>
          <dependent id="13">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">university</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">continue</governor>
          <dependent id="15">university</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="this year" type="DATE" score="0.0">
          <tokens>
            <token id="5" string="this" />
            <token id="6" string="year" />
          </tokens>
        </entity>
        <entity id="2" string="Fujita" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Fujita" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="38" has_coreference="true">
      <content>&amp;quot;In Texas one time, five people were killed when they drove right into a tornado.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Texas" lemma="Texas" stem="texa" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="4" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="5" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="five" lemma="five" stem="five" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="8" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="killed" lemma="kill" stem="kill" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="drove" lemma="drive" stem="drove" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="right" lemma="right" stem="right" pos="RB" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="15" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="tornado" lemma="tornado" stem="tornado" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="true" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (PP (IN In) (NP (NNP Texas) (CD one))) (NP-TMP (NN time)) (, ,) (NP (CD five) (NNS people)) (VP (VBD were) (VP (VBN killed) (SBAR (WHADVP (WRB when)) (S (NP (PRP they)) (VP (VBD drove) (ADVP (RB right)) (PP (IN into) (NP (DT a) (NN tornado)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="killed when they drove right into a tornado" type="VP">
          <tokens>
            <token id="10" string="killed" />
            <token id="11" string="when" />
            <token id="12" string="they" />
            <token id="13" string="drove" />
            <token id="14" string="right" />
            <token id="15" string="into" />
            <token id="16" string="a" />
            <token id="17" string="tornado" />
          </tokens>
        </chunking>
        <chunking id="2" string="they" type="NP">
          <tokens>
            <token id="12" string="they" />
          </tokens>
        </chunking>
        <chunking id="3" string="five people" type="NP">
          <tokens>
            <token id="7" string="five" />
            <token id="8" string="people" />
          </tokens>
        </chunking>
        <chunking id="4" string="when they drove right into a tornado" type="SBAR">
          <tokens>
            <token id="11" string="when" />
            <token id="12" string="they" />
            <token id="13" string="drove" />
            <token id="14" string="right" />
            <token id="15" string="into" />
            <token id="16" string="a" />
            <token id="17" string="tornado" />
          </tokens>
        </chunking>
        <chunking id="5" string="were killed when they drove right into a tornado" type="VP">
          <tokens>
            <token id="9" string="were" />
            <token id="10" string="killed" />
            <token id="11" string="when" />
            <token id="12" string="they" />
            <token id="13" string="drove" />
            <token id="14" string="right" />
            <token id="15" string="into" />
            <token id="16" string="a" />
            <token id="17" string="tornado" />
          </tokens>
        </chunking>
        <chunking id="6" string="drove right into a tornado" type="VP">
          <tokens>
            <token id="13" string="drove" />
            <token id="14" string="right" />
            <token id="15" string="into" />
            <token id="16" string="a" />
            <token id="17" string="tornado" />
          </tokens>
        </chunking>
        <chunking id="7" string="when" type="WHADVP">
          <tokens>
            <token id="11" string="when" />
          </tokens>
        </chunking>
        <chunking id="8" string="Texas one" type="NP">
          <tokens>
            <token id="3" string="Texas" />
            <token id="4" string="one" />
          </tokens>
        </chunking>
        <chunking id="9" string="a tornado" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="tornado" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">Texas</governor>
          <dependent id="2">In</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">killed</governor>
          <dependent id="3">Texas</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="3">Texas</governor>
          <dependent id="4">one</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="10">killed</governor>
          <dependent id="5">time</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="8">people</governor>
          <dependent id="7">five</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="10">killed</governor>
          <dependent id="8">people</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="10">killed</governor>
          <dependent id="9">were</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">killed</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">drove</governor>
          <dependent id="11">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">drove</governor>
          <dependent id="12">they</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="10">killed</governor>
          <dependent id="13">drove</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">drove</governor>
          <dependent id="14">right</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">tornado</governor>
          <dependent id="15">into</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">tornado</governor>
          <dependent id="16">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">drove</governor>
          <dependent id="17">tornado</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="tornado" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="17" string="tornado" />
          </tokens>
        </entity>
        <entity id="2" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="4" string="one" />
          </tokens>
        </entity>
        <entity id="3" string="Texas" type="LOCATION" score="0.0">
          <tokens>
            <token id="3" string="Texas" />
          </tokens>
        </entity>
        <entity id="4" string="right" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="14" string="right" />
          </tokens>
        </entity>
        <entity id="5" string="five" type="NUMBER" score="0.0">
          <tokens>
            <token id="7" string="five" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="39" has_coreference="true">
      <content>They just didn&amp;apost;t know any better,&amp;quot; Fujita said.</content>
      <tokens>
        <token id="1" string="They" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="know" lemma="know" stem="know" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="any" lemma="any" stem="ani" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="better" lemma="better" stem="better" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Fujita" lemma="Fujita" stem="fujita" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="11" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP They)) (ADVP (RB just)) (VP (VBD did) (RB n't) (VP (VB know) (NP (DT any) (JJR better))))) (, ,) ('' '') (NP (NNP Fujita)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="They" type="NP">
          <tokens>
            <token id="1" string="They" />
          </tokens>
        </chunking>
        <chunking id="2" string="any better" type="NP">
          <tokens>
            <token id="6" string="any" />
            <token id="7" string="better" />
          </tokens>
        </chunking>
        <chunking id="3" string="know any better" type="VP">
          <tokens>
            <token id="5" string="know" />
            <token id="6" string="any" />
            <token id="7" string="better" />
          </tokens>
        </chunking>
        <chunking id="4" string="did n't know any better" type="VP">
          <tokens>
            <token id="3" string="did" />
            <token id="4" string="n't" />
            <token id="5" string="know" />
            <token id="6" string="any" />
            <token id="7" string="better" />
          </tokens>
        </chunking>
        <chunking id="5" string="said" type="VP">
          <tokens>
            <token id="11" string="said" />
          </tokens>
        </chunking>
        <chunking id="6" string="Fujita" type="NP">
          <tokens>
            <token id="10" string="Fujita" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">know</governor>
          <dependent id="1">They</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">know</governor>
          <dependent id="2">just</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">know</governor>
          <dependent id="3">did</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">know</governor>
          <dependent id="4">n't</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">said</governor>
          <dependent id="5">know</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">better</governor>
          <dependent id="6">any</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">know</governor>
          <dependent id="7">better</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">said</governor>
          <dependent id="10">Fujita</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Fujita" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Fujita" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="40" has_coreference="true">
      <content>&amp;quot;I want to make people safer.&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="want" lemma="want" stem="want" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="make" lemma="make" stem="make" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="safer" lemma="safer" stem="safer" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP I)) (VP (VBP want) (S (VP (TO to) (VP (VB make) (S (NP (NNS people)) (ADJP (JJR safer))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="want to make people safer" type="VP">
          <tokens>
            <token id="3" string="want" />
            <token id="4" string="to" />
            <token id="5" string="make" />
            <token id="6" string="people" />
            <token id="7" string="safer" />
          </tokens>
        </chunking>
        <chunking id="2" string="safer" type="ADJP">
          <tokens>
            <token id="7" string="safer" />
          </tokens>
        </chunking>
        <chunking id="3" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="4" string="make people safer" type="VP">
          <tokens>
            <token id="5" string="make" />
            <token id="6" string="people" />
            <token id="7" string="safer" />
          </tokens>
        </chunking>
        <chunking id="5" string="people" type="NP">
          <tokens>
            <token id="6" string="people" />
          </tokens>
        </chunking>
        <chunking id="6" string="to make people safer" type="VP">
          <tokens>
            <token id="4" string="to" />
            <token id="5" string="make" />
            <token id="6" string="people" />
            <token id="7" string="safer" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">want</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">want</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">make</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">want</governor>
          <dependent id="5">make</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">safer</governor>
          <dependent id="6">people</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">make</governor>
          <dependent id="7">safer</dependent>
        </dependency>
      </dependencies>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="1" type="PROPER">
      <referenced ids_tokens="1-2-3" string="Tetsuya Theodore Fujita" id_sentence="1" />
      <mentions>
        <mention ids_tokens="6" string="my" id_sentence="2" />
        <mention ids_tokens="13-41" string="Fujita , a professor of geophysical science who has been studying tornadoes for 42 years and is considered one of the world's foremost authorities on the violent storms" id_sentence="3" />
        <mention ids_tokens="13" string="Fujita" id_sentence="3" />
        <mention ids_tokens="15-41" string="a professor of geophysical science who has been studying tornadoes for 42 years and is considered one of the world's foremost authorities on the violent storms" id_sentence="3" />
        <mention ids_tokens="1-3" string="Fujita , 69" id_sentence="4" />
        <mention ids_tokens="1" string="Fujita" id_sentence="4" />
        <mention ids_tokens="8" string="his" id_sentence="4" />
        <mention ids_tokens="11" string="his" id_sentence="4" />
        <mention ids_tokens="1" string="He" id_sentence="5" />
        <mention ids_tokens="13" string="he" id_sentence="6" />
        <mention ids_tokens="16" string="he" id_sentence="7" />
        <mention ids_tokens="1" string="He" id_sentence="8" />
        <mention ids_tokens="1" string="Fujita" id_sentence="9" />
        <mention ids_tokens="10" string="Fujita" id_sentence="10" />
        <mention ids_tokens="9" string="Fujita" id_sentence="15" />
        <mention ids_tokens="2" string="Fujita" id_sentence="19" />
        <mention ids_tokens="1" string="Fujita" id_sentence="23" />
        <mention ids_tokens="15" string="he" id_sentence="23" />
        <mention ids_tokens="5" string="Fujita" id_sentence="26" />
        <mention ids_tokens="2" string="Fujita" id_sentence="28" />
        <mention ids_tokens="4" string="his" id_sentence="28" />
        <mention ids_tokens="15" string="his" id_sentence="28" />
        <mention ids_tokens="21" string="Fujita" id_sentence="31" />
        <mention ids_tokens="14" string="Fujita" id_sentence="32" />
        <mention ids_tokens="1-2" string="Fujita's" id_sentence="35" />
        <mention ids_tokens="1" string="Fujita" id_sentence="37" />
        <mention ids_tokens="11" string="his" id_sentence="37" />
        <mention ids_tokens="10" string="Fujita" id_sentence="39" />
      </mentions>
    </coreference>
    <coreference id="2" type="PROPER">
      <referenced ids_tokens="10" string="Denver" id_sentence="1" />
      <mentions>
        <mention ids_tokens="12-13" string="Denver's" id_sentence="36" />
      </mentions>
    </coreference>
    <coreference id="3" type="PROPER">
      <referenced ids_tokens="5-6-7-8" string="his only natural tornado" id_sentence="1" />
      <mentions>
        <mention ids_tokens="2" string="It" id_sentence="2" />
      </mentions>
    </coreference>
    <coreference id="4" type="NOMINAL">
      <referenced ids_tokens="5-6-7" string="meeting my lover" id_sentence="2" />
      <mentions>
        <mention ids_tokens="5" string="my" id_sentence="3" />
      </mentions>
    </coreference>
    <coreference id="5" type="NOMINAL">
      <referenced ids_tokens="24-25-26-27" string="tornadoes for 42 years" id_sentence="3" />
      <mentions>
        <mention ids_tokens="19" string="tornadoes" id_sentence="4" />
        <mention ids_tokens="2" string="Tornadoes" id_sentence="10" />
        <mention ids_tokens="6" string="tornadoes" id_sentence="18" />
        <mention ids_tokens="10" string="tornadoes" id_sentence="20" />
        <mention ids_tokens="12" string="tornadoes" id_sentence="26" />
      </mentions>
    </coreference>
    <coreference id="6" type="PROPER">
      <referenced ids_tokens="11-12" string="that one" id_sentence="16" />
      <mentions>
        <mention ids_tokens="31-37" string="one of the world's foremost authorities" id_sentence="3" />
      </mentions>
    </coreference>
    <coreference id="7" type="PROPER">
      <referenced ids_tokens="14-15-16-17" string="the University of Chicago" id_sentence="4" />
      <mentions>
        <mention ids_tokens="14-15" string="the university" id_sentence="37" />
      </mentions>
    </coreference>
    <coreference id="9" type="NOMINAL">
      <referenced ids_tokens="15-16-17-18-19-20" string="twisters six to eight feet tall" id_sentence="6" />
      <mentions>
        <mention ids_tokens="12" string="their" id_sentence="7" />
      </mentions>
    </coreference>
    <coreference id="10" type="NOMINAL">
      <referenced ids_tokens="12-13-14" string="their full-size cousins" id_sentence="7" />
      <mentions>
        <mention ids_tokens="10" string="them" id_sentence="8" />
        <mention ids_tokens="18" string="their" id_sentence="8" />
        <mention ids_tokens="2" string="They" id_sentence="11" />
      </mentions>
    </coreference>
    <coreference id="11" type="PROPER">
      <referenced ids_tokens="8-9-10" string="Japan in 1953" id_sentence="9" />
      <mentions>
        <mention ids_tokens="7" string="Japan" id_sentence="10" />
        <mention ids_tokens="1" string="I" id_sentence="13" />
      </mentions>
    </coreference>
    <coreference id="12" type="PROPER">
      <referenced ids_tokens="4-5-6-7-8-9" string="about 10 to 15 a year" id_sentence="11" />
      <mentions>
        <mention ids_tokens="6" string="15" id_sentence="12" />
      </mentions>
    </coreference>
    <coreference id="13" type="PROPER">
      <referenced ids_tokens="5" string="first" id_sentence="14" />
      <mentions>
        <mention ids_tokens="2" string="It" id_sentence="15" />
        <mention ids_tokens="4-6" string="a beautiful thing" id_sentence="15" />
        <mention ids_tokens="5" string="I" id_sentence="16" />
        <mention ids_tokens="6" string="it" id_sentence="17" />
      </mentions>
    </coreference>
    <coreference id="17" type="PROPER">
      <referenced ids_tokens="7" string="20" id_sentence="16" />
      <mentions>
        <mention ids_tokens="13" string="it" id_sentence="17" />
        <mention ids_tokens="15-17" string="a terrible thing" id_sentence="17" />
      </mentions>
    </coreference>
    <coreference id="19" type="NOMINAL">
      <referenced ids_tokens="1" string="Forecasters" id_sentence="18" />
      <mentions>
        <mention ids_tokens="12" string="them" id_sentence="19" />
      </mentions>
    </coreference>
    <coreference id="20" type="NOMINAL">
      <referenced ids_tokens="1-2-3" string="Groups of thunderstorms" id_sentence="20" />
      <mentions>
        <mention ids_tokens="9" string="they" id_sentence="21" />
        <mention ids_tokens="1" string="They" id_sentence="22" />
      </mentions>
    </coreference>
    <coreference id="22" type="PROPER">
      <referenced ids_tokens="22" string="right" id_sentence="24" />
      <mentions>
        <mention ids_tokens="23" string="it" id_sentence="25" />
      </mentions>
    </coreference>
    <coreference id="23" type="PRONOMINAL">
      <referenced ids_tokens="19" string="you" id_sentence="24" />
      <mentions>
        <mention ids_tokens="1" string="He" id_sentence="25" />
        <mention ids_tokens="1" string="He" id_sentence="26" />
      </mentions>
    </coreference>
    <coreference id="25" type="NOMINAL">
      <referenced ids_tokens="4-5-6" string="the Fujita scale" id_sentence="26" />
      <mentions>
        <mention ids_tokens="1" string="It" id_sentence="27" />
      </mentions>
    </coreference>
    <coreference id="27" type="NOMINAL">
      <referenced ids_tokens="3-4-5-6-7-8-9-10-11-12" string="powerful drafts of air moving down from a thunderstorm cloud" id_sentence="29" />
      <mentions>
        <mention ids_tokens="6" string="downbursts" id_sentence="31" />
      </mentions>
    </coreference>
    <coreference id="28" type="NOMINAL">
      <referenced ids_tokens="1" string="Microbursts" id_sentence="31" />
      <mentions>
        <mention ids_tokens="2" string="them" id_sentence="33" />
      </mentions>
    </coreference>
    <coreference id="29" type="NOMINAL">
      <referenced ids_tokens="16-17-18-19" string="less time to react" id_sentence="31" />
      <mentions>
        <mention ids_tokens="5" string="time" id_sentence="38" />
      </mentions>
    </coreference>
    <coreference id="30" type="PROPER">
      <referenced ids_tokens="19-20" string="last year" id_sentence="36" />
      <mentions>
        <mention ids_tokens="5-6" string="this year" id_sentence="37" />
      </mentions>
    </coreference>
    <coreference id="31" type="NOMINAL">
      <referenced ids_tokens="7-8" string="five people" id_sentence="38" />
      <mentions>
        <mention ids_tokens="1" string="They" id_sentence="39" />
        <mention ids_tokens="6" string="people" id_sentence="40" />
      </mentions>
    </coreference>
    <coreference id="32" type="PROPER">
      <referenced ids_tokens="16-17" string="a tornado" id_sentence="38" />
      <mentions>
        <mention ids_tokens="2" string="I" id_sentence="40" />
      </mentions>
    </coreference>
  </coreferences>
</document>
