<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="SJMN91-06129119">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>CONSIDER THE following case: A suspect involved in a high-speed chase refuses to stop.; At the end of the chase the officer takes his baton and brutally hits the suspect on the back eight to 10 times, then kicks him in the face.</content>
      <tokens>
        <token id="1" string="CONSIDER" lemma="CONSIDER" stem="consider" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="THE" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="following" lemma="follow" stem="follow" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="suspect" lemma="suspect" stem="suspect" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="involved" lemma="involve" stem="involv" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="high-speed" lemma="high-speed" stem="high-spe" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="chase" lemma="chase" stem="chase" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="refuses" lemma="refuse" stem="refus" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="stop." lemma="stop." stem="stop." pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="At" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="end" lemma="end" stem="end" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="chase" lemma="chase" stem="chase" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="24" string="officer" lemma="officer" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="25" string="takes" lemma="take" stem="take" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="baton" lemma="baton" stem="baton" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="brutally" lemma="brutally" stem="brutal" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="hits" lemma="hit" stem="hit" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="suspect" lemma="suspect" stem="suspect" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="back" lemma="back" stem="back" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="eight" lemma="eight" stem="eight" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="37" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="10" lemma="10" stem="10" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="39" string="times" lemma="time" stem="time" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="kicks" lemma="kick" stem="kick" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="46" string="face" lemma="face" stem="face" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="47" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (NNP CONSIDER) (DT THE)) (PP (VBG following) (NP (NP (NN case)) (: :) (NP (NP (DT A) (ADJP (JJ suspect) (VBN involved))) (PP (IN in) (NP (DT a) (JJ high-speed) (NN chase))))))) (VP (VBZ refuses) (S (VP (TO to) (VP (VB stop.)))))) (: ;) (S (PP (IN At) (NP (NP (DT the) (NN end)) (PP (IN of) (NP (DT the) (NN chase))))) (NP (DT the) (NN officer)) (VP (VP (VBZ takes) (NP (PRP$ his) (NN baton))) (CC and) (VP (ADVP (RB brutally)) (VBZ hits) (NP (NP (DT the) (NN suspect)) (PP (IN on) (NP (DT the) (JJ back) (QP (CD eight) (TO to) (CD 10) (NNS times)))))) (, ,) (ADVP (RB then)) (VP (VBZ kicks) (NP (PRP him)) (PP (IN in) (NP (DT the) (NN face)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="stop." type="VP">
          <tokens>
            <token id="15" string="stop." />
          </tokens>
        </chunking>
        <chunking id="2" string="case : A suspect involved in a high-speed chase" type="NP">
          <tokens>
            <token id="4" string="case" />
            <token id="5" string=":" />
            <token id="6" string="A" />
            <token id="7" string="suspect" />
            <token id="8" string="involved" />
            <token id="9" string="in" />
            <token id="10" string="a" />
            <token id="11" string="high-speed" />
            <token id="12" string="chase" />
          </tokens>
        </chunking>
        <chunking id="3" string="his baton" type="NP">
          <tokens>
            <token id="26" string="his" />
            <token id="27" string="baton" />
          </tokens>
        </chunking>
        <chunking id="4" string="kicks him in the face" type="VP">
          <tokens>
            <token id="42" string="kicks" />
            <token id="43" string="him" />
            <token id="44" string="in" />
            <token id="45" string="the" />
            <token id="46" string="face" />
          </tokens>
        </chunking>
        <chunking id="5" string="takes his baton" type="VP">
          <tokens>
            <token id="25" string="takes" />
            <token id="26" string="his" />
            <token id="27" string="baton" />
          </tokens>
        </chunking>
        <chunking id="6" string="the chase" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="chase" />
          </tokens>
        </chunking>
        <chunking id="7" string="the back eight to 10 times" type="NP">
          <tokens>
            <token id="34" string="the" />
            <token id="35" string="back" />
            <token id="36" string="eight" />
            <token id="37" string="to" />
            <token id="38" string="10" />
            <token id="39" string="times" />
          </tokens>
        </chunking>
        <chunking id="8" string="CONSIDER THE following case : A suspect involved in a high-speed chase" type="NP">
          <tokens>
            <token id="1" string="CONSIDER" />
            <token id="2" string="THE" />
            <token id="3" string="following" />
            <token id="4" string="case" />
            <token id="5" string=":" />
            <token id="6" string="A" />
            <token id="7" string="suspect" />
            <token id="8" string="involved" />
            <token id="9" string="in" />
            <token id="10" string="a" />
            <token id="11" string="high-speed" />
            <token id="12" string="chase" />
          </tokens>
        </chunking>
        <chunking id="9" string="A suspect involved in a high-speed chase" type="NP">
          <tokens>
            <token id="6" string="A" />
            <token id="7" string="suspect" />
            <token id="8" string="involved" />
            <token id="9" string="in" />
            <token id="10" string="a" />
            <token id="11" string="high-speed" />
            <token id="12" string="chase" />
          </tokens>
        </chunking>
        <chunking id="10" string="the face" type="NP">
          <tokens>
            <token id="45" string="the" />
            <token id="46" string="face" />
          </tokens>
        </chunking>
        <chunking id="11" string="CONSIDER THE" type="NP">
          <tokens>
            <token id="1" string="CONSIDER" />
            <token id="2" string="THE" />
          </tokens>
        </chunking>
        <chunking id="12" string="the end of the chase" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="end" />
            <token id="20" string="of" />
            <token id="21" string="the" />
            <token id="22" string="chase" />
          </tokens>
        </chunking>
        <chunking id="13" string="refuses to stop." type="VP">
          <tokens>
            <token id="13" string="refuses" />
            <token id="14" string="to" />
            <token id="15" string="stop." />
          </tokens>
        </chunking>
        <chunking id="14" string="takes his baton and brutally hits the suspect on the back eight to 10 times , then kicks him in the face" type="VP">
          <tokens>
            <token id="25" string="takes" />
            <token id="26" string="his" />
            <token id="27" string="baton" />
            <token id="28" string="and" />
            <token id="29" string="brutally" />
            <token id="30" string="hits" />
            <token id="31" string="the" />
            <token id="32" string="suspect" />
            <token id="33" string="on" />
            <token id="34" string="the" />
            <token id="35" string="back" />
            <token id="36" string="eight" />
            <token id="37" string="to" />
            <token id="38" string="10" />
            <token id="39" string="times" />
            <token id="40" string="," />
            <token id="41" string="then" />
            <token id="42" string="kicks" />
            <token id="43" string="him" />
            <token id="44" string="in" />
            <token id="45" string="the" />
            <token id="46" string="face" />
          </tokens>
        </chunking>
        <chunking id="15" string="the suspect" type="NP">
          <tokens>
            <token id="31" string="the" />
            <token id="32" string="suspect" />
          </tokens>
        </chunking>
        <chunking id="16" string="case" type="NP">
          <tokens>
            <token id="4" string="case" />
          </tokens>
        </chunking>
        <chunking id="17" string="the end" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="end" />
          </tokens>
        </chunking>
        <chunking id="18" string="to stop." type="VP">
          <tokens>
            <token id="14" string="to" />
            <token id="15" string="stop." />
          </tokens>
        </chunking>
        <chunking id="19" string="the officer" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="officer" />
          </tokens>
        </chunking>
        <chunking id="20" string="him" type="NP">
          <tokens>
            <token id="43" string="him" />
          </tokens>
        </chunking>
        <chunking id="21" string="brutally hits the suspect on the back eight to 10 times" type="VP">
          <tokens>
            <token id="29" string="brutally" />
            <token id="30" string="hits" />
            <token id="31" string="the" />
            <token id="32" string="suspect" />
            <token id="33" string="on" />
            <token id="34" string="the" />
            <token id="35" string="back" />
            <token id="36" string="eight" />
            <token id="37" string="to" />
            <token id="38" string="10" />
            <token id="39" string="times" />
          </tokens>
        </chunking>
        <chunking id="22" string="A suspect involved" type="NP">
          <tokens>
            <token id="6" string="A" />
            <token id="7" string="suspect" />
            <token id="8" string="involved" />
          </tokens>
        </chunking>
        <chunking id="23" string="the suspect on the back eight to 10 times" type="NP">
          <tokens>
            <token id="31" string="the" />
            <token id="32" string="suspect" />
            <token id="33" string="on" />
            <token id="34" string="the" />
            <token id="35" string="back" />
            <token id="36" string="eight" />
            <token id="37" string="to" />
            <token id="38" string="10" />
            <token id="39" string="times" />
          </tokens>
        </chunking>
        <chunking id="24" string="suspect involved" type="ADJP">
          <tokens>
            <token id="7" string="suspect" />
            <token id="8" string="involved" />
          </tokens>
        </chunking>
        <chunking id="25" string="a high-speed chase" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="high-speed" />
            <token id="12" string="chase" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="13">refuses</governor>
          <dependent id="1">CONSIDER</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="1">CONSIDER</governor>
          <dependent id="2">THE</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">case</governor>
          <dependent id="3">following</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">CONSIDER</governor>
          <dependent id="4">case</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">involved</governor>
          <dependent id="6">A</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="8">involved</governor>
          <dependent id="7">suspect</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="4">case</governor>
          <dependent id="8">involved</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">chase</governor>
          <dependent id="9">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">chase</governor>
          <dependent id="10">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">chase</governor>
          <dependent id="11">high-speed</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">involved</governor>
          <dependent id="12">chase</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">refuses</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">stop.</governor>
          <dependent id="14">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="13">refuses</governor>
          <dependent id="15">stop.</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">end</governor>
          <dependent id="17">At</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">end</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">takes</governor>
          <dependent id="19">end</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">chase</governor>
          <dependent id="20">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">chase</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">end</governor>
          <dependent id="22">chase</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">officer</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">takes</governor>
          <dependent id="24">officer</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="13">refuses</governor>
          <dependent id="25">takes</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="27">baton</governor>
          <dependent id="26">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="25">takes</governor>
          <dependent id="27">baton</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="25">takes</governor>
          <dependent id="28">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="30">hits</governor>
          <dependent id="29">brutally</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="25">takes</governor>
          <dependent id="30">hits</dependent>
        </dependency>
        <dependency type="det">
          <governor id="32">suspect</governor>
          <dependent id="31">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="30">hits</governor>
          <dependent id="32">suspect</dependent>
        </dependency>
        <dependency type="case">
          <governor id="39">times</governor>
          <dependent id="33">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="39">times</governor>
          <dependent id="34">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="39">times</governor>
          <dependent id="35">back</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="39">times</governor>
          <dependent id="36">eight</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="39">times</governor>
          <dependent id="37">to</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="39">times</governor>
          <dependent id="38">10</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="32">suspect</governor>
          <dependent id="39">times</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="42">kicks</governor>
          <dependent id="41">then</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="25">takes</governor>
          <dependent id="42">kicks</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="42">kicks</governor>
          <dependent id="43">him</dependent>
        </dependency>
        <dependency type="case">
          <governor id="46">face</governor>
          <dependent id="44">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="46">face</governor>
          <dependent id="45">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="42">kicks</governor>
          <dependent id="46">face</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="eight" type="NUMBER" score="0.0">
          <tokens>
            <token id="36" string="eight" />
          </tokens>
        </entity>
        <entity id="2" string="10" type="NUMBER" score="0.0">
          <tokens>
            <token id="38" string="10" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>He is then picked up by his shoulders and his face is slammed into the pavement.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="picked" lemma="pick" stem="pick" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="shoulders" lemma="shoulder" stem="shoulder" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="face" lemma="face" stem="face" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="slammed" lemma="slam" stem="slam" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="pavement" lemma="pavement" stem="pavement" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP He)) (VP (VBZ is) (ADVP (RB then)) (VP (VBN picked) (PRT (RP up)) (PP (IN by) (NP (PRP$ his) (NNS shoulders)))))) (CC and) (S (NP (PRP$ his) (NN face)) (VP (VBZ is) (VP (VBN slammed) (PP (IN into) (NP (DT the) (NN pavement)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="his shoulders" type="NP">
          <tokens>
            <token id="7" string="his" />
            <token id="8" string="shoulders" />
          </tokens>
        </chunking>
        <chunking id="2" string="the pavement" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="pavement" />
          </tokens>
        </chunking>
        <chunking id="3" string="his face" type="NP">
          <tokens>
            <token id="10" string="his" />
            <token id="11" string="face" />
          </tokens>
        </chunking>
        <chunking id="4" string="is slammed into the pavement" type="VP">
          <tokens>
            <token id="12" string="is" />
            <token id="13" string="slammed" />
            <token id="14" string="into" />
            <token id="15" string="the" />
            <token id="16" string="pavement" />
          </tokens>
        </chunking>
        <chunking id="5" string="slammed into the pavement" type="VP">
          <tokens>
            <token id="13" string="slammed" />
            <token id="14" string="into" />
            <token id="15" string="the" />
            <token id="16" string="pavement" />
          </tokens>
        </chunking>
        <chunking id="6" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="7" string="is then picked up by his shoulders" type="VP">
          <tokens>
            <token id="2" string="is" />
            <token id="3" string="then" />
            <token id="4" string="picked" />
            <token id="5" string="up" />
            <token id="6" string="by" />
            <token id="7" string="his" />
            <token id="8" string="shoulders" />
          </tokens>
        </chunking>
        <chunking id="8" string="picked up by his shoulders" type="VP">
          <tokens>
            <token id="4" string="picked" />
            <token id="5" string="up" />
            <token id="6" string="by" />
            <token id="7" string="his" />
            <token id="8" string="shoulders" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="4">picked</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="4">picked</governor>
          <dependent id="2">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">picked</governor>
          <dependent id="3">then</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">picked</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="4">picked</governor>
          <dependent id="5">up</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">shoulders</governor>
          <dependent id="6">by</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">shoulders</governor>
          <dependent id="7">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">picked</governor>
          <dependent id="8">shoulders</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">picked</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">face</governor>
          <dependent id="10">his</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="13">slammed</governor>
          <dependent id="11">face</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="13">slammed</governor>
          <dependent id="12">is</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">picked</governor>
          <dependent id="13">slammed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">pavement</governor>
          <dependent id="14">into</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">pavement</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">slammed</governor>
          <dependent id="16">pavement</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>The suspect, unconscious, is taken to Valley Medical Center where he is found to have a dislocated shoulder, a concussion, and numerous cuts, bruises and contusions.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="suspect" lemma="suspect" stem="suspect" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="unconscious" lemma="unconscious" stem="unconsci" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="taken" lemma="take" stem="taken" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Valley" lemma="Valley" stem="vallei" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="10" string="Medical" lemma="Medical" stem="medic" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="11" string="Center" lemma="Center" stem="center" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="12" string="where" lemma="where" stem="where" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="found" lemma="find" stem="found" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="dislocated" lemma="dislocate" stem="disloc" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="shoulder" lemma="shoulder" stem="shoulder" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="concussion" lemma="concussion" stem="concuss" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="numerous" lemma="numerous" stem="numer" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="cuts" lemma="cut" stem="cut" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="bruises" lemma="bruise" stem="bruis" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="contusions" lemma="contusion" stem="contus" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (NN suspect)) (, ,) (ADJP (JJ unconscious)) (, ,)) (VP (VBZ is) (VP (VBN taken) (PP (TO to) (NP (NP (NNP Valley) (NNP Medical) (NNP Center)) (SBAR (WHADVP (WRB where)) (S (NP (PRP he)) (VP (VBZ is) (VP (VBN found) (S (VP (TO to) (VP (VB have) (NP (NP (DT a)) (VP (VBN dislocated) (NP (NP (NN shoulder)) (, ,) (NP (DT a) (NN concussion)) (, ,) (CC and) (NP (JJ numerous) (NNS cuts) (, ,) (NNS bruises) (CC and) (NNS contusions)))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="unconscious" type="ADJP">
          <tokens>
            <token id="4" string="unconscious" />
          </tokens>
        </chunking>
        <chunking id="2" string="a" type="NP">
          <tokens>
            <token id="18" string="a" />
          </tokens>
        </chunking>
        <chunking id="3" string="shoulder" type="NP">
          <tokens>
            <token id="20" string="shoulder" />
          </tokens>
        </chunking>
        <chunking id="4" string="The suspect" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="suspect" />
          </tokens>
        </chunking>
        <chunking id="5" string="a concussion" type="NP">
          <tokens>
            <token id="22" string="a" />
            <token id="23" string="concussion" />
          </tokens>
        </chunking>
        <chunking id="6" string="Valley Medical Center where he is found to have a dislocated shoulder , a concussion , and numerous cuts , bruises and contusions" type="NP">
          <tokens>
            <token id="9" string="Valley" />
            <token id="10" string="Medical" />
            <token id="11" string="Center" />
            <token id="12" string="where" />
            <token id="13" string="he" />
            <token id="14" string="is" />
            <token id="15" string="found" />
            <token id="16" string="to" />
            <token id="17" string="have" />
            <token id="18" string="a" />
            <token id="19" string="dislocated" />
            <token id="20" string="shoulder" />
            <token id="21" string="," />
            <token id="22" string="a" />
            <token id="23" string="concussion" />
            <token id="24" string="," />
            <token id="25" string="and" />
            <token id="26" string="numerous" />
            <token id="27" string="cuts" />
            <token id="28" string="," />
            <token id="29" string="bruises" />
            <token id="30" string="and" />
            <token id="31" string="contusions" />
          </tokens>
        </chunking>
        <chunking id="7" string="is found to have a dislocated shoulder , a concussion , and numerous cuts , bruises and contusions" type="VP">
          <tokens>
            <token id="14" string="is" />
            <token id="15" string="found" />
            <token id="16" string="to" />
            <token id="17" string="have" />
            <token id="18" string="a" />
            <token id="19" string="dislocated" />
            <token id="20" string="shoulder" />
            <token id="21" string="," />
            <token id="22" string="a" />
            <token id="23" string="concussion" />
            <token id="24" string="," />
            <token id="25" string="and" />
            <token id="26" string="numerous" />
            <token id="27" string="cuts" />
            <token id="28" string="," />
            <token id="29" string="bruises" />
            <token id="30" string="and" />
            <token id="31" string="contusions" />
          </tokens>
        </chunking>
        <chunking id="8" string="where he is found to have a dislocated shoulder , a concussion , and numerous cuts , bruises and contusions" type="SBAR">
          <tokens>
            <token id="12" string="where" />
            <token id="13" string="he" />
            <token id="14" string="is" />
            <token id="15" string="found" />
            <token id="16" string="to" />
            <token id="17" string="have" />
            <token id="18" string="a" />
            <token id="19" string="dislocated" />
            <token id="20" string="shoulder" />
            <token id="21" string="," />
            <token id="22" string="a" />
            <token id="23" string="concussion" />
            <token id="24" string="," />
            <token id="25" string="and" />
            <token id="26" string="numerous" />
            <token id="27" string="cuts" />
            <token id="28" string="," />
            <token id="29" string="bruises" />
            <token id="30" string="and" />
            <token id="31" string="contusions" />
          </tokens>
        </chunking>
        <chunking id="9" string="shoulder , a concussion , and numerous cuts , bruises and contusions" type="NP">
          <tokens>
            <token id="20" string="shoulder" />
            <token id="21" string="," />
            <token id="22" string="a" />
            <token id="23" string="concussion" />
            <token id="24" string="," />
            <token id="25" string="and" />
            <token id="26" string="numerous" />
            <token id="27" string="cuts" />
            <token id="28" string="," />
            <token id="29" string="bruises" />
            <token id="30" string="and" />
            <token id="31" string="contusions" />
          </tokens>
        </chunking>
        <chunking id="10" string="is taken to Valley Medical Center where he is found to have a dislocated shoulder , a concussion , and numerous cuts , bruises and contusions" type="VP">
          <tokens>
            <token id="6" string="is" />
            <token id="7" string="taken" />
            <token id="8" string="to" />
            <token id="9" string="Valley" />
            <token id="10" string="Medical" />
            <token id="11" string="Center" />
            <token id="12" string="where" />
            <token id="13" string="he" />
            <token id="14" string="is" />
            <token id="15" string="found" />
            <token id="16" string="to" />
            <token id="17" string="have" />
            <token id="18" string="a" />
            <token id="19" string="dislocated" />
            <token id="20" string="shoulder" />
            <token id="21" string="," />
            <token id="22" string="a" />
            <token id="23" string="concussion" />
            <token id="24" string="," />
            <token id="25" string="and" />
            <token id="26" string="numerous" />
            <token id="27" string="cuts" />
            <token id="28" string="," />
            <token id="29" string="bruises" />
            <token id="30" string="and" />
            <token id="31" string="contusions" />
          </tokens>
        </chunking>
        <chunking id="11" string="to have a dislocated shoulder , a concussion , and numerous cuts , bruises and contusions" type="VP">
          <tokens>
            <token id="16" string="to" />
            <token id="17" string="have" />
            <token id="18" string="a" />
            <token id="19" string="dislocated" />
            <token id="20" string="shoulder" />
            <token id="21" string="," />
            <token id="22" string="a" />
            <token id="23" string="concussion" />
            <token id="24" string="," />
            <token id="25" string="and" />
            <token id="26" string="numerous" />
            <token id="27" string="cuts" />
            <token id="28" string="," />
            <token id="29" string="bruises" />
            <token id="30" string="and" />
            <token id="31" string="contusions" />
          </tokens>
        </chunking>
        <chunking id="12" string="The suspect , unconscious ," type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="suspect" />
            <token id="3" string="," />
            <token id="4" string="unconscious" />
            <token id="5" string="," />
          </tokens>
        </chunking>
        <chunking id="13" string="taken to Valley Medical Center where he is found to have a dislocated shoulder , a concussion , and numerous cuts , bruises and contusions" type="VP">
          <tokens>
            <token id="7" string="taken" />
            <token id="8" string="to" />
            <token id="9" string="Valley" />
            <token id="10" string="Medical" />
            <token id="11" string="Center" />
            <token id="12" string="where" />
            <token id="13" string="he" />
            <token id="14" string="is" />
            <token id="15" string="found" />
            <token id="16" string="to" />
            <token id="17" string="have" />
            <token id="18" string="a" />
            <token id="19" string="dislocated" />
            <token id="20" string="shoulder" />
            <token id="21" string="," />
            <token id="22" string="a" />
            <token id="23" string="concussion" />
            <token id="24" string="," />
            <token id="25" string="and" />
            <token id="26" string="numerous" />
            <token id="27" string="cuts" />
            <token id="28" string="," />
            <token id="29" string="bruises" />
            <token id="30" string="and" />
            <token id="31" string="contusions" />
          </tokens>
        </chunking>
        <chunking id="14" string="dislocated shoulder , a concussion , and numerous cuts , bruises and contusions" type="VP">
          <tokens>
            <token id="19" string="dislocated" />
            <token id="20" string="shoulder" />
            <token id="21" string="," />
            <token id="22" string="a" />
            <token id="23" string="concussion" />
            <token id="24" string="," />
            <token id="25" string="and" />
            <token id="26" string="numerous" />
            <token id="27" string="cuts" />
            <token id="28" string="," />
            <token id="29" string="bruises" />
            <token id="30" string="and" />
            <token id="31" string="contusions" />
          </tokens>
        </chunking>
        <chunking id="15" string="Valley Medical Center" type="NP">
          <tokens>
            <token id="9" string="Valley" />
            <token id="10" string="Medical" />
            <token id="11" string="Center" />
          </tokens>
        </chunking>
        <chunking id="16" string="where" type="WHADVP">
          <tokens>
            <token id="12" string="where" />
          </tokens>
        </chunking>
        <chunking id="17" string="have a dislocated shoulder , a concussion , and numerous cuts , bruises and contusions" type="VP">
          <tokens>
            <token id="17" string="have" />
            <token id="18" string="a" />
            <token id="19" string="dislocated" />
            <token id="20" string="shoulder" />
            <token id="21" string="," />
            <token id="22" string="a" />
            <token id="23" string="concussion" />
            <token id="24" string="," />
            <token id="25" string="and" />
            <token id="26" string="numerous" />
            <token id="27" string="cuts" />
            <token id="28" string="," />
            <token id="29" string="bruises" />
            <token id="30" string="and" />
            <token id="31" string="contusions" />
          </tokens>
        </chunking>
        <chunking id="18" string="a dislocated shoulder , a concussion , and numerous cuts , bruises and contusions" type="NP">
          <tokens>
            <token id="18" string="a" />
            <token id="19" string="dislocated" />
            <token id="20" string="shoulder" />
            <token id="21" string="," />
            <token id="22" string="a" />
            <token id="23" string="concussion" />
            <token id="24" string="," />
            <token id="25" string="and" />
            <token id="26" string="numerous" />
            <token id="27" string="cuts" />
            <token id="28" string="," />
            <token id="29" string="bruises" />
            <token id="30" string="and" />
            <token id="31" string="contusions" />
          </tokens>
        </chunking>
        <chunking id="19" string="he" type="NP">
          <tokens>
            <token id="13" string="he" />
          </tokens>
        </chunking>
        <chunking id="20" string="numerous cuts , bruises and contusions" type="NP">
          <tokens>
            <token id="26" string="numerous" />
            <token id="27" string="cuts" />
            <token id="28" string="," />
            <token id="29" string="bruises" />
            <token id="30" string="and" />
            <token id="31" string="contusions" />
          </tokens>
        </chunking>
        <chunking id="21" string="found to have a dislocated shoulder , a concussion , and numerous cuts , bruises and contusions" type="VP">
          <tokens>
            <token id="15" string="found" />
            <token id="16" string="to" />
            <token id="17" string="have" />
            <token id="18" string="a" />
            <token id="19" string="dislocated" />
            <token id="20" string="shoulder" />
            <token id="21" string="," />
            <token id="22" string="a" />
            <token id="23" string="concussion" />
            <token id="24" string="," />
            <token id="25" string="and" />
            <token id="26" string="numerous" />
            <token id="27" string="cuts" />
            <token id="28" string="," />
            <token id="29" string="bruises" />
            <token id="30" string="and" />
            <token id="31" string="contusions" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">suspect</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="7">taken</governor>
          <dependent id="2">suspect</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="2">suspect</governor>
          <dependent id="4">unconscious</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="7">taken</governor>
          <dependent id="6">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">taken</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Center</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Center</governor>
          <dependent id="9">Valley</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Center</governor>
          <dependent id="10">Medical</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">taken</governor>
          <dependent id="11">Center</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">found</governor>
          <dependent id="12">where</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="15">found</governor>
          <dependent id="13">he</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="15">found</governor>
          <dependent id="14">is</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="11">Center</governor>
          <dependent id="15">found</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">have</governor>
          <dependent id="16">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="15">found</governor>
          <dependent id="17">have</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">have</governor>
          <dependent id="18">a</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="18">a</governor>
          <dependent id="19">dislocated</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">dislocated</governor>
          <dependent id="20">shoulder</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">concussion</governor>
          <dependent id="22">a</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="20">shoulder</governor>
          <dependent id="23">concussion</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="20">shoulder</governor>
          <dependent id="25">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="27">cuts</governor>
          <dependent id="26">numerous</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="20">shoulder</governor>
          <dependent id="27">cuts</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="27">cuts</governor>
          <dependent id="29">bruises</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="27">cuts</governor>
          <dependent id="30">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="27">cuts</governor>
          <dependent id="31">contusions</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Valley Medical Center" type="LOCATION" score="0.0">
          <tokens>
            <token id="9" string="Valley" />
            <token id="10" string="Medical" />
            <token id="11" string="Center" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="false">
      <content>This was a real case involving a Santa Clara County police agency.</content>
      <tokens>
        <token id="1" string="This" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="real" lemma="real" stem="real" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="involving" lemma="involve" stem="involv" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="Santa" lemma="Santa" stem="santa" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="9" string="Clara" lemma="Clara" stem="clara" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="10" string="County" lemma="County" stem="counti" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="11" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="agency" lemma="agency" stem="agenc" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT This)) (VP (VBD was) (NP (NP (DT a) (JJ real) (NN case)) (PP (VBG involving) (NP (DT a) (NNP Santa) (NNP Clara) (NNP County) (NN police) (NN agency))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a real case involving a Santa Clara County police agency" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="real" />
            <token id="5" string="case" />
            <token id="6" string="involving" />
            <token id="7" string="a" />
            <token id="8" string="Santa" />
            <token id="9" string="Clara" />
            <token id="10" string="County" />
            <token id="11" string="police" />
            <token id="12" string="agency" />
          </tokens>
        </chunking>
        <chunking id="2" string="was a real case involving a Santa Clara County police agency" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="a" />
            <token id="4" string="real" />
            <token id="5" string="case" />
            <token id="6" string="involving" />
            <token id="7" string="a" />
            <token id="8" string="Santa" />
            <token id="9" string="Clara" />
            <token id="10" string="County" />
            <token id="11" string="police" />
            <token id="12" string="agency" />
          </tokens>
        </chunking>
        <chunking id="3" string="This" type="NP">
          <tokens>
            <token id="1" string="This" />
          </tokens>
        </chunking>
        <chunking id="4" string="a real case" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="real" />
            <token id="5" string="case" />
          </tokens>
        </chunking>
        <chunking id="5" string="a Santa Clara County police agency" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="Santa" />
            <token id="9" string="Clara" />
            <token id="10" string="County" />
            <token id="11" string="police" />
            <token id="12" string="agency" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">case</governor>
          <dependent id="1">This</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">case</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">case</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">case</governor>
          <dependent id="4">real</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">case</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">agency</governor>
          <dependent id="6">involving</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">agency</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">agency</governor>
          <dependent id="8">Santa</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">agency</governor>
          <dependent id="9">Clara</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">agency</governor>
          <dependent id="10">County</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">agency</governor>
          <dependent id="11">police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">case</governor>
          <dependent id="12">agency</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Santa Clara County" type="LOCATION" score="0.0">
          <tokens>
            <token id="8" string="Santa" />
            <token id="9" string="Clara" />
            <token id="10" string="County" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>I represented the suspect.</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="represented" lemma="represent" stem="repres" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="suspect" lemma="suspect" stem="suspect" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (VP (VBD represented) (NP (DT the) (NN suspect))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="2" string="represented the suspect" type="VP">
          <tokens>
            <token id="2" string="represented" />
            <token id="3" string="the" />
            <token id="4" string="suspect" />
          </tokens>
        </chunking>
        <chunking id="3" string="the suspect" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="suspect" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">represented</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">represented</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">suspect</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">represented</governor>
          <dependent id="4">suspect</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>The offending officer&amp;apost;s police report indicated that the suspect&amp;apost;s injuries were due to a fall from his bike and that he appeared unconscious, although he had also struggled against being handcuffed.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="offending" lemma="offend" stem="offend" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="officer" lemma="officer" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="report" lemma="report" stem="report" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="indicated" lemma="indicate" stem="indic" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="suspect" lemma="suspect" stem="suspect" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="injuries" lemma="injury" stem="injuri" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="due" lemma="due" stem="due" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="fall" lemma="fall" stem="fall" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="18" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="bike" lemma="bike" stem="bike" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="appeared" lemma="appear" stem="appear" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="unconscious" lemma="unconscious" stem="unconsci" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="although" lemma="although" stem="although" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="29" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="struggled" lemma="struggle" stem="struggl" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="being" lemma="be" stem="be" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="handcuffed" lemma="handcuff" stem="handcuf" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (VBG offending) (NN officer) (POS 's)) (NN police) (NN report)) (VP (VBD indicated) (SBAR (SBAR (IN that) (S (NP (NP (DT the) (NN suspect) (POS 's)) (NNS injuries)) (VP (VBD were) (ADJP (JJ due) (PP (TO to) (NP (NP (DT a) (NN fall)) (PP (IN from) (NP (PRP$ his) (NN bike))))))))) (CC and) (SBAR (IN that) (S (NP (PRP he)) (VP (VBD appeared) (ADJP (JJ unconscious)) (, ,) (SBAR (IN although) (S (NP (PRP he)) (VP (VBD had) (ADVP (RB also)) (VP (VBN struggled) (PP (IN against) (S (VP (VBG being) (ADJP (VBN handcuffed)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="unconscious" type="ADJP">
          <tokens>
            <token id="25" string="unconscious" />
          </tokens>
        </chunking>
        <chunking id="2" string="a fall" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="fall" />
          </tokens>
        </chunking>
        <chunking id="3" string="being handcuffed" type="VP">
          <tokens>
            <token id="33" string="being" />
            <token id="34" string="handcuffed" />
          </tokens>
        </chunking>
        <chunking id="4" string="the suspect 's injuries" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="suspect" />
            <token id="11" string="'s" />
            <token id="12" string="injuries" />
          </tokens>
        </chunking>
        <chunking id="5" string="struggled against being handcuffed" type="VP">
          <tokens>
            <token id="31" string="struggled" />
            <token id="32" string="against" />
            <token id="33" string="being" />
            <token id="34" string="handcuffed" />
          </tokens>
        </chunking>
        <chunking id="6" string="The offending officer 's" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="offending" />
            <token id="3" string="officer" />
            <token id="4" string="'s" />
          </tokens>
        </chunking>
        <chunking id="7" string="although he had also struggled against being handcuffed" type="SBAR">
          <tokens>
            <token id="27" string="although" />
            <token id="28" string="he" />
            <token id="29" string="had" />
            <token id="30" string="also" />
            <token id="31" string="struggled" />
            <token id="32" string="against" />
            <token id="33" string="being" />
            <token id="34" string="handcuffed" />
          </tokens>
        </chunking>
        <chunking id="8" string="that the suspect 's injuries were due to a fall from his bike and that he appeared unconscious , although he had also struggled against being handcuffed" type="SBAR">
          <tokens>
            <token id="8" string="that" />
            <token id="9" string="the" />
            <token id="10" string="suspect" />
            <token id="11" string="'s" />
            <token id="12" string="injuries" />
            <token id="13" string="were" />
            <token id="14" string="due" />
            <token id="15" string="to" />
            <token id="16" string="a" />
            <token id="17" string="fall" />
            <token id="18" string="from" />
            <token id="19" string="his" />
            <token id="20" string="bike" />
            <token id="21" string="and" />
            <token id="22" string="that" />
            <token id="23" string="he" />
            <token id="24" string="appeared" />
            <token id="25" string="unconscious" />
            <token id="26" string="," />
            <token id="27" string="although" />
            <token id="28" string="he" />
            <token id="29" string="had" />
            <token id="30" string="also" />
            <token id="31" string="struggled" />
            <token id="32" string="against" />
            <token id="33" string="being" />
            <token id="34" string="handcuffed" />
          </tokens>
        </chunking>
        <chunking id="9" string="had also struggled against being handcuffed" type="VP">
          <tokens>
            <token id="29" string="had" />
            <token id="30" string="also" />
            <token id="31" string="struggled" />
            <token id="32" string="against" />
            <token id="33" string="being" />
            <token id="34" string="handcuffed" />
          </tokens>
        </chunking>
        <chunking id="10" string="were due to a fall from his bike" type="VP">
          <tokens>
            <token id="13" string="were" />
            <token id="14" string="due" />
            <token id="15" string="to" />
            <token id="16" string="a" />
            <token id="17" string="fall" />
            <token id="18" string="from" />
            <token id="19" string="his" />
            <token id="20" string="bike" />
          </tokens>
        </chunking>
        <chunking id="11" string="a fall from his bike" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="fall" />
            <token id="18" string="from" />
            <token id="19" string="his" />
            <token id="20" string="bike" />
          </tokens>
        </chunking>
        <chunking id="12" string="the suspect 's" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="suspect" />
            <token id="11" string="'s" />
          </tokens>
        </chunking>
        <chunking id="13" string="that he appeared unconscious , although he had also struggled against being handcuffed" type="SBAR">
          <tokens>
            <token id="22" string="that" />
            <token id="23" string="he" />
            <token id="24" string="appeared" />
            <token id="25" string="unconscious" />
            <token id="26" string="," />
            <token id="27" string="although" />
            <token id="28" string="he" />
            <token id="29" string="had" />
            <token id="30" string="also" />
            <token id="31" string="struggled" />
            <token id="32" string="against" />
            <token id="33" string="being" />
            <token id="34" string="handcuffed" />
          </tokens>
        </chunking>
        <chunking id="14" string="due to a fall from his bike" type="ADJP">
          <tokens>
            <token id="14" string="due" />
            <token id="15" string="to" />
            <token id="16" string="a" />
            <token id="17" string="fall" />
            <token id="18" string="from" />
            <token id="19" string="his" />
            <token id="20" string="bike" />
          </tokens>
        </chunking>
        <chunking id="15" string="indicated that the suspect 's injuries were due to a fall from his bike and that he appeared unconscious , although he had also struggled against being handcuffed" type="VP">
          <tokens>
            <token id="7" string="indicated" />
            <token id="8" string="that" />
            <token id="9" string="the" />
            <token id="10" string="suspect" />
            <token id="11" string="'s" />
            <token id="12" string="injuries" />
            <token id="13" string="were" />
            <token id="14" string="due" />
            <token id="15" string="to" />
            <token id="16" string="a" />
            <token id="17" string="fall" />
            <token id="18" string="from" />
            <token id="19" string="his" />
            <token id="20" string="bike" />
            <token id="21" string="and" />
            <token id="22" string="that" />
            <token id="23" string="he" />
            <token id="24" string="appeared" />
            <token id="25" string="unconscious" />
            <token id="26" string="," />
            <token id="27" string="although" />
            <token id="28" string="he" />
            <token id="29" string="had" />
            <token id="30" string="also" />
            <token id="31" string="struggled" />
            <token id="32" string="against" />
            <token id="33" string="being" />
            <token id="34" string="handcuffed" />
          </tokens>
        </chunking>
        <chunking id="16" string="his bike" type="NP">
          <tokens>
            <token id="19" string="his" />
            <token id="20" string="bike" />
          </tokens>
        </chunking>
        <chunking id="17" string="The offending officer 's police report" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="offending" />
            <token id="3" string="officer" />
            <token id="4" string="'s" />
            <token id="5" string="police" />
            <token id="6" string="report" />
          </tokens>
        </chunking>
        <chunking id="18" string="handcuffed" type="ADJP">
          <tokens>
            <token id="34" string="handcuffed" />
          </tokens>
        </chunking>
        <chunking id="19" string="that the suspect 's injuries were due to a fall from his bike" type="SBAR">
          <tokens>
            <token id="8" string="that" />
            <token id="9" string="the" />
            <token id="10" string="suspect" />
            <token id="11" string="'s" />
            <token id="12" string="injuries" />
            <token id="13" string="were" />
            <token id="14" string="due" />
            <token id="15" string="to" />
            <token id="16" string="a" />
            <token id="17" string="fall" />
            <token id="18" string="from" />
            <token id="19" string="his" />
            <token id="20" string="bike" />
          </tokens>
        </chunking>
        <chunking id="20" string="he" type="NP">
          <tokens>
            <token id="23" string="he" />
          </tokens>
        </chunking>
        <chunking id="21" string="appeared unconscious , although he had also struggled against being handcuffed" type="VP">
          <tokens>
            <token id="24" string="appeared" />
            <token id="25" string="unconscious" />
            <token id="26" string="," />
            <token id="27" string="although" />
            <token id="28" string="he" />
            <token id="29" string="had" />
            <token id="30" string="also" />
            <token id="31" string="struggled" />
            <token id="32" string="against" />
            <token id="33" string="being" />
            <token id="34" string="handcuffed" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">officer</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">officer</governor>
          <dependent id="2">offending</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="6">report</governor>
          <dependent id="3">officer</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">officer</governor>
          <dependent id="4">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">report</governor>
          <dependent id="5">police</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">indicated</governor>
          <dependent id="6">report</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">indicated</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">due</governor>
          <dependent id="8">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">suspect</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="12">injuries</governor>
          <dependent id="10">suspect</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">suspect</governor>
          <dependent id="11">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">due</governor>
          <dependent id="12">injuries</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="14">due</governor>
          <dependent id="13">were</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">indicated</governor>
          <dependent id="14">due</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">fall</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">fall</governor>
          <dependent id="16">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">due</governor>
          <dependent id="17">fall</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">bike</governor>
          <dependent id="18">from</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="20">bike</governor>
          <dependent id="19">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">fall</governor>
          <dependent id="20">bike</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="14">due</governor>
          <dependent id="21">and</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="24">appeared</governor>
          <dependent id="22">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">appeared</governor>
          <dependent id="23">he</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">due</governor>
          <dependent id="24">appeared</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="24">appeared</governor>
          <dependent id="25">unconscious</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="31">struggled</governor>
          <dependent id="27">although</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="31">struggled</governor>
          <dependent id="28">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="31">struggled</governor>
          <dependent id="29">had</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="31">struggled</governor>
          <dependent id="30">also</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="24">appeared</governor>
          <dependent id="31">struggled</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="34">handcuffed</governor>
          <dependent id="32">against</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="34">handcuffed</governor>
          <dependent id="33">being</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="31">struggled</governor>
          <dependent id="34">handcuffed</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="fall" type="DATE" score="0.0">
          <tokens>
            <token id="17" string="fall" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>There is no mention of police brutality.</content>
      <tokens>
        <token id="1" string="There" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="mention" lemma="mention" stem="mention" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="brutality" lemma="brutality" stem="brutal" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (EX There)) (VP (VBZ is) (NP (NP (DT no) (NN mention)) (PP (IN of) (NP (NN police) (NN brutality))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="There" type="NP">
          <tokens>
            <token id="1" string="There" />
          </tokens>
        </chunking>
        <chunking id="2" string="police brutality" type="NP">
          <tokens>
            <token id="6" string="police" />
            <token id="7" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="3" string="is no mention of police brutality" type="VP">
          <tokens>
            <token id="2" string="is" />
            <token id="3" string="no" />
            <token id="4" string="mention" />
            <token id="5" string="of" />
            <token id="6" string="police" />
            <token id="7" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="4" string="no mention of police brutality" type="NP">
          <tokens>
            <token id="3" string="no" />
            <token id="4" string="mention" />
            <token id="5" string="of" />
            <token id="6" string="police" />
            <token id="7" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="5" string="no mention" type="NP">
          <tokens>
            <token id="3" string="no" />
            <token id="4" string="mention" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="expl">
          <governor id="2">is</governor>
          <dependent id="1">There</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">is</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="4">mention</governor>
          <dependent id="3">no</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="2">is</governor>
          <dependent id="4">mention</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">brutality</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">brutality</governor>
          <dependent id="6">police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">mention</governor>
          <dependent id="7">brutality</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>None of the back-up officers reported any brutality.</content>
      <tokens>
        <token id="1" string="None" lemma="none" stem="none" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="back-up" lemma="back-up" stem="back-up" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="reported" lemma="report" stem="report" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="any" lemma="any" stem="ani" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="brutality" lemma="brutality" stem="brutal" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NN None)) (PP (IN of) (NP (DT the) (NX (JJ back-up) (NNS officers))))) (VP (VBD reported) (NP (DT any) (NN brutality))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the back-up officers" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="back-up" />
            <token id="5" string="officers" />
          </tokens>
        </chunking>
        <chunking id="2" string="any brutality" type="NP">
          <tokens>
            <token id="7" string="any" />
            <token id="8" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="3" string="None" type="NP">
          <tokens>
            <token id="1" string="None" />
          </tokens>
        </chunking>
        <chunking id="4" string="None of the back-up officers" type="NP">
          <tokens>
            <token id="1" string="None" />
            <token id="2" string="of" />
            <token id="3" string="the" />
            <token id="4" string="back-up" />
            <token id="5" string="officers" />
          </tokens>
        </chunking>
        <chunking id="5" string="reported any brutality" type="VP">
          <tokens>
            <token id="6" string="reported" />
            <token id="7" string="any" />
            <token id="8" string="brutality" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="6">reported</governor>
          <dependent id="1">None</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">officers</governor>
          <dependent id="2">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">officers</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">officers</governor>
          <dependent id="4">back-up</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">None</governor>
          <dependent id="5">officers</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">reported</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">brutality</governor>
          <dependent id="7">any</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">reported</governor>
          <dependent id="8">brutality</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>One sergeant reported that the suspect kept trying to move around and had to be told to remain lying down.</content>
      <tokens>
        <token id="1" string="One" lemma="one" stem="one" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="2" string="sergeant" lemma="sergeant" stem="sergeant" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="reported" lemma="report" stem="report" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="suspect" lemma="suspect" stem="suspect" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="kept" lemma="keep" stem="kept" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="trying" lemma="try" stem="try" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="move" lemma="move" stem="move" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="around" lemma="around" stem="around" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="told" lemma="tell" stem="told" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="remain" lemma="remain" stem="remain" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="lying" lemma="lie" stem="ly" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="down" lemma="down" stem="down" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (CD One) (NN sergeant)) (VP (VBD reported) (SBAR (IN that) (S (NP (DT the) (ADJP (JJ suspect))) (VP (VP (VBD kept) (S (VP (VBG trying) (S (VP (TO to) (VP (VB move) (ADVP (RB around)))))))) (CC and) (VP (VBD had) (S (VP (TO to) (VP (VB be) (VP (VBN told) (S (VP (TO to) (VP (VB remain) (S (VP (VBG lying) (ADVP (RB down)))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="kept trying to move around and had to be told to remain lying down" type="VP">
          <tokens>
            <token id="7" string="kept" />
            <token id="8" string="trying" />
            <token id="9" string="to" />
            <token id="10" string="move" />
            <token id="11" string="around" />
            <token id="12" string="and" />
            <token id="13" string="had" />
            <token id="14" string="to" />
            <token id="15" string="be" />
            <token id="16" string="told" />
            <token id="17" string="to" />
            <token id="18" string="remain" />
            <token id="19" string="lying" />
            <token id="20" string="down" />
          </tokens>
        </chunking>
        <chunking id="2" string="remain lying down" type="VP">
          <tokens>
            <token id="18" string="remain" />
            <token id="19" string="lying" />
            <token id="20" string="down" />
          </tokens>
        </chunking>
        <chunking id="3" string="told to remain lying down" type="VP">
          <tokens>
            <token id="16" string="told" />
            <token id="17" string="to" />
            <token id="18" string="remain" />
            <token id="19" string="lying" />
            <token id="20" string="down" />
          </tokens>
        </chunking>
        <chunking id="4" string="suspect" type="ADJP">
          <tokens>
            <token id="6" string="suspect" />
          </tokens>
        </chunking>
        <chunking id="5" string="had to be told to remain lying down" type="VP">
          <tokens>
            <token id="13" string="had" />
            <token id="14" string="to" />
            <token id="15" string="be" />
            <token id="16" string="told" />
            <token id="17" string="to" />
            <token id="18" string="remain" />
            <token id="19" string="lying" />
            <token id="20" string="down" />
          </tokens>
        </chunking>
        <chunking id="6" string="reported that the suspect kept trying to move around and had to be told to remain lying down" type="VP">
          <tokens>
            <token id="3" string="reported" />
            <token id="4" string="that" />
            <token id="5" string="the" />
            <token id="6" string="suspect" />
            <token id="7" string="kept" />
            <token id="8" string="trying" />
            <token id="9" string="to" />
            <token id="10" string="move" />
            <token id="11" string="around" />
            <token id="12" string="and" />
            <token id="13" string="had" />
            <token id="14" string="to" />
            <token id="15" string="be" />
            <token id="16" string="told" />
            <token id="17" string="to" />
            <token id="18" string="remain" />
            <token id="19" string="lying" />
            <token id="20" string="down" />
          </tokens>
        </chunking>
        <chunking id="7" string="kept trying to move around" type="VP">
          <tokens>
            <token id="7" string="kept" />
            <token id="8" string="trying" />
            <token id="9" string="to" />
            <token id="10" string="move" />
            <token id="11" string="around" />
          </tokens>
        </chunking>
        <chunking id="8" string="to remain lying down" type="VP">
          <tokens>
            <token id="17" string="to" />
            <token id="18" string="remain" />
            <token id="19" string="lying" />
            <token id="20" string="down" />
          </tokens>
        </chunking>
        <chunking id="9" string="trying to move around" type="VP">
          <tokens>
            <token id="8" string="trying" />
            <token id="9" string="to" />
            <token id="10" string="move" />
            <token id="11" string="around" />
          </tokens>
        </chunking>
        <chunking id="10" string="to move around" type="VP">
          <tokens>
            <token id="9" string="to" />
            <token id="10" string="move" />
            <token id="11" string="around" />
          </tokens>
        </chunking>
        <chunking id="11" string="move around" type="VP">
          <tokens>
            <token id="10" string="move" />
            <token id="11" string="around" />
          </tokens>
        </chunking>
        <chunking id="12" string="One sergeant" type="NP">
          <tokens>
            <token id="1" string="One" />
            <token id="2" string="sergeant" />
          </tokens>
        </chunking>
        <chunking id="13" string="to be told to remain lying down" type="VP">
          <tokens>
            <token id="14" string="to" />
            <token id="15" string="be" />
            <token id="16" string="told" />
            <token id="17" string="to" />
            <token id="18" string="remain" />
            <token id="19" string="lying" />
            <token id="20" string="down" />
          </tokens>
        </chunking>
        <chunking id="14" string="be told to remain lying down" type="VP">
          <tokens>
            <token id="15" string="be" />
            <token id="16" string="told" />
            <token id="17" string="to" />
            <token id="18" string="remain" />
            <token id="19" string="lying" />
            <token id="20" string="down" />
          </tokens>
        </chunking>
        <chunking id="15" string="lying down" type="VP">
          <tokens>
            <token id="19" string="lying" />
            <token id="20" string="down" />
          </tokens>
        </chunking>
        <chunking id="16" string="that the suspect kept trying to move around and had to be told to remain lying down" type="SBAR">
          <tokens>
            <token id="4" string="that" />
            <token id="5" string="the" />
            <token id="6" string="suspect" />
            <token id="7" string="kept" />
            <token id="8" string="trying" />
            <token id="9" string="to" />
            <token id="10" string="move" />
            <token id="11" string="around" />
            <token id="12" string="and" />
            <token id="13" string="had" />
            <token id="14" string="to" />
            <token id="15" string="be" />
            <token id="16" string="told" />
            <token id="17" string="to" />
            <token id="18" string="remain" />
            <token id="19" string="lying" />
            <token id="20" string="down" />
          </tokens>
        </chunking>
        <chunking id="17" string="the suspect" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="suspect" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nummod">
          <governor id="2">sergeant</governor>
          <dependent id="1">One</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">reported</governor>
          <dependent id="2">sergeant</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">reported</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">kept</governor>
          <dependent id="4">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">suspect</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">kept</governor>
          <dependent id="6">suspect</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">reported</governor>
          <dependent id="7">kept</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="7">kept</governor>
          <dependent id="8">trying</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">move</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="8">trying</governor>
          <dependent id="10">move</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">move</governor>
          <dependent id="11">around</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">kept</governor>
          <dependent id="12">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">kept</governor>
          <dependent id="13">had</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">told</governor>
          <dependent id="14">to</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="16">told</governor>
          <dependent id="15">be</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="13">had</governor>
          <dependent id="16">told</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">remain</governor>
          <dependent id="17">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="16">told</governor>
          <dependent id="18">remain</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="18">remain</governor>
          <dependent id="19">lying</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="19">lying</governor>
          <dependent id="20">down</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="One" type="NUMBER" score="0.0">
          <tokens>
            <token id="1" string="One" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>Another officer reported that the only verbal abuse was by the suspect toward officers.</content>
      <tokens>
        <token id="1" string="Another" lemma="another" stem="another" pos="DT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="officer" lemma="officer" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="reported" lemma="report" stem="report" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="only" lemma="only" stem="onli" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="verbal" lemma="verbal" stem="verbal" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="abuse" lemma="abuse" stem="abus" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="suspect" lemma="suspect" stem="suspect" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="toward" lemma="toward" stem="toward" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT Another) (NN officer)) (VP (VBD reported) (SBAR (IN that) (S (NP (DT the) (JJ only) (JJ verbal) (NN abuse)) (VP (VBD was) (PP (IN by) (NP (NP (DT the) (NN suspect)) (PP (IN toward) (NP (NNS officers))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="reported that the only verbal abuse was by the suspect toward officers" type="VP">
          <tokens>
            <token id="3" string="reported" />
            <token id="4" string="that" />
            <token id="5" string="the" />
            <token id="6" string="only" />
            <token id="7" string="verbal" />
            <token id="8" string="abuse" />
            <token id="9" string="was" />
            <token id="10" string="by" />
            <token id="11" string="the" />
            <token id="12" string="suspect" />
            <token id="13" string="toward" />
            <token id="14" string="officers" />
          </tokens>
        </chunking>
        <chunking id="2" string="the only verbal abuse" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="only" />
            <token id="7" string="verbal" />
            <token id="8" string="abuse" />
          </tokens>
        </chunking>
        <chunking id="3" string="the suspect toward officers" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="suspect" />
            <token id="13" string="toward" />
            <token id="14" string="officers" />
          </tokens>
        </chunking>
        <chunking id="4" string="was by the suspect toward officers" type="VP">
          <tokens>
            <token id="9" string="was" />
            <token id="10" string="by" />
            <token id="11" string="the" />
            <token id="12" string="suspect" />
            <token id="13" string="toward" />
            <token id="14" string="officers" />
          </tokens>
        </chunking>
        <chunking id="5" string="that the only verbal abuse was by the suspect toward officers" type="SBAR">
          <tokens>
            <token id="4" string="that" />
            <token id="5" string="the" />
            <token id="6" string="only" />
            <token id="7" string="verbal" />
            <token id="8" string="abuse" />
            <token id="9" string="was" />
            <token id="10" string="by" />
            <token id="11" string="the" />
            <token id="12" string="suspect" />
            <token id="13" string="toward" />
            <token id="14" string="officers" />
          </tokens>
        </chunking>
        <chunking id="6" string="Another officer" type="NP">
          <tokens>
            <token id="1" string="Another" />
            <token id="2" string="officer" />
          </tokens>
        </chunking>
        <chunking id="7" string="officers" type="NP">
          <tokens>
            <token id="14" string="officers" />
          </tokens>
        </chunking>
        <chunking id="8" string="the suspect" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="suspect" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">officer</governor>
          <dependent id="1">Another</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">reported</governor>
          <dependent id="2">officer</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">reported</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">suspect</governor>
          <dependent id="4">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">abuse</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">abuse</governor>
          <dependent id="6">only</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">abuse</governor>
          <dependent id="7">verbal</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">suspect</governor>
          <dependent id="8">abuse</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="12">suspect</governor>
          <dependent id="9">was</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">suspect</governor>
          <dependent id="10">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">suspect</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">reported</governor>
          <dependent id="12">suspect</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">officers</governor>
          <dependent id="13">toward</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">suspect</governor>
          <dependent id="14">officers</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>The suspect subsequently complained of brutality.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="suspect" lemma="suspect" stem="suspect" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="subsequently" lemma="subsequently" stem="subsequ" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="complained" lemma="complain" stem="complain" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="brutality" lemma="brutality" stem="brutal" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (ADJP (JJ suspect))) (ADVP (RB subsequently)) (VP (VBD complained) (PP (IN of) (NP (NN brutality)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="The suspect" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="suspect" />
          </tokens>
        </chunking>
        <chunking id="2" string="suspect" type="ADJP">
          <tokens>
            <token id="2" string="suspect" />
          </tokens>
        </chunking>
        <chunking id="3" string="complained of brutality" type="VP">
          <tokens>
            <token id="4" string="complained" />
            <token id="5" string="of" />
            <token id="6" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="4" string="brutality" type="NP">
          <tokens>
            <token id="6" string="brutality" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">suspect</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">complained</governor>
          <dependent id="2">suspect</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">complained</governor>
          <dependent id="3">subsequently</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">complained</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">brutality</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">complained</governor>
          <dependent id="6">brutality</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="12" has_coreference="false">
      <content>The internal affairs department determined that the complaint was unsubstantiated and the matter was dropped.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="internal" lemma="internal" stem="intern" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="affairs" lemma="affair" stem="affair" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="department" lemma="department" stem="depart" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="determined" lemma="determine" stem="determin" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="complaint" lemma="complaint" stem="complaint" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="unsubstantiated" lemma="unsubstantiated" stem="unsubstanti" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="matter" lemma="matter" stem="matter" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="dropped" lemma="drop" stem="drop" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (DT The) (JJ internal) (NNS affairs) (NN department)) (VP (VBD determined) (SBAR (IN that) (S (NP (DT the) (NN complaint)) (VP (VBD was) (ADJP (JJ unsubstantiated))))))) (CC and) (S (NP (DT the) (NN matter)) (VP (VBD was) (VP (VBN dropped)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="was dropped" type="VP">
          <tokens>
            <token id="14" string="was" />
            <token id="15" string="dropped" />
          </tokens>
        </chunking>
        <chunking id="2" string="The internal affairs department" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="internal" />
            <token id="3" string="affairs" />
            <token id="4" string="department" />
          </tokens>
        </chunking>
        <chunking id="3" string="that the complaint was unsubstantiated" type="SBAR">
          <tokens>
            <token id="6" string="that" />
            <token id="7" string="the" />
            <token id="8" string="complaint" />
            <token id="9" string="was" />
            <token id="10" string="unsubstantiated" />
          </tokens>
        </chunking>
        <chunking id="4" string="dropped" type="VP">
          <tokens>
            <token id="15" string="dropped" />
          </tokens>
        </chunking>
        <chunking id="5" string="the complaint" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="complaint" />
          </tokens>
        </chunking>
        <chunking id="6" string="was unsubstantiated" type="VP">
          <tokens>
            <token id="9" string="was" />
            <token id="10" string="unsubstantiated" />
          </tokens>
        </chunking>
        <chunking id="7" string="determined that the complaint was unsubstantiated" type="VP">
          <tokens>
            <token id="5" string="determined" />
            <token id="6" string="that" />
            <token id="7" string="the" />
            <token id="8" string="complaint" />
            <token id="9" string="was" />
            <token id="10" string="unsubstantiated" />
          </tokens>
        </chunking>
        <chunking id="8" string="unsubstantiated" type="ADJP">
          <tokens>
            <token id="10" string="unsubstantiated" />
          </tokens>
        </chunking>
        <chunking id="9" string="the matter" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="matter" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="4">department</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">department</governor>
          <dependent id="2">internal</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">department</governor>
          <dependent id="3">affairs</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">determined</governor>
          <dependent id="4">department</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">determined</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">unsubstantiated</governor>
          <dependent id="6">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">complaint</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">unsubstantiated</governor>
          <dependent id="8">complaint</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="10">unsubstantiated</governor>
          <dependent id="9">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">determined</governor>
          <dependent id="10">unsubstantiated</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">determined</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">matter</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="15">dropped</governor>
          <dependent id="13">matter</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="15">dropped</governor>
          <dependent id="14">was</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">determined</governor>
          <dependent id="15">dropped</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>But four citizens called to complain that they had witnessed the arrest and that the suspect not only was not struggling but also had been brutally beaten.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="four" lemma="four" stem="four" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="3" string="citizens" lemma="citizen" stem="citizen" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="called" lemma="call" stem="call" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="complain" lemma="complain" stem="complain" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="witnessed" lemma="witness" stem="wit" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="arrest" lemma="arrest" stem="arrest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="suspect" lemma="suspect" stem="suspect" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="only" lemma="only" stem="onli" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="struggling" lemma="struggle" stem="struggl" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="brutally" lemma="brutally" stem="brutal" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="beaten" lemma="beat" stem="beaten" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (CD four) (NNS citizens)) (VP (VBN called) (S (VP (TO to) (VP (VB complain) (SBAR (SBAR (IN that) (S (NP (PRP they)) (VP (VBD had) (VP (VBN witnessed) (NP (DT the) (NN arrest)))))) (CC and) (SBAR (IN that) (S (NP (DT the) (NN suspect)) (VP (CONJP (RB not) (RB only)) (VP (VBD was) (RB not) (VP (VBG struggling))) (CC but) (VP (ADVP (RB also)) (VBD had) (VP (VBN been) (VP (ADVP (RB brutally)) (VBN beaten)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="also had been brutally beaten" type="VP">
          <tokens>
            <token id="23" string="also" />
            <token id="24" string="had" />
            <token id="25" string="been" />
            <token id="26" string="brutally" />
            <token id="27" string="beaten" />
          </tokens>
        </chunking>
        <chunking id="2" string="been brutally beaten" type="VP">
          <tokens>
            <token id="25" string="been" />
            <token id="26" string="brutally" />
            <token id="27" string="beaten" />
          </tokens>
        </chunking>
        <chunking id="3" string="brutally beaten" type="VP">
          <tokens>
            <token id="26" string="brutally" />
            <token id="27" string="beaten" />
          </tokens>
        </chunking>
        <chunking id="4" string="the arrest" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="5" string="not only was not struggling but also had been brutally beaten" type="VP">
          <tokens>
            <token id="17" string="not" />
            <token id="18" string="only" />
            <token id="19" string="was" />
            <token id="20" string="not" />
            <token id="21" string="struggling" />
            <token id="22" string="but" />
            <token id="23" string="also" />
            <token id="24" string="had" />
            <token id="25" string="been" />
            <token id="26" string="brutally" />
            <token id="27" string="beaten" />
          </tokens>
        </chunking>
        <chunking id="6" string="had witnessed the arrest" type="VP">
          <tokens>
            <token id="9" string="had" />
            <token id="10" string="witnessed" />
            <token id="11" string="the" />
            <token id="12" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="7" string="complain that they had witnessed the arrest and that the suspect not only was not struggling but also had been brutally beaten" type="VP">
          <tokens>
            <token id="6" string="complain" />
            <token id="7" string="that" />
            <token id="8" string="they" />
            <token id="9" string="had" />
            <token id="10" string="witnessed" />
            <token id="11" string="the" />
            <token id="12" string="arrest" />
            <token id="13" string="and" />
            <token id="14" string="that" />
            <token id="15" string="the" />
            <token id="16" string="suspect" />
            <token id="17" string="not" />
            <token id="18" string="only" />
            <token id="19" string="was" />
            <token id="20" string="not" />
            <token id="21" string="struggling" />
            <token id="22" string="but" />
            <token id="23" string="also" />
            <token id="24" string="had" />
            <token id="25" string="been" />
            <token id="26" string="brutally" />
            <token id="27" string="beaten" />
          </tokens>
        </chunking>
        <chunking id="8" string="was not struggling" type="VP">
          <tokens>
            <token id="19" string="was" />
            <token id="20" string="not" />
            <token id="21" string="struggling" />
          </tokens>
        </chunking>
        <chunking id="9" string="witnessed the arrest" type="VP">
          <tokens>
            <token id="10" string="witnessed" />
            <token id="11" string="the" />
            <token id="12" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="10" string="that the suspect not only was not struggling but also had been brutally beaten" type="SBAR">
          <tokens>
            <token id="14" string="that" />
            <token id="15" string="the" />
            <token id="16" string="suspect" />
            <token id="17" string="not" />
            <token id="18" string="only" />
            <token id="19" string="was" />
            <token id="20" string="not" />
            <token id="21" string="struggling" />
            <token id="22" string="but" />
            <token id="23" string="also" />
            <token id="24" string="had" />
            <token id="25" string="been" />
            <token id="26" string="brutally" />
            <token id="27" string="beaten" />
          </tokens>
        </chunking>
        <chunking id="11" string="they" type="NP">
          <tokens>
            <token id="8" string="they" />
          </tokens>
        </chunking>
        <chunking id="12" string="that they had witnessed the arrest and that the suspect not only was not struggling but also had been brutally beaten" type="SBAR">
          <tokens>
            <token id="7" string="that" />
            <token id="8" string="they" />
            <token id="9" string="had" />
            <token id="10" string="witnessed" />
            <token id="11" string="the" />
            <token id="12" string="arrest" />
            <token id="13" string="and" />
            <token id="14" string="that" />
            <token id="15" string="the" />
            <token id="16" string="suspect" />
            <token id="17" string="not" />
            <token id="18" string="only" />
            <token id="19" string="was" />
            <token id="20" string="not" />
            <token id="21" string="struggling" />
            <token id="22" string="but" />
            <token id="23" string="also" />
            <token id="24" string="had" />
            <token id="25" string="been" />
            <token id="26" string="brutally" />
            <token id="27" string="beaten" />
          </tokens>
        </chunking>
        <chunking id="13" string="that they had witnessed the arrest" type="SBAR">
          <tokens>
            <token id="7" string="that" />
            <token id="8" string="they" />
            <token id="9" string="had" />
            <token id="10" string="witnessed" />
            <token id="11" string="the" />
            <token id="12" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="14" string="to complain that they had witnessed the arrest and that the suspect not only was not struggling but also had been brutally beaten" type="VP">
          <tokens>
            <token id="5" string="to" />
            <token id="6" string="complain" />
            <token id="7" string="that" />
            <token id="8" string="they" />
            <token id="9" string="had" />
            <token id="10" string="witnessed" />
            <token id="11" string="the" />
            <token id="12" string="arrest" />
            <token id="13" string="and" />
            <token id="14" string="that" />
            <token id="15" string="the" />
            <token id="16" string="suspect" />
            <token id="17" string="not" />
            <token id="18" string="only" />
            <token id="19" string="was" />
            <token id="20" string="not" />
            <token id="21" string="struggling" />
            <token id="22" string="but" />
            <token id="23" string="also" />
            <token id="24" string="had" />
            <token id="25" string="been" />
            <token id="26" string="brutally" />
            <token id="27" string="beaten" />
          </tokens>
        </chunking>
        <chunking id="15" string="called to complain that they had witnessed the arrest and that the suspect not only was not struggling but also had been brutally beaten" type="VP">
          <tokens>
            <token id="4" string="called" />
            <token id="5" string="to" />
            <token id="6" string="complain" />
            <token id="7" string="that" />
            <token id="8" string="they" />
            <token id="9" string="had" />
            <token id="10" string="witnessed" />
            <token id="11" string="the" />
            <token id="12" string="arrest" />
            <token id="13" string="and" />
            <token id="14" string="that" />
            <token id="15" string="the" />
            <token id="16" string="suspect" />
            <token id="17" string="not" />
            <token id="18" string="only" />
            <token id="19" string="was" />
            <token id="20" string="not" />
            <token id="21" string="struggling" />
            <token id="22" string="but" />
            <token id="23" string="also" />
            <token id="24" string="had" />
            <token id="25" string="been" />
            <token id="26" string="brutally" />
            <token id="27" string="beaten" />
          </tokens>
        </chunking>
        <chunking id="16" string="struggling" type="VP">
          <tokens>
            <token id="21" string="struggling" />
          </tokens>
        </chunking>
        <chunking id="17" string="four citizens" type="NP">
          <tokens>
            <token id="2" string="four" />
            <token id="3" string="citizens" />
          </tokens>
        </chunking>
        <chunking id="18" string="the suspect" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="suspect" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="4">called</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="3">citizens</governor>
          <dependent id="2">four</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">called</governor>
          <dependent id="3">citizens</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">called</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">complain</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">called</governor>
          <dependent id="6">complain</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">witnessed</governor>
          <dependent id="7">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">witnessed</governor>
          <dependent id="8">they</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="10">witnessed</governor>
          <dependent id="9">had</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">complain</governor>
          <dependent id="10">witnessed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">arrest</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">witnessed</governor>
          <dependent id="12">arrest</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">witnessed</governor>
          <dependent id="13">and</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="21">struggling</governor>
          <dependent id="14">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">suspect</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">struggling</governor>
          <dependent id="16">suspect</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="18">only</governor>
          <dependent id="17">not</dependent>
        </dependency>
        <dependency type="cc:preconj">
          <governor id="21">struggling</governor>
          <dependent id="18">only</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="21">struggling</governor>
          <dependent id="19">was</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="21">struggling</governor>
          <dependent id="20">not</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">witnessed</governor>
          <dependent id="21">struggling</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="21">struggling</governor>
          <dependent id="22">but</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="27">beaten</governor>
          <dependent id="23">also</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="27">beaten</governor>
          <dependent id="24">had</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="27">beaten</governor>
          <dependent id="25">been</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="27">beaten</governor>
          <dependent id="26">brutally</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="21">struggling</governor>
          <dependent id="27">beaten</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="four" type="NUMBER" score="0.0">
          <tokens>
            <token id="2" string="four" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>According to the witnesses, the officer taunted the suspect, knelt on the suspect&amp;apost;s stomach, beat him numerous times with his club and kicked him in his face.</content>
      <tokens>
        <token id="1" string="According" lemma="accord" stem="accord" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="witnesses" lemma="witness" stem="wit" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="officer" lemma="officer" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="taunted" lemma="taunt" stem="taunt" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="suspect" lemma="suspect" stem="suspect" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="knelt" lemma="knelt" stem="knelt" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="suspect" lemma="suspect" stem="suspect" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="stomach" lemma="stomach" stem="stomach" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="beat" lemma="beat" stem="beat" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="numerous" lemma="numerous" stem="numer" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="times" lemma="time" stem="time" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="club" lemma="club" stem="club" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="kicked" lemma="kick" stem="kick" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="29" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="31" string="face" lemma="face" stem="face" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (VBG According) (PP (TO to) (NP (DT the) (NNS witnesses)))) (, ,) (NP (DT the) (NN officer)) (VP (VBD taunted) (SBAR (S (NP (NP (DT the) (NN suspect)) (, ,) (NP (NP (NN knelt)) (PP (IN on) (NP (NP (DT the) (NN suspect) (POS 's)) (NN stomach)))) (, ,)) (VP (VP (VBD beat) (NP (PRP him)) (NP-TMP (JJ numerous) (NNS times)) (PP (IN with) (NP (PRP$ his) (NN club)))) (CC and) (VP (VBD kicked) (NP (PRP him)) (PP (IN in) (NP (PRP$ his) (NN face)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="taunted the suspect , knelt on the suspect 's stomach , beat him numerous times with his club and kicked him in his face" type="VP">
          <tokens>
            <token id="8" string="taunted" />
            <token id="9" string="the" />
            <token id="10" string="suspect" />
            <token id="11" string="," />
            <token id="12" string="knelt" />
            <token id="13" string="on" />
            <token id="14" string="the" />
            <token id="15" string="suspect" />
            <token id="16" string="'s" />
            <token id="17" string="stomach" />
            <token id="18" string="," />
            <token id="19" string="beat" />
            <token id="20" string="him" />
            <token id="21" string="numerous" />
            <token id="22" string="times" />
            <token id="23" string="with" />
            <token id="24" string="his" />
            <token id="25" string="club" />
            <token id="26" string="and" />
            <token id="27" string="kicked" />
            <token id="28" string="him" />
            <token id="29" string="in" />
            <token id="30" string="his" />
            <token id="31" string="face" />
          </tokens>
        </chunking>
        <chunking id="2" string="the suspect , knelt on the suspect 's stomach ," type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="suspect" />
            <token id="11" string="," />
            <token id="12" string="knelt" />
            <token id="13" string="on" />
            <token id="14" string="the" />
            <token id="15" string="suspect" />
            <token id="16" string="'s" />
            <token id="17" string="stomach" />
            <token id="18" string="," />
          </tokens>
        </chunking>
        <chunking id="3" string="knelt on the suspect 's stomach" type="NP">
          <tokens>
            <token id="12" string="knelt" />
            <token id="13" string="on" />
            <token id="14" string="the" />
            <token id="15" string="suspect" />
            <token id="16" string="'s" />
            <token id="17" string="stomach" />
          </tokens>
        </chunking>
        <chunking id="4" string="the officer" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="officer" />
          </tokens>
        </chunking>
        <chunking id="5" string="him" type="NP">
          <tokens>
            <token id="20" string="him" />
          </tokens>
        </chunking>
        <chunking id="6" string="the suspect 's" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="suspect" />
            <token id="16" string="'s" />
          </tokens>
        </chunking>
        <chunking id="7" string="his face" type="NP">
          <tokens>
            <token id="30" string="his" />
            <token id="31" string="face" />
          </tokens>
        </chunking>
        <chunking id="8" string="beat him numerous times with his club" type="VP">
          <tokens>
            <token id="19" string="beat" />
            <token id="20" string="him" />
            <token id="21" string="numerous" />
            <token id="22" string="times" />
            <token id="23" string="with" />
            <token id="24" string="his" />
            <token id="25" string="club" />
          </tokens>
        </chunking>
        <chunking id="9" string="his club" type="NP">
          <tokens>
            <token id="24" string="his" />
            <token id="25" string="club" />
          </tokens>
        </chunking>
        <chunking id="10" string="the suspect , knelt on the suspect 's stomach , beat him numerous times with his club and kicked him in his face" type="SBAR">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="suspect" />
            <token id="11" string="," />
            <token id="12" string="knelt" />
            <token id="13" string="on" />
            <token id="14" string="the" />
            <token id="15" string="suspect" />
            <token id="16" string="'s" />
            <token id="17" string="stomach" />
            <token id="18" string="," />
            <token id="19" string="beat" />
            <token id="20" string="him" />
            <token id="21" string="numerous" />
            <token id="22" string="times" />
            <token id="23" string="with" />
            <token id="24" string="his" />
            <token id="25" string="club" />
            <token id="26" string="and" />
            <token id="27" string="kicked" />
            <token id="28" string="him" />
            <token id="29" string="in" />
            <token id="30" string="his" />
            <token id="31" string="face" />
          </tokens>
        </chunking>
        <chunking id="11" string="kicked him in his face" type="VP">
          <tokens>
            <token id="27" string="kicked" />
            <token id="28" string="him" />
            <token id="29" string="in" />
            <token id="30" string="his" />
            <token id="31" string="face" />
          </tokens>
        </chunking>
        <chunking id="12" string="beat him numerous times with his club and kicked him in his face" type="VP">
          <tokens>
            <token id="19" string="beat" />
            <token id="20" string="him" />
            <token id="21" string="numerous" />
            <token id="22" string="times" />
            <token id="23" string="with" />
            <token id="24" string="his" />
            <token id="25" string="club" />
            <token id="26" string="and" />
            <token id="27" string="kicked" />
            <token id="28" string="him" />
            <token id="29" string="in" />
            <token id="30" string="his" />
            <token id="31" string="face" />
          </tokens>
        </chunking>
        <chunking id="13" string="the witnesses" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="witnesses" />
          </tokens>
        </chunking>
        <chunking id="14" string="knelt" type="NP">
          <tokens>
            <token id="12" string="knelt" />
          </tokens>
        </chunking>
        <chunking id="15" string="the suspect" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="suspect" />
          </tokens>
        </chunking>
        <chunking id="16" string="the suspect 's stomach" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="suspect" />
            <token id="16" string="'s" />
            <token id="17" string="stomach" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">witnesses</governor>
          <dependent id="1">According</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="1">According</governor>
          <dependent id="2">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">witnesses</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">taunted</governor>
          <dependent id="4">witnesses</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">officer</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">taunted</governor>
          <dependent id="7">officer</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">taunted</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">suspect</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">beat</governor>
          <dependent id="10">suspect</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="10">suspect</governor>
          <dependent id="12">knelt</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">stomach</governor>
          <dependent id="13">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">suspect</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="17">stomach</governor>
          <dependent id="15">suspect</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">suspect</governor>
          <dependent id="16">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">knelt</governor>
          <dependent id="17">stomach</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="8">taunted</governor>
          <dependent id="19">beat</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">beat</governor>
          <dependent id="20">him</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">times</governor>
          <dependent id="21">numerous</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="19">beat</governor>
          <dependent id="22">times</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">club</governor>
          <dependent id="23">with</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="25">club</governor>
          <dependent id="24">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">beat</governor>
          <dependent id="25">club</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="19">beat</governor>
          <dependent id="26">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="19">beat</governor>
          <dependent id="27">kicked</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="27">kicked</governor>
          <dependent id="28">him</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">face</governor>
          <dependent id="29">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="31">face</governor>
          <dependent id="30">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">kicked</governor>
          <dependent id="31">face</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="15" has_coreference="false">
      <content>The witnesses also said:; The suspect at no time resisted.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="witnesses" lemma="witness" stem="wit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="suspect" lemma="suspect" stem="suspect" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="resisted" lemma="resist" stem="resist" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (DT The) (NNS witnesses)) (ADVP (RB also)) (VP (VBD said))) (: :) (: ;) (S (NP (NP (DT The) (NN suspect)) (PP (IN at) (NP (DT no) (NN time)))) (VP (VBD resisted))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="The suspect" type="NP">
          <tokens>
            <token id="7" string="The" />
            <token id="8" string="suspect" />
          </tokens>
        </chunking>
        <chunking id="2" string="no time" type="NP">
          <tokens>
            <token id="10" string="no" />
            <token id="11" string="time" />
          </tokens>
        </chunking>
        <chunking id="3" string="The witnesses" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="witnesses" />
          </tokens>
        </chunking>
        <chunking id="4" string="said" type="VP">
          <tokens>
            <token id="4" string="said" />
          </tokens>
        </chunking>
        <chunking id="5" string="The suspect at no time" type="NP">
          <tokens>
            <token id="7" string="The" />
            <token id="8" string="suspect" />
            <token id="9" string="at" />
            <token id="10" string="no" />
            <token id="11" string="time" />
          </tokens>
        </chunking>
        <chunking id="6" string="resisted" type="VP">
          <tokens>
            <token id="12" string="resisted" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">witnesses</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">said</governor>
          <dependent id="2">witnesses</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">said</governor>
          <dependent id="3">also</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">said</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">suspect</governor>
          <dependent id="7">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">resisted</governor>
          <dependent id="8">suspect</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">time</governor>
          <dependent id="9">at</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="11">time</governor>
          <dependent id="10">no</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">suspect</governor>
          <dependent id="11">time</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="4">said</governor>
          <dependent id="12">resisted</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>The only words from the suspect were pleas for help.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="only" lemma="only" stem="onli" pos="JJ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="words" lemma="word" stem="word" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="6" string="suspect" lemma="suspect" stem="suspect" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="7" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="pleas" lemma="plea" stem="plea" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="help" lemma="help" stem="help" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (JJ only) (NNS words)) (PP (IN from) (NP (DT the) (NN suspect)))) (VP (VBD were) (NP (NP (NNS pleas)) (PP (IN for) (NP (NN help))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="help" type="NP">
          <tokens>
            <token id="10" string="help" />
          </tokens>
        </chunking>
        <chunking id="2" string="The only words from the suspect" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="only" />
            <token id="3" string="words" />
            <token id="4" string="from" />
            <token id="5" string="the" />
            <token id="6" string="suspect" />
          </tokens>
        </chunking>
        <chunking id="3" string="pleas" type="NP">
          <tokens>
            <token id="8" string="pleas" />
          </tokens>
        </chunking>
        <chunking id="4" string="The only words" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="only" />
            <token id="3" string="words" />
          </tokens>
        </chunking>
        <chunking id="5" string="were pleas for help" type="VP">
          <tokens>
            <token id="7" string="were" />
            <token id="8" string="pleas" />
            <token id="9" string="for" />
            <token id="10" string="help" />
          </tokens>
        </chunking>
        <chunking id="6" string="pleas for help" type="NP">
          <tokens>
            <token id="8" string="pleas" />
            <token id="9" string="for" />
            <token id="10" string="help" />
          </tokens>
        </chunking>
        <chunking id="7" string="the suspect" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="suspect" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">words</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">words</governor>
          <dependent id="2">only</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">pleas</governor>
          <dependent id="3">words</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">suspect</governor>
          <dependent id="4">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">suspect</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">words</governor>
          <dependent id="6">suspect</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="8">pleas</governor>
          <dependent id="7">were</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">pleas</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">help</governor>
          <dependent id="9">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">pleas</governor>
          <dependent id="10">help</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="17" has_coreference="true">
      <content>In response to another officer&amp;apost;s inquiry, the original officer picked up the suspect, let his head fall to the pavement and said, &amp;quot;It looks like he&amp;apost;s dead.&amp;quot;</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="response" lemma="response" stem="respons" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="another" lemma="another" stem="anoth" pos="DT" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="officer" lemma="officer" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="inquiry" lemma="inquiry" stem="inquiri" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="original" lemma="original" stem="origin" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="officer" lemma="officer" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="picked" lemma="pick" stem="pick" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="suspect" lemma="suspect" stem="suspect" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="let" lemma="let" stem="let" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="head" lemma="head" stem="head" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="fall" lemma="fall" stem="fall" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="21" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="pavement" lemma="pavement" stem="pavement" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="looks" lemma="look" stem="look" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="dead" lemma="dead" stem="dead" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (NP (NN response)) (PP (TO to) (NP (NP (DT another) (NN officer) (POS 's)) (NN inquiry))))) (PRN (, ,) (S (NP (DT the) (JJ original) (NN officer)) (VP (VP (VBD picked) (PRT (RP up)) (NP (DT the) (NN suspect))) (, ,) (VP (VB let) (NP (PRP$ his) (NN head) (NN fall)) (PP (TO to) (NP (DT the) (NN pavement)))) (CC and) (VP (VBD said)))) (, ,)) (`` ``) (NP (PRP It)) (VP (VBZ looks) (SBAR (IN like) (S (NP (PRP he)) (VP (VBZ 's) (ADJP (JJ dead)))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="the pavement" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="pavement" />
          </tokens>
        </chunking>
        <chunking id="2" string="picked up the suspect , let his head fall to the pavement and said" type="VP">
          <tokens>
            <token id="12" string="picked" />
            <token id="13" string="up" />
            <token id="14" string="the" />
            <token id="15" string="suspect" />
            <token id="16" string="," />
            <token id="17" string="let" />
            <token id="18" string="his" />
            <token id="19" string="head" />
            <token id="20" string="fall" />
            <token id="21" string="to" />
            <token id="22" string="the" />
            <token id="23" string="pavement" />
            <token id="24" string="and" />
            <token id="25" string="said" />
          </tokens>
        </chunking>
        <chunking id="3" string="It" type="NP">
          <tokens>
            <token id="28" string="It" />
          </tokens>
        </chunking>
        <chunking id="4" string="like he 's dead" type="SBAR">
          <tokens>
            <token id="30" string="like" />
            <token id="31" string="he" />
            <token id="32" string="'s" />
            <token id="33" string="dead" />
          </tokens>
        </chunking>
        <chunking id="5" string="dead" type="ADJP">
          <tokens>
            <token id="33" string="dead" />
          </tokens>
        </chunking>
        <chunking id="6" string="another officer 's" type="NP">
          <tokens>
            <token id="4" string="another" />
            <token id="5" string="officer" />
            <token id="6" string="'s" />
          </tokens>
        </chunking>
        <chunking id="7" string="the original officer" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="original" />
            <token id="11" string="officer" />
          </tokens>
        </chunking>
        <chunking id="8" string="picked up the suspect" type="VP">
          <tokens>
            <token id="12" string="picked" />
            <token id="13" string="up" />
            <token id="14" string="the" />
            <token id="15" string="suspect" />
          </tokens>
        </chunking>
        <chunking id="9" string="his head fall" type="NP">
          <tokens>
            <token id="18" string="his" />
            <token id="19" string="head" />
            <token id="20" string="fall" />
          </tokens>
        </chunking>
        <chunking id="10" string="'s dead" type="VP">
          <tokens>
            <token id="32" string="'s" />
            <token id="33" string="dead" />
          </tokens>
        </chunking>
        <chunking id="11" string="response to another officer 's inquiry" type="NP">
          <tokens>
            <token id="2" string="response" />
            <token id="3" string="to" />
            <token id="4" string="another" />
            <token id="5" string="officer" />
            <token id="6" string="'s" />
            <token id="7" string="inquiry" />
          </tokens>
        </chunking>
        <chunking id="12" string="response" type="NP">
          <tokens>
            <token id="2" string="response" />
          </tokens>
        </chunking>
        <chunking id="13" string="another officer 's inquiry" type="NP">
          <tokens>
            <token id="4" string="another" />
            <token id="5" string="officer" />
            <token id="6" string="'s" />
            <token id="7" string="inquiry" />
          </tokens>
        </chunking>
        <chunking id="14" string="let his head fall to the pavement" type="VP">
          <tokens>
            <token id="17" string="let" />
            <token id="18" string="his" />
            <token id="19" string="head" />
            <token id="20" string="fall" />
            <token id="21" string="to" />
            <token id="22" string="the" />
            <token id="23" string="pavement" />
          </tokens>
        </chunking>
        <chunking id="15" string="he" type="NP">
          <tokens>
            <token id="31" string="he" />
          </tokens>
        </chunking>
        <chunking id="16" string="said" type="VP">
          <tokens>
            <token id="25" string="said" />
          </tokens>
        </chunking>
        <chunking id="17" string="the suspect" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="suspect" />
          </tokens>
        </chunking>
        <chunking id="18" string="looks like he 's dead" type="VP">
          <tokens>
            <token id="29" string="looks" />
            <token id="30" string="like" />
            <token id="31" string="he" />
            <token id="32" string="'s" />
            <token id="33" string="dead" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">response</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">looks</governor>
          <dependent id="2">response</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">inquiry</governor>
          <dependent id="3">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">officer</governor>
          <dependent id="4">another</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="7">inquiry</governor>
          <dependent id="5">officer</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">officer</governor>
          <dependent id="6">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">response</governor>
          <dependent id="7">inquiry</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">officer</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">officer</governor>
          <dependent id="10">original</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">picked</governor>
          <dependent id="11">officer</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="29">looks</governor>
          <dependent id="12">picked</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="12">picked</governor>
          <dependent id="13">up</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">suspect</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">picked</governor>
          <dependent id="15">suspect</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">picked</governor>
          <dependent id="17">let</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="20">fall</governor>
          <dependent id="18">his</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">fall</governor>
          <dependent id="19">head</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="17">let</governor>
          <dependent id="20">fall</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">pavement</governor>
          <dependent id="21">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">pavement</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">let</governor>
          <dependent id="23">pavement</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="12">picked</governor>
          <dependent id="24">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">picked</governor>
          <dependent id="25">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">looks</governor>
          <dependent id="28">It</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="29">looks</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="33">dead</governor>
          <dependent id="30">like</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="33">dead</governor>
          <dependent id="31">he</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="33">dead</governor>
          <dependent id="32">'s</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="29">looks</governor>
          <dependent id="33">dead</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="fall" type="DATE" score="0.0">
          <tokens>
            <token id="20" string="fall" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="18" has_coreference="false">
      <content>Both officers smirked and laughed.</content>
      <tokens>
        <token id="1" string="Both" lemma="both" stem="both" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="smirked" lemma="smirk" stem="smirk" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="laughed" lemma="laugh" stem="laugh" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT Both) (NNS officers)) (VP (VP (VBD smirked)) (CC and) (VP (VBD laughed))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="laughed" type="VP">
          <tokens>
            <token id="5" string="laughed" />
          </tokens>
        </chunking>
        <chunking id="2" string="smirked and laughed" type="VP">
          <tokens>
            <token id="3" string="smirked" />
            <token id="4" string="and" />
            <token id="5" string="laughed" />
          </tokens>
        </chunking>
        <chunking id="3" string="Both officers" type="NP">
          <tokens>
            <token id="1" string="Both" />
            <token id="2" string="officers" />
          </tokens>
        </chunking>
        <chunking id="4" string="smirked" type="VP">
          <tokens>
            <token id="3" string="smirked" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">officers</governor>
          <dependent id="1">Both</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">smirked</governor>
          <dependent id="2">officers</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">smirked</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">smirked</governor>
          <dependent id="4">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">smirked</governor>
          <dependent id="5">laughed</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="19" has_coreference="true">
      <content>The offending officer was later arrested and prosecuted by the district attorney.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="offending" lemma="offend" stem="offend" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="officer" lemma="officer" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="later" lemma="later" stem="later" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="arrested" lemma="arrest" stem="arrest" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="prosecuted" lemma="prosecute" stem="prosecut" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="district" lemma="district" stem="district" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="attorney" lemma="attorney" stem="attornei" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (VBG offending) (NN officer)) (VP (VBD was) (ADVP (RB later)) (VP (VBN arrested) (CC and) (VBN prosecuted) (PP (IN by) (NP (DT the) (NN district) (NN attorney))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the district attorney" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="district" />
            <token id="12" string="attorney" />
          </tokens>
        </chunking>
        <chunking id="2" string="arrested and prosecuted by the district attorney" type="VP">
          <tokens>
            <token id="6" string="arrested" />
            <token id="7" string="and" />
            <token id="8" string="prosecuted" />
            <token id="9" string="by" />
            <token id="10" string="the" />
            <token id="11" string="district" />
            <token id="12" string="attorney" />
          </tokens>
        </chunking>
        <chunking id="3" string="was later arrested and prosecuted by the district attorney" type="VP">
          <tokens>
            <token id="4" string="was" />
            <token id="5" string="later" />
            <token id="6" string="arrested" />
            <token id="7" string="and" />
            <token id="8" string="prosecuted" />
            <token id="9" string="by" />
            <token id="10" string="the" />
            <token id="11" string="district" />
            <token id="12" string="attorney" />
          </tokens>
        </chunking>
        <chunking id="4" string="The offending officer" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="offending" />
            <token id="3" string="officer" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">officer</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">officer</governor>
          <dependent id="2">offending</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="6">arrested</governor>
          <dependent id="3">officer</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="6">arrested</governor>
          <dependent id="4">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">arrested</governor>
          <dependent id="5">later</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">arrested</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">arrested</governor>
          <dependent id="7">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">arrested</governor>
          <dependent id="8">prosecuted</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">attorney</governor>
          <dependent id="9">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">attorney</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">attorney</governor>
          <dependent id="11">district</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">arrested</governor>
          <dependent id="12">attorney</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="20" has_coreference="true">
      <content>What if there had not been four citizens who observed the brutal beating of my client?</content>
      <tokens>
        <token id="1" string="What" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="four" lemma="four" stem="four" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="true" />
        <token id="8" string="citizens" lemma="citizen" stem="citizen" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="observed" lemma="observe" stem="observ" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="brutal" lemma="brutal" stem="brutal" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="beating" lemma="beating" stem="beat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="my" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="client" lemma="client" stem="client" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SBAR (WP What) (IN if) (S (NP (EX there)) (VP (VBD had) (RB not) (VP (VBN been) (NP (NP (CD four) (NNS citizens)) (SBAR (WHNP (WP who)) (S (VP (VBD observed) (NP (NP (DT the) (JJ brutal) (NN beating)) (PP (IN of) (NP (PRP$ my) (NN client))))))))))) (. ?)))</syntactictree>
      <chunkings>
        <chunking id="1" string="there" type="NP">
          <tokens>
            <token id="3" string="there" />
          </tokens>
        </chunking>
        <chunking id="2" string="who observed the brutal beating of my client" type="SBAR">
          <tokens>
            <token id="9" string="who" />
            <token id="10" string="observed" />
            <token id="11" string="the" />
            <token id="12" string="brutal" />
            <token id="13" string="beating" />
            <token id="14" string="of" />
            <token id="15" string="my" />
            <token id="16" string="client" />
          </tokens>
        </chunking>
        <chunking id="3" string="observed the brutal beating of my client" type="VP">
          <tokens>
            <token id="10" string="observed" />
            <token id="11" string="the" />
            <token id="12" string="brutal" />
            <token id="13" string="beating" />
            <token id="14" string="of" />
            <token id="15" string="my" />
            <token id="16" string="client" />
          </tokens>
        </chunking>
        <chunking id="4" string="had not been four citizens who observed the brutal beating of my client" type="VP">
          <tokens>
            <token id="4" string="had" />
            <token id="5" string="not" />
            <token id="6" string="been" />
            <token id="7" string="four" />
            <token id="8" string="citizens" />
            <token id="9" string="who" />
            <token id="10" string="observed" />
            <token id="11" string="the" />
            <token id="12" string="brutal" />
            <token id="13" string="beating" />
            <token id="14" string="of" />
            <token id="15" string="my" />
            <token id="16" string="client" />
          </tokens>
        </chunking>
        <chunking id="5" string="my client" type="NP">
          <tokens>
            <token id="15" string="my" />
            <token id="16" string="client" />
          </tokens>
        </chunking>
        <chunking id="6" string="What if there had not been four citizens who observed the brutal beating of my client ?" type="SBAR">
          <tokens>
            <token id="1" string="What" />
            <token id="2" string="if" />
            <token id="3" string="there" />
            <token id="4" string="had" />
            <token id="5" string="not" />
            <token id="6" string="been" />
            <token id="7" string="four" />
            <token id="8" string="citizens" />
            <token id="9" string="who" />
            <token id="10" string="observed" />
            <token id="11" string="the" />
            <token id="12" string="brutal" />
            <token id="13" string="beating" />
            <token id="14" string="of" />
            <token id="15" string="my" />
            <token id="16" string="client" />
            <token id="17" string="?" />
          </tokens>
        </chunking>
        <chunking id="7" string="the brutal beating of my client" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="brutal" />
            <token id="13" string="beating" />
            <token id="14" string="of" />
            <token id="15" string="my" />
            <token id="16" string="client" />
          </tokens>
        </chunking>
        <chunking id="8" string="been four citizens who observed the brutal beating of my client" type="VP">
          <tokens>
            <token id="6" string="been" />
            <token id="7" string="four" />
            <token id="8" string="citizens" />
            <token id="9" string="who" />
            <token id="10" string="observed" />
            <token id="11" string="the" />
            <token id="12" string="brutal" />
            <token id="13" string="beating" />
            <token id="14" string="of" />
            <token id="15" string="my" />
            <token id="16" string="client" />
          </tokens>
        </chunking>
        <chunking id="9" string="four citizens" type="NP">
          <tokens>
            <token id="7" string="four" />
            <token id="8" string="citizens" />
          </tokens>
        </chunking>
        <chunking id="10" string="the brutal beating" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="brutal" />
            <token id="13" string="beating" />
          </tokens>
        </chunking>
        <chunking id="11" string="four citizens who observed the brutal beating of my client" type="NP">
          <tokens>
            <token id="7" string="four" />
            <token id="8" string="citizens" />
            <token id="9" string="who" />
            <token id="10" string="observed" />
            <token id="11" string="the" />
            <token id="12" string="brutal" />
            <token id="13" string="beating" />
            <token id="14" string="of" />
            <token id="15" string="my" />
            <token id="16" string="client" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="dep">
          <governor id="8">citizens</governor>
          <dependent id="1">What</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">citizens</governor>
          <dependent id="2">if</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="8">citizens</governor>
          <dependent id="3">there</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">citizens</governor>
          <dependent id="4">had</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="8">citizens</governor>
          <dependent id="5">not</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="8">citizens</governor>
          <dependent id="6">been</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="8">citizens</governor>
          <dependent id="7">four</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">citizens</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">observed</governor>
          <dependent id="9">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="8">citizens</governor>
          <dependent id="10">observed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">beating</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">beating</governor>
          <dependent id="12">brutal</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">observed</governor>
          <dependent id="13">beating</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">client</governor>
          <dependent id="14">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="16">client</governor>
          <dependent id="15">my</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">beating</governor>
          <dependent id="16">client</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="four" type="NUMBER" score="0.0">
          <tokens>
            <token id="7" string="four" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="21" has_coreference="false">
      <content>; One of the problems in monitoring police brutality is that almost all victims of police abuse have themselves committed some kind of law violation.</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="One" lemma="one" stem="one" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="problems" lemma="problem" stem="problem" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="monitoring" lemma="monitor" stem="monitor" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="brutality" lemma="brutality" stem="brutal" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="almost" lemma="almost" stem="almost" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="victims" lemma="victim" stem="victim" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="abuse" lemma="abuse" stem="abus" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="themselves" lemma="themselves" stem="themselv" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="committed" lemma="commit" stem="commit" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="kind" lemma="kind" stem="kind" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="law" lemma="law" stem="law" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="violation" lemma="violation" stem="violat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ;) (NP (NP (CD One)) (PP (IN of) (NP (NP (DT the) (NNS problems)) (PP (IN in) (NP (VBG monitoring) (NN police) (NN brutality)))))) (VP (VBZ is) (SBAR (IN that) (S (NP (NP (QP (RB almost) (DT all)) (NNS victims)) (PP (IN of) (NP (NN police) (NN abuse)))) (VP (VBP have) (NP (PRP themselves)) (VP (VBN committed) (NP (NP (DT some) (NN kind)) (PP (IN of) (NP (NN law) (NN violation))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="law violation" type="NP">
          <tokens>
            <token id="24" string="law" />
            <token id="25" string="violation" />
          </tokens>
        </chunking>
        <chunking id="2" string="the problems in monitoring police brutality" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="problems" />
            <token id="6" string="in" />
            <token id="7" string="monitoring" />
            <token id="8" string="police" />
            <token id="9" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="3" string="One" type="NP">
          <tokens>
            <token id="2" string="One" />
          </tokens>
        </chunking>
        <chunking id="4" string="some kind" type="NP">
          <tokens>
            <token id="21" string="some" />
            <token id="22" string="kind" />
          </tokens>
        </chunking>
        <chunking id="5" string="committed some kind of law violation" type="VP">
          <tokens>
            <token id="20" string="committed" />
            <token id="21" string="some" />
            <token id="22" string="kind" />
            <token id="23" string="of" />
            <token id="24" string="law" />
            <token id="25" string="violation" />
          </tokens>
        </chunking>
        <chunking id="6" string="that almost all victims of police abuse have themselves committed some kind of law violation" type="SBAR">
          <tokens>
            <token id="11" string="that" />
            <token id="12" string="almost" />
            <token id="13" string="all" />
            <token id="14" string="victims" />
            <token id="15" string="of" />
            <token id="16" string="police" />
            <token id="17" string="abuse" />
            <token id="18" string="have" />
            <token id="19" string="themselves" />
            <token id="20" string="committed" />
            <token id="21" string="some" />
            <token id="22" string="kind" />
            <token id="23" string="of" />
            <token id="24" string="law" />
            <token id="25" string="violation" />
          </tokens>
        </chunking>
        <chunking id="7" string="monitoring police brutality" type="NP">
          <tokens>
            <token id="7" string="monitoring" />
            <token id="8" string="police" />
            <token id="9" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="8" string="some kind of law violation" type="NP">
          <tokens>
            <token id="21" string="some" />
            <token id="22" string="kind" />
            <token id="23" string="of" />
            <token id="24" string="law" />
            <token id="25" string="violation" />
          </tokens>
        </chunking>
        <chunking id="9" string="themselves" type="NP">
          <tokens>
            <token id="19" string="themselves" />
          </tokens>
        </chunking>
        <chunking id="10" string="One of the problems in monitoring police brutality" type="NP">
          <tokens>
            <token id="2" string="One" />
            <token id="3" string="of" />
            <token id="4" string="the" />
            <token id="5" string="problems" />
            <token id="6" string="in" />
            <token id="7" string="monitoring" />
            <token id="8" string="police" />
            <token id="9" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="11" string="the problems" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="problems" />
          </tokens>
        </chunking>
        <chunking id="12" string="is that almost all victims of police abuse have themselves committed some kind of law violation" type="VP">
          <tokens>
            <token id="10" string="is" />
            <token id="11" string="that" />
            <token id="12" string="almost" />
            <token id="13" string="all" />
            <token id="14" string="victims" />
            <token id="15" string="of" />
            <token id="16" string="police" />
            <token id="17" string="abuse" />
            <token id="18" string="have" />
            <token id="19" string="themselves" />
            <token id="20" string="committed" />
            <token id="21" string="some" />
            <token id="22" string="kind" />
            <token id="23" string="of" />
            <token id="24" string="law" />
            <token id="25" string="violation" />
          </tokens>
        </chunking>
        <chunking id="13" string="almost all victims" type="NP">
          <tokens>
            <token id="12" string="almost" />
            <token id="13" string="all" />
            <token id="14" string="victims" />
          </tokens>
        </chunking>
        <chunking id="14" string="almost all victims of police abuse" type="NP">
          <tokens>
            <token id="12" string="almost" />
            <token id="13" string="all" />
            <token id="14" string="victims" />
            <token id="15" string="of" />
            <token id="16" string="police" />
            <token id="17" string="abuse" />
          </tokens>
        </chunking>
        <chunking id="15" string="police abuse" type="NP">
          <tokens>
            <token id="16" string="police" />
            <token id="17" string="abuse" />
          </tokens>
        </chunking>
        <chunking id="16" string="have themselves committed some kind of law violation" type="VP">
          <tokens>
            <token id="18" string="have" />
            <token id="19" string="themselves" />
            <token id="20" string="committed" />
            <token id="21" string="some" />
            <token id="22" string="kind" />
            <token id="23" string="of" />
            <token id="24" string="law" />
            <token id="25" string="violation" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="10">is</governor>
          <dependent id="2">One</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">problems</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">problems</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">One</governor>
          <dependent id="5">problems</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">brutality</governor>
          <dependent id="6">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">brutality</governor>
          <dependent id="7">monitoring</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">brutality</governor>
          <dependent id="8">police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">problems</governor>
          <dependent id="9">brutality</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">is</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="20">committed</governor>
          <dependent id="11">that</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">all</governor>
          <dependent id="12">almost</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="14">victims</governor>
          <dependent id="13">all</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">committed</governor>
          <dependent id="14">victims</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">abuse</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">abuse</governor>
          <dependent id="16">police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">victims</governor>
          <dependent id="17">abuse</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="20">committed</governor>
          <dependent id="18">have</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">committed</governor>
          <dependent id="19">themselves</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">is</governor>
          <dependent id="20">committed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">kind</governor>
          <dependent id="21">some</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">committed</governor>
          <dependent id="22">kind</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">violation</governor>
          <dependent id="23">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">violation</governor>
          <dependent id="24">law</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">kind</governor>
          <dependent id="25">violation</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="One" type="NUMBER" score="0.0">
          <tokens>
            <token id="2" string="One" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="22" has_coreference="false">
      <content>This makes their complaints difficult to sustain.</content>
      <tokens>
        <token id="1" string="This" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="makes" lemma="make" stem="make" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="complaints" lemma="complaint" stem="complaint" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="difficult" lemma="difficult" stem="difficult" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="sustain" lemma="sustain" stem="sustain" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT This)) (VP (VBZ makes) (S (NP (PRP$ their) (NNS complaints)) (ADJP (JJ difficult) (S (VP (TO to) (VP (VB sustain))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="their complaints" type="NP">
          <tokens>
            <token id="3" string="their" />
            <token id="4" string="complaints" />
          </tokens>
        </chunking>
        <chunking id="2" string="difficult to sustain" type="ADJP">
          <tokens>
            <token id="5" string="difficult" />
            <token id="6" string="to" />
            <token id="7" string="sustain" />
          </tokens>
        </chunking>
        <chunking id="3" string="This" type="NP">
          <tokens>
            <token id="1" string="This" />
          </tokens>
        </chunking>
        <chunking id="4" string="to sustain" type="VP">
          <tokens>
            <token id="6" string="to" />
            <token id="7" string="sustain" />
          </tokens>
        </chunking>
        <chunking id="5" string="makes their complaints difficult to sustain" type="VP">
          <tokens>
            <token id="2" string="makes" />
            <token id="3" string="their" />
            <token id="4" string="complaints" />
            <token id="5" string="difficult" />
            <token id="6" string="to" />
            <token id="7" string="sustain" />
          </tokens>
        </chunking>
        <chunking id="6" string="sustain" type="VP">
          <tokens>
            <token id="7" string="sustain" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">makes</governor>
          <dependent id="1">This</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">makes</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">complaints</governor>
          <dependent id="3">their</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">difficult</governor>
          <dependent id="4">complaints</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="2">makes</governor>
          <dependent id="5">difficult</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">sustain</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">difficult</governor>
          <dependent id="7">sustain</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="23" has_coreference="true">
      <content>But there is another problem: a police discipline system that is cloaked in secrecy.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="another" lemma="another" stem="anoth" pos="DT" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="problem" lemma="problem" stem="problem" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="discipline" lemma="discipline" stem="disciplin" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="system" lemma="system" stem="system" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="cloaked" lemma="cloak" stem="cloak" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="secrecy" lemma="secrecy" stem="secreci" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (EX there)) (VP (VBZ is) (NP (NP (DT another) (NN problem)) (: :) (NP (NP (DT a) (NN police) (NN discipline) (NN system)) (SBAR (WHNP (WDT that)) (S (VP (VBZ is) (VP (VBN cloaked) (PP (IN in) (NP (NN secrecy)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="there" type="NP">
          <tokens>
            <token id="2" string="there" />
          </tokens>
        </chunking>
        <chunking id="2" string="a police discipline system" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="police" />
            <token id="9" string="discipline" />
            <token id="10" string="system" />
          </tokens>
        </chunking>
        <chunking id="3" string="that is cloaked in secrecy" type="SBAR">
          <tokens>
            <token id="11" string="that" />
            <token id="12" string="is" />
            <token id="13" string="cloaked" />
            <token id="14" string="in" />
            <token id="15" string="secrecy" />
          </tokens>
        </chunking>
        <chunking id="4" string="a police discipline system that is cloaked in secrecy" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="police" />
            <token id="9" string="discipline" />
            <token id="10" string="system" />
            <token id="11" string="that" />
            <token id="12" string="is" />
            <token id="13" string="cloaked" />
            <token id="14" string="in" />
            <token id="15" string="secrecy" />
          </tokens>
        </chunking>
        <chunking id="5" string="secrecy" type="NP">
          <tokens>
            <token id="15" string="secrecy" />
          </tokens>
        </chunking>
        <chunking id="6" string="is cloaked in secrecy" type="VP">
          <tokens>
            <token id="12" string="is" />
            <token id="13" string="cloaked" />
            <token id="14" string="in" />
            <token id="15" string="secrecy" />
          </tokens>
        </chunking>
        <chunking id="7" string="another problem : a police discipline system that is cloaked in secrecy" type="NP">
          <tokens>
            <token id="4" string="another" />
            <token id="5" string="problem" />
            <token id="6" string=":" />
            <token id="7" string="a" />
            <token id="8" string="police" />
            <token id="9" string="discipline" />
            <token id="10" string="system" />
            <token id="11" string="that" />
            <token id="12" string="is" />
            <token id="13" string="cloaked" />
            <token id="14" string="in" />
            <token id="15" string="secrecy" />
          </tokens>
        </chunking>
        <chunking id="8" string="is another problem : a police discipline system that is cloaked in secrecy" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="another" />
            <token id="5" string="problem" />
            <token id="6" string=":" />
            <token id="7" string="a" />
            <token id="8" string="police" />
            <token id="9" string="discipline" />
            <token id="10" string="system" />
            <token id="11" string="that" />
            <token id="12" string="is" />
            <token id="13" string="cloaked" />
            <token id="14" string="in" />
            <token id="15" string="secrecy" />
          </tokens>
        </chunking>
        <chunking id="9" string="another problem" type="NP">
          <tokens>
            <token id="4" string="another" />
            <token id="5" string="problem" />
          </tokens>
        </chunking>
        <chunking id="10" string="cloaked in secrecy" type="VP">
          <tokens>
            <token id="13" string="cloaked" />
            <token id="14" string="in" />
            <token id="15" string="secrecy" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="3">is</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="3">is</governor>
          <dependent id="2">there</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">problem</governor>
          <dependent id="4">another</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">is</governor>
          <dependent id="5">problem</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">system</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">system</governor>
          <dependent id="8">police</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">system</governor>
          <dependent id="9">discipline</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="5">problem</governor>
          <dependent id="10">system</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="13">cloaked</governor>
          <dependent id="11">that</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="13">cloaked</governor>
          <dependent id="12">is</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="10">system</governor>
          <dependent id="13">cloaked</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">secrecy</governor>
          <dependent id="14">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">cloaked</governor>
          <dependent id="15">secrecy</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="24" has_coreference="true">
      <content>San Jose Police Chief Joseph MacNamara recently referred to the Los Angeles incident as &amp;quot;disgusting brutality&amp;quot; and pointed out that the disturbing aspect was the failure of leadership and the code of silence.</content>
      <tokens>
        <token id="1" string="San" lemma="San" stem="san" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="2" string="Jose" lemma="Jose" stem="jose" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="3" string="Police" lemma="Police" stem="polic" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="4" string="Chief" lemma="Chief" stem="chief" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="true" is_refers="false" />
        <token id="5" string="Joseph" lemma="Joseph" stem="joseph" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="6" string="MacNamara" lemma="MacNamara" stem="macnamara" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="7" string="recently" lemma="recently" stem="recent" pos="RB" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="8" string="referred" lemma="refer" stem="refer" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Los" lemma="Los" stem="lo" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="12" string="Angeles" lemma="Angeles" stem="angele" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="13" string="incident" lemma="incident" stem="incid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="disgusting" lemma="disgusting" stem="disgust" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="brutality" lemma="brutality" stem="brutal" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="pointed" lemma="point" stem="point" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="24" string="disturbing" lemma="disturbing" stem="disturb" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="25" string="aspect" lemma="aspect" stem="aspect" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="26" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="failure" lemma="failure" stem="failur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="leadership" lemma="leadership" stem="leadership" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="33" string="code" lemma="code" stem="code" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="34" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="35" string="silence" lemma="silence" stem="silenc" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="36" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP San) (NNP Jose) (NNP Police) (NNP Chief) (NNP Joseph) (NNP MacNamara)) (ADVP (RB recently)) (VP (VP (VBD referred) (PP (TO to) (NP (DT the) (NNP Los) (NNP Angeles) (NN incident))) (PP (IN as) (`` ``) (NP (JJ disgusting) (NN brutality)) ('' ''))) (CC and) (VP (VBD pointed) (PRT (RP out))) (SBAR (IN that) (S (NP (DT the) (JJ disturbing) (NN aspect)) (VP (VBD was) (NP (NP (NP (DT the) (NN failure)) (PP (IN of) (NP (NN leadership)))) (CC and) (NP (NP (DT the) (NN code)) (PP (IN of) (NP (NN silence))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the code" type="NP">
          <tokens>
            <token id="32" string="the" />
            <token id="33" string="code" />
          </tokens>
        </chunking>
        <chunking id="2" string="the failure" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="failure" />
          </tokens>
        </chunking>
        <chunking id="3" string="that the disturbing aspect was the failure of leadership and the code of silence" type="SBAR">
          <tokens>
            <token id="22" string="that" />
            <token id="23" string="the" />
            <token id="24" string="disturbing" />
            <token id="25" string="aspect" />
            <token id="26" string="was" />
            <token id="27" string="the" />
            <token id="28" string="failure" />
            <token id="29" string="of" />
            <token id="30" string="leadership" />
            <token id="31" string="and" />
            <token id="32" string="the" />
            <token id="33" string="code" />
            <token id="34" string="of" />
            <token id="35" string="silence" />
          </tokens>
        </chunking>
        <chunking id="4" string="the disturbing aspect" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="disturbing" />
            <token id="25" string="aspect" />
          </tokens>
        </chunking>
        <chunking id="5" string="the failure of leadership" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="failure" />
            <token id="29" string="of" />
            <token id="30" string="leadership" />
          </tokens>
        </chunking>
        <chunking id="6" string="pointed out" type="VP">
          <tokens>
            <token id="20" string="pointed" />
            <token id="21" string="out" />
          </tokens>
        </chunking>
        <chunking id="7" string="the code of silence" type="NP">
          <tokens>
            <token id="32" string="the" />
            <token id="33" string="code" />
            <token id="34" string="of" />
            <token id="35" string="silence" />
          </tokens>
        </chunking>
        <chunking id="8" string="the Los Angeles incident" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="Los" />
            <token id="12" string="Angeles" />
            <token id="13" string="incident" />
          </tokens>
        </chunking>
        <chunking id="9" string="the failure of leadership and the code of silence" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="failure" />
            <token id="29" string="of" />
            <token id="30" string="leadership" />
            <token id="31" string="and" />
            <token id="32" string="the" />
            <token id="33" string="code" />
            <token id="34" string="of" />
            <token id="35" string="silence" />
          </tokens>
        </chunking>
        <chunking id="10" string="referred to the Los Angeles incident as `` disgusting brutality ''" type="VP">
          <tokens>
            <token id="8" string="referred" />
            <token id="9" string="to" />
            <token id="10" string="the" />
            <token id="11" string="Los" />
            <token id="12" string="Angeles" />
            <token id="13" string="incident" />
            <token id="14" string="as" />
            <token id="15" string="&quot;" />
            <token id="16" string="disgusting" />
            <token id="17" string="brutality" />
            <token id="18" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="11" string="leadership" type="NP">
          <tokens>
            <token id="30" string="leadership" />
          </tokens>
        </chunking>
        <chunking id="12" string="San Jose Police Chief Joseph MacNamara" type="NP">
          <tokens>
            <token id="1" string="San" />
            <token id="2" string="Jose" />
            <token id="3" string="Police" />
            <token id="4" string="Chief" />
            <token id="5" string="Joseph" />
            <token id="6" string="MacNamara" />
          </tokens>
        </chunking>
        <chunking id="13" string="referred to the Los Angeles incident as `` disgusting brutality '' and pointed out that the disturbing aspect was the failure of leadership and the code of silence" type="VP">
          <tokens>
            <token id="8" string="referred" />
            <token id="9" string="to" />
            <token id="10" string="the" />
            <token id="11" string="Los" />
            <token id="12" string="Angeles" />
            <token id="13" string="incident" />
            <token id="14" string="as" />
            <token id="15" string="&quot;" />
            <token id="16" string="disgusting" />
            <token id="17" string="brutality" />
            <token id="18" string="&quot;" />
            <token id="19" string="and" />
            <token id="20" string="pointed" />
            <token id="21" string="out" />
            <token id="22" string="that" />
            <token id="23" string="the" />
            <token id="24" string="disturbing" />
            <token id="25" string="aspect" />
            <token id="26" string="was" />
            <token id="27" string="the" />
            <token id="28" string="failure" />
            <token id="29" string="of" />
            <token id="30" string="leadership" />
            <token id="31" string="and" />
            <token id="32" string="the" />
            <token id="33" string="code" />
            <token id="34" string="of" />
            <token id="35" string="silence" />
          </tokens>
        </chunking>
        <chunking id="14" string="was the failure of leadership and the code of silence" type="VP">
          <tokens>
            <token id="26" string="was" />
            <token id="27" string="the" />
            <token id="28" string="failure" />
            <token id="29" string="of" />
            <token id="30" string="leadership" />
            <token id="31" string="and" />
            <token id="32" string="the" />
            <token id="33" string="code" />
            <token id="34" string="of" />
            <token id="35" string="silence" />
          </tokens>
        </chunking>
        <chunking id="15" string="silence" type="NP">
          <tokens>
            <token id="35" string="silence" />
          </tokens>
        </chunking>
        <chunking id="16" string="disgusting brutality" type="NP">
          <tokens>
            <token id="16" string="disgusting" />
            <token id="17" string="brutality" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="6">MacNamara</governor>
          <dependent id="1">San</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">MacNamara</governor>
          <dependent id="2">Jose</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">MacNamara</governor>
          <dependent id="3">Police</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">MacNamara</governor>
          <dependent id="4">Chief</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">MacNamara</governor>
          <dependent id="5">Joseph</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">referred</governor>
          <dependent id="6">MacNamara</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">referred</governor>
          <dependent id="7">recently</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">referred</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">incident</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">incident</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">incident</governor>
          <dependent id="11">Los</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">incident</governor>
          <dependent id="12">Angeles</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">referred</governor>
          <dependent id="13">incident</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">brutality</governor>
          <dependent id="14">as</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">brutality</governor>
          <dependent id="16">disgusting</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">referred</governor>
          <dependent id="17">brutality</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">referred</governor>
          <dependent id="19">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">referred</governor>
          <dependent id="20">pointed</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="20">pointed</governor>
          <dependent id="21">out</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="28">failure</governor>
          <dependent id="22">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">aspect</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">aspect</governor>
          <dependent id="24">disturbing</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="28">failure</governor>
          <dependent id="25">aspect</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="28">failure</governor>
          <dependent id="26">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">failure</governor>
          <dependent id="27">the</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="8">referred</governor>
          <dependent id="28">failure</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">leadership</governor>
          <dependent id="29">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">failure</governor>
          <dependent id="30">leadership</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="28">failure</governor>
          <dependent id="31">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="33">code</governor>
          <dependent id="32">the</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="28">failure</governor>
          <dependent id="33">code</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">silence</governor>
          <dependent id="34">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="33">code</governor>
          <dependent id="35">silence</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Joseph MacNamara" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Joseph" />
            <token id="6" string="MacNamara" />
          </tokens>
        </entity>
        <entity id="2" string="Chief" type="TITLE" score="0.0">
          <tokens>
            <token id="4" string="Chief" />
          </tokens>
        </entity>
        <entity id="3" string="San Jose Police" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="1" string="San" />
            <token id="2" string="Jose" />
            <token id="3" string="Police" />
          </tokens>
        </entity>
        <entity id="4" string="recently" type="DATE" score="0.0">
          <tokens>
            <token id="7" string="recently" />
          </tokens>
        </entity>
        <entity id="5" string="Los Angeles" type="LOCATION" score="0.0">
          <tokens>
            <token id="11" string="Los" />
            <token id="12" string="Angeles" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="25" has_coreference="true">
      <content>MacNamara diagnosed the problem as an organizational attitude for which the leadership must take responsibility.</content>
      <tokens>
        <token id="1" string="MacNamara" lemma="MacNamara" stem="macnamara" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="diagnosed" lemma="diagnose" stem="diagnos" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="problem" lemma="problem" stem="problem" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="organizational" lemma="organizational" stem="organiz" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="attitude" lemma="attitude" stem="attitud" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="leadership" lemma="leadership" stem="leadership" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="must" lemma="must" stem="must" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="take" lemma="take" stem="take" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="responsibility" lemma="responsibility" stem="respons" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP MacNamara)) (VP (VBD diagnosed) (NP (DT the) (NN problem)) (PP (IN as) (NP (NP (DT an) (JJ organizational) (NN attitude)) (SBAR (WHPP (IN for) (WHNP (WDT which))) (S (NP (DT the) (NN leadership)) (VP (MD must) (VP (VB take) (NP (NN responsibility))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="MacNamara" type="NP">
          <tokens>
            <token id="1" string="MacNamara" />
          </tokens>
        </chunking>
        <chunking id="2" string="an organizational attitude" type="NP">
          <tokens>
            <token id="6" string="an" />
            <token id="7" string="organizational" />
            <token id="8" string="attitude" />
          </tokens>
        </chunking>
        <chunking id="3" string="the problem" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="problem" />
          </tokens>
        </chunking>
        <chunking id="4" string="an organizational attitude for which the leadership must take responsibility" type="NP">
          <tokens>
            <token id="6" string="an" />
            <token id="7" string="organizational" />
            <token id="8" string="attitude" />
            <token id="9" string="for" />
            <token id="10" string="which" />
            <token id="11" string="the" />
            <token id="12" string="leadership" />
            <token id="13" string="must" />
            <token id="14" string="take" />
            <token id="15" string="responsibility" />
          </tokens>
        </chunking>
        <chunking id="5" string="responsibility" type="NP">
          <tokens>
            <token id="15" string="responsibility" />
          </tokens>
        </chunking>
        <chunking id="6" string="take responsibility" type="VP">
          <tokens>
            <token id="14" string="take" />
            <token id="15" string="responsibility" />
          </tokens>
        </chunking>
        <chunking id="7" string="diagnosed the problem as an organizational attitude for which the leadership must take responsibility" type="VP">
          <tokens>
            <token id="2" string="diagnosed" />
            <token id="3" string="the" />
            <token id="4" string="problem" />
            <token id="5" string="as" />
            <token id="6" string="an" />
            <token id="7" string="organizational" />
            <token id="8" string="attitude" />
            <token id="9" string="for" />
            <token id="10" string="which" />
            <token id="11" string="the" />
            <token id="12" string="leadership" />
            <token id="13" string="must" />
            <token id="14" string="take" />
            <token id="15" string="responsibility" />
          </tokens>
        </chunking>
        <chunking id="8" string="the leadership" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="leadership" />
          </tokens>
        </chunking>
        <chunking id="9" string="for which the leadership must take responsibility" type="SBAR">
          <tokens>
            <token id="9" string="for" />
            <token id="10" string="which" />
            <token id="11" string="the" />
            <token id="12" string="leadership" />
            <token id="13" string="must" />
            <token id="14" string="take" />
            <token id="15" string="responsibility" />
          </tokens>
        </chunking>
        <chunking id="10" string="must take responsibility" type="VP">
          <tokens>
            <token id="13" string="must" />
            <token id="14" string="take" />
            <token id="15" string="responsibility" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">diagnosed</governor>
          <dependent id="1">MacNamara</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">diagnosed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">problem</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">diagnosed</governor>
          <dependent id="4">problem</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">attitude</governor>
          <dependent id="5">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">attitude</governor>
          <dependent id="6">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">attitude</governor>
          <dependent id="7">organizational</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">diagnosed</governor>
          <dependent id="8">attitude</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">which</governor>
          <dependent id="9">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">take</governor>
          <dependent id="10">which</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">leadership</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">take</governor>
          <dependent id="12">leadership</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="14">take</governor>
          <dependent id="13">must</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="8">attitude</governor>
          <dependent id="14">take</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">take</governor>
          <dependent id="15">responsibility</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="MacNamara" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="MacNamara" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="26" has_coreference="true">
      <content>He correctly notes that it is important for police credibility that police chiefs break the code of silence and repudiate such acts and attitudes.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="correctly" lemma="correctly" stem="correctli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="notes" lemma="note" stem="note" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="important" lemma="important" stem="import" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="credibility" lemma="credibility" stem="credibl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="chiefs" lemma="chief" stem="chief" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="break" lemma="break" stem="break" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="code" lemma="code" stem="code" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="silence" lemma="silence" stem="silenc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="repudiate" lemma="repudiate" stem="repudi" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="such" lemma="such" stem="such" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="acts" lemma="act" stem="act" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="attitudes" lemma="attitude" stem="attitud" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (ADVP (RB correctly)) (VP (VBZ notes) (SBAR (IN that) (S (NP (PRP it)) (VP (VBZ is) (ADJP (JJ important) (PP (IN for) (NP (NN police) (NN credibility)))) (SBAR (WHNP (WDT that)) (S (NP (NN police) (NNS chiefs)) (VP (VP (VBP break) (NP (NP (DT the) (NN code)) (PP (IN of) (NP (NN silence))))) (CC and) (VP (VB repudiate) (NP (JJ such) (NNS acts) (CC and) (NNS attitudes)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the code" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="code" />
          </tokens>
        </chunking>
        <chunking id="2" string="that police chiefs break the code of silence and repudiate such acts and attitudes" type="SBAR">
          <tokens>
            <token id="11" string="that" />
            <token id="12" string="police" />
            <token id="13" string="chiefs" />
            <token id="14" string="break" />
            <token id="15" string="the" />
            <token id="16" string="code" />
            <token id="17" string="of" />
            <token id="18" string="silence" />
            <token id="19" string="and" />
            <token id="20" string="repudiate" />
            <token id="21" string="such" />
            <token id="22" string="acts" />
            <token id="23" string="and" />
            <token id="24" string="attitudes" />
          </tokens>
        </chunking>
        <chunking id="3" string="it" type="NP">
          <tokens>
            <token id="5" string="it" />
          </tokens>
        </chunking>
        <chunking id="4" string="police credibility" type="NP">
          <tokens>
            <token id="9" string="police" />
            <token id="10" string="credibility" />
          </tokens>
        </chunking>
        <chunking id="5" string="police chiefs" type="NP">
          <tokens>
            <token id="12" string="police" />
            <token id="13" string="chiefs" />
          </tokens>
        </chunking>
        <chunking id="6" string="the code of silence" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="code" />
            <token id="17" string="of" />
            <token id="18" string="silence" />
          </tokens>
        </chunking>
        <chunking id="7" string="notes that it is important for police credibility that police chiefs break the code of silence and repudiate such acts and attitudes" type="VP">
          <tokens>
            <token id="3" string="notes" />
            <token id="4" string="that" />
            <token id="5" string="it" />
            <token id="6" string="is" />
            <token id="7" string="important" />
            <token id="8" string="for" />
            <token id="9" string="police" />
            <token id="10" string="credibility" />
            <token id="11" string="that" />
            <token id="12" string="police" />
            <token id="13" string="chiefs" />
            <token id="14" string="break" />
            <token id="15" string="the" />
            <token id="16" string="code" />
            <token id="17" string="of" />
            <token id="18" string="silence" />
            <token id="19" string="and" />
            <token id="20" string="repudiate" />
            <token id="21" string="such" />
            <token id="22" string="acts" />
            <token id="23" string="and" />
            <token id="24" string="attitudes" />
          </tokens>
        </chunking>
        <chunking id="8" string="break the code of silence" type="VP">
          <tokens>
            <token id="14" string="break" />
            <token id="15" string="the" />
            <token id="16" string="code" />
            <token id="17" string="of" />
            <token id="18" string="silence" />
          </tokens>
        </chunking>
        <chunking id="9" string="repudiate such acts and attitudes" type="VP">
          <tokens>
            <token id="20" string="repudiate" />
            <token id="21" string="such" />
            <token id="22" string="acts" />
            <token id="23" string="and" />
            <token id="24" string="attitudes" />
          </tokens>
        </chunking>
        <chunking id="10" string="that it is important for police credibility that police chiefs break the code of silence and repudiate such acts and attitudes" type="SBAR">
          <tokens>
            <token id="4" string="that" />
            <token id="5" string="it" />
            <token id="6" string="is" />
            <token id="7" string="important" />
            <token id="8" string="for" />
            <token id="9" string="police" />
            <token id="10" string="credibility" />
            <token id="11" string="that" />
            <token id="12" string="police" />
            <token id="13" string="chiefs" />
            <token id="14" string="break" />
            <token id="15" string="the" />
            <token id="16" string="code" />
            <token id="17" string="of" />
            <token id="18" string="silence" />
            <token id="19" string="and" />
            <token id="20" string="repudiate" />
            <token id="21" string="such" />
            <token id="22" string="acts" />
            <token id="23" string="and" />
            <token id="24" string="attitudes" />
          </tokens>
        </chunking>
        <chunking id="11" string="break the code of silence and repudiate such acts and attitudes" type="VP">
          <tokens>
            <token id="14" string="break" />
            <token id="15" string="the" />
            <token id="16" string="code" />
            <token id="17" string="of" />
            <token id="18" string="silence" />
            <token id="19" string="and" />
            <token id="20" string="repudiate" />
            <token id="21" string="such" />
            <token id="22" string="acts" />
            <token id="23" string="and" />
            <token id="24" string="attitudes" />
          </tokens>
        </chunking>
        <chunking id="12" string="such acts and attitudes" type="NP">
          <tokens>
            <token id="21" string="such" />
            <token id="22" string="acts" />
            <token id="23" string="and" />
            <token id="24" string="attitudes" />
          </tokens>
        </chunking>
        <chunking id="13" string="is important for police credibility that police chiefs break the code of silence and repudiate such acts and attitudes" type="VP">
          <tokens>
            <token id="6" string="is" />
            <token id="7" string="important" />
            <token id="8" string="for" />
            <token id="9" string="police" />
            <token id="10" string="credibility" />
            <token id="11" string="that" />
            <token id="12" string="police" />
            <token id="13" string="chiefs" />
            <token id="14" string="break" />
            <token id="15" string="the" />
            <token id="16" string="code" />
            <token id="17" string="of" />
            <token id="18" string="silence" />
            <token id="19" string="and" />
            <token id="20" string="repudiate" />
            <token id="21" string="such" />
            <token id="22" string="acts" />
            <token id="23" string="and" />
            <token id="24" string="attitudes" />
          </tokens>
        </chunking>
        <chunking id="14" string="silence" type="NP">
          <tokens>
            <token id="18" string="silence" />
          </tokens>
        </chunking>
        <chunking id="15" string="important for police credibility" type="ADJP">
          <tokens>
            <token id="7" string="important" />
            <token id="8" string="for" />
            <token id="9" string="police" />
            <token id="10" string="credibility" />
          </tokens>
        </chunking>
        <chunking id="16" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">notes</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">notes</governor>
          <dependent id="2">correctly</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">notes</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">important</governor>
          <dependent id="4">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">important</governor>
          <dependent id="5">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">important</governor>
          <dependent id="6">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">notes</governor>
          <dependent id="7">important</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">credibility</governor>
          <dependent id="8">for</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">credibility</governor>
          <dependent id="9">police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">important</governor>
          <dependent id="10">credibility</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">break</governor>
          <dependent id="11">that</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">chiefs</governor>
          <dependent id="12">police</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">break</governor>
          <dependent id="13">chiefs</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">important</governor>
          <dependent id="14">break</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">code</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">break</governor>
          <dependent id="16">code</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">silence</governor>
          <dependent id="17">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">code</governor>
          <dependent id="18">silence</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="14">break</governor>
          <dependent id="19">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">break</governor>
          <dependent id="20">repudiate</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">acts</governor>
          <dependent id="21">such</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">repudiate</governor>
          <dependent id="22">acts</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="22">acts</governor>
          <dependent id="23">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="22">acts</governor>
          <dependent id="24">attitudes</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="27" has_coreference="true">
      <content>Unfortunately, MacNamara also believes that San Jose does not need a citizens&amp;apost; review board.</content>
      <tokens>
        <token id="1" string="Unfortunately" lemma="unfortunately" stem="unfortun" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="MacNamara" lemma="MacNamara" stem="macnamara" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="4" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="believes" lemma="believe" stem="believ" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="San" lemma="San" stem="san" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="8" string="Jose" lemma="Jose" stem="jose" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="9" string="does" lemma="do" stem="doe" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="need" lemma="need" stem="need" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="citizens" lemma="citizen" stem="citizen" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="review" lemma="review" stem="review" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="board" lemma="board" stem="board" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Unfortunately)) (, ,) (NP (NNP MacNamara)) (ADVP (RB also)) (VP (VBZ believes) (SBAR (IN that) (S (NP (NNP San) (NNP Jose)) (VP (VBZ does) (RB not) (VP (VB need) (NP (NP (DT a) (NNS citizens) (POS ')) (NN review) (NN board))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="MacNamara" type="NP">
          <tokens>
            <token id="3" string="MacNamara" />
          </tokens>
        </chunking>
        <chunking id="2" string="believes that San Jose does not need a citizens ' review board" type="VP">
          <tokens>
            <token id="5" string="believes" />
            <token id="6" string="that" />
            <token id="7" string="San" />
            <token id="8" string="Jose" />
            <token id="9" string="does" />
            <token id="10" string="not" />
            <token id="11" string="need" />
            <token id="12" string="a" />
            <token id="13" string="citizens" />
            <token id="14" string="'" />
            <token id="15" string="review" />
            <token id="16" string="board" />
          </tokens>
        </chunking>
        <chunking id="3" string="does not need a citizens ' review board" type="VP">
          <tokens>
            <token id="9" string="does" />
            <token id="10" string="not" />
            <token id="11" string="need" />
            <token id="12" string="a" />
            <token id="13" string="citizens" />
            <token id="14" string="'" />
            <token id="15" string="review" />
            <token id="16" string="board" />
          </tokens>
        </chunking>
        <chunking id="4" string="that San Jose does not need a citizens ' review board" type="SBAR">
          <tokens>
            <token id="6" string="that" />
            <token id="7" string="San" />
            <token id="8" string="Jose" />
            <token id="9" string="does" />
            <token id="10" string="not" />
            <token id="11" string="need" />
            <token id="12" string="a" />
            <token id="13" string="citizens" />
            <token id="14" string="'" />
            <token id="15" string="review" />
            <token id="16" string="board" />
          </tokens>
        </chunking>
        <chunking id="5" string="a citizens '" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="citizens" />
            <token id="14" string="'" />
          </tokens>
        </chunking>
        <chunking id="6" string="a citizens ' review board" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="citizens" />
            <token id="14" string="'" />
            <token id="15" string="review" />
            <token id="16" string="board" />
          </tokens>
        </chunking>
        <chunking id="7" string="need a citizens ' review board" type="VP">
          <tokens>
            <token id="11" string="need" />
            <token id="12" string="a" />
            <token id="13" string="citizens" />
            <token id="14" string="'" />
            <token id="15" string="review" />
            <token id="16" string="board" />
          </tokens>
        </chunking>
        <chunking id="8" string="San Jose" type="NP">
          <tokens>
            <token id="7" string="San" />
            <token id="8" string="Jose" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="5">believes</governor>
          <dependent id="1">Unfortunately</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">believes</governor>
          <dependent id="3">MacNamara</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">believes</governor>
          <dependent id="4">also</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">believes</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">need</governor>
          <dependent id="6">that</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">Jose</governor>
          <dependent id="7">San</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">need</governor>
          <dependent id="8">Jose</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">need</governor>
          <dependent id="9">does</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="11">need</governor>
          <dependent id="10">not</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">believes</governor>
          <dependent id="11">need</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">citizens</governor>
          <dependent id="12">a</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="16">board</governor>
          <dependent id="13">citizens</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">citizens</governor>
          <dependent id="14">'</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">board</governor>
          <dependent id="15">review</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">need</governor>
          <dependent id="16">board</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="MacNamara" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="MacNamara" />
          </tokens>
        </entity>
        <entity id="2" string="San Jose" type="LOCATION" score="0.0">
          <tokens>
            <token id="7" string="San" />
            <token id="8" string="Jose" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="28" has_coreference="false">
      <content>I respectfully disagree.</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="respectfully" lemma="respectfully" stem="respectfulli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="disagree" lemma="disagree" stem="disagre" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (ADVP (RB respectfully)) (VP (VBP disagree)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="disagree" type="VP">
          <tokens>
            <token id="3" string="disagree" />
          </tokens>
        </chunking>
        <chunking id="2" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">disagree</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">disagree</governor>
          <dependent id="2">respectfully</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">disagree</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="29" has_coreference="true">
      <content>That is precisely what we need.</content>
      <tokens>
        <token id="1" string="That" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="precisely" lemma="precisely" stem="precis" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="need" lemma="need" stem="need" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT That)) (VP (VBZ is) (SBAR (WHNP (RB precisely) (WP what)) (S (NP (PRP we)) (VP (VBP need))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="That" type="NP">
          <tokens>
            <token id="1" string="That" />
          </tokens>
        </chunking>
        <chunking id="2" string="precisely what we need" type="SBAR">
          <tokens>
            <token id="3" string="precisely" />
            <token id="4" string="what" />
            <token id="5" string="we" />
            <token id="6" string="need" />
          </tokens>
        </chunking>
        <chunking id="3" string="need" type="VP">
          <tokens>
            <token id="6" string="need" />
          </tokens>
        </chunking>
        <chunking id="4" string="we" type="NP">
          <tokens>
            <token id="5" string="we" />
          </tokens>
        </chunking>
        <chunking id="5" string="is precisely what we need" type="VP">
          <tokens>
            <token id="2" string="is" />
            <token id="3" string="precisely" />
            <token id="4" string="what" />
            <token id="5" string="we" />
            <token id="6" string="need" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">is</governor>
          <dependent id="1">That</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">what</governor>
          <dependent id="3">precisely</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">need</governor>
          <dependent id="4">what</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">need</governor>
          <dependent id="5">we</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">is</governor>
          <dependent id="6">need</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="30" has_coreference="false">
      <content>Communities often don&amp;apost;t know the extent and the nature of police misconduct.</content>
      <tokens>
        <token id="1" string="Communities" lemma="community" stem="commun" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="often" lemma="often" stem="often" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="know" lemma="know" stem="know" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="extent" lemma="extent" stem="extent" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="nature" lemma="nature" stem="natur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="misconduct" lemma="misconduct" stem="misconduct" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNS Communities)) (ADVP (RB often)) (VP (VBP do) (RB n't) (VP (VB know) (NP (NP (DT the) (NN extent)) (CC and) (NP (NP (DT the) (NN nature)) (PP (IN of) (NP (NN police) (NN misconduct))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the nature of police misconduct" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="nature" />
            <token id="11" string="of" />
            <token id="12" string="police" />
            <token id="13" string="misconduct" />
          </tokens>
        </chunking>
        <chunking id="2" string="police misconduct" type="NP">
          <tokens>
            <token id="12" string="police" />
            <token id="13" string="misconduct" />
          </tokens>
        </chunking>
        <chunking id="3" string="the nature" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="nature" />
          </tokens>
        </chunking>
        <chunking id="4" string="Communities" type="NP">
          <tokens>
            <token id="1" string="Communities" />
          </tokens>
        </chunking>
        <chunking id="5" string="the extent" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="extent" />
          </tokens>
        </chunking>
        <chunking id="6" string="the extent and the nature of police misconduct" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="extent" />
            <token id="8" string="and" />
            <token id="9" string="the" />
            <token id="10" string="nature" />
            <token id="11" string="of" />
            <token id="12" string="police" />
            <token id="13" string="misconduct" />
          </tokens>
        </chunking>
        <chunking id="7" string="know the extent and the nature of police misconduct" type="VP">
          <tokens>
            <token id="5" string="know" />
            <token id="6" string="the" />
            <token id="7" string="extent" />
            <token id="8" string="and" />
            <token id="9" string="the" />
            <token id="10" string="nature" />
            <token id="11" string="of" />
            <token id="12" string="police" />
            <token id="13" string="misconduct" />
          </tokens>
        </chunking>
        <chunking id="8" string="do n't know the extent and the nature of police misconduct" type="VP">
          <tokens>
            <token id="3" string="do" />
            <token id="4" string="n't" />
            <token id="5" string="know" />
            <token id="6" string="the" />
            <token id="7" string="extent" />
            <token id="8" string="and" />
            <token id="9" string="the" />
            <token id="10" string="nature" />
            <token id="11" string="of" />
            <token id="12" string="police" />
            <token id="13" string="misconduct" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">know</governor>
          <dependent id="1">Communities</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">know</governor>
          <dependent id="2">often</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">know</governor>
          <dependent id="3">do</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">know</governor>
          <dependent id="4">n't</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">know</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">extent</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">know</governor>
          <dependent id="7">extent</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">extent</governor>
          <dependent id="8">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">nature</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">extent</governor>
          <dependent id="10">nature</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">misconduct</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">misconduct</governor>
          <dependent id="12">police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">nature</governor>
          <dependent id="13">misconduct</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="31" has_coreference="false">
      <content>State privacy laws combined with investigation and reporting procedures keep brutality complaints sealed.</content>
      <tokens>
        <token id="1" string="State" lemma="State" stem="state" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="privacy" lemma="privacy" stem="privaci" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="laws" lemma="law" stem="law" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="combined" lemma="combine" stem="combin" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="investigation" lemma="investigation" stem="investig" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="reporting" lemma="report" stem="report" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="procedures" lemma="procedure" stem="procedur" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="keep" lemma="keep" stem="keep" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="brutality" lemma="brutality" stem="brutal" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="complaints" lemma="complaint" stem="complaint" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="sealed" lemma="seal" stem="seal" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP State) (NN privacy) (NNS laws)) (VP (VP (VBN combined) (PP (IN with) (NP (NN investigation)))) (CC and) (VP (VBG reporting) (S (NP (NNS procedures)) (VP (VB keep) (NP (NP (NN brutality) (NNS complaints)) (VP (VBN sealed))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="brutality complaints" type="NP">
          <tokens>
            <token id="11" string="brutality" />
            <token id="12" string="complaints" />
          </tokens>
        </chunking>
        <chunking id="2" string="sealed" type="VP">
          <tokens>
            <token id="13" string="sealed" />
          </tokens>
        </chunking>
        <chunking id="3" string="brutality complaints sealed" type="NP">
          <tokens>
            <token id="11" string="brutality" />
            <token id="12" string="complaints" />
            <token id="13" string="sealed" />
          </tokens>
        </chunking>
        <chunking id="4" string="combined with investigation" type="VP">
          <tokens>
            <token id="4" string="combined" />
            <token id="5" string="with" />
            <token id="6" string="investigation" />
          </tokens>
        </chunking>
        <chunking id="5" string="keep brutality complaints sealed" type="VP">
          <tokens>
            <token id="10" string="keep" />
            <token id="11" string="brutality" />
            <token id="12" string="complaints" />
            <token id="13" string="sealed" />
          </tokens>
        </chunking>
        <chunking id="6" string="procedures" type="NP">
          <tokens>
            <token id="9" string="procedures" />
          </tokens>
        </chunking>
        <chunking id="7" string="investigation" type="NP">
          <tokens>
            <token id="6" string="investigation" />
          </tokens>
        </chunking>
        <chunking id="8" string="State privacy laws" type="NP">
          <tokens>
            <token id="1" string="State" />
            <token id="2" string="privacy" />
            <token id="3" string="laws" />
          </tokens>
        </chunking>
        <chunking id="9" string="combined with investigation and reporting procedures keep brutality complaints sealed" type="VP">
          <tokens>
            <token id="4" string="combined" />
            <token id="5" string="with" />
            <token id="6" string="investigation" />
            <token id="7" string="and" />
            <token id="8" string="reporting" />
            <token id="9" string="procedures" />
            <token id="10" string="keep" />
            <token id="11" string="brutality" />
            <token id="12" string="complaints" />
            <token id="13" string="sealed" />
          </tokens>
        </chunking>
        <chunking id="10" string="reporting procedures keep brutality complaints sealed" type="VP">
          <tokens>
            <token id="8" string="reporting" />
            <token id="9" string="procedures" />
            <token id="10" string="keep" />
            <token id="11" string="brutality" />
            <token id="12" string="complaints" />
            <token id="13" string="sealed" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">laws</governor>
          <dependent id="1">State</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">laws</governor>
          <dependent id="2">privacy</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">combined</governor>
          <dependent id="3">laws</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">combined</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">investigation</governor>
          <dependent id="5">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">combined</governor>
          <dependent id="6">investigation</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">combined</governor>
          <dependent id="7">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">combined</governor>
          <dependent id="8">reporting</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">keep</governor>
          <dependent id="9">procedures</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="8">reporting</governor>
          <dependent id="10">keep</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">complaints</governor>
          <dependent id="11">brutality</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">keep</governor>
          <dependent id="12">complaints</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="12">complaints</governor>
          <dependent id="13">sealed</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="32" has_coreference="true">
      <content>This is bad public policy.</content>
      <tokens>
        <token id="1" string="This" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="bad" lemma="bad" stem="bad" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="public" lemma="public" stem="public" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="policy" lemma="policy" stem="polici" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT This)) (VP (VBZ is) (NP (JJ bad) (JJ public) (NN policy))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="This" type="NP">
          <tokens>
            <token id="1" string="This" />
          </tokens>
        </chunking>
        <chunking id="2" string="bad public policy" type="NP">
          <tokens>
            <token id="3" string="bad" />
            <token id="4" string="public" />
            <token id="5" string="policy" />
          </tokens>
        </chunking>
        <chunking id="3" string="is bad public policy" type="VP">
          <tokens>
            <token id="2" string="is" />
            <token id="3" string="bad" />
            <token id="4" string="public" />
            <token id="5" string="policy" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">policy</governor>
          <dependent id="1">This</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">policy</governor>
          <dependent id="2">is</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">policy</governor>
          <dependent id="3">bad</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">policy</governor>
          <dependent id="4">public</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">policy</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="33" has_coreference="true">
      <content>Government must remain accountable to its citizens.</content>
      <tokens>
        <token id="1" string="Government" lemma="government" stem="govern" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="must" lemma="must" stem="must" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="remain" lemma="remain" stem="remain" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="accountable" lemma="accountable" stem="account" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="citizens" lemma="citizen" stem="citizen" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NN Government)) (VP (MD must) (VP (VB remain) (ADJP (JJ accountable) (PP (TO to) (NP (PRP$ its) (NNS citizens)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="must remain accountable to its citizens" type="VP">
          <tokens>
            <token id="2" string="must" />
            <token id="3" string="remain" />
            <token id="4" string="accountable" />
            <token id="5" string="to" />
            <token id="6" string="its" />
            <token id="7" string="citizens" />
          </tokens>
        </chunking>
        <chunking id="2" string="Government" type="NP">
          <tokens>
            <token id="1" string="Government" />
          </tokens>
        </chunking>
        <chunking id="3" string="accountable to its citizens" type="ADJP">
          <tokens>
            <token id="4" string="accountable" />
            <token id="5" string="to" />
            <token id="6" string="its" />
            <token id="7" string="citizens" />
          </tokens>
        </chunking>
        <chunking id="4" string="its citizens" type="NP">
          <tokens>
            <token id="6" string="its" />
            <token id="7" string="citizens" />
          </tokens>
        </chunking>
        <chunking id="5" string="remain accountable to its citizens" type="VP">
          <tokens>
            <token id="3" string="remain" />
            <token id="4" string="accountable" />
            <token id="5" string="to" />
            <token id="6" string="its" />
            <token id="7" string="citizens" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">remain</governor>
          <dependent id="1">Government</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="3">remain</governor>
          <dependent id="2">must</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">remain</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">remain</governor>
          <dependent id="4">accountable</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">citizens</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="7">citizens</governor>
          <dependent id="6">its</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">accountable</governor>
          <dependent id="7">citizens</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="34" has_coreference="true">
      <content>Those government employees who are given the right and the power to use force against citizens should be the most accountable.</content>
      <tokens>
        <token id="1" string="Those" lemma="those" stem="those" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="government" lemma="government" stem="govern" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="employees" lemma="employee" stem="employe" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="given" lemma="give" stem="given" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="right" lemma="right" stem="right" pos="NN" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="power" lemma="power" stem="power" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="use" lemma="use" stem="us" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="force" lemma="force" stem="forc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="citizens" lemma="citizen" stem="citizen" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="should" lemma="should" stem="should" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="most" lemma="most" stem="most" pos="RBS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="accountable" lemma="accountable" stem="account" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT Those) (NN government) (NNS employees)) (SBAR (WHNP (WP who)) (S (VP (VBP are) (VP (VBN given) (S (NP (NP (DT the) (NN right)) (CC and) (NP (DT the) (NN power))) (VP (TO to) (VP (VB use) (NP (NN force)) (PP (IN against) (NP (NNS citizens))))))))))) (VP (MD should) (VP (VB be) (NP (DT the) (ADJP (RBS most) (JJ accountable))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Those government employees" type="NP">
          <tokens>
            <token id="1" string="Those" />
            <token id="2" string="government" />
            <token id="3" string="employees" />
          </tokens>
        </chunking>
        <chunking id="2" string="are given the right and the power to use force against citizens" type="VP">
          <tokens>
            <token id="5" string="are" />
            <token id="6" string="given" />
            <token id="7" string="the" />
            <token id="8" string="right" />
            <token id="9" string="and" />
            <token id="10" string="the" />
            <token id="11" string="power" />
            <token id="12" string="to" />
            <token id="13" string="use" />
            <token id="14" string="force" />
            <token id="15" string="against" />
            <token id="16" string="citizens" />
          </tokens>
        </chunking>
        <chunking id="3" string="the right" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="right" />
          </tokens>
        </chunking>
        <chunking id="4" string="use force against citizens" type="VP">
          <tokens>
            <token id="13" string="use" />
            <token id="14" string="force" />
            <token id="15" string="against" />
            <token id="16" string="citizens" />
          </tokens>
        </chunking>
        <chunking id="5" string="the most accountable" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="most" />
            <token id="21" string="accountable" />
          </tokens>
        </chunking>
        <chunking id="6" string="should be the most accountable" type="VP">
          <tokens>
            <token id="17" string="should" />
            <token id="18" string="be" />
            <token id="19" string="the" />
            <token id="20" string="most" />
            <token id="21" string="accountable" />
          </tokens>
        </chunking>
        <chunking id="7" string="to use force against citizens" type="VP">
          <tokens>
            <token id="12" string="to" />
            <token id="13" string="use" />
            <token id="14" string="force" />
            <token id="15" string="against" />
            <token id="16" string="citizens" />
          </tokens>
        </chunking>
        <chunking id="8" string="given the right and the power to use force against citizens" type="VP">
          <tokens>
            <token id="6" string="given" />
            <token id="7" string="the" />
            <token id="8" string="right" />
            <token id="9" string="and" />
            <token id="10" string="the" />
            <token id="11" string="power" />
            <token id="12" string="to" />
            <token id="13" string="use" />
            <token id="14" string="force" />
            <token id="15" string="against" />
            <token id="16" string="citizens" />
          </tokens>
        </chunking>
        <chunking id="9" string="most accountable" type="ADJP">
          <tokens>
            <token id="20" string="most" />
            <token id="21" string="accountable" />
          </tokens>
        </chunking>
        <chunking id="10" string="who are given the right and the power to use force against citizens" type="SBAR">
          <tokens>
            <token id="4" string="who" />
            <token id="5" string="are" />
            <token id="6" string="given" />
            <token id="7" string="the" />
            <token id="8" string="right" />
            <token id="9" string="and" />
            <token id="10" string="the" />
            <token id="11" string="power" />
            <token id="12" string="to" />
            <token id="13" string="use" />
            <token id="14" string="force" />
            <token id="15" string="against" />
            <token id="16" string="citizens" />
          </tokens>
        </chunking>
        <chunking id="11" string="Those government employees who are given the right and the power to use force against citizens" type="NP">
          <tokens>
            <token id="1" string="Those" />
            <token id="2" string="government" />
            <token id="3" string="employees" />
            <token id="4" string="who" />
            <token id="5" string="are" />
            <token id="6" string="given" />
            <token id="7" string="the" />
            <token id="8" string="right" />
            <token id="9" string="and" />
            <token id="10" string="the" />
            <token id="11" string="power" />
            <token id="12" string="to" />
            <token id="13" string="use" />
            <token id="14" string="force" />
            <token id="15" string="against" />
            <token id="16" string="citizens" />
          </tokens>
        </chunking>
        <chunking id="12" string="the right and the power" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="right" />
            <token id="9" string="and" />
            <token id="10" string="the" />
            <token id="11" string="power" />
          </tokens>
        </chunking>
        <chunking id="13" string="force" type="NP">
          <tokens>
            <token id="14" string="force" />
          </tokens>
        </chunking>
        <chunking id="14" string="be the most accountable" type="VP">
          <tokens>
            <token id="18" string="be" />
            <token id="19" string="the" />
            <token id="20" string="most" />
            <token id="21" string="accountable" />
          </tokens>
        </chunking>
        <chunking id="15" string="the power" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="power" />
          </tokens>
        </chunking>
        <chunking id="16" string="citizens" type="NP">
          <tokens>
            <token id="16" string="citizens" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">employees</governor>
          <dependent id="1">Those</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">employees</governor>
          <dependent id="2">government</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">accountable</governor>
          <dependent id="3">employees</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="6">given</governor>
          <dependent id="4">who</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="6">given</governor>
          <dependent id="5">are</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="3">employees</governor>
          <dependent id="6">given</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">right</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">given</governor>
          <dependent id="8">right</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">right</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">power</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">right</governor>
          <dependent id="11">power</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">use</governor>
          <dependent id="12">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">given</governor>
          <dependent id="13">use</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">use</governor>
          <dependent id="14">force</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">citizens</governor>
          <dependent id="15">against</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">use</governor>
          <dependent id="16">citizens</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="21">accountable</governor>
          <dependent id="17">should</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="21">accountable</governor>
          <dependent id="18">be</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">accountable</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="21">accountable</governor>
          <dependent id="20">most</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="21">accountable</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="right" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="8" string="right" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="35" has_coreference="true">
      <content>As MacNamara points out, police are public servants.</content>
      <tokens>
        <token id="1" string="As" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="MacNamara" lemma="MacNamara" stem="macnamara" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="points" lemma="point" stem="point" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="police" lemma="police" stem="polic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="public" lemma="public" stem="public" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="servants" lemma="servant" stem="servant" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN As) (S (NP (NNP MacNamara)) (VP (VBZ points) (PRT (RP out))))) (, ,) (NP (NNS police)) (VP (VBP are) (NP (JJ public) (NNS servants))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="As MacNamara points out" type="SBAR">
          <tokens>
            <token id="1" string="As" />
            <token id="2" string="MacNamara" />
            <token id="3" string="points" />
            <token id="4" string="out" />
          </tokens>
        </chunking>
        <chunking id="2" string="MacNamara" type="NP">
          <tokens>
            <token id="2" string="MacNamara" />
          </tokens>
        </chunking>
        <chunking id="3" string="police" type="NP">
          <tokens>
            <token id="6" string="police" />
          </tokens>
        </chunking>
        <chunking id="4" string="public servants" type="NP">
          <tokens>
            <token id="8" string="public" />
            <token id="9" string="servants" />
          </tokens>
        </chunking>
        <chunking id="5" string="are public servants" type="VP">
          <tokens>
            <token id="7" string="are" />
            <token id="8" string="public" />
            <token id="9" string="servants" />
          </tokens>
        </chunking>
        <chunking id="6" string="points out" type="VP">
          <tokens>
            <token id="3" string="points" />
            <token id="4" string="out" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="3">points</governor>
          <dependent id="1">As</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">points</governor>
          <dependent id="2">MacNamara</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="9">servants</governor>
          <dependent id="3">points</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="3">points</governor>
          <dependent id="4">out</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">servants</governor>
          <dependent id="6">police</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="9">servants</governor>
          <dependent id="7">are</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">servants</governor>
          <dependent id="8">public</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">servants</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="MacNamara" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="MacNamara" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="36" has_coreference="true">
      <content>A minimal invasion of their privacy is a small price to pay for the power to maim and kill.</content>
      <tokens>
        <token id="1" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="minimal" lemma="minimal" stem="minim" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="invasion" lemma="invasion" stem="invas" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="6" string="privacy" lemma="privacy" stem="privaci" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="small" lemma="small" stem="small" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="price" lemma="price" stem="price" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="pay" lemma="pay" stem="pai" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="power" lemma="power" stem="power" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="maim" lemma="maim" stem="maim" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="kill" lemma="kill" stem="kill" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT A) (JJ minimal) (NN invasion)) (PP (IN of) (NP (PRP$ their) (NN privacy)))) (VP (VBZ is) (NP (DT a) (JJ small) (NN price) (S (VP (TO to) (VP (VB pay) (PP (IN for) (NP (DT the) (NN power) (S (VP (TO to) (VP (VB maim) (CC and) (VB kill))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="A minimal invasion" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="minimal" />
            <token id="3" string="invasion" />
          </tokens>
        </chunking>
        <chunking id="2" string="their privacy" type="NP">
          <tokens>
            <token id="5" string="their" />
            <token id="6" string="privacy" />
          </tokens>
        </chunking>
        <chunking id="3" string="A minimal invasion of their privacy" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="minimal" />
            <token id="3" string="invasion" />
            <token id="4" string="of" />
            <token id="5" string="their" />
            <token id="6" string="privacy" />
          </tokens>
        </chunking>
        <chunking id="4" string="is a small price to pay for the power to maim and kill" type="VP">
          <tokens>
            <token id="7" string="is" />
            <token id="8" string="a" />
            <token id="9" string="small" />
            <token id="10" string="price" />
            <token id="11" string="to" />
            <token id="12" string="pay" />
            <token id="13" string="for" />
            <token id="14" string="the" />
            <token id="15" string="power" />
            <token id="16" string="to" />
            <token id="17" string="maim" />
            <token id="18" string="and" />
            <token id="19" string="kill" />
          </tokens>
        </chunking>
        <chunking id="5" string="the power to maim and kill" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="power" />
            <token id="16" string="to" />
            <token id="17" string="maim" />
            <token id="18" string="and" />
            <token id="19" string="kill" />
          </tokens>
        </chunking>
        <chunking id="6" string="a small price to pay for the power to maim and kill" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="small" />
            <token id="10" string="price" />
            <token id="11" string="to" />
            <token id="12" string="pay" />
            <token id="13" string="for" />
            <token id="14" string="the" />
            <token id="15" string="power" />
            <token id="16" string="to" />
            <token id="17" string="maim" />
            <token id="18" string="and" />
            <token id="19" string="kill" />
          </tokens>
        </chunking>
        <chunking id="7" string="to pay for the power to maim and kill" type="VP">
          <tokens>
            <token id="11" string="to" />
            <token id="12" string="pay" />
            <token id="13" string="for" />
            <token id="14" string="the" />
            <token id="15" string="power" />
            <token id="16" string="to" />
            <token id="17" string="maim" />
            <token id="18" string="and" />
            <token id="19" string="kill" />
          </tokens>
        </chunking>
        <chunking id="8" string="pay for the power to maim and kill" type="VP">
          <tokens>
            <token id="12" string="pay" />
            <token id="13" string="for" />
            <token id="14" string="the" />
            <token id="15" string="power" />
            <token id="16" string="to" />
            <token id="17" string="maim" />
            <token id="18" string="and" />
            <token id="19" string="kill" />
          </tokens>
        </chunking>
        <chunking id="9" string="maim and kill" type="VP">
          <tokens>
            <token id="17" string="maim" />
            <token id="18" string="and" />
            <token id="19" string="kill" />
          </tokens>
        </chunking>
        <chunking id="10" string="to maim and kill" type="VP">
          <tokens>
            <token id="16" string="to" />
            <token id="17" string="maim" />
            <token id="18" string="and" />
            <token id="19" string="kill" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">invasion</governor>
          <dependent id="1">A</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">invasion</governor>
          <dependent id="2">minimal</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">price</governor>
          <dependent id="3">invasion</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">privacy</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="6">privacy</governor>
          <dependent id="5">their</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">invasion</governor>
          <dependent id="6">privacy</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="10">price</governor>
          <dependent id="7">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">price</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">price</governor>
          <dependent id="9">small</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">price</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">pay</governor>
          <dependent id="11">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="10">price</governor>
          <dependent id="12">pay</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">power</governor>
          <dependent id="13">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">power</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">pay</governor>
          <dependent id="15">power</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">maim</governor>
          <dependent id="16">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="15">power</governor>
          <dependent id="17">maim</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="17">maim</governor>
          <dependent id="18">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">maim</governor>
          <dependent id="19">kill</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="37" has_coreference="true">
      <content>Monitoring police brutality is further complicated by the fact that local communities leave it to the police departments to investigate citizen complaints.</content>
      <tokens>
        <token id="1" string="Monitoring" lemma="monitor" stem="monitor" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="police" lemma="police" stem="polic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="brutality" lemma="brutality" stem="brutal" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="further" lemma="further" stem="further" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="complicated" lemma="complicate" stem="complic" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="fact" lemma="fact" stem="fact" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="local" lemma="local" stem="local" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="communities" lemma="community" stem="commun" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="leave" lemma="leave" stem="leav" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="departments" lemma="department" stem="depart" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="investigate" lemma="investigate" stem="investig" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="citizen" lemma="citizen" stem="citizen" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="complaints" lemma="complaint" stem="complaint" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (VBG Monitoring) (NP (NNS police) (NN brutality)))) (VP (VBZ is) (ADJP (ADJP (RBR further) (VBN complicated) (PP (IN by) (NP (DT the) (NN fact)))) (SBAR (IN that) (S (NP (JJ local) (NNS communities)) (VP (VBP leave) (NP (PRP it)) (PP (TO to) (NP (DT the) (NN police) (NNS departments))) (S (VP (TO to) (VP (VB investigate) (NP (NN citizen) (NNS complaints)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="citizen complaints" type="NP">
          <tokens>
            <token id="21" string="citizen" />
            <token id="22" string="complaints" />
          </tokens>
        </chunking>
        <chunking id="2" string="the police departments" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="police" />
            <token id="18" string="departments" />
          </tokens>
        </chunking>
        <chunking id="3" string="the fact" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="fact" />
          </tokens>
        </chunking>
        <chunking id="4" string="further complicated by the fact" type="ADJP">
          <tokens>
            <token id="5" string="further" />
            <token id="6" string="complicated" />
            <token id="7" string="by" />
            <token id="8" string="the" />
            <token id="9" string="fact" />
          </tokens>
        </chunking>
        <chunking id="5" string="further complicated by the fact that local communities leave it to the police departments to investigate citizen complaints" type="ADJP">
          <tokens>
            <token id="5" string="further" />
            <token id="6" string="complicated" />
            <token id="7" string="by" />
            <token id="8" string="the" />
            <token id="9" string="fact" />
            <token id="10" string="that" />
            <token id="11" string="local" />
            <token id="12" string="communities" />
            <token id="13" string="leave" />
            <token id="14" string="it" />
            <token id="15" string="to" />
            <token id="16" string="the" />
            <token id="17" string="police" />
            <token id="18" string="departments" />
            <token id="19" string="to" />
            <token id="20" string="investigate" />
            <token id="21" string="citizen" />
            <token id="22" string="complaints" />
          </tokens>
        </chunking>
        <chunking id="6" string="is further complicated by the fact that local communities leave it to the police departments to investigate citizen complaints" type="VP">
          <tokens>
            <token id="4" string="is" />
            <token id="5" string="further" />
            <token id="6" string="complicated" />
            <token id="7" string="by" />
            <token id="8" string="the" />
            <token id="9" string="fact" />
            <token id="10" string="that" />
            <token id="11" string="local" />
            <token id="12" string="communities" />
            <token id="13" string="leave" />
            <token id="14" string="it" />
            <token id="15" string="to" />
            <token id="16" string="the" />
            <token id="17" string="police" />
            <token id="18" string="departments" />
            <token id="19" string="to" />
            <token id="20" string="investigate" />
            <token id="21" string="citizen" />
            <token id="22" string="complaints" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="14" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="Monitoring police brutality" type="VP">
          <tokens>
            <token id="1" string="Monitoring" />
            <token id="2" string="police" />
            <token id="3" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="9" string="local communities" type="NP">
          <tokens>
            <token id="11" string="local" />
            <token id="12" string="communities" />
          </tokens>
        </chunking>
        <chunking id="10" string="investigate citizen complaints" type="VP">
          <tokens>
            <token id="20" string="investigate" />
            <token id="21" string="citizen" />
            <token id="22" string="complaints" />
          </tokens>
        </chunking>
        <chunking id="11" string="police brutality" type="NP">
          <tokens>
            <token id="2" string="police" />
            <token id="3" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="12" string="that local communities leave it to the police departments to investigate citizen complaints" type="SBAR">
          <tokens>
            <token id="10" string="that" />
            <token id="11" string="local" />
            <token id="12" string="communities" />
            <token id="13" string="leave" />
            <token id="14" string="it" />
            <token id="15" string="to" />
            <token id="16" string="the" />
            <token id="17" string="police" />
            <token id="18" string="departments" />
            <token id="19" string="to" />
            <token id="20" string="investigate" />
            <token id="21" string="citizen" />
            <token id="22" string="complaints" />
          </tokens>
        </chunking>
        <chunking id="13" string="to investigate citizen complaints" type="VP">
          <tokens>
            <token id="19" string="to" />
            <token id="20" string="investigate" />
            <token id="21" string="citizen" />
            <token id="22" string="complaints" />
          </tokens>
        </chunking>
        <chunking id="14" string="leave it to the police departments to investigate citizen complaints" type="VP">
          <tokens>
            <token id="13" string="leave" />
            <token id="14" string="it" />
            <token id="15" string="to" />
            <token id="16" string="the" />
            <token id="17" string="police" />
            <token id="18" string="departments" />
            <token id="19" string="to" />
            <token id="20" string="investigate" />
            <token id="21" string="citizen" />
            <token id="22" string="complaints" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="csubj">
          <governor id="6">complicated</governor>
          <dependent id="1">Monitoring</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">brutality</governor>
          <dependent id="2">police</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="1">Monitoring</governor>
          <dependent id="3">brutality</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">complicated</governor>
          <dependent id="4">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">complicated</governor>
          <dependent id="5">further</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">complicated</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">fact</governor>
          <dependent id="7">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">fact</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">complicated</governor>
          <dependent id="9">fact</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">leave</governor>
          <dependent id="10">that</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">communities</governor>
          <dependent id="11">local</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">leave</governor>
          <dependent id="12">communities</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">complicated</governor>
          <dependent id="13">leave</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">leave</governor>
          <dependent id="14">it</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">departments</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">departments</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">departments</governor>
          <dependent id="17">police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">leave</governor>
          <dependent id="18">departments</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="20">investigate</governor>
          <dependent id="19">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="13">leave</governor>
          <dependent id="20">investigate</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">complaints</governor>
          <dependent id="21">citizen</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">investigate</governor>
          <dependent id="22">complaints</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="38" has_coreference="true">
      <content>Although the penal code makes the findings of investigations confidential, investigations themselves can be conducted by the public and can be open to the public.</content>
      <tokens>
        <token id="1" string="Although" lemma="although" stem="although" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="penal" lemma="penal" stem="penal" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="code" lemma="code" stem="code" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="makes" lemma="make" stem="make" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="findings" lemma="finding" stem="find" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="investigations" lemma="investigation" stem="investig" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="confidential" lemma="confidential" stem="confidenti" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="investigations" lemma="investigation" stem="investig" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="themselves" lemma="themselves" stem="themselv" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="conducted" lemma="conduct" stem="conduct" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="public" lemma="public" stem="public" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="open" lemma="open" stem="open" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="public" lemma="public" stem="public" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN Although) (S (NP (DT the) (JJ penal) (NN code)) (VP (VBZ makes) (S (NP (NP (DT the) (NNS findings)) (PP (IN of) (NP (NNS investigations)))) (ADJP (JJ confidential)))))) (, ,) (NP (NNS investigations)) (ADVP (PRP themselves)) (VP (VP (MD can) (VP (VB be) (VP (VBN conducted) (PP (IN by) (NP (DT the) (JJ public)))))) (CC and) (VP (MD can) (VP (VB be) (ADJP (JJ open) (PP (TO to) (NP (DT the) (NN public))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the findings" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="findings" />
          </tokens>
        </chunking>
        <chunking id="2" string="the public" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="public" />
          </tokens>
        </chunking>
        <chunking id="3" string="investigations" type="NP">
          <tokens>
            <token id="9" string="investigations" />
          </tokens>
        </chunking>
        <chunking id="4" string="open to the public" type="ADJP">
          <tokens>
            <token id="23" string="open" />
            <token id="24" string="to" />
            <token id="25" string="the" />
            <token id="26" string="public" />
          </tokens>
        </chunking>
        <chunking id="5" string="confidential" type="ADJP">
          <tokens>
            <token id="10" string="confidential" />
          </tokens>
        </chunking>
        <chunking id="6" string="makes the findings of investigations confidential" type="VP">
          <tokens>
            <token id="5" string="makes" />
            <token id="6" string="the" />
            <token id="7" string="findings" />
            <token id="8" string="of" />
            <token id="9" string="investigations" />
            <token id="10" string="confidential" />
          </tokens>
        </chunking>
        <chunking id="7" string="the findings of investigations" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="findings" />
            <token id="8" string="of" />
            <token id="9" string="investigations" />
          </tokens>
        </chunking>
        <chunking id="8" string="can be conducted by the public and can be open to the public" type="VP">
          <tokens>
            <token id="14" string="can" />
            <token id="15" string="be" />
            <token id="16" string="conducted" />
            <token id="17" string="by" />
            <token id="18" string="the" />
            <token id="19" string="public" />
            <token id="20" string="and" />
            <token id="21" string="can" />
            <token id="22" string="be" />
            <token id="23" string="open" />
            <token id="24" string="to" />
            <token id="25" string="the" />
            <token id="26" string="public" />
          </tokens>
        </chunking>
        <chunking id="9" string="the penal code" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="penal" />
            <token id="4" string="code" />
          </tokens>
        </chunking>
        <chunking id="10" string="be conducted by the public" type="VP">
          <tokens>
            <token id="15" string="be" />
            <token id="16" string="conducted" />
            <token id="17" string="by" />
            <token id="18" string="the" />
            <token id="19" string="public" />
          </tokens>
        </chunking>
        <chunking id="11" string="can be open to the public" type="VP">
          <tokens>
            <token id="21" string="can" />
            <token id="22" string="be" />
            <token id="23" string="open" />
            <token id="24" string="to" />
            <token id="25" string="the" />
            <token id="26" string="public" />
          </tokens>
        </chunking>
        <chunking id="12" string="can be conducted by the public" type="VP">
          <tokens>
            <token id="14" string="can" />
            <token id="15" string="be" />
            <token id="16" string="conducted" />
            <token id="17" string="by" />
            <token id="18" string="the" />
            <token id="19" string="public" />
          </tokens>
        </chunking>
        <chunking id="13" string="Although the penal code makes the findings of investigations confidential" type="SBAR">
          <tokens>
            <token id="1" string="Although" />
            <token id="2" string="the" />
            <token id="3" string="penal" />
            <token id="4" string="code" />
            <token id="5" string="makes" />
            <token id="6" string="the" />
            <token id="7" string="findings" />
            <token id="8" string="of" />
            <token id="9" string="investigations" />
            <token id="10" string="confidential" />
          </tokens>
        </chunking>
        <chunking id="14" string="be open to the public" type="VP">
          <tokens>
            <token id="22" string="be" />
            <token id="23" string="open" />
            <token id="24" string="to" />
            <token id="25" string="the" />
            <token id="26" string="public" />
          </tokens>
        </chunking>
        <chunking id="15" string="conducted by the public" type="VP">
          <tokens>
            <token id="16" string="conducted" />
            <token id="17" string="by" />
            <token id="18" string="the" />
            <token id="19" string="public" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="5">makes</governor>
          <dependent id="1">Although</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">code</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">code</governor>
          <dependent id="3">penal</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">makes</governor>
          <dependent id="4">code</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="16">conducted</governor>
          <dependent id="5">makes</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">findings</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">confidential</governor>
          <dependent id="7">findings</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">investigations</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">findings</governor>
          <dependent id="9">investigations</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">makes</governor>
          <dependent id="10">confidential</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="16">conducted</governor>
          <dependent id="12">investigations</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">conducted</governor>
          <dependent id="13">themselves</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">conducted</governor>
          <dependent id="14">can</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="16">conducted</governor>
          <dependent id="15">be</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="16">conducted</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">public</governor>
          <dependent id="17">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">public</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">conducted</governor>
          <dependent id="19">public</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="16">conducted</governor>
          <dependent id="20">and</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="23">open</governor>
          <dependent id="21">can</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="23">open</governor>
          <dependent id="22">be</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">conducted</governor>
          <dependent id="23">open</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">public</governor>
          <dependent id="24">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">public</governor>
          <dependent id="25">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">open</governor>
          <dependent id="26">public</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="39" has_coreference="false">
      <content>Complaints of police brutality should be handled in an open process that is neutral and thorough.</content>
      <tokens>
        <token id="1" string="Complaints" lemma="complaint" stem="complaint" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="brutality" lemma="brutality" stem="brutal" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="should" lemma="should" stem="should" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="handled" lemma="handle" stem="handl" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="open" lemma="open" stem="open" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="process" lemma="process" stem="process" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="neutral" lemma="neutral" stem="neutral" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="thorough" lemma="thorough" stem="thorough" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNS Complaints)) (PP (IN of) (NP (NN police) (NN brutality)))) (VP (MD should) (VP (VB be) (VP (VBN handled) (PP (IN in) (NP (NP (DT an) (JJ open) (NN process)) (SBAR (WHNP (WDT that)) (S (VP (VBZ is) (ADJP (JJ neutral) (CC and) (JJ thorough)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="be handled in an open process that is neutral and thorough" type="VP">
          <tokens>
            <token id="6" string="be" />
            <token id="7" string="handled" />
            <token id="8" string="in" />
            <token id="9" string="an" />
            <token id="10" string="open" />
            <token id="11" string="process" />
            <token id="12" string="that" />
            <token id="13" string="is" />
            <token id="14" string="neutral" />
            <token id="15" string="and" />
            <token id="16" string="thorough" />
          </tokens>
        </chunking>
        <chunking id="2" string="handled in an open process that is neutral and thorough" type="VP">
          <tokens>
            <token id="7" string="handled" />
            <token id="8" string="in" />
            <token id="9" string="an" />
            <token id="10" string="open" />
            <token id="11" string="process" />
            <token id="12" string="that" />
            <token id="13" string="is" />
            <token id="14" string="neutral" />
            <token id="15" string="and" />
            <token id="16" string="thorough" />
          </tokens>
        </chunking>
        <chunking id="3" string="an open process" type="NP">
          <tokens>
            <token id="9" string="an" />
            <token id="10" string="open" />
            <token id="11" string="process" />
          </tokens>
        </chunking>
        <chunking id="4" string="Complaints" type="NP">
          <tokens>
            <token id="1" string="Complaints" />
          </tokens>
        </chunking>
        <chunking id="5" string="neutral and thorough" type="ADJP">
          <tokens>
            <token id="14" string="neutral" />
            <token id="15" string="and" />
            <token id="16" string="thorough" />
          </tokens>
        </chunking>
        <chunking id="6" string="is neutral and thorough" type="VP">
          <tokens>
            <token id="13" string="is" />
            <token id="14" string="neutral" />
            <token id="15" string="and" />
            <token id="16" string="thorough" />
          </tokens>
        </chunking>
        <chunking id="7" string="should be handled in an open process that is neutral and thorough" type="VP">
          <tokens>
            <token id="5" string="should" />
            <token id="6" string="be" />
            <token id="7" string="handled" />
            <token id="8" string="in" />
            <token id="9" string="an" />
            <token id="10" string="open" />
            <token id="11" string="process" />
            <token id="12" string="that" />
            <token id="13" string="is" />
            <token id="14" string="neutral" />
            <token id="15" string="and" />
            <token id="16" string="thorough" />
          </tokens>
        </chunking>
        <chunking id="8" string="that is neutral and thorough" type="SBAR">
          <tokens>
            <token id="12" string="that" />
            <token id="13" string="is" />
            <token id="14" string="neutral" />
            <token id="15" string="and" />
            <token id="16" string="thorough" />
          </tokens>
        </chunking>
        <chunking id="9" string="police brutality" type="NP">
          <tokens>
            <token id="3" string="police" />
            <token id="4" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="10" string="Complaints of police brutality" type="NP">
          <tokens>
            <token id="1" string="Complaints" />
            <token id="2" string="of" />
            <token id="3" string="police" />
            <token id="4" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="11" string="an open process that is neutral and thorough" type="NP">
          <tokens>
            <token id="9" string="an" />
            <token id="10" string="open" />
            <token id="11" string="process" />
            <token id="12" string="that" />
            <token id="13" string="is" />
            <token id="14" string="neutral" />
            <token id="15" string="and" />
            <token id="16" string="thorough" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="7">handled</governor>
          <dependent id="1">Complaints</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">brutality</governor>
          <dependent id="2">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">brutality</governor>
          <dependent id="3">police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Complaints</governor>
          <dependent id="4">brutality</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">handled</governor>
          <dependent id="5">should</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="7">handled</governor>
          <dependent id="6">be</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">handled</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">process</governor>
          <dependent id="8">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">process</governor>
          <dependent id="9">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">process</governor>
          <dependent id="10">open</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">handled</governor>
          <dependent id="11">process</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">neutral</governor>
          <dependent id="12">that</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="14">neutral</governor>
          <dependent id="13">is</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="11">process</governor>
          <dependent id="14">neutral</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="14">neutral</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">neutral</governor>
          <dependent id="16">thorough</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="40" has_coreference="false">
      <content>Having the fox guard the chicken house fails to provide that assurance.</content>
      <tokens>
        <token id="1" string="Having" lemma="have" stem="have" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="fox" lemma="fox" stem="fox" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="guard" lemma="guard" stem="guard" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="chicken" lemma="chicken" stem="chicken" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="house" lemma="house" stem="hous" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="fails" lemma="fail" stem="fail" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="provide" lemma="provide" stem="provid" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="assurance" lemma="assurance" stem="assur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (VBG Having) (NP (DT the) (NN fox) (NN guard)))) (NP (DT the) (NN chicken) (NN house)) (VP (VBZ fails) (S (VP (TO to) (VP (VB provide) (SBAR (IN that) (FRAG (NP (NN assurance)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="fails to provide that assurance" type="VP">
          <tokens>
            <token id="8" string="fails" />
            <token id="9" string="to" />
            <token id="10" string="provide" />
            <token id="11" string="that" />
            <token id="12" string="assurance" />
          </tokens>
        </chunking>
        <chunking id="2" string="to provide that assurance" type="VP">
          <tokens>
            <token id="9" string="to" />
            <token id="10" string="provide" />
            <token id="11" string="that" />
            <token id="12" string="assurance" />
          </tokens>
        </chunking>
        <chunking id="3" string="assurance" type="NP">
          <tokens>
            <token id="12" string="assurance" />
          </tokens>
        </chunking>
        <chunking id="4" string="the chicken house" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="chicken" />
            <token id="7" string="house" />
          </tokens>
        </chunking>
        <chunking id="5" string="the fox guard" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="fox" />
            <token id="4" string="guard" />
          </tokens>
        </chunking>
        <chunking id="6" string="provide that assurance" type="VP">
          <tokens>
            <token id="10" string="provide" />
            <token id="11" string="that" />
            <token id="12" string="assurance" />
          </tokens>
        </chunking>
        <chunking id="7" string="that assurance" type="SBAR">
          <tokens>
            <token id="11" string="that" />
            <token id="12" string="assurance" />
          </tokens>
        </chunking>
        <chunking id="8" string="Having the fox guard" type="VP">
          <tokens>
            <token id="1" string="Having" />
            <token id="2" string="the" />
            <token id="3" string="fox" />
            <token id="4" string="guard" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="dep">
          <governor id="8">fails</governor>
          <dependent id="1">Having</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">guard</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">guard</governor>
          <dependent id="3">fox</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="1">Having</governor>
          <dependent id="4">guard</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">house</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">house</governor>
          <dependent id="6">chicken</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">fails</governor>
          <dependent id="7">house</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">fails</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">provide</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="8">fails</governor>
          <dependent id="10">provide</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">assurance</governor>
          <dependent id="11">that</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="10">provide</governor>
          <dependent id="12">assurance</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="41" has_coreference="true">
      <content>The attitude of the public will determine the effectiveness of the police discipline system.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="attitude" lemma="attitude" stem="attitud" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="public" lemma="public" stem="public" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="determine" lemma="determine" stem="determin" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="effectiveness" lemma="effectiveness" stem="effect" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="discipline" lemma="discipline" stem="disciplin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="system" lemma="system" stem="system" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (NN attitude)) (PP (IN of) (NP (DT the) (NN public)))) (VP (MD will) (VP (VB determine) (NP (NP (DT the) (NN effectiveness)) (PP (IN of) (NP (DT the) (NN police) (NN discipline) (NN system)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="will determine the effectiveness of the police discipline system" type="VP">
          <tokens>
            <token id="6" string="will" />
            <token id="7" string="determine" />
            <token id="8" string="the" />
            <token id="9" string="effectiveness" />
            <token id="10" string="of" />
            <token id="11" string="the" />
            <token id="12" string="police" />
            <token id="13" string="discipline" />
            <token id="14" string="system" />
          </tokens>
        </chunking>
        <chunking id="2" string="the effectiveness of the police discipline system" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="effectiveness" />
            <token id="10" string="of" />
            <token id="11" string="the" />
            <token id="12" string="police" />
            <token id="13" string="discipline" />
            <token id="14" string="system" />
          </tokens>
        </chunking>
        <chunking id="3" string="determine the effectiveness of the police discipline system" type="VP">
          <tokens>
            <token id="7" string="determine" />
            <token id="8" string="the" />
            <token id="9" string="effectiveness" />
            <token id="10" string="of" />
            <token id="11" string="the" />
            <token id="12" string="police" />
            <token id="13" string="discipline" />
            <token id="14" string="system" />
          </tokens>
        </chunking>
        <chunking id="4" string="The attitude" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="attitude" />
          </tokens>
        </chunking>
        <chunking id="5" string="the public" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="public" />
          </tokens>
        </chunking>
        <chunking id="6" string="The attitude of the public" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="attitude" />
            <token id="3" string="of" />
            <token id="4" string="the" />
            <token id="5" string="public" />
          </tokens>
        </chunking>
        <chunking id="7" string="the police discipline system" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="police" />
            <token id="13" string="discipline" />
            <token id="14" string="system" />
          </tokens>
        </chunking>
        <chunking id="8" string="the effectiveness" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="effectiveness" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">attitude</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">determine</governor>
          <dependent id="2">attitude</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">public</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">public</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">attitude</governor>
          <dependent id="5">public</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">determine</governor>
          <dependent id="6">will</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">determine</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">effectiveness</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">determine</governor>
          <dependent id="9">effectiveness</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">system</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">system</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">system</governor>
          <dependent id="12">police</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">system</governor>
          <dependent id="13">discipline</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">effectiveness</governor>
          <dependent id="14">system</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="42" has_coreference="false">
      <content>A system can be theoretically sound, but it must be respected by the public.</content>
      <tokens>
        <token id="1" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="system" lemma="system" stem="system" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="theoretically" lemma="theoretically" stem="theoret" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="sound" lemma="sound" stem="sound" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="must" lemma="must" stem="must" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="respected" lemma="respect" stem="respect" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="public" lemma="public" stem="public" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (DT A) (NN system)) (VP (MD can) (VP (VB be) (ADJP (RB theoretically) (JJ sound))))) (, ,) (CC but) (S (NP (PRP it)) (VP (MD must) (VP (VB be) (VP (VBN respected) (PP (IN by) (NP (DT the) (NN public))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="can be theoretically sound" type="VP">
          <tokens>
            <token id="3" string="can" />
            <token id="4" string="be" />
            <token id="5" string="theoretically" />
            <token id="6" string="sound" />
          </tokens>
        </chunking>
        <chunking id="2" string="be respected by the public" type="VP">
          <tokens>
            <token id="11" string="be" />
            <token id="12" string="respected" />
            <token id="13" string="by" />
            <token id="14" string="the" />
            <token id="15" string="public" />
          </tokens>
        </chunking>
        <chunking id="3" string="theoretically sound" type="ADJP">
          <tokens>
            <token id="5" string="theoretically" />
            <token id="6" string="sound" />
          </tokens>
        </chunking>
        <chunking id="4" string="the public" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="public" />
          </tokens>
        </chunking>
        <chunking id="5" string="it" type="NP">
          <tokens>
            <token id="9" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="respected by the public" type="VP">
          <tokens>
            <token id="12" string="respected" />
            <token id="13" string="by" />
            <token id="14" string="the" />
            <token id="15" string="public" />
          </tokens>
        </chunking>
        <chunking id="7" string="A system" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="system" />
          </tokens>
        </chunking>
        <chunking id="8" string="be theoretically sound" type="VP">
          <tokens>
            <token id="4" string="be" />
            <token id="5" string="theoretically" />
            <token id="6" string="sound" />
          </tokens>
        </chunking>
        <chunking id="9" string="must be respected by the public" type="VP">
          <tokens>
            <token id="10" string="must" />
            <token id="11" string="be" />
            <token id="12" string="respected" />
            <token id="13" string="by" />
            <token id="14" string="the" />
            <token id="15" string="public" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">system</governor>
          <dependent id="1">A</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">sound</governor>
          <dependent id="2">system</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">sound</governor>
          <dependent id="3">can</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">sound</governor>
          <dependent id="4">be</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">sound</governor>
          <dependent id="5">theoretically</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">sound</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">sound</governor>
          <dependent id="8">but</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="12">respected</governor>
          <dependent id="9">it</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">respected</governor>
          <dependent id="10">must</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="12">respected</governor>
          <dependent id="11">be</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">sound</governor>
          <dependent id="12">respected</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">public</governor>
          <dependent id="13">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">public</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">respected</governor>
          <dependent id="15">public</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="43" has_coreference="true">
      <content>I agree with Councilwoman Blanca Alvarado&amp;apost;s suggestion and the San Jose City Council&amp;apost;s decision to create a system where a city official will receive and track citizen complaints about the police.</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="agree" lemma="agree" stem="agre" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Councilwoman" lemma="councilwoman" stem="councilwoman" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="Blanca" lemma="Blanca" stem="blanca" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="6" string="Alvarado" lemma="Alvarado" stem="alvarado" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="7" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="suggestion" lemma="suggestion" stem="suggest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="San" lemma="San" stem="san" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="12" string="Jose" lemma="Jose" stem="jose" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="13" string="City" lemma="City" stem="citi" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="14" string="Council" lemma="Council" stem="council" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="15" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="decision" lemma="decision" stem="decis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="create" lemma="create" stem="creat" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="system" lemma="system" stem="system" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="where" lemma="where" stem="where" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="city" lemma="city" stem="citi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="official" lemma="official" stem="offici" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="receive" lemma="receive" stem="receiv" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="track" lemma="track" stem="track" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="citizen" lemma="citizen" stem="citizen" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="complaints" lemma="complaint" stem="complaint" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="33" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="34" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (VP (VBP agree) (PP (IN with) (NP (NP (NP (NN Councilwoman) (NNP Blanca) (NNP Alvarado) (POS 's)) (NN suggestion)) (CC and) (NP (NP (DT the) (NNP San) (NNP Jose) (NNP City) (NNP Council) (POS 's)) (NN decision)))) (S (VP (TO to) (VP (VB create) (NP (DT a) (NN system)) (SBAR (WHADVP (WRB where)) (S (NP (DT a) (NN city) (NN official)) (VP (MD will) (VP (VB receive) (CC and) (VB track) (NP (NN citizen) (NNS complaints)) (PP (IN about) (NP (DT the) (NN police))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Councilwoman Blanca Alvarado 's" type="NP">
          <tokens>
            <token id="4" string="Councilwoman" />
            <token id="5" string="Blanca" />
            <token id="6" string="Alvarado" />
            <token id="7" string="'s" />
          </tokens>
        </chunking>
        <chunking id="2" string="citizen complaints" type="NP">
          <tokens>
            <token id="29" string="citizen" />
            <token id="30" string="complaints" />
          </tokens>
        </chunking>
        <chunking id="3" string="agree with Councilwoman Blanca Alvarado 's suggestion and the San Jose City Council 's decision to create a system where a city official will receive and track citizen complaints about the police" type="VP">
          <tokens>
            <token id="2" string="agree" />
            <token id="3" string="with" />
            <token id="4" string="Councilwoman" />
            <token id="5" string="Blanca" />
            <token id="6" string="Alvarado" />
            <token id="7" string="'s" />
            <token id="8" string="suggestion" />
            <token id="9" string="and" />
            <token id="10" string="the" />
            <token id="11" string="San" />
            <token id="12" string="Jose" />
            <token id="13" string="City" />
            <token id="14" string="Council" />
            <token id="15" string="'s" />
            <token id="16" string="decision" />
            <token id="17" string="to" />
            <token id="18" string="create" />
            <token id="19" string="a" />
            <token id="20" string="system" />
            <token id="21" string="where" />
            <token id="22" string="a" />
            <token id="23" string="city" />
            <token id="24" string="official" />
            <token id="25" string="will" />
            <token id="26" string="receive" />
            <token id="27" string="and" />
            <token id="28" string="track" />
            <token id="29" string="citizen" />
            <token id="30" string="complaints" />
            <token id="31" string="about" />
            <token id="32" string="the" />
            <token id="33" string="police" />
          </tokens>
        </chunking>
        <chunking id="4" string="receive and track citizen complaints about the police" type="VP">
          <tokens>
            <token id="26" string="receive" />
            <token id="27" string="and" />
            <token id="28" string="track" />
            <token id="29" string="citizen" />
            <token id="30" string="complaints" />
            <token id="31" string="about" />
            <token id="32" string="the" />
            <token id="33" string="police" />
          </tokens>
        </chunking>
        <chunking id="5" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="6" string="will receive and track citizen complaints about the police" type="VP">
          <tokens>
            <token id="25" string="will" />
            <token id="26" string="receive" />
            <token id="27" string="and" />
            <token id="28" string="track" />
            <token id="29" string="citizen" />
            <token id="30" string="complaints" />
            <token id="31" string="about" />
            <token id="32" string="the" />
            <token id="33" string="police" />
          </tokens>
        </chunking>
        <chunking id="7" string="a city official" type="NP">
          <tokens>
            <token id="22" string="a" />
            <token id="23" string="city" />
            <token id="24" string="official" />
          </tokens>
        </chunking>
        <chunking id="8" string="the police" type="NP">
          <tokens>
            <token id="32" string="the" />
            <token id="33" string="police" />
          </tokens>
        </chunking>
        <chunking id="9" string="the San Jose City Council 's" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="San" />
            <token id="12" string="Jose" />
            <token id="13" string="City" />
            <token id="14" string="Council" />
            <token id="15" string="'s" />
          </tokens>
        </chunking>
        <chunking id="10" string="where a city official will receive and track citizen complaints about the police" type="SBAR">
          <tokens>
            <token id="21" string="where" />
            <token id="22" string="a" />
            <token id="23" string="city" />
            <token id="24" string="official" />
            <token id="25" string="will" />
            <token id="26" string="receive" />
            <token id="27" string="and" />
            <token id="28" string="track" />
            <token id="29" string="citizen" />
            <token id="30" string="complaints" />
            <token id="31" string="about" />
            <token id="32" string="the" />
            <token id="33" string="police" />
          </tokens>
        </chunking>
        <chunking id="11" string="create a system where a city official will receive and track citizen complaints about the police" type="VP">
          <tokens>
            <token id="18" string="create" />
            <token id="19" string="a" />
            <token id="20" string="system" />
            <token id="21" string="where" />
            <token id="22" string="a" />
            <token id="23" string="city" />
            <token id="24" string="official" />
            <token id="25" string="will" />
            <token id="26" string="receive" />
            <token id="27" string="and" />
            <token id="28" string="track" />
            <token id="29" string="citizen" />
            <token id="30" string="complaints" />
            <token id="31" string="about" />
            <token id="32" string="the" />
            <token id="33" string="police" />
          </tokens>
        </chunking>
        <chunking id="12" string="a system" type="NP">
          <tokens>
            <token id="19" string="a" />
            <token id="20" string="system" />
          </tokens>
        </chunking>
        <chunking id="13" string="to create a system where a city official will receive and track citizen complaints about the police" type="VP">
          <tokens>
            <token id="17" string="to" />
            <token id="18" string="create" />
            <token id="19" string="a" />
            <token id="20" string="system" />
            <token id="21" string="where" />
            <token id="22" string="a" />
            <token id="23" string="city" />
            <token id="24" string="official" />
            <token id="25" string="will" />
            <token id="26" string="receive" />
            <token id="27" string="and" />
            <token id="28" string="track" />
            <token id="29" string="citizen" />
            <token id="30" string="complaints" />
            <token id="31" string="about" />
            <token id="32" string="the" />
            <token id="33" string="police" />
          </tokens>
        </chunking>
        <chunking id="14" string="Councilwoman Blanca Alvarado 's suggestion" type="NP">
          <tokens>
            <token id="4" string="Councilwoman" />
            <token id="5" string="Blanca" />
            <token id="6" string="Alvarado" />
            <token id="7" string="'s" />
            <token id="8" string="suggestion" />
          </tokens>
        </chunking>
        <chunking id="15" string="where" type="WHADVP">
          <tokens>
            <token id="21" string="where" />
          </tokens>
        </chunking>
        <chunking id="16" string="the San Jose City Council 's decision" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="San" />
            <token id="12" string="Jose" />
            <token id="13" string="City" />
            <token id="14" string="Council" />
            <token id="15" string="'s" />
            <token id="16" string="decision" />
          </tokens>
        </chunking>
        <chunking id="17" string="Councilwoman Blanca Alvarado 's suggestion and the San Jose City Council 's decision" type="NP">
          <tokens>
            <token id="4" string="Councilwoman" />
            <token id="5" string="Blanca" />
            <token id="6" string="Alvarado" />
            <token id="7" string="'s" />
            <token id="8" string="suggestion" />
            <token id="9" string="and" />
            <token id="10" string="the" />
            <token id="11" string="San" />
            <token id="12" string="Jose" />
            <token id="13" string="City" />
            <token id="14" string="Council" />
            <token id="15" string="'s" />
            <token id="16" string="decision" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">agree</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">agree</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">suggestion</governor>
          <dependent id="3">with</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Alvarado</governor>
          <dependent id="4">Councilwoman</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Alvarado</governor>
          <dependent id="5">Blanca</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">suggestion</governor>
          <dependent id="6">Alvarado</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">Alvarado</governor>
          <dependent id="7">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">agree</governor>
          <dependent id="8">suggestion</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">suggestion</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">Council</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Council</governor>
          <dependent id="11">San</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Council</governor>
          <dependent id="12">Jose</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Council</governor>
          <dependent id="13">City</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="16">decision</governor>
          <dependent id="14">Council</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">Council</governor>
          <dependent id="15">'s</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">suggestion</governor>
          <dependent id="16">decision</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">create</governor>
          <dependent id="17">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="2">agree</governor>
          <dependent id="18">create</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">system</governor>
          <dependent id="19">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">create</governor>
          <dependent id="20">system</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="26">receive</governor>
          <dependent id="21">where</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">official</governor>
          <dependent id="22">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">official</governor>
          <dependent id="23">city</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">receive</governor>
          <dependent id="24">official</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="26">receive</governor>
          <dependent id="25">will</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="18">create</governor>
          <dependent id="26">receive</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="26">receive</governor>
          <dependent id="27">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="26">receive</governor>
          <dependent id="28">track</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="30">complaints</governor>
          <dependent id="29">citizen</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="26">receive</governor>
          <dependent id="30">complaints</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">police</governor>
          <dependent id="31">about</dependent>
        </dependency>
        <dependency type="det">
          <governor id="33">police</governor>
          <dependent id="32">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">receive</governor>
          <dependent id="33">police</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="San Jose City Council" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="11" string="San" />
            <token id="12" string="Jose" />
            <token id="13" string="City" />
            <token id="14" string="Council" />
          </tokens>
        </entity>
        <entity id="2" string="Blanca Alvarado" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Blanca" />
            <token id="6" string="Alvarado" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="44" has_coreference="false">
      <content>I would further recommend that local communities establish citizen review boards.</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="further" lemma="further" stem="further" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="recommend" lemma="recommend" stem="recommend" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="local" lemma="local" stem="local" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="communities" lemma="community" stem="commun" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="establish" lemma="establish" stem="establish" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="citizen" lemma="citizen" stem="citizen" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="review" lemma="review" stem="review" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="boards" lemma="board" stem="board" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (VP (MD would) (ADVP (RB further)) (VP (VB recommend) (SBAR (IN that) (S (NP (JJ local) (NNS communities)) (VP (VBP establish) (NP (NN citizen) (NN review) (NNS boards))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="local communities" type="NP">
          <tokens>
            <token id="6" string="local" />
            <token id="7" string="communities" />
          </tokens>
        </chunking>
        <chunking id="2" string="recommend that local communities establish citizen review boards" type="VP">
          <tokens>
            <token id="4" string="recommend" />
            <token id="5" string="that" />
            <token id="6" string="local" />
            <token id="7" string="communities" />
            <token id="8" string="establish" />
            <token id="9" string="citizen" />
            <token id="10" string="review" />
            <token id="11" string="boards" />
          </tokens>
        </chunking>
        <chunking id="3" string="that local communities establish citizen review boards" type="SBAR">
          <tokens>
            <token id="5" string="that" />
            <token id="6" string="local" />
            <token id="7" string="communities" />
            <token id="8" string="establish" />
            <token id="9" string="citizen" />
            <token id="10" string="review" />
            <token id="11" string="boards" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="would further recommend that local communities establish citizen review boards" type="VP">
          <tokens>
            <token id="2" string="would" />
            <token id="3" string="further" />
            <token id="4" string="recommend" />
            <token id="5" string="that" />
            <token id="6" string="local" />
            <token id="7" string="communities" />
            <token id="8" string="establish" />
            <token id="9" string="citizen" />
            <token id="10" string="review" />
            <token id="11" string="boards" />
          </tokens>
        </chunking>
        <chunking id="6" string="citizen review boards" type="NP">
          <tokens>
            <token id="9" string="citizen" />
            <token id="10" string="review" />
            <token id="11" string="boards" />
          </tokens>
        </chunking>
        <chunking id="7" string="establish citizen review boards" type="VP">
          <tokens>
            <token id="8" string="establish" />
            <token id="9" string="citizen" />
            <token id="10" string="review" />
            <token id="11" string="boards" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">recommend</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">recommend</governor>
          <dependent id="2">would</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">recommend</governor>
          <dependent id="3">further</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">recommend</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">establish</governor>
          <dependent id="5">that</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">communities</governor>
          <dependent id="6">local</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">establish</governor>
          <dependent id="7">communities</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">recommend</governor>
          <dependent id="8">establish</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">boards</governor>
          <dependent id="9">citizen</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">boards</governor>
          <dependent id="10">review</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">establish</governor>
          <dependent id="11">boards</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="45" has_coreference="true">
      <content>Police accountability includes the right of the public to review records of investigations of complaints.</content>
      <tokens>
        <token id="1" string="Police" lemma="Police" stem="polic" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="accountability" lemma="accountability" stem="account" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="includes" lemma="include" stem="includ" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="right" lemma="right" stem="right" pos="NN" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="public" lemma="public" stem="public" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="review" lemma="review" stem="review" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="records" lemma="record" stem="record" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="investigations" lemma="investigation" stem="investig" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="complaints" lemma="complaint" stem="complaint" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Police) (NN accountability)) (VP (VBZ includes) (S (NP (NP (DT the) (NN right)) (PP (IN of) (NP (DT the) (JJ public)))) (VP (TO to) (VP (VB review) (NP (NP (NNS records)) (PP (IN of) (NP (NP (NNS investigations)) (PP (IN of) (NP (NNS complaints)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Police accountability" type="NP">
          <tokens>
            <token id="1" string="Police" />
            <token id="2" string="accountability" />
          </tokens>
        </chunking>
        <chunking id="2" string="includes the right of the public to review records of investigations of complaints" type="VP">
          <tokens>
            <token id="3" string="includes" />
            <token id="4" string="the" />
            <token id="5" string="right" />
            <token id="6" string="of" />
            <token id="7" string="the" />
            <token id="8" string="public" />
            <token id="9" string="to" />
            <token id="10" string="review" />
            <token id="11" string="records" />
            <token id="12" string="of" />
            <token id="13" string="investigations" />
            <token id="14" string="of" />
            <token id="15" string="complaints" />
          </tokens>
        </chunking>
        <chunking id="3" string="records" type="NP">
          <tokens>
            <token id="11" string="records" />
          </tokens>
        </chunking>
        <chunking id="4" string="the public" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="public" />
          </tokens>
        </chunking>
        <chunking id="5" string="investigations of complaints" type="NP">
          <tokens>
            <token id="13" string="investigations" />
            <token id="14" string="of" />
            <token id="15" string="complaints" />
          </tokens>
        </chunking>
        <chunking id="6" string="complaints" type="NP">
          <tokens>
            <token id="15" string="complaints" />
          </tokens>
        </chunking>
        <chunking id="7" string="the right" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="right" />
          </tokens>
        </chunking>
        <chunking id="8" string="review records of investigations of complaints" type="VP">
          <tokens>
            <token id="10" string="review" />
            <token id="11" string="records" />
            <token id="12" string="of" />
            <token id="13" string="investigations" />
            <token id="14" string="of" />
            <token id="15" string="complaints" />
          </tokens>
        </chunking>
        <chunking id="9" string="investigations" type="NP">
          <tokens>
            <token id="13" string="investigations" />
          </tokens>
        </chunking>
        <chunking id="10" string="the right of the public" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="right" />
            <token id="6" string="of" />
            <token id="7" string="the" />
            <token id="8" string="public" />
          </tokens>
        </chunking>
        <chunking id="11" string="to review records of investigations of complaints" type="VP">
          <tokens>
            <token id="9" string="to" />
            <token id="10" string="review" />
            <token id="11" string="records" />
            <token id="12" string="of" />
            <token id="13" string="investigations" />
            <token id="14" string="of" />
            <token id="15" string="complaints" />
          </tokens>
        </chunking>
        <chunking id="12" string="records of investigations of complaints" type="NP">
          <tokens>
            <token id="11" string="records" />
            <token id="12" string="of" />
            <token id="13" string="investigations" />
            <token id="14" string="of" />
            <token id="15" string="complaints" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">accountability</governor>
          <dependent id="1">Police</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">includes</governor>
          <dependent id="2">accountability</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">includes</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">right</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">includes</governor>
          <dependent id="5">right</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">public</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">public</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">right</governor>
          <dependent id="8">public</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">review</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">includes</governor>
          <dependent id="10">review</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">review</governor>
          <dependent id="11">records</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">investigations</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">records</governor>
          <dependent id="13">investigations</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">complaints</governor>
          <dependent id="14">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">investigations</governor>
          <dependent id="15">complaints</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="right" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="5" string="right" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="46" has_coreference="false">
      <content>Any loss of police confidentiality is a fair and necessary trade-off for the right to carry and use a club.</content>
      <tokens>
        <token id="1" string="Any" lemma="any" stem="any" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="loss" lemma="loss" stem="loss" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="confidentiality" lemma="confidentiality" stem="confidenti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="fair" lemma="fair" stem="fair" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="necessary" lemma="necessary" stem="necessari" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="trade-off" lemma="trade-off" stem="trade-off" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="right" lemma="right" stem="right" pos="NN" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="carry" lemma="carry" stem="carri" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="use" lemma="use" stem="us" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="club" lemma="club" stem="club" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT Any) (NN loss)) (PP (IN of) (NP (NN police) (NN confidentiality)))) (VP (VBZ is) (NP (NP (DT a) (ADJP (JJ fair) (CC and) (JJ necessary)) (NN trade-off)) (PP (IN for) (NP (DT the) (NN right) (S (VP (TO to) (VP (VB carry) (CC and) (VB use) (NP (DT a) (NN club))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="fair and necessary" type="ADJP">
          <tokens>
            <token id="8" string="fair" />
            <token id="9" string="and" />
            <token id="10" string="necessary" />
          </tokens>
        </chunking>
        <chunking id="2" string="the right to carry and use a club" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="right" />
            <token id="15" string="to" />
            <token id="16" string="carry" />
            <token id="17" string="and" />
            <token id="18" string="use" />
            <token id="19" string="a" />
            <token id="20" string="club" />
          </tokens>
        </chunking>
        <chunking id="3" string="a club" type="NP">
          <tokens>
            <token id="19" string="a" />
            <token id="20" string="club" />
          </tokens>
        </chunking>
        <chunking id="4" string="a fair and necessary trade-off for the right to carry and use a club" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="fair" />
            <token id="9" string="and" />
            <token id="10" string="necessary" />
            <token id="11" string="trade-off" />
            <token id="12" string="for" />
            <token id="13" string="the" />
            <token id="14" string="right" />
            <token id="15" string="to" />
            <token id="16" string="carry" />
            <token id="17" string="and" />
            <token id="18" string="use" />
            <token id="19" string="a" />
            <token id="20" string="club" />
          </tokens>
        </chunking>
        <chunking id="5" string="a fair and necessary trade-off" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="fair" />
            <token id="9" string="and" />
            <token id="10" string="necessary" />
            <token id="11" string="trade-off" />
          </tokens>
        </chunking>
        <chunking id="6" string="to carry and use a club" type="VP">
          <tokens>
            <token id="15" string="to" />
            <token id="16" string="carry" />
            <token id="17" string="and" />
            <token id="18" string="use" />
            <token id="19" string="a" />
            <token id="20" string="club" />
          </tokens>
        </chunking>
        <chunking id="7" string="police confidentiality" type="NP">
          <tokens>
            <token id="4" string="police" />
            <token id="5" string="confidentiality" />
          </tokens>
        </chunking>
        <chunking id="8" string="is a fair and necessary trade-off for the right to carry and use a club" type="VP">
          <tokens>
            <token id="6" string="is" />
            <token id="7" string="a" />
            <token id="8" string="fair" />
            <token id="9" string="and" />
            <token id="10" string="necessary" />
            <token id="11" string="trade-off" />
            <token id="12" string="for" />
            <token id="13" string="the" />
            <token id="14" string="right" />
            <token id="15" string="to" />
            <token id="16" string="carry" />
            <token id="17" string="and" />
            <token id="18" string="use" />
            <token id="19" string="a" />
            <token id="20" string="club" />
          </tokens>
        </chunking>
        <chunking id="9" string="Any loss of police confidentiality" type="NP">
          <tokens>
            <token id="1" string="Any" />
            <token id="2" string="loss" />
            <token id="3" string="of" />
            <token id="4" string="police" />
            <token id="5" string="confidentiality" />
          </tokens>
        </chunking>
        <chunking id="10" string="carry and use a club" type="VP">
          <tokens>
            <token id="16" string="carry" />
            <token id="17" string="and" />
            <token id="18" string="use" />
            <token id="19" string="a" />
            <token id="20" string="club" />
          </tokens>
        </chunking>
        <chunking id="11" string="Any loss" type="NP">
          <tokens>
            <token id="1" string="Any" />
            <token id="2" string="loss" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">loss</governor>
          <dependent id="1">Any</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">trade-off</governor>
          <dependent id="2">loss</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">confidentiality</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">confidentiality</governor>
          <dependent id="4">police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">loss</governor>
          <dependent id="5">confidentiality</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="11">trade-off</governor>
          <dependent id="6">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">trade-off</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">trade-off</governor>
          <dependent id="8">fair</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">fair</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">fair</governor>
          <dependent id="10">necessary</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">trade-off</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">right</governor>
          <dependent id="12">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">right</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">trade-off</governor>
          <dependent id="14">right</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">carry</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="14">right</governor>
          <dependent id="16">carry</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="16">carry</governor>
          <dependent id="17">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">carry</governor>
          <dependent id="18">use</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">club</governor>
          <dependent id="19">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">carry</governor>
          <dependent id="20">club</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="right" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="14" string="right" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="47" has_coreference="false">
      <content>Or a .45.</content>
      <tokens>
        <token id="1" string="Or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string=".45" lemma=".45" stem=".45" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="4" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (FRAG (CC Or) (SBAR (WHNP (DT a)) (FRAG (NP (CD .45)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a .45" type="SBAR">
          <tokens>
            <token id="2" string="a" />
            <token id="3" string=".45" />
          </tokens>
        </chunking>
        <chunking id="2" string=".45" type="NP">
          <tokens>
            <token id="3" string=".45" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="3">.45</governor>
          <dependent id="1">Or</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="3">.45</governor>
          <dependent id="2">a</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">.45</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string=".45" type="NUMBER" score="0.0">
          <tokens>
            <token id="3" string=".45" />
          </tokens>
        </entity>
      </entities>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="1" type="PROPER">
      <referenced ids_tokens="1-2-3-4-5-6-7-8-9-10-11-12" string="CONSIDER THE following case : A suspect involved in a high-speed chase" id_sentence="1" />
      <mentions>
        <mention ids_tokens="1" string="He" id_sentence="2" />
        <mention ids_tokens="7" string="his" id_sentence="2" />
        <mention ids_tokens="10" string="his" id_sentence="2" />
      </mentions>
    </coreference>
    <coreference id="4" type="NOMINAL">
      <referenced ids_tokens="45-46" string="the face" id_sentence="1" />
      <mentions>
        <mention ids_tokens="10-11" string="his face" id_sentence="2" />
        <mention ids_tokens="30-31" string="his face" id_sentence="14" />
      </mentions>
    </coreference>
    <coreference id="6" type="NOMINAL">
      <referenced ids_tokens="1-2-3-4" string="The suspect , unconscious" id_sentence="3" />
      <mentions>
        <mention ids_tokens="3-4" string="the suspect" id_sentence="5" />
        <mention ids_tokens="9-11" string="the suspect's" id_sentence="6" />
        <mention ids_tokens="19" string="his" id_sentence="6" />
        <mention ids_tokens="23" string="he" id_sentence="6" />
        <mention ids_tokens="28" string="he" id_sentence="6" />
        <mention ids_tokens="5-6" string="the suspect" id_sentence="9" />
        <mention ids_tokens="1-2" string="The suspect" id_sentence="11" />
        <mention ids_tokens="15-16" string="the suspect" id_sentence="13" />
        <mention ids_tokens="9-17" string="the suspect , knelt on the suspect's stomach" id_sentence="14" />
        <mention ids_tokens="9-10" string="the suspect" id_sentence="14" />
        <mention ids_tokens="12-17" string="knelt on the suspect's stomach" id_sentence="14" />
        <mention ids_tokens="14-16" string="the suspect's" id_sentence="14" />
        <mention ids_tokens="20" string="him" id_sentence="14" />
        <mention ids_tokens="24" string="his" id_sentence="14" />
        <mention ids_tokens="28" string="him" id_sentence="14" />
        <mention ids_tokens="30" string="his" id_sentence="14" />
        <mention ids_tokens="5-6" string="the suspect" id_sentence="16" />
        <mention ids_tokens="14-15" string="the suspect" id_sentence="17" />
      </mentions>
    </coreference>
    <coreference id="8" type="PRONOMINAL">
      <referenced ids_tokens="1" string="I" id_sentence="5" />
      <mentions>
        <mention ids_tokens="15" string="my" id_sentence="20" />
        <mention ids_tokens="1" string="That" id_sentence="29" />
      </mentions>
    </coreference>
    <coreference id="9" type="NOMINAL">
      <referenced ids_tokens="1-2-3-4" string="The offending officer 's" id_sentence="6" />
      <mentions>
        <mention ids_tokens="1-3" string="The offending officer" id_sentence="19" />
      </mentions>
    </coreference>
    <coreference id="10" type="NOMINAL">
      <referenced ids_tokens="6-7" string="police brutality" id_sentence="7" />
      <mentions>
        <mention ids_tokens="14" string="it" id_sentence="37" />
      </mentions>
    </coreference>
    <coreference id="11" type="NOMINAL">
      <referenced ids_tokens="3-4-5" string="the back-up officers" id_sentence="8" />
      <mentions>
        <mention ids_tokens="14" string="officers" id_sentence="10" />
      </mentions>
    </coreference>
    <coreference id="13" type="NOMINAL">
      <referenced ids_tokens="2-3" string="four citizens" id_sentence="13" />
      <mentions>
        <mention ids_tokens="7-16" string="four citizens who observed the brutal beating of my client" id_sentence="20" />
      </mentions>
    </coreference>
    <coreference id="21" type="NOMINAL">
      <referenced ids_tokens="4-5-6-7-8-9-10-11-12-13-14-15" string="another problem : a police discipline system that is cloaked in secrecy" id_sentence="23" />
      <mentions>
        <mention ids_tokens="3-4" string="the problem" id_sentence="25" />
      </mentions>
    </coreference>
    <coreference id="22" type="NOMINAL">
      <referenced ids_tokens="7-8-9-10-11-12-13-14-15" string="a police discipline system that is cloaked in secrecy" id_sentence="23" />
      <mentions>
        <mention ids_tokens="11-14" string="the police discipline system" id_sentence="41" />
      </mentions>
    </coreference>
    <coreference id="23" type="PROPER">
      <referenced ids_tokens="1-2-3-4-5-6" string="San Jose Police Chief Joseph MacNamara" id_sentence="24" />
      <mentions>
        <mention ids_tokens="1" string="MacNamara" id_sentence="25" />
        <mention ids_tokens="1" string="He" id_sentence="26" />
        <mention ids_tokens="3" string="MacNamara" id_sentence="27" />
        <mention ids_tokens="2" string="MacNamara" id_sentence="35" />
      </mentions>
    </coreference>
    <coreference id="26" type="NOMINAL">
      <referenced ids_tokens="12-13-14" string="a citizens '" id_sentence="27" />
      <mentions>
        <mention ids_tokens="6-7" string="its citizens" id_sentence="33" />
        <mention ids_tokens="16" string="citizens" id_sentence="34" />
      </mentions>
    </coreference>
    <coreference id="27" type="NOMINAL">
      <referenced ids_tokens="1" string="This" id_sentence="32" />
      <mentions>
        <mention ids_tokens="6" string="its" id_sentence="33" />
      </mentions>
    </coreference>
    <coreference id="28" type="NOMINAL">
      <referenced ids_tokens="8-9" string="public servants" id_sentence="35" />
      <mentions>
        <mention ids_tokens="5" string="their" id_sentence="36" />
        <mention ids_tokens="13" string="themselves" id_sentence="38" />
        <mention ids_tokens="32-33" string="the police" id_sentence="43" />
      </mentions>
    </coreference>
    <coreference id="31" type="NOMINAL">
      <referenced ids_tokens="21-22" string="citizen complaints" id_sentence="37" />
      <mentions>
        <mention ids_tokens="15" string="complaints" id_sentence="45" />
      </mentions>
    </coreference>
  </coreferences>
</document>
