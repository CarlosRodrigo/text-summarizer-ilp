<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="AP890322-0010">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>Allegations of police racism and brutality have shaken this city that for decades has prided itself on a progressive attitude toward civil rights and a reputation for racial harmony.</content>
      <tokens>
        <token id="1" string="Allegations" lemma="allegation" stem="allegat" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="racism" lemma="racism" stem="racism" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="brutality" lemma="brutality" stem="brutal" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="shaken" lemma="shake" stem="shaken" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="city" lemma="city" stem="citi" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="decades" lemma="decade" stem="decad" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="14" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="prided" lemma="pride" stem="pride" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="itself" lemma="itself" stem="itself" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="progressive" lemma="progressive" stem="progress" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="attitude" lemma="attitude" stem="attitud" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="toward" lemma="toward" stem="toward" pos="IN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="civil" lemma="civil" stem="civil" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="rights" lemma="rights" stem="right" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="25" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="26" string="reputation" lemma="reputation" stem="reput" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="27" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="28" string="racial" lemma="racial" stem="racial" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="29" string="harmony" lemma="harmony" stem="harmoni" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNS Allegations)) (PP (IN of) (NP (NN police) (NN racism) (CC and) (NN brutality)))) (VP (VBP have) (VP (VBN shaken) (NP (NP (DT this) (NN city)) (SBAR (WHNP (WDT that)) (S (PP (IN for) (NP (NNS decades))) (VP (VBZ has) (VP (VBN prided) (NP (PRP itself)) (PP (IN on) (NP (NP (NP (DT a) (JJ progressive) (NN attitude)) (PP (IN toward) (NP (JJ civil) (NNS rights)))) (CC and) (NP (NP (DT a) (NN reputation)) (PP (IN for) (NP (JJ racial) (NN harmony))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="have shaken this city that for decades has prided itself on a progressive attitude toward civil rights and a reputation for racial harmony" type="VP">
          <tokens>
            <token id="7" string="have" />
            <token id="8" string="shaken" />
            <token id="9" string="this" />
            <token id="10" string="city" />
            <token id="11" string="that" />
            <token id="12" string="for" />
            <token id="13" string="decades" />
            <token id="14" string="has" />
            <token id="15" string="prided" />
            <token id="16" string="itself" />
            <token id="17" string="on" />
            <token id="18" string="a" />
            <token id="19" string="progressive" />
            <token id="20" string="attitude" />
            <token id="21" string="toward" />
            <token id="22" string="civil" />
            <token id="23" string="rights" />
            <token id="24" string="and" />
            <token id="25" string="a" />
            <token id="26" string="reputation" />
            <token id="27" string="for" />
            <token id="28" string="racial" />
            <token id="29" string="harmony" />
          </tokens>
        </chunking>
        <chunking id="2" string="Allegations of police racism and brutality" type="NP">
          <tokens>
            <token id="1" string="Allegations" />
            <token id="2" string="of" />
            <token id="3" string="police" />
            <token id="4" string="racism" />
            <token id="5" string="and" />
            <token id="6" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="3" string="a reputation" type="NP">
          <tokens>
            <token id="25" string="a" />
            <token id="26" string="reputation" />
          </tokens>
        </chunking>
        <chunking id="4" string="prided itself on a progressive attitude toward civil rights and a reputation for racial harmony" type="VP">
          <tokens>
            <token id="15" string="prided" />
            <token id="16" string="itself" />
            <token id="17" string="on" />
            <token id="18" string="a" />
            <token id="19" string="progressive" />
            <token id="20" string="attitude" />
            <token id="21" string="toward" />
            <token id="22" string="civil" />
            <token id="23" string="rights" />
            <token id="24" string="and" />
            <token id="25" string="a" />
            <token id="26" string="reputation" />
            <token id="27" string="for" />
            <token id="28" string="racial" />
            <token id="29" string="harmony" />
          </tokens>
        </chunking>
        <chunking id="5" string="a progressive attitude toward civil rights and a reputation for racial harmony" type="NP">
          <tokens>
            <token id="18" string="a" />
            <token id="19" string="progressive" />
            <token id="20" string="attitude" />
            <token id="21" string="toward" />
            <token id="22" string="civil" />
            <token id="23" string="rights" />
            <token id="24" string="and" />
            <token id="25" string="a" />
            <token id="26" string="reputation" />
            <token id="27" string="for" />
            <token id="28" string="racial" />
            <token id="29" string="harmony" />
          </tokens>
        </chunking>
        <chunking id="6" string="shaken this city that for decades has prided itself on a progressive attitude toward civil rights and a reputation for racial harmony" type="VP">
          <tokens>
            <token id="8" string="shaken" />
            <token id="9" string="this" />
            <token id="10" string="city" />
            <token id="11" string="that" />
            <token id="12" string="for" />
            <token id="13" string="decades" />
            <token id="14" string="has" />
            <token id="15" string="prided" />
            <token id="16" string="itself" />
            <token id="17" string="on" />
            <token id="18" string="a" />
            <token id="19" string="progressive" />
            <token id="20" string="attitude" />
            <token id="21" string="toward" />
            <token id="22" string="civil" />
            <token id="23" string="rights" />
            <token id="24" string="and" />
            <token id="25" string="a" />
            <token id="26" string="reputation" />
            <token id="27" string="for" />
            <token id="28" string="racial" />
            <token id="29" string="harmony" />
          </tokens>
        </chunking>
        <chunking id="7" string="a progressive attitude toward civil rights" type="NP">
          <tokens>
            <token id="18" string="a" />
            <token id="19" string="progressive" />
            <token id="20" string="attitude" />
            <token id="21" string="toward" />
            <token id="22" string="civil" />
            <token id="23" string="rights" />
          </tokens>
        </chunking>
        <chunking id="8" string="a progressive attitude" type="NP">
          <tokens>
            <token id="18" string="a" />
            <token id="19" string="progressive" />
            <token id="20" string="attitude" />
          </tokens>
        </chunking>
        <chunking id="9" string="that for decades has prided itself on a progressive attitude toward civil rights and a reputation for racial harmony" type="SBAR">
          <tokens>
            <token id="11" string="that" />
            <token id="12" string="for" />
            <token id="13" string="decades" />
            <token id="14" string="has" />
            <token id="15" string="prided" />
            <token id="16" string="itself" />
            <token id="17" string="on" />
            <token id="18" string="a" />
            <token id="19" string="progressive" />
            <token id="20" string="attitude" />
            <token id="21" string="toward" />
            <token id="22" string="civil" />
            <token id="23" string="rights" />
            <token id="24" string="and" />
            <token id="25" string="a" />
            <token id="26" string="reputation" />
            <token id="27" string="for" />
            <token id="28" string="racial" />
            <token id="29" string="harmony" />
          </tokens>
        </chunking>
        <chunking id="10" string="has prided itself on a progressive attitude toward civil rights and a reputation for racial harmony" type="VP">
          <tokens>
            <token id="14" string="has" />
            <token id="15" string="prided" />
            <token id="16" string="itself" />
            <token id="17" string="on" />
            <token id="18" string="a" />
            <token id="19" string="progressive" />
            <token id="20" string="attitude" />
            <token id="21" string="toward" />
            <token id="22" string="civil" />
            <token id="23" string="rights" />
            <token id="24" string="and" />
            <token id="25" string="a" />
            <token id="26" string="reputation" />
            <token id="27" string="for" />
            <token id="28" string="racial" />
            <token id="29" string="harmony" />
          </tokens>
        </chunking>
        <chunking id="11" string="a reputation for racial harmony" type="NP">
          <tokens>
            <token id="25" string="a" />
            <token id="26" string="reputation" />
            <token id="27" string="for" />
            <token id="28" string="racial" />
            <token id="29" string="harmony" />
          </tokens>
        </chunking>
        <chunking id="12" string="racial harmony" type="NP">
          <tokens>
            <token id="28" string="racial" />
            <token id="29" string="harmony" />
          </tokens>
        </chunking>
        <chunking id="13" string="police racism and brutality" type="NP">
          <tokens>
            <token id="3" string="police" />
            <token id="4" string="racism" />
            <token id="5" string="and" />
            <token id="6" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="14" string="civil rights" type="NP">
          <tokens>
            <token id="22" string="civil" />
            <token id="23" string="rights" />
          </tokens>
        </chunking>
        <chunking id="15" string="itself" type="NP">
          <tokens>
            <token id="16" string="itself" />
          </tokens>
        </chunking>
        <chunking id="16" string="this city" type="NP">
          <tokens>
            <token id="9" string="this" />
            <token id="10" string="city" />
          </tokens>
        </chunking>
        <chunking id="17" string="this city that for decades has prided itself on a progressive attitude toward civil rights and a reputation for racial harmony" type="NP">
          <tokens>
            <token id="9" string="this" />
            <token id="10" string="city" />
            <token id="11" string="that" />
            <token id="12" string="for" />
            <token id="13" string="decades" />
            <token id="14" string="has" />
            <token id="15" string="prided" />
            <token id="16" string="itself" />
            <token id="17" string="on" />
            <token id="18" string="a" />
            <token id="19" string="progressive" />
            <token id="20" string="attitude" />
            <token id="21" string="toward" />
            <token id="22" string="civil" />
            <token id="23" string="rights" />
            <token id="24" string="and" />
            <token id="25" string="a" />
            <token id="26" string="reputation" />
            <token id="27" string="for" />
            <token id="28" string="racial" />
            <token id="29" string="harmony" />
          </tokens>
        </chunking>
        <chunking id="18" string="decades" type="NP">
          <tokens>
            <token id="13" string="decades" />
          </tokens>
        </chunking>
        <chunking id="19" string="Allegations" type="NP">
          <tokens>
            <token id="1" string="Allegations" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="8">shaken</governor>
          <dependent id="1">Allegations</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">racism</governor>
          <dependent id="2">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">racism</governor>
          <dependent id="3">police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Allegations</governor>
          <dependent id="4">racism</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">racism</governor>
          <dependent id="5">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">racism</governor>
          <dependent id="6">brutality</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">shaken</governor>
          <dependent id="7">have</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">shaken</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">city</governor>
          <dependent id="9">this</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">shaken</governor>
          <dependent id="10">city</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">prided</governor>
          <dependent id="11">that</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">decades</governor>
          <dependent id="12">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">prided</governor>
          <dependent id="13">decades</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="15">prided</governor>
          <dependent id="14">has</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="10">city</governor>
          <dependent id="15">prided</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">prided</governor>
          <dependent id="16">itself</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">attitude</governor>
          <dependent id="17">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">attitude</governor>
          <dependent id="18">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">attitude</governor>
          <dependent id="19">progressive</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">prided</governor>
          <dependent id="20">attitude</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">rights</governor>
          <dependent id="21">toward</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">rights</governor>
          <dependent id="22">civil</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">attitude</governor>
          <dependent id="23">rights</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="20">attitude</governor>
          <dependent id="24">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">reputation</governor>
          <dependent id="25">a</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="20">attitude</governor>
          <dependent id="26">reputation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">harmony</governor>
          <dependent id="27">for</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="29">harmony</governor>
          <dependent id="28">racial</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">reputation</governor>
          <dependent id="29">harmony</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="decades" type="DURATION" score="0.0">
          <tokens>
            <token id="13" string="decades" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>The deaths of two blacks at a drug raid that went awry, followed 10 days later by a scuffle between police and blacks at a downtown hotel, touched off an outcry by minority leaders for an outside review of the department.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="deaths" lemma="death" stem="death" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="5" string="blacks" lemma="black" stem="black" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="drug" lemma="drug" stem="drug" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="raid" lemma="raid" stem="raid" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="went" lemma="go" stem="went" pos="VBD" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="awry" lemma="awry" stem="awri" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="followed" lemma="follow" stem="follow" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="10" lemma="10" stem="10" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="16" string="days" lemma="day" stem="dai" pos="NNS" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="17" string="later" lemma="later" stem="later" pos="RB" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="18" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="scuffle" lemma="scuffle" stem="scuffl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="between" lemma="between" stem="between" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="blacks" lemma="black" stem="black" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="27" string="downtown" lemma="downtown" stem="downtown" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="28" string="hotel" lemma="hotel" stem="hotel" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="29" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="touched" lemma="touch" stem="touch" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="off" lemma="off" stem="off" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="outcry" lemma="outcry" stem="outcri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="minority" lemma="minority" stem="minor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="leaders" lemma="leader" stem="leader" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="outside" lemma="outside" stem="outsid" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="review" lemma="review" stem="review" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="43" string="department" lemma="department" stem="depart" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="44" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (NNS deaths)) (PP (IN of) (NP (NP (CD two) (NNS blacks)) (PP (IN at) (NP (NP (DT a) (NN drug) (NN raid)) (SBAR (WHNP (WDT that)) (S (VP (VBD went) (ADVP (RB awry)))))))))) (, ,) (S (VP (VBD followed) (PP (ADVP (NP (CD 10) (NNS days)) (RB later)) (IN by) (NP (NP (DT a) (NN scuffle)) (PP (IN between) (NP (NN police) (CC and) (NNS blacks))))) (PP (IN at) (NP (DT a) (NN downtown) (NN hotel))))) (, ,) (VP (VBD touched) (PRT (RP off)) (NP (DT an) (NN outcry)) (PP (IN by) (NP (NN minority) (NNS leaders))) (PP (IN for) (NP (NP (DT an) (JJ outside) (NN review)) (PP (IN of) (NP (DT the) (NN department)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="that went awry" type="SBAR">
          <tokens>
            <token id="10" string="that" />
            <token id="11" string="went" />
            <token id="12" string="awry" />
          </tokens>
        </chunking>
        <chunking id="2" string="a drug raid" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="drug" />
            <token id="9" string="raid" />
          </tokens>
        </chunking>
        <chunking id="3" string="The deaths of two blacks at a drug raid that went awry" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="deaths" />
            <token id="3" string="of" />
            <token id="4" string="two" />
            <token id="5" string="blacks" />
            <token id="6" string="at" />
            <token id="7" string="a" />
            <token id="8" string="drug" />
            <token id="9" string="raid" />
            <token id="10" string="that" />
            <token id="11" string="went" />
            <token id="12" string="awry" />
          </tokens>
        </chunking>
        <chunking id="4" string="an outside review" type="NP">
          <tokens>
            <token id="38" string="an" />
            <token id="39" string="outside" />
            <token id="40" string="review" />
          </tokens>
        </chunking>
        <chunking id="5" string="a drug raid that went awry" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="drug" />
            <token id="9" string="raid" />
            <token id="10" string="that" />
            <token id="11" string="went" />
            <token id="12" string="awry" />
          </tokens>
        </chunking>
        <chunking id="6" string="two blacks at a drug raid that went awry" type="NP">
          <tokens>
            <token id="4" string="two" />
            <token id="5" string="blacks" />
            <token id="6" string="at" />
            <token id="7" string="a" />
            <token id="8" string="drug" />
            <token id="9" string="raid" />
            <token id="10" string="that" />
            <token id="11" string="went" />
            <token id="12" string="awry" />
          </tokens>
        </chunking>
        <chunking id="7" string="minority leaders" type="NP">
          <tokens>
            <token id="35" string="minority" />
            <token id="36" string="leaders" />
          </tokens>
        </chunking>
        <chunking id="8" string="a scuffle between police and blacks" type="NP">
          <tokens>
            <token id="19" string="a" />
            <token id="20" string="scuffle" />
            <token id="21" string="between" />
            <token id="22" string="police" />
            <token id="23" string="and" />
            <token id="24" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="9" string="an outcry" type="NP">
          <tokens>
            <token id="32" string="an" />
            <token id="33" string="outcry" />
          </tokens>
        </chunking>
        <chunking id="10" string="The deaths" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="deaths" />
          </tokens>
        </chunking>
        <chunking id="11" string="a scuffle" type="NP">
          <tokens>
            <token id="19" string="a" />
            <token id="20" string="scuffle" />
          </tokens>
        </chunking>
        <chunking id="12" string="touched off an outcry by minority leaders for an outside review of the department" type="VP">
          <tokens>
            <token id="30" string="touched" />
            <token id="31" string="off" />
            <token id="32" string="an" />
            <token id="33" string="outcry" />
            <token id="34" string="by" />
            <token id="35" string="minority" />
            <token id="36" string="leaders" />
            <token id="37" string="for" />
            <token id="38" string="an" />
            <token id="39" string="outside" />
            <token id="40" string="review" />
            <token id="41" string="of" />
            <token id="42" string="the" />
            <token id="43" string="department" />
          </tokens>
        </chunking>
        <chunking id="13" string="followed 10 days later by a scuffle between police and blacks at a downtown hotel" type="VP">
          <tokens>
            <token id="14" string="followed" />
            <token id="15" string="10" />
            <token id="16" string="days" />
            <token id="17" string="later" />
            <token id="18" string="by" />
            <token id="19" string="a" />
            <token id="20" string="scuffle" />
            <token id="21" string="between" />
            <token id="22" string="police" />
            <token id="23" string="and" />
            <token id="24" string="blacks" />
            <token id="25" string="at" />
            <token id="26" string="a" />
            <token id="27" string="downtown" />
            <token id="28" string="hotel" />
          </tokens>
        </chunking>
        <chunking id="14" string="the department" type="NP">
          <tokens>
            <token id="42" string="the" />
            <token id="43" string="department" />
          </tokens>
        </chunking>
        <chunking id="15" string="a downtown hotel" type="NP">
          <tokens>
            <token id="26" string="a" />
            <token id="27" string="downtown" />
            <token id="28" string="hotel" />
          </tokens>
        </chunking>
        <chunking id="16" string="two blacks" type="NP">
          <tokens>
            <token id="4" string="two" />
            <token id="5" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="17" string="10 days" type="NP">
          <tokens>
            <token id="15" string="10" />
            <token id="16" string="days" />
          </tokens>
        </chunking>
        <chunking id="18" string="police and blacks" type="NP">
          <tokens>
            <token id="22" string="police" />
            <token id="23" string="and" />
            <token id="24" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="19" string="went awry" type="VP">
          <tokens>
            <token id="11" string="went" />
            <token id="12" string="awry" />
          </tokens>
        </chunking>
        <chunking id="20" string="an outside review of the department" type="NP">
          <tokens>
            <token id="38" string="an" />
            <token id="39" string="outside" />
            <token id="40" string="review" />
            <token id="41" string="of" />
            <token id="42" string="the" />
            <token id="43" string="department" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">deaths</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="30">touched</governor>
          <dependent id="2">deaths</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">blacks</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="5">blacks</governor>
          <dependent id="4">two</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">deaths</governor>
          <dependent id="5">blacks</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">raid</governor>
          <dependent id="6">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">raid</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">raid</governor>
          <dependent id="8">drug</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">blacks</governor>
          <dependent id="9">raid</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">went</governor>
          <dependent id="10">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="9">raid</governor>
          <dependent id="11">went</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">went</governor>
          <dependent id="12">awry</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="30">touched</governor>
          <dependent id="14">followed</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="16">days</governor>
          <dependent id="15">10</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="17">later</governor>
          <dependent id="16">days</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="20">scuffle</governor>
          <dependent id="17">later</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">scuffle</governor>
          <dependent id="18">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">scuffle</governor>
          <dependent id="19">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">followed</governor>
          <dependent id="20">scuffle</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">police</governor>
          <dependent id="21">between</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">scuffle</governor>
          <dependent id="22">police</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="22">police</governor>
          <dependent id="23">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="22">police</governor>
          <dependent id="24">blacks</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">hotel</governor>
          <dependent id="25">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">hotel</governor>
          <dependent id="26">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">hotel</governor>
          <dependent id="27">downtown</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">followed</governor>
          <dependent id="28">hotel</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="30">touched</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="30">touched</governor>
          <dependent id="31">off</dependent>
        </dependency>
        <dependency type="det">
          <governor id="33">outcry</governor>
          <dependent id="32">an</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="30">touched</governor>
          <dependent id="33">outcry</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">leaders</governor>
          <dependent id="34">by</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="36">leaders</governor>
          <dependent id="35">minority</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">touched</governor>
          <dependent id="36">leaders</dependent>
        </dependency>
        <dependency type="case">
          <governor id="40">review</governor>
          <dependent id="37">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="40">review</governor>
          <dependent id="38">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="40">review</governor>
          <dependent id="39">outside</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">touched</governor>
          <dependent id="40">review</dependent>
        </dependency>
        <dependency type="case">
          <governor id="43">department</governor>
          <dependent id="41">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="43">department</governor>
          <dependent id="42">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="40">review</governor>
          <dependent id="43">department</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="4" string="two" />
          </tokens>
        </entity>
        <entity id="2" string="10 days later" type="DATE" score="0.0">
          <tokens>
            <token id="15" string="10" />
            <token id="16" string="days" />
            <token id="17" string="later" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>``It&amp;apost;s like a watch spring.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="watch" lemma="watch" stem="watch" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="spring" lemma="spring" stem="spring" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP It)) (VP (VBZ 's) (PP (IN like) (NP (DT a) (NN watch) (NN spring)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="'s like a watch spring" type="VP">
          <tokens>
            <token id="3" string="'s" />
            <token id="4" string="like" />
            <token id="5" string="a" />
            <token id="6" string="watch" />
            <token id="7" string="spring" />
          </tokens>
        </chunking>
        <chunking id="2" string="It" type="NP">
          <tokens>
            <token id="2" string="It" />
          </tokens>
        </chunking>
        <chunking id="3" string="a watch spring" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="watch" />
            <token id="7" string="spring" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="7">spring</governor>
          <dependent id="2">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">spring</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">spring</governor>
          <dependent id="4">like</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">spring</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">spring</governor>
          <dependent id="6">watch</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">spring</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="spring" type="DATE" score="0.0">
          <tokens>
            <token id="7" string="spring" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="false">
      <content>You can only wind the watch so tightly before it&amp;apost;s going to snap.</content>
      <tokens>
        <token id="1" string="You" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="only" lemma="only" stem="onli" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="wind" lemma="wind" stem="wind" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="watch" lemma="watch" stem="watch" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="so" lemma="so" stem="so" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="tightly" lemma="tightly" stem="tightli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="before" lemma="before" stem="befor" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="going" lemma="go" stem="go" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="snap" lemma="snap" stem="snap" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP You)) (VP (MD can) (ADVP (RB only)) (VP (VB wind) (NP (DT the) (NN watch)) (ADVP (ADVP (RB so) (RB tightly)) (SBAR (IN before) (S (NP (PRP it)) (VP (VBZ 's) (VP (VBG going) (S (VP (TO to) (VP (VB snap))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="can only wind the watch so tightly before it 's going to snap" type="VP">
          <tokens>
            <token id="2" string="can" />
            <token id="3" string="only" />
            <token id="4" string="wind" />
            <token id="5" string="the" />
            <token id="6" string="watch" />
            <token id="7" string="so" />
            <token id="8" string="tightly" />
            <token id="9" string="before" />
            <token id="10" string="it" />
            <token id="11" string="'s" />
            <token id="12" string="going" />
            <token id="13" string="to" />
            <token id="14" string="snap" />
          </tokens>
        </chunking>
        <chunking id="2" string="before it 's going to snap" type="SBAR">
          <tokens>
            <token id="9" string="before" />
            <token id="10" string="it" />
            <token id="11" string="'s" />
            <token id="12" string="going" />
            <token id="13" string="to" />
            <token id="14" string="snap" />
          </tokens>
        </chunking>
        <chunking id="3" string="wind the watch so tightly before it 's going to snap" type="VP">
          <tokens>
            <token id="4" string="wind" />
            <token id="5" string="the" />
            <token id="6" string="watch" />
            <token id="7" string="so" />
            <token id="8" string="tightly" />
            <token id="9" string="before" />
            <token id="10" string="it" />
            <token id="11" string="'s" />
            <token id="12" string="going" />
            <token id="13" string="to" />
            <token id="14" string="snap" />
          </tokens>
        </chunking>
        <chunking id="4" string="'s going to snap" type="VP">
          <tokens>
            <token id="11" string="'s" />
            <token id="12" string="going" />
            <token id="13" string="to" />
            <token id="14" string="snap" />
          </tokens>
        </chunking>
        <chunking id="5" string="going to snap" type="VP">
          <tokens>
            <token id="12" string="going" />
            <token id="13" string="to" />
            <token id="14" string="snap" />
          </tokens>
        </chunking>
        <chunking id="6" string="the watch" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="watch" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="10" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="to snap" type="VP">
          <tokens>
            <token id="13" string="to" />
            <token id="14" string="snap" />
          </tokens>
        </chunking>
        <chunking id="9" string="snap" type="VP">
          <tokens>
            <token id="14" string="snap" />
          </tokens>
        </chunking>
        <chunking id="10" string="You" type="NP">
          <tokens>
            <token id="1" string="You" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">wind</governor>
          <dependent id="1">You</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">wind</governor>
          <dependent id="2">can</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">wind</governor>
          <dependent id="3">only</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">wind</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">watch</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">wind</governor>
          <dependent id="6">watch</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">tightly</governor>
          <dependent id="7">so</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">wind</governor>
          <dependent id="8">tightly</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">going</governor>
          <dependent id="9">before</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">going</governor>
          <dependent id="10">it</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">going</governor>
          <dependent id="11">'s</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="8">tightly</governor>
          <dependent id="12">going</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">snap</governor>
          <dependent id="13">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="12">going</governor>
          <dependent id="14">snap</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>I think we&amp;apost;re approaching that breaking point,&amp;apost;&amp;apost; said Van Hayden, 25, a student who says police beat him at the hotel.</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="think" lemma="think" stem="think" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="'re" lemma="be" stem="'re" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="approaching" lemma="approach" stem="approach" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="breaking" lemma="break" stem="break" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="point" lemma="point" stem="point" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="Van" lemma="Van" stem="van" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="13" string="Hayden" lemma="Hayden" stem="hayden" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="25" lemma="25" stem="25" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="student" lemma="student" stem="student" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="beat" lemma="beat" stem="beat" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="26" string="hotel" lemma="hotel" stem="hotel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (S (NP (PRP I)) (VP (VBP think) (SBAR (S (NP (PRP we)) (VP (VBP 're) (VP (VBG approaching) (SBAR (IN that) (S (VP (VBG breaking) (NP (NN point))))))))))) (, ,) ('' '') (VP (VBD said)) (NP (NP (NNP Van) (NNP Hayden)) (, ,) (NP (NP (CD 25)) (, ,) (NP (NP (DT a) (NN student)) (SBAR (WHNP (WP who)) (S (VP (VBZ says) (SBAR (S (NP (NN police)) (VP (VBD beat) (NP (PRP him)) (PP (IN at) (NP (DT the) (NN hotel)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="25" type="NP">
          <tokens>
            <token id="15" string="25" />
          </tokens>
        </chunking>
        <chunking id="2" string="police beat him at the hotel" type="SBAR">
          <tokens>
            <token id="21" string="police" />
            <token id="22" string="beat" />
            <token id="23" string="him" />
            <token id="24" string="at" />
            <token id="25" string="the" />
            <token id="26" string="hotel" />
          </tokens>
        </chunking>
        <chunking id="3" string="beat him at the hotel" type="VP">
          <tokens>
            <token id="22" string="beat" />
            <token id="23" string="him" />
            <token id="24" string="at" />
            <token id="25" string="the" />
            <token id="26" string="hotel" />
          </tokens>
        </chunking>
        <chunking id="4" string="approaching that breaking point" type="VP">
          <tokens>
            <token id="5" string="approaching" />
            <token id="6" string="that" />
            <token id="7" string="breaking" />
            <token id="8" string="point" />
          </tokens>
        </chunking>
        <chunking id="5" string="Van Hayden" type="NP">
          <tokens>
            <token id="12" string="Van" />
            <token id="13" string="Hayden" />
          </tokens>
        </chunking>
        <chunking id="6" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="7" string="25 , a student who says police beat him at the hotel" type="NP">
          <tokens>
            <token id="15" string="25" />
            <token id="16" string="," />
            <token id="17" string="a" />
            <token id="18" string="student" />
            <token id="19" string="who" />
            <token id="20" string="says" />
            <token id="21" string="police" />
            <token id="22" string="beat" />
            <token id="23" string="him" />
            <token id="24" string="at" />
            <token id="25" string="the" />
            <token id="26" string="hotel" />
          </tokens>
        </chunking>
        <chunking id="8" string="a student" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="student" />
          </tokens>
        </chunking>
        <chunking id="9" string="him" type="NP">
          <tokens>
            <token id="23" string="him" />
          </tokens>
        </chunking>
        <chunking id="10" string="'re approaching that breaking point" type="VP">
          <tokens>
            <token id="4" string="'re" />
            <token id="5" string="approaching" />
            <token id="6" string="that" />
            <token id="7" string="breaking" />
            <token id="8" string="point" />
          </tokens>
        </chunking>
        <chunking id="11" string="breaking point" type="VP">
          <tokens>
            <token id="7" string="breaking" />
            <token id="8" string="point" />
          </tokens>
        </chunking>
        <chunking id="12" string="we" type="NP">
          <tokens>
            <token id="3" string="we" />
          </tokens>
        </chunking>
        <chunking id="13" string="Van Hayden , 25 , a student who says police beat him at the hotel" type="NP">
          <tokens>
            <token id="12" string="Van" />
            <token id="13" string="Hayden" />
            <token id="14" string="," />
            <token id="15" string="25" />
            <token id="16" string="," />
            <token id="17" string="a" />
            <token id="18" string="student" />
            <token id="19" string="who" />
            <token id="20" string="says" />
            <token id="21" string="police" />
            <token id="22" string="beat" />
            <token id="23" string="him" />
            <token id="24" string="at" />
            <token id="25" string="the" />
            <token id="26" string="hotel" />
          </tokens>
        </chunking>
        <chunking id="14" string="police" type="NP">
          <tokens>
            <token id="21" string="police" />
          </tokens>
        </chunking>
        <chunking id="15" string="point" type="NP">
          <tokens>
            <token id="8" string="point" />
          </tokens>
        </chunking>
        <chunking id="16" string="that breaking point" type="SBAR">
          <tokens>
            <token id="6" string="that" />
            <token id="7" string="breaking" />
            <token id="8" string="point" />
          </tokens>
        </chunking>
        <chunking id="17" string="a student who says police beat him at the hotel" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="student" />
            <token id="19" string="who" />
            <token id="20" string="says" />
            <token id="21" string="police" />
            <token id="22" string="beat" />
            <token id="23" string="him" />
            <token id="24" string="at" />
            <token id="25" string="the" />
            <token id="26" string="hotel" />
          </tokens>
        </chunking>
        <chunking id="18" string="who says police beat him at the hotel" type="SBAR">
          <tokens>
            <token id="19" string="who" />
            <token id="20" string="says" />
            <token id="21" string="police" />
            <token id="22" string="beat" />
            <token id="23" string="him" />
            <token id="24" string="at" />
            <token id="25" string="the" />
            <token id="26" string="hotel" />
          </tokens>
        </chunking>
        <chunking id="19" string="we 're approaching that breaking point" type="SBAR">
          <tokens>
            <token id="3" string="we" />
            <token id="4" string="'re" />
            <token id="5" string="approaching" />
            <token id="6" string="that" />
            <token id="7" string="breaking" />
            <token id="8" string="point" />
          </tokens>
        </chunking>
        <chunking id="20" string="says police beat him at the hotel" type="VP">
          <tokens>
            <token id="20" string="says" />
            <token id="21" string="police" />
            <token id="22" string="beat" />
            <token id="23" string="him" />
            <token id="24" string="at" />
            <token id="25" string="the" />
            <token id="26" string="hotel" />
          </tokens>
        </chunking>
        <chunking id="21" string="said" type="VP">
          <tokens>
            <token id="11" string="said" />
          </tokens>
        </chunking>
        <chunking id="22" string="the hotel" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="hotel" />
          </tokens>
        </chunking>
        <chunking id="23" string="think we 're approaching that breaking point" type="VP">
          <tokens>
            <token id="2" string="think" />
            <token id="3" string="we" />
            <token id="4" string="'re" />
            <token id="5" string="approaching" />
            <token id="6" string="that" />
            <token id="7" string="breaking" />
            <token id="8" string="point" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">think</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">said</governor>
          <dependent id="2">think</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">approaching</governor>
          <dependent id="3">we</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">approaching</governor>
          <dependent id="4">'re</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">think</governor>
          <dependent id="5">approaching</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">breaking</governor>
          <dependent id="6">that</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">approaching</governor>
          <dependent id="7">breaking</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">breaking</governor>
          <dependent id="8">point</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Hayden</governor>
          <dependent id="12">Van</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">said</governor>
          <dependent id="13">Hayden</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="13">Hayden</governor>
          <dependent id="15">25</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">student</governor>
          <dependent id="17">a</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="15">25</governor>
          <dependent id="18">student</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">says</governor>
          <dependent id="19">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="18">student</governor>
          <dependent id="20">says</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">beat</governor>
          <dependent id="21">police</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="20">says</governor>
          <dependent id="22">beat</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">beat</governor>
          <dependent id="23">him</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">hotel</governor>
          <dependent id="24">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">hotel</governor>
          <dependent id="25">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">beat</governor>
          <dependent id="26">hotel</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="25" type="NUMBER" score="0.0">
          <tokens>
            <token id="15" string="25" />
          </tokens>
        </entity>
        <entity id="2" string="Van Hayden" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Van" />
            <token id="13" string="Hayden" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>The city&amp;apost;s police chief, John Laux, says there is no reason to assume the department would be immune to a problem that is present in all segments of society.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="city" lemma="city" stem="citi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="chief" lemma="chief" stem="chief" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="8" string="Laux" lemma="Laux" stem="laux" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="reason" lemma="reason" stem="reason" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="assume" lemma="assume" stem="assum" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="department" lemma="department" stem="depart" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="immune" lemma="immune" stem="immun" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="24" string="problem" lemma="problem" stem="problem" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="25" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="26" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="27" string="present" lemma="present" stem="present" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="28" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="29" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="30" string="segments" lemma="segment" stem="segment" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="31" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="32" string="society" lemma="society" stem="societi" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NP (DT The) (NN city) (POS 's)) (NN police) (NN chief)) (, ,) (NP (NNP John) (NNP Laux)) (, ,)) (VP (VBZ says) (SBAR (S (NP (EX there)) (VP (VBZ is) (NP (DT no) (NN reason) (S (VP (TO to) (VP (VB assume) (SBAR (S (NP (DT the) (NN department)) (VP (MD would) (VP (VB be) (ADJP (JJ immune) (PP (TO to) (NP (NP (DT a) (NN problem)) (SBAR (WHNP (WDT that)) (S (VP (VBZ is) (ADJP (JJ present) (PP (IN in) (NP (NP (DT all) (NNS segments)) (PP (IN of) (NP (NN society)))))))))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="John Laux" type="NP">
          <tokens>
            <token id="7" string="John" />
            <token id="8" string="Laux" />
          </tokens>
        </chunking>
        <chunking id="2" string="no reason to assume the department would be immune to a problem that is present in all segments of society" type="NP">
          <tokens>
            <token id="13" string="no" />
            <token id="14" string="reason" />
            <token id="15" string="to" />
            <token id="16" string="assume" />
            <token id="17" string="the" />
            <token id="18" string="department" />
            <token id="19" string="would" />
            <token id="20" string="be" />
            <token id="21" string="immune" />
            <token id="22" string="to" />
            <token id="23" string="a" />
            <token id="24" string="problem" />
            <token id="25" string="that" />
            <token id="26" string="is" />
            <token id="27" string="present" />
            <token id="28" string="in" />
            <token id="29" string="all" />
            <token id="30" string="segments" />
            <token id="31" string="of" />
            <token id="32" string="society" />
          </tokens>
        </chunking>
        <chunking id="3" string="The city 's" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="city" />
            <token id="3" string="'s" />
          </tokens>
        </chunking>
        <chunking id="4" string="assume the department would be immune to a problem that is present in all segments of society" type="VP">
          <tokens>
            <token id="16" string="assume" />
            <token id="17" string="the" />
            <token id="18" string="department" />
            <token id="19" string="would" />
            <token id="20" string="be" />
            <token id="21" string="immune" />
            <token id="22" string="to" />
            <token id="23" string="a" />
            <token id="24" string="problem" />
            <token id="25" string="that" />
            <token id="26" string="is" />
            <token id="27" string="present" />
            <token id="28" string="in" />
            <token id="29" string="all" />
            <token id="30" string="segments" />
            <token id="31" string="of" />
            <token id="32" string="society" />
          </tokens>
        </chunking>
        <chunking id="5" string="be immune to a problem that is present in all segments of society" type="VP">
          <tokens>
            <token id="20" string="be" />
            <token id="21" string="immune" />
            <token id="22" string="to" />
            <token id="23" string="a" />
            <token id="24" string="problem" />
            <token id="25" string="that" />
            <token id="26" string="is" />
            <token id="27" string="present" />
            <token id="28" string="in" />
            <token id="29" string="all" />
            <token id="30" string="segments" />
            <token id="31" string="of" />
            <token id="32" string="society" />
          </tokens>
        </chunking>
        <chunking id="6" string="immune to a problem that is present in all segments of society" type="ADJP">
          <tokens>
            <token id="21" string="immune" />
            <token id="22" string="to" />
            <token id="23" string="a" />
            <token id="24" string="problem" />
            <token id="25" string="that" />
            <token id="26" string="is" />
            <token id="27" string="present" />
            <token id="28" string="in" />
            <token id="29" string="all" />
            <token id="30" string="segments" />
            <token id="31" string="of" />
            <token id="32" string="society" />
          </tokens>
        </chunking>
        <chunking id="7" string="there is no reason to assume the department would be immune to a problem that is present in all segments of society" type="SBAR">
          <tokens>
            <token id="11" string="there" />
            <token id="12" string="is" />
            <token id="13" string="no" />
            <token id="14" string="reason" />
            <token id="15" string="to" />
            <token id="16" string="assume" />
            <token id="17" string="the" />
            <token id="18" string="department" />
            <token id="19" string="would" />
            <token id="20" string="be" />
            <token id="21" string="immune" />
            <token id="22" string="to" />
            <token id="23" string="a" />
            <token id="24" string="problem" />
            <token id="25" string="that" />
            <token id="26" string="is" />
            <token id="27" string="present" />
            <token id="28" string="in" />
            <token id="29" string="all" />
            <token id="30" string="segments" />
            <token id="31" string="of" />
            <token id="32" string="society" />
          </tokens>
        </chunking>
        <chunking id="8" string="The city 's police chief , John Laux ," type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="city" />
            <token id="3" string="'s" />
            <token id="4" string="police" />
            <token id="5" string="chief" />
            <token id="6" string="," />
            <token id="7" string="John" />
            <token id="8" string="Laux" />
            <token id="9" string="," />
          </tokens>
        </chunking>
        <chunking id="9" string="to assume the department would be immune to a problem that is present in all segments of society" type="VP">
          <tokens>
            <token id="15" string="to" />
            <token id="16" string="assume" />
            <token id="17" string="the" />
            <token id="18" string="department" />
            <token id="19" string="would" />
            <token id="20" string="be" />
            <token id="21" string="immune" />
            <token id="22" string="to" />
            <token id="23" string="a" />
            <token id="24" string="problem" />
            <token id="25" string="that" />
            <token id="26" string="is" />
            <token id="27" string="present" />
            <token id="28" string="in" />
            <token id="29" string="all" />
            <token id="30" string="segments" />
            <token id="31" string="of" />
            <token id="32" string="society" />
          </tokens>
        </chunking>
        <chunking id="10" string="there" type="NP">
          <tokens>
            <token id="11" string="there" />
          </tokens>
        </chunking>
        <chunking id="11" string="that is present in all segments of society" type="SBAR">
          <tokens>
            <token id="25" string="that" />
            <token id="26" string="is" />
            <token id="27" string="present" />
            <token id="28" string="in" />
            <token id="29" string="all" />
            <token id="30" string="segments" />
            <token id="31" string="of" />
            <token id="32" string="society" />
          </tokens>
        </chunking>
        <chunking id="12" string="the department" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="department" />
          </tokens>
        </chunking>
        <chunking id="13" string="is present in all segments of society" type="VP">
          <tokens>
            <token id="26" string="is" />
            <token id="27" string="present" />
            <token id="28" string="in" />
            <token id="29" string="all" />
            <token id="30" string="segments" />
            <token id="31" string="of" />
            <token id="32" string="society" />
          </tokens>
        </chunking>
        <chunking id="14" string="says there is no reason to assume the department would be immune to a problem that is present in all segments of society" type="VP">
          <tokens>
            <token id="10" string="says" />
            <token id="11" string="there" />
            <token id="12" string="is" />
            <token id="13" string="no" />
            <token id="14" string="reason" />
            <token id="15" string="to" />
            <token id="16" string="assume" />
            <token id="17" string="the" />
            <token id="18" string="department" />
            <token id="19" string="would" />
            <token id="20" string="be" />
            <token id="21" string="immune" />
            <token id="22" string="to" />
            <token id="23" string="a" />
            <token id="24" string="problem" />
            <token id="25" string="that" />
            <token id="26" string="is" />
            <token id="27" string="present" />
            <token id="28" string="in" />
            <token id="29" string="all" />
            <token id="30" string="segments" />
            <token id="31" string="of" />
            <token id="32" string="society" />
          </tokens>
        </chunking>
        <chunking id="15" string="The city 's police chief" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="city" />
            <token id="3" string="'s" />
            <token id="4" string="police" />
            <token id="5" string="chief" />
          </tokens>
        </chunking>
        <chunking id="16" string="a problem that is present in all segments of society" type="NP">
          <tokens>
            <token id="23" string="a" />
            <token id="24" string="problem" />
            <token id="25" string="that" />
            <token id="26" string="is" />
            <token id="27" string="present" />
            <token id="28" string="in" />
            <token id="29" string="all" />
            <token id="30" string="segments" />
            <token id="31" string="of" />
            <token id="32" string="society" />
          </tokens>
        </chunking>
        <chunking id="17" string="would be immune to a problem that is present in all segments of society" type="VP">
          <tokens>
            <token id="19" string="would" />
            <token id="20" string="be" />
            <token id="21" string="immune" />
            <token id="22" string="to" />
            <token id="23" string="a" />
            <token id="24" string="problem" />
            <token id="25" string="that" />
            <token id="26" string="is" />
            <token id="27" string="present" />
            <token id="28" string="in" />
            <token id="29" string="all" />
            <token id="30" string="segments" />
            <token id="31" string="of" />
            <token id="32" string="society" />
          </tokens>
        </chunking>
        <chunking id="18" string="is no reason to assume the department would be immune to a problem that is present in all segments of society" type="VP">
          <tokens>
            <token id="12" string="is" />
            <token id="13" string="no" />
            <token id="14" string="reason" />
            <token id="15" string="to" />
            <token id="16" string="assume" />
            <token id="17" string="the" />
            <token id="18" string="department" />
            <token id="19" string="would" />
            <token id="20" string="be" />
            <token id="21" string="immune" />
            <token id="22" string="to" />
            <token id="23" string="a" />
            <token id="24" string="problem" />
            <token id="25" string="that" />
            <token id="26" string="is" />
            <token id="27" string="present" />
            <token id="28" string="in" />
            <token id="29" string="all" />
            <token id="30" string="segments" />
            <token id="31" string="of" />
            <token id="32" string="society" />
          </tokens>
        </chunking>
        <chunking id="19" string="all segments" type="NP">
          <tokens>
            <token id="29" string="all" />
            <token id="30" string="segments" />
          </tokens>
        </chunking>
        <chunking id="20" string="society" type="NP">
          <tokens>
            <token id="32" string="society" />
          </tokens>
        </chunking>
        <chunking id="21" string="the department would be immune to a problem that is present in all segments of society" type="SBAR">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="department" />
            <token id="19" string="would" />
            <token id="20" string="be" />
            <token id="21" string="immune" />
            <token id="22" string="to" />
            <token id="23" string="a" />
            <token id="24" string="problem" />
            <token id="25" string="that" />
            <token id="26" string="is" />
            <token id="27" string="present" />
            <token id="28" string="in" />
            <token id="29" string="all" />
            <token id="30" string="segments" />
            <token id="31" string="of" />
            <token id="32" string="society" />
          </tokens>
        </chunking>
        <chunking id="22" string="present in all segments of society" type="ADJP">
          <tokens>
            <token id="27" string="present" />
            <token id="28" string="in" />
            <token id="29" string="all" />
            <token id="30" string="segments" />
            <token id="31" string="of" />
            <token id="32" string="society" />
          </tokens>
        </chunking>
        <chunking id="23" string="all segments of society" type="NP">
          <tokens>
            <token id="29" string="all" />
            <token id="30" string="segments" />
            <token id="31" string="of" />
            <token id="32" string="society" />
          </tokens>
        </chunking>
        <chunking id="24" string="a problem" type="NP">
          <tokens>
            <token id="23" string="a" />
            <token id="24" string="problem" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">city</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">chief</governor>
          <dependent id="2">city</dependent>
        </dependency>
        <dependency type="case">
          <governor id="2">city</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">chief</governor>
          <dependent id="4">police</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">says</governor>
          <dependent id="5">chief</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">Laux</governor>
          <dependent id="7">John</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="5">chief</governor>
          <dependent id="8">Laux</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">says</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="12">is</governor>
          <dependent id="11">there</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">says</governor>
          <dependent id="12">is</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="14">reason</governor>
          <dependent id="13">no</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">is</governor>
          <dependent id="14">reason</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">assume</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="14">reason</governor>
          <dependent id="16">assume</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">department</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">immune</governor>
          <dependent id="18">department</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="21">immune</governor>
          <dependent id="19">would</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="21">immune</governor>
          <dependent id="20">be</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="16">assume</governor>
          <dependent id="21">immune</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">problem</governor>
          <dependent id="22">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">problem</governor>
          <dependent id="23">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">immune</governor>
          <dependent id="24">problem</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">present</governor>
          <dependent id="25">that</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="27">present</governor>
          <dependent id="26">is</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="24">problem</governor>
          <dependent id="27">present</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">segments</governor>
          <dependent id="28">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">segments</governor>
          <dependent id="29">all</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">present</governor>
          <dependent id="30">segments</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">society</governor>
          <dependent id="31">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">segments</governor>
          <dependent id="32">society</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="John Laux" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="John" />
            <token id="8" string="Laux" />
          </tokens>
        </entity>
        <entity id="2" string="present" type="DATE" score="0.0">
          <tokens>
            <token id="27" string="present" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>``The whole society to different degrees has problems of racism,&amp;apost;&amp;apost; he said.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="whole" lemma="whole" stem="whole" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="society" lemma="society" stem="societi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="different" lemma="different" stem="differ" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="degrees" lemma="degree" stem="degre" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="problems" lemma="problem" stem="problem" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="racism" lemma="racism" stem="racism" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (NP (DT The) (JJ whole) (NN society)) (PP (TO to) (NP (JJ different) (NNS degrees)))) (VP (VBZ has) (NP (NP (NNS problems)) (PP (IN of) (NP (NN racism)))))) (, ,) ('' '') (NP (PRP he)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="racism" type="NP">
          <tokens>
            <token id="11" string="racism" />
          </tokens>
        </chunking>
        <chunking id="2" string="problems of racism" type="NP">
          <tokens>
            <token id="9" string="problems" />
            <token id="10" string="of" />
            <token id="11" string="racism" />
          </tokens>
        </chunking>
        <chunking id="3" string="The whole society to different degrees" type="NP">
          <tokens>
            <token id="2" string="The" />
            <token id="3" string="whole" />
            <token id="4" string="society" />
            <token id="5" string="to" />
            <token id="6" string="different" />
            <token id="7" string="degrees" />
          </tokens>
        </chunking>
        <chunking id="4" string="has problems of racism" type="VP">
          <tokens>
            <token id="8" string="has" />
            <token id="9" string="problems" />
            <token id="10" string="of" />
            <token id="11" string="racism" />
          </tokens>
        </chunking>
        <chunking id="5" string="problems" type="NP">
          <tokens>
            <token id="9" string="problems" />
          </tokens>
        </chunking>
        <chunking id="6" string="he" type="NP">
          <tokens>
            <token id="14" string="he" />
          </tokens>
        </chunking>
        <chunking id="7" string="said" type="VP">
          <tokens>
            <token id="15" string="said" />
          </tokens>
        </chunking>
        <chunking id="8" string="The whole society" type="NP">
          <tokens>
            <token id="2" string="The" />
            <token id="3" string="whole" />
            <token id="4" string="society" />
          </tokens>
        </chunking>
        <chunking id="9" string="different degrees" type="NP">
          <tokens>
            <token id="6" string="different" />
            <token id="7" string="degrees" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="4">society</governor>
          <dependent id="2">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">society</governor>
          <dependent id="3">whole</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">has</governor>
          <dependent id="4">society</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">degrees</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">degrees</governor>
          <dependent id="6">different</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">society</governor>
          <dependent id="7">degrees</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="15">said</governor>
          <dependent id="8">has</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">has</governor>
          <dependent id="9">problems</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">racism</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">problems</governor>
          <dependent id="11">racism</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">said</governor>
          <dependent id="14">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">said</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>In a letter to police supervisors in mid-February, Laux said: ``Let me make one thing perfectly clear _ any act of bias will be dealt with directly and severely.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="letter" lemma="letter" stem="letter" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="supervisors" lemma="supervisor" stem="supervisor" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="mid-February" lemma="mid-february" stem="mid-februari" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Laux" lemma="Laux" stem="laux" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="11" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Let" lemma="let" stem="let" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="make" lemma="make" stem="make" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="18" string="thing" lemma="thing" stem="thing" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="perfectly" lemma="perfectly" stem="perfectli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="clear" lemma="clear" stem="clear" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="_" lemma="_" stem="_" pos="IN" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="any" lemma="any" stem="ani" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="act" lemma="act" stem="act" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="bias" lemma="bias" stem="bia" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="dealt" lemma="deal" stem="dealt" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="directly" lemma="directly" stem="directli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="severely" lemma="severely" stem="sever" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (NP (DT a) (NN letter)) (PP (TO to) (NP (NP (NN police) (NNS supervisors)) (PP (IN in) (NP (JJ mid-February))))))) (, ,) (NP (NNP Laux)) (VP (VBD said) (: :) (`` ``) (S (VP (VB Let) (S (NP (PRP me)) (VP (VB make) (S (NP (CD one) (NN thing)) (ADJP (RB perfectly) (JJ clear)) (SBAR (IN _) (S (NP (NP (DT any) (NN act)) (PP (IN of) (NP (NN bias)))) (VP (MD will) (VP (VB be) (VP (VBN dealt) (PP (IN with) (ADVP (RB directly) (CC and) (RB severely)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="one thing" type="NP">
          <tokens>
            <token id="17" string="one" />
            <token id="18" string="thing" />
          </tokens>
        </chunking>
        <chunking id="2" string="any act of bias" type="NP">
          <tokens>
            <token id="22" string="any" />
            <token id="23" string="act" />
            <token id="24" string="of" />
            <token id="25" string="bias" />
          </tokens>
        </chunking>
        <chunking id="3" string="police supervisors in mid-February" type="NP">
          <tokens>
            <token id="5" string="police" />
            <token id="6" string="supervisors" />
            <token id="7" string="in" />
            <token id="8" string="mid-February" />
          </tokens>
        </chunking>
        <chunking id="4" string="police supervisors" type="NP">
          <tokens>
            <token id="5" string="police" />
            <token id="6" string="supervisors" />
          </tokens>
        </chunking>
        <chunking id="5" string="a letter" type="NP">
          <tokens>
            <token id="2" string="a" />
            <token id="3" string="letter" />
          </tokens>
        </chunking>
        <chunking id="6" string="mid-February" type="NP">
          <tokens>
            <token id="8" string="mid-February" />
          </tokens>
        </chunking>
        <chunking id="7" string="_ any act of bias will be dealt with directly and severely" type="SBAR">
          <tokens>
            <token id="21" string="_" />
            <token id="22" string="any" />
            <token id="23" string="act" />
            <token id="24" string="of" />
            <token id="25" string="bias" />
            <token id="26" string="will" />
            <token id="27" string="be" />
            <token id="28" string="dealt" />
            <token id="29" string="with" />
            <token id="30" string="directly" />
            <token id="31" string="and" />
            <token id="32" string="severely" />
          </tokens>
        </chunking>
        <chunking id="8" string="dealt with directly and severely" type="VP">
          <tokens>
            <token id="28" string="dealt" />
            <token id="29" string="with" />
            <token id="30" string="directly" />
            <token id="31" string="and" />
            <token id="32" string="severely" />
          </tokens>
        </chunking>
        <chunking id="9" string="Let me make one thing perfectly clear _ any act of bias will be dealt with directly and severely" type="VP">
          <tokens>
            <token id="14" string="Let" />
            <token id="15" string="me" />
            <token id="16" string="make" />
            <token id="17" string="one" />
            <token id="18" string="thing" />
            <token id="19" string="perfectly" />
            <token id="20" string="clear" />
            <token id="21" string="_" />
            <token id="22" string="any" />
            <token id="23" string="act" />
            <token id="24" string="of" />
            <token id="25" string="bias" />
            <token id="26" string="will" />
            <token id="27" string="be" />
            <token id="28" string="dealt" />
            <token id="29" string="with" />
            <token id="30" string="directly" />
            <token id="31" string="and" />
            <token id="32" string="severely" />
          </tokens>
        </chunking>
        <chunking id="10" string="make one thing perfectly clear _ any act of bias will be dealt with directly and severely" type="VP">
          <tokens>
            <token id="16" string="make" />
            <token id="17" string="one" />
            <token id="18" string="thing" />
            <token id="19" string="perfectly" />
            <token id="20" string="clear" />
            <token id="21" string="_" />
            <token id="22" string="any" />
            <token id="23" string="act" />
            <token id="24" string="of" />
            <token id="25" string="bias" />
            <token id="26" string="will" />
            <token id="27" string="be" />
            <token id="28" string="dealt" />
            <token id="29" string="with" />
            <token id="30" string="directly" />
            <token id="31" string="and" />
            <token id="32" string="severely" />
          </tokens>
        </chunking>
        <chunking id="11" string="Laux" type="NP">
          <tokens>
            <token id="10" string="Laux" />
          </tokens>
        </chunking>
        <chunking id="12" string="perfectly clear" type="ADJP">
          <tokens>
            <token id="19" string="perfectly" />
            <token id="20" string="clear" />
          </tokens>
        </chunking>
        <chunking id="13" string="bias" type="NP">
          <tokens>
            <token id="25" string="bias" />
          </tokens>
        </chunking>
        <chunking id="14" string="said : `` Let me make one thing perfectly clear _ any act of bias will be dealt with directly and severely" type="VP">
          <tokens>
            <token id="11" string="said" />
            <token id="12" string=":" />
            <token id="13" string="``" />
            <token id="14" string="Let" />
            <token id="15" string="me" />
            <token id="16" string="make" />
            <token id="17" string="one" />
            <token id="18" string="thing" />
            <token id="19" string="perfectly" />
            <token id="20" string="clear" />
            <token id="21" string="_" />
            <token id="22" string="any" />
            <token id="23" string="act" />
            <token id="24" string="of" />
            <token id="25" string="bias" />
            <token id="26" string="will" />
            <token id="27" string="be" />
            <token id="28" string="dealt" />
            <token id="29" string="with" />
            <token id="30" string="directly" />
            <token id="31" string="and" />
            <token id="32" string="severely" />
          </tokens>
        </chunking>
        <chunking id="15" string="me" type="NP">
          <tokens>
            <token id="15" string="me" />
          </tokens>
        </chunking>
        <chunking id="16" string="any act" type="NP">
          <tokens>
            <token id="22" string="any" />
            <token id="23" string="act" />
          </tokens>
        </chunking>
        <chunking id="17" string="will be dealt with directly and severely" type="VP">
          <tokens>
            <token id="26" string="will" />
            <token id="27" string="be" />
            <token id="28" string="dealt" />
            <token id="29" string="with" />
            <token id="30" string="directly" />
            <token id="31" string="and" />
            <token id="32" string="severely" />
          </tokens>
        </chunking>
        <chunking id="18" string="be dealt with directly and severely" type="VP">
          <tokens>
            <token id="27" string="be" />
            <token id="28" string="dealt" />
            <token id="29" string="with" />
            <token id="30" string="directly" />
            <token id="31" string="and" />
            <token id="32" string="severely" />
          </tokens>
        </chunking>
        <chunking id="19" string="a letter to police supervisors in mid-February" type="NP">
          <tokens>
            <token id="2" string="a" />
            <token id="3" string="letter" />
            <token id="4" string="to" />
            <token id="5" string="police" />
            <token id="6" string="supervisors" />
            <token id="7" string="in" />
            <token id="8" string="mid-February" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">letter</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">letter</governor>
          <dependent id="2">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">said</governor>
          <dependent id="3">letter</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">supervisors</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">supervisors</governor>
          <dependent id="5">police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">letter</governor>
          <dependent id="6">supervisors</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">mid-February</governor>
          <dependent id="7">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">supervisors</governor>
          <dependent id="8">mid-February</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">said</governor>
          <dependent id="10">Laux</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">said</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">said</governor>
          <dependent id="14">Let</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">make</governor>
          <dependent id="15">me</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="14">Let</governor>
          <dependent id="16">make</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="18">thing</governor>
          <dependent id="17">one</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="28">dealt</governor>
          <dependent id="18">thing</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="20">clear</governor>
          <dependent id="19">perfectly</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="28">dealt</governor>
          <dependent id="20">clear</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="28">dealt</governor>
          <dependent id="21">_</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">act</governor>
          <dependent id="22">any</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="28">dealt</governor>
          <dependent id="23">act</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">bias</governor>
          <dependent id="24">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">act</governor>
          <dependent id="25">bias</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="28">dealt</governor>
          <dependent id="26">will</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="28">dealt</governor>
          <dependent id="27">be</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="16">make</governor>
          <dependent id="28">dealt</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">directly</governor>
          <dependent id="29">with</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="28">dealt</governor>
          <dependent id="30">directly</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="30">directly</governor>
          <dependent id="31">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="30">directly</governor>
          <dependent id="32">severely</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Laux" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Laux" />
          </tokens>
        </entity>
        <entity id="2" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="17" string="one" />
          </tokens>
        </entity>
        <entity id="3" string="mid-February" type="DATE" score="0.0">
          <tokens>
            <token id="8" string="mid-February" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="9" has_coreference="false">
      <content>There will be no tolerance for that type of inexcusable behavior.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="There" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="tolerance" lemma="tolerance" stem="toler" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="type" lemma="type" stem="type" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="inexcusable" lemma="inexcusable" stem="inexcus" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="behavior" lemma="behavior" stem="behavior" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (EX There)) (VP (MD will) (VP (VB be) (NP (NP (DT no) (NN tolerance)) (PP (IN for) (NP (NP (DT that) (NN type)) (PP (IN of) (NP (JJ inexcusable) (NN behavior)))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="inexcusable behavior" type="NP">
          <tokens>
            <token id="10" string="inexcusable" />
            <token id="11" string="behavior" />
          </tokens>
        </chunking>
        <chunking id="2" string="There" type="NP">
          <tokens>
            <token id="1" string="There" />
          </tokens>
        </chunking>
        <chunking id="3" string="will be no tolerance for that type of inexcusable behavior" type="VP">
          <tokens>
            <token id="2" string="will" />
            <token id="3" string="be" />
            <token id="4" string="no" />
            <token id="5" string="tolerance" />
            <token id="6" string="for" />
            <token id="7" string="that" />
            <token id="8" string="type" />
            <token id="9" string="of" />
            <token id="10" string="inexcusable" />
            <token id="11" string="behavior" />
          </tokens>
        </chunking>
        <chunking id="4" string="that type of inexcusable behavior" type="NP">
          <tokens>
            <token id="7" string="that" />
            <token id="8" string="type" />
            <token id="9" string="of" />
            <token id="10" string="inexcusable" />
            <token id="11" string="behavior" />
          </tokens>
        </chunking>
        <chunking id="5" string="that type" type="NP">
          <tokens>
            <token id="7" string="that" />
            <token id="8" string="type" />
          </tokens>
        </chunking>
        <chunking id="6" string="no tolerance for that type of inexcusable behavior" type="NP">
          <tokens>
            <token id="4" string="no" />
            <token id="5" string="tolerance" />
            <token id="6" string="for" />
            <token id="7" string="that" />
            <token id="8" string="type" />
            <token id="9" string="of" />
            <token id="10" string="inexcusable" />
            <token id="11" string="behavior" />
          </tokens>
        </chunking>
        <chunking id="7" string="be no tolerance for that type of inexcusable behavior" type="VP">
          <tokens>
            <token id="3" string="be" />
            <token id="4" string="no" />
            <token id="5" string="tolerance" />
            <token id="6" string="for" />
            <token id="7" string="that" />
            <token id="8" string="type" />
            <token id="9" string="of" />
            <token id="10" string="inexcusable" />
            <token id="11" string="behavior" />
          </tokens>
        </chunking>
        <chunking id="8" string="no tolerance" type="NP">
          <tokens>
            <token id="4" string="no" />
            <token id="5" string="tolerance" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="expl">
          <governor id="5">tolerance</governor>
          <dependent id="1">There</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">tolerance</governor>
          <dependent id="2">will</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">tolerance</governor>
          <dependent id="3">be</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">tolerance</governor>
          <dependent id="4">no</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">tolerance</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">type</governor>
          <dependent id="6">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">type</governor>
          <dependent id="7">that</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">tolerance</governor>
          <dependent id="8">type</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">behavior</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">behavior</governor>
          <dependent id="10">inexcusable</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">type</governor>
          <dependent id="11">behavior</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>Since former Vice President Hubert H. Humphrey, then a 35-year-old mayor running for the U.S. Senate, electrified the 1948 Democratic National Convention with his historic speech in support of civil rights, Minneapolis has been viewed as a liberal, progressive city.</content>
      <tokens>
        <token id="1" string="Since" lemma="since" stem="sinc" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="former" lemma="former" stem="former" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Vice" lemma="Vice" stem="vice" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="President" lemma="President" stem="presid" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="false" is_refers="false" />
        <token id="5" string="Hubert" lemma="Hubert" stem="hubert" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="6" string="H." lemma="H." stem="h." pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="7" string="Humphrey" lemma="Humphrey" stem="humphrei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="35-year-old" lemma="35-year-old" stem="35-year-old" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="12" string="mayor" lemma="mayor" stem="mayor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="running" lemma="run" stem="run" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="U.S." lemma="U.S." stem="u.s." pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="17" string="Senate" lemma="Senate" stem="senat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="electrified" lemma="electrify" stem="electrifi" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="1948" lemma="1948" stem="1948" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="22" string="Democratic" lemma="democratic" stem="democrat" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="23" string="National" lemma="National" stem="nation" pos="NNP" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="24" string="Convention" lemma="Convention" stem="convent" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="25" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="historic" lemma="historic" stem="histor" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="speech" lemma="speech" stem="speech" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="support" lemma="support" stem="support" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="civil" lemma="civil" stem="civil" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="rights" lemma="rights" stem="right" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="Minneapolis" lemma="Minneapolis" stem="minneapoli" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="36" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="viewed" lemma="view" stem="view" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="liberal" lemma="liberal" stem="liber" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="true" is_refers="false" />
        <token id="42" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="progressive" lemma="progressive" stem="progress" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="44" string="city" lemma="city" stem="citi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="45" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN Since) (S (NP (NP (JJ former) (NNP Vice) (NNP President) (NNP Hubert) (NNP H.) (NNP Humphrey)) (, ,) (NP (NP (RB then) (DT a) (JJ 35-year-old) (NN mayor)) (VP (VBG running) (PP (IN for) (NP (DT the) (NNP U.S.) (NNP Senate))))) (, ,)) (VP (VBD electrified) (NP (DT the) (CD 1948) (NP (NP (JJ Democratic) (NNP National) (NNP Convention)) (PP (IN with) (NP (PRP$ his) (JJ historic) (NN speech))))) (PP (IN in) (NP (NP (NN support)) (PP (IN of) (NP (JJ civil) (NNS rights)))))))) (, ,) (NP (NNP Minneapolis)) (VP (VBZ has) (VP (VBN been) (VP (VBN viewed) (PP (IN as) (NP (DT a) (JJ liberal) (, ,) (JJ progressive) (NN city)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="former Vice President Hubert H. Humphrey , then a 35-year-old mayor running for the U.S. Senate ," type="NP">
          <tokens>
            <token id="2" string="former" />
            <token id="3" string="Vice" />
            <token id="4" string="President" />
            <token id="5" string="Hubert" />
            <token id="6" string="H." />
            <token id="7" string="Humphrey" />
            <token id="8" string="," />
            <token id="9" string="then" />
            <token id="10" string="a" />
            <token id="11" string="35-year-old" />
            <token id="12" string="mayor" />
            <token id="13" string="running" />
            <token id="14" string="for" />
            <token id="15" string="the" />
            <token id="16" string="U.S." />
            <token id="17" string="Senate" />
            <token id="18" string="," />
          </tokens>
        </chunking>
        <chunking id="2" string="Democratic National Convention with his historic speech" type="NP">
          <tokens>
            <token id="22" string="Democratic" />
            <token id="23" string="National" />
            <token id="24" string="Convention" />
            <token id="25" string="with" />
            <token id="26" string="his" />
            <token id="27" string="historic" />
            <token id="28" string="speech" />
          </tokens>
        </chunking>
        <chunking id="3" string="Democratic National Convention" type="NP">
          <tokens>
            <token id="22" string="Democratic" />
            <token id="23" string="National" />
            <token id="24" string="Convention" />
          </tokens>
        </chunking>
        <chunking id="4" string="support of civil rights" type="NP">
          <tokens>
            <token id="30" string="support" />
            <token id="31" string="of" />
            <token id="32" string="civil" />
            <token id="33" string="rights" />
          </tokens>
        </chunking>
        <chunking id="5" string="been viewed as a liberal , progressive city" type="VP">
          <tokens>
            <token id="37" string="been" />
            <token id="38" string="viewed" />
            <token id="39" string="as" />
            <token id="40" string="a" />
            <token id="41" string="liberal" />
            <token id="42" string="," />
            <token id="43" string="progressive" />
            <token id="44" string="city" />
          </tokens>
        </chunking>
        <chunking id="6" string="running for the U.S. Senate" type="VP">
          <tokens>
            <token id="13" string="running" />
            <token id="14" string="for" />
            <token id="15" string="the" />
            <token id="16" string="U.S." />
            <token id="17" string="Senate" />
          </tokens>
        </chunking>
        <chunking id="7" string="electrified the 1948 Democratic National Convention with his historic speech in support of civil rights" type="VP">
          <tokens>
            <token id="19" string="electrified" />
            <token id="20" string="the" />
            <token id="21" string="1948" />
            <token id="22" string="Democratic" />
            <token id="23" string="National" />
            <token id="24" string="Convention" />
            <token id="25" string="with" />
            <token id="26" string="his" />
            <token id="27" string="historic" />
            <token id="28" string="speech" />
            <token id="29" string="in" />
            <token id="30" string="support" />
            <token id="31" string="of" />
            <token id="32" string="civil" />
            <token id="33" string="rights" />
          </tokens>
        </chunking>
        <chunking id="8" string="civil rights" type="NP">
          <tokens>
            <token id="32" string="civil" />
            <token id="33" string="rights" />
          </tokens>
        </chunking>
        <chunking id="9" string="the U.S. Senate" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="U.S." />
            <token id="17" string="Senate" />
          </tokens>
        </chunking>
        <chunking id="10" string="viewed as a liberal , progressive city" type="VP">
          <tokens>
            <token id="38" string="viewed" />
            <token id="39" string="as" />
            <token id="40" string="a" />
            <token id="41" string="liberal" />
            <token id="42" string="," />
            <token id="43" string="progressive" />
            <token id="44" string="city" />
          </tokens>
        </chunking>
        <chunking id="11" string="then a 35-year-old mayor" type="NP">
          <tokens>
            <token id="9" string="then" />
            <token id="10" string="a" />
            <token id="11" string="35-year-old" />
            <token id="12" string="mayor" />
          </tokens>
        </chunking>
        <chunking id="12" string="Minneapolis" type="NP">
          <tokens>
            <token id="35" string="Minneapolis" />
          </tokens>
        </chunking>
        <chunking id="13" string="then a 35-year-old mayor running for the U.S. Senate" type="NP">
          <tokens>
            <token id="9" string="then" />
            <token id="10" string="a" />
            <token id="11" string="35-year-old" />
            <token id="12" string="mayor" />
            <token id="13" string="running" />
            <token id="14" string="for" />
            <token id="15" string="the" />
            <token id="16" string="U.S." />
            <token id="17" string="Senate" />
          </tokens>
        </chunking>
        <chunking id="14" string="the 1948 Democratic National Convention with his historic speech" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="1948" />
            <token id="22" string="Democratic" />
            <token id="23" string="National" />
            <token id="24" string="Convention" />
            <token id="25" string="with" />
            <token id="26" string="his" />
            <token id="27" string="historic" />
            <token id="28" string="speech" />
          </tokens>
        </chunking>
        <chunking id="15" string="a liberal , progressive city" type="NP">
          <tokens>
            <token id="40" string="a" />
            <token id="41" string="liberal" />
            <token id="42" string="," />
            <token id="43" string="progressive" />
            <token id="44" string="city" />
          </tokens>
        </chunking>
        <chunking id="16" string="Since former Vice President Hubert H. Humphrey , then a 35-year-old mayor running for the U.S. Senate , electrified the 1948 Democratic National Convention with his historic speech in support of civil rights" type="SBAR">
          <tokens>
            <token id="1" string="Since" />
            <token id="2" string="former" />
            <token id="3" string="Vice" />
            <token id="4" string="President" />
            <token id="5" string="Hubert" />
            <token id="6" string="H." />
            <token id="7" string="Humphrey" />
            <token id="8" string="," />
            <token id="9" string="then" />
            <token id="10" string="a" />
            <token id="11" string="35-year-old" />
            <token id="12" string="mayor" />
            <token id="13" string="running" />
            <token id="14" string="for" />
            <token id="15" string="the" />
            <token id="16" string="U.S." />
            <token id="17" string="Senate" />
            <token id="18" string="," />
            <token id="19" string="electrified" />
            <token id="20" string="the" />
            <token id="21" string="1948" />
            <token id="22" string="Democratic" />
            <token id="23" string="National" />
            <token id="24" string="Convention" />
            <token id="25" string="with" />
            <token id="26" string="his" />
            <token id="27" string="historic" />
            <token id="28" string="speech" />
            <token id="29" string="in" />
            <token id="30" string="support" />
            <token id="31" string="of" />
            <token id="32" string="civil" />
            <token id="33" string="rights" />
          </tokens>
        </chunking>
        <chunking id="17" string="former Vice President Hubert H. Humphrey" type="NP">
          <tokens>
            <token id="2" string="former" />
            <token id="3" string="Vice" />
            <token id="4" string="President" />
            <token id="5" string="Hubert" />
            <token id="6" string="H." />
            <token id="7" string="Humphrey" />
          </tokens>
        </chunking>
        <chunking id="18" string="his historic speech" type="NP">
          <tokens>
            <token id="26" string="his" />
            <token id="27" string="historic" />
            <token id="28" string="speech" />
          </tokens>
        </chunking>
        <chunking id="19" string="has been viewed as a liberal , progressive city" type="VP">
          <tokens>
            <token id="36" string="has" />
            <token id="37" string="been" />
            <token id="38" string="viewed" />
            <token id="39" string="as" />
            <token id="40" string="a" />
            <token id="41" string="liberal" />
            <token id="42" string="," />
            <token id="43" string="progressive" />
            <token id="44" string="city" />
          </tokens>
        </chunking>
        <chunking id="20" string="support" type="NP">
          <tokens>
            <token id="30" string="support" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="19">electrified</governor>
          <dependent id="1">Since</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">Humphrey</governor>
          <dependent id="2">former</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Humphrey</governor>
          <dependent id="3">Vice</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Humphrey</governor>
          <dependent id="4">President</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Humphrey</governor>
          <dependent id="5">Hubert</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Humphrey</governor>
          <dependent id="6">H.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">electrified</governor>
          <dependent id="7">Humphrey</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">mayor</governor>
          <dependent id="9">then</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">mayor</governor>
          <dependent id="10">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">mayor</governor>
          <dependent id="11">35-year-old</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="7">Humphrey</governor>
          <dependent id="12">mayor</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="12">mayor</governor>
          <dependent id="13">running</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">Senate</governor>
          <dependent id="14">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">Senate</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">Senate</governor>
          <dependent id="16">U.S.</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">running</governor>
          <dependent id="17">Senate</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="38">viewed</governor>
          <dependent id="19">electrified</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">Convention</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="24">Convention</governor>
          <dependent id="21">1948</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">Convention</governor>
          <dependent id="22">Democratic</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">Convention</governor>
          <dependent id="23">National</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">electrified</governor>
          <dependent id="24">Convention</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">speech</governor>
          <dependent id="25">with</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="28">speech</governor>
          <dependent id="26">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">speech</governor>
          <dependent id="27">historic</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">Convention</governor>
          <dependent id="28">speech</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">support</governor>
          <dependent id="29">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">electrified</governor>
          <dependent id="30">support</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">rights</governor>
          <dependent id="31">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="33">rights</governor>
          <dependent id="32">civil</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">support</governor>
          <dependent id="33">rights</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="38">viewed</governor>
          <dependent id="35">Minneapolis</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="38">viewed</governor>
          <dependent id="36">has</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="38">viewed</governor>
          <dependent id="37">been</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="38">viewed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="44">city</governor>
          <dependent id="39">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="44">city</governor>
          <dependent id="40">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="44">city</governor>
          <dependent id="41">liberal</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="44">city</governor>
          <dependent id="43">progressive</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="38">viewed</governor>
          <dependent id="44">city</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="35-year-old" type="DURATION" score="0.0">
          <tokens>
            <token id="11" string="35-year-old" />
          </tokens>
        </entity>
        <entity id="2" string="Convention" type="MISC" score="0.0">
          <tokens>
            <token id="24" string="Convention" />
          </tokens>
        </entity>
        <entity id="3" string="U.S. Senate" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="16" string="U.S." />
            <token id="17" string="Senate" />
          </tokens>
        </entity>
        <entity id="4" string="Minneapolis" type="LOCATION" score="0.0">
          <tokens>
            <token id="35" string="Minneapolis" />
          </tokens>
        </entity>
        <entity id="5" string="Hubert H. Humphrey" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Hubert" />
            <token id="6" string="H." />
            <token id="7" string="Humphrey" />
          </tokens>
        </entity>
        <entity id="6" string="1948" type="DATE" score="0.0">
          <tokens>
            <token id="21" string="1948" />
          </tokens>
        </entity>
        <entity id="7" string="President" type="TITLE" score="0.0">
          <tokens>
            <token id="4" string="President" />
          </tokens>
        </entity>
        <entity id="8" string="liberal" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="41" string="liberal" />
          </tokens>
        </entity>
        <entity id="9" string="Democratic National" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="22" string="Democratic" />
            <token id="23" string="National" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>Some, including Hayden, say that image now blocks progress.</content>
      <tokens>
        <token id="1" string="Some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="including" lemma="include" stem="includ" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="Hayden" lemma="Hayden" stem="hayden" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="say" lemma="say" stem="sai" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="image" lemma="image" stem="imag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="10" string="blocks" lemma="block" stem="block" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="progress" lemma="progress" stem="progress" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT Some)) (, ,) (PP (VBG including) (NP (NNP Hayden))) (, ,)) (VP (VBP say) (SBAR (IN that) (S (NP (NN image)) (ADVP (RB now)) (VP (VBZ blocks) (NP (NN progress)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Some , including Hayden ," type="NP">
          <tokens>
            <token id="1" string="Some" />
            <token id="2" string="," />
            <token id="3" string="including" />
            <token id="4" string="Hayden" />
            <token id="5" string="," />
          </tokens>
        </chunking>
        <chunking id="2" string="Hayden" type="NP">
          <tokens>
            <token id="4" string="Hayden" />
          </tokens>
        </chunking>
        <chunking id="3" string="image" type="NP">
          <tokens>
            <token id="8" string="image" />
          </tokens>
        </chunking>
        <chunking id="4" string="Some" type="NP">
          <tokens>
            <token id="1" string="Some" />
          </tokens>
        </chunking>
        <chunking id="5" string="progress" type="NP">
          <tokens>
            <token id="11" string="progress" />
          </tokens>
        </chunking>
        <chunking id="6" string="that image now blocks progress" type="SBAR">
          <tokens>
            <token id="7" string="that" />
            <token id="8" string="image" />
            <token id="9" string="now" />
            <token id="10" string="blocks" />
            <token id="11" string="progress" />
          </tokens>
        </chunking>
        <chunking id="7" string="say that image now blocks progress" type="VP">
          <tokens>
            <token id="6" string="say" />
            <token id="7" string="that" />
            <token id="8" string="image" />
            <token id="9" string="now" />
            <token id="10" string="blocks" />
            <token id="11" string="progress" />
          </tokens>
        </chunking>
        <chunking id="8" string="blocks progress" type="VP">
          <tokens>
            <token id="10" string="blocks" />
            <token id="11" string="progress" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="6">say</governor>
          <dependent id="1">Some</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">Hayden</governor>
          <dependent id="3">including</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Some</governor>
          <dependent id="4">Hayden</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">say</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">blocks</governor>
          <dependent id="7">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">blocks</governor>
          <dependent id="8">image</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">blocks</governor>
          <dependent id="9">now</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">say</governor>
          <dependent id="10">blocks</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">blocks</governor>
          <dependent id="11">progress</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Hayden" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Hayden" />
          </tokens>
        </entity>
        <entity id="2" string="now" type="DATE" score="0.0">
          <tokens>
            <token id="9" string="now" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>``I think this city has to wake up.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="think" lemma="think" stem="think" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="city" lemma="city" stem="citi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="wake" lemma="wake" stem="wake" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP I)) (VP (VBP think) (SBAR (S (NP (DT this) (NN city)) (VP (VBZ has) (S (VP (TO to) (VP (VB wake) (PRT (RP up))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="this city" type="NP">
          <tokens>
            <token id="4" string="this" />
            <token id="5" string="city" />
          </tokens>
        </chunking>
        <chunking id="2" string="to wake up" type="VP">
          <tokens>
            <token id="7" string="to" />
            <token id="8" string="wake" />
            <token id="9" string="up" />
          </tokens>
        </chunking>
        <chunking id="3" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="4" string="this city has to wake up" type="SBAR">
          <tokens>
            <token id="4" string="this" />
            <token id="5" string="city" />
            <token id="6" string="has" />
            <token id="7" string="to" />
            <token id="8" string="wake" />
            <token id="9" string="up" />
          </tokens>
        </chunking>
        <chunking id="5" string="think this city has to wake up" type="VP">
          <tokens>
            <token id="3" string="think" />
            <token id="4" string="this" />
            <token id="5" string="city" />
            <token id="6" string="has" />
            <token id="7" string="to" />
            <token id="8" string="wake" />
            <token id="9" string="up" />
          </tokens>
        </chunking>
        <chunking id="6" string="wake up" type="VP">
          <tokens>
            <token id="8" string="wake" />
            <token id="9" string="up" />
          </tokens>
        </chunking>
        <chunking id="7" string="has to wake up" type="VP">
          <tokens>
            <token id="6" string="has" />
            <token id="7" string="to" />
            <token id="8" string="wake" />
            <token id="9" string="up" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">think</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">think</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">city</governor>
          <dependent id="4">this</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">has</governor>
          <dependent id="5">city</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">think</governor>
          <dependent id="6">has</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">wake</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">has</governor>
          <dependent id="8">wake</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="8">wake</governor>
          <dependent id="9">up</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>Everyone always says, `I can&amp;apost;t believe this is happening in Minnesota, in Minneapolis, the home of progressiveness.&amp;apost;</content>
      <tokens>
        <token id="1" string="Everyone" lemma="everyone" stem="everyon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="always" lemma="always" stem="alwai" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="`" lemma="`" stem="`" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="ca" lemma="can" stem="ca" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="believe" lemma="believe" stem="believ" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="happening" lemma="happen" stem="happen" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Minnesota" lemma="Minnesota" stem="minnesota" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Minneapolis" lemma="Minneapolis" stem="minneapoli" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="home" lemma="home" stem="home" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="21" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="progressiveness" lemma="progressiveness" stem="progress" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NN Everyone)) (ADVP (RB always)) (VP (VBZ says) (, ,) (`` `) (S (NP (PRP I)) (VP (MD ca) (RB n't) (VP (VB believe) (SBAR (S (NP (DT this)) (VP (VBZ is) (VP (VBG happening) (PP (IN in) (NP (NNP Minnesota))) (, ,) (PP (IN in) (NP (NP (NNP Minneapolis)) (, ,) (NP (NP (DT the) (NN home)) (PP (IN of) (NP (NN progressiveness)))))))))))))) (. .) ('' ')))</syntactictree>
      <chunkings>
        <chunking id="1" string="the home of progressiveness" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="home" />
            <token id="21" string="of" />
            <token id="22" string="progressiveness" />
          </tokens>
        </chunking>
        <chunking id="2" string="Everyone" type="NP">
          <tokens>
            <token id="1" string="Everyone" />
          </tokens>
        </chunking>
        <chunking id="3" string="says , ` I ca n't believe this is happening in Minnesota , in Minneapolis , the home of progressiveness" type="VP">
          <tokens>
            <token id="3" string="says" />
            <token id="4" string="," />
            <token id="5" string="`" />
            <token id="6" string="I" />
            <token id="7" string="ca" />
            <token id="8" string="n't" />
            <token id="9" string="believe" />
            <token id="10" string="this" />
            <token id="11" string="is" />
            <token id="12" string="happening" />
            <token id="13" string="in" />
            <token id="14" string="Minnesota" />
            <token id="15" string="," />
            <token id="16" string="in" />
            <token id="17" string="Minneapolis" />
            <token id="18" string="," />
            <token id="19" string="the" />
            <token id="20" string="home" />
            <token id="21" string="of" />
            <token id="22" string="progressiveness" />
          </tokens>
        </chunking>
        <chunking id="4" string="ca n't believe this is happening in Minnesota , in Minneapolis , the home of progressiveness" type="VP">
          <tokens>
            <token id="7" string="ca" />
            <token id="8" string="n't" />
            <token id="9" string="believe" />
            <token id="10" string="this" />
            <token id="11" string="is" />
            <token id="12" string="happening" />
            <token id="13" string="in" />
            <token id="14" string="Minnesota" />
            <token id="15" string="," />
            <token id="16" string="in" />
            <token id="17" string="Minneapolis" />
            <token id="18" string="," />
            <token id="19" string="the" />
            <token id="20" string="home" />
            <token id="21" string="of" />
            <token id="22" string="progressiveness" />
          </tokens>
        </chunking>
        <chunking id="5" string="I" type="NP">
          <tokens>
            <token id="6" string="I" />
          </tokens>
        </chunking>
        <chunking id="6" string="Minnesota" type="NP">
          <tokens>
            <token id="14" string="Minnesota" />
          </tokens>
        </chunking>
        <chunking id="7" string="Minneapolis , the home of progressiveness" type="NP">
          <tokens>
            <token id="17" string="Minneapolis" />
            <token id="18" string="," />
            <token id="19" string="the" />
            <token id="20" string="home" />
            <token id="21" string="of" />
            <token id="22" string="progressiveness" />
          </tokens>
        </chunking>
        <chunking id="8" string="this" type="NP">
          <tokens>
            <token id="10" string="this" />
          </tokens>
        </chunking>
        <chunking id="9" string="progressiveness" type="NP">
          <tokens>
            <token id="22" string="progressiveness" />
          </tokens>
        </chunking>
        <chunking id="10" string="the home" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="home" />
          </tokens>
        </chunking>
        <chunking id="11" string="happening in Minnesota , in Minneapolis , the home of progressiveness" type="VP">
          <tokens>
            <token id="12" string="happening" />
            <token id="13" string="in" />
            <token id="14" string="Minnesota" />
            <token id="15" string="," />
            <token id="16" string="in" />
            <token id="17" string="Minneapolis" />
            <token id="18" string="," />
            <token id="19" string="the" />
            <token id="20" string="home" />
            <token id="21" string="of" />
            <token id="22" string="progressiveness" />
          </tokens>
        </chunking>
        <chunking id="12" string="Minneapolis" type="NP">
          <tokens>
            <token id="17" string="Minneapolis" />
          </tokens>
        </chunking>
        <chunking id="13" string="believe this is happening in Minnesota , in Minneapolis , the home of progressiveness" type="VP">
          <tokens>
            <token id="9" string="believe" />
            <token id="10" string="this" />
            <token id="11" string="is" />
            <token id="12" string="happening" />
            <token id="13" string="in" />
            <token id="14" string="Minnesota" />
            <token id="15" string="," />
            <token id="16" string="in" />
            <token id="17" string="Minneapolis" />
            <token id="18" string="," />
            <token id="19" string="the" />
            <token id="20" string="home" />
            <token id="21" string="of" />
            <token id="22" string="progressiveness" />
          </tokens>
        </chunking>
        <chunking id="14" string="is happening in Minnesota , in Minneapolis , the home of progressiveness" type="VP">
          <tokens>
            <token id="11" string="is" />
            <token id="12" string="happening" />
            <token id="13" string="in" />
            <token id="14" string="Minnesota" />
            <token id="15" string="," />
            <token id="16" string="in" />
            <token id="17" string="Minneapolis" />
            <token id="18" string="," />
            <token id="19" string="the" />
            <token id="20" string="home" />
            <token id="21" string="of" />
            <token id="22" string="progressiveness" />
          </tokens>
        </chunking>
        <chunking id="15" string="this is happening in Minnesota , in Minneapolis , the home of progressiveness" type="SBAR">
          <tokens>
            <token id="10" string="this" />
            <token id="11" string="is" />
            <token id="12" string="happening" />
            <token id="13" string="in" />
            <token id="14" string="Minnesota" />
            <token id="15" string="," />
            <token id="16" string="in" />
            <token id="17" string="Minneapolis" />
            <token id="18" string="," />
            <token id="19" string="the" />
            <token id="20" string="home" />
            <token id="21" string="of" />
            <token id="22" string="progressiveness" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">says</governor>
          <dependent id="1">Everyone</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">says</governor>
          <dependent id="2">always</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">says</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">believe</governor>
          <dependent id="6">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">believe</governor>
          <dependent id="7">ca</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="9">believe</governor>
          <dependent id="8">n't</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">says</governor>
          <dependent id="9">believe</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">happening</governor>
          <dependent id="10">this</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">happening</governor>
          <dependent id="11">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="9">believe</governor>
          <dependent id="12">happening</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">Minnesota</governor>
          <dependent id="13">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">happening</governor>
          <dependent id="14">Minnesota</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">Minneapolis</governor>
          <dependent id="16">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">happening</governor>
          <dependent id="17">Minneapolis</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">home</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="17">Minneapolis</governor>
          <dependent id="20">home</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">progressiveness</governor>
          <dependent id="21">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">home</governor>
          <dependent id="22">progressiveness</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Minneapolis" type="LOCATION" score="0.0">
          <tokens>
            <token id="17" string="Minneapolis" />
          </tokens>
        </entity>
        <entity id="2" string="Minnesota" type="LOCATION" score="0.0">
          <tokens>
            <token id="14" string="Minnesota" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>That is real tricky,&amp;apost;&amp;apost; Hayden said.</content>
      <tokens>
        <token id="1" string="That" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="real" lemma="real" stem="real" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="tricky" lemma="tricky" stem="tricki" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Hayden" lemma="Hayden" stem="hayden" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="8" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (DT That)) (VP (VBZ is) (ADVP (JJ real)) (ADJP (JJ tricky)))) (, ,) ('' '') (NP (NNP Hayden)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Hayden" type="NP">
          <tokens>
            <token id="7" string="Hayden" />
          </tokens>
        </chunking>
        <chunking id="2" string="That" type="NP">
          <tokens>
            <token id="1" string="That" />
          </tokens>
        </chunking>
        <chunking id="3" string="is real tricky" type="VP">
          <tokens>
            <token id="2" string="is" />
            <token id="3" string="real" />
            <token id="4" string="tricky" />
          </tokens>
        </chunking>
        <chunking id="4" string="tricky" type="ADJP">
          <tokens>
            <token id="4" string="tricky" />
          </tokens>
        </chunking>
        <chunking id="5" string="said" type="VP">
          <tokens>
            <token id="8" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">tricky</governor>
          <dependent id="1">That</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">tricky</governor>
          <dependent id="2">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">tricky</governor>
          <dependent id="3">real</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="8">said</governor>
          <dependent id="4">tricky</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">said</governor>
          <dependent id="7">Hayden</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Hayden" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Hayden" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>``If we get preoccupied with the image of the city, we&amp;apost;re not going to be able to thoroughly address the problems we&amp;apost;re facing.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="If" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="get" lemma="get" stem="get" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="preoccupied" lemma="preoccupy" stem="preoccupi" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="image" lemma="image" stem="imag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="city" lemma="city" stem="citi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="'re" lemma="be" stem="'re" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="going" lemma="go" stem="go" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="able" lemma="able" stem="abl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="thoroughly" lemma="thoroughly" stem="thoroughli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="address" lemma="address" stem="address" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="problems" lemma="problem" stem="problem" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="'re" lemma="be" stem="'re" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="facing" lemma="face" stem="face" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (SBAR (IN If) (S (NP (PRP we)) (VP (VBP get) (VP (VBN preoccupied) (PP (IN with) (NP (NP (DT the) (NN image)) (PP (IN of) (NP (DT the) (NN city))))))))) (, ,) (NP (PRP we)) (VP (VBP 're) (RB not) (VP (VBG going) (S (VP (TO to) (VP (VB be) (ADJP (JJ able) (S (VP (TO to) (VP (ADVP (RB thoroughly)) (VB address) (NP (NP (DT the) (NNS problems)) (SBAR (S (NP (PRP we)) (VP (VBP 're) (VP (VBG facing))))))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="we 're facing" type="SBAR">
          <tokens>
            <token id="25" string="we" />
            <token id="26" string="'re" />
            <token id="27" string="facing" />
          </tokens>
        </chunking>
        <chunking id="2" string="the city" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="city" />
          </tokens>
        </chunking>
        <chunking id="3" string="going to be able to thoroughly address the problems we 're facing" type="VP">
          <tokens>
            <token id="16" string="going" />
            <token id="17" string="to" />
            <token id="18" string="be" />
            <token id="19" string="able" />
            <token id="20" string="to" />
            <token id="21" string="thoroughly" />
            <token id="22" string="address" />
            <token id="23" string="the" />
            <token id="24" string="problems" />
            <token id="25" string="we" />
            <token id="26" string="'re" />
            <token id="27" string="facing" />
          </tokens>
        </chunking>
        <chunking id="4" string="'re facing" type="VP">
          <tokens>
            <token id="26" string="'re" />
            <token id="27" string="facing" />
          </tokens>
        </chunking>
        <chunking id="5" string="preoccupied with the image of the city" type="VP">
          <tokens>
            <token id="5" string="preoccupied" />
            <token id="6" string="with" />
            <token id="7" string="the" />
            <token id="8" string="image" />
            <token id="9" string="of" />
            <token id="10" string="the" />
            <token id="11" string="city" />
          </tokens>
        </chunking>
        <chunking id="6" string="able to thoroughly address the problems we 're facing" type="ADJP">
          <tokens>
            <token id="19" string="able" />
            <token id="20" string="to" />
            <token id="21" string="thoroughly" />
            <token id="22" string="address" />
            <token id="23" string="the" />
            <token id="24" string="problems" />
            <token id="25" string="we" />
            <token id="26" string="'re" />
            <token id="27" string="facing" />
          </tokens>
        </chunking>
        <chunking id="7" string="the problems we 're facing" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="problems" />
            <token id="25" string="we" />
            <token id="26" string="'re" />
            <token id="27" string="facing" />
          </tokens>
        </chunking>
        <chunking id="8" string="the image of the city" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="image" />
            <token id="9" string="of" />
            <token id="10" string="the" />
            <token id="11" string="city" />
          </tokens>
        </chunking>
        <chunking id="9" string="to thoroughly address the problems we 're facing" type="VP">
          <tokens>
            <token id="20" string="to" />
            <token id="21" string="thoroughly" />
            <token id="22" string="address" />
            <token id="23" string="the" />
            <token id="24" string="problems" />
            <token id="25" string="we" />
            <token id="26" string="'re" />
            <token id="27" string="facing" />
          </tokens>
        </chunking>
        <chunking id="10" string="thoroughly address the problems we 're facing" type="VP">
          <tokens>
            <token id="21" string="thoroughly" />
            <token id="22" string="address" />
            <token id="23" string="the" />
            <token id="24" string="problems" />
            <token id="25" string="we" />
            <token id="26" string="'re" />
            <token id="27" string="facing" />
          </tokens>
        </chunking>
        <chunking id="11" string="facing" type="VP">
          <tokens>
            <token id="27" string="facing" />
          </tokens>
        </chunking>
        <chunking id="12" string="the image" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="image" />
          </tokens>
        </chunking>
        <chunking id="13" string="we" type="NP">
          <tokens>
            <token id="3" string="we" />
          </tokens>
        </chunking>
        <chunking id="14" string="get preoccupied with the image of the city" type="VP">
          <tokens>
            <token id="4" string="get" />
            <token id="5" string="preoccupied" />
            <token id="6" string="with" />
            <token id="7" string="the" />
            <token id="8" string="image" />
            <token id="9" string="of" />
            <token id="10" string="the" />
            <token id="11" string="city" />
          </tokens>
        </chunking>
        <chunking id="15" string="be able to thoroughly address the problems we 're facing" type="VP">
          <tokens>
            <token id="18" string="be" />
            <token id="19" string="able" />
            <token id="20" string="to" />
            <token id="21" string="thoroughly" />
            <token id="22" string="address" />
            <token id="23" string="the" />
            <token id="24" string="problems" />
            <token id="25" string="we" />
            <token id="26" string="'re" />
            <token id="27" string="facing" />
          </tokens>
        </chunking>
        <chunking id="16" string="If we get preoccupied with the image of the city" type="SBAR">
          <tokens>
            <token id="2" string="If" />
            <token id="3" string="we" />
            <token id="4" string="get" />
            <token id="5" string="preoccupied" />
            <token id="6" string="with" />
            <token id="7" string="the" />
            <token id="8" string="image" />
            <token id="9" string="of" />
            <token id="10" string="the" />
            <token id="11" string="city" />
          </tokens>
        </chunking>
        <chunking id="17" string="'re not going to be able to thoroughly address the problems we 're facing" type="VP">
          <tokens>
            <token id="14" string="'re" />
            <token id="15" string="not" />
            <token id="16" string="going" />
            <token id="17" string="to" />
            <token id="18" string="be" />
            <token id="19" string="able" />
            <token id="20" string="to" />
            <token id="21" string="thoroughly" />
            <token id="22" string="address" />
            <token id="23" string="the" />
            <token id="24" string="problems" />
            <token id="25" string="we" />
            <token id="26" string="'re" />
            <token id="27" string="facing" />
          </tokens>
        </chunking>
        <chunking id="18" string="the problems" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="problems" />
          </tokens>
        </chunking>
        <chunking id="19" string="to be able to thoroughly address the problems we 're facing" type="VP">
          <tokens>
            <token id="17" string="to" />
            <token id="18" string="be" />
            <token id="19" string="able" />
            <token id="20" string="to" />
            <token id="21" string="thoroughly" />
            <token id="22" string="address" />
            <token id="23" string="the" />
            <token id="24" string="problems" />
            <token id="25" string="we" />
            <token id="26" string="'re" />
            <token id="27" string="facing" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="5">preoccupied</governor>
          <dependent id="2">If</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="5">preoccupied</governor>
          <dependent id="3">we</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="5">preoccupied</governor>
          <dependent id="4">get</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="16">going</governor>
          <dependent id="5">preoccupied</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">image</governor>
          <dependent id="6">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">image</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">preoccupied</governor>
          <dependent id="8">image</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">city</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">city</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">image</governor>
          <dependent id="11">city</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">going</governor>
          <dependent id="13">we</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">going</governor>
          <dependent id="14">'re</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="16">going</governor>
          <dependent id="15">not</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="16">going</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">able</governor>
          <dependent id="17">to</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="19">able</governor>
          <dependent id="18">be</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="16">going</governor>
          <dependent id="19">able</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">address</governor>
          <dependent id="20">to</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="22">address</governor>
          <dependent id="21">thoroughly</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="19">able</governor>
          <dependent id="22">address</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">problems</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">address</governor>
          <dependent id="24">problems</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">facing</governor>
          <dependent id="25">we</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="27">facing</governor>
          <dependent id="26">'re</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="24">problems</governor>
          <dependent id="27">facing</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="16" has_coreference="false">
      <content>``The liberal image is a false picture,&amp;apost;&amp;apost; said Chris Nisan, a University of Minnesota student who has been involved in recent protests.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="liberal" lemma="liberal" stem="liber" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="true" is_refers="false" />
        <token id="4" string="image" lemma="image" stem="imag" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="false" lemma="false" stem="fals" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="picture" lemma="picture" stem="pictur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="Chris" lemma="Chris" stem="chri" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="13" string="Nisan" lemma="Nisan" stem="nisan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="University" lemma="University" stem="univers" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="17" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="18" string="Minnesota" lemma="Minnesota" stem="minnesota" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="19" string="student" lemma="student" stem="student" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="involved" lemma="involve" stem="involv" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="recent" lemma="recent" stem="recent" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="protests" lemma="protest" stem="protest" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (NP (DT The) (JJ liberal) (NN image)) (VP (VBZ is) (NP (DT a) (JJ false) (NN picture)))) (, ,) ('' '') (VP (VBD said)) (NP (NP (NNP Chris) (NNP Nisan)) (, ,) (NP (NP (DT a) (NAC (NNP University) (PP (IN of) (NP (NNP Minnesota)))) (NN student)) (SBAR (WHNP (WP who)) (S (VP (VBZ has) (VP (VBN been) (VP (VBN involved) (PP (IN in) (NP (JJ recent) (NNS protests)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Chris Nisan , a University of Minnesota student who has been involved in recent protests" type="NP">
          <tokens>
            <token id="12" string="Chris" />
            <token id="13" string="Nisan" />
            <token id="14" string="," />
            <token id="15" string="a" />
            <token id="16" string="University" />
            <token id="17" string="of" />
            <token id="18" string="Minnesota" />
            <token id="19" string="student" />
            <token id="20" string="who" />
            <token id="21" string="has" />
            <token id="22" string="been" />
            <token id="23" string="involved" />
            <token id="24" string="in" />
            <token id="25" string="recent" />
            <token id="26" string="protests" />
          </tokens>
        </chunking>
        <chunking id="2" string="is a false picture" type="VP">
          <tokens>
            <token id="5" string="is" />
            <token id="6" string="a" />
            <token id="7" string="false" />
            <token id="8" string="picture" />
          </tokens>
        </chunking>
        <chunking id="3" string="a University of Minnesota student" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="University" />
            <token id="17" string="of" />
            <token id="18" string="Minnesota" />
            <token id="19" string="student" />
          </tokens>
        </chunking>
        <chunking id="4" string="been involved in recent protests" type="VP">
          <tokens>
            <token id="22" string="been" />
            <token id="23" string="involved" />
            <token id="24" string="in" />
            <token id="25" string="recent" />
            <token id="26" string="protests" />
          </tokens>
        </chunking>
        <chunking id="5" string="Minnesota" type="NP">
          <tokens>
            <token id="18" string="Minnesota" />
          </tokens>
        </chunking>
        <chunking id="6" string="a false picture" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="false" />
            <token id="8" string="picture" />
          </tokens>
        </chunking>
        <chunking id="7" string="recent protests" type="NP">
          <tokens>
            <token id="25" string="recent" />
            <token id="26" string="protests" />
          </tokens>
        </chunking>
        <chunking id="8" string="involved in recent protests" type="VP">
          <tokens>
            <token id="23" string="involved" />
            <token id="24" string="in" />
            <token id="25" string="recent" />
            <token id="26" string="protests" />
          </tokens>
        </chunking>
        <chunking id="9" string="Chris Nisan" type="NP">
          <tokens>
            <token id="12" string="Chris" />
            <token id="13" string="Nisan" />
          </tokens>
        </chunking>
        <chunking id="10" string="who has been involved in recent protests" type="SBAR">
          <tokens>
            <token id="20" string="who" />
            <token id="21" string="has" />
            <token id="22" string="been" />
            <token id="23" string="involved" />
            <token id="24" string="in" />
            <token id="25" string="recent" />
            <token id="26" string="protests" />
          </tokens>
        </chunking>
        <chunking id="11" string="The liberal image" type="NP">
          <tokens>
            <token id="2" string="The" />
            <token id="3" string="liberal" />
            <token id="4" string="image" />
          </tokens>
        </chunking>
        <chunking id="12" string="a University of Minnesota student who has been involved in recent protests" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="University" />
            <token id="17" string="of" />
            <token id="18" string="Minnesota" />
            <token id="19" string="student" />
            <token id="20" string="who" />
            <token id="21" string="has" />
            <token id="22" string="been" />
            <token id="23" string="involved" />
            <token id="24" string="in" />
            <token id="25" string="recent" />
            <token id="26" string="protests" />
          </tokens>
        </chunking>
        <chunking id="13" string="said" type="VP">
          <tokens>
            <token id="11" string="said" />
          </tokens>
        </chunking>
        <chunking id="14" string="has been involved in recent protests" type="VP">
          <tokens>
            <token id="21" string="has" />
            <token id="22" string="been" />
            <token id="23" string="involved" />
            <token id="24" string="in" />
            <token id="25" string="recent" />
            <token id="26" string="protests" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="4">image</governor>
          <dependent id="2">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">image</governor>
          <dependent id="3">liberal</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">picture</governor>
          <dependent id="4">image</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="8">picture</governor>
          <dependent id="5">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">picture</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">picture</governor>
          <dependent id="7">false</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">said</governor>
          <dependent id="8">picture</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Nisan</governor>
          <dependent id="12">Chris</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">said</governor>
          <dependent id="13">Nisan</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">student</governor>
          <dependent id="15">a</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="19">student</governor>
          <dependent id="16">University</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">Minnesota</governor>
          <dependent id="17">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">University</governor>
          <dependent id="18">Minnesota</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="13">Nisan</governor>
          <dependent id="19">student</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="23">involved</governor>
          <dependent id="20">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="23">involved</governor>
          <dependent id="21">has</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="23">involved</governor>
          <dependent id="22">been</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="19">student</governor>
          <dependent id="23">involved</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">protests</governor>
          <dependent id="24">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">protests</governor>
          <dependent id="25">recent</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">involved</governor>
          <dependent id="26">protests</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Chris Nisan" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Chris" />
            <token id="13" string="Nisan" />
          </tokens>
        </entity>
        <entity id="2" string="University of Minnesota" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="16" string="University" />
            <token id="17" string="of" />
            <token id="18" string="Minnesota" />
          </tokens>
        </entity>
        <entity id="3" string="liberal" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="3" string="liberal" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="17" has_coreference="true">
      <content>In a series of rallies in recent weeks, protesters demanded that officers involved in the drug raid be suspended, charges against those arrested at the hotel be dropped, and that a citizen police review board be established.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="series" lemma="series" stem="seri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="rallies" lemma="rally" stem="ralli" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="recent" lemma="recent" stem="recent" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="8" string="weeks" lemma="week" stem="week" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="protesters" lemma="protester" stem="protest" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="demanded" lemma="demand" stem="demand" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="involved" lemma="involve" stem="involv" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="drug" lemma="drug" stem="drug" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="18" string="raid" lemma="raid" stem="raid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="19" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="suspended" lemma="suspend" stem="suspend" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="charges" lemma="charge" stem="charg" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="24" string="those" lemma="those" stem="those" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="25" string="arrested" lemma="arrest" stem="arrest" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="26" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="27" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="28" string="hotel" lemma="hotel" stem="hotel" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="29" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="dropped" lemma="drop" stem="drop" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="citizen" lemma="citizen" stem="citizen" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="review" lemma="review" stem="review" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="board" lemma="board" stem="board" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="established" lemma="establish" stem="establish" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (NP (DT a) (NN series)) (PP (IN of) (NP (NP (NNS rallies)) (PP (IN in) (NP (JJ recent) (NNS weeks))))))) (, ,) (NP (NNS protesters)) (VP (VBD demanded) (SBAR (SBAR (IN that) (S (NP (NP (NNS officers)) (VP (VBN involved) (PP (IN in) (NP (DT the) (NN drug) (NN raid))) (S (VP (VB be) (VP (VBN suspended) (, ,) (NP (NP (NNS charges)) (PP (IN against) (NP (NP (DT those)) (VP (VBN arrested) (PP (IN at) (NP (DT the) (NN hotel)))))))))))) (VP (VB be) (VP (VBN dropped))))) (, ,) (CC and) (SBAR (IN that) (S (NP (DT a) (NN citizen) (NN police) (NN review) (NN board)) (VP (VB be) (VP (VBN established))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="be suspended , charges against those arrested at the hotel" type="VP">
          <tokens>
            <token id="19" string="be" />
            <token id="20" string="suspended" />
            <token id="21" string="," />
            <token id="22" string="charges" />
            <token id="23" string="against" />
            <token id="24" string="those" />
            <token id="25" string="arrested" />
            <token id="26" string="at" />
            <token id="27" string="the" />
            <token id="28" string="hotel" />
          </tokens>
        </chunking>
        <chunking id="2" string="a series of rallies in recent weeks" type="NP">
          <tokens>
            <token id="2" string="a" />
            <token id="3" string="series" />
            <token id="4" string="of" />
            <token id="5" string="rallies" />
            <token id="6" string="in" />
            <token id="7" string="recent" />
            <token id="8" string="weeks" />
          </tokens>
        </chunking>
        <chunking id="3" string="rallies in recent weeks" type="NP">
          <tokens>
            <token id="5" string="rallies" />
            <token id="6" string="in" />
            <token id="7" string="recent" />
            <token id="8" string="weeks" />
          </tokens>
        </chunking>
        <chunking id="4" string="be dropped" type="VP">
          <tokens>
            <token id="29" string="be" />
            <token id="30" string="dropped" />
          </tokens>
        </chunking>
        <chunking id="5" string="established" type="VP">
          <tokens>
            <token id="40" string="established" />
          </tokens>
        </chunking>
        <chunking id="6" string="charges against those arrested at the hotel" type="NP">
          <tokens>
            <token id="22" string="charges" />
            <token id="23" string="against" />
            <token id="24" string="those" />
            <token id="25" string="arrested" />
            <token id="26" string="at" />
            <token id="27" string="the" />
            <token id="28" string="hotel" />
          </tokens>
        </chunking>
        <chunking id="7" string="protesters" type="NP">
          <tokens>
            <token id="10" string="protesters" />
          </tokens>
        </chunking>
        <chunking id="8" string="the drug raid" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="drug" />
            <token id="18" string="raid" />
          </tokens>
        </chunking>
        <chunking id="9" string="a citizen police review board" type="NP">
          <tokens>
            <token id="34" string="a" />
            <token id="35" string="citizen" />
            <token id="36" string="police" />
            <token id="37" string="review" />
            <token id="38" string="board" />
          </tokens>
        </chunking>
        <chunking id="10" string="charges" type="NP">
          <tokens>
            <token id="22" string="charges" />
          </tokens>
        </chunking>
        <chunking id="11" string="rallies" type="NP">
          <tokens>
            <token id="5" string="rallies" />
          </tokens>
        </chunking>
        <chunking id="12" string="dropped" type="VP">
          <tokens>
            <token id="30" string="dropped" />
          </tokens>
        </chunking>
        <chunking id="13" string="that officers involved in the drug raid be suspended , charges against those arrested at the hotel be dropped , and that a citizen police review board be established" type="SBAR">
          <tokens>
            <token id="12" string="that" />
            <token id="13" string="officers" />
            <token id="14" string="involved" />
            <token id="15" string="in" />
            <token id="16" string="the" />
            <token id="17" string="drug" />
            <token id="18" string="raid" />
            <token id="19" string="be" />
            <token id="20" string="suspended" />
            <token id="21" string="," />
            <token id="22" string="charges" />
            <token id="23" string="against" />
            <token id="24" string="those" />
            <token id="25" string="arrested" />
            <token id="26" string="at" />
            <token id="27" string="the" />
            <token id="28" string="hotel" />
            <token id="29" string="be" />
            <token id="30" string="dropped" />
            <token id="31" string="," />
            <token id="32" string="and" />
            <token id="33" string="that" />
            <token id="34" string="a" />
            <token id="35" string="citizen" />
            <token id="36" string="police" />
            <token id="37" string="review" />
            <token id="38" string="board" />
            <token id="39" string="be" />
            <token id="40" string="established" />
          </tokens>
        </chunking>
        <chunking id="14" string="arrested at the hotel" type="VP">
          <tokens>
            <token id="25" string="arrested" />
            <token id="26" string="at" />
            <token id="27" string="the" />
            <token id="28" string="hotel" />
          </tokens>
        </chunking>
        <chunking id="15" string="that a citizen police review board be established" type="SBAR">
          <tokens>
            <token id="33" string="that" />
            <token id="34" string="a" />
            <token id="35" string="citizen" />
            <token id="36" string="police" />
            <token id="37" string="review" />
            <token id="38" string="board" />
            <token id="39" string="be" />
            <token id="40" string="established" />
          </tokens>
        </chunking>
        <chunking id="16" string="be established" type="VP">
          <tokens>
            <token id="39" string="be" />
            <token id="40" string="established" />
          </tokens>
        </chunking>
        <chunking id="17" string="involved in the drug raid be suspended , charges against those arrested at the hotel" type="VP">
          <tokens>
            <token id="14" string="involved" />
            <token id="15" string="in" />
            <token id="16" string="the" />
            <token id="17" string="drug" />
            <token id="18" string="raid" />
            <token id="19" string="be" />
            <token id="20" string="suspended" />
            <token id="21" string="," />
            <token id="22" string="charges" />
            <token id="23" string="against" />
            <token id="24" string="those" />
            <token id="25" string="arrested" />
            <token id="26" string="at" />
            <token id="27" string="the" />
            <token id="28" string="hotel" />
          </tokens>
        </chunking>
        <chunking id="18" string="that officers involved in the drug raid be suspended , charges against those arrested at the hotel be dropped" type="SBAR">
          <tokens>
            <token id="12" string="that" />
            <token id="13" string="officers" />
            <token id="14" string="involved" />
            <token id="15" string="in" />
            <token id="16" string="the" />
            <token id="17" string="drug" />
            <token id="18" string="raid" />
            <token id="19" string="be" />
            <token id="20" string="suspended" />
            <token id="21" string="," />
            <token id="22" string="charges" />
            <token id="23" string="against" />
            <token id="24" string="those" />
            <token id="25" string="arrested" />
            <token id="26" string="at" />
            <token id="27" string="the" />
            <token id="28" string="hotel" />
            <token id="29" string="be" />
            <token id="30" string="dropped" />
          </tokens>
        </chunking>
        <chunking id="19" string="a series" type="NP">
          <tokens>
            <token id="2" string="a" />
            <token id="3" string="series" />
          </tokens>
        </chunking>
        <chunking id="20" string="recent weeks" type="NP">
          <tokens>
            <token id="7" string="recent" />
            <token id="8" string="weeks" />
          </tokens>
        </chunking>
        <chunking id="21" string="suspended , charges against those arrested at the hotel" type="VP">
          <tokens>
            <token id="20" string="suspended" />
            <token id="21" string="," />
            <token id="22" string="charges" />
            <token id="23" string="against" />
            <token id="24" string="those" />
            <token id="25" string="arrested" />
            <token id="26" string="at" />
            <token id="27" string="the" />
            <token id="28" string="hotel" />
          </tokens>
        </chunking>
        <chunking id="22" string="officers involved in the drug raid be suspended , charges against those arrested at the hotel" type="NP">
          <tokens>
            <token id="13" string="officers" />
            <token id="14" string="involved" />
            <token id="15" string="in" />
            <token id="16" string="the" />
            <token id="17" string="drug" />
            <token id="18" string="raid" />
            <token id="19" string="be" />
            <token id="20" string="suspended" />
            <token id="21" string="," />
            <token id="22" string="charges" />
            <token id="23" string="against" />
            <token id="24" string="those" />
            <token id="25" string="arrested" />
            <token id="26" string="at" />
            <token id="27" string="the" />
            <token id="28" string="hotel" />
          </tokens>
        </chunking>
        <chunking id="23" string="those arrested at the hotel" type="NP">
          <tokens>
            <token id="24" string="those" />
            <token id="25" string="arrested" />
            <token id="26" string="at" />
            <token id="27" string="the" />
            <token id="28" string="hotel" />
          </tokens>
        </chunking>
        <chunking id="24" string="demanded that officers involved in the drug raid be suspended , charges against those arrested at the hotel be dropped , and that a citizen police review board be established" type="VP">
          <tokens>
            <token id="11" string="demanded" />
            <token id="12" string="that" />
            <token id="13" string="officers" />
            <token id="14" string="involved" />
            <token id="15" string="in" />
            <token id="16" string="the" />
            <token id="17" string="drug" />
            <token id="18" string="raid" />
            <token id="19" string="be" />
            <token id="20" string="suspended" />
            <token id="21" string="," />
            <token id="22" string="charges" />
            <token id="23" string="against" />
            <token id="24" string="those" />
            <token id="25" string="arrested" />
            <token id="26" string="at" />
            <token id="27" string="the" />
            <token id="28" string="hotel" />
            <token id="29" string="be" />
            <token id="30" string="dropped" />
            <token id="31" string="," />
            <token id="32" string="and" />
            <token id="33" string="that" />
            <token id="34" string="a" />
            <token id="35" string="citizen" />
            <token id="36" string="police" />
            <token id="37" string="review" />
            <token id="38" string="board" />
            <token id="39" string="be" />
            <token id="40" string="established" />
          </tokens>
        </chunking>
        <chunking id="25" string="officers" type="NP">
          <tokens>
            <token id="13" string="officers" />
          </tokens>
        </chunking>
        <chunking id="26" string="the hotel" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="hotel" />
          </tokens>
        </chunking>
        <chunking id="27" string="those" type="NP">
          <tokens>
            <token id="24" string="those" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">series</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">series</governor>
          <dependent id="2">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">demanded</governor>
          <dependent id="3">series</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">rallies</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">series</governor>
          <dependent id="5">rallies</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">weeks</governor>
          <dependent id="6">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">weeks</governor>
          <dependent id="7">recent</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">rallies</governor>
          <dependent id="8">weeks</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">demanded</governor>
          <dependent id="10">protesters</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">demanded</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="30">dropped</governor>
          <dependent id="12">that</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="30">dropped</governor>
          <dependent id="13">officers</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="13">officers</governor>
          <dependent id="14">involved</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">raid</governor>
          <dependent id="15">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">raid</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">raid</governor>
          <dependent id="17">drug</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">involved</governor>
          <dependent id="18">raid</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="20">suspended</governor>
          <dependent id="19">be</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="14">involved</governor>
          <dependent id="20">suspended</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">suspended</governor>
          <dependent id="22">charges</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">those</governor>
          <dependent id="23">against</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">charges</governor>
          <dependent id="24">those</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="24">those</governor>
          <dependent id="25">arrested</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">hotel</governor>
          <dependent id="26">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">hotel</governor>
          <dependent id="27">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">arrested</governor>
          <dependent id="28">hotel</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="30">dropped</governor>
          <dependent id="29">be</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">demanded</governor>
          <dependent id="30">dropped</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="30">dropped</governor>
          <dependent id="32">and</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="40">established</governor>
          <dependent id="33">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="38">board</governor>
          <dependent id="34">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="38">board</governor>
          <dependent id="35">citizen</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="38">board</governor>
          <dependent id="36">police</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="38">board</governor>
          <dependent id="37">review</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="40">established</governor>
          <dependent id="38">board</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="40">established</governor>
          <dependent id="39">be</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="30">dropped</governor>
          <dependent id="40">established</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="recent weeks" type="DURATION" score="0.0">
          <tokens>
            <token id="7" string="recent" />
            <token id="8" string="weeks" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="18" has_coreference="true">
      <content>City Council voted last week to study the problem.</content>
      <tokens>
        <token id="1" string="City" lemma="City" stem="citi" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="2" string="Council" lemma="Council" stem="council" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="3" string="voted" lemma="vote" stem="vote" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="5" string="week" lemma="week" stem="week" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="study" lemma="study" stem="studi" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="problem" lemma="problem" stem="problem" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP City) (NNP Council)) (VP (VBD voted) (NP-TMP (JJ last) (NN week)) (S (VP (TO to) (VP (VB study) (NP (DT the) (NN problem)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="study the problem" type="VP">
          <tokens>
            <token id="7" string="study" />
            <token id="8" string="the" />
            <token id="9" string="problem" />
          </tokens>
        </chunking>
        <chunking id="2" string="the problem" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="problem" />
          </tokens>
        </chunking>
        <chunking id="3" string="voted last week to study the problem" type="VP">
          <tokens>
            <token id="3" string="voted" />
            <token id="4" string="last" />
            <token id="5" string="week" />
            <token id="6" string="to" />
            <token id="7" string="study" />
            <token id="8" string="the" />
            <token id="9" string="problem" />
          </tokens>
        </chunking>
        <chunking id="4" string="City Council" type="NP">
          <tokens>
            <token id="1" string="City" />
            <token id="2" string="Council" />
          </tokens>
        </chunking>
        <chunking id="5" string="to study the problem" type="VP">
          <tokens>
            <token id="6" string="to" />
            <token id="7" string="study" />
            <token id="8" string="the" />
            <token id="9" string="problem" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Council</governor>
          <dependent id="1">City</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">voted</governor>
          <dependent id="2">Council</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">voted</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">week</governor>
          <dependent id="4">last</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="3">voted</governor>
          <dependent id="5">week</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">study</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">voted</governor>
          <dependent id="7">study</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">problem</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">study</governor>
          <dependent id="9">problem</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="last week" type="DATE" score="0.0">
          <tokens>
            <token id="4" string="last" />
            <token id="5" string="week" />
          </tokens>
        </entity>
        <entity id="2" string="City Council" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="1" string="City" />
            <token id="2" string="Council" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="19" has_coreference="true">
      <content>``There are bad apples in every bunch and the Minneapolis Police Department is no exception,&amp;apost;&amp;apost; said Councilwoman Sayles Belton.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="There" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="bad" lemma="bad" stem="bad" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="apples" lemma="apple" stem="appl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="every" lemma="every" stem="everi" pos="DT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="bunch" lemma="bunch" stem="bunch" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="Minneapolis" lemma="Minneapolis" stem="minneapoli" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="12" string="Police" lemma="Police" stem="polic" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="13" string="Department" lemma="Department" stem="depart" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="14" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="exception" lemma="exception" stem="except" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="Councilwoman" lemma="Councilwoman" stem="councilwoman" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="Sayles" lemma="Sayles" stem="sayl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="22" string="Belton" lemma="Belton" stem="belton" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (S (NP (EX There)) (VP (VBP are) (NP (NP (JJ bad) (NNS apples)) (PP (IN in) (NP (DT every) (NN bunch)))))) (CC and) (S (NP (DT the) (NNP Minneapolis) (NNP Police) (NNP Department)) (VP (VBZ is) (NP (DT no) (NN exception))))) (, ,) ('' '') (VP (VBD said)) (NP (NNP Councilwoman) (NNP Sayles) (NNP Belton)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="bad apples in every bunch" type="NP">
          <tokens>
            <token id="4" string="bad" />
            <token id="5" string="apples" />
            <token id="6" string="in" />
            <token id="7" string="every" />
            <token id="8" string="bunch" />
          </tokens>
        </chunking>
        <chunking id="2" string="There" type="NP">
          <tokens>
            <token id="2" string="There" />
          </tokens>
        </chunking>
        <chunking id="3" string="no exception" type="NP">
          <tokens>
            <token id="15" string="no" />
            <token id="16" string="exception" />
          </tokens>
        </chunking>
        <chunking id="4" string="Councilwoman Sayles Belton" type="NP">
          <tokens>
            <token id="20" string="Councilwoman" />
            <token id="21" string="Sayles" />
            <token id="22" string="Belton" />
          </tokens>
        </chunking>
        <chunking id="5" string="are bad apples in every bunch" type="VP">
          <tokens>
            <token id="3" string="are" />
            <token id="4" string="bad" />
            <token id="5" string="apples" />
            <token id="6" string="in" />
            <token id="7" string="every" />
            <token id="8" string="bunch" />
          </tokens>
        </chunking>
        <chunking id="6" string="is no exception" type="VP">
          <tokens>
            <token id="14" string="is" />
            <token id="15" string="no" />
            <token id="16" string="exception" />
          </tokens>
        </chunking>
        <chunking id="7" string="every bunch" type="NP">
          <tokens>
            <token id="7" string="every" />
            <token id="8" string="bunch" />
          </tokens>
        </chunking>
        <chunking id="8" string="the Minneapolis Police Department" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="Minneapolis" />
            <token id="12" string="Police" />
            <token id="13" string="Department" />
          </tokens>
        </chunking>
        <chunking id="9" string="said" type="VP">
          <tokens>
            <token id="19" string="said" />
          </tokens>
        </chunking>
        <chunking id="10" string="bad apples" type="NP">
          <tokens>
            <token id="4" string="bad" />
            <token id="5" string="apples" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="expl">
          <governor id="3">are</governor>
          <dependent id="2">There</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="19">said</governor>
          <dependent id="3">are</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">apples</governor>
          <dependent id="4">bad</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">are</governor>
          <dependent id="5">apples</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">bunch</governor>
          <dependent id="6">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">bunch</governor>
          <dependent id="7">every</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">apples</governor>
          <dependent id="8">bunch</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">are</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">Department</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Department</governor>
          <dependent id="11">Minneapolis</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Department</governor>
          <dependent id="12">Police</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">exception</governor>
          <dependent id="13">Department</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="16">exception</governor>
          <dependent id="14">is</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="16">exception</governor>
          <dependent id="15">no</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">are</governor>
          <dependent id="16">exception</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="19">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">Belton</governor>
          <dependent id="20">Councilwoman</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">Belton</governor>
          <dependent id="21">Sayles</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">said</governor>
          <dependent id="22">Belton</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Minneapolis Police Department" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="11" string="Minneapolis" />
            <token id="12" string="Police" />
            <token id="13" string="Department" />
          </tokens>
        </entity>
        <entity id="2" string="Sayles Belton" type="PERSON" score="0.0">
          <tokens>
            <token id="21" string="Sayles" />
            <token id="22" string="Belton" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="20" has_coreference="true">
      <content>``I don&amp;apost;t think they (the good officers) are pleased with the few that are giving them the bad rap _ the spoilers.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="think" lemma="think" stem="think" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="good" lemma="good" stem="good" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="pleased" lemma="please" stem="pleas" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="few" lemma="few" stem="few" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="giving" lemma="give" stem="give" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="bad" lemma="bad" stem="bad" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="rap" lemma="rap" stem="rap" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="_" lemma="_" stem="_" pos="VBD" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="spoilers" lemma="spoiler" stem="spoiler" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP I)) (VP (VBP do) (RB n't) (VP (VB think) (NP (PRP they)) (SBAR (S (-LRB- -LRB-) (NP (DT the) (JJ good) (NNS officers)) (-RRB- -RRB-) (VP (VBP are) (ADJP (VBN pleased) (PP (IN with) (NP (NP (DT the) (JJ few)) (SBAR (WHNP (DT that)) (S (VP (VBP are) (VP (VBG giving) (NP (PRP them)) (NP (NP (DT the) (JJ bad) (NN rap)) (SBAR (S (VP (VBD _) (NP (DT the) (NNS spoilers)))))))))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="the bad rap _ the spoilers" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="bad" />
            <token id="23" string="rap" />
            <token id="24" string="_" />
            <token id="25" string="the" />
            <token id="26" string="spoilers" />
          </tokens>
        </chunking>
        <chunking id="2" string="the bad rap" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="bad" />
            <token id="23" string="rap" />
          </tokens>
        </chunking>
        <chunking id="3" string="-LRB- the good officers -RRB- are pleased with the few that are giving them the bad rap _ the spoilers" type="SBAR">
          <tokens>
            <token id="7" string="(" />
            <token id="8" string="the" />
            <token id="9" string="good" />
            <token id="10" string="officers" />
            <token id="11" string=")" />
            <token id="12" string="are" />
            <token id="13" string="pleased" />
            <token id="14" string="with" />
            <token id="15" string="the" />
            <token id="16" string="few" />
            <token id="17" string="that" />
            <token id="18" string="are" />
            <token id="19" string="giving" />
            <token id="20" string="them" />
            <token id="21" string="the" />
            <token id="22" string="bad" />
            <token id="23" string="rap" />
            <token id="24" string="_" />
            <token id="25" string="the" />
            <token id="26" string="spoilers" />
          </tokens>
        </chunking>
        <chunking id="4" string="the few that are giving them the bad rap _ the spoilers" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="few" />
            <token id="17" string="that" />
            <token id="18" string="are" />
            <token id="19" string="giving" />
            <token id="20" string="them" />
            <token id="21" string="the" />
            <token id="22" string="bad" />
            <token id="23" string="rap" />
            <token id="24" string="_" />
            <token id="25" string="the" />
            <token id="26" string="spoilers" />
          </tokens>
        </chunking>
        <chunking id="5" string="the few" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="few" />
          </tokens>
        </chunking>
        <chunking id="6" string="_ the spoilers" type="SBAR">
          <tokens>
            <token id="24" string="_" />
            <token id="25" string="the" />
            <token id="26" string="spoilers" />
          </tokens>
        </chunking>
        <chunking id="7" string="are giving them the bad rap _ the spoilers" type="VP">
          <tokens>
            <token id="18" string="are" />
            <token id="19" string="giving" />
            <token id="20" string="them" />
            <token id="21" string="the" />
            <token id="22" string="bad" />
            <token id="23" string="rap" />
            <token id="24" string="_" />
            <token id="25" string="the" />
            <token id="26" string="spoilers" />
          </tokens>
        </chunking>
        <chunking id="8" string="pleased with the few that are giving them the bad rap _ the spoilers" type="ADJP">
          <tokens>
            <token id="13" string="pleased" />
            <token id="14" string="with" />
            <token id="15" string="the" />
            <token id="16" string="few" />
            <token id="17" string="that" />
            <token id="18" string="are" />
            <token id="19" string="giving" />
            <token id="20" string="them" />
            <token id="21" string="the" />
            <token id="22" string="bad" />
            <token id="23" string="rap" />
            <token id="24" string="_" />
            <token id="25" string="the" />
            <token id="26" string="spoilers" />
          </tokens>
        </chunking>
        <chunking id="9" string="that are giving them the bad rap _ the spoilers" type="SBAR">
          <tokens>
            <token id="17" string="that" />
            <token id="18" string="are" />
            <token id="19" string="giving" />
            <token id="20" string="them" />
            <token id="21" string="the" />
            <token id="22" string="bad" />
            <token id="23" string="rap" />
            <token id="24" string="_" />
            <token id="25" string="the" />
            <token id="26" string="spoilers" />
          </tokens>
        </chunking>
        <chunking id="10" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="11" string="the spoilers" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="spoilers" />
          </tokens>
        </chunking>
        <chunking id="12" string="them" type="NP">
          <tokens>
            <token id="20" string="them" />
          </tokens>
        </chunking>
        <chunking id="13" string="are pleased with the few that are giving them the bad rap _ the spoilers" type="VP">
          <tokens>
            <token id="12" string="are" />
            <token id="13" string="pleased" />
            <token id="14" string="with" />
            <token id="15" string="the" />
            <token id="16" string="few" />
            <token id="17" string="that" />
            <token id="18" string="are" />
            <token id="19" string="giving" />
            <token id="20" string="them" />
            <token id="21" string="the" />
            <token id="22" string="bad" />
            <token id="23" string="rap" />
            <token id="24" string="_" />
            <token id="25" string="the" />
            <token id="26" string="spoilers" />
          </tokens>
        </chunking>
        <chunking id="14" string="they" type="NP">
          <tokens>
            <token id="6" string="they" />
          </tokens>
        </chunking>
        <chunking id="15" string="giving them the bad rap _ the spoilers" type="VP">
          <tokens>
            <token id="19" string="giving" />
            <token id="20" string="them" />
            <token id="21" string="the" />
            <token id="22" string="bad" />
            <token id="23" string="rap" />
            <token id="24" string="_" />
            <token id="25" string="the" />
            <token id="26" string="spoilers" />
          </tokens>
        </chunking>
        <chunking id="16" string="do n't think they -LRB- the good officers -RRB- are pleased with the few that are giving them the bad rap _ the spoilers" type="VP">
          <tokens>
            <token id="3" string="do" />
            <token id="4" string="n't" />
            <token id="5" string="think" />
            <token id="6" string="they" />
            <token id="7" string="(" />
            <token id="8" string="the" />
            <token id="9" string="good" />
            <token id="10" string="officers" />
            <token id="11" string=")" />
            <token id="12" string="are" />
            <token id="13" string="pleased" />
            <token id="14" string="with" />
            <token id="15" string="the" />
            <token id="16" string="few" />
            <token id="17" string="that" />
            <token id="18" string="are" />
            <token id="19" string="giving" />
            <token id="20" string="them" />
            <token id="21" string="the" />
            <token id="22" string="bad" />
            <token id="23" string="rap" />
            <token id="24" string="_" />
            <token id="25" string="the" />
            <token id="26" string="spoilers" />
          </tokens>
        </chunking>
        <chunking id="17" string="think they -LRB- the good officers -RRB- are pleased with the few that are giving them the bad rap _ the spoilers" type="VP">
          <tokens>
            <token id="5" string="think" />
            <token id="6" string="they" />
            <token id="7" string="(" />
            <token id="8" string="the" />
            <token id="9" string="good" />
            <token id="10" string="officers" />
            <token id="11" string=")" />
            <token id="12" string="are" />
            <token id="13" string="pleased" />
            <token id="14" string="with" />
            <token id="15" string="the" />
            <token id="16" string="few" />
            <token id="17" string="that" />
            <token id="18" string="are" />
            <token id="19" string="giving" />
            <token id="20" string="them" />
            <token id="21" string="the" />
            <token id="22" string="bad" />
            <token id="23" string="rap" />
            <token id="24" string="_" />
            <token id="25" string="the" />
            <token id="26" string="spoilers" />
          </tokens>
        </chunking>
        <chunking id="18" string="the good officers" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="good" />
            <token id="10" string="officers" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">think</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">think</governor>
          <dependent id="3">do</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">think</governor>
          <dependent id="4">n't</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">think</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">think</governor>
          <dependent id="6">they</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">officers</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">officers</governor>
          <dependent id="9">good</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="13">pleased</governor>
          <dependent id="10">officers</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="13">pleased</governor>
          <dependent id="12">are</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="5">think</governor>
          <dependent id="13">pleased</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">few</governor>
          <dependent id="14">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">few</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">pleased</governor>
          <dependent id="16">few</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">giving</governor>
          <dependent id="17">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="19">giving</governor>
          <dependent id="18">are</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="16">few</governor>
          <dependent id="19">giving</dependent>
        </dependency>
        <dependency type="iobj">
          <governor id="19">giving</governor>
          <dependent id="20">them</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">rap</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">rap</governor>
          <dependent id="22">bad</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">giving</governor>
          <dependent id="23">rap</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="23">rap</governor>
          <dependent id="24">_</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">spoilers</governor>
          <dependent id="25">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="24">_</governor>
          <dependent id="26">spoilers</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="21" has_coreference="true">
      <content>Lloyd Smalley, 71, and Lillian Weiss, 65, were killed Jan. 25 in a fire that started after police hurled a stun grenade into their apartment, where others also lived, during a drug raid.</content>
      <tokens>
        <token id="1" string="Lloyd" lemma="Lloyd" stem="lloyd" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="Smalley" lemma="Smalley" stem="smallei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="71" lemma="71" stem="71" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="Lillian" lemma="Lillian" stem="lillian" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="8" string="Weiss" lemma="Weiss" stem="weiss" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="65" lemma="65" stem="65" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="killed" lemma="kill" stem="kill" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="Jan." lemma="Jan." stem="jan." pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="15" string="25" lemma="25" stem="25" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="16" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="fire" lemma="fire" stem="fire" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="19" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="started" lemma="start" stem="start" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="hurled" lemma="hurl" stem="hurl" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="stun" lemma="stun" stem="stun" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="grenade" lemma="grenade" stem="grenad" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="apartment" lemma="apartment" stem="apart" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="where" lemma="where" stem="where" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="others" lemma="other" stem="other" pos="NNS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="lived" lemma="live" stem="live" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="during" lemma="during" stem="dure" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="38" string="drug" lemma="drug" stem="drug" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="39" string="raid" lemma="raid" stem="raid" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="40" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NP (NNP Lloyd) (NNP Smalley)) (, ,) (NP (CD 71)) (, ,) (CC and) (NP (NNP Lillian) (NNP Weiss))) (, ,) (NP (CD 65)) (, ,)) (VP (VBD were) (VP (VBN killed) (NP-TMP (NNP Jan.) (CD 25)) (PP (IN in) (NP (NP (DT a) (NN fire)) (SBAR (WHNP (WDT that)) (S (VP (VBD started) (SBAR (IN after) (S (NP (NN police)) (VP (VBD hurled) (NP (DT a) (JJ stun) (NN grenade)) (PP (IN into) (NP (PRP$ their) (NN apartment))) (, ,) (SBAR (WHADVP (WRB where)) (S (NP (NNS others)) (ADVP (RB also)) (VP (VBD lived) (, ,) (PP (IN during) (NP (DT a) (NN drug) (NN raid)))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="where others also lived , during a drug raid" type="SBAR">
          <tokens>
            <token id="31" string="where" />
            <token id="32" string="others" />
            <token id="33" string="also" />
            <token id="34" string="lived" />
            <token id="35" string="," />
            <token id="36" string="during" />
            <token id="37" string="a" />
            <token id="38" string="drug" />
            <token id="39" string="raid" />
          </tokens>
        </chunking>
        <chunking id="2" string="after police hurled a stun grenade into their apartment , where others also lived , during a drug raid" type="SBAR">
          <tokens>
            <token id="21" string="after" />
            <token id="22" string="police" />
            <token id="23" string="hurled" />
            <token id="24" string="a" />
            <token id="25" string="stun" />
            <token id="26" string="grenade" />
            <token id="27" string="into" />
            <token id="28" string="their" />
            <token id="29" string="apartment" />
            <token id="30" string="," />
            <token id="31" string="where" />
            <token id="32" string="others" />
            <token id="33" string="also" />
            <token id="34" string="lived" />
            <token id="35" string="," />
            <token id="36" string="during" />
            <token id="37" string="a" />
            <token id="38" string="drug" />
            <token id="39" string="raid" />
          </tokens>
        </chunking>
        <chunking id="3" string="a drug raid" type="NP">
          <tokens>
            <token id="37" string="a" />
            <token id="38" string="drug" />
            <token id="39" string="raid" />
          </tokens>
        </chunking>
        <chunking id="4" string="started after police hurled a stun grenade into their apartment , where others also lived , during a drug raid" type="VP">
          <tokens>
            <token id="20" string="started" />
            <token id="21" string="after" />
            <token id="22" string="police" />
            <token id="23" string="hurled" />
            <token id="24" string="a" />
            <token id="25" string="stun" />
            <token id="26" string="grenade" />
            <token id="27" string="into" />
            <token id="28" string="their" />
            <token id="29" string="apartment" />
            <token id="30" string="," />
            <token id="31" string="where" />
            <token id="32" string="others" />
            <token id="33" string="also" />
            <token id="34" string="lived" />
            <token id="35" string="," />
            <token id="36" string="during" />
            <token id="37" string="a" />
            <token id="38" string="drug" />
            <token id="39" string="raid" />
          </tokens>
        </chunking>
        <chunking id="5" string="a stun grenade" type="NP">
          <tokens>
            <token id="24" string="a" />
            <token id="25" string="stun" />
            <token id="26" string="grenade" />
          </tokens>
        </chunking>
        <chunking id="6" string="Lillian Weiss" type="NP">
          <tokens>
            <token id="7" string="Lillian" />
            <token id="8" string="Weiss" />
          </tokens>
        </chunking>
        <chunking id="7" string="a fire" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="fire" />
          </tokens>
        </chunking>
        <chunking id="8" string="their apartment" type="NP">
          <tokens>
            <token id="28" string="their" />
            <token id="29" string="apartment" />
          </tokens>
        </chunking>
        <chunking id="9" string="were killed Jan. 25 in a fire that started after police hurled a stun grenade into their apartment , where others also lived , during a drug raid" type="VP">
          <tokens>
            <token id="12" string="were" />
            <token id="13" string="killed" />
            <token id="14" string="Jan." />
            <token id="15" string="25" />
            <token id="16" string="in" />
            <token id="17" string="a" />
            <token id="18" string="fire" />
            <token id="19" string="that" />
            <token id="20" string="started" />
            <token id="21" string="after" />
            <token id="22" string="police" />
            <token id="23" string="hurled" />
            <token id="24" string="a" />
            <token id="25" string="stun" />
            <token id="26" string="grenade" />
            <token id="27" string="into" />
            <token id="28" string="their" />
            <token id="29" string="apartment" />
            <token id="30" string="," />
            <token id="31" string="where" />
            <token id="32" string="others" />
            <token id="33" string="also" />
            <token id="34" string="lived" />
            <token id="35" string="," />
            <token id="36" string="during" />
            <token id="37" string="a" />
            <token id="38" string="drug" />
            <token id="39" string="raid" />
          </tokens>
        </chunking>
        <chunking id="10" string="Lloyd Smalley , 71 , and Lillian Weiss , 65 ," type="NP">
          <tokens>
            <token id="1" string="Lloyd" />
            <token id="2" string="Smalley" />
            <token id="3" string="," />
            <token id="4" string="71" />
            <token id="5" string="," />
            <token id="6" string="and" />
            <token id="7" string="Lillian" />
            <token id="8" string="Weiss" />
            <token id="9" string="," />
            <token id="10" string="65" />
            <token id="11" string="," />
          </tokens>
        </chunking>
        <chunking id="11" string="police" type="NP">
          <tokens>
            <token id="22" string="police" />
          </tokens>
        </chunking>
        <chunking id="12" string="lived , during a drug raid" type="VP">
          <tokens>
            <token id="34" string="lived" />
            <token id="35" string="," />
            <token id="36" string="during" />
            <token id="37" string="a" />
            <token id="38" string="drug" />
            <token id="39" string="raid" />
          </tokens>
        </chunking>
        <chunking id="13" string="Lloyd Smalley" type="NP">
          <tokens>
            <token id="1" string="Lloyd" />
            <token id="2" string="Smalley" />
          </tokens>
        </chunking>
        <chunking id="14" string="that started after police hurled a stun grenade into their apartment , where others also lived , during a drug raid" type="SBAR">
          <tokens>
            <token id="19" string="that" />
            <token id="20" string="started" />
            <token id="21" string="after" />
            <token id="22" string="police" />
            <token id="23" string="hurled" />
            <token id="24" string="a" />
            <token id="25" string="stun" />
            <token id="26" string="grenade" />
            <token id="27" string="into" />
            <token id="28" string="their" />
            <token id="29" string="apartment" />
            <token id="30" string="," />
            <token id="31" string="where" />
            <token id="32" string="others" />
            <token id="33" string="also" />
            <token id="34" string="lived" />
            <token id="35" string="," />
            <token id="36" string="during" />
            <token id="37" string="a" />
            <token id="38" string="drug" />
            <token id="39" string="raid" />
          </tokens>
        </chunking>
        <chunking id="15" string="a fire that started after police hurled a stun grenade into their apartment , where others also lived , during a drug raid" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="fire" />
            <token id="19" string="that" />
            <token id="20" string="started" />
            <token id="21" string="after" />
            <token id="22" string="police" />
            <token id="23" string="hurled" />
            <token id="24" string="a" />
            <token id="25" string="stun" />
            <token id="26" string="grenade" />
            <token id="27" string="into" />
            <token id="28" string="their" />
            <token id="29" string="apartment" />
            <token id="30" string="," />
            <token id="31" string="where" />
            <token id="32" string="others" />
            <token id="33" string="also" />
            <token id="34" string="lived" />
            <token id="35" string="," />
            <token id="36" string="during" />
            <token id="37" string="a" />
            <token id="38" string="drug" />
            <token id="39" string="raid" />
          </tokens>
        </chunking>
        <chunking id="16" string="71" type="NP">
          <tokens>
            <token id="4" string="71" />
          </tokens>
        </chunking>
        <chunking id="17" string="killed Jan. 25 in a fire that started after police hurled a stun grenade into their apartment , where others also lived , during a drug raid" type="VP">
          <tokens>
            <token id="13" string="killed" />
            <token id="14" string="Jan." />
            <token id="15" string="25" />
            <token id="16" string="in" />
            <token id="17" string="a" />
            <token id="18" string="fire" />
            <token id="19" string="that" />
            <token id="20" string="started" />
            <token id="21" string="after" />
            <token id="22" string="police" />
            <token id="23" string="hurled" />
            <token id="24" string="a" />
            <token id="25" string="stun" />
            <token id="26" string="grenade" />
            <token id="27" string="into" />
            <token id="28" string="their" />
            <token id="29" string="apartment" />
            <token id="30" string="," />
            <token id="31" string="where" />
            <token id="32" string="others" />
            <token id="33" string="also" />
            <token id="34" string="lived" />
            <token id="35" string="," />
            <token id="36" string="during" />
            <token id="37" string="a" />
            <token id="38" string="drug" />
            <token id="39" string="raid" />
          </tokens>
        </chunking>
        <chunking id="18" string="where" type="WHADVP">
          <tokens>
            <token id="31" string="where" />
          </tokens>
        </chunking>
        <chunking id="19" string="Lloyd Smalley , 71 , and Lillian Weiss" type="NP">
          <tokens>
            <token id="1" string="Lloyd" />
            <token id="2" string="Smalley" />
            <token id="3" string="," />
            <token id="4" string="71" />
            <token id="5" string="," />
            <token id="6" string="and" />
            <token id="7" string="Lillian" />
            <token id="8" string="Weiss" />
          </tokens>
        </chunking>
        <chunking id="20" string="65" type="NP">
          <tokens>
            <token id="10" string="65" />
          </tokens>
        </chunking>
        <chunking id="21" string="hurled a stun grenade into their apartment , where others also lived , during a drug raid" type="VP">
          <tokens>
            <token id="23" string="hurled" />
            <token id="24" string="a" />
            <token id="25" string="stun" />
            <token id="26" string="grenade" />
            <token id="27" string="into" />
            <token id="28" string="their" />
            <token id="29" string="apartment" />
            <token id="30" string="," />
            <token id="31" string="where" />
            <token id="32" string="others" />
            <token id="33" string="also" />
            <token id="34" string="lived" />
            <token id="35" string="," />
            <token id="36" string="during" />
            <token id="37" string="a" />
            <token id="38" string="drug" />
            <token id="39" string="raid" />
          </tokens>
        </chunking>
        <chunking id="22" string="others" type="NP">
          <tokens>
            <token id="32" string="others" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Smalley</governor>
          <dependent id="1">Lloyd</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="13">killed</governor>
          <dependent id="2">Smalley</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">Smalley</governor>
          <dependent id="4">71</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">Smalley</governor>
          <dependent id="6">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">Weiss</governor>
          <dependent id="7">Lillian</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">Smalley</governor>
          <dependent id="8">Weiss</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="2">Smalley</governor>
          <dependent id="10">65</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="13">killed</governor>
          <dependent id="12">were</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">killed</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="13">killed</governor>
          <dependent id="14">Jan.</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="14">Jan.</governor>
          <dependent id="15">25</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">fire</governor>
          <dependent id="16">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">fire</governor>
          <dependent id="17">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">killed</governor>
          <dependent id="18">fire</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">started</governor>
          <dependent id="19">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="18">fire</governor>
          <dependent id="20">started</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="23">hurled</governor>
          <dependent id="21">after</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">hurled</governor>
          <dependent id="22">police</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="20">started</governor>
          <dependent id="23">hurled</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">grenade</governor>
          <dependent id="24">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">grenade</governor>
          <dependent id="25">stun</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="23">hurled</governor>
          <dependent id="26">grenade</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">apartment</governor>
          <dependent id="27">into</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="29">apartment</governor>
          <dependent id="28">their</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">hurled</governor>
          <dependent id="29">apartment</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="34">lived</governor>
          <dependent id="31">where</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="34">lived</governor>
          <dependent id="32">others</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="34">lived</governor>
          <dependent id="33">also</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="23">hurled</governor>
          <dependent id="34">lived</dependent>
        </dependency>
        <dependency type="case">
          <governor id="39">raid</governor>
          <dependent id="36">during</dependent>
        </dependency>
        <dependency type="det">
          <governor id="39">raid</governor>
          <dependent id="37">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="39">raid</governor>
          <dependent id="38">drug</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="34">lived</governor>
          <dependent id="39">raid</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lloyd Smalley" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Lloyd" />
            <token id="2" string="Smalley" />
          </tokens>
        </entity>
        <entity id="2" string="71" type="NUMBER" score="0.0">
          <tokens>
            <token id="4" string="71" />
          </tokens>
        </entity>
        <entity id="3" string="fire" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="18" string="fire" />
          </tokens>
        </entity>
        <entity id="4" string="Lillian Weiss" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Lillian" />
            <token id="8" string="Weiss" />
          </tokens>
        </entity>
        <entity id="5" string="Jan. 25" type="DATE" score="0.0">
          <tokens>
            <token id="14" string="Jan." />
            <token id="15" string="25" />
          </tokens>
        </entity>
        <entity id="6" string="65" type="NUMBER" score="0.0">
          <tokens>
            <token id="10" string="65" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="22" has_coreference="true">
      <content>No one conducting the raid knew the elderly people were living there, said Laux.</content>
      <tokens>
        <token id="1" string="No" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="one" lemma="one" stem="on" pos="NN" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="3" string="conducting" lemma="conduct" stem="conduct" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="raid" lemma="raid" stem="raid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="knew" lemma="know" stem="knew" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="elderly" lemma="elderly" stem="elderli" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="living" lemma="live" stem="live" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="there" lemma="there" stem="there" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="Laux" lemma="Laux" stem="laux" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (S (NP (NP (DT No) (NN one)) (VP (VBG conducting) (NP (DT the) (NN raid)))) (VP (VBD knew) (SBAR (S (NP (DT the) (JJ elderly) (NNS people)) (VP (VBD were) (VP (VBG living) (ADVP (RB there)))))))) (, ,) (VP (VBD said)) (NP (NNP Laux)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="No one" type="NP">
          <tokens>
            <token id="1" string="No" />
            <token id="2" string="one" />
          </tokens>
        </chunking>
        <chunking id="2" string="living there" type="VP">
          <tokens>
            <token id="11" string="living" />
            <token id="12" string="there" />
          </tokens>
        </chunking>
        <chunking id="3" string="the elderly people" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="elderly" />
            <token id="9" string="people" />
          </tokens>
        </chunking>
        <chunking id="4" string="knew the elderly people were living there" type="VP">
          <tokens>
            <token id="6" string="knew" />
            <token id="7" string="the" />
            <token id="8" string="elderly" />
            <token id="9" string="people" />
            <token id="10" string="were" />
            <token id="11" string="living" />
            <token id="12" string="there" />
          </tokens>
        </chunking>
        <chunking id="5" string="Laux" type="NP">
          <tokens>
            <token id="15" string="Laux" />
          </tokens>
        </chunking>
        <chunking id="6" string="the elderly people were living there" type="SBAR">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="elderly" />
            <token id="9" string="people" />
            <token id="10" string="were" />
            <token id="11" string="living" />
            <token id="12" string="there" />
          </tokens>
        </chunking>
        <chunking id="7" string="the raid" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="raid" />
          </tokens>
        </chunking>
        <chunking id="8" string="conducting the raid" type="VP">
          <tokens>
            <token id="3" string="conducting" />
            <token id="4" string="the" />
            <token id="5" string="raid" />
          </tokens>
        </chunking>
        <chunking id="9" string="No one conducting the raid" type="NP">
          <tokens>
            <token id="1" string="No" />
            <token id="2" string="one" />
            <token id="3" string="conducting" />
            <token id="4" string="the" />
            <token id="5" string="raid" />
          </tokens>
        </chunking>
        <chunking id="10" string="said" type="VP">
          <tokens>
            <token id="14" string="said" />
          </tokens>
        </chunking>
        <chunking id="11" string="were living there" type="VP">
          <tokens>
            <token id="10" string="were" />
            <token id="11" string="living" />
            <token id="12" string="there" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="neg">
          <governor id="2">one</governor>
          <dependent id="1">No</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">knew</governor>
          <dependent id="2">one</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="2">one</governor>
          <dependent id="3">conducting</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">raid</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">conducting</governor>
          <dependent id="5">raid</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="14">said</governor>
          <dependent id="6">knew</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">people</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">people</governor>
          <dependent id="8">elderly</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">living</governor>
          <dependent id="9">people</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">living</governor>
          <dependent id="10">were</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">knew</governor>
          <dependent id="11">living</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">living</governor>
          <dependent id="12">there</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">said</governor>
          <dependent id="15">Laux</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Laux" type="PERSON" score="0.0">
          <tokens>
            <token id="15" string="Laux" />
          </tokens>
        </entity>
        <entity id="2" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="2" string="one" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="23" has_coreference="true">
      <content>A grand jury decided not to bring charges against any officers, but an FBI investigation is continuing.</content>
      <tokens>
        <token id="1" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="grand" lemma="grand" stem="grand" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="jury" lemma="jury" stem="juri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="decided" lemma="decide" stem="decid" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="bring" lemma="bring" stem="bring" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="charges" lemma="charge" stem="charg" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="any" lemma="any" stem="ani" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="FBI" lemma="FBI" stem="fbi" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="16" string="investigation" lemma="investigation" stem="investig" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="continuing" lemma="continue" stem="continu" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (DT A) (JJ grand) (NN jury)) (VP (VBD decided) (S (RB not) (VP (TO to) (VP (VB bring) (NP (NNS charges)) (PP (IN against) (NP (DT any) (NNS officers)))))))) (, ,) (CC but) (S (NP (DT an) (NNP FBI) (NN investigation)) (VP (VBZ is) (VP (VBG continuing)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="bring charges against any officers" type="VP">
          <tokens>
            <token id="7" string="bring" />
            <token id="8" string="charges" />
            <token id="9" string="against" />
            <token id="10" string="any" />
            <token id="11" string="officers" />
          </tokens>
        </chunking>
        <chunking id="2" string="charges" type="NP">
          <tokens>
            <token id="8" string="charges" />
          </tokens>
        </chunking>
        <chunking id="3" string="an FBI investigation" type="NP">
          <tokens>
            <token id="14" string="an" />
            <token id="15" string="FBI" />
            <token id="16" string="investigation" />
          </tokens>
        </chunking>
        <chunking id="4" string="is continuing" type="VP">
          <tokens>
            <token id="17" string="is" />
            <token id="18" string="continuing" />
          </tokens>
        </chunking>
        <chunking id="5" string="A grand jury" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="grand" />
            <token id="3" string="jury" />
          </tokens>
        </chunking>
        <chunking id="6" string="any officers" type="NP">
          <tokens>
            <token id="10" string="any" />
            <token id="11" string="officers" />
          </tokens>
        </chunking>
        <chunking id="7" string="continuing" type="VP">
          <tokens>
            <token id="18" string="continuing" />
          </tokens>
        </chunking>
        <chunking id="8" string="decided not to bring charges against any officers" type="VP">
          <tokens>
            <token id="4" string="decided" />
            <token id="5" string="not" />
            <token id="6" string="to" />
            <token id="7" string="bring" />
            <token id="8" string="charges" />
            <token id="9" string="against" />
            <token id="10" string="any" />
            <token id="11" string="officers" />
          </tokens>
        </chunking>
        <chunking id="9" string="to bring charges against any officers" type="VP">
          <tokens>
            <token id="6" string="to" />
            <token id="7" string="bring" />
            <token id="8" string="charges" />
            <token id="9" string="against" />
            <token id="10" string="any" />
            <token id="11" string="officers" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">jury</governor>
          <dependent id="1">A</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">jury</governor>
          <dependent id="2">grand</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">decided</governor>
          <dependent id="3">jury</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">decided</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="7">bring</governor>
          <dependent id="5">not</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">bring</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">decided</governor>
          <dependent id="7">bring</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">bring</governor>
          <dependent id="8">charges</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">officers</governor>
          <dependent id="9">against</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">officers</governor>
          <dependent id="10">any</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">bring</governor>
          <dependent id="11">officers</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">decided</governor>
          <dependent id="13">but</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">investigation</governor>
          <dependent id="14">an</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">investigation</governor>
          <dependent id="15">FBI</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">continuing</governor>
          <dependent id="16">investigation</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="18">continuing</governor>
          <dependent id="17">is</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">decided</governor>
          <dependent id="18">continuing</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="FBI" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="15" string="FBI" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="24" has_coreference="true">
      <content>In the hotel scuffle, police said they responsed to a call of a loud party.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="hotel" lemma="hotel" stem="hotel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="scuffle" lemma="scuffle" stem="scuffl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="responsed" lemma="response" stem="respons" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="call" lemma="call" stem="call" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="loud" lemma="loud" stem="loud" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="party" lemma="party" stem="parti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (DT the) (NN hotel) (NN scuffle))) (, ,) (NP (NN police)) (VP (VBD said) (SBAR (S (NP (PRP they)) (VP (VBD responsed) (PP (TO to) (NP (NP (DT a) (NN call)) (PP (IN of) (NP (DT a) (JJ loud) (NN party))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the hotel scuffle" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="hotel" />
            <token id="4" string="scuffle" />
          </tokens>
        </chunking>
        <chunking id="2" string="police" type="NP">
          <tokens>
            <token id="6" string="police" />
          </tokens>
        </chunking>
        <chunking id="3" string="a call of a loud party" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="call" />
            <token id="13" string="of" />
            <token id="14" string="a" />
            <token id="15" string="loud" />
            <token id="16" string="party" />
          </tokens>
        </chunking>
        <chunking id="4" string="they" type="NP">
          <tokens>
            <token id="8" string="they" />
          </tokens>
        </chunking>
        <chunking id="5" string="they responsed to a call of a loud party" type="SBAR">
          <tokens>
            <token id="8" string="they" />
            <token id="9" string="responsed" />
            <token id="10" string="to" />
            <token id="11" string="a" />
            <token id="12" string="call" />
            <token id="13" string="of" />
            <token id="14" string="a" />
            <token id="15" string="loud" />
            <token id="16" string="party" />
          </tokens>
        </chunking>
        <chunking id="6" string="responsed to a call of a loud party" type="VP">
          <tokens>
            <token id="9" string="responsed" />
            <token id="10" string="to" />
            <token id="11" string="a" />
            <token id="12" string="call" />
            <token id="13" string="of" />
            <token id="14" string="a" />
            <token id="15" string="loud" />
            <token id="16" string="party" />
          </tokens>
        </chunking>
        <chunking id="7" string="said they responsed to a call of a loud party" type="VP">
          <tokens>
            <token id="7" string="said" />
            <token id="8" string="they" />
            <token id="9" string="responsed" />
            <token id="10" string="to" />
            <token id="11" string="a" />
            <token id="12" string="call" />
            <token id="13" string="of" />
            <token id="14" string="a" />
            <token id="15" string="loud" />
            <token id="16" string="party" />
          </tokens>
        </chunking>
        <chunking id="8" string="a call" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="call" />
          </tokens>
        </chunking>
        <chunking id="9" string="a loud party" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="loud" />
            <token id="16" string="party" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">scuffle</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">scuffle</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">scuffle</governor>
          <dependent id="3">hotel</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">said</governor>
          <dependent id="4">scuffle</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">said</governor>
          <dependent id="6">police</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">responsed</governor>
          <dependent id="8">they</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">said</governor>
          <dependent id="9">responsed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">call</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">call</governor>
          <dependent id="11">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">responsed</governor>
          <dependent id="12">call</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">party</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">party</governor>
          <dependent id="14">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">party</governor>
          <dependent id="15">loud</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">call</governor>
          <dependent id="16">party</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="25" has_coreference="true">
      <content>Partygoers alleged that officers used the term ``nigger,&amp;apost;&amp;apost; and beat some of those arrested.</content>
      <tokens>
        <token id="1" string="Partygoers" lemma="Partygoers" stem="partygo" pos="NNPS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="alleged" lemma="allege" stem="alleg" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="used" lemma="use" stem="us" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="term" lemma="term" stem="term" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="nigger" lemma="nigger" stem="nigger" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="beat" lemma="beat" stem="beat" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="those" lemma="those" stem="those" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="arrested" lemma="arrest" stem="arrest" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNPS Partygoers)) (VP (VBD alleged) (SBAR (IN that) (S (NP (NNS officers)) (VP (VP (VBD used) (NP (DT the) (NN term) (`` ``) (NN nigger) (, ,) ('' ''))) (CC and) (VP (VB beat) (NP (NP (DT some)) (PP (IN of) (NP (NP (DT those)) (VP (VBN arrested)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="alleged that officers used the term `` nigger , '' and beat some of those arrested" type="VP">
          <tokens>
            <token id="2" string="alleged" />
            <token id="3" string="that" />
            <token id="4" string="officers" />
            <token id="5" string="used" />
            <token id="6" string="the" />
            <token id="7" string="term" />
            <token id="8" string="``" />
            <token id="9" string="nigger" />
            <token id="10" string="," />
            <token id="11" string="''" />
            <token id="12" string="and" />
            <token id="13" string="beat" />
            <token id="14" string="some" />
            <token id="15" string="of" />
            <token id="16" string="those" />
            <token id="17" string="arrested" />
          </tokens>
        </chunking>
        <chunking id="2" string="used the term `` nigger , ''" type="VP">
          <tokens>
            <token id="5" string="used" />
            <token id="6" string="the" />
            <token id="7" string="term" />
            <token id="8" string="``" />
            <token id="9" string="nigger" />
            <token id="10" string="," />
            <token id="11" string="''" />
          </tokens>
        </chunking>
        <chunking id="3" string="Partygoers" type="NP">
          <tokens>
            <token id="1" string="Partygoers" />
          </tokens>
        </chunking>
        <chunking id="4" string="arrested" type="VP">
          <tokens>
            <token id="17" string="arrested" />
          </tokens>
        </chunking>
        <chunking id="5" string="beat some of those arrested" type="VP">
          <tokens>
            <token id="13" string="beat" />
            <token id="14" string="some" />
            <token id="15" string="of" />
            <token id="16" string="those" />
            <token id="17" string="arrested" />
          </tokens>
        </chunking>
        <chunking id="6" string="some" type="NP">
          <tokens>
            <token id="14" string="some" />
          </tokens>
        </chunking>
        <chunking id="7" string="used the term `` nigger , '' and beat some of those arrested" type="VP">
          <tokens>
            <token id="5" string="used" />
            <token id="6" string="the" />
            <token id="7" string="term" />
            <token id="8" string="``" />
            <token id="9" string="nigger" />
            <token id="10" string="," />
            <token id="11" string="''" />
            <token id="12" string="and" />
            <token id="13" string="beat" />
            <token id="14" string="some" />
            <token id="15" string="of" />
            <token id="16" string="those" />
            <token id="17" string="arrested" />
          </tokens>
        </chunking>
        <chunking id="8" string="some of those arrested" type="NP">
          <tokens>
            <token id="14" string="some" />
            <token id="15" string="of" />
            <token id="16" string="those" />
            <token id="17" string="arrested" />
          </tokens>
        </chunking>
        <chunking id="9" string="that officers used the term `` nigger , '' and beat some of those arrested" type="SBAR">
          <tokens>
            <token id="3" string="that" />
            <token id="4" string="officers" />
            <token id="5" string="used" />
            <token id="6" string="the" />
            <token id="7" string="term" />
            <token id="8" string="``" />
            <token id="9" string="nigger" />
            <token id="10" string="," />
            <token id="11" string="''" />
            <token id="12" string="and" />
            <token id="13" string="beat" />
            <token id="14" string="some" />
            <token id="15" string="of" />
            <token id="16" string="those" />
            <token id="17" string="arrested" />
          </tokens>
        </chunking>
        <chunking id="10" string="those arrested" type="NP">
          <tokens>
            <token id="16" string="those" />
            <token id="17" string="arrested" />
          </tokens>
        </chunking>
        <chunking id="11" string="officers" type="NP">
          <tokens>
            <token id="4" string="officers" />
          </tokens>
        </chunking>
        <chunking id="12" string="the term `` nigger , ''" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="term" />
            <token id="8" string="``" />
            <token id="9" string="nigger" />
            <token id="10" string="," />
            <token id="11" string="''" />
          </tokens>
        </chunking>
        <chunking id="13" string="those" type="NP">
          <tokens>
            <token id="16" string="those" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">alleged</governor>
          <dependent id="1">Partygoers</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">alleged</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">used</governor>
          <dependent id="3">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">used</governor>
          <dependent id="4">officers</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">alleged</governor>
          <dependent id="5">used</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">nigger</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">nigger</governor>
          <dependent id="7">term</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">used</governor>
          <dependent id="9">nigger</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">used</governor>
          <dependent id="12">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">used</governor>
          <dependent id="13">beat</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">beat</governor>
          <dependent id="14">some</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">those</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">some</governor>
          <dependent id="16">those</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="16">those</governor>
          <dependent id="17">arrested</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="26" has_coreference="true">
      <content>Laux said his officers have denied using racial names and said protesters lied about the number of people receiving medical attention following the arrests.</content>
      <tokens>
        <token id="1" string="Laux" lemma="Laux" stem="laux" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="denied" lemma="deny" stem="deni" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="using" lemma="use" stem="us" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="racial" lemma="racial" stem="racial" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="names" lemma="name" stem="name" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="protesters" lemma="protester" stem="protest" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="lied" lemma="lie" stem="li" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="number" lemma="number" stem="number" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="receiving" lemma="receive" stem="receiv" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="medical" lemma="medical" stem="medic" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="attention" lemma="attention" stem="attent" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="following" lemma="follow" stem="follow" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="arrests" lemma="arrest" stem="arrest" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Laux)) (VP (VP (VBD said) (SBAR (S (NP (PRP$ his) (NNS officers)) (VP (VBP have) (VP (VBN denied) (S (VP (VBG using) (NP (JJ racial) (NNS names))))))))) (CC and) (VP (VBD said) (SBAR (S (NP (NNS protesters)) (VP (VBD lied) (PP (IN about) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (NNS people))))) (S (VP (VBG receiving) (NP (NP (JJ medical) (NN attention)) (PP (VBG following) (NP (DT the) (NNS arrests))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="racial names" type="NP">
          <tokens>
            <token id="8" string="racial" />
            <token id="9" string="names" />
          </tokens>
        </chunking>
        <chunking id="2" string="the number of people" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="number" />
            <token id="17" string="of" />
            <token id="18" string="people" />
          </tokens>
        </chunking>
        <chunking id="3" string="said his officers have denied using racial names and said protesters lied about the number of people receiving medical attention following the arrests" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="his" />
            <token id="4" string="officers" />
            <token id="5" string="have" />
            <token id="6" string="denied" />
            <token id="7" string="using" />
            <token id="8" string="racial" />
            <token id="9" string="names" />
            <token id="10" string="and" />
            <token id="11" string="said" />
            <token id="12" string="protesters" />
            <token id="13" string="lied" />
            <token id="14" string="about" />
            <token id="15" string="the" />
            <token id="16" string="number" />
            <token id="17" string="of" />
            <token id="18" string="people" />
            <token id="19" string="receiving" />
            <token id="20" string="medical" />
            <token id="21" string="attention" />
            <token id="22" string="following" />
            <token id="23" string="the" />
            <token id="24" string="arrests" />
          </tokens>
        </chunking>
        <chunking id="4" string="his officers have denied using racial names" type="SBAR">
          <tokens>
            <token id="3" string="his" />
            <token id="4" string="officers" />
            <token id="5" string="have" />
            <token id="6" string="denied" />
            <token id="7" string="using" />
            <token id="8" string="racial" />
            <token id="9" string="names" />
          </tokens>
        </chunking>
        <chunking id="5" string="the arrests" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="arrests" />
          </tokens>
        </chunking>
        <chunking id="6" string="lied about the number of people receiving medical attention following the arrests" type="VP">
          <tokens>
            <token id="13" string="lied" />
            <token id="14" string="about" />
            <token id="15" string="the" />
            <token id="16" string="number" />
            <token id="17" string="of" />
            <token id="18" string="people" />
            <token id="19" string="receiving" />
            <token id="20" string="medical" />
            <token id="21" string="attention" />
            <token id="22" string="following" />
            <token id="23" string="the" />
            <token id="24" string="arrests" />
          </tokens>
        </chunking>
        <chunking id="7" string="his officers" type="NP">
          <tokens>
            <token id="3" string="his" />
            <token id="4" string="officers" />
          </tokens>
        </chunking>
        <chunking id="8" string="people" type="NP">
          <tokens>
            <token id="18" string="people" />
          </tokens>
        </chunking>
        <chunking id="9" string="receiving medical attention following the arrests" type="VP">
          <tokens>
            <token id="19" string="receiving" />
            <token id="20" string="medical" />
            <token id="21" string="attention" />
            <token id="22" string="following" />
            <token id="23" string="the" />
            <token id="24" string="arrests" />
          </tokens>
        </chunking>
        <chunking id="10" string="denied using racial names" type="VP">
          <tokens>
            <token id="6" string="denied" />
            <token id="7" string="using" />
            <token id="8" string="racial" />
            <token id="9" string="names" />
          </tokens>
        </chunking>
        <chunking id="11" string="protesters" type="NP">
          <tokens>
            <token id="12" string="protesters" />
          </tokens>
        </chunking>
        <chunking id="12" string="Laux" type="NP">
          <tokens>
            <token id="1" string="Laux" />
          </tokens>
        </chunking>
        <chunking id="13" string="have denied using racial names" type="VP">
          <tokens>
            <token id="5" string="have" />
            <token id="6" string="denied" />
            <token id="7" string="using" />
            <token id="8" string="racial" />
            <token id="9" string="names" />
          </tokens>
        </chunking>
        <chunking id="14" string="medical attention" type="NP">
          <tokens>
            <token id="20" string="medical" />
            <token id="21" string="attention" />
          </tokens>
        </chunking>
        <chunking id="15" string="said his officers have denied using racial names" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="his" />
            <token id="4" string="officers" />
            <token id="5" string="have" />
            <token id="6" string="denied" />
            <token id="7" string="using" />
            <token id="8" string="racial" />
            <token id="9" string="names" />
          </tokens>
        </chunking>
        <chunking id="16" string="using racial names" type="VP">
          <tokens>
            <token id="7" string="using" />
            <token id="8" string="racial" />
            <token id="9" string="names" />
          </tokens>
        </chunking>
        <chunking id="17" string="said protesters lied about the number of people receiving medical attention following the arrests" type="VP">
          <tokens>
            <token id="11" string="said" />
            <token id="12" string="protesters" />
            <token id="13" string="lied" />
            <token id="14" string="about" />
            <token id="15" string="the" />
            <token id="16" string="number" />
            <token id="17" string="of" />
            <token id="18" string="people" />
            <token id="19" string="receiving" />
            <token id="20" string="medical" />
            <token id="21" string="attention" />
            <token id="22" string="following" />
            <token id="23" string="the" />
            <token id="24" string="arrests" />
          </tokens>
        </chunking>
        <chunking id="18" string="protesters lied about the number of people receiving medical attention following the arrests" type="SBAR">
          <tokens>
            <token id="12" string="protesters" />
            <token id="13" string="lied" />
            <token id="14" string="about" />
            <token id="15" string="the" />
            <token id="16" string="number" />
            <token id="17" string="of" />
            <token id="18" string="people" />
            <token id="19" string="receiving" />
            <token id="20" string="medical" />
            <token id="21" string="attention" />
            <token id="22" string="following" />
            <token id="23" string="the" />
            <token id="24" string="arrests" />
          </tokens>
        </chunking>
        <chunking id="19" string="the number" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="number" />
          </tokens>
        </chunking>
        <chunking id="20" string="medical attention following the arrests" type="NP">
          <tokens>
            <token id="20" string="medical" />
            <token id="21" string="attention" />
            <token id="22" string="following" />
            <token id="23" string="the" />
            <token id="24" string="arrests" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">Laux</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">officers</governor>
          <dependent id="3">his</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">denied</governor>
          <dependent id="4">officers</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">denied</governor>
          <dependent id="5">have</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="6">denied</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">denied</governor>
          <dependent id="7">using</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">names</governor>
          <dependent id="8">racial</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">using</governor>
          <dependent id="9">names</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">said</governor>
          <dependent id="10">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">said</governor>
          <dependent id="11">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">lied</governor>
          <dependent id="12">protesters</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">said</governor>
          <dependent id="13">lied</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">number</governor>
          <dependent id="14">about</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">number</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">lied</governor>
          <dependent id="16">number</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">people</governor>
          <dependent id="17">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">number</governor>
          <dependent id="18">people</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="13">lied</governor>
          <dependent id="19">receiving</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">attention</governor>
          <dependent id="20">medical</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">receiving</governor>
          <dependent id="21">attention</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">arrests</governor>
          <dependent id="22">following</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">arrests</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">attention</governor>
          <dependent id="24">arrests</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Laux" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Laux" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="27" has_coreference="true">
      <content>Gleason Glover, president of the Minneapolis Urban League, which works for interracial cooperation, said police racism has been a problem since he took over the league position 21 years ago.</content>
      <tokens>
        <token id="1" string="Gleason" lemma="Gleason" stem="gleason" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="Glover" lemma="Glover" stem="glover" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="president" lemma="president" stem="presid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Minneapolis" lemma="Minneapolis" stem="minneapoli" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="8" string="Urban" lemma="Urban" stem="urban" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="9" string="League" lemma="League" stem="leagu" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="works" lemma="work" stem="work" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="interracial" lemma="interracial" stem="interraci" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="cooperation" lemma="cooperation" stem="cooper" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="racism" lemma="racism" stem="racism" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="problem" lemma="problem" stem="problem" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="24" string="since" lemma="since" stem="sinc" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="took" lemma="take" stem="took" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="over" lemma="over" stem="over" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="league" lemma="league" stem="leagu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="position" lemma="position" stem="posit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="21" lemma="21" stem="21" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="32" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="33" string="ago" lemma="ago" stem="ago" pos="RB" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="34" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Gleason) (NNP Glover)) (, ,) (NP (NP (NN president)) (PP (IN of) (NP (NP (DT the) (NNP Minneapolis) (NNP Urban) (NNP League)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ works) (PP (IN for) (NP (JJ interracial) (NN cooperation))))))))) (, ,)) (VP (VBD said) (SBAR (S (NP (NN police) (NN racism)) (VP (VBZ has) (VP (VBN been) (NP (DT a) (NN problem)) (SBAR (IN since) (S (NP (PRP he)) (VP (VBD took) (PRT (RP over)) (NP (DT the) (NN league) (NN position)) (ADVP (NP (CD 21) (NNS years)) (RB ago)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="president" type="NP">
          <tokens>
            <token id="4" string="president" />
          </tokens>
        </chunking>
        <chunking id="2" string="said police racism has been a problem since he took over the league position 21 years ago" type="VP">
          <tokens>
            <token id="17" string="said" />
            <token id="18" string="police" />
            <token id="19" string="racism" />
            <token id="20" string="has" />
            <token id="21" string="been" />
            <token id="22" string="a" />
            <token id="23" string="problem" />
            <token id="24" string="since" />
            <token id="25" string="he" />
            <token id="26" string="took" />
            <token id="27" string="over" />
            <token id="28" string="the" />
            <token id="29" string="league" />
            <token id="30" string="position" />
            <token id="31" string="21" />
            <token id="32" string="years" />
            <token id="33" string="ago" />
          </tokens>
        </chunking>
        <chunking id="3" string="since he took over the league position 21 years ago" type="SBAR">
          <tokens>
            <token id="24" string="since" />
            <token id="25" string="he" />
            <token id="26" string="took" />
            <token id="27" string="over" />
            <token id="28" string="the" />
            <token id="29" string="league" />
            <token id="30" string="position" />
            <token id="31" string="21" />
            <token id="32" string="years" />
            <token id="33" string="ago" />
          </tokens>
        </chunking>
        <chunking id="4" string="works for interracial cooperation" type="VP">
          <tokens>
            <token id="12" string="works" />
            <token id="13" string="for" />
            <token id="14" string="interracial" />
            <token id="15" string="cooperation" />
          </tokens>
        </chunking>
        <chunking id="5" string="the league position" type="NP">
          <tokens>
            <token id="28" string="the" />
            <token id="29" string="league" />
            <token id="30" string="position" />
          </tokens>
        </chunking>
        <chunking id="6" string="the Minneapolis Urban League" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="Minneapolis" />
            <token id="8" string="Urban" />
            <token id="9" string="League" />
          </tokens>
        </chunking>
        <chunking id="7" string="police racism" type="NP">
          <tokens>
            <token id="18" string="police" />
            <token id="19" string="racism" />
          </tokens>
        </chunking>
        <chunking id="8" string="took over the league position 21 years ago" type="VP">
          <tokens>
            <token id="26" string="took" />
            <token id="27" string="over" />
            <token id="28" string="the" />
            <token id="29" string="league" />
            <token id="30" string="position" />
            <token id="31" string="21" />
            <token id="32" string="years" />
            <token id="33" string="ago" />
          </tokens>
        </chunking>
        <chunking id="9" string="president of the Minneapolis Urban League , which works for interracial cooperation" type="NP">
          <tokens>
            <token id="4" string="president" />
            <token id="5" string="of" />
            <token id="6" string="the" />
            <token id="7" string="Minneapolis" />
            <token id="8" string="Urban" />
            <token id="9" string="League" />
            <token id="10" string="," />
            <token id="11" string="which" />
            <token id="12" string="works" />
            <token id="13" string="for" />
            <token id="14" string="interracial" />
            <token id="15" string="cooperation" />
          </tokens>
        </chunking>
        <chunking id="10" string="which works for interracial cooperation" type="SBAR">
          <tokens>
            <token id="11" string="which" />
            <token id="12" string="works" />
            <token id="13" string="for" />
            <token id="14" string="interracial" />
            <token id="15" string="cooperation" />
          </tokens>
        </chunking>
        <chunking id="11" string="police racism has been a problem since he took over the league position 21 years ago" type="SBAR">
          <tokens>
            <token id="18" string="police" />
            <token id="19" string="racism" />
            <token id="20" string="has" />
            <token id="21" string="been" />
            <token id="22" string="a" />
            <token id="23" string="problem" />
            <token id="24" string="since" />
            <token id="25" string="he" />
            <token id="26" string="took" />
            <token id="27" string="over" />
            <token id="28" string="the" />
            <token id="29" string="league" />
            <token id="30" string="position" />
            <token id="31" string="21" />
            <token id="32" string="years" />
            <token id="33" string="ago" />
          </tokens>
        </chunking>
        <chunking id="12" string="21 years" type="NP">
          <tokens>
            <token id="31" string="21" />
            <token id="32" string="years" />
          </tokens>
        </chunking>
        <chunking id="13" string="interracial cooperation" type="NP">
          <tokens>
            <token id="14" string="interracial" />
            <token id="15" string="cooperation" />
          </tokens>
        </chunking>
        <chunking id="14" string="Gleason Glover" type="NP">
          <tokens>
            <token id="1" string="Gleason" />
            <token id="2" string="Glover" />
          </tokens>
        </chunking>
        <chunking id="15" string="been a problem since he took over the league position 21 years ago" type="VP">
          <tokens>
            <token id="21" string="been" />
            <token id="22" string="a" />
            <token id="23" string="problem" />
            <token id="24" string="since" />
            <token id="25" string="he" />
            <token id="26" string="took" />
            <token id="27" string="over" />
            <token id="28" string="the" />
            <token id="29" string="league" />
            <token id="30" string="position" />
            <token id="31" string="21" />
            <token id="32" string="years" />
            <token id="33" string="ago" />
          </tokens>
        </chunking>
        <chunking id="16" string="has been a problem since he took over the league position 21 years ago" type="VP">
          <tokens>
            <token id="20" string="has" />
            <token id="21" string="been" />
            <token id="22" string="a" />
            <token id="23" string="problem" />
            <token id="24" string="since" />
            <token id="25" string="he" />
            <token id="26" string="took" />
            <token id="27" string="over" />
            <token id="28" string="the" />
            <token id="29" string="league" />
            <token id="30" string="position" />
            <token id="31" string="21" />
            <token id="32" string="years" />
            <token id="33" string="ago" />
          </tokens>
        </chunking>
        <chunking id="17" string="the Minneapolis Urban League , which works for interracial cooperation" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="Minneapolis" />
            <token id="8" string="Urban" />
            <token id="9" string="League" />
            <token id="10" string="," />
            <token id="11" string="which" />
            <token id="12" string="works" />
            <token id="13" string="for" />
            <token id="14" string="interracial" />
            <token id="15" string="cooperation" />
          </tokens>
        </chunking>
        <chunking id="18" string="Gleason Glover , president of the Minneapolis Urban League , which works for interracial cooperation ," type="NP">
          <tokens>
            <token id="1" string="Gleason" />
            <token id="2" string="Glover" />
            <token id="3" string="," />
            <token id="4" string="president" />
            <token id="5" string="of" />
            <token id="6" string="the" />
            <token id="7" string="Minneapolis" />
            <token id="8" string="Urban" />
            <token id="9" string="League" />
            <token id="10" string="," />
            <token id="11" string="which" />
            <token id="12" string="works" />
            <token id="13" string="for" />
            <token id="14" string="interracial" />
            <token id="15" string="cooperation" />
            <token id="16" string="," />
          </tokens>
        </chunking>
        <chunking id="19" string="he" type="NP">
          <tokens>
            <token id="25" string="he" />
          </tokens>
        </chunking>
        <chunking id="20" string="a problem" type="NP">
          <tokens>
            <token id="22" string="a" />
            <token id="23" string="problem" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Glover</governor>
          <dependent id="1">Gleason</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">said</governor>
          <dependent id="2">Glover</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="2">Glover</governor>
          <dependent id="4">president</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">League</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">League</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">League</governor>
          <dependent id="7">Minneapolis</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">League</governor>
          <dependent id="8">Urban</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">president</governor>
          <dependent id="9">League</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">works</governor>
          <dependent id="11">which</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="9">League</governor>
          <dependent id="12">works</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">cooperation</governor>
          <dependent id="13">for</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">cooperation</governor>
          <dependent id="14">interracial</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">works</governor>
          <dependent id="15">cooperation</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="17">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">racism</governor>
          <dependent id="18">police</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">problem</governor>
          <dependent id="19">racism</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="23">problem</governor>
          <dependent id="20">has</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="23">problem</governor>
          <dependent id="21">been</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">problem</governor>
          <dependent id="22">a</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="17">said</governor>
          <dependent id="23">problem</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="26">took</governor>
          <dependent id="24">since</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">took</governor>
          <dependent id="25">he</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="23">problem</governor>
          <dependent id="26">took</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="26">took</governor>
          <dependent id="27">over</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">position</governor>
          <dependent id="28">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="30">position</governor>
          <dependent id="29">league</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="26">took</governor>
          <dependent id="30">position</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="32">years</governor>
          <dependent id="31">21</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="33">ago</governor>
          <dependent id="32">years</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="26">took</governor>
          <dependent id="33">ago</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="21 years ago" type="DATE" score="0.0">
          <tokens>
            <token id="31" string="21" />
            <token id="32" string="years" />
            <token id="33" string="ago" />
          </tokens>
        </entity>
        <entity id="2" string="Minneapolis Urban League" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="7" string="Minneapolis" />
            <token id="8" string="Urban" />
            <token id="9" string="League" />
          </tokens>
        </entity>
        <entity id="3" string="Gleason Glover" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Gleason" />
            <token id="2" string="Glover" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="28" has_coreference="true">
      <content>``The matter of police misconduct and brutality has been going on for at least the 21 years I&amp;apost;ve been here, but I think the deaths pushed the issue beyond the point of tolerance that usually is the case in matters of police misconduct,&amp;apost;&amp;apost; Glover said.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="matter" lemma="matter" stem="matter" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="misconduct" lemma="misconduct" stem="misconduct" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="brutality" lemma="brutality" stem="brutal" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="going" lemma="go" stem="go" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="15" string="least" lemma="least" stem="least" pos="JJS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="17" string="21" lemma="21" stem="21" pos="CD" type="Number" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="18" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="19" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="'ve" lemma="have" stem="'ve" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="here" lemma="here" stem="here" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="26" string="think" lemma="think" stem="think" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="28" string="deaths" lemma="death" stem="death" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="29" string="pushed" lemma="push" stem="push" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="issue" lemma="issue" stem="issu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="beyond" lemma="beyond" stem="beyond" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="point" lemma="point" stem="point" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="tolerance" lemma="tolerance" stem="toler" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="usually" lemma="usually" stem="usual" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="matters" lemma="matter" stem="matter" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="44" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="46" string="misconduct" lemma="misconduct" stem="misconduct" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="47" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="48" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="49" string="Glover" lemma="Glover" stem="glover" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="50" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="51" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (NP (DT The) (NN matter)) (PP (IN of) (NP (NN police) (NN misconduct) (CC and) (NN brutality)))) (VP (VBZ has) (VP (VBN been) (VP (VBG going) (PP (IN on) (PP (IN for) (ADVP (IN at) (JJS least)))) (NP-TMP (DT the) (CD 21) (NNS years)) (SBAR (S (NP (PRP I)) (VP (VBP 've) (VP (VBN been) (ADVP (RB here))))) (, ,) (CC but) (S (NP (PRP I)) (VP (VBP think) (SBAR (S (NP (DT the) (NNS deaths)) (VP (VBD pushed) (NP (DT the) (NN issue)) (PP (IN beyond) (NP (NP (DT the) (NN point)) (PP (IN of) (NP (NN tolerance))) (SBAR (WHNP (WDT that)) (S (ADVP (RB usually)) (VP (VBZ is) (NP (NP (DT the) (NN case)) (PP (IN in) (NP (NP (NNS matters)) (PP (IN of) (NP (NN police) (NN misconduct))))))))))))))))))))) (, ,) ('' '') (NP (NNP Glover)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="is the case in matters of police misconduct" type="VP">
          <tokens>
            <token id="39" string="is" />
            <token id="40" string="the" />
            <token id="41" string="case" />
            <token id="42" string="in" />
            <token id="43" string="matters" />
            <token id="44" string="of" />
            <token id="45" string="police" />
            <token id="46" string="misconduct" />
          </tokens>
        </chunking>
        <chunking id="2" string="been here" type="VP">
          <tokens>
            <token id="21" string="been" />
            <token id="22" string="here" />
          </tokens>
        </chunking>
        <chunking id="3" string="the case" type="NP">
          <tokens>
            <token id="40" string="the" />
            <token id="41" string="case" />
          </tokens>
        </chunking>
        <chunking id="4" string="that usually is the case in matters of police misconduct" type="SBAR">
          <tokens>
            <token id="37" string="that" />
            <token id="38" string="usually" />
            <token id="39" string="is" />
            <token id="40" string="the" />
            <token id="41" string="case" />
            <token id="42" string="in" />
            <token id="43" string="matters" />
            <token id="44" string="of" />
            <token id="45" string="police" />
            <token id="46" string="misconduct" />
          </tokens>
        </chunking>
        <chunking id="5" string="has been going on for at least the 21 years I 've been here , but I think the deaths pushed the issue beyond the point of tolerance that usually is the case in matters of police misconduct" type="VP">
          <tokens>
            <token id="9" string="has" />
            <token id="10" string="been" />
            <token id="11" string="going" />
            <token id="12" string="on" />
            <token id="13" string="for" />
            <token id="14" string="at" />
            <token id="15" string="least" />
            <token id="16" string="the" />
            <token id="17" string="21" />
            <token id="18" string="years" />
            <token id="19" string="I" />
            <token id="20" string="'ve" />
            <token id="21" string="been" />
            <token id="22" string="here" />
            <token id="23" string="," />
            <token id="24" string="but" />
            <token id="25" string="I" />
            <token id="26" string="think" />
            <token id="27" string="the" />
            <token id="28" string="deaths" />
            <token id="29" string="pushed" />
            <token id="30" string="the" />
            <token id="31" string="issue" />
            <token id="32" string="beyond" />
            <token id="33" string="the" />
            <token id="34" string="point" />
            <token id="35" string="of" />
            <token id="36" string="tolerance" />
            <token id="37" string="that" />
            <token id="38" string="usually" />
            <token id="39" string="is" />
            <token id="40" string="the" />
            <token id="41" string="case" />
            <token id="42" string="in" />
            <token id="43" string="matters" />
            <token id="44" string="of" />
            <token id="45" string="police" />
            <token id="46" string="misconduct" />
          </tokens>
        </chunking>
        <chunking id="6" string="the point" type="NP">
          <tokens>
            <token id="33" string="the" />
            <token id="34" string="point" />
          </tokens>
        </chunking>
        <chunking id="7" string="matters of police misconduct" type="NP">
          <tokens>
            <token id="43" string="matters" />
            <token id="44" string="of" />
            <token id="45" string="police" />
            <token id="46" string="misconduct" />
          </tokens>
        </chunking>
        <chunking id="8" string="matters" type="NP">
          <tokens>
            <token id="43" string="matters" />
          </tokens>
        </chunking>
        <chunking id="9" string="The matter" type="NP">
          <tokens>
            <token id="2" string="The" />
            <token id="3" string="matter" />
          </tokens>
        </chunking>
        <chunking id="10" string="I 've been here , but I think the deaths pushed the issue beyond the point of tolerance that usually is the case in matters of police misconduct" type="SBAR">
          <tokens>
            <token id="19" string="I" />
            <token id="20" string="'ve" />
            <token id="21" string="been" />
            <token id="22" string="here" />
            <token id="23" string="," />
            <token id="24" string="but" />
            <token id="25" string="I" />
            <token id="26" string="think" />
            <token id="27" string="the" />
            <token id="28" string="deaths" />
            <token id="29" string="pushed" />
            <token id="30" string="the" />
            <token id="31" string="issue" />
            <token id="32" string="beyond" />
            <token id="33" string="the" />
            <token id="34" string="point" />
            <token id="35" string="of" />
            <token id="36" string="tolerance" />
            <token id="37" string="that" />
            <token id="38" string="usually" />
            <token id="39" string="is" />
            <token id="40" string="the" />
            <token id="41" string="case" />
            <token id="42" string="in" />
            <token id="43" string="matters" />
            <token id="44" string="of" />
            <token id="45" string="police" />
            <token id="46" string="misconduct" />
          </tokens>
        </chunking>
        <chunking id="11" string="the point of tolerance that usually is the case in matters of police misconduct" type="NP">
          <tokens>
            <token id="33" string="the" />
            <token id="34" string="point" />
            <token id="35" string="of" />
            <token id="36" string="tolerance" />
            <token id="37" string="that" />
            <token id="38" string="usually" />
            <token id="39" string="is" />
            <token id="40" string="the" />
            <token id="41" string="case" />
            <token id="42" string="in" />
            <token id="43" string="matters" />
            <token id="44" string="of" />
            <token id="45" string="police" />
            <token id="46" string="misconduct" />
          </tokens>
        </chunking>
        <chunking id="12" string="The matter of police misconduct and brutality" type="NP">
          <tokens>
            <token id="2" string="The" />
            <token id="3" string="matter" />
            <token id="4" string="of" />
            <token id="5" string="police" />
            <token id="6" string="misconduct" />
            <token id="7" string="and" />
            <token id="8" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="13" string="the issue" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="issue" />
          </tokens>
        </chunking>
        <chunking id="14" string="police misconduct and brutality" type="NP">
          <tokens>
            <token id="5" string="police" />
            <token id="6" string="misconduct" />
            <token id="7" string="and" />
            <token id="8" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="15" string="I" type="NP">
          <tokens>
            <token id="19" string="I" />
          </tokens>
        </chunking>
        <chunking id="16" string="going on for at least the 21 years I 've been here , but I think the deaths pushed the issue beyond the point of tolerance that usually is the case in matters of police misconduct" type="VP">
          <tokens>
            <token id="11" string="going" />
            <token id="12" string="on" />
            <token id="13" string="for" />
            <token id="14" string="at" />
            <token id="15" string="least" />
            <token id="16" string="the" />
            <token id="17" string="21" />
            <token id="18" string="years" />
            <token id="19" string="I" />
            <token id="20" string="'ve" />
            <token id="21" string="been" />
            <token id="22" string="here" />
            <token id="23" string="," />
            <token id="24" string="but" />
            <token id="25" string="I" />
            <token id="26" string="think" />
            <token id="27" string="the" />
            <token id="28" string="deaths" />
            <token id="29" string="pushed" />
            <token id="30" string="the" />
            <token id="31" string="issue" />
            <token id="32" string="beyond" />
            <token id="33" string="the" />
            <token id="34" string="point" />
            <token id="35" string="of" />
            <token id="36" string="tolerance" />
            <token id="37" string="that" />
            <token id="38" string="usually" />
            <token id="39" string="is" />
            <token id="40" string="the" />
            <token id="41" string="case" />
            <token id="42" string="in" />
            <token id="43" string="matters" />
            <token id="44" string="of" />
            <token id="45" string="police" />
            <token id="46" string="misconduct" />
          </tokens>
        </chunking>
        <chunking id="17" string="the deaths pushed the issue beyond the point of tolerance that usually is the case in matters of police misconduct" type="SBAR">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="deaths" />
            <token id="29" string="pushed" />
            <token id="30" string="the" />
            <token id="31" string="issue" />
            <token id="32" string="beyond" />
            <token id="33" string="the" />
            <token id="34" string="point" />
            <token id="35" string="of" />
            <token id="36" string="tolerance" />
            <token id="37" string="that" />
            <token id="38" string="usually" />
            <token id="39" string="is" />
            <token id="40" string="the" />
            <token id="41" string="case" />
            <token id="42" string="in" />
            <token id="43" string="matters" />
            <token id="44" string="of" />
            <token id="45" string="police" />
            <token id="46" string="misconduct" />
          </tokens>
        </chunking>
        <chunking id="18" string="police misconduct" type="NP">
          <tokens>
            <token id="45" string="police" />
            <token id="46" string="misconduct" />
          </tokens>
        </chunking>
        <chunking id="19" string="'ve been here" type="VP">
          <tokens>
            <token id="20" string="'ve" />
            <token id="21" string="been" />
            <token id="22" string="here" />
          </tokens>
        </chunking>
        <chunking id="20" string="been going on for at least the 21 years I 've been here , but I think the deaths pushed the issue beyond the point of tolerance that usually is the case in matters of police misconduct" type="VP">
          <tokens>
            <token id="10" string="been" />
            <token id="11" string="going" />
            <token id="12" string="on" />
            <token id="13" string="for" />
            <token id="14" string="at" />
            <token id="15" string="least" />
            <token id="16" string="the" />
            <token id="17" string="21" />
            <token id="18" string="years" />
            <token id="19" string="I" />
            <token id="20" string="'ve" />
            <token id="21" string="been" />
            <token id="22" string="here" />
            <token id="23" string="," />
            <token id="24" string="but" />
            <token id="25" string="I" />
            <token id="26" string="think" />
            <token id="27" string="the" />
            <token id="28" string="deaths" />
            <token id="29" string="pushed" />
            <token id="30" string="the" />
            <token id="31" string="issue" />
            <token id="32" string="beyond" />
            <token id="33" string="the" />
            <token id="34" string="point" />
            <token id="35" string="of" />
            <token id="36" string="tolerance" />
            <token id="37" string="that" />
            <token id="38" string="usually" />
            <token id="39" string="is" />
            <token id="40" string="the" />
            <token id="41" string="case" />
            <token id="42" string="in" />
            <token id="43" string="matters" />
            <token id="44" string="of" />
            <token id="45" string="police" />
            <token id="46" string="misconduct" />
          </tokens>
        </chunking>
        <chunking id="21" string="Glover" type="NP">
          <tokens>
            <token id="49" string="Glover" />
          </tokens>
        </chunking>
        <chunking id="22" string="pushed the issue beyond the point of tolerance that usually is the case in matters of police misconduct" type="VP">
          <tokens>
            <token id="29" string="pushed" />
            <token id="30" string="the" />
            <token id="31" string="issue" />
            <token id="32" string="beyond" />
            <token id="33" string="the" />
            <token id="34" string="point" />
            <token id="35" string="of" />
            <token id="36" string="tolerance" />
            <token id="37" string="that" />
            <token id="38" string="usually" />
            <token id="39" string="is" />
            <token id="40" string="the" />
            <token id="41" string="case" />
            <token id="42" string="in" />
            <token id="43" string="matters" />
            <token id="44" string="of" />
            <token id="45" string="police" />
            <token id="46" string="misconduct" />
          </tokens>
        </chunking>
        <chunking id="23" string="the deaths" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="deaths" />
          </tokens>
        </chunking>
        <chunking id="24" string="the case in matters of police misconduct" type="NP">
          <tokens>
            <token id="40" string="the" />
            <token id="41" string="case" />
            <token id="42" string="in" />
            <token id="43" string="matters" />
            <token id="44" string="of" />
            <token id="45" string="police" />
            <token id="46" string="misconduct" />
          </tokens>
        </chunking>
        <chunking id="25" string="said" type="VP">
          <tokens>
            <token id="50" string="said" />
          </tokens>
        </chunking>
        <chunking id="26" string="think the deaths pushed the issue beyond the point of tolerance that usually is the case in matters of police misconduct" type="VP">
          <tokens>
            <token id="26" string="think" />
            <token id="27" string="the" />
            <token id="28" string="deaths" />
            <token id="29" string="pushed" />
            <token id="30" string="the" />
            <token id="31" string="issue" />
            <token id="32" string="beyond" />
            <token id="33" string="the" />
            <token id="34" string="point" />
            <token id="35" string="of" />
            <token id="36" string="tolerance" />
            <token id="37" string="that" />
            <token id="38" string="usually" />
            <token id="39" string="is" />
            <token id="40" string="the" />
            <token id="41" string="case" />
            <token id="42" string="in" />
            <token id="43" string="matters" />
            <token id="44" string="of" />
            <token id="45" string="police" />
            <token id="46" string="misconduct" />
          </tokens>
        </chunking>
        <chunking id="27" string="tolerance" type="NP">
          <tokens>
            <token id="36" string="tolerance" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">matter</governor>
          <dependent id="2">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">going</governor>
          <dependent id="3">matter</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">misconduct</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">misconduct</governor>
          <dependent id="5">police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">matter</governor>
          <dependent id="6">misconduct</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">misconduct</governor>
          <dependent id="7">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">misconduct</governor>
          <dependent id="8">brutality</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">going</governor>
          <dependent id="9">has</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">going</governor>
          <dependent id="10">been</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="50">said</governor>
          <dependent id="11">going</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">at</governor>
          <dependent id="12">on</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">at</governor>
          <dependent id="13">for</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="11">going</governor>
          <dependent id="14">at</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="14">at</governor>
          <dependent id="15">least</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">years</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="18">years</governor>
          <dependent id="17">21</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="11">going</governor>
          <dependent id="18">years</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">been</governor>
          <dependent id="19">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="21">been</governor>
          <dependent id="20">'ve</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">going</governor>
          <dependent id="21">been</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="21">been</governor>
          <dependent id="22">here</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="21">been</governor>
          <dependent id="24">but</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">think</governor>
          <dependent id="25">I</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="21">been</governor>
          <dependent id="26">think</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">deaths</governor>
          <dependent id="27">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">pushed</governor>
          <dependent id="28">deaths</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="26">think</governor>
          <dependent id="29">pushed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">issue</governor>
          <dependent id="30">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="29">pushed</governor>
          <dependent id="31">issue</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">point</governor>
          <dependent id="32">beyond</dependent>
        </dependency>
        <dependency type="det">
          <governor id="34">point</governor>
          <dependent id="33">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">pushed</governor>
          <dependent id="34">point</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">tolerance</governor>
          <dependent id="35">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="34">point</governor>
          <dependent id="36">tolerance</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="41">case</governor>
          <dependent id="37">that</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="41">case</governor>
          <dependent id="38">usually</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="41">case</governor>
          <dependent id="39">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="41">case</governor>
          <dependent id="40">the</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="34">point</governor>
          <dependent id="41">case</dependent>
        </dependency>
        <dependency type="case">
          <governor id="43">matters</governor>
          <dependent id="42">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="41">case</governor>
          <dependent id="43">matters</dependent>
        </dependency>
        <dependency type="case">
          <governor id="46">misconduct</governor>
          <dependent id="44">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="46">misconduct</governor>
          <dependent id="45">police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="43">matters</governor>
          <dependent id="46">misconduct</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="50">said</governor>
          <dependent id="49">Glover</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="50">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Glover" type="PERSON" score="0.0">
          <tokens>
            <token id="49" string="Glover" />
          </tokens>
        </entity>
        <entity id="2" string="at least the 21 years" type="DURATION" score="0.0">
          <tokens>
            <token id="14" string="at" />
            <token id="15" string="least" />
            <token id="16" string="the" />
            <token id="17" string="21" />
            <token id="18" string="years" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="29" has_coreference="true">
      <content>``There is deep resentment in both the black community and among police officers with regard to how they feel they are perceived by each other ... I do not see a quick fix solution to it,&amp;apost;&amp;apost; Glover said.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="There" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="deep" lemma="deep" stem="deep" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="resentment" lemma="resentment" stem="resent" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="both" lemma="both" stem="both" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="black" lemma="black" stem="black" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="community" lemma="community" stem="commun" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="among" lemma="among" stem="among" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="police" lemma="police" stem="polic" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="regard" lemma="regard" stem="regard" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="how" lemma="how" stem="how" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="feel" lemma="feel" stem="feel" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="perceived" lemma="perceive" stem="perceiv" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="each" lemma="each" stem="each" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="..." lemma="..." stem="..." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="29" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="see" lemma="see" stem="see" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="33" string="quick" lemma="quick" stem="quick" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="34" string="fix" lemma="fix" stem="fix" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="35" string="solution" lemma="solution" stem="solut" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="36" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="Glover" lemma="Glover" stem="glover" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="41" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (S (NP (EX There)) (VP (VBZ is) (NP (JJ deep) (NN resentment)) (PP (PP (IN in) (CC both) (NP (DT the) (JJ black) (NN community))) (CC and) (PP (IN among) (NP (NP (NNS police) (NNS officers)) (PP (IN with) (NP (NN regard)))))) (PP (TO to) (SBAR (WHADVP (WRB how)) (S (NP (PRP they)) (VP (VBP feel) (SBAR (S (NP (PRP they)) (VP (VBP are) (VP (VBN perceived) (PP (IN by) (NP (DT each) (JJ other))))))))))))) (: ...) (S (NP (PRP I)) (VP (VBP do) (RB not) (VP (VB see) (NP (DT a) (JJ quick) (NN fix) (NN solution)) (PP (TO to) (NP (PRP it))))))) (, ,) ('' '') (NP (NNP Glover)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="each other" type="NP">
          <tokens>
            <token id="25" string="each" />
            <token id="26" string="other" />
          </tokens>
        </chunking>
        <chunking id="2" string="perceived by each other" type="VP">
          <tokens>
            <token id="23" string="perceived" />
            <token id="24" string="by" />
            <token id="25" string="each" />
            <token id="26" string="other" />
          </tokens>
        </chunking>
        <chunking id="3" string="do not see a quick fix solution to it" type="VP">
          <tokens>
            <token id="29" string="do" />
            <token id="30" string="not" />
            <token id="31" string="see" />
            <token id="32" string="a" />
            <token id="33" string="quick" />
            <token id="34" string="fix" />
            <token id="35" string="solution" />
            <token id="36" string="to" />
            <token id="37" string="it" />
          </tokens>
        </chunking>
        <chunking id="4" string="is deep resentment in both the black community and among police officers with regard to how they feel they are perceived by each other" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="deep" />
            <token id="5" string="resentment" />
            <token id="6" string="in" />
            <token id="7" string="both" />
            <token id="8" string="the" />
            <token id="9" string="black" />
            <token id="10" string="community" />
            <token id="11" string="and" />
            <token id="12" string="among" />
            <token id="13" string="police" />
            <token id="14" string="officers" />
            <token id="15" string="with" />
            <token id="16" string="regard" />
            <token id="17" string="to" />
            <token id="18" string="how" />
            <token id="19" string="they" />
            <token id="20" string="feel" />
            <token id="21" string="they" />
            <token id="22" string="are" />
            <token id="23" string="perceived" />
            <token id="24" string="by" />
            <token id="25" string="each" />
            <token id="26" string="other" />
          </tokens>
        </chunking>
        <chunking id="5" string="I" type="NP">
          <tokens>
            <token id="28" string="I" />
          </tokens>
        </chunking>
        <chunking id="6" string="see a quick fix solution to it" type="VP">
          <tokens>
            <token id="31" string="see" />
            <token id="32" string="a" />
            <token id="33" string="quick" />
            <token id="34" string="fix" />
            <token id="35" string="solution" />
            <token id="36" string="to" />
            <token id="37" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="37" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="deep resentment" type="NP">
          <tokens>
            <token id="4" string="deep" />
            <token id="5" string="resentment" />
          </tokens>
        </chunking>
        <chunking id="9" string="how" type="WHADVP">
          <tokens>
            <token id="18" string="how" />
          </tokens>
        </chunking>
        <chunking id="10" string="a quick fix solution" type="NP">
          <tokens>
            <token id="32" string="a" />
            <token id="33" string="quick" />
            <token id="34" string="fix" />
            <token id="35" string="solution" />
          </tokens>
        </chunking>
        <chunking id="11" string="they" type="NP">
          <tokens>
            <token id="19" string="they" />
          </tokens>
        </chunking>
        <chunking id="12" string="the black community" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="black" />
            <token id="10" string="community" />
          </tokens>
        </chunking>
        <chunking id="13" string="feel they are perceived by each other" type="VP">
          <tokens>
            <token id="20" string="feel" />
            <token id="21" string="they" />
            <token id="22" string="are" />
            <token id="23" string="perceived" />
            <token id="24" string="by" />
            <token id="25" string="each" />
            <token id="26" string="other" />
          </tokens>
        </chunking>
        <chunking id="14" string="There" type="NP">
          <tokens>
            <token id="2" string="There" />
          </tokens>
        </chunking>
        <chunking id="15" string="how they feel they are perceived by each other" type="SBAR">
          <tokens>
            <token id="18" string="how" />
            <token id="19" string="they" />
            <token id="20" string="feel" />
            <token id="21" string="they" />
            <token id="22" string="are" />
            <token id="23" string="perceived" />
            <token id="24" string="by" />
            <token id="25" string="each" />
            <token id="26" string="other" />
          </tokens>
        </chunking>
        <chunking id="16" string="regard" type="NP">
          <tokens>
            <token id="16" string="regard" />
          </tokens>
        </chunking>
        <chunking id="17" string="Glover" type="NP">
          <tokens>
            <token id="40" string="Glover" />
          </tokens>
        </chunking>
        <chunking id="18" string="they are perceived by each other" type="SBAR">
          <tokens>
            <token id="21" string="they" />
            <token id="22" string="are" />
            <token id="23" string="perceived" />
            <token id="24" string="by" />
            <token id="25" string="each" />
            <token id="26" string="other" />
          </tokens>
        </chunking>
        <chunking id="19" string="police officers" type="NP">
          <tokens>
            <token id="13" string="police" />
            <token id="14" string="officers" />
          </tokens>
        </chunking>
        <chunking id="20" string="are perceived by each other" type="VP">
          <tokens>
            <token id="22" string="are" />
            <token id="23" string="perceived" />
            <token id="24" string="by" />
            <token id="25" string="each" />
            <token id="26" string="other" />
          </tokens>
        </chunking>
        <chunking id="21" string="said" type="VP">
          <tokens>
            <token id="41" string="said" />
          </tokens>
        </chunking>
        <chunking id="22" string="police officers with regard" type="NP">
          <tokens>
            <token id="13" string="police" />
            <token id="14" string="officers" />
            <token id="15" string="with" />
            <token id="16" string="regard" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="expl">
          <governor id="3">is</governor>
          <dependent id="2">There</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="41">said</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">resentment</governor>
          <dependent id="4">deep</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">is</governor>
          <dependent id="5">resentment</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">is</governor>
          <dependent id="6">in</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="6">in</governor>
          <dependent id="7">both</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">community</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">community</governor>
          <dependent id="9">black</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">in</governor>
          <dependent id="10">community</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">in</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">officers</governor>
          <dependent id="12">among</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">officers</governor>
          <dependent id="13">police</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">in</governor>
          <dependent id="14">officers</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">regard</governor>
          <dependent id="15">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">officers</governor>
          <dependent id="16">regard</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="20">feel</governor>
          <dependent id="17">to</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="20">feel</governor>
          <dependent id="18">how</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">feel</governor>
          <dependent id="19">they</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">is</governor>
          <dependent id="20">feel</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="23">perceived</governor>
          <dependent id="21">they</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="23">perceived</governor>
          <dependent id="22">are</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="20">feel</governor>
          <dependent id="23">perceived</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">other</governor>
          <dependent id="24">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">other</governor>
          <dependent id="25">each</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">perceived</governor>
          <dependent id="26">other</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="31">see</governor>
          <dependent id="28">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="31">see</governor>
          <dependent id="29">do</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="31">see</governor>
          <dependent id="30">not</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="3">is</governor>
          <dependent id="31">see</dependent>
        </dependency>
        <dependency type="det">
          <governor id="35">solution</governor>
          <dependent id="32">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="35">solution</governor>
          <dependent id="33">quick</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="35">solution</governor>
          <dependent id="34">fix</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="31">see</governor>
          <dependent id="35">solution</dependent>
        </dependency>
        <dependency type="case">
          <governor id="37">it</governor>
          <dependent id="36">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">see</governor>
          <dependent id="37">it</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="41">said</governor>
          <dependent id="40">Glover</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="41">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Glover" type="PERSON" score="0.0">
          <tokens>
            <token id="40" string="Glover" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="30" has_coreference="true">
      <content>Allegations of police misconduct currently are reviewed by a panel appointed by the mayor.</content>
      <tokens>
        <token id="1" string="Allegations" lemma="allegation" stem="allegat" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="misconduct" lemma="misconduct" stem="misconduct" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="currently" lemma="currently" stem="current" pos="RB" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="6" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="reviewed" lemma="review" stem="review" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="panel" lemma="panel" stem="panel" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="appointed" lemma="appoint" stem="appoint" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="14" string="mayor" lemma="mayor" stem="mayor" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNS Allegations)) (PP (IN of) (NP (NN police) (NN misconduct)))) (ADVP (RB currently)) (VP (VBP are) (VP (VBN reviewed) (PP (IN by) (NP (NP (DT a) (NN panel)) (VP (VBN appointed) (PP (IN by) (NP (DT the) (NN mayor)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="police misconduct" type="NP">
          <tokens>
            <token id="3" string="police" />
            <token id="4" string="misconduct" />
          </tokens>
        </chunking>
        <chunking id="2" string="reviewed by a panel appointed by the mayor" type="VP">
          <tokens>
            <token id="7" string="reviewed" />
            <token id="8" string="by" />
            <token id="9" string="a" />
            <token id="10" string="panel" />
            <token id="11" string="appointed" />
            <token id="12" string="by" />
            <token id="13" string="the" />
            <token id="14" string="mayor" />
          </tokens>
        </chunking>
        <chunking id="3" string="Allegations of police misconduct" type="NP">
          <tokens>
            <token id="1" string="Allegations" />
            <token id="2" string="of" />
            <token id="3" string="police" />
            <token id="4" string="misconduct" />
          </tokens>
        </chunking>
        <chunking id="4" string="the mayor" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="mayor" />
          </tokens>
        </chunking>
        <chunking id="5" string="are reviewed by a panel appointed by the mayor" type="VP">
          <tokens>
            <token id="6" string="are" />
            <token id="7" string="reviewed" />
            <token id="8" string="by" />
            <token id="9" string="a" />
            <token id="10" string="panel" />
            <token id="11" string="appointed" />
            <token id="12" string="by" />
            <token id="13" string="the" />
            <token id="14" string="mayor" />
          </tokens>
        </chunking>
        <chunking id="6" string="appointed by the mayor" type="VP">
          <tokens>
            <token id="11" string="appointed" />
            <token id="12" string="by" />
            <token id="13" string="the" />
            <token id="14" string="mayor" />
          </tokens>
        </chunking>
        <chunking id="7" string="a panel" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="panel" />
          </tokens>
        </chunking>
        <chunking id="8" string="a panel appointed by the mayor" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="panel" />
            <token id="11" string="appointed" />
            <token id="12" string="by" />
            <token id="13" string="the" />
            <token id="14" string="mayor" />
          </tokens>
        </chunking>
        <chunking id="9" string="Allegations" type="NP">
          <tokens>
            <token id="1" string="Allegations" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="7">reviewed</governor>
          <dependent id="1">Allegations</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">misconduct</governor>
          <dependent id="2">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">misconduct</governor>
          <dependent id="3">police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Allegations</governor>
          <dependent id="4">misconduct</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">reviewed</governor>
          <dependent id="5">currently</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="7">reviewed</governor>
          <dependent id="6">are</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">reviewed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">panel</governor>
          <dependent id="8">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">panel</governor>
          <dependent id="9">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">reviewed</governor>
          <dependent id="10">panel</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="10">panel</governor>
          <dependent id="11">appointed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">mayor</governor>
          <dependent id="12">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">mayor</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">appointed</governor>
          <dependent id="14">mayor</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="currently" type="DATE" score="0.0">
          <tokens>
            <token id="5" string="currently" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="31" has_coreference="true">
      <content>The panel can only make recommendations.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="panel" lemma="panel" stem="panel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="only" lemma="only" stem="onli" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="make" lemma="make" stem="make" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="recommendations" lemma="recommendation" stem="recommend" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN panel)) (VP (MD can) (ADVP (RB only)) (VP (VB make) (NP (NNS recommendations)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="The panel" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="panel" />
          </tokens>
        </chunking>
        <chunking id="2" string="can only make recommendations" type="VP">
          <tokens>
            <token id="3" string="can" />
            <token id="4" string="only" />
            <token id="5" string="make" />
            <token id="6" string="recommendations" />
          </tokens>
        </chunking>
        <chunking id="3" string="recommendations" type="NP">
          <tokens>
            <token id="6" string="recommendations" />
          </tokens>
        </chunking>
        <chunking id="4" string="make recommendations" type="VP">
          <tokens>
            <token id="5" string="make" />
            <token id="6" string="recommendations" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">panel</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">make</governor>
          <dependent id="2">panel</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">make</governor>
          <dependent id="3">can</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">make</governor>
          <dependent id="4">only</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">make</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">make</governor>
          <dependent id="6">recommendations</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="32" has_coreference="true">
      <content>Laux opposes establisment of a citizen panel to look into police actions.</content>
      <tokens>
        <token id="1" string="Laux" lemma="Laux" stem="laux" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="opposes" lemma="oppose" stem="oppos" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="establisment" lemma="establisment" stem="establis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="citizen" lemma="citizen" stem="citizen" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="panel" lemma="panel" stem="panel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="look" lemma="look" stem="look" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="actions" lemma="action" stem="action" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Laux)) (VP (VBZ opposes) (S (NP (NP (NN establisment)) (PP (IN of) (NP (DT a) (NN citizen) (NN panel)))) (VP (TO to) (VP (VB look) (PP (IN into) (NP (NN police) (NNS actions))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="look into police actions" type="VP">
          <tokens>
            <token id="9" string="look" />
            <token id="10" string="into" />
            <token id="11" string="police" />
            <token id="12" string="actions" />
          </tokens>
        </chunking>
        <chunking id="2" string="Laux" type="NP">
          <tokens>
            <token id="1" string="Laux" />
          </tokens>
        </chunking>
        <chunking id="3" string="a citizen panel" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="citizen" />
            <token id="7" string="panel" />
          </tokens>
        </chunking>
        <chunking id="4" string="to look into police actions" type="VP">
          <tokens>
            <token id="8" string="to" />
            <token id="9" string="look" />
            <token id="10" string="into" />
            <token id="11" string="police" />
            <token id="12" string="actions" />
          </tokens>
        </chunking>
        <chunking id="5" string="police actions" type="NP">
          <tokens>
            <token id="11" string="police" />
            <token id="12" string="actions" />
          </tokens>
        </chunking>
        <chunking id="6" string="opposes establisment of a citizen panel to look into police actions" type="VP">
          <tokens>
            <token id="2" string="opposes" />
            <token id="3" string="establisment" />
            <token id="4" string="of" />
            <token id="5" string="a" />
            <token id="6" string="citizen" />
            <token id="7" string="panel" />
            <token id="8" string="to" />
            <token id="9" string="look" />
            <token id="10" string="into" />
            <token id="11" string="police" />
            <token id="12" string="actions" />
          </tokens>
        </chunking>
        <chunking id="7" string="establisment of a citizen panel" type="NP">
          <tokens>
            <token id="3" string="establisment" />
            <token id="4" string="of" />
            <token id="5" string="a" />
            <token id="6" string="citizen" />
            <token id="7" string="panel" />
          </tokens>
        </chunking>
        <chunking id="8" string="establisment" type="NP">
          <tokens>
            <token id="3" string="establisment" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">opposes</governor>
          <dependent id="1">Laux</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">opposes</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">opposes</governor>
          <dependent id="3">establisment</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">panel</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">panel</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">panel</governor>
          <dependent id="6">citizen</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">establisment</governor>
          <dependent id="7">panel</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">look</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="2">opposes</governor>
          <dependent id="9">look</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">actions</governor>
          <dependent id="10">into</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">actions</governor>
          <dependent id="11">police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">look</governor>
          <dependent id="12">actions</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Laux" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Laux" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="33" has_coreference="true">
      <content>``The key point is that any time the head of the police department cannot hire, fire or impose discipline, you are no longer in charge,&amp;apost;&amp;apost; he said.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="key" lemma="key" stem="kei" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="point" lemma="point" stem="point" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="any" lemma="any" stem="ani" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="head" lemma="head" stem="head" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="department" lemma="department" stem="depart" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="hire" lemma="hire" stem="hire" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="fire" lemma="fire" stem="fire" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="20" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="impose" lemma="impose" stem="impos" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="discipline" lemma="discipline" stem="disciplin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="no" lemma="no" stem="no" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="longer" lemma="longer" stem="longer" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="charge" lemma="charge" stem="charg" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="33" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (S (NP (DT The) (JJ key) (NN point)) (VP (VBZ is) (SBAR (IN that) (S (NP-TMP (DT any) (NN time)) (NP (NP (DT the) (NN head)) (PP (IN of) (NP (DT the) (NN police) (NN department)))) (VP (MD can) (RB not) (VP (VP (VB hire) (FRAG (, ,) (NP (NN fire)))) (CC or) (VP (VB impose) (NP (NN discipline))))))))) (, ,) (NP (PRP you)) (VP (VBP are) (ADVP (RB no) (RB longer)) (PP (IN in) (NP (NN charge))))) (, ,) ('' '') (NP (PRP he)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="charge" type="NP">
          <tokens>
            <token id="29" string="charge" />
          </tokens>
        </chunking>
        <chunking id="2" string="that any time the head of the police department can not hire , fire or impose discipline" type="SBAR">
          <tokens>
            <token id="6" string="that" />
            <token id="7" string="any" />
            <token id="8" string="time" />
            <token id="9" string="the" />
            <token id="10" string="head" />
            <token id="11" string="of" />
            <token id="12" string="the" />
            <token id="13" string="police" />
            <token id="14" string="department" />
            <token id="15" string="can" />
            <token id="16" string="not" />
            <token id="17" string="hire" />
            <token id="18" string="," />
            <token id="19" string="fire" />
            <token id="20" string="or" />
            <token id="21" string="impose" />
            <token id="22" string="discipline" />
          </tokens>
        </chunking>
        <chunking id="3" string="is that any time the head of the police department can not hire , fire or impose discipline" type="VP">
          <tokens>
            <token id="5" string="is" />
            <token id="6" string="that" />
            <token id="7" string="any" />
            <token id="8" string="time" />
            <token id="9" string="the" />
            <token id="10" string="head" />
            <token id="11" string="of" />
            <token id="12" string="the" />
            <token id="13" string="police" />
            <token id="14" string="department" />
            <token id="15" string="can" />
            <token id="16" string="not" />
            <token id="17" string="hire" />
            <token id="18" string="," />
            <token id="19" string="fire" />
            <token id="20" string="or" />
            <token id="21" string="impose" />
            <token id="22" string="discipline" />
          </tokens>
        </chunking>
        <chunking id="4" string="the police department" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="police" />
            <token id="14" string="department" />
          </tokens>
        </chunking>
        <chunking id="5" string="hire , fire or impose discipline" type="VP">
          <tokens>
            <token id="17" string="hire" />
            <token id="18" string="," />
            <token id="19" string="fire" />
            <token id="20" string="or" />
            <token id="21" string="impose" />
            <token id="22" string="discipline" />
          </tokens>
        </chunking>
        <chunking id="6" string="impose discipline" type="VP">
          <tokens>
            <token id="21" string="impose" />
            <token id="22" string="discipline" />
          </tokens>
        </chunking>
        <chunking id="7" string="the head of the police department" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="head" />
            <token id="11" string="of" />
            <token id="12" string="the" />
            <token id="13" string="police" />
            <token id="14" string="department" />
          </tokens>
        </chunking>
        <chunking id="8" string="The key point" type="NP">
          <tokens>
            <token id="2" string="The" />
            <token id="3" string="key" />
            <token id="4" string="point" />
          </tokens>
        </chunking>
        <chunking id="9" string="hire , fire" type="VP">
          <tokens>
            <token id="17" string="hire" />
            <token id="18" string="," />
            <token id="19" string="fire" />
          </tokens>
        </chunking>
        <chunking id="10" string="the head" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="head" />
          </tokens>
        </chunking>
        <chunking id="11" string="discipline" type="NP">
          <tokens>
            <token id="22" string="discipline" />
          </tokens>
        </chunking>
        <chunking id="12" string="are no longer in charge" type="VP">
          <tokens>
            <token id="25" string="are" />
            <token id="26" string="no" />
            <token id="27" string="longer" />
            <token id="28" string="in" />
            <token id="29" string="charge" />
          </tokens>
        </chunking>
        <chunking id="13" string="fire" type="NP">
          <tokens>
            <token id="19" string="fire" />
          </tokens>
        </chunking>
        <chunking id="14" string="he" type="NP">
          <tokens>
            <token id="32" string="he" />
          </tokens>
        </chunking>
        <chunking id="15" string="said" type="VP">
          <tokens>
            <token id="33" string="said" />
          </tokens>
        </chunking>
        <chunking id="16" string="can not hire , fire or impose discipline" type="VP">
          <tokens>
            <token id="15" string="can" />
            <token id="16" string="not" />
            <token id="17" string="hire" />
            <token id="18" string="," />
            <token id="19" string="fire" />
            <token id="20" string="or" />
            <token id="21" string="impose" />
            <token id="22" string="discipline" />
          </tokens>
        </chunking>
        <chunking id="17" string="you" type="NP">
          <tokens>
            <token id="24" string="you" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="4">point</governor>
          <dependent id="2">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">point</governor>
          <dependent id="3">key</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">is</governor>
          <dependent id="4">point</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="29">charge</governor>
          <dependent id="5">is</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">hire</governor>
          <dependent id="6">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">time</governor>
          <dependent id="7">any</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="17">hire</governor>
          <dependent id="8">time</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">head</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">hire</governor>
          <dependent id="10">head</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">department</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">department</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">department</governor>
          <dependent id="13">police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">head</governor>
          <dependent id="14">department</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="17">hire</governor>
          <dependent id="15">can</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="17">hire</governor>
          <dependent id="16">not</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">is</governor>
          <dependent id="17">hire</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="17">hire</governor>
          <dependent id="19">fire</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="17">hire</governor>
          <dependent id="20">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">hire</governor>
          <dependent id="21">impose</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">impose</governor>
          <dependent id="22">discipline</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">charge</governor>
          <dependent id="24">you</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="29">charge</governor>
          <dependent id="25">are</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="27">longer</governor>
          <dependent id="26">no</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="29">charge</governor>
          <dependent id="27">longer</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">charge</governor>
          <dependent id="28">in</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="33">said</governor>
          <dependent id="29">charge</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="33">said</governor>
          <dependent id="32">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="33">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="fire" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="19" string="fire" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="34" has_coreference="true">
      <content>Laux said the 750-member department, which includes 62 minority members and 68 white women, will begin cultural awareness training for all officers, probably this fall.</content>
      <tokens>
        <token id="1" string="Laux" lemma="Laux" stem="laux" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="750-member" lemma="750-member" stem="750-member" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="department" lemma="department" stem="depart" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="includes" lemma="include" stem="includ" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="62" lemma="62" stem="62" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="10" string="minority" lemma="minority" stem="minor" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="members" lemma="member" stem="member" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="68" lemma="68" stem="68" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="14" string="white" lemma="white" stem="white" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="women" lemma="woman" stem="women" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="begin" lemma="begin" stem="begin" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="cultural" lemma="cultural" stem="cultur" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="awareness" lemma="awareness" stem="awar" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="training" lemma="training" stem="train" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="probably" lemma="probably" stem="probabl" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="28" string="fall" lemma="fall" stem="fall" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Laux)) (VP (VBD said) (SBAR (S (NP (NP (DT the) (JJ 750-member) (NN department)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ includes) (NP (NP (CD 62) (NN minority) (NNS members)) (CC and) (NP (CD 68) (JJ white) (NNS women)))))) (, ,)) (VP (MD will) (VP (VB begin) (NP (JJ cultural) (NN awareness) (NN training)) (PP (IN for) (NP (NP (DT all) (NNS officers)) (, ,) (ADVP (RB probably)))) (NP-TMP (DT this) (NN fall))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the 750-member department , which includes 62 minority members and 68 white women ," type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="750-member" />
            <token id="5" string="department" />
            <token id="6" string="," />
            <token id="7" string="which" />
            <token id="8" string="includes" />
            <token id="9" string="62" />
            <token id="10" string="minority" />
            <token id="11" string="members" />
            <token id="12" string="and" />
            <token id="13" string="68" />
            <token id="14" string="white" />
            <token id="15" string="women" />
            <token id="16" string="," />
          </tokens>
        </chunking>
        <chunking id="2" string="the 750-member department , which includes 62 minority members and 68 white women , will begin cultural awareness training for all officers , probably this fall" type="SBAR">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="750-member" />
            <token id="5" string="department" />
            <token id="6" string="," />
            <token id="7" string="which" />
            <token id="8" string="includes" />
            <token id="9" string="62" />
            <token id="10" string="minority" />
            <token id="11" string="members" />
            <token id="12" string="and" />
            <token id="13" string="68" />
            <token id="14" string="white" />
            <token id="15" string="women" />
            <token id="16" string="," />
            <token id="17" string="will" />
            <token id="18" string="begin" />
            <token id="19" string="cultural" />
            <token id="20" string="awareness" />
            <token id="21" string="training" />
            <token id="22" string="for" />
            <token id="23" string="all" />
            <token id="24" string="officers" />
            <token id="25" string="," />
            <token id="26" string="probably" />
            <token id="27" string="this" />
            <token id="28" string="fall" />
          </tokens>
        </chunking>
        <chunking id="3" string="the 750-member department" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="750-member" />
            <token id="5" string="department" />
          </tokens>
        </chunking>
        <chunking id="4" string="which includes 62 minority members and 68 white women" type="SBAR">
          <tokens>
            <token id="7" string="which" />
            <token id="8" string="includes" />
            <token id="9" string="62" />
            <token id="10" string="minority" />
            <token id="11" string="members" />
            <token id="12" string="and" />
            <token id="13" string="68" />
            <token id="14" string="white" />
            <token id="15" string="women" />
          </tokens>
        </chunking>
        <chunking id="5" string="62 minority members" type="NP">
          <tokens>
            <token id="9" string="62" />
            <token id="10" string="minority" />
            <token id="11" string="members" />
          </tokens>
        </chunking>
        <chunking id="6" string="includes 62 minority members and 68 white women" type="VP">
          <tokens>
            <token id="8" string="includes" />
            <token id="9" string="62" />
            <token id="10" string="minority" />
            <token id="11" string="members" />
            <token id="12" string="and" />
            <token id="13" string="68" />
            <token id="14" string="white" />
            <token id="15" string="women" />
          </tokens>
        </chunking>
        <chunking id="7" string="all officers" type="NP">
          <tokens>
            <token id="23" string="all" />
            <token id="24" string="officers" />
          </tokens>
        </chunking>
        <chunking id="8" string="will begin cultural awareness training for all officers , probably this fall" type="VP">
          <tokens>
            <token id="17" string="will" />
            <token id="18" string="begin" />
            <token id="19" string="cultural" />
            <token id="20" string="awareness" />
            <token id="21" string="training" />
            <token id="22" string="for" />
            <token id="23" string="all" />
            <token id="24" string="officers" />
            <token id="25" string="," />
            <token id="26" string="probably" />
            <token id="27" string="this" />
            <token id="28" string="fall" />
          </tokens>
        </chunking>
        <chunking id="9" string="Laux" type="NP">
          <tokens>
            <token id="1" string="Laux" />
          </tokens>
        </chunking>
        <chunking id="10" string="62 minority members and 68 white women" type="NP">
          <tokens>
            <token id="9" string="62" />
            <token id="10" string="minority" />
            <token id="11" string="members" />
            <token id="12" string="and" />
            <token id="13" string="68" />
            <token id="14" string="white" />
            <token id="15" string="women" />
          </tokens>
        </chunking>
        <chunking id="11" string="cultural awareness training" type="NP">
          <tokens>
            <token id="19" string="cultural" />
            <token id="20" string="awareness" />
            <token id="21" string="training" />
          </tokens>
        </chunking>
        <chunking id="12" string="begin cultural awareness training for all officers , probably this fall" type="VP">
          <tokens>
            <token id="18" string="begin" />
            <token id="19" string="cultural" />
            <token id="20" string="awareness" />
            <token id="21" string="training" />
            <token id="22" string="for" />
            <token id="23" string="all" />
            <token id="24" string="officers" />
            <token id="25" string="," />
            <token id="26" string="probably" />
            <token id="27" string="this" />
            <token id="28" string="fall" />
          </tokens>
        </chunking>
        <chunking id="13" string="all officers , probably" type="NP">
          <tokens>
            <token id="23" string="all" />
            <token id="24" string="officers" />
            <token id="25" string="," />
            <token id="26" string="probably" />
          </tokens>
        </chunking>
        <chunking id="14" string="said the 750-member department , which includes 62 minority members and 68 white women , will begin cultural awareness training for all officers , probably this fall" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="the" />
            <token id="4" string="750-member" />
            <token id="5" string="department" />
            <token id="6" string="," />
            <token id="7" string="which" />
            <token id="8" string="includes" />
            <token id="9" string="62" />
            <token id="10" string="minority" />
            <token id="11" string="members" />
            <token id="12" string="and" />
            <token id="13" string="68" />
            <token id="14" string="white" />
            <token id="15" string="women" />
            <token id="16" string="," />
            <token id="17" string="will" />
            <token id="18" string="begin" />
            <token id="19" string="cultural" />
            <token id="20" string="awareness" />
            <token id="21" string="training" />
            <token id="22" string="for" />
            <token id="23" string="all" />
            <token id="24" string="officers" />
            <token id="25" string="," />
            <token id="26" string="probably" />
            <token id="27" string="this" />
            <token id="28" string="fall" />
          </tokens>
        </chunking>
        <chunking id="15" string="68 white women" type="NP">
          <tokens>
            <token id="13" string="68" />
            <token id="14" string="white" />
            <token id="15" string="women" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">Laux</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">department</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">department</governor>
          <dependent id="4">750-member</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">begin</governor>
          <dependent id="5">department</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">includes</governor>
          <dependent id="7">which</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="5">department</governor>
          <dependent id="8">includes</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="11">members</governor>
          <dependent id="9">62</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">members</governor>
          <dependent id="10">minority</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">includes</governor>
          <dependent id="11">members</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="11">members</governor>
          <dependent id="12">and</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="15">women</governor>
          <dependent id="13">68</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">women</governor>
          <dependent id="14">white</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">members</governor>
          <dependent id="15">women</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="18">begin</governor>
          <dependent id="17">will</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="18">begin</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">training</governor>
          <dependent id="19">cultural</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">training</governor>
          <dependent id="20">awareness</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">begin</governor>
          <dependent id="21">training</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">officers</governor>
          <dependent id="22">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">officers</governor>
          <dependent id="23">all</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">begin</governor>
          <dependent id="24">officers</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="24">officers</governor>
          <dependent id="26">probably</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">fall</governor>
          <dependent id="27">this</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="18">begin</governor>
          <dependent id="28">fall</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="68" type="NUMBER" score="0.0">
          <tokens>
            <token id="13" string="68" />
          </tokens>
        </entity>
        <entity id="2" string="Laux" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Laux" />
          </tokens>
        </entity>
        <entity id="3" string="this fall" type="DATE" score="0.0">
          <tokens>
            <token id="27" string="this" />
            <token id="28" string="fall" />
          </tokens>
        </entity>
        <entity id="4" string="62" type="NUMBER" score="0.0">
          <tokens>
            <token id="9" string="62" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="35" has_coreference="true">
      <content>``We need to get more education about ourselves and about everyone else.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="We" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="need" lemma="need" stem="need" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="get" lemma="get" stem="get" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="more" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="education" lemma="education" stem="educ" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="ourselves" lemma="ourselves" stem="ourselv" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="everyone" lemma="everyone" stem="everyon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="else" lemma="else" stem="els" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP We)) (VP (VBP need) (S (VP (TO to) (VP (VB get) (NP (JJR more) (NN education)) (PP (PP (IN about) (NP (PRP ourselves))) (CC and) (PP (IN about) (NP (NN everyone) (RB else)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="get more education about ourselves and about everyone else" type="VP">
          <tokens>
            <token id="5" string="get" />
            <token id="6" string="more" />
            <token id="7" string="education" />
            <token id="8" string="about" />
            <token id="9" string="ourselves" />
            <token id="10" string="and" />
            <token id="11" string="about" />
            <token id="12" string="everyone" />
            <token id="13" string="else" />
          </tokens>
        </chunking>
        <chunking id="2" string="more education" type="NP">
          <tokens>
            <token id="6" string="more" />
            <token id="7" string="education" />
          </tokens>
        </chunking>
        <chunking id="3" string="to get more education about ourselves and about everyone else" type="VP">
          <tokens>
            <token id="4" string="to" />
            <token id="5" string="get" />
            <token id="6" string="more" />
            <token id="7" string="education" />
            <token id="8" string="about" />
            <token id="9" string="ourselves" />
            <token id="10" string="and" />
            <token id="11" string="about" />
            <token id="12" string="everyone" />
            <token id="13" string="else" />
          </tokens>
        </chunking>
        <chunking id="4" string="need to get more education about ourselves and about everyone else" type="VP">
          <tokens>
            <token id="3" string="need" />
            <token id="4" string="to" />
            <token id="5" string="get" />
            <token id="6" string="more" />
            <token id="7" string="education" />
            <token id="8" string="about" />
            <token id="9" string="ourselves" />
            <token id="10" string="and" />
            <token id="11" string="about" />
            <token id="12" string="everyone" />
            <token id="13" string="else" />
          </tokens>
        </chunking>
        <chunking id="5" string="everyone else" type="NP">
          <tokens>
            <token id="12" string="everyone" />
            <token id="13" string="else" />
          </tokens>
        </chunking>
        <chunking id="6" string="We" type="NP">
          <tokens>
            <token id="2" string="We" />
          </tokens>
        </chunking>
        <chunking id="7" string="ourselves" type="NP">
          <tokens>
            <token id="9" string="ourselves" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">need</governor>
          <dependent id="2">We</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">need</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">get</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">need</governor>
          <dependent id="5">get</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">get</governor>
          <dependent id="5">get</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">education</governor>
          <dependent id="6">more</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">get</governor>
          <dependent id="7">education</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">ourselves</governor>
          <dependent id="8">about</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">get</governor>
          <dependent id="9">ourselves</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">get</governor>
          <dependent id="10">and</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">everyone</governor>
          <dependent id="11">about</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">get</governor>
          <dependent id="12">everyone</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">everyone</governor>
          <dependent id="13">else</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="36" has_coreference="true">
      <content>Our goal is to find out who can offer that to us and in what form,&amp;apost;&amp;apost; said Laux.</content>
      <tokens>
        <token id="1" string="Our" lemma="we" stem="our" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="2" string="goal" lemma="goal" stem="goal" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="find" lemma="find" stem="find" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="offer" lemma="offer" stem="offer" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="us" lemma="we" stem="u" pos="PRP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="form" lemma="form" stem="form" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="Laux" lemma="Laux" stem="laux" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (S (NP (PRP$ Our) (NN goal)) (VP (VBZ is) (S (VP (TO to) (VP (VB find) (PRT (RP out)) (SBAR (WHNP (WP who)) (S (VP (MD can) (VP (VB offer) (NP (UCP (ADVP (IN that) (PP (TO to) (NP (PRP us)))) (CC and) (PP (IN in) (WHNP (WP what)))) (NN form))))))))))) (, ,) ('' '') (VP (VBD said)) (NP (NNP Laux)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="can offer that to us and in what form" type="VP">
          <tokens>
            <token id="8" string="can" />
            <token id="9" string="offer" />
            <token id="10" string="that" />
            <token id="11" string="to" />
            <token id="12" string="us" />
            <token id="13" string="and" />
            <token id="14" string="in" />
            <token id="15" string="what" />
            <token id="16" string="form" />
          </tokens>
        </chunking>
        <chunking id="2" string="Laux" type="NP">
          <tokens>
            <token id="20" string="Laux" />
          </tokens>
        </chunking>
        <chunking id="3" string="who can offer that to us and in what form" type="SBAR">
          <tokens>
            <token id="7" string="who" />
            <token id="8" string="can" />
            <token id="9" string="offer" />
            <token id="10" string="that" />
            <token id="11" string="to" />
            <token id="12" string="us" />
            <token id="13" string="and" />
            <token id="14" string="in" />
            <token id="15" string="what" />
            <token id="16" string="form" />
          </tokens>
        </chunking>
        <chunking id="4" string="Our goal" type="NP">
          <tokens>
            <token id="1" string="Our" />
            <token id="2" string="goal" />
          </tokens>
        </chunking>
        <chunking id="5" string="is to find out who can offer that to us and in what form" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="to" />
            <token id="5" string="find" />
            <token id="6" string="out" />
            <token id="7" string="who" />
            <token id="8" string="can" />
            <token id="9" string="offer" />
            <token id="10" string="that" />
            <token id="11" string="to" />
            <token id="12" string="us" />
            <token id="13" string="and" />
            <token id="14" string="in" />
            <token id="15" string="what" />
            <token id="16" string="form" />
          </tokens>
        </chunking>
        <chunking id="6" string="to find out who can offer that to us and in what form" type="VP">
          <tokens>
            <token id="4" string="to" />
            <token id="5" string="find" />
            <token id="6" string="out" />
            <token id="7" string="who" />
            <token id="8" string="can" />
            <token id="9" string="offer" />
            <token id="10" string="that" />
            <token id="11" string="to" />
            <token id="12" string="us" />
            <token id="13" string="and" />
            <token id="14" string="in" />
            <token id="15" string="what" />
            <token id="16" string="form" />
          </tokens>
        </chunking>
        <chunking id="7" string="offer that to us and in what form" type="VP">
          <tokens>
            <token id="9" string="offer" />
            <token id="10" string="that" />
            <token id="11" string="to" />
            <token id="12" string="us" />
            <token id="13" string="and" />
            <token id="14" string="in" />
            <token id="15" string="what" />
            <token id="16" string="form" />
          </tokens>
        </chunking>
        <chunking id="8" string="find out who can offer that to us and in what form" type="VP">
          <tokens>
            <token id="5" string="find" />
            <token id="6" string="out" />
            <token id="7" string="who" />
            <token id="8" string="can" />
            <token id="9" string="offer" />
            <token id="10" string="that" />
            <token id="11" string="to" />
            <token id="12" string="us" />
            <token id="13" string="and" />
            <token id="14" string="in" />
            <token id="15" string="what" />
            <token id="16" string="form" />
          </tokens>
        </chunking>
        <chunking id="9" string="that to us and in what form" type="NP">
          <tokens>
            <token id="10" string="that" />
            <token id="11" string="to" />
            <token id="12" string="us" />
            <token id="13" string="and" />
            <token id="14" string="in" />
            <token id="15" string="what" />
            <token id="16" string="form" />
          </tokens>
        </chunking>
        <chunking id="10" string="us" type="NP">
          <tokens>
            <token id="12" string="us" />
          </tokens>
        </chunking>
        <chunking id="11" string="said" type="VP">
          <tokens>
            <token id="19" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="2">goal</governor>
          <dependent id="1">Our</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">is</governor>
          <dependent id="2">goal</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="19">said</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">find</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">is</governor>
          <dependent id="5">find</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="5">find</governor>
          <dependent id="6">out</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">offer</governor>
          <dependent id="7">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">offer</governor>
          <dependent id="8">can</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">find</governor>
          <dependent id="9">offer</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">and</governor>
          <dependent id="10">that</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">us</governor>
          <dependent id="11">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">that</governor>
          <dependent id="12">us</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">form</governor>
          <dependent id="13">and</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">what</governor>
          <dependent id="14">in</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">and</governor>
          <dependent id="15">what</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">offer</governor>
          <dependent id="16">form</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="19">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">said</governor>
          <dependent id="20">Laux</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Laux" type="PERSON" score="0.0">
          <tokens>
            <token id="20" string="Laux" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="37" has_coreference="true">
      <content>``But it must be thoughtful and be done by the right people.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="must" lemma="must" stem="must" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="thoughtful" lemma="thoughtful" stem="thought" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="done" lemma="do" stem="done" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="right" lemma="right" stem="right" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="13" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (CC But) (NP (PRP it)) (VP (MD must) (VP (VP (VB be) (ADJP (JJ thoughtful))) (CC and) (VP (VB be) (VP (VBN done) (PP (IN by) (NP (DT the) (JJ right) (NNS people))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="the right people" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="right" />
            <token id="13" string="people" />
          </tokens>
        </chunking>
        <chunking id="2" string="thoughtful" type="ADJP">
          <tokens>
            <token id="6" string="thoughtful" />
          </tokens>
        </chunking>
        <chunking id="3" string="be thoughtful and be done by the right people" type="VP">
          <tokens>
            <token id="5" string="be" />
            <token id="6" string="thoughtful" />
            <token id="7" string="and" />
            <token id="8" string="be" />
            <token id="9" string="done" />
            <token id="10" string="by" />
            <token id="11" string="the" />
            <token id="12" string="right" />
            <token id="13" string="people" />
          </tokens>
        </chunking>
        <chunking id="4" string="be thoughtful" type="VP">
          <tokens>
            <token id="5" string="be" />
            <token id="6" string="thoughtful" />
          </tokens>
        </chunking>
        <chunking id="5" string="must be thoughtful and be done by the right people" type="VP">
          <tokens>
            <token id="4" string="must" />
            <token id="5" string="be" />
            <token id="6" string="thoughtful" />
            <token id="7" string="and" />
            <token id="8" string="be" />
            <token id="9" string="done" />
            <token id="10" string="by" />
            <token id="11" string="the" />
            <token id="12" string="right" />
            <token id="13" string="people" />
          </tokens>
        </chunking>
        <chunking id="6" string="be done by the right people" type="VP">
          <tokens>
            <token id="8" string="be" />
            <token id="9" string="done" />
            <token id="10" string="by" />
            <token id="11" string="the" />
            <token id="12" string="right" />
            <token id="13" string="people" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="3" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="done by the right people" type="VP">
          <tokens>
            <token id="9" string="done" />
            <token id="10" string="by" />
            <token id="11" string="the" />
            <token id="12" string="right" />
            <token id="13" string="people" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="6">thoughtful</governor>
          <dependent id="2">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">thoughtful</governor>
          <dependent id="3">it</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">thoughtful</governor>
          <dependent id="4">must</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">thoughtful</governor>
          <dependent id="5">be</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">thoughtful</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">thoughtful</governor>
          <dependent id="7">and</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="9">done</governor>
          <dependent id="8">be</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">thoughtful</governor>
          <dependent id="9">done</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">people</governor>
          <dependent id="10">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">people</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">people</governor>
          <dependent id="12">right</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">done</governor>
          <dependent id="13">people</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="right" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="12" string="right" />
          </tokens>
        </entity>
      </entities>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="1" type="NOMINAL">
      <referenced ids_tokens="18-19" string="police racism" id_sentence="27" />
      <mentions>
        <mention ids_tokens="3-6" string="police racism and brutality" id_sentence="1" />
      </mentions>
    </coreference>
    <coreference id="2" type="NOMINAL">
      <referenced ids_tokens="9-10-11-12-13-14-15-16-17-18-19-20-21-22-23-24-25-26-27-28-29" string="this city that for decades has prided itself on a progressive attitude toward civil rights and a reputation for racial harmony" id_sentence="1" />
      <mentions>
        <mention ids_tokens="1-3" string="The city's" id_sentence="6" />
        <mention ids_tokens="4-5" string="this city" id_sentence="12" />
        <mention ids_tokens="10-11" string="the city" id_sentence="15" />
      </mentions>
    </coreference>
    <coreference id="5" type="PROPER">
      <referenced ids_tokens="4" string="two" id_sentence="2" />
      <mentions>
        <mention ids_tokens="2" string="It" id_sentence="3" />
      </mentions>
    </coreference>
    <coreference id="6" type="NOMINAL">
      <referenced ids_tokens="1-2-3-4-5-6-7-8-9-10-11-12" string="The deaths of two blacks at a drug raid that went awry" id_sentence="2" />
      <mentions>
        <mention ids_tokens="27-28" string="the deaths" id_sentence="28" />
      </mentions>
    </coreference>
    <coreference id="7" type="NOMINAL">
      <referenced ids_tokens="4-5-6-7-8-9-10-11-12" string="two blacks at a drug raid that went awry" id_sentence="2" />
      <mentions>
        <mention ids_tokens="1" string="I" id_sentence="5" />
        <mention ids_tokens="3" string="we" id_sentence="5" />
        <mention ids_tokens="23" string="him" id_sentence="5" />
      </mentions>
    </coreference>
    <coreference id="8" type="NOMINAL">
      <referenced ids_tokens="7-8-9-10-11-12" string="a drug raid that went awry" id_sentence="2" />
      <mentions>
        <mention ids_tokens="16-18" string="the drug raid" id_sentence="17" />
      </mentions>
    </coreference>
    <coreference id="9" type="NOMINAL">
      <referenced ids_tokens="26-27-28" string="a downtown hotel" id_sentence="2" />
      <mentions>
        <mention ids_tokens="25-26" string="the hotel" id_sentence="5" />
        <mention ids_tokens="27-28" string="the hotel" id_sentence="17" />
      </mentions>
    </coreference>
    <coreference id="12" type="PROPER">
      <referenced ids_tokens="12-13" string="Van Hayden" id_sentence="5" />
      <mentions>
        <mention ids_tokens="4" string="Hayden" id_sentence="11" />
        <mention ids_tokens="7" string="Hayden" id_sentence="14" />
      </mentions>
    </coreference>
    <coreference id="13" type="PROPER">
      <referenced ids_tokens="7-8" string="John Laux" id_sentence="6" />
      <mentions>
        <mention ids_tokens="14" string="he" id_sentence="7" />
        <mention ids_tokens="10" string="Laux" id_sentence="8" />
        <mention ids_tokens="15" string="me" id_sentence="8" />
        <mention ids_tokens="15" string="Laux" id_sentence="22" />
        <mention ids_tokens="1" string="Laux" id_sentence="26" />
        <mention ids_tokens="3" string="his" id_sentence="26" />
        <mention ids_tokens="1" string="Laux" id_sentence="32" />
        <mention ids_tokens="32" string="he" id_sentence="33" />
        <mention ids_tokens="1" string="Laux" id_sentence="34" />
        <mention ids_tokens="20" string="Laux" id_sentence="36" />
      </mentions>
    </coreference>
    <coreference id="14" type="NOMINAL">
      <referenced ids_tokens="23-24-25-26-27-28-29-30-31-32" string="a problem that is present in all segments of society" id_sentence="6" />
      <mentions>
        <mention ids_tokens="8-9" string="the problem" id_sentence="18" />
        <mention ids_tokens="22-23" string="a problem" id_sentence="27" />
      </mentions>
    </coreference>
    <coreference id="15" type="PROPER">
      <referenced ids_tokens="5-6-7" string="Hubert H. Humphrey" id_sentence="10" />
      <mentions>
        <mention ids_tokens="13-14" string="the mayor" id_sentence="30" />
      </mentions>
    </coreference>
    <coreference id="16" type="PROPER">
      <referenced ids_tokens="35" string="Minneapolis" id_sentence="10" />
      <mentions>
        <mention ids_tokens="2" string="I" id_sentence="12" />
        <mention ids_tokens="6" string="I" id_sentence="13" />
        <mention ids_tokens="17-22" string="Minneapolis , the home of progressiveness" id_sentence="13" />
        <mention ids_tokens="19-22" string="the home of progressiveness" id_sentence="13" />
      </mentions>
    </coreference>
    <coreference id="18" type="NOMINAL">
      <referenced ids_tokens="10" string="this" id_sentence="13" />
      <mentions>
        <mention ids_tokens="1" string="That" id_sentence="14" />
      </mentions>
    </coreference>
    <coreference id="22" type="NOMINAL">
      <referenced ids_tokens="10" string="protesters" id_sentence="17" />
      <mentions>
        <mention ids_tokens="6" string="they" id_sentence="20" />
      </mentions>
    </coreference>
    <coreference id="23" type="NOMINAL">
      <referenced ids_tokens="22-23-24-25-26-27-28" string="charges against those arrested at the hotel" id_sentence="17" />
      <mentions>
        <mention ids_tokens="8" string="charges" id_sentence="23" />
      </mentions>
    </coreference>
    <coreference id="24" type="NOMINAL">
      <referenced ids_tokens="24-25-26-27-28" string="those arrested at the hotel" id_sentence="17" />
      <mentions>
        <mention ids_tokens="16-17" string="those arrested" id_sentence="25" />
      </mentions>
    </coreference>
    <coreference id="25" type="PROPER">
      <referenced ids_tokens="10-11-12-13" string="the Minneapolis Police Department" id_sentence="19" />
      <mentions>
        <mention ids_tokens="2" string="I" id_sentence="20" />
        <mention ids_tokens="12-14" string="the police department" id_sentence="33" />
      </mentions>
    </coreference>
    <coreference id="26" type="NOMINAL">
      <referenced ids_tokens="8-9-10" string="the good officers" id_sentence="20" />
      <mentions>
        <mention ids_tokens="4" string="officers" id_sentence="25" />
        <mention ids_tokens="3-4" string="his officers" id_sentence="26" />
      </mentions>
    </coreference>
    <coreference id="28" type="NOMINAL">
      <referenced ids_tokens="37-38-39" string="a drug raid" id_sentence="21" />
      <mentions>
        <mention ids_tokens="4-5" string="the raid" id_sentence="22" />
      </mentions>
    </coreference>
    <coreference id="29" type="NOMINAL">
      <referenced ids_tokens="7-8-9" string="the elderly people" id_sentence="22" />
      <mentions>
        <mention ids_tokens="8" string="they" id_sentence="24" />
      </mentions>
    </coreference>
    <coreference id="30" type="PROPER">
      <referenced ids_tokens="1-2" string="Gleason Glover" id_sentence="27" />
      <mentions>
        <mention ids_tokens="49" string="Glover" id_sentence="28" />
        <mention ids_tokens="40" string="Glover" id_sentence="29" />
      </mentions>
    </coreference>
    <coreference id="31" type="PROPER">
      <referenced ids_tokens="31-32" string="21 years" id_sentence="27" />
      <mentions>
        <mention ids_tokens="19" string="I" id_sentence="28" />
        <mention ids_tokens="25" string="I" id_sentence="28" />
      </mentions>
    </coreference>
    <coreference id="32" type="NOMINAL">
      <referenced ids_tokens="45-46" string="police misconduct" id_sentence="28" />
      <mentions>
        <mention ids_tokens="28" string="I" id_sentence="29" />
        <mention ids_tokens="24" string="you" id_sentence="33" />
      </mentions>
    </coreference>
    <coreference id="35" type="NOMINAL">
      <referenced ids_tokens="9-10-11-12-13-14" string="a panel appointed by the mayor" id_sentence="30" />
      <mentions>
        <mention ids_tokens="1-2" string="The panel" id_sentence="31" />
      </mentions>
    </coreference>
    <coreference id="36" type="LIST">
      <referenced ids_tokens="9-10-11-12-13-14-15" string="62 minority members and 68 white women" id_sentence="34" />
      <mentions>
        <mention ids_tokens="1" string="Our" id_sentence="36" />
      </mentions>
    </coreference>
    <coreference id="37" type="NOMINAL">
      <referenced ids_tokens="9-10-11" string="62 minority members" id_sentence="34" />
      <mentions>
        <mention ids_tokens="2" string="We" id_sentence="35" />
        <mention ids_tokens="9" string="ourselves" id_sentence="35" />
        <mention ids_tokens="12" string="us" id_sentence="36" />
      </mentions>
    </coreference>
    <coreference id="38" type="NOMINAL">
      <referenced ids_tokens="1-2" string="Our goal" id_sentence="36" />
      <mentions>
        <mention ids_tokens="3" string="it" id_sentence="37" />
      </mentions>
    </coreference>
  </coreferences>
</document>
