<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="LA120290-0163">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>Cheers erupted Saturday on both sides of the English Channel when British and French workers digging the Channel Tunnel finally met after knocking out a passage large enough to walk through and shake hands.</content>
      <tokens>
        <token id="1" string="Cheers" lemma="Cheers" stem="cheer" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="erupted" lemma="erupt" stem="erupt" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Saturday" lemma="Saturday" stem="saturdai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="4" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="both" lemma="both" stem="both" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="sides" lemma="side" stem="side" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="English" lemma="English" stem="english" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="10" string="Channel" lemma="Channel" stem="channel" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="11" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="British" lemma="british" stem="british" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="true" />
        <token id="13" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="French" lemma="french" stem="french" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="true" />
        <token id="15" string="workers" lemma="worker" stem="worker" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="digging" lemma="digging" stem="dig" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="Channel" lemma="Channel" stem="channel" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="19" string="Tunnel" lemma="tunnel" stem="tunnel" pos="NN" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="20" string="finally" lemma="finally" stem="final" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="met" lemma="meet" stem="met" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="knocking" lemma="knock" stem="knock" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="26" string="passage" lemma="passage" stem="passag" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="27" string="large" lemma="large" stem="larg" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="28" string="enough" lemma="enough" stem="enough" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="29" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="30" string="walk" lemma="walk" stem="walk" pos="VB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="31" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="32" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="33" string="shake" lemma="shake" stem="shake" pos="VB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="34" string="hands" lemma="hand" stem="hand" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="35" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Cheers)) (VP (VBD erupted) (NP-TMP (NNP Saturday)) (PP (IN on) (NP (NP (DT both) (NNS sides)) (PP (IN of) (NP (DT the) (NNP English) (NNP Channel))))) (SBAR (WHADVP (WRB when) (NP (NP (JJ British) (CC and) (JJ French) (NNS workers)) (NP (NN digging)))) (S (NP (DT the) (NNP Channel) (NN Tunnel)) (ADVP (RB finally)) (VP (VBD met) (PP (IN after) (S (VP (VBG knocking) (PRT (RP out)) (NP (NP (DT a) (NN passage)) (ADJP (JJ large) (RB enough) (S (VP (TO to) (VP (VP (VB walk) (PP (IN through))) (CC and) (VP (VB shake) (NP (NNS hands))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="hands" type="NP">
          <tokens>
            <token id="34" string="hands" />
          </tokens>
        </chunking>
        <chunking id="2" string="knocking out a passage large enough to walk through and shake hands" type="VP">
          <tokens>
            <token id="23" string="knocking" />
            <token id="24" string="out" />
            <token id="25" string="a" />
            <token id="26" string="passage" />
            <token id="27" string="large" />
            <token id="28" string="enough" />
            <token id="29" string="to" />
            <token id="30" string="walk" />
            <token id="31" string="through" />
            <token id="32" string="and" />
            <token id="33" string="shake" />
            <token id="34" string="hands" />
          </tokens>
        </chunking>
        <chunking id="3" string="to walk through and shake hands" type="VP">
          <tokens>
            <token id="29" string="to" />
            <token id="30" string="walk" />
            <token id="31" string="through" />
            <token id="32" string="and" />
            <token id="33" string="shake" />
            <token id="34" string="hands" />
          </tokens>
        </chunking>
        <chunking id="4" string="both sides" type="NP">
          <tokens>
            <token id="5" string="both" />
            <token id="6" string="sides" />
          </tokens>
        </chunking>
        <chunking id="5" string="both sides of the English Channel" type="NP">
          <tokens>
            <token id="5" string="both" />
            <token id="6" string="sides" />
            <token id="7" string="of" />
            <token id="8" string="the" />
            <token id="9" string="English" />
            <token id="10" string="Channel" />
          </tokens>
        </chunking>
        <chunking id="6" string="digging" type="NP">
          <tokens>
            <token id="16" string="digging" />
          </tokens>
        </chunking>
        <chunking id="7" string="met after knocking out a passage large enough to walk through and shake hands" type="VP">
          <tokens>
            <token id="21" string="met" />
            <token id="22" string="after" />
            <token id="23" string="knocking" />
            <token id="24" string="out" />
            <token id="25" string="a" />
            <token id="26" string="passage" />
            <token id="27" string="large" />
            <token id="28" string="enough" />
            <token id="29" string="to" />
            <token id="30" string="walk" />
            <token id="31" string="through" />
            <token id="32" string="and" />
            <token id="33" string="shake" />
            <token id="34" string="hands" />
          </tokens>
        </chunking>
        <chunking id="8" string="when British and French workers digging the Channel Tunnel finally met after knocking out a passage large enough to walk through and shake hands" type="SBAR">
          <tokens>
            <token id="11" string="when" />
            <token id="12" string="British" />
            <token id="13" string="and" />
            <token id="14" string="French" />
            <token id="15" string="workers" />
            <token id="16" string="digging" />
            <token id="17" string="the" />
            <token id="18" string="Channel" />
            <token id="19" string="Tunnel" />
            <token id="20" string="finally" />
            <token id="21" string="met" />
            <token id="22" string="after" />
            <token id="23" string="knocking" />
            <token id="24" string="out" />
            <token id="25" string="a" />
            <token id="26" string="passage" />
            <token id="27" string="large" />
            <token id="28" string="enough" />
            <token id="29" string="to" />
            <token id="30" string="walk" />
            <token id="31" string="through" />
            <token id="32" string="and" />
            <token id="33" string="shake" />
            <token id="34" string="hands" />
          </tokens>
        </chunking>
        <chunking id="9" string="walk through and shake hands" type="VP">
          <tokens>
            <token id="30" string="walk" />
            <token id="31" string="through" />
            <token id="32" string="and" />
            <token id="33" string="shake" />
            <token id="34" string="hands" />
          </tokens>
        </chunking>
        <chunking id="10" string="walk through" type="VP">
          <tokens>
            <token id="30" string="walk" />
            <token id="31" string="through" />
          </tokens>
        </chunking>
        <chunking id="11" string="the Channel Tunnel" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="Channel" />
            <token id="19" string="Tunnel" />
          </tokens>
        </chunking>
        <chunking id="12" string="a passage" type="NP">
          <tokens>
            <token id="25" string="a" />
            <token id="26" string="passage" />
          </tokens>
        </chunking>
        <chunking id="13" string="erupted Saturday on both sides of the English Channel when British and French workers digging the Channel Tunnel finally met after knocking out a passage large enough to walk through and shake hands" type="VP">
          <tokens>
            <token id="2" string="erupted" />
            <token id="3" string="Saturday" />
            <token id="4" string="on" />
            <token id="5" string="both" />
            <token id="6" string="sides" />
            <token id="7" string="of" />
            <token id="8" string="the" />
            <token id="9" string="English" />
            <token id="10" string="Channel" />
            <token id="11" string="when" />
            <token id="12" string="British" />
            <token id="13" string="and" />
            <token id="14" string="French" />
            <token id="15" string="workers" />
            <token id="16" string="digging" />
            <token id="17" string="the" />
            <token id="18" string="Channel" />
            <token id="19" string="Tunnel" />
            <token id="20" string="finally" />
            <token id="21" string="met" />
            <token id="22" string="after" />
            <token id="23" string="knocking" />
            <token id="24" string="out" />
            <token id="25" string="a" />
            <token id="26" string="passage" />
            <token id="27" string="large" />
            <token id="28" string="enough" />
            <token id="29" string="to" />
            <token id="30" string="walk" />
            <token id="31" string="through" />
            <token id="32" string="and" />
            <token id="33" string="shake" />
            <token id="34" string="hands" />
          </tokens>
        </chunking>
        <chunking id="14" string="British and French workers digging" type="NP">
          <tokens>
            <token id="12" string="British" />
            <token id="13" string="and" />
            <token id="14" string="French" />
            <token id="15" string="workers" />
            <token id="16" string="digging" />
          </tokens>
        </chunking>
        <chunking id="15" string="the English Channel" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="English" />
            <token id="10" string="Channel" />
          </tokens>
        </chunking>
        <chunking id="16" string="when British and French workers digging" type="WHADVP">
          <tokens>
            <token id="11" string="when" />
            <token id="12" string="British" />
            <token id="13" string="and" />
            <token id="14" string="French" />
            <token id="15" string="workers" />
            <token id="16" string="digging" />
          </tokens>
        </chunking>
        <chunking id="17" string="Cheers" type="NP">
          <tokens>
            <token id="1" string="Cheers" />
          </tokens>
        </chunking>
        <chunking id="18" string="large enough to walk through and shake hands" type="ADJP">
          <tokens>
            <token id="27" string="large" />
            <token id="28" string="enough" />
            <token id="29" string="to" />
            <token id="30" string="walk" />
            <token id="31" string="through" />
            <token id="32" string="and" />
            <token id="33" string="shake" />
            <token id="34" string="hands" />
          </tokens>
        </chunking>
        <chunking id="19" string="a passage large enough to walk through and shake hands" type="NP">
          <tokens>
            <token id="25" string="a" />
            <token id="26" string="passage" />
            <token id="27" string="large" />
            <token id="28" string="enough" />
            <token id="29" string="to" />
            <token id="30" string="walk" />
            <token id="31" string="through" />
            <token id="32" string="and" />
            <token id="33" string="shake" />
            <token id="34" string="hands" />
          </tokens>
        </chunking>
        <chunking id="20" string="British and French workers" type="NP">
          <tokens>
            <token id="12" string="British" />
            <token id="13" string="and" />
            <token id="14" string="French" />
            <token id="15" string="workers" />
          </tokens>
        </chunking>
        <chunking id="21" string="shake hands" type="VP">
          <tokens>
            <token id="33" string="shake" />
            <token id="34" string="hands" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">erupted</governor>
          <dependent id="1">Cheers</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">erupted</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="2">erupted</governor>
          <dependent id="3">Saturday</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">sides</governor>
          <dependent id="4">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">sides</governor>
          <dependent id="5">both</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">erupted</governor>
          <dependent id="6">sides</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">Channel</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">Channel</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Channel</governor>
          <dependent id="9">English</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">sides</governor>
          <dependent id="10">Channel</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="21">met</governor>
          <dependent id="11">when</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">workers</governor>
          <dependent id="12">British</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="12">British</governor>
          <dependent id="13">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">British</governor>
          <dependent id="14">French</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="11">when</governor>
          <dependent id="15">workers</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="15">workers</governor>
          <dependent id="16">digging</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">Tunnel</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">Tunnel</governor>
          <dependent id="18">Channel</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">met</governor>
          <dependent id="19">Tunnel</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="21">met</governor>
          <dependent id="20">finally</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="2">erupted</governor>
          <dependent id="21">met</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="23">knocking</governor>
          <dependent id="22">after</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="21">met</governor>
          <dependent id="23">knocking</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="23">knocking</governor>
          <dependent id="24">out</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">passage</governor>
          <dependent id="25">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="23">knocking</governor>
          <dependent id="26">passage</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">passage</governor>
          <dependent id="27">large</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="27">large</governor>
          <dependent id="28">enough</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="30">walk</governor>
          <dependent id="29">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="27">large</governor>
          <dependent id="30">walk</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">walk</governor>
          <dependent id="31">through</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="30">walk</governor>
          <dependent id="32">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="30">walk</governor>
          <dependent id="33">shake</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="33">shake</governor>
          <dependent id="34">hands</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="French" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="14" string="French" />
          </tokens>
        </entity>
        <entity id="2" string="British" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="12" string="British" />
          </tokens>
        </entity>
        <entity id="3" string="English Channel" type="MISC" score="0.0">
          <tokens>
            <token id="9" string="English" />
            <token id="10" string="Channel" />
          </tokens>
        </entity>
        <entity id="4" string="Saturday" type="DATE" score="0.0">
          <tokens>
            <token id="3" string="Saturday" />
          </tokens>
        </entity>
        <entity id="5" string="Channel Tunnel" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="18" string="Channel" />
            <token id="19" string="Tunnel" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="false">
      <content>&amp;quot;Today, for the first time, men can cross the channel underground,&amp;quot; French President Francois Mitterrand said.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Today" lemma="today" stem="todai" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="true" is_refers="false" />
        <token id="7" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="men" lemma="man" stem="men" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="cross" lemma="cross" stem="cross" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="channel" lemma="channel" stem="channel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="underground" lemma="underground" stem="underground" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="French" lemma="French" stem="french" pos="NNP" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="18" string="President" lemma="President" stem="presid" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="false" is_refers="false" />
        <token id="19" string="Francois" lemma="Francois" stem="francoi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="20" string="Mitterrand" lemma="Mitterrand" stem="mitterrand" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="21" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP-TMP (NN Today)) (, ,) (PP (IN for) (NP (DT the) (JJ first) (NN time))) (, ,) (NP (NNS men)) (VP (MD can) (VP (VB cross) (NP (DT the) (NN channel) (NN underground))))) (, ,) ('' '') (NP (NNP French) (NNP President) (NNP Francois) (NNP Mitterrand)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the first time" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="first" />
            <token id="7" string="time" />
          </tokens>
        </chunking>
        <chunking id="2" string="the channel underground" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="channel" />
            <token id="14" string="underground" />
          </tokens>
        </chunking>
        <chunking id="3" string="men" type="NP">
          <tokens>
            <token id="9" string="men" />
          </tokens>
        </chunking>
        <chunking id="4" string="cross the channel underground" type="VP">
          <tokens>
            <token id="11" string="cross" />
            <token id="12" string="the" />
            <token id="13" string="channel" />
            <token id="14" string="underground" />
          </tokens>
        </chunking>
        <chunking id="5" string="can cross the channel underground" type="VP">
          <tokens>
            <token id="10" string="can" />
            <token id="11" string="cross" />
            <token id="12" string="the" />
            <token id="13" string="channel" />
            <token id="14" string="underground" />
          </tokens>
        </chunking>
        <chunking id="6" string="French President Francois Mitterrand" type="NP">
          <tokens>
            <token id="17" string="French" />
            <token id="18" string="President" />
            <token id="19" string="Francois" />
            <token id="20" string="Mitterrand" />
          </tokens>
        </chunking>
        <chunking id="7" string="said" type="VP">
          <tokens>
            <token id="21" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:tmod">
          <governor id="11">cross</governor>
          <dependent id="2">Today</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">time</governor>
          <dependent id="4">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">time</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">time</governor>
          <dependent id="6">first</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">cross</governor>
          <dependent id="7">time</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">cross</governor>
          <dependent id="9">men</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">cross</governor>
          <dependent id="10">can</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="21">said</governor>
          <dependent id="11">cross</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">underground</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">underground</governor>
          <dependent id="13">channel</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">cross</governor>
          <dependent id="14">underground</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">Mitterrand</governor>
          <dependent id="17">French</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">Mitterrand</governor>
          <dependent id="18">President</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">Mitterrand</governor>
          <dependent id="19">Francois</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">said</governor>
          <dependent id="20">Mitterrand</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="21">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="French" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="17" string="French" />
          </tokens>
        </entity>
        <entity id="2" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="6" string="first" />
          </tokens>
        </entity>
        <entity id="3" string="Today" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="Today" />
          </tokens>
        </entity>
        <entity id="4" string="Francois Mitterrand" type="PERSON" score="0.0">
          <tokens>
            <token id="19" string="Francois" />
            <token id="20" string="Mitterrand" />
          </tokens>
        </entity>
        <entity id="5" string="President" type="TITLE" score="0.0">
          <tokens>
            <token id="18" string="President" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>&amp;quot;What a brilliant sign of the vitality of our two countries.&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="What" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="brilliant" lemma="brilliant" stem="brilliant" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="sign" lemma="sign" stem="sign" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="vitality" lemma="vitality" stem="vital" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="our" lemma="we" stem="our" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="11" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="12" string="countries" lemma="country" stem="countri" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (FRAG (NP (NP (`` ``) (NP (NP (WP What)) (NP (DT a) (JJ brilliant))) (NP-TMP (NN sign)) (PP (IN of) (NP (DT the) (NN vitality)))) (PP (IN of) (NP (PRP$ our) (CD two) (NNS countries)))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="our two countries" type="NP">
          <tokens>
            <token id="10" string="our" />
            <token id="11" string="two" />
            <token id="12" string="countries" />
          </tokens>
        </chunking>
        <chunking id="2" string="`` What a brilliant sign of the vitality of our two countries" type="NP">
          <tokens>
            <token id="1" string="&quot;" />
            <token id="2" string="What" />
            <token id="3" string="a" />
            <token id="4" string="brilliant" />
            <token id="5" string="sign" />
            <token id="6" string="of" />
            <token id="7" string="the" />
            <token id="8" string="vitality" />
            <token id="9" string="of" />
            <token id="10" string="our" />
            <token id="11" string="two" />
            <token id="12" string="countries" />
          </tokens>
        </chunking>
        <chunking id="3" string="the vitality" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="vitality" />
          </tokens>
        </chunking>
        <chunking id="4" string="What a brilliant" type="NP">
          <tokens>
            <token id="2" string="What" />
            <token id="3" string="a" />
            <token id="4" string="brilliant" />
          </tokens>
        </chunking>
        <chunking id="5" string="`` What a brilliant sign of the vitality" type="NP">
          <tokens>
            <token id="1" string="&quot;" />
            <token id="2" string="What" />
            <token id="3" string="a" />
            <token id="4" string="brilliant" />
            <token id="5" string="sign" />
            <token id="6" string="of" />
            <token id="7" string="the" />
            <token id="8" string="vitality" />
          </tokens>
        </chunking>
        <chunking id="6" string="What" type="NP">
          <tokens>
            <token id="2" string="What" />
          </tokens>
        </chunking>
        <chunking id="7" string="a brilliant" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="brilliant" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">What</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">brilliant</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="2">What</governor>
          <dependent id="4">brilliant</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="2">What</governor>
          <dependent id="5">sign</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">vitality</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">vitality</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">What</governor>
          <dependent id="8">vitality</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">countries</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="12">countries</governor>
          <dependent id="10">our</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="12">countries</governor>
          <dependent id="11">two</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">What</governor>
          <dependent id="12">countries</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="11" string="two" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>The breakthrough came in a 6-foot-tall service tunnel that will be used to maintain two rail tunnels still being bored.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="breakthrough" lemma="breakthrough" stem="breakthrough" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="came" lemma="come" stem="came" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="6-foot-tall" lemma="6-foot-tall" stem="6-foot-tal" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="service" lemma="service" stem="servic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="tunnel" lemma="tunnel" stem="tunnel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="used" lemma="use" stem="us" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="maintain" lemma="maintain" stem="maintain" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="16" string="rail" lemma="rail" stem="rail" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="tunnels" lemma="tunnel" stem="tunnel" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="still" lemma="still" stem="still" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="being" lemma="be" stem="be" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="bored" lemma="bore" stem="bore" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN breakthrough)) (VP (VBD came) (PP (IN in) (NP (NP (DT a) (JJ 6-foot-tall) (NN service) (NN tunnel)) (SBAR (WHNP (WDT that)) (S (VP (MD will) (VP (VB be) (VP (VBN used) (S (VP (TO to) (VP (VB maintain) (NP (CD two) (NN rail) (NNS tunnels)) (ADVP (RB still)) (S (VP (VBG being) (ADJP (VBN bored))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="came in a 6-foot-tall service tunnel that will be used to maintain two rail tunnels still being bored" type="VP">
          <tokens>
            <token id="3" string="came" />
            <token id="4" string="in" />
            <token id="5" string="a" />
            <token id="6" string="6-foot-tall" />
            <token id="7" string="service" />
            <token id="8" string="tunnel" />
            <token id="9" string="that" />
            <token id="10" string="will" />
            <token id="11" string="be" />
            <token id="12" string="used" />
            <token id="13" string="to" />
            <token id="14" string="maintain" />
            <token id="15" string="two" />
            <token id="16" string="rail" />
            <token id="17" string="tunnels" />
            <token id="18" string="still" />
            <token id="19" string="being" />
            <token id="20" string="bored" />
          </tokens>
        </chunking>
        <chunking id="2" string="maintain two rail tunnels still being bored" type="VP">
          <tokens>
            <token id="14" string="maintain" />
            <token id="15" string="two" />
            <token id="16" string="rail" />
            <token id="17" string="tunnels" />
            <token id="18" string="still" />
            <token id="19" string="being" />
            <token id="20" string="bored" />
          </tokens>
        </chunking>
        <chunking id="3" string="that will be used to maintain two rail tunnels still being bored" type="SBAR">
          <tokens>
            <token id="9" string="that" />
            <token id="10" string="will" />
            <token id="11" string="be" />
            <token id="12" string="used" />
            <token id="13" string="to" />
            <token id="14" string="maintain" />
            <token id="15" string="two" />
            <token id="16" string="rail" />
            <token id="17" string="tunnels" />
            <token id="18" string="still" />
            <token id="19" string="being" />
            <token id="20" string="bored" />
          </tokens>
        </chunking>
        <chunking id="4" string="to maintain two rail tunnels still being bored" type="VP">
          <tokens>
            <token id="13" string="to" />
            <token id="14" string="maintain" />
            <token id="15" string="two" />
            <token id="16" string="rail" />
            <token id="17" string="tunnels" />
            <token id="18" string="still" />
            <token id="19" string="being" />
            <token id="20" string="bored" />
          </tokens>
        </chunking>
        <chunking id="5" string="used to maintain two rail tunnels still being bored" type="VP">
          <tokens>
            <token id="12" string="used" />
            <token id="13" string="to" />
            <token id="14" string="maintain" />
            <token id="15" string="two" />
            <token id="16" string="rail" />
            <token id="17" string="tunnels" />
            <token id="18" string="still" />
            <token id="19" string="being" />
            <token id="20" string="bored" />
          </tokens>
        </chunking>
        <chunking id="6" string="being bored" type="VP">
          <tokens>
            <token id="19" string="being" />
            <token id="20" string="bored" />
          </tokens>
        </chunking>
        <chunking id="7" string="The breakthrough" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="breakthrough" />
          </tokens>
        </chunking>
        <chunking id="8" string="will be used to maintain two rail tunnels still being bored" type="VP">
          <tokens>
            <token id="10" string="will" />
            <token id="11" string="be" />
            <token id="12" string="used" />
            <token id="13" string="to" />
            <token id="14" string="maintain" />
            <token id="15" string="two" />
            <token id="16" string="rail" />
            <token id="17" string="tunnels" />
            <token id="18" string="still" />
            <token id="19" string="being" />
            <token id="20" string="bored" />
          </tokens>
        </chunking>
        <chunking id="9" string="a 6-foot-tall service tunnel that will be used to maintain two rail tunnels still being bored" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="6-foot-tall" />
            <token id="7" string="service" />
            <token id="8" string="tunnel" />
            <token id="9" string="that" />
            <token id="10" string="will" />
            <token id="11" string="be" />
            <token id="12" string="used" />
            <token id="13" string="to" />
            <token id="14" string="maintain" />
            <token id="15" string="two" />
            <token id="16" string="rail" />
            <token id="17" string="tunnels" />
            <token id="18" string="still" />
            <token id="19" string="being" />
            <token id="20" string="bored" />
          </tokens>
        </chunking>
        <chunking id="10" string="a 6-foot-tall service tunnel" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="6-foot-tall" />
            <token id="7" string="service" />
            <token id="8" string="tunnel" />
          </tokens>
        </chunking>
        <chunking id="11" string="two rail tunnels" type="NP">
          <tokens>
            <token id="15" string="two" />
            <token id="16" string="rail" />
            <token id="17" string="tunnels" />
          </tokens>
        </chunking>
        <chunking id="12" string="be used to maintain two rail tunnels still being bored" type="VP">
          <tokens>
            <token id="11" string="be" />
            <token id="12" string="used" />
            <token id="13" string="to" />
            <token id="14" string="maintain" />
            <token id="15" string="two" />
            <token id="16" string="rail" />
            <token id="17" string="tunnels" />
            <token id="18" string="still" />
            <token id="19" string="being" />
            <token id="20" string="bored" />
          </tokens>
        </chunking>
        <chunking id="13" string="bored" type="ADJP">
          <tokens>
            <token id="20" string="bored" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">breakthrough</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">came</governor>
          <dependent id="2">breakthrough</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">came</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">tunnel</governor>
          <dependent id="4">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">tunnel</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">tunnel</governor>
          <dependent id="6">6-foot-tall</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">tunnel</governor>
          <dependent id="7">service</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">came</governor>
          <dependent id="8">tunnel</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="12">used</governor>
          <dependent id="9">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">used</governor>
          <dependent id="10">will</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="12">used</governor>
          <dependent id="11">be</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="8">tunnel</governor>
          <dependent id="12">used</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">maintain</governor>
          <dependent id="13">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="12">used</governor>
          <dependent id="14">maintain</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="17">tunnels</governor>
          <dependent id="15">two</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">tunnels</governor>
          <dependent id="16">rail</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">maintain</governor>
          <dependent id="17">tunnels</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">maintain</governor>
          <dependent id="18">still</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="20">bored</governor>
          <dependent id="19">being</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="14">maintain</governor>
          <dependent id="20">bored</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="15" string="two" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>It marked a symbolic milestone in Europe&amp;apost;s biggest engineering project.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="marked" lemma="mark" stem="mark" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="symbolic" lemma="symbolic" stem="symbol" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="milestone" lemma="milestone" stem="mileston" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Europe" lemma="Europe" stem="europ" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="8" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="biggest" lemma="biggest" stem="biggest" pos="JJS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="engineering" lemma="engineering" stem="engin" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="project" lemma="project" stem="project" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP It)) (VP (VBD marked) (NP (DT a) (JJ symbolic) (NN milestone)) (PP (IN in) (NP (NP (NNP Europe) (POS 's)) (JJS biggest) (NN engineering) (NN project)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="marked a symbolic milestone in Europe 's biggest engineering project" type="VP">
          <tokens>
            <token id="2" string="marked" />
            <token id="3" string="a" />
            <token id="4" string="symbolic" />
            <token id="5" string="milestone" />
            <token id="6" string="in" />
            <token id="7" string="Europe" />
            <token id="8" string="'s" />
            <token id="9" string="biggest" />
            <token id="10" string="engineering" />
            <token id="11" string="project" />
          </tokens>
        </chunking>
        <chunking id="2" string="Europe 's biggest engineering project" type="NP">
          <tokens>
            <token id="7" string="Europe" />
            <token id="8" string="'s" />
            <token id="9" string="biggest" />
            <token id="10" string="engineering" />
            <token id="11" string="project" />
          </tokens>
        </chunking>
        <chunking id="3" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="4" string="a symbolic milestone" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="symbolic" />
            <token id="5" string="milestone" />
          </tokens>
        </chunking>
        <chunking id="5" string="Europe 's" type="NP">
          <tokens>
            <token id="7" string="Europe" />
            <token id="8" string="'s" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">marked</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">marked</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">milestone</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">milestone</governor>
          <dependent id="4">symbolic</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">marked</governor>
          <dependent id="5">milestone</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">project</governor>
          <dependent id="6">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">project</governor>
          <dependent id="7">Europe</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">Europe</governor>
          <dependent id="8">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">project</governor>
          <dependent id="9">biggest</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">project</governor>
          <dependent id="10">engineering</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">marked</governor>
          <dependent id="11">project</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Europe" type="LOCATION" score="0.0">
          <tokens>
            <token id="7" string="Europe" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>Using jackhammers, Graham Fagg, 42, of Dover, England, and Philippe Cozette, 37, of Calais, France, knocked out the last foot of chalk to link up the British and French sides of the tunnel -- which has been dubbed a &amp;quot;chunnel.&amp;quot;</content>
      <tokens>
        <token id="1" string="Using" lemma="use" stem="using" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="jackhammers" lemma="jackhammer" stem="jackhamm" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Graham" lemma="Graham" stem="graham" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="5" string="Fagg" lemma="Fagg" stem="fagg" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="42" lemma="42" stem="42" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="Dover" lemma="Dover" stem="dover" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="England" lemma="England" stem="england" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="Philippe" lemma="Philippe" stem="philipp" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="16" string="Cozette" lemma="Cozette" stem="cozett" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="37" lemma="37" stem="37" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="Calais" lemma="Calais" stem="calai" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="23" string="France" lemma="France" stem="franc" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="knocked" lemma="knock" stem="knock" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="foot" lemma="foot" stem="foot" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="chalk" lemma="chalk" stem="chalk" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="link" lemma="link" stem="link" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="British" lemma="british" stem="british" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="37" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="French" lemma="french" stem="french" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="39" string="sides" lemma="side" stem="side" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="tunnel" lemma="tunnel" stem="tunnel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="46" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="47" string="dubbed" lemma="dub" stem="dub" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="48" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="49" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="50" string="chunnel" lemma="chunnel" stem="chunnel" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="51" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="52" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (VBG Using) (NP (NNS jackhammers)))) (, ,) (NP (NP (NNP Graham) (NNP Fagg)) (, ,) (NP (NP (NP (CD 42)) (, ,) (PP (IN of) (NP (NP (NNP Dover) (, ,) (NNP England) (, ,) (CC and) (NNP Philippe) (NNP Cozette)) (, ,) (NP (CD 37)))) (, ,)) (PP (IN of) (NP (NNP Calais) (, ,) (NNP France)))) (, ,)) (VP (VBD knocked) (PRT (RP out)) (NP (NP (DT the) (JJ last) (NN foot)) (PP (IN of) (NP (NN chalk)))) (S (VP (TO to) (VP (VB link) (PRT (RP up)) (NP (NP (DT the) (JJ British) (CC and) (JJ French) (NNS sides)) (PP (IN of) (NP (NP (DT the) (NN tunnel)) (: --) (SBAR (WHNP (WDT which)) (S (VP (VBZ has) (VP (VBN been) (VP (VBN dubbed) (NP (DT a) (`` ``) (NX (NNP chunnel))))))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="link up the British and French sides of the tunnel -- which has been dubbed a `` chunnel" type="VP">
          <tokens>
            <token id="33" string="link" />
            <token id="34" string="up" />
            <token id="35" string="the" />
            <token id="36" string="British" />
            <token id="37" string="and" />
            <token id="38" string="French" />
            <token id="39" string="sides" />
            <token id="40" string="of" />
            <token id="41" string="the" />
            <token id="42" string="tunnel" />
            <token id="43" string="--" />
            <token id="44" string="which" />
            <token id="45" string="has" />
            <token id="46" string="been" />
            <token id="47" string="dubbed" />
            <token id="48" string="a" />
            <token id="49" string="&quot;" />
            <token id="50" string="chunnel" />
          </tokens>
        </chunking>
        <chunking id="2" string="37" type="NP">
          <tokens>
            <token id="18" string="37" />
          </tokens>
        </chunking>
        <chunking id="3" string="the British and French sides of the tunnel -- which has been dubbed a `` chunnel" type="NP">
          <tokens>
            <token id="35" string="the" />
            <token id="36" string="British" />
            <token id="37" string="and" />
            <token id="38" string="French" />
            <token id="39" string="sides" />
            <token id="40" string="of" />
            <token id="41" string="the" />
            <token id="42" string="tunnel" />
            <token id="43" string="--" />
            <token id="44" string="which" />
            <token id="45" string="has" />
            <token id="46" string="been" />
            <token id="47" string="dubbed" />
            <token id="48" string="a" />
            <token id="49" string="&quot;" />
            <token id="50" string="chunnel" />
          </tokens>
        </chunking>
        <chunking id="4" string="which has been dubbed a `` chunnel" type="SBAR">
          <tokens>
            <token id="44" string="which" />
            <token id="45" string="has" />
            <token id="46" string="been" />
            <token id="47" string="dubbed" />
            <token id="48" string="a" />
            <token id="49" string="&quot;" />
            <token id="50" string="chunnel" />
          </tokens>
        </chunking>
        <chunking id="5" string="been dubbed a `` chunnel" type="VP">
          <tokens>
            <token id="46" string="been" />
            <token id="47" string="dubbed" />
            <token id="48" string="a" />
            <token id="49" string="&quot;" />
            <token id="50" string="chunnel" />
          </tokens>
        </chunking>
        <chunking id="6" string="42 , of Dover , England , and Philippe Cozette , 37 , of Calais , France" type="NP">
          <tokens>
            <token id="7" string="42" />
            <token id="8" string="," />
            <token id="9" string="of" />
            <token id="10" string="Dover" />
            <token id="11" string="," />
            <token id="12" string="England" />
            <token id="13" string="," />
            <token id="14" string="and" />
            <token id="15" string="Philippe" />
            <token id="16" string="Cozette" />
            <token id="17" string="," />
            <token id="18" string="37" />
            <token id="19" string="," />
            <token id="20" string="of" />
            <token id="21" string="Calais" />
            <token id="22" string="," />
            <token id="23" string="France" />
          </tokens>
        </chunking>
        <chunking id="7" string="has been dubbed a `` chunnel" type="VP">
          <tokens>
            <token id="45" string="has" />
            <token id="46" string="been" />
            <token id="47" string="dubbed" />
            <token id="48" string="a" />
            <token id="49" string="&quot;" />
            <token id="50" string="chunnel" />
          </tokens>
        </chunking>
        <chunking id="8" string="Using jackhammers" type="VP">
          <tokens>
            <token id="1" string="Using" />
            <token id="2" string="jackhammers" />
          </tokens>
        </chunking>
        <chunking id="9" string="a `` chunnel" type="NP">
          <tokens>
            <token id="48" string="a" />
            <token id="49" string="&quot;" />
            <token id="50" string="chunnel" />
          </tokens>
        </chunking>
        <chunking id="10" string="Dover , England , and Philippe Cozette , 37" type="NP">
          <tokens>
            <token id="10" string="Dover" />
            <token id="11" string="," />
            <token id="12" string="England" />
            <token id="13" string="," />
            <token id="14" string="and" />
            <token id="15" string="Philippe" />
            <token id="16" string="Cozette" />
            <token id="17" string="," />
            <token id="18" string="37" />
          </tokens>
        </chunking>
        <chunking id="11" string="the tunnel -- which has been dubbed a `` chunnel" type="NP">
          <tokens>
            <token id="41" string="the" />
            <token id="42" string="tunnel" />
            <token id="43" string="--" />
            <token id="44" string="which" />
            <token id="45" string="has" />
            <token id="46" string="been" />
            <token id="47" string="dubbed" />
            <token id="48" string="a" />
            <token id="49" string="&quot;" />
            <token id="50" string="chunnel" />
          </tokens>
        </chunking>
        <chunking id="12" string="jackhammers" type="NP">
          <tokens>
            <token id="2" string="jackhammers" />
          </tokens>
        </chunking>
        <chunking id="13" string="chalk" type="NP">
          <tokens>
            <token id="31" string="chalk" />
          </tokens>
        </chunking>
        <chunking id="14" string="42 , of Dover , England , and Philippe Cozette , 37 ," type="NP">
          <tokens>
            <token id="7" string="42" />
            <token id="8" string="," />
            <token id="9" string="of" />
            <token id="10" string="Dover" />
            <token id="11" string="," />
            <token id="12" string="England" />
            <token id="13" string="," />
            <token id="14" string="and" />
            <token id="15" string="Philippe" />
            <token id="16" string="Cozette" />
            <token id="17" string="," />
            <token id="18" string="37" />
            <token id="19" string="," />
          </tokens>
        </chunking>
        <chunking id="15" string="42" type="NP">
          <tokens>
            <token id="7" string="42" />
          </tokens>
        </chunking>
        <chunking id="16" string="Dover , England , and Philippe Cozette" type="NP">
          <tokens>
            <token id="10" string="Dover" />
            <token id="11" string="," />
            <token id="12" string="England" />
            <token id="13" string="," />
            <token id="14" string="and" />
            <token id="15" string="Philippe" />
            <token id="16" string="Cozette" />
          </tokens>
        </chunking>
        <chunking id="17" string="the last foot" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="last" />
            <token id="29" string="foot" />
          </tokens>
        </chunking>
        <chunking id="18" string="the tunnel" type="NP">
          <tokens>
            <token id="41" string="the" />
            <token id="42" string="tunnel" />
          </tokens>
        </chunking>
        <chunking id="19" string="the last foot of chalk" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="last" />
            <token id="29" string="foot" />
            <token id="30" string="of" />
            <token id="31" string="chalk" />
          </tokens>
        </chunking>
        <chunking id="20" string="knocked out the last foot of chalk to link up the British and French sides of the tunnel -- which has been dubbed a `` chunnel" type="VP">
          <tokens>
            <token id="25" string="knocked" />
            <token id="26" string="out" />
            <token id="27" string="the" />
            <token id="28" string="last" />
            <token id="29" string="foot" />
            <token id="30" string="of" />
            <token id="31" string="chalk" />
            <token id="32" string="to" />
            <token id="33" string="link" />
            <token id="34" string="up" />
            <token id="35" string="the" />
            <token id="36" string="British" />
            <token id="37" string="and" />
            <token id="38" string="French" />
            <token id="39" string="sides" />
            <token id="40" string="of" />
            <token id="41" string="the" />
            <token id="42" string="tunnel" />
            <token id="43" string="--" />
            <token id="44" string="which" />
            <token id="45" string="has" />
            <token id="46" string="been" />
            <token id="47" string="dubbed" />
            <token id="48" string="a" />
            <token id="49" string="&quot;" />
            <token id="50" string="chunnel" />
          </tokens>
        </chunking>
        <chunking id="21" string="dubbed a `` chunnel" type="VP">
          <tokens>
            <token id="47" string="dubbed" />
            <token id="48" string="a" />
            <token id="49" string="&quot;" />
            <token id="50" string="chunnel" />
          </tokens>
        </chunking>
        <chunking id="22" string="Graham Fagg" type="NP">
          <tokens>
            <token id="4" string="Graham" />
            <token id="5" string="Fagg" />
          </tokens>
        </chunking>
        <chunking id="23" string="Graham Fagg , 42 , of Dover , England , and Philippe Cozette , 37 , of Calais , France ," type="NP">
          <tokens>
            <token id="4" string="Graham" />
            <token id="5" string="Fagg" />
            <token id="6" string="," />
            <token id="7" string="42" />
            <token id="8" string="," />
            <token id="9" string="of" />
            <token id="10" string="Dover" />
            <token id="11" string="," />
            <token id="12" string="England" />
            <token id="13" string="," />
            <token id="14" string="and" />
            <token id="15" string="Philippe" />
            <token id="16" string="Cozette" />
            <token id="17" string="," />
            <token id="18" string="37" />
            <token id="19" string="," />
            <token id="20" string="of" />
            <token id="21" string="Calais" />
            <token id="22" string="," />
            <token id="23" string="France" />
            <token id="24" string="," />
          </tokens>
        </chunking>
        <chunking id="24" string="Calais , France" type="NP">
          <tokens>
            <token id="21" string="Calais" />
            <token id="22" string="," />
            <token id="23" string="France" />
          </tokens>
        </chunking>
        <chunking id="25" string="to link up the British and French sides of the tunnel -- which has been dubbed a `` chunnel" type="VP">
          <tokens>
            <token id="32" string="to" />
            <token id="33" string="link" />
            <token id="34" string="up" />
            <token id="35" string="the" />
            <token id="36" string="British" />
            <token id="37" string="and" />
            <token id="38" string="French" />
            <token id="39" string="sides" />
            <token id="40" string="of" />
            <token id="41" string="the" />
            <token id="42" string="tunnel" />
            <token id="43" string="--" />
            <token id="44" string="which" />
            <token id="45" string="has" />
            <token id="46" string="been" />
            <token id="47" string="dubbed" />
            <token id="48" string="a" />
            <token id="49" string="&quot;" />
            <token id="50" string="chunnel" />
          </tokens>
        </chunking>
        <chunking id="26" string="the British and French sides" type="NP">
          <tokens>
            <token id="35" string="the" />
            <token id="36" string="British" />
            <token id="37" string="and" />
            <token id="38" string="French" />
            <token id="39" string="sides" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advcl">
          <governor id="25">knocked</governor>
          <dependent id="1">Using</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="1">Using</governor>
          <dependent id="2">jackhammers</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Fagg</governor>
          <dependent id="4">Graham</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">knocked</governor>
          <dependent id="5">Fagg</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="5">Fagg</governor>
          <dependent id="7">42</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">England</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">England</governor>
          <dependent id="10">Dover</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">42</governor>
          <dependent id="12">England</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="12">England</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Cozette</governor>
          <dependent id="15">Philippe</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">England</governor>
          <dependent id="16">Cozette</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">England</governor>
          <dependent id="18">37</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">France</governor>
          <dependent id="20">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">France</governor>
          <dependent id="21">Calais</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">42</governor>
          <dependent id="23">France</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="25">knocked</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="25">knocked</governor>
          <dependent id="26">out</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">foot</governor>
          <dependent id="27">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="29">foot</governor>
          <dependent id="28">last</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="25">knocked</governor>
          <dependent id="29">foot</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">chalk</governor>
          <dependent id="30">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">foot</governor>
          <dependent id="31">chalk</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="33">link</governor>
          <dependent id="32">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="25">knocked</governor>
          <dependent id="33">link</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="33">link</governor>
          <dependent id="34">up</dependent>
        </dependency>
        <dependency type="det">
          <governor id="39">sides</governor>
          <dependent id="35">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="39">sides</governor>
          <dependent id="36">British</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="36">British</governor>
          <dependent id="37">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="36">British</governor>
          <dependent id="38">French</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="33">link</governor>
          <dependent id="39">sides</dependent>
        </dependency>
        <dependency type="case">
          <governor id="42">tunnel</governor>
          <dependent id="40">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="42">tunnel</governor>
          <dependent id="41">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="39">sides</governor>
          <dependent id="42">tunnel</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="47">dubbed</governor>
          <dependent id="44">which</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="47">dubbed</governor>
          <dependent id="45">has</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="47">dubbed</governor>
          <dependent id="46">been</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="42">tunnel</governor>
          <dependent id="47">dubbed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="50">chunnel</governor>
          <dependent id="48">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="47">dubbed</governor>
          <dependent id="50">chunnel</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="French" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="38" string="French" />
          </tokens>
        </entity>
        <entity id="2" string="Calais" type="LOCATION" score="0.0">
          <tokens>
            <token id="21" string="Calais" />
          </tokens>
        </entity>
        <entity id="3" string="37" type="NUMBER" score="0.0">
          <tokens>
            <token id="18" string="37" />
          </tokens>
        </entity>
        <entity id="4" string="British" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="36" string="British" />
          </tokens>
        </entity>
        <entity id="5" string="Dover" type="LOCATION" score="0.0">
          <tokens>
            <token id="10" string="Dover" />
          </tokens>
        </entity>
        <entity id="6" string="Graham Fagg" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Graham" />
            <token id="5" string="Fagg" />
          </tokens>
        </entity>
        <entity id="7" string="England" type="LOCATION" score="0.0">
          <tokens>
            <token id="12" string="England" />
          </tokens>
        </entity>
        <entity id="8" string="42" type="NUMBER" score="0.0">
          <tokens>
            <token id="7" string="42" />
          </tokens>
        </entity>
        <entity id="9" string="France" type="LOCATION" score="0.0">
          <tokens>
            <token id="23" string="France" />
          </tokens>
        </entity>
        <entity id="10" string="Philippe Cozette" type="PERSON" score="0.0">
          <tokens>
            <token id="15" string="Philippe" />
            <token id="16" string="Cozette" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>The smiling pair then clasped hands, embraced and exchanged their national flags.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="smiling" lemma="smile" stem="smile" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="pair" lemma="pair" stem="pair" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="clasped" lemma="clasp" stem="clasp" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="hands" lemma="hand" stem="hand" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="embraced" lemma="embrace" stem="embrac" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="exchanged" lemma="exchange" stem="exchang" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="national" lemma="national" stem="nation" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="flags" lemma="flag" stem="flag" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (VBG smiling) (NN pair)) (ADVP (RB then)) (VP (VP (VBD clasped) (NP (NNS hands))) (, ,) (VP (VBD embraced)) (CC and) (VP (VBD exchanged) (NP (PRP$ their) (JJ national) (NNS flags)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="The smiling pair" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="smiling" />
            <token id="3" string="pair" />
          </tokens>
        </chunking>
        <chunking id="2" string="clasped hands , embraced and exchanged their national flags" type="VP">
          <tokens>
            <token id="5" string="clasped" />
            <token id="6" string="hands" />
            <token id="7" string="," />
            <token id="8" string="embraced" />
            <token id="9" string="and" />
            <token id="10" string="exchanged" />
            <token id="11" string="their" />
            <token id="12" string="national" />
            <token id="13" string="flags" />
          </tokens>
        </chunking>
        <chunking id="3" string="hands" type="NP">
          <tokens>
            <token id="6" string="hands" />
          </tokens>
        </chunking>
        <chunking id="4" string="embraced" type="VP">
          <tokens>
            <token id="8" string="embraced" />
          </tokens>
        </chunking>
        <chunking id="5" string="their national flags" type="NP">
          <tokens>
            <token id="11" string="their" />
            <token id="12" string="national" />
            <token id="13" string="flags" />
          </tokens>
        </chunking>
        <chunking id="6" string="clasped hands" type="VP">
          <tokens>
            <token id="5" string="clasped" />
            <token id="6" string="hands" />
          </tokens>
        </chunking>
        <chunking id="7" string="exchanged their national flags" type="VP">
          <tokens>
            <token id="10" string="exchanged" />
            <token id="11" string="their" />
            <token id="12" string="national" />
            <token id="13" string="flags" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">pair</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">pair</governor>
          <dependent id="2">smiling</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">clasped</governor>
          <dependent id="3">pair</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">clasped</governor>
          <dependent id="4">then</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">clasped</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">clasped</governor>
          <dependent id="6">hands</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">clasped</governor>
          <dependent id="8">embraced</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">clasped</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">clasped</governor>
          <dependent id="10">exchanged</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="13">flags</governor>
          <dependent id="11">their</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">flags</governor>
          <dependent id="12">national</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">exchanged</governor>
          <dependent id="13">flags</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="8" has_coreference="false">
      <content>Workers in overalls looked on and applauded.</content>
      <tokens>
        <token id="1" string="Workers" lemma="worker" stem="worker" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="overalls" lemma="overalls" stem="overal" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="looked" lemma="look" stem="look" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="applauded" lemma="applaud" stem="applaud" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNS Workers)) (PP (IN in) (NP (NNS overalls)))) (VP (VP (VBD looked) (PP (IN on))) (CC and) (VP (VBD applauded))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Workers" type="NP">
          <tokens>
            <token id="1" string="Workers" />
          </tokens>
        </chunking>
        <chunking id="2" string="Workers in overalls" type="NP">
          <tokens>
            <token id="1" string="Workers" />
            <token id="2" string="in" />
            <token id="3" string="overalls" />
          </tokens>
        </chunking>
        <chunking id="3" string="applauded" type="VP">
          <tokens>
            <token id="7" string="applauded" />
          </tokens>
        </chunking>
        <chunking id="4" string="looked on and applauded" type="VP">
          <tokens>
            <token id="4" string="looked" />
            <token id="5" string="on" />
            <token id="6" string="and" />
            <token id="7" string="applauded" />
          </tokens>
        </chunking>
        <chunking id="5" string="looked on" type="VP">
          <tokens>
            <token id="4" string="looked" />
            <token id="5" string="on" />
          </tokens>
        </chunking>
        <chunking id="6" string="overalls" type="NP">
          <tokens>
            <token id="3" string="overalls" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">looked</governor>
          <dependent id="1">Workers</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">overalls</governor>
          <dependent id="2">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Workers</governor>
          <dependent id="3">overalls</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">looked</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">looked</governor>
          <dependent id="5">on</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">looked</governor>
          <dependent id="6">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">looked</governor>
          <dependent id="7">applauded</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="9" has_coreference="false">
      <content>&amp;quot;God save the queen!&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="God" lemma="God" stem="god" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="save" lemma="save" stem="save" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="queen" lemma="queen" stem="queen" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="!" lemma="!" stem="!" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (NNP God)) (VP (VB save) (NP (DT the) (NN queen))) (. !) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="the queen" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="queen" />
          </tokens>
        </chunking>
        <chunking id="2" string="God" type="NP">
          <tokens>
            <token id="2" string="God" />
          </tokens>
        </chunking>
        <chunking id="3" string="save the queen" type="VP">
          <tokens>
            <token id="3" string="save" />
            <token id="4" string="the" />
            <token id="5" string="queen" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">save</governor>
          <dependent id="2">God</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">save</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">queen</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">save</governor>
          <dependent id="5">queen</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>cried French workers, uncorking Champagne bottles.</content>
      <tokens>
        <token id="1" string="cried" lemma="cry" stem="cri" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="French" lemma="french" stem="french" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="true" is_refers="false" />
        <token id="3" string="workers" lemma="worker" stem="worker" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="uncorking" lemma="uncork" stem="uncork" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="Champagne" lemma="Champagne" stem="champagn" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="7" string="bottles" lemma="bottle" stem="bottl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (VP (VBD cried) (NP (JJ French) (NNS workers)) (, ,) (S (VP (VBG uncorking) (NP (NNP Champagne) (NNS bottles))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Champagne bottles" type="NP">
          <tokens>
            <token id="6" string="Champagne" />
            <token id="7" string="bottles" />
          </tokens>
        </chunking>
        <chunking id="2" string="uncorking Champagne bottles" type="VP">
          <tokens>
            <token id="5" string="uncorking" />
            <token id="6" string="Champagne" />
            <token id="7" string="bottles" />
          </tokens>
        </chunking>
        <chunking id="3" string="French workers" type="NP">
          <tokens>
            <token id="2" string="French" />
            <token id="3" string="workers" />
          </tokens>
        </chunking>
        <chunking id="4" string="cried French workers , uncorking Champagne bottles" type="VP">
          <tokens>
            <token id="1" string="cried" />
            <token id="2" string="French" />
            <token id="3" string="workers" />
            <token id="4" string="," />
            <token id="5" string="uncorking" />
            <token id="6" string="Champagne" />
            <token id="7" string="bottles" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="1">cried</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">workers</governor>
          <dependent id="2">French</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="1">cried</governor>
          <dependent id="3">workers</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="1">cried</governor>
          <dependent id="5">uncorking</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">bottles</governor>
          <dependent id="6">Champagne</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">uncorking</governor>
          <dependent id="7">bottles</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="French" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="2" string="French" />
          </tokens>
        </entity>
        <entity id="2" string="Champagne" type="MISC" score="0.0">
          <tokens>
            <token id="6" string="Champagne" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="11" has_coreference="false">
      <content>&amp;quot;Vive la France!&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Vive" lemma="Vive" stem="vive" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="la" lemma="la" stem="la" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="France" lemma="France" stem="franc" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="5" string="!" lemma="!" stem="!" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (NP (NP (`` ``) (NNP Vive)) (NP (NNP la) (NNP France) (. !) ('' ''))))</syntactictree>
      <chunkings>
        <chunking id="1" string="`` Vive" type="NP">
          <tokens>
            <token id="1" string="&quot;" />
            <token id="2" string="Vive" />
          </tokens>
        </chunking>
        <chunking id="2" string="`` Vive la France ! ''" type="NP">
          <tokens>
            <token id="1" string="&quot;" />
            <token id="2" string="Vive" />
            <token id="3" string="la" />
            <token id="4" string="France" />
            <token id="5" string="!" />
            <token id="6" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="3" string="la France ! ''" type="NP">
          <tokens>
            <token id="3" string="la" />
            <token id="4" string="France" />
            <token id="5" string="!" />
            <token id="6" string="&quot;" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">Vive</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">France</governor>
          <dependent id="3">la</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="2">Vive</governor>
          <dependent id="4">France</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="France" type="LOCATION" score="0.0">
          <tokens>
            <token id="4" string="France" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="12" has_coreference="false">
      <content>came the reply from the British side.</content>
      <tokens>
        <token id="1" string="came" lemma="come" stem="came" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="reply" lemma="reply" stem="repli" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="British" lemma="british" stem="british" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="7" string="side" lemma="side" stem="side" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (VP (VBD came) (NP (DT the) (NN reply)) (PP (IN from) (NP (DT the) (JJ British) (NN side)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="came the reply from the British side" type="VP">
          <tokens>
            <token id="1" string="came" />
            <token id="2" string="the" />
            <token id="3" string="reply" />
            <token id="4" string="from" />
            <token id="5" string="the" />
            <token id="6" string="British" />
            <token id="7" string="side" />
          </tokens>
        </chunking>
        <chunking id="2" string="the reply" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="reply" />
          </tokens>
        </chunking>
        <chunking id="3" string="the British side" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="British" />
            <token id="7" string="side" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="1">came</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">reply</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="1">came</governor>
          <dependent id="3">reply</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">side</governor>
          <dependent id="4">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">side</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">side</governor>
          <dependent id="6">British</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">came</governor>
          <dependent id="7">side</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="British" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="6" string="British" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>Saturday&amp;apost;s handshake came three years to the day after tunneling began at Sangatte, near Calais, and in Folkestone, England.</content>
      <tokens>
        <token id="1" string="Saturday" lemma="Saturday" stem="saturdai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="true" />
        <token id="2" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="3" string="handshake" lemma="handshake" stem="handshak" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="came" lemma="come" stem="came" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="three" lemma="three" stem="three" pos="CD" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="6" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="9" string="day" lemma="day" stem="dai" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="10" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="tunneling" lemma="tunneling" stem="tunnel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="began" lemma="begin" stem="began" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Sangatte" lemma="Sangatte" stem="sangatt" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="near" lemma="near" stem="near" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="Calais" lemma="Calais" stem="calai" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="Folkestone" lemma="Folkestone" stem="folkeston" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="England" lemma="England" stem="england" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Saturday) (POS 's)) (NN handshake)) (VP (VBD came) (NP (CD three) (NNS years)) (PP (TO to) (NP (DT the) (NN day))) (SBAR (IN after) (S (NP (NN tunneling)) (VP (VBD began) (PP (IN at) (NP (NNP Sangatte))) (, ,) (PP (PP (IN near) (NP (NNP Calais))) (, ,) (CC and) (PP (IN in) (NP (NNP Folkestone) (, ,) (NNP England)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="after tunneling began at Sangatte , near Calais , and in Folkestone , England" type="SBAR">
          <tokens>
            <token id="10" string="after" />
            <token id="11" string="tunneling" />
            <token id="12" string="began" />
            <token id="13" string="at" />
            <token id="14" string="Sangatte" />
            <token id="15" string="," />
            <token id="16" string="near" />
            <token id="17" string="Calais" />
            <token id="18" string="," />
            <token id="19" string="and" />
            <token id="20" string="in" />
            <token id="21" string="Folkestone" />
            <token id="22" string="," />
            <token id="23" string="England" />
          </tokens>
        </chunking>
        <chunking id="2" string="Calais" type="NP">
          <tokens>
            <token id="17" string="Calais" />
          </tokens>
        </chunking>
        <chunking id="3" string="three years" type="NP">
          <tokens>
            <token id="5" string="three" />
            <token id="6" string="years" />
          </tokens>
        </chunking>
        <chunking id="4" string="began at Sangatte , near Calais , and in Folkestone , England" type="VP">
          <tokens>
            <token id="12" string="began" />
            <token id="13" string="at" />
            <token id="14" string="Sangatte" />
            <token id="15" string="," />
            <token id="16" string="near" />
            <token id="17" string="Calais" />
            <token id="18" string="," />
            <token id="19" string="and" />
            <token id="20" string="in" />
            <token id="21" string="Folkestone" />
            <token id="22" string="," />
            <token id="23" string="England" />
          </tokens>
        </chunking>
        <chunking id="5" string="the day" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="day" />
          </tokens>
        </chunking>
        <chunking id="6" string="Sangatte" type="NP">
          <tokens>
            <token id="14" string="Sangatte" />
          </tokens>
        </chunking>
        <chunking id="7" string="came three years to the day after tunneling began at Sangatte , near Calais , and in Folkestone , England" type="VP">
          <tokens>
            <token id="4" string="came" />
            <token id="5" string="three" />
            <token id="6" string="years" />
            <token id="7" string="to" />
            <token id="8" string="the" />
            <token id="9" string="day" />
            <token id="10" string="after" />
            <token id="11" string="tunneling" />
            <token id="12" string="began" />
            <token id="13" string="at" />
            <token id="14" string="Sangatte" />
            <token id="15" string="," />
            <token id="16" string="near" />
            <token id="17" string="Calais" />
            <token id="18" string="," />
            <token id="19" string="and" />
            <token id="20" string="in" />
            <token id="21" string="Folkestone" />
            <token id="22" string="," />
            <token id="23" string="England" />
          </tokens>
        </chunking>
        <chunking id="8" string="tunneling" type="NP">
          <tokens>
            <token id="11" string="tunneling" />
          </tokens>
        </chunking>
        <chunking id="9" string="Saturday 's handshake" type="NP">
          <tokens>
            <token id="1" string="Saturday" />
            <token id="2" string="'s" />
            <token id="3" string="handshake" />
          </tokens>
        </chunking>
        <chunking id="10" string="Folkestone , England" type="NP">
          <tokens>
            <token id="21" string="Folkestone" />
            <token id="22" string="," />
            <token id="23" string="England" />
          </tokens>
        </chunking>
        <chunking id="11" string="Saturday 's" type="NP">
          <tokens>
            <token id="1" string="Saturday" />
            <token id="2" string="'s" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="3">handshake</governor>
          <dependent id="1">Saturday</dependent>
        </dependency>
        <dependency type="case">
          <governor id="1">Saturday</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">came</governor>
          <dependent id="3">handshake</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">came</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="6">years</governor>
          <dependent id="5">three</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="4">came</governor>
          <dependent id="6">years</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">day</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">day</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">came</governor>
          <dependent id="9">day</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">began</governor>
          <dependent id="10">after</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">began</governor>
          <dependent id="11">tunneling</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">came</governor>
          <dependent id="12">began</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">began</governor>
          <dependent id="12">began</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">Sangatte</governor>
          <dependent id="13">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">began</governor>
          <dependent id="14">Sangatte</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">Calais</governor>
          <dependent id="16">near</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">began</governor>
          <dependent id="17">Calais</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="12">began</governor>
          <dependent id="19">and</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">England</governor>
          <dependent id="20">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">England</governor>
          <dependent id="21">Folkestone</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">began</governor>
          <dependent id="23">England</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Calais" type="LOCATION" score="0.0">
          <tokens>
            <token id="17" string="Calais" />
          </tokens>
        </entity>
        <entity id="2" string="three years" type="DURATION" score="0.0">
          <tokens>
            <token id="5" string="three" />
            <token id="6" string="years" />
          </tokens>
        </entity>
        <entity id="3" string="the day" type="DATE" score="0.0">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="day" />
          </tokens>
        </entity>
        <entity id="4" string="Sangatte" type="LOCATION" score="0.0">
          <tokens>
            <token id="14" string="Sangatte" />
          </tokens>
        </entity>
        <entity id="5" string="Folkestone" type="LOCATION" score="0.0">
          <tokens>
            <token id="21" string="Folkestone" />
          </tokens>
        </entity>
        <entity id="6" string="England" type="LOCATION" score="0.0">
          <tokens>
            <token id="23" string="England" />
          </tokens>
        </entity>
        <entity id="7" string="Saturday" type="DATE" score="0.0">
          <tokens>
            <token id="1" string="Saturday" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>The $16.7-billion Channel Tunnel will make it possible to travel from Paris to London by high-speed train in 3 1/2 hours when it opens in June, 1993.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="3" string="16.7-billion" lemma="16.7-billion" stem="16.7-billion" pos="CD" type="Word" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="4" string="Channel" lemma="Channel" stem="channel" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="5" string="Tunnel" lemma="tunnel" stem="tunnel" pos="NN" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="6" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="make" lemma="make" stem="make" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="possible" lemma="possible" stem="possibl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="travel" lemma="travel" stem="travel" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Paris" lemma="Paris" stem="pari" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="14" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="London" lemma="London" stem="london" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="16" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="high-speed" lemma="high-speed" stem="high-spe" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="train" lemma="train" stem="train" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="3 1/2" lemma="31/2" stem="3 1/2" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="21" string="hours" lemma="hour" stem="hour" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="22" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="opens" lemma="open" stem="open" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="June" lemma="June" stem="june" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="27" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="28" string="1993" lemma="1993" stem="1993" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) ($ $) (CD 16.7-billion)) (NP (NNP Channel) (NN Tunnel))) (VP (MD will) (VP (VB make) (S (NP (PRP it)) (ADJP (JJ possible) (S (VP (TO to) (VP (VB travel) (PP (IN from) (NP (NNP Paris))) (PP (TO to) (NP (NNP London))) (PP (IN by) (NP (NP (JJ high-speed) (NN train)) (PP (IN in) (NP (CD 31/2) (NNS hours)))))))))) (SBAR (WHADVP (WRB when)) (S (NP (PRP it)) (VP (VBZ opens) (PP (IN in) (NP (NP (NNP June)) (, ,) (NP (CD 1993))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="possible to travel from Paris to London by high-speed train in 31/2 hours" type="ADJP">
          <tokens>
            <token id="9" string="possible" />
            <token id="10" string="to" />
            <token id="11" string="travel" />
            <token id="12" string="from" />
            <token id="13" string="Paris" />
            <token id="14" string="to" />
            <token id="15" string="London" />
            <token id="16" string="by" />
            <token id="17" string="high-speed" />
            <token id="18" string="train" />
            <token id="19" string="in" />
            <token id="20" string="3 1/2" />
            <token id="21" string="hours" />
          </tokens>
        </chunking>
        <chunking id="2" string="make it possible to travel from Paris to London by high-speed train in 31/2 hours when it opens in June , 1993" type="VP">
          <tokens>
            <token id="7" string="make" />
            <token id="8" string="it" />
            <token id="9" string="possible" />
            <token id="10" string="to" />
            <token id="11" string="travel" />
            <token id="12" string="from" />
            <token id="13" string="Paris" />
            <token id="14" string="to" />
            <token id="15" string="London" />
            <token id="16" string="by" />
            <token id="17" string="high-speed" />
            <token id="18" string="train" />
            <token id="19" string="in" />
            <token id="20" string="3 1/2" />
            <token id="21" string="hours" />
            <token id="22" string="when" />
            <token id="23" string="it" />
            <token id="24" string="opens" />
            <token id="25" string="in" />
            <token id="26" string="June" />
            <token id="27" string="," />
            <token id="28" string="1993" />
          </tokens>
        </chunking>
        <chunking id="3" string="June" type="NP">
          <tokens>
            <token id="26" string="June" />
          </tokens>
        </chunking>
        <chunking id="4" string="travel from Paris to London by high-speed train in 31/2 hours" type="VP">
          <tokens>
            <token id="11" string="travel" />
            <token id="12" string="from" />
            <token id="13" string="Paris" />
            <token id="14" string="to" />
            <token id="15" string="London" />
            <token id="16" string="by" />
            <token id="17" string="high-speed" />
            <token id="18" string="train" />
            <token id="19" string="in" />
            <token id="20" string="3 1/2" />
            <token id="21" string="hours" />
          </tokens>
        </chunking>
        <chunking id="5" string="will make it possible to travel from Paris to London by high-speed train in 31/2 hours when it opens in June , 1993" type="VP">
          <tokens>
            <token id="6" string="will" />
            <token id="7" string="make" />
            <token id="8" string="it" />
            <token id="9" string="possible" />
            <token id="10" string="to" />
            <token id="11" string="travel" />
            <token id="12" string="from" />
            <token id="13" string="Paris" />
            <token id="14" string="to" />
            <token id="15" string="London" />
            <token id="16" string="by" />
            <token id="17" string="high-speed" />
            <token id="18" string="train" />
            <token id="19" string="in" />
            <token id="20" string="3 1/2" />
            <token id="21" string="hours" />
            <token id="22" string="when" />
            <token id="23" string="it" />
            <token id="24" string="opens" />
            <token id="25" string="in" />
            <token id="26" string="June" />
            <token id="27" string="," />
            <token id="28" string="1993" />
          </tokens>
        </chunking>
        <chunking id="6" string="it" type="NP">
          <tokens>
            <token id="8" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="The $ 16.7-billion Channel Tunnel" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="$" />
            <token id="3" string="16.7-billion" />
            <token id="4" string="Channel" />
            <token id="5" string="Tunnel" />
          </tokens>
        </chunking>
        <chunking id="8" string="high-speed train" type="NP">
          <tokens>
            <token id="17" string="high-speed" />
            <token id="18" string="train" />
          </tokens>
        </chunking>
        <chunking id="9" string="to travel from Paris to London by high-speed train in 31/2 hours" type="VP">
          <tokens>
            <token id="10" string="to" />
            <token id="11" string="travel" />
            <token id="12" string="from" />
            <token id="13" string="Paris" />
            <token id="14" string="to" />
            <token id="15" string="London" />
            <token id="16" string="by" />
            <token id="17" string="high-speed" />
            <token id="18" string="train" />
            <token id="19" string="in" />
            <token id="20" string="3 1/2" />
            <token id="21" string="hours" />
          </tokens>
        </chunking>
        <chunking id="10" string="when" type="WHADVP">
          <tokens>
            <token id="22" string="when" />
          </tokens>
        </chunking>
        <chunking id="11" string="Channel Tunnel" type="NP">
          <tokens>
            <token id="4" string="Channel" />
            <token id="5" string="Tunnel" />
          </tokens>
        </chunking>
        <chunking id="12" string="31/2 hours" type="NP">
          <tokens>
            <token id="20" string="3 1/2" />
            <token id="21" string="hours" />
          </tokens>
        </chunking>
        <chunking id="13" string="June , 1993" type="NP">
          <tokens>
            <token id="26" string="June" />
            <token id="27" string="," />
            <token id="28" string="1993" />
          </tokens>
        </chunking>
        <chunking id="14" string="The $ 16.7-billion" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="$" />
            <token id="3" string="16.7-billion" />
          </tokens>
        </chunking>
        <chunking id="15" string="high-speed train in 31/2 hours" type="NP">
          <tokens>
            <token id="17" string="high-speed" />
            <token id="18" string="train" />
            <token id="19" string="in" />
            <token id="20" string="3 1/2" />
            <token id="21" string="hours" />
          </tokens>
        </chunking>
        <chunking id="16" string="when it opens in June , 1993" type="SBAR">
          <tokens>
            <token id="22" string="when" />
            <token id="23" string="it" />
            <token id="24" string="opens" />
            <token id="25" string="in" />
            <token id="26" string="June" />
            <token id="27" string="," />
            <token id="28" string="1993" />
          </tokens>
        </chunking>
        <chunking id="17" string="1993" type="NP">
          <tokens>
            <token id="28" string="1993" />
          </tokens>
        </chunking>
        <chunking id="18" string="London" type="NP">
          <tokens>
            <token id="15" string="London" />
          </tokens>
        </chunking>
        <chunking id="19" string="Paris" type="NP">
          <tokens>
            <token id="13" string="Paris" />
          </tokens>
        </chunking>
        <chunking id="20" string="opens in June , 1993" type="VP">
          <tokens>
            <token id="24" string="opens" />
            <token id="25" string="in" />
            <token id="26" string="June" />
            <token id="27" string="," />
            <token id="28" string="1993" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">16.7-billion</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="3">16.7-billion</governor>
          <dependent id="2">$</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">make</governor>
          <dependent id="3">16.7-billion</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Tunnel</governor>
          <dependent id="4">Channel</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="3">16.7-billion</governor>
          <dependent id="5">Tunnel</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">make</governor>
          <dependent id="6">will</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">make</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">possible</governor>
          <dependent id="8">it</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="7">make</governor>
          <dependent id="9">possible</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">travel</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="9">possible</governor>
          <dependent id="11">travel</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Paris</governor>
          <dependent id="12">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">travel</governor>
          <dependent id="13">Paris</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">London</governor>
          <dependent id="14">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">travel</governor>
          <dependent id="15">London</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">train</governor>
          <dependent id="16">by</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">train</governor>
          <dependent id="17">high-speed</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">travel</governor>
          <dependent id="18">train</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">hours</governor>
          <dependent id="19">in</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="21">hours</governor>
          <dependent id="20">31/2</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">train</governor>
          <dependent id="21">hours</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="24">opens</governor>
          <dependent id="22">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">opens</governor>
          <dependent id="23">it</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="7">make</governor>
          <dependent id="24">opens</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">June</governor>
          <dependent id="25">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">opens</governor>
          <dependent id="26">June</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">June</governor>
          <dependent id="28">1993</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="June , 1993" type="DATE" score="0.0">
          <tokens>
            <token id="26" string="June" />
            <token id="27" string="," />
            <token id="28" string="1993" />
          </tokens>
        </entity>
        <entity id="2" string="$ 16.7-billion" type="MONEY" score="0.0">
          <tokens>
            <token id="2" string="$" />
            <token id="3" string="16.7-billion" />
          </tokens>
        </entity>
        <entity id="3" string="hours" type="DURATION" score="0.0">
          <tokens>
            <token id="21" string="hours" />
          </tokens>
        </entity>
        <entity id="4" string="London" type="LOCATION" score="0.0">
          <tokens>
            <token id="15" string="London" />
          </tokens>
        </entity>
        <entity id="5" string="3 1/2" type="NUMBER" score="0.0">
          <tokens>
            <token id="20" string="3 1/2" />
          </tokens>
        </entity>
        <entity id="6" string="Channel Tunnel" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="4" string="Channel" />
            <token id="5" string="Tunnel" />
          </tokens>
        </entity>
        <entity id="7" string="Paris" type="LOCATION" score="0.0">
          <tokens>
            <token id="13" string="Paris" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>The train trip through just the tunnel is expected to take 35 minutes, compared with 90 minutes to cross the channel by ferry.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="train" lemma="train" stem="train" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="trip" lemma="trip" stem="trip" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="through" lemma="through" stem="through" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="tunnel" lemma="tunnel" stem="tunnel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="expected" lemma="expect" stem="expect" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="take" lemma="take" stem="take" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="35" lemma="35" stem="35" pos="CD" type="Number" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="13" string="minutes" lemma="minute" stem="minut" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="compared" lemma="compare" stem="compar" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="90" lemma="90" stem="90" pos="CD" type="Number" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="18" string="minutes" lemma="minute" stem="minut" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="19" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="cross" lemma="cross" stem="cross" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="channel" lemma="channel" stem="channel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="23" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="ferry" lemma="ferry" stem="ferri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN train) (NN trip)) (ADVP (RB through)) (ADVP (RB just)) (NP (DT the) (NN tunnel)) (VP (VBZ is) (VP (VBN expected) (S (VP (TO to) (VP (VB take) (NP (CD 35) (NNS minutes))))) (, ,) (PP (VBN compared) (PP (IN with) (NP (NP (CD 90) (NNS minutes)) (SBAR (S (VP (TO to) (VP (VB cross) (NP (DT the) (NN channel)) (PP (IN by) (NP (NN ferry)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="90 minutes to cross the channel by ferry" type="NP">
          <tokens>
            <token id="17" string="90" />
            <token id="18" string="minutes" />
            <token id="19" string="to" />
            <token id="20" string="cross" />
            <token id="21" string="the" />
            <token id="22" string="channel" />
            <token id="23" string="by" />
            <token id="24" string="ferry" />
          </tokens>
        </chunking>
        <chunking id="2" string="is expected to take 35 minutes , compared with 90 minutes to cross the channel by ferry" type="VP">
          <tokens>
            <token id="8" string="is" />
            <token id="9" string="expected" />
            <token id="10" string="to" />
            <token id="11" string="take" />
            <token id="12" string="35" />
            <token id="13" string="minutes" />
            <token id="14" string="," />
            <token id="15" string="compared" />
            <token id="16" string="with" />
            <token id="17" string="90" />
            <token id="18" string="minutes" />
            <token id="19" string="to" />
            <token id="20" string="cross" />
            <token id="21" string="the" />
            <token id="22" string="channel" />
            <token id="23" string="by" />
            <token id="24" string="ferry" />
          </tokens>
        </chunking>
        <chunking id="3" string="take 35 minutes" type="VP">
          <tokens>
            <token id="11" string="take" />
            <token id="12" string="35" />
            <token id="13" string="minutes" />
          </tokens>
        </chunking>
        <chunking id="4" string="35 minutes" type="NP">
          <tokens>
            <token id="12" string="35" />
            <token id="13" string="minutes" />
          </tokens>
        </chunking>
        <chunking id="5" string="to cross the channel by ferry" type="SBAR">
          <tokens>
            <token id="19" string="to" />
            <token id="20" string="cross" />
            <token id="21" string="the" />
            <token id="22" string="channel" />
            <token id="23" string="by" />
            <token id="24" string="ferry" />
          </tokens>
        </chunking>
        <chunking id="6" string="cross the channel by ferry" type="VP">
          <tokens>
            <token id="20" string="cross" />
            <token id="21" string="the" />
            <token id="22" string="channel" />
            <token id="23" string="by" />
            <token id="24" string="ferry" />
          </tokens>
        </chunking>
        <chunking id="7" string="expected to take 35 minutes , compared with 90 minutes to cross the channel by ferry" type="VP">
          <tokens>
            <token id="9" string="expected" />
            <token id="10" string="to" />
            <token id="11" string="take" />
            <token id="12" string="35" />
            <token id="13" string="minutes" />
            <token id="14" string="," />
            <token id="15" string="compared" />
            <token id="16" string="with" />
            <token id="17" string="90" />
            <token id="18" string="minutes" />
            <token id="19" string="to" />
            <token id="20" string="cross" />
            <token id="21" string="the" />
            <token id="22" string="channel" />
            <token id="23" string="by" />
            <token id="24" string="ferry" />
          </tokens>
        </chunking>
        <chunking id="8" string="the channel" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="channel" />
          </tokens>
        </chunking>
        <chunking id="9" string="ferry" type="NP">
          <tokens>
            <token id="24" string="ferry" />
          </tokens>
        </chunking>
        <chunking id="10" string="The train trip" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="train" />
            <token id="3" string="trip" />
          </tokens>
        </chunking>
        <chunking id="11" string="90 minutes" type="NP">
          <tokens>
            <token id="17" string="90" />
            <token id="18" string="minutes" />
          </tokens>
        </chunking>
        <chunking id="12" string="to take 35 minutes" type="VP">
          <tokens>
            <token id="10" string="to" />
            <token id="11" string="take" />
            <token id="12" string="35" />
            <token id="13" string="minutes" />
          </tokens>
        </chunking>
        <chunking id="13" string="the tunnel" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="tunnel" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">trip</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">trip</governor>
          <dependent id="2">train</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="9">expected</governor>
          <dependent id="3">trip</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">expected</governor>
          <dependent id="4">through</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">expected</governor>
          <dependent id="5">just</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">tunnel</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="9">expected</governor>
          <dependent id="7">tunnel</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="9">expected</governor>
          <dependent id="8">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">expected</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">take</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="9">expected</governor>
          <dependent id="11">take</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="13">minutes</governor>
          <dependent id="12">35</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">take</governor>
          <dependent id="13">minutes</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">minutes</governor>
          <dependent id="15">compared</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="15">compared</governor>
          <dependent id="16">with</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="18">minutes</governor>
          <dependent id="17">90</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="9">expected</governor>
          <dependent id="18">minutes</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="20">cross</governor>
          <dependent id="19">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="18">minutes</governor>
          <dependent id="20">cross</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">channel</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">cross</governor>
          <dependent id="22">channel</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">ferry</governor>
          <dependent id="23">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">cross</governor>
          <dependent id="24">ferry</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="90 minutes" type="DURATION" score="0.0">
          <tokens>
            <token id="17" string="90" />
            <token id="18" string="minutes" />
          </tokens>
        </entity>
        <entity id="2" string="35 minutes" type="DURATION" score="0.0">
          <tokens>
            <token id="12" string="35" />
            <token id="13" string="minutes" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="16" has_coreference="false">
      <content>Fares for the undersea crossing have not been set.</content>
      <tokens>
        <token id="1" string="Fares" lemma="fare" stem="fare" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="undersea" lemma="undersea" stem="undersea" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="crossing" lemma="cross" stem="cross" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="set" lemma="set" stem="set" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNS Fares)) (PP (IN for) (NP (NP (DT the) (NN undersea)) (VP (VBG crossing))))) (VP (VBP have) (RB not) (VP (VBN been) (VP (VBN set)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="set" type="VP">
          <tokens>
            <token id="9" string="set" />
          </tokens>
        </chunking>
        <chunking id="2" string="Fares for the undersea crossing" type="NP">
          <tokens>
            <token id="1" string="Fares" />
            <token id="2" string="for" />
            <token id="3" string="the" />
            <token id="4" string="undersea" />
            <token id="5" string="crossing" />
          </tokens>
        </chunking>
        <chunking id="3" string="the undersea crossing" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="undersea" />
            <token id="5" string="crossing" />
          </tokens>
        </chunking>
        <chunking id="4" string="the undersea" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="undersea" />
          </tokens>
        </chunking>
        <chunking id="5" string="Fares" type="NP">
          <tokens>
            <token id="1" string="Fares" />
          </tokens>
        </chunking>
        <chunking id="6" string="have not been set" type="VP">
          <tokens>
            <token id="6" string="have" />
            <token id="7" string="not" />
            <token id="8" string="been" />
            <token id="9" string="set" />
          </tokens>
        </chunking>
        <chunking id="7" string="been set" type="VP">
          <tokens>
            <token id="8" string="been" />
            <token id="9" string="set" />
          </tokens>
        </chunking>
        <chunking id="8" string="crossing" type="VP">
          <tokens>
            <token id="5" string="crossing" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="9">set</governor>
          <dependent id="1">Fares</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">undersea</governor>
          <dependent id="2">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">undersea</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Fares</governor>
          <dependent id="4">undersea</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="4">undersea</governor>
          <dependent id="5">crossing</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">set</governor>
          <dependent id="6">have</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="9">set</governor>
          <dependent id="7">not</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="9">set</governor>
          <dependent id="8">been</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">set</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="17" has_coreference="false">
      <content>But experts say the charges may be at least double the 1986 projections of $46 per person in a car and $19 per train passenger.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="experts" lemma="expert" stem="expert" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="say" lemma="say" stem="sai" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="charges" lemma="charge" stem="charg" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="may" lemma="may" stem="mai" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="least" lemma="least" stem="least" pos="JJS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="double" lemma="double" stem="doubl" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="1986" lemma="1986" stem="1986" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="13" string="projections" lemma="projection" stem="project" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="true" is_refers="false" />
        <token id="16" string="46" lemma="46" stem="46" pos="CD" type="Number" isStopWord="false" ner="MONEY" is_referenced="true" is_refers="false" />
        <token id="17" string="per" lemma="per" stem="per" pos="IN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="person" lemma="person" stem="person" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="car" lemma="car" stem="car" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="24" string="19" lemma="19" stem="19" pos="CD" type="Number" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="25" string="per" lemma="per" stem="per" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="train" lemma="train" stem="train" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="passenger" lemma="passenger" stem="passeng" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (NNS experts)) (VP (VBP say) (SBAR (S (NP (DT the) (NNS charges)) (VP (MD may) (VP (VB be) (NP (NP (NP (NP (QP (IN at) (JJS least) (JJ double))) (NP (DT the) (CD 1986) (NNS projections))) (PP (IN of) (NP (NP ($ $) (CD 46)) (PP (IN per) (NP (NP (NN person)) (PP (IN in) (NP (DT a) (NN car)))))))) (CC and) (NP (NP ($ $) (CD 19)) (PP (IN per) (NP (NN train) (NN passenger)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="at least double the 1986 projections of $ 46 per person in a car and $ 19 per train passenger" type="NP">
          <tokens>
            <token id="8" string="at" />
            <token id="9" string="least" />
            <token id="10" string="double" />
            <token id="11" string="the" />
            <token id="12" string="1986" />
            <token id="13" string="projections" />
            <token id="14" string="of" />
            <token id="15" string="$" />
            <token id="16" string="46" />
            <token id="17" string="per" />
            <token id="18" string="person" />
            <token id="19" string="in" />
            <token id="20" string="a" />
            <token id="21" string="car" />
            <token id="22" string="and" />
            <token id="23" string="$" />
            <token id="24" string="19" />
            <token id="25" string="per" />
            <token id="26" string="train" />
            <token id="27" string="passenger" />
          </tokens>
        </chunking>
        <chunking id="2" string="at least double the 1986 projections" type="NP">
          <tokens>
            <token id="8" string="at" />
            <token id="9" string="least" />
            <token id="10" string="double" />
            <token id="11" string="the" />
            <token id="12" string="1986" />
            <token id="13" string="projections" />
          </tokens>
        </chunking>
        <chunking id="3" string="the 1986 projections" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="1986" />
            <token id="13" string="projections" />
          </tokens>
        </chunking>
        <chunking id="4" string="the charges" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="charges" />
          </tokens>
        </chunking>
        <chunking id="5" string="be at least double the 1986 projections of $ 46 per person in a car and $ 19 per train passenger" type="VP">
          <tokens>
            <token id="7" string="be" />
            <token id="8" string="at" />
            <token id="9" string="least" />
            <token id="10" string="double" />
            <token id="11" string="the" />
            <token id="12" string="1986" />
            <token id="13" string="projections" />
            <token id="14" string="of" />
            <token id="15" string="$" />
            <token id="16" string="46" />
            <token id="17" string="per" />
            <token id="18" string="person" />
            <token id="19" string="in" />
            <token id="20" string="a" />
            <token id="21" string="car" />
            <token id="22" string="and" />
            <token id="23" string="$" />
            <token id="24" string="19" />
            <token id="25" string="per" />
            <token id="26" string="train" />
            <token id="27" string="passenger" />
          </tokens>
        </chunking>
        <chunking id="6" string="at least double the 1986 projections of $ 46 per person in a car" type="NP">
          <tokens>
            <token id="8" string="at" />
            <token id="9" string="least" />
            <token id="10" string="double" />
            <token id="11" string="the" />
            <token id="12" string="1986" />
            <token id="13" string="projections" />
            <token id="14" string="of" />
            <token id="15" string="$" />
            <token id="16" string="46" />
            <token id="17" string="per" />
            <token id="18" string="person" />
            <token id="19" string="in" />
            <token id="20" string="a" />
            <token id="21" string="car" />
          </tokens>
        </chunking>
        <chunking id="7" string="$ 46" type="NP">
          <tokens>
            <token id="15" string="$" />
            <token id="16" string="46" />
          </tokens>
        </chunking>
        <chunking id="8" string="say the charges may be at least double the 1986 projections of $ 46 per person in a car and $ 19 per train passenger" type="VP">
          <tokens>
            <token id="3" string="say" />
            <token id="4" string="the" />
            <token id="5" string="charges" />
            <token id="6" string="may" />
            <token id="7" string="be" />
            <token id="8" string="at" />
            <token id="9" string="least" />
            <token id="10" string="double" />
            <token id="11" string="the" />
            <token id="12" string="1986" />
            <token id="13" string="projections" />
            <token id="14" string="of" />
            <token id="15" string="$" />
            <token id="16" string="46" />
            <token id="17" string="per" />
            <token id="18" string="person" />
            <token id="19" string="in" />
            <token id="20" string="a" />
            <token id="21" string="car" />
            <token id="22" string="and" />
            <token id="23" string="$" />
            <token id="24" string="19" />
            <token id="25" string="per" />
            <token id="26" string="train" />
            <token id="27" string="passenger" />
          </tokens>
        </chunking>
        <chunking id="9" string="person in a car" type="NP">
          <tokens>
            <token id="18" string="person" />
            <token id="19" string="in" />
            <token id="20" string="a" />
            <token id="21" string="car" />
          </tokens>
        </chunking>
        <chunking id="10" string="a car" type="NP">
          <tokens>
            <token id="20" string="a" />
            <token id="21" string="car" />
          </tokens>
        </chunking>
        <chunking id="11" string="$ 19" type="NP">
          <tokens>
            <token id="23" string="$" />
            <token id="24" string="19" />
          </tokens>
        </chunking>
        <chunking id="12" string="train passenger" type="NP">
          <tokens>
            <token id="26" string="train" />
            <token id="27" string="passenger" />
          </tokens>
        </chunking>
        <chunking id="13" string="person" type="NP">
          <tokens>
            <token id="18" string="person" />
          </tokens>
        </chunking>
        <chunking id="14" string="$ 19 per train passenger" type="NP">
          <tokens>
            <token id="23" string="$" />
            <token id="24" string="19" />
            <token id="25" string="per" />
            <token id="26" string="train" />
            <token id="27" string="passenger" />
          </tokens>
        </chunking>
        <chunking id="15" string="may be at least double the 1986 projections of $ 46 per person in a car and $ 19 per train passenger" type="VP">
          <tokens>
            <token id="6" string="may" />
            <token id="7" string="be" />
            <token id="8" string="at" />
            <token id="9" string="least" />
            <token id="10" string="double" />
            <token id="11" string="the" />
            <token id="12" string="1986" />
            <token id="13" string="projections" />
            <token id="14" string="of" />
            <token id="15" string="$" />
            <token id="16" string="46" />
            <token id="17" string="per" />
            <token id="18" string="person" />
            <token id="19" string="in" />
            <token id="20" string="a" />
            <token id="21" string="car" />
            <token id="22" string="and" />
            <token id="23" string="$" />
            <token id="24" string="19" />
            <token id="25" string="per" />
            <token id="26" string="train" />
            <token id="27" string="passenger" />
          </tokens>
        </chunking>
        <chunking id="16" string="experts" type="NP">
          <tokens>
            <token id="2" string="experts" />
          </tokens>
        </chunking>
        <chunking id="17" string="the charges may be at least double the 1986 projections of $ 46 per person in a car and $ 19 per train passenger" type="SBAR">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="charges" />
            <token id="6" string="may" />
            <token id="7" string="be" />
            <token id="8" string="at" />
            <token id="9" string="least" />
            <token id="10" string="double" />
            <token id="11" string="the" />
            <token id="12" string="1986" />
            <token id="13" string="projections" />
            <token id="14" string="of" />
            <token id="15" string="$" />
            <token id="16" string="46" />
            <token id="17" string="per" />
            <token id="18" string="person" />
            <token id="19" string="in" />
            <token id="20" string="a" />
            <token id="21" string="car" />
            <token id="22" string="and" />
            <token id="23" string="$" />
            <token id="24" string="19" />
            <token id="25" string="per" />
            <token id="26" string="train" />
            <token id="27" string="passenger" />
          </tokens>
        </chunking>
        <chunking id="18" string="at least double" type="NP">
          <tokens>
            <token id="8" string="at" />
            <token id="9" string="least" />
            <token id="10" string="double" />
          </tokens>
        </chunking>
        <chunking id="19" string="$ 46 per person in a car" type="NP">
          <tokens>
            <token id="15" string="$" />
            <token id="16" string="46" />
            <token id="17" string="per" />
            <token id="18" string="person" />
            <token id="19" string="in" />
            <token id="20" string="a" />
            <token id="21" string="car" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="3">say</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">say</governor>
          <dependent id="2">experts</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">say</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">charges</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">double</governor>
          <dependent id="5">charges</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="10">double</governor>
          <dependent id="6">may</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="10">double</governor>
          <dependent id="7">be</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">least</governor>
          <dependent id="8">at</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="10">double</governor>
          <dependent id="9">least</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">say</governor>
          <dependent id="10">double</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">projections</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="13">projections</governor>
          <dependent id="12">1986</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="10">double</governor>
          <dependent id="13">projections</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">46</governor>
          <dependent id="14">of</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="16">46</governor>
          <dependent id="15">$</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">double</governor>
          <dependent id="16">46</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">person</governor>
          <dependent id="17">per</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">46</governor>
          <dependent id="18">person</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">car</governor>
          <dependent id="19">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">car</governor>
          <dependent id="20">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">person</governor>
          <dependent id="21">car</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">double</governor>
          <dependent id="22">and</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="24">19</governor>
          <dependent id="23">$</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">double</governor>
          <dependent id="24">19</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">passenger</governor>
          <dependent id="25">per</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">passenger</governor>
          <dependent id="26">train</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">19</governor>
          <dependent id="27">passenger</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1986" type="DATE" score="0.0">
          <tokens>
            <token id="12" string="1986" />
          </tokens>
        </entity>
        <entity id="2" string="$ 19" type="MONEY" score="0.0">
          <tokens>
            <token id="23" string="$" />
            <token id="24" string="19" />
          </tokens>
        </entity>
        <entity id="3" string="$ 46" type="MONEY" score="0.0">
          <tokens>
            <token id="15" string="$" />
            <token id="16" string="46" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="18" has_coreference="false">
      <content>The tunnelers have spent the last month drilling through the last 100 yards of chalk with giant American-built boring machines, trying to align the two halves.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="tunnelers" lemma="tunneler" stem="tunnel" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="spent" lemma="spend" stem="spent" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="6" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="7" string="month" lemma="month" stem="month" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="8" string="drilling" lemma="drilling" stem="drill" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="100" lemma="100" stem="100" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="13" string="yards" lemma="yard" stem="yard" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="chalk" lemma="chalk" stem="chalk" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="giant" lemma="giant" stem="giant" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="American-built" lemma="american-built" stem="american-built" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="19" string="boring" lemma="boring" stem="bore" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="machines" lemma="machine" stem="machin" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="trying" lemma="try" stem="try" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="align" lemma="align" stem="align" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="27" string="halves" lemma="half" stem="halv" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NNS tunnelers)) (VP (VBP have) (VP (VBN spent) (NP (DT the) (JJ last) (NN month) (NN drilling)) (PP (IN through) (NP (NP (DT the) (JJ last) (CD 100) (NNS yards)) (PP (IN of) (NP (NN chalk))))) (PP (IN with) (NP (JJ giant) (ADJP (JJ American-built) (JJ boring)) (NNS machines))) (, ,) (S (VP (VBG trying) (S (VP (TO to) (VP (VB align) (NP (DT the) (CD two) (NNS halves))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the last month drilling" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="last" />
            <token id="7" string="month" />
            <token id="8" string="drilling" />
          </tokens>
        </chunking>
        <chunking id="2" string="trying to align the two halves" type="VP">
          <tokens>
            <token id="22" string="trying" />
            <token id="23" string="to" />
            <token id="24" string="align" />
            <token id="25" string="the" />
            <token id="26" string="two" />
            <token id="27" string="halves" />
          </tokens>
        </chunking>
        <chunking id="3" string="to align the two halves" type="VP">
          <tokens>
            <token id="23" string="to" />
            <token id="24" string="align" />
            <token id="25" string="the" />
            <token id="26" string="two" />
            <token id="27" string="halves" />
          </tokens>
        </chunking>
        <chunking id="4" string="align the two halves" type="VP">
          <tokens>
            <token id="24" string="align" />
            <token id="25" string="the" />
            <token id="26" string="two" />
            <token id="27" string="halves" />
          </tokens>
        </chunking>
        <chunking id="5" string="The tunnelers" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="tunnelers" />
          </tokens>
        </chunking>
        <chunking id="6" string="have spent the last month drilling through the last 100 yards of chalk with giant American-built boring machines , trying to align the two halves" type="VP">
          <tokens>
            <token id="3" string="have" />
            <token id="4" string="spent" />
            <token id="5" string="the" />
            <token id="6" string="last" />
            <token id="7" string="month" />
            <token id="8" string="drilling" />
            <token id="9" string="through" />
            <token id="10" string="the" />
            <token id="11" string="last" />
            <token id="12" string="100" />
            <token id="13" string="yards" />
            <token id="14" string="of" />
            <token id="15" string="chalk" />
            <token id="16" string="with" />
            <token id="17" string="giant" />
            <token id="18" string="American-built" />
            <token id="19" string="boring" />
            <token id="20" string="machines" />
            <token id="21" string="," />
            <token id="22" string="trying" />
            <token id="23" string="to" />
            <token id="24" string="align" />
            <token id="25" string="the" />
            <token id="26" string="two" />
            <token id="27" string="halves" />
          </tokens>
        </chunking>
        <chunking id="7" string="giant American-built boring machines" type="NP">
          <tokens>
            <token id="17" string="giant" />
            <token id="18" string="American-built" />
            <token id="19" string="boring" />
            <token id="20" string="machines" />
          </tokens>
        </chunking>
        <chunking id="8" string="the last 100 yards of chalk" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="last" />
            <token id="12" string="100" />
            <token id="13" string="yards" />
            <token id="14" string="of" />
            <token id="15" string="chalk" />
          </tokens>
        </chunking>
        <chunking id="9" string="the last 100 yards" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="last" />
            <token id="12" string="100" />
            <token id="13" string="yards" />
          </tokens>
        </chunking>
        <chunking id="10" string="American-built boring" type="ADJP">
          <tokens>
            <token id="18" string="American-built" />
            <token id="19" string="boring" />
          </tokens>
        </chunking>
        <chunking id="11" string="chalk" type="NP">
          <tokens>
            <token id="15" string="chalk" />
          </tokens>
        </chunking>
        <chunking id="12" string="the two halves" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="two" />
            <token id="27" string="halves" />
          </tokens>
        </chunking>
        <chunking id="13" string="spent the last month drilling through the last 100 yards of chalk with giant American-built boring machines , trying to align the two halves" type="VP">
          <tokens>
            <token id="4" string="spent" />
            <token id="5" string="the" />
            <token id="6" string="last" />
            <token id="7" string="month" />
            <token id="8" string="drilling" />
            <token id="9" string="through" />
            <token id="10" string="the" />
            <token id="11" string="last" />
            <token id="12" string="100" />
            <token id="13" string="yards" />
            <token id="14" string="of" />
            <token id="15" string="chalk" />
            <token id="16" string="with" />
            <token id="17" string="giant" />
            <token id="18" string="American-built" />
            <token id="19" string="boring" />
            <token id="20" string="machines" />
            <token id="21" string="," />
            <token id="22" string="trying" />
            <token id="23" string="to" />
            <token id="24" string="align" />
            <token id="25" string="the" />
            <token id="26" string="two" />
            <token id="27" string="halves" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">tunnelers</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">spent</governor>
          <dependent id="2">tunnelers</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">spent</governor>
          <dependent id="3">have</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">spent</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">drilling</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">drilling</governor>
          <dependent id="6">last</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">drilling</governor>
          <dependent id="7">month</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">spent</governor>
          <dependent id="8">drilling</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">yards</governor>
          <dependent id="9">through</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">yards</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">yards</governor>
          <dependent id="11">last</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="13">yards</governor>
          <dependent id="12">100</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">spent</governor>
          <dependent id="13">yards</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">chalk</governor>
          <dependent id="14">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">yards</governor>
          <dependent id="15">chalk</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">machines</governor>
          <dependent id="16">with</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">machines</governor>
          <dependent id="17">giant</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">boring</governor>
          <dependent id="18">American-built</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">machines</governor>
          <dependent id="19">boring</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">spent</governor>
          <dependent id="20">machines</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">spent</governor>
          <dependent id="22">trying</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="24">align</governor>
          <dependent id="23">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="22">trying</governor>
          <dependent id="24">align</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">halves</governor>
          <dependent id="25">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="27">halves</governor>
          <dependent id="26">two</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="24">align</governor>
          <dependent id="27">halves</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="100" type="NUMBER" score="0.0">
          <tokens>
            <token id="12" string="100" />
          </tokens>
        </entity>
        <entity id="2" string="American-built" type="MISC" score="0.0">
          <tokens>
            <token id="18" string="American-built" />
          </tokens>
        </entity>
        <entity id="3" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="26" string="two" />
          </tokens>
        </entity>
        <entity id="4" string="the last month" type="DATE" score="0.0">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="last" />
            <token id="7" string="month" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="19" has_coreference="true">
      <content>The British tunnelers actually linked up with the French on Oct. 29, when workers drilled a 2-inch hole through the chalk in a service tunnel.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="British" lemma="british" stem="british" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="3" string="tunnelers" lemma="tunneler" stem="tunnel" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="actually" lemma="actually" stem="actual" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="linked" lemma="link" stem="link" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="French" lemma="french" stem="french" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="10" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Oct." lemma="Oct." stem="oct." pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="12" string="29" lemma="29" stem="29" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="workers" lemma="worker" stem="worker" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="drilled" lemma="drill" stem="drill" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="2-inch" lemma="2-inch" stem="2-inch" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="hole" lemma="hole" stem="hole" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="chalk" lemma="chalk" stem="chalk" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="service" lemma="service" stem="servic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="tunnel" lemma="tunnel" stem="tunnel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (JJ British) (NNS tunnelers)) (ADVP (RB actually)) (VP (VBN linked) (PRT (RP up)) (PP (IN with) (NP (NP (DT the) (JJ French)) (PP (IN on) (NP (NNP Oct.) (CD 29))))) (, ,) (SBAR (WHADVP (WRB when)) (S (NP (NNS workers)) (VP (VBD drilled) (NP (DT a) (JJ 2-inch) (NN hole)) (PP (IN through) (NP (DT the) (NN chalk))) (PP (IN in) (NP (DT a) (NN service) (NN tunnel))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the French on Oct. 29" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="French" />
            <token id="10" string="on" />
            <token id="11" string="Oct." />
            <token id="12" string="29" />
          </tokens>
        </chunking>
        <chunking id="2" string="when workers drilled a 2-inch hole through the chalk in a service tunnel" type="SBAR">
          <tokens>
            <token id="14" string="when" />
            <token id="15" string="workers" />
            <token id="16" string="drilled" />
            <token id="17" string="a" />
            <token id="18" string="2-inch" />
            <token id="19" string="hole" />
            <token id="20" string="through" />
            <token id="21" string="the" />
            <token id="22" string="chalk" />
            <token id="23" string="in" />
            <token id="24" string="a" />
            <token id="25" string="service" />
            <token id="26" string="tunnel" />
          </tokens>
        </chunking>
        <chunking id="3" string="the French" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="French" />
          </tokens>
        </chunking>
        <chunking id="4" string="The British tunnelers" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="British" />
            <token id="3" string="tunnelers" />
          </tokens>
        </chunking>
        <chunking id="5" string="a service tunnel" type="NP">
          <tokens>
            <token id="24" string="a" />
            <token id="25" string="service" />
            <token id="26" string="tunnel" />
          </tokens>
        </chunking>
        <chunking id="6" string="linked up with the French on Oct. 29 , when workers drilled a 2-inch hole through the chalk in a service tunnel" type="VP">
          <tokens>
            <token id="5" string="linked" />
            <token id="6" string="up" />
            <token id="7" string="with" />
            <token id="8" string="the" />
            <token id="9" string="French" />
            <token id="10" string="on" />
            <token id="11" string="Oct." />
            <token id="12" string="29" />
            <token id="13" string="," />
            <token id="14" string="when" />
            <token id="15" string="workers" />
            <token id="16" string="drilled" />
            <token id="17" string="a" />
            <token id="18" string="2-inch" />
            <token id="19" string="hole" />
            <token id="20" string="through" />
            <token id="21" string="the" />
            <token id="22" string="chalk" />
            <token id="23" string="in" />
            <token id="24" string="a" />
            <token id="25" string="service" />
            <token id="26" string="tunnel" />
          </tokens>
        </chunking>
        <chunking id="7" string="the chalk" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="chalk" />
          </tokens>
        </chunking>
        <chunking id="8" string="Oct. 29" type="NP">
          <tokens>
            <token id="11" string="Oct." />
            <token id="12" string="29" />
          </tokens>
        </chunking>
        <chunking id="9" string="workers" type="NP">
          <tokens>
            <token id="15" string="workers" />
          </tokens>
        </chunking>
        <chunking id="10" string="when" type="WHADVP">
          <tokens>
            <token id="14" string="when" />
          </tokens>
        </chunking>
        <chunking id="11" string="a 2-inch hole" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="2-inch" />
            <token id="19" string="hole" />
          </tokens>
        </chunking>
        <chunking id="12" string="drilled a 2-inch hole through the chalk in a service tunnel" type="VP">
          <tokens>
            <token id="16" string="drilled" />
            <token id="17" string="a" />
            <token id="18" string="2-inch" />
            <token id="19" string="hole" />
            <token id="20" string="through" />
            <token id="21" string="the" />
            <token id="22" string="chalk" />
            <token id="23" string="in" />
            <token id="24" string="a" />
            <token id="25" string="service" />
            <token id="26" string="tunnel" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">tunnelers</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">tunnelers</governor>
          <dependent id="2">British</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">linked</governor>
          <dependent id="3">tunnelers</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">linked</governor>
          <dependent id="4">actually</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">linked</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="5">linked</governor>
          <dependent id="6">up</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">French</governor>
          <dependent id="7">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">French</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">linked</governor>
          <dependent id="9">French</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Oct.</governor>
          <dependent id="10">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">French</governor>
          <dependent id="11">Oct.</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="11">Oct.</governor>
          <dependent id="12">29</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">drilled</governor>
          <dependent id="14">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">drilled</governor>
          <dependent id="15">workers</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="5">linked</governor>
          <dependent id="16">drilled</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">hole</governor>
          <dependent id="17">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">hole</governor>
          <dependent id="18">2-inch</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">drilled</governor>
          <dependent id="19">hole</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">chalk</governor>
          <dependent id="20">through</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">chalk</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">drilled</governor>
          <dependent id="22">chalk</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">tunnel</governor>
          <dependent id="23">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">tunnel</governor>
          <dependent id="24">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">tunnel</governor>
          <dependent id="25">service</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">drilled</governor>
          <dependent id="26">tunnel</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="French" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="9" string="French" />
          </tokens>
        </entity>
        <entity id="2" string="British" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="2" string="British" />
          </tokens>
        </entity>
        <entity id="3" string="Oct. 29" type="DATE" score="0.0">
          <tokens>
            <token id="11" string="Oct." />
            <token id="12" string="29" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="20" has_coreference="true">
      <content>The connection ended Britain&amp;apost;s island separation from continental Europe for the first time since the last Ice Age about 8,000 years ago.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="connection" lemma="connection" stem="connect" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="ended" lemma="end" stem="end" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="Britain" lemma="Britain" stem="britain" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="5" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="island" lemma="island" stem="island" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="separation" lemma="separation" stem="separ" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="continental" lemma="continental" stem="continent" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="Europe" lemma="Europe" stem="europ" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="11" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="14" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="since" lemma="since" stem="sinc" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="Ice" lemma="Ice" stem="ice" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="Age" lemma="Age" stem="age" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="21" string="8,000" lemma="8,000" stem="8,000" pos="CD" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="22" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="23" string="ago" lemma="ago" stem="ago" pos="RB" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN connection)) (VP (VBD ended) (NP (NP (NNP Britain) (POS 's)) (NN island) (NN separation)) (PP (IN from) (NP (JJ continental) (NNP Europe))) (PP (IN for) (NP (NP (DT the) (JJ first) (NN time)) (PP (IN since) (NP (DT the) (JJ last) (NNP Ice) (NNP Age))))) (PP (IN about) (ADVP (NP (CD 8,000) (NNS years)) (RB ago)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the first time" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="first" />
            <token id="14" string="time" />
          </tokens>
        </chunking>
        <chunking id="2" string="8,000 years" type="NP">
          <tokens>
            <token id="21" string="8,000" />
            <token id="22" string="years" />
          </tokens>
        </chunking>
        <chunking id="3" string="the first time since the last Ice Age" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="first" />
            <token id="14" string="time" />
            <token id="15" string="since" />
            <token id="16" string="the" />
            <token id="17" string="last" />
            <token id="18" string="Ice" />
            <token id="19" string="Age" />
          </tokens>
        </chunking>
        <chunking id="4" string="Britain 's" type="NP">
          <tokens>
            <token id="4" string="Britain" />
            <token id="5" string="'s" />
          </tokens>
        </chunking>
        <chunking id="5" string="continental Europe" type="NP">
          <tokens>
            <token id="9" string="continental" />
            <token id="10" string="Europe" />
          </tokens>
        </chunking>
        <chunking id="6" string="ended Britain 's island separation from continental Europe for the first time since the last Ice Age about 8,000 years ago" type="VP">
          <tokens>
            <token id="3" string="ended" />
            <token id="4" string="Britain" />
            <token id="5" string="'s" />
            <token id="6" string="island" />
            <token id="7" string="separation" />
            <token id="8" string="from" />
            <token id="9" string="continental" />
            <token id="10" string="Europe" />
            <token id="11" string="for" />
            <token id="12" string="the" />
            <token id="13" string="first" />
            <token id="14" string="time" />
            <token id="15" string="since" />
            <token id="16" string="the" />
            <token id="17" string="last" />
            <token id="18" string="Ice" />
            <token id="19" string="Age" />
            <token id="20" string="about" />
            <token id="21" string="8,000" />
            <token id="22" string="years" />
            <token id="23" string="ago" />
          </tokens>
        </chunking>
        <chunking id="7" string="Britain 's island separation" type="NP">
          <tokens>
            <token id="4" string="Britain" />
            <token id="5" string="'s" />
            <token id="6" string="island" />
            <token id="7" string="separation" />
          </tokens>
        </chunking>
        <chunking id="8" string="The connection" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="connection" />
          </tokens>
        </chunking>
        <chunking id="9" string="the last Ice Age" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="last" />
            <token id="18" string="Ice" />
            <token id="19" string="Age" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">connection</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">ended</governor>
          <dependent id="2">connection</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">ended</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="7">separation</governor>
          <dependent id="4">Britain</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">Britain</governor>
          <dependent id="5">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">separation</governor>
          <dependent id="6">island</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">ended</governor>
          <dependent id="7">separation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">Europe</governor>
          <dependent id="8">from</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">Europe</governor>
          <dependent id="9">continental</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">ended</governor>
          <dependent id="10">Europe</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">time</governor>
          <dependent id="11">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">time</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">time</governor>
          <dependent id="13">first</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">ended</governor>
          <dependent id="14">time</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">Age</governor>
          <dependent id="15">since</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">Age</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">Age</governor>
          <dependent id="17">last</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">Age</governor>
          <dependent id="18">Ice</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">time</governor>
          <dependent id="19">Age</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">ago</governor>
          <dependent id="20">about</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="22">years</governor>
          <dependent id="21">8,000</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="23">ago</governor>
          <dependent id="22">years</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">ended</governor>
          <dependent id="23">ago</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="13" string="first" />
          </tokens>
        </entity>
        <entity id="2" string="Europe" type="LOCATION" score="0.0">
          <tokens>
            <token id="10" string="Europe" />
          </tokens>
        </entity>
        <entity id="3" string="about 8,000 years ago" type="DATE" score="0.0">
          <tokens>
            <token id="20" string="about" />
            <token id="21" string="8,000" />
            <token id="22" string="years" />
            <token id="23" string="ago" />
          </tokens>
        </entity>
        <entity id="4" string="Britain" type="LOCATION" score="0.0">
          <tokens>
            <token id="4" string="Britain" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="21" has_coreference="true">
      <content>Fagg and Cozette were chosen by draw from among the 3,000 workers to represent their countries in Saturday&amp;apost;s meeting.</content>
      <tokens>
        <token id="1" string="Fagg" lemma="Fagg" stem="fagg" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="2" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="Cozette" lemma="Cozette" stem="cozett" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="4" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="chosen" lemma="choose" stem="chosen" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="draw" lemma="draw" stem="draw" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="among" lemma="among" stem="among" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="3,000" lemma="3,000" stem="3,000" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="12" string="workers" lemma="worker" stem="worker" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="represent" lemma="represent" stem="repres" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="countries" lemma="country" stem="countri" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Saturday" lemma="Saturday" stem="saturdai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="19" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="meeting" lemma="meeting" stem="meet" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Fagg) (CC and) (NNP Cozette)) (VP (VBD were) (VP (VBN chosen) (PP (IN by) (NP (NN draw))) (PP (IN from) (PP (IN among) (NP (DT the) (CD 3,000) (NNS workers)))) (S (VP (TO to) (VP (VB represent) (NP (PRP$ their) (NNS countries)) (PP (IN in) (NP (NP (NNP Saturday) (POS 's)) (NN meeting)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Saturday 's meeting" type="NP">
          <tokens>
            <token id="18" string="Saturday" />
            <token id="19" string="'s" />
            <token id="20" string="meeting" />
          </tokens>
        </chunking>
        <chunking id="2" string="to represent their countries in Saturday 's meeting" type="VP">
          <tokens>
            <token id="13" string="to" />
            <token id="14" string="represent" />
            <token id="15" string="their" />
            <token id="16" string="countries" />
            <token id="17" string="in" />
            <token id="18" string="Saturday" />
            <token id="19" string="'s" />
            <token id="20" string="meeting" />
          </tokens>
        </chunking>
        <chunking id="3" string="their countries" type="NP">
          <tokens>
            <token id="15" string="their" />
            <token id="16" string="countries" />
          </tokens>
        </chunking>
        <chunking id="4" string="Fagg and Cozette" type="NP">
          <tokens>
            <token id="1" string="Fagg" />
            <token id="2" string="and" />
            <token id="3" string="Cozette" />
          </tokens>
        </chunking>
        <chunking id="5" string="were chosen by draw from among the 3,000 workers to represent their countries in Saturday 's meeting" type="VP">
          <tokens>
            <token id="4" string="were" />
            <token id="5" string="chosen" />
            <token id="6" string="by" />
            <token id="7" string="draw" />
            <token id="8" string="from" />
            <token id="9" string="among" />
            <token id="10" string="the" />
            <token id="11" string="3,000" />
            <token id="12" string="workers" />
            <token id="13" string="to" />
            <token id="14" string="represent" />
            <token id="15" string="their" />
            <token id="16" string="countries" />
            <token id="17" string="in" />
            <token id="18" string="Saturday" />
            <token id="19" string="'s" />
            <token id="20" string="meeting" />
          </tokens>
        </chunking>
        <chunking id="6" string="represent their countries in Saturday 's meeting" type="VP">
          <tokens>
            <token id="14" string="represent" />
            <token id="15" string="their" />
            <token id="16" string="countries" />
            <token id="17" string="in" />
            <token id="18" string="Saturday" />
            <token id="19" string="'s" />
            <token id="20" string="meeting" />
          </tokens>
        </chunking>
        <chunking id="7" string="draw" type="NP">
          <tokens>
            <token id="7" string="draw" />
          </tokens>
        </chunking>
        <chunking id="8" string="the 3,000 workers" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="3,000" />
            <token id="12" string="workers" />
          </tokens>
        </chunking>
        <chunking id="9" string="chosen by draw from among the 3,000 workers to represent their countries in Saturday 's meeting" type="VP">
          <tokens>
            <token id="5" string="chosen" />
            <token id="6" string="by" />
            <token id="7" string="draw" />
            <token id="8" string="from" />
            <token id="9" string="among" />
            <token id="10" string="the" />
            <token id="11" string="3,000" />
            <token id="12" string="workers" />
            <token id="13" string="to" />
            <token id="14" string="represent" />
            <token id="15" string="their" />
            <token id="16" string="countries" />
            <token id="17" string="in" />
            <token id="18" string="Saturday" />
            <token id="19" string="'s" />
            <token id="20" string="meeting" />
          </tokens>
        </chunking>
        <chunking id="10" string="Saturday 's" type="NP">
          <tokens>
            <token id="18" string="Saturday" />
            <token id="19" string="'s" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="5">chosen</governor>
          <dependent id="1">Fagg</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="1">Fagg</governor>
          <dependent id="2">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="1">Fagg</governor>
          <dependent id="3">Cozette</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="5">chosen</governor>
          <dependent id="4">were</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">chosen</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">draw</governor>
          <dependent id="6">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">chosen</governor>
          <dependent id="7">draw</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">workers</governor>
          <dependent id="8">from</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">workers</governor>
          <dependent id="9">among</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">workers</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="12">workers</governor>
          <dependent id="11">3,000</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">chosen</governor>
          <dependent id="12">workers</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">represent</governor>
          <dependent id="13">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">chosen</governor>
          <dependent id="14">represent</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="16">countries</governor>
          <dependent id="15">their</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">represent</governor>
          <dependent id="16">countries</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">meeting</governor>
          <dependent id="17">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="20">meeting</governor>
          <dependent id="18">Saturday</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">Saturday</governor>
          <dependent id="19">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">represent</governor>
          <dependent id="20">meeting</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="3,000" type="NUMBER" score="0.0">
          <tokens>
            <token id="11" string="3,000" />
          </tokens>
        </entity>
        <entity id="2" string="Saturday" type="DATE" score="0.0">
          <tokens>
            <token id="18" string="Saturday" />
          </tokens>
        </entity>
        <entity id="3" string="Cozette" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Cozette" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="22" has_coreference="true">
      <content>After widening the passage from the size of a peephole to a window, they laid down their tools and shook hands.</content>
      <tokens>
        <token id="1" string="After" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="widening" lemma="widen" stem="widen" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="passage" lemma="passage" stem="passag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="size" lemma="size" stem="size" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="peephole" lemma="peephole" stem="peephol" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="window" lemma="window" stem="window" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="laid" lemma="lay" stem="laid" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="down" lemma="down" stem="down" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="tools" lemma="tool" stem="tool" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="shook" lemma="shake" stem="shook" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="hands" lemma="hand" stem="hand" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN After) (S (VP (VBG widening) (NP (DT the) (NN passage)) (PP (IN from) (NP (NP (DT the) (NN size)) (PP (IN of) (NP (DT a) (NN peephole))))) (PP (TO to) (NP (DT a) (NN window)))))) (, ,) (NP (PRP they)) (VP (VP (VBD laid) (PRT (RP down)) (NP (PRP$ their) (NNS tools))) (CC and) (VP (VBD shook) (NP (NNS hands)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="laid down their tools" type="VP">
          <tokens>
            <token id="16" string="laid" />
            <token id="17" string="down" />
            <token id="18" string="their" />
            <token id="19" string="tools" />
          </tokens>
        </chunking>
        <chunking id="2" string="a peephole" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="peephole" />
          </tokens>
        </chunking>
        <chunking id="3" string="they" type="NP">
          <tokens>
            <token id="15" string="they" />
          </tokens>
        </chunking>
        <chunking id="4" string="shook hands" type="VP">
          <tokens>
            <token id="21" string="shook" />
            <token id="22" string="hands" />
          </tokens>
        </chunking>
        <chunking id="5" string="hands" type="NP">
          <tokens>
            <token id="22" string="hands" />
          </tokens>
        </chunking>
        <chunking id="6" string="the size of a peephole" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="size" />
            <token id="8" string="of" />
            <token id="9" string="a" />
            <token id="10" string="peephole" />
          </tokens>
        </chunking>
        <chunking id="7" string="laid down their tools and shook hands" type="VP">
          <tokens>
            <token id="16" string="laid" />
            <token id="17" string="down" />
            <token id="18" string="their" />
            <token id="19" string="tools" />
            <token id="20" string="and" />
            <token id="21" string="shook" />
            <token id="22" string="hands" />
          </tokens>
        </chunking>
        <chunking id="8" string="the passage" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="passage" />
          </tokens>
        </chunking>
        <chunking id="9" string="a window" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="window" />
          </tokens>
        </chunking>
        <chunking id="10" string="widening the passage from the size of a peephole to a window" type="VP">
          <tokens>
            <token id="2" string="widening" />
            <token id="3" string="the" />
            <token id="4" string="passage" />
            <token id="5" string="from" />
            <token id="6" string="the" />
            <token id="7" string="size" />
            <token id="8" string="of" />
            <token id="9" string="a" />
            <token id="10" string="peephole" />
            <token id="11" string="to" />
            <token id="12" string="a" />
            <token id="13" string="window" />
          </tokens>
        </chunking>
        <chunking id="11" string="the size" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="size" />
          </tokens>
        </chunking>
        <chunking id="12" string="their tools" type="NP">
          <tokens>
            <token id="18" string="their" />
            <token id="19" string="tools" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="2">widening</governor>
          <dependent id="1">After</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="16">laid</governor>
          <dependent id="2">widening</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">passage</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">widening</governor>
          <dependent id="4">passage</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">size</governor>
          <dependent id="5">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">size</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">widening</governor>
          <dependent id="7">size</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">peephole</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">peephole</governor>
          <dependent id="9">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">size</governor>
          <dependent id="10">peephole</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">window</governor>
          <dependent id="11">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">window</governor>
          <dependent id="12">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">widening</governor>
          <dependent id="13">window</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">laid</governor>
          <dependent id="15">they</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="16">laid</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="16">laid</governor>
          <dependent id="17">down</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="19">tools</governor>
          <dependent id="18">their</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">laid</governor>
          <dependent id="19">tools</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="16">laid</governor>
          <dependent id="20">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">laid</governor>
          <dependent id="21">shook</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">shook</governor>
          <dependent id="22">hands</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="23" has_coreference="true">
      <content>&amp;quot;Bonjour,&amp;quot; boomed Fagg.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Bonjour" lemma="Bonjour" stem="bonjour" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="boomed" lemma="boom" stem="boom" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="Fagg" lemma="Fagg" stem="fagg" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (FRAG (NP (NNP Bonjour))) (, ,) ('' '') (VP (VBD boomed)) (NP (NNP Fagg)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="boomed" type="VP">
          <tokens>
            <token id="5" string="boomed" />
          </tokens>
        </chunking>
        <chunking id="2" string="Bonjour" type="NP">
          <tokens>
            <token id="2" string="Bonjour" />
          </tokens>
        </chunking>
        <chunking id="3" string="Fagg" type="NP">
          <tokens>
            <token id="6" string="Fagg" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="dep">
          <governor id="5">boomed</governor>
          <dependent id="2">Bonjour</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">boomed</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">boomed</governor>
          <dependent id="6">Fagg</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="24" has_coreference="true">
      <content>&amp;quot;Hello,&amp;quot; Cozette said, chuckling.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Hello" lemma="hello" stem="hello" pos="UH" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Cozette" lemma="Cozette" stem="cozett" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="6" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="chuckling" lemma="chuckle" stem="chuckl" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (FRAG (INTJ (UH Hello))) (, ,) ('' '') (NP (NNP Cozette)) (VP (VBD said) (, ,) (S (VP (VBG chuckling)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="said , chuckling" type="VP">
          <tokens>
            <token id="6" string="said" />
            <token id="7" string="," />
            <token id="8" string="chuckling" />
          </tokens>
        </chunking>
        <chunking id="2" string="chuckling" type="VP">
          <tokens>
            <token id="8" string="chuckling" />
          </tokens>
        </chunking>
        <chunking id="3" string="Cozette" type="NP">
          <tokens>
            <token id="5" string="Cozette" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="dep">
          <governor id="6">said</governor>
          <dependent id="2">Hello</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">said</governor>
          <dependent id="5">Cozette</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">said</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">said</governor>
          <dependent id="8">chuckling</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Cozette" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Cozette" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="25" has_coreference="true">
      <content>Michel Delebarre and Malcolm Rifkind, the French and British transportation ministers, rode in small service trains down the maintenance tunnel to witness the handshake.</content>
      <tokens>
        <token id="1" string="Michel" lemma="Michel" stem="michel" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="Delebarre" lemma="Delebarre" stem="delebarr" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="Malcolm" lemma="Malcolm" stem="malcolm" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="5" string="Rifkind" lemma="Rifkind" stem="rifkind" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="French" lemma="french" stem="french" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="true" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="British" lemma="british" stem="british" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="true" is_refers="false" />
        <token id="11" string="transportation" lemma="transportation" stem="transport" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="ministers" lemma="minister" stem="minist" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="rode" lemma="ride" stem="rode" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="small" lemma="small" stem="small" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="service" lemma="service" stem="servic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="trains" lemma="train" stem="train" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="down" lemma="down" stem="down" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="maintenance" lemma="maintenance" stem="mainten" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="tunnel" lemma="tunnel" stem="tunnel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="witness" lemma="witness" stem="wit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="26" string="handshake" lemma="handshake" stem="handshak" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Michel) (NNP Delebarre) (CC and) (NNP Malcolm) (NNP Rifkind)) (, ,) (NP (DT the) (JJ French) (CC and) (JJ British) (NN transportation) (NNS ministers)) (, ,)) (VP (VBD rode) (PP (IN in) (NP (JJ small) (NN service) (NNS trains))) (PP (IN down) (NP (DT the) (NN maintenance) (NN tunnel))) (PP (TO to) (NP (NP (NN witness)) (NP (DT the) (NN handshake))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="witness" type="NP">
          <tokens>
            <token id="24" string="witness" />
          </tokens>
        </chunking>
        <chunking id="2" string="the maintenance tunnel" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="maintenance" />
            <token id="22" string="tunnel" />
          </tokens>
        </chunking>
        <chunking id="3" string="small service trains" type="NP">
          <tokens>
            <token id="16" string="small" />
            <token id="17" string="service" />
            <token id="18" string="trains" />
          </tokens>
        </chunking>
        <chunking id="4" string="rode in small service trains down the maintenance tunnel to witness the handshake" type="VP">
          <tokens>
            <token id="14" string="rode" />
            <token id="15" string="in" />
            <token id="16" string="small" />
            <token id="17" string="service" />
            <token id="18" string="trains" />
            <token id="19" string="down" />
            <token id="20" string="the" />
            <token id="21" string="maintenance" />
            <token id="22" string="tunnel" />
            <token id="23" string="to" />
            <token id="24" string="witness" />
            <token id="25" string="the" />
            <token id="26" string="handshake" />
          </tokens>
        </chunking>
        <chunking id="5" string="Michel Delebarre and Malcolm Rifkind , the French and British transportation ministers ," type="NP">
          <tokens>
            <token id="1" string="Michel" />
            <token id="2" string="Delebarre" />
            <token id="3" string="and" />
            <token id="4" string="Malcolm" />
            <token id="5" string="Rifkind" />
            <token id="6" string="," />
            <token id="7" string="the" />
            <token id="8" string="French" />
            <token id="9" string="and" />
            <token id="10" string="British" />
            <token id="11" string="transportation" />
            <token id="12" string="ministers" />
            <token id="13" string="," />
          </tokens>
        </chunking>
        <chunking id="6" string="Michel Delebarre and Malcolm Rifkind" type="NP">
          <tokens>
            <token id="1" string="Michel" />
            <token id="2" string="Delebarre" />
            <token id="3" string="and" />
            <token id="4" string="Malcolm" />
            <token id="5" string="Rifkind" />
          </tokens>
        </chunking>
        <chunking id="7" string="the French and British transportation ministers" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="French" />
            <token id="9" string="and" />
            <token id="10" string="British" />
            <token id="11" string="transportation" />
            <token id="12" string="ministers" />
          </tokens>
        </chunking>
        <chunking id="8" string="witness the handshake" type="NP">
          <tokens>
            <token id="24" string="witness" />
            <token id="25" string="the" />
            <token id="26" string="handshake" />
          </tokens>
        </chunking>
        <chunking id="9" string="the handshake" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="handshake" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Delebarre</governor>
          <dependent id="1">Michel</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">rode</governor>
          <dependent id="2">Delebarre</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">Delebarre</governor>
          <dependent id="3">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Rifkind</governor>
          <dependent id="4">Malcolm</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">Delebarre</governor>
          <dependent id="5">Rifkind</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">French</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="2">Delebarre</governor>
          <dependent id="8">French</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">French</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">ministers</governor>
          <dependent id="10">British</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">ministers</governor>
          <dependent id="11">transportation</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">French</governor>
          <dependent id="12">ministers</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">rode</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">trains</governor>
          <dependent id="15">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">trains</governor>
          <dependent id="16">small</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">trains</governor>
          <dependent id="17">service</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">rode</governor>
          <dependent id="18">trains</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">tunnel</governor>
          <dependent id="19">down</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">tunnel</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">tunnel</governor>
          <dependent id="21">maintenance</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">rode</governor>
          <dependent id="22">tunnel</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">witness</governor>
          <dependent id="23">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">rode</governor>
          <dependent id="24">witness</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">handshake</governor>
          <dependent id="25">the</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="24">witness</governor>
          <dependent id="26">handshake</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="French" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="8" string="French" />
          </tokens>
        </entity>
        <entity id="2" string="British" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="10" string="British" />
          </tokens>
        </entity>
        <entity id="3" string="Michel Delebarre" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Michel" />
            <token id="2" string="Delebarre" />
          </tokens>
        </entity>
        <entity id="4" string="Malcolm Rifkind" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Malcolm" />
            <token id="5" string="Rifkind" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="26" has_coreference="true">
      <content>Fagg and Rifkind rode on to Sangatte, while Cozette and Delebarre headed for Folkestone to join in celebrations that lasted into the night.</content>
      <tokens>
        <token id="1" string="Fagg" lemma="Fagg" stem="fagg" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="2" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Rifkind" lemma="Rifkind" stem="rifkind" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="4" string="rode" lemma="ride" stem="rode" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Sangatte" lemma="Sangatte" stem="sangatt" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="while" lemma="while" stem="while" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Cozette" lemma="Cozette" stem="cozett" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="Delebarre" lemma="Delebarre" stem="delebarr" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="13" string="headed" lemma="head" stem="head" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="Folkestone" lemma="Folkestone" stem="folkeston" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="16" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="join" lemma="join" stem="join" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="celebrations" lemma="celebration" stem="celebr" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="lasted" lemma="last" stem="last" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="night" lemma="night" stem="night" pos="NN" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Fagg) (CC and) (NNP Rifkind)) (VP (VBD rode) (PP (IN on) (PP (TO to) (NP (NNP Sangatte)))) (, ,) (SBAR (IN while) (S (NP (NNP Cozette) (CC and) (NNP Delebarre)) (VP (VBD headed) (PP (IN for) (NP (NNP Folkestone))) (S (VP (TO to) (VP (VB join) (PP (IN in) (NP (NP (NNS celebrations)) (SBAR (WHNP (WDT that)) (S (VP (VBD lasted) (PP (IN into) (NP (DT the) (NN night))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="lasted into the night" type="VP">
          <tokens>
            <token id="21" string="lasted" />
            <token id="22" string="into" />
            <token id="23" string="the" />
            <token id="24" string="night" />
          </tokens>
        </chunking>
        <chunking id="2" string="to join in celebrations that lasted into the night" type="VP">
          <tokens>
            <token id="16" string="to" />
            <token id="17" string="join" />
            <token id="18" string="in" />
            <token id="19" string="celebrations" />
            <token id="20" string="that" />
            <token id="21" string="lasted" />
            <token id="22" string="into" />
            <token id="23" string="the" />
            <token id="24" string="night" />
          </tokens>
        </chunking>
        <chunking id="3" string="rode on to Sangatte , while Cozette and Delebarre headed for Folkestone to join in celebrations that lasted into the night" type="VP">
          <tokens>
            <token id="4" string="rode" />
            <token id="5" string="on" />
            <token id="6" string="to" />
            <token id="7" string="Sangatte" />
            <token id="8" string="," />
            <token id="9" string="while" />
            <token id="10" string="Cozette" />
            <token id="11" string="and" />
            <token id="12" string="Delebarre" />
            <token id="13" string="headed" />
            <token id="14" string="for" />
            <token id="15" string="Folkestone" />
            <token id="16" string="to" />
            <token id="17" string="join" />
            <token id="18" string="in" />
            <token id="19" string="celebrations" />
            <token id="20" string="that" />
            <token id="21" string="lasted" />
            <token id="22" string="into" />
            <token id="23" string="the" />
            <token id="24" string="night" />
          </tokens>
        </chunking>
        <chunking id="4" string="join in celebrations that lasted into the night" type="VP">
          <tokens>
            <token id="17" string="join" />
            <token id="18" string="in" />
            <token id="19" string="celebrations" />
            <token id="20" string="that" />
            <token id="21" string="lasted" />
            <token id="22" string="into" />
            <token id="23" string="the" />
            <token id="24" string="night" />
          </tokens>
        </chunking>
        <chunking id="5" string="the night" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="night" />
          </tokens>
        </chunking>
        <chunking id="6" string="Sangatte" type="NP">
          <tokens>
            <token id="7" string="Sangatte" />
          </tokens>
        </chunking>
        <chunking id="7" string="celebrations that lasted into the night" type="NP">
          <tokens>
            <token id="19" string="celebrations" />
            <token id="20" string="that" />
            <token id="21" string="lasted" />
            <token id="22" string="into" />
            <token id="23" string="the" />
            <token id="24" string="night" />
          </tokens>
        </chunking>
        <chunking id="8" string="that lasted into the night" type="SBAR">
          <tokens>
            <token id="20" string="that" />
            <token id="21" string="lasted" />
            <token id="22" string="into" />
            <token id="23" string="the" />
            <token id="24" string="night" />
          </tokens>
        </chunking>
        <chunking id="9" string="Cozette and Delebarre" type="NP">
          <tokens>
            <token id="10" string="Cozette" />
            <token id="11" string="and" />
            <token id="12" string="Delebarre" />
          </tokens>
        </chunking>
        <chunking id="10" string="headed for Folkestone to join in celebrations that lasted into the night" type="VP">
          <tokens>
            <token id="13" string="headed" />
            <token id="14" string="for" />
            <token id="15" string="Folkestone" />
            <token id="16" string="to" />
            <token id="17" string="join" />
            <token id="18" string="in" />
            <token id="19" string="celebrations" />
            <token id="20" string="that" />
            <token id="21" string="lasted" />
            <token id="22" string="into" />
            <token id="23" string="the" />
            <token id="24" string="night" />
          </tokens>
        </chunking>
        <chunking id="11" string="celebrations" type="NP">
          <tokens>
            <token id="19" string="celebrations" />
          </tokens>
        </chunking>
        <chunking id="12" string="Fagg and Rifkind" type="NP">
          <tokens>
            <token id="1" string="Fagg" />
            <token id="2" string="and" />
            <token id="3" string="Rifkind" />
          </tokens>
        </chunking>
        <chunking id="13" string="Folkestone" type="NP">
          <tokens>
            <token id="15" string="Folkestone" />
          </tokens>
        </chunking>
        <chunking id="14" string="while Cozette and Delebarre headed for Folkestone to join in celebrations that lasted into the night" type="SBAR">
          <tokens>
            <token id="9" string="while" />
            <token id="10" string="Cozette" />
            <token id="11" string="and" />
            <token id="12" string="Delebarre" />
            <token id="13" string="headed" />
            <token id="14" string="for" />
            <token id="15" string="Folkestone" />
            <token id="16" string="to" />
            <token id="17" string="join" />
            <token id="18" string="in" />
            <token id="19" string="celebrations" />
            <token id="20" string="that" />
            <token id="21" string="lasted" />
            <token id="22" string="into" />
            <token id="23" string="the" />
            <token id="24" string="night" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">rode</governor>
          <dependent id="1">Fagg</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="1">Fagg</governor>
          <dependent id="2">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="1">Fagg</governor>
          <dependent id="3">Rifkind</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">rode</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">Sangatte</governor>
          <dependent id="5">on</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">Sangatte</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">rode</governor>
          <dependent id="7">Sangatte</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">headed</governor>
          <dependent id="9">while</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">headed</governor>
          <dependent id="10">Cozette</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">Cozette</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">Cozette</governor>
          <dependent id="12">Delebarre</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">rode</governor>
          <dependent id="13">headed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">Folkestone</governor>
          <dependent id="14">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">headed</governor>
          <dependent id="15">Folkestone</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">join</governor>
          <dependent id="16">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="13">headed</governor>
          <dependent id="17">join</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">celebrations</governor>
          <dependent id="18">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">join</governor>
          <dependent id="19">celebrations</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">lasted</governor>
          <dependent id="20">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="19">celebrations</governor>
          <dependent id="21">lasted</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">night</governor>
          <dependent id="22">into</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">night</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">lasted</governor>
          <dependent id="24">night</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Sangatte" type="LOCATION" score="0.0">
          <tokens>
            <token id="7" string="Sangatte" />
          </tokens>
        </entity>
        <entity id="2" string="Folkestone" type="LOCATION" score="0.0">
          <tokens>
            <token id="15" string="Folkestone" />
          </tokens>
        </entity>
        <entity id="3" string="night" type="TIME" score="0.0">
          <tokens>
            <token id="24" string="night" />
          </tokens>
        </entity>
        <entity id="4" string="Rifkind" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Rifkind" />
          </tokens>
        </entity>
        <entity id="5" string="Delebarre" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Delebarre" />
          </tokens>
        </entity>
        <entity id="6" string="Cozette" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Cozette" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="27" has_coreference="true">
      <content>Nine workers have been killed during the project.</content>
      <tokens>
        <token id="1" string="Nine" lemma="nine" stem="nine" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="2" string="workers" lemma="worker" stem="worker" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="killed" lemma="kill" stem="kill" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="during" lemma="during" stem="dure" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="project" lemma="project" stem="project" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (CD Nine) (NNS workers)) (VP (VBP have) (VP (VBN been) (VP (VBN killed) (PP (IN during) (NP (DT the) (NN project)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="have been killed during the project" type="VP">
          <tokens>
            <token id="3" string="have" />
            <token id="4" string="been" />
            <token id="5" string="killed" />
            <token id="6" string="during" />
            <token id="7" string="the" />
            <token id="8" string="project" />
          </tokens>
        </chunking>
        <chunking id="2" string="killed during the project" type="VP">
          <tokens>
            <token id="5" string="killed" />
            <token id="6" string="during" />
            <token id="7" string="the" />
            <token id="8" string="project" />
          </tokens>
        </chunking>
        <chunking id="3" string="the project" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="project" />
          </tokens>
        </chunking>
        <chunking id="4" string="Nine workers" type="NP">
          <tokens>
            <token id="1" string="Nine" />
            <token id="2" string="workers" />
          </tokens>
        </chunking>
        <chunking id="5" string="been killed during the project" type="VP">
          <tokens>
            <token id="4" string="been" />
            <token id="5" string="killed" />
            <token id="6" string="during" />
            <token id="7" string="the" />
            <token id="8" string="project" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nummod">
          <governor id="2">workers</governor>
          <dependent id="1">Nine</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="5">killed</governor>
          <dependent id="2">workers</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">killed</governor>
          <dependent id="3">have</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="5">killed</governor>
          <dependent id="4">been</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">killed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">project</governor>
          <dependent id="6">during</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">project</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">killed</governor>
          <dependent id="8">project</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Nine" type="NUMBER" score="0.0">
          <tokens>
            <token id="1" string="Nine" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="28" has_coreference="false">
      <content>The cost has climbed from an initial estimate of $9.4 billion to $16.7 billion.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="cost" lemma="cost" stem="cost" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="climbed" lemma="climb" stem="climb" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="initial" lemma="initial" stem="initi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="estimate" lemma="estimate" stem="estim" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="11" string="9.4" lemma="9.4" stem="9.4" pos="CD" type="Number" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="12" string="billion" lemma="billion" stem="billion" pos="CD" type="Word" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="13" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="15" string="16.7" lemma="16.7" stem="16.7" pos="CD" type="Number" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="16" string="billion" lemma="billion" stem="billion" pos="CD" type="Word" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN cost)) (VP (VBZ has) (VP (VBN climbed) (PP (IN from) (NP (NP (DT an) (JJ initial) (NN estimate)) (PP (IN of) (NP (QP ($ $) (CD 9.4) (CD billion) (TO to) ($ $) (CD 16.7) (CD billion)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="climbed from an initial estimate of $ 9.4 billion to $ 16.7 billion" type="VP">
          <tokens>
            <token id="4" string="climbed" />
            <token id="5" string="from" />
            <token id="6" string="an" />
            <token id="7" string="initial" />
            <token id="8" string="estimate" />
            <token id="9" string="of" />
            <token id="10" string="$" />
            <token id="11" string="9.4" />
            <token id="12" string="billion" />
            <token id="13" string="to" />
            <token id="14" string="$" />
            <token id="15" string="16.7" />
            <token id="16" string="billion" />
          </tokens>
        </chunking>
        <chunking id="2" string="has climbed from an initial estimate of $ 9.4 billion to $ 16.7 billion" type="VP">
          <tokens>
            <token id="3" string="has" />
            <token id="4" string="climbed" />
            <token id="5" string="from" />
            <token id="6" string="an" />
            <token id="7" string="initial" />
            <token id="8" string="estimate" />
            <token id="9" string="of" />
            <token id="10" string="$" />
            <token id="11" string="9.4" />
            <token id="12" string="billion" />
            <token id="13" string="to" />
            <token id="14" string="$" />
            <token id="15" string="16.7" />
            <token id="16" string="billion" />
          </tokens>
        </chunking>
        <chunking id="3" string="$ 9.4 billion to $ 16.7 billion" type="NP">
          <tokens>
            <token id="10" string="$" />
            <token id="11" string="9.4" />
            <token id="12" string="billion" />
            <token id="13" string="to" />
            <token id="14" string="$" />
            <token id="15" string="16.7" />
            <token id="16" string="billion" />
          </tokens>
        </chunking>
        <chunking id="4" string="an initial estimate of $ 9.4 billion to $ 16.7 billion" type="NP">
          <tokens>
            <token id="6" string="an" />
            <token id="7" string="initial" />
            <token id="8" string="estimate" />
            <token id="9" string="of" />
            <token id="10" string="$" />
            <token id="11" string="9.4" />
            <token id="12" string="billion" />
            <token id="13" string="to" />
            <token id="14" string="$" />
            <token id="15" string="16.7" />
            <token id="16" string="billion" />
          </tokens>
        </chunking>
        <chunking id="5" string="an initial estimate" type="NP">
          <tokens>
            <token id="6" string="an" />
            <token id="7" string="initial" />
            <token id="8" string="estimate" />
          </tokens>
        </chunking>
        <chunking id="6" string="The cost" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="cost" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">cost</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">climbed</governor>
          <dependent id="2">cost</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">climbed</governor>
          <dependent id="3">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">climbed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">estimate</governor>
          <dependent id="5">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">estimate</governor>
          <dependent id="6">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">estimate</governor>
          <dependent id="7">initial</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">climbed</governor>
          <dependent id="8">estimate</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">$</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="14">$</governor>
          <dependent id="10">$</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">$</governor>
          <dependent id="11">9.4</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">$</governor>
          <dependent id="12">billion</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="14">$</governor>
          <dependent id="13">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">estimate</governor>
          <dependent id="14">$</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">billion</governor>
          <dependent id="15">16.7</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="14">$</governor>
          <dependent id="16">billion</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="$ 9.4 billion" type="MONEY" score="0.0">
          <tokens>
            <token id="10" string="$" />
            <token id="11" string="9.4" />
            <token id="12" string="billion" />
          </tokens>
        </entity>
        <entity id="2" string="$ 16.7 billion" type="MONEY" score="0.0">
          <tokens>
            <token id="14" string="$" />
            <token id="15" string="16.7" />
            <token id="16" string="billion" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="29" has_coreference="true">
      <content>The tunnel is viewed positively in France, where it is expected to revive economically depressed northern areas.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="tunnel" lemma="tunnel" stem="tunnel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="viewed" lemma="view" stem="view" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="positively" lemma="positively" stem="posit" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="France" lemma="France" stem="franc" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="where" lemma="where" stem="where" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="expected" lemma="expect" stem="expect" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="revive" lemma="revive" stem="reviv" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="economically" lemma="economically" stem="econom" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="depressed" lemma="depressed" stem="depress" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="northern" lemma="northern" stem="northern" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="areas" lemma="area" stem="area" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN tunnel)) (VP (VBZ is) (VP (VBN viewed) (ADVP (RB positively)) (PP (IN in) (NP (NNP France))) (, ,) (SBAR (WHADVP (WRB where)) (S (NP (PRP it)) (VP (VBZ is) (VP (VBN expected) (S (VP (TO to) (VP (VB revive) (NP (ADJP (RB economically) (JJ depressed)) (JJ northern) (NNS areas))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="revive economically depressed northern areas" type="VP">
          <tokens>
            <token id="14" string="revive" />
            <token id="15" string="economically" />
            <token id="16" string="depressed" />
            <token id="17" string="northern" />
            <token id="18" string="areas" />
          </tokens>
        </chunking>
        <chunking id="2" string="is expected to revive economically depressed northern areas" type="VP">
          <tokens>
            <token id="11" string="is" />
            <token id="12" string="expected" />
            <token id="13" string="to" />
            <token id="14" string="revive" />
            <token id="15" string="economically" />
            <token id="16" string="depressed" />
            <token id="17" string="northern" />
            <token id="18" string="areas" />
          </tokens>
        </chunking>
        <chunking id="3" string="it" type="NP">
          <tokens>
            <token id="10" string="it" />
          </tokens>
        </chunking>
        <chunking id="4" string="economically depressed northern areas" type="NP">
          <tokens>
            <token id="15" string="economically" />
            <token id="16" string="depressed" />
            <token id="17" string="northern" />
            <token id="18" string="areas" />
          </tokens>
        </chunking>
        <chunking id="5" string="where it is expected to revive economically depressed northern areas" type="SBAR">
          <tokens>
            <token id="9" string="where" />
            <token id="10" string="it" />
            <token id="11" string="is" />
            <token id="12" string="expected" />
            <token id="13" string="to" />
            <token id="14" string="revive" />
            <token id="15" string="economically" />
            <token id="16" string="depressed" />
            <token id="17" string="northern" />
            <token id="18" string="areas" />
          </tokens>
        </chunking>
        <chunking id="6" string="The tunnel" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="tunnel" />
          </tokens>
        </chunking>
        <chunking id="7" string="expected to revive economically depressed northern areas" type="VP">
          <tokens>
            <token id="12" string="expected" />
            <token id="13" string="to" />
            <token id="14" string="revive" />
            <token id="15" string="economically" />
            <token id="16" string="depressed" />
            <token id="17" string="northern" />
            <token id="18" string="areas" />
          </tokens>
        </chunking>
        <chunking id="8" string="is viewed positively in France , where it is expected to revive economically depressed northern areas" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="viewed" />
            <token id="5" string="positively" />
            <token id="6" string="in" />
            <token id="7" string="France" />
            <token id="8" string="," />
            <token id="9" string="where" />
            <token id="10" string="it" />
            <token id="11" string="is" />
            <token id="12" string="expected" />
            <token id="13" string="to" />
            <token id="14" string="revive" />
            <token id="15" string="economically" />
            <token id="16" string="depressed" />
            <token id="17" string="northern" />
            <token id="18" string="areas" />
          </tokens>
        </chunking>
        <chunking id="9" string="where" type="WHADVP">
          <tokens>
            <token id="9" string="where" />
          </tokens>
        </chunking>
        <chunking id="10" string="France" type="NP">
          <tokens>
            <token id="7" string="France" />
          </tokens>
        </chunking>
        <chunking id="11" string="economically depressed" type="ADJP">
          <tokens>
            <token id="15" string="economically" />
            <token id="16" string="depressed" />
          </tokens>
        </chunking>
        <chunking id="12" string="viewed positively in France , where it is expected to revive economically depressed northern areas" type="VP">
          <tokens>
            <token id="4" string="viewed" />
            <token id="5" string="positively" />
            <token id="6" string="in" />
            <token id="7" string="France" />
            <token id="8" string="," />
            <token id="9" string="where" />
            <token id="10" string="it" />
            <token id="11" string="is" />
            <token id="12" string="expected" />
            <token id="13" string="to" />
            <token id="14" string="revive" />
            <token id="15" string="economically" />
            <token id="16" string="depressed" />
            <token id="17" string="northern" />
            <token id="18" string="areas" />
          </tokens>
        </chunking>
        <chunking id="13" string="to revive economically depressed northern areas" type="VP">
          <tokens>
            <token id="13" string="to" />
            <token id="14" string="revive" />
            <token id="15" string="economically" />
            <token id="16" string="depressed" />
            <token id="17" string="northern" />
            <token id="18" string="areas" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">tunnel</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="4">viewed</governor>
          <dependent id="2">tunnel</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="4">viewed</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">viewed</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">viewed</governor>
          <dependent id="5">positively</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">France</governor>
          <dependent id="6">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">viewed</governor>
          <dependent id="7">France</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">expected</governor>
          <dependent id="9">where</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="12">expected</governor>
          <dependent id="10">it</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="12">expected</governor>
          <dependent id="11">is</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">viewed</governor>
          <dependent id="12">expected</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">revive</governor>
          <dependent id="13">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="12">expected</governor>
          <dependent id="14">revive</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">depressed</governor>
          <dependent id="15">economically</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">areas</governor>
          <dependent id="16">depressed</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">areas</governor>
          <dependent id="17">northern</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">revive</governor>
          <dependent id="18">areas</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="France" type="LOCATION" score="0.0">
          <tokens>
            <token id="7" string="France" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="30" has_coreference="true">
      <content>But Britain has shown worry over the loss of its historic moat from the Continent.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Britain" lemma="Britain" stem="britain" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="3" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="shown" lemma="show" stem="shown" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="worry" lemma="worry" stem="worri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="over" lemma="over" stem="over" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="loss" lemma="loss" stem="loss" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="historic" lemma="historic" stem="histor" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="moat" lemma="moat" stem="moat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="Continent" lemma="continent" stem="contin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (NNP Britain)) (VP (VBZ has) (VP (VBN shown) (NP (NP (NN worry)) (PP (IN over) (NP (NP (DT the) (NN loss)) (PP (IN of) (NP (PRP$ its) (JJ historic) (NN moat)))))) (PP (IN from) (NP (DT the) (NN Continent))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="has shown worry over the loss of its historic moat from the Continent" type="VP">
          <tokens>
            <token id="3" string="has" />
            <token id="4" string="shown" />
            <token id="5" string="worry" />
            <token id="6" string="over" />
            <token id="7" string="the" />
            <token id="8" string="loss" />
            <token id="9" string="of" />
            <token id="10" string="its" />
            <token id="11" string="historic" />
            <token id="12" string="moat" />
            <token id="13" string="from" />
            <token id="14" string="the" />
            <token id="15" string="Continent" />
          </tokens>
        </chunking>
        <chunking id="2" string="shown worry over the loss of its historic moat from the Continent" type="VP">
          <tokens>
            <token id="4" string="shown" />
            <token id="5" string="worry" />
            <token id="6" string="over" />
            <token id="7" string="the" />
            <token id="8" string="loss" />
            <token id="9" string="of" />
            <token id="10" string="its" />
            <token id="11" string="historic" />
            <token id="12" string="moat" />
            <token id="13" string="from" />
            <token id="14" string="the" />
            <token id="15" string="Continent" />
          </tokens>
        </chunking>
        <chunking id="3" string="worry" type="NP">
          <tokens>
            <token id="5" string="worry" />
          </tokens>
        </chunking>
        <chunking id="4" string="its historic moat" type="NP">
          <tokens>
            <token id="10" string="its" />
            <token id="11" string="historic" />
            <token id="12" string="moat" />
          </tokens>
        </chunking>
        <chunking id="5" string="the loss of its historic moat" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="loss" />
            <token id="9" string="of" />
            <token id="10" string="its" />
            <token id="11" string="historic" />
            <token id="12" string="moat" />
          </tokens>
        </chunking>
        <chunking id="6" string="Britain" type="NP">
          <tokens>
            <token id="2" string="Britain" />
          </tokens>
        </chunking>
        <chunking id="7" string="the Continent" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="Continent" />
          </tokens>
        </chunking>
        <chunking id="8" string="the loss" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="loss" />
          </tokens>
        </chunking>
        <chunking id="9" string="worry over the loss of its historic moat" type="NP">
          <tokens>
            <token id="5" string="worry" />
            <token id="6" string="over" />
            <token id="7" string="the" />
            <token id="8" string="loss" />
            <token id="9" string="of" />
            <token id="10" string="its" />
            <token id="11" string="historic" />
            <token id="12" string="moat" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="4">shown</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">shown</governor>
          <dependent id="2">Britain</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">shown</governor>
          <dependent id="3">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">shown</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">shown</governor>
          <dependent id="5">worry</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">loss</governor>
          <dependent id="6">over</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">loss</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">worry</governor>
          <dependent id="8">loss</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">moat</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="12">moat</governor>
          <dependent id="10">its</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">moat</governor>
          <dependent id="11">historic</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">loss</governor>
          <dependent id="12">moat</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">Continent</governor>
          <dependent id="13">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">Continent</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">shown</governor>
          <dependent id="15">Continent</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Britain" type="LOCATION" score="0.0">
          <tokens>
            <token id="2" string="Britain" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="31" has_coreference="true">
      <content>Many Britons fear drug traffickers or terrorists will invade their island via the tunnel.</content>
      <tokens>
        <token id="1" string="Many" lemma="many" stem="mani" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="Britons" lemma="Britons" stem="briton" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="3" string="fear" lemma="fear" stem="fear" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="drug" lemma="drug" stem="drug" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="traffickers" lemma="trafficker" stem="traffick" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="terrorists" lemma="terrorist" stem="terrorist" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="invade" lemma="invade" stem="invad" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="island" lemma="island" stem="island" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="via" lemma="via" stem="via" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="tunnel" lemma="tunnel" stem="tunnel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (JJ Many) (NNPS Britons)) (VP (VBP fear) (SBAR (S (NP (NN drug) (NNS traffickers) (CC or) (NNS terrorists)) (VP (MD will) (VP (VB invade) (NP (NP (PRP$ their) (NN island)) (PP (IN via) (NP (DT the) (NN tunnel))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="invade their island via the tunnel" type="VP">
          <tokens>
            <token id="9" string="invade" />
            <token id="10" string="their" />
            <token id="11" string="island" />
            <token id="12" string="via" />
            <token id="13" string="the" />
            <token id="14" string="tunnel" />
          </tokens>
        </chunking>
        <chunking id="2" string="Many Britons" type="NP">
          <tokens>
            <token id="1" string="Many" />
            <token id="2" string="Britons" />
          </tokens>
        </chunking>
        <chunking id="3" string="their island via the tunnel" type="NP">
          <tokens>
            <token id="10" string="their" />
            <token id="11" string="island" />
            <token id="12" string="via" />
            <token id="13" string="the" />
            <token id="14" string="tunnel" />
          </tokens>
        </chunking>
        <chunking id="4" string="drug traffickers or terrorists will invade their island via the tunnel" type="SBAR">
          <tokens>
            <token id="4" string="drug" />
            <token id="5" string="traffickers" />
            <token id="6" string="or" />
            <token id="7" string="terrorists" />
            <token id="8" string="will" />
            <token id="9" string="invade" />
            <token id="10" string="their" />
            <token id="11" string="island" />
            <token id="12" string="via" />
            <token id="13" string="the" />
            <token id="14" string="tunnel" />
          </tokens>
        </chunking>
        <chunking id="5" string="drug traffickers or terrorists" type="NP">
          <tokens>
            <token id="4" string="drug" />
            <token id="5" string="traffickers" />
            <token id="6" string="or" />
            <token id="7" string="terrorists" />
          </tokens>
        </chunking>
        <chunking id="6" string="will invade their island via the tunnel" type="VP">
          <tokens>
            <token id="8" string="will" />
            <token id="9" string="invade" />
            <token id="10" string="their" />
            <token id="11" string="island" />
            <token id="12" string="via" />
            <token id="13" string="the" />
            <token id="14" string="tunnel" />
          </tokens>
        </chunking>
        <chunking id="7" string="fear drug traffickers or terrorists will invade their island via the tunnel" type="VP">
          <tokens>
            <token id="3" string="fear" />
            <token id="4" string="drug" />
            <token id="5" string="traffickers" />
            <token id="6" string="or" />
            <token id="7" string="terrorists" />
            <token id="8" string="will" />
            <token id="9" string="invade" />
            <token id="10" string="their" />
            <token id="11" string="island" />
            <token id="12" string="via" />
            <token id="13" string="the" />
            <token id="14" string="tunnel" />
          </tokens>
        </chunking>
        <chunking id="8" string="their island" type="NP">
          <tokens>
            <token id="10" string="their" />
            <token id="11" string="island" />
          </tokens>
        </chunking>
        <chunking id="9" string="the tunnel" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="tunnel" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="2">Britons</governor>
          <dependent id="1">Many</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">fear</governor>
          <dependent id="2">Britons</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">fear</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">traffickers</governor>
          <dependent id="4">drug</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">invade</governor>
          <dependent id="5">traffickers</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">traffickers</governor>
          <dependent id="6">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">traffickers</governor>
          <dependent id="7">terrorists</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">invade</governor>
          <dependent id="8">will</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">fear</governor>
          <dependent id="9">invade</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">island</governor>
          <dependent id="10">their</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">invade</governor>
          <dependent id="11">island</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">tunnel</governor>
          <dependent id="12">via</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">tunnel</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">island</governor>
          <dependent id="14">tunnel</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Britons" type="MISC" score="0.0">
          <tokens>
            <token id="2" string="Britons" />
          </tokens>
        </entity>
      </entities>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="1" type="PROPER">
      <referenced ids_tokens="3" string="Saturday" id_sentence="1" />
      <mentions>
        <mention ids_tokens="1-2" string="Saturday's" id_sentence="13" />
        <mention ids_tokens="18-19" string="Saturday's" id_sentence="21" />
      </mentions>
    </coreference>
    <coreference id="2" type="PROPER">
      <referenced ids_tokens="8-9-10" string="the English Channel" id_sentence="1" />
      <mentions>
        <mention ids_tokens="21-22" string="the channel" id_sentence="15" />
      </mentions>
    </coreference>
    <coreference id="3" type="NOMINAL">
      <referenced ids_tokens="2-3" string="French workers" id_sentence="10" />
      <mentions>
        <mention ids_tokens="12-16" string="British and French workers digging" id_sentence="1" />
        <mention ids_tokens="10" string="our" id_sentence="3" />
        <mention ids_tokens="15" string="workers" id_sentence="19" />
      </mentions>
    </coreference>
    <coreference id="4" type="PROPER">
      <referenced ids_tokens="17-18-19" string="the Channel Tunnel" id_sentence="1" />
      <mentions>
        <mention ids_tokens="4-5" string="Channel Tunnel" id_sentence="14" />
        <mention ids_tokens="8" string="it" id_sentence="14" />
        <mention ids_tokens="23" string="it" id_sentence="14" />
        <mention ids_tokens="6-7" string="the tunnel" id_sentence="15" />
        <mention ids_tokens="1-2" string="The tunnel" id_sentence="29" />
        <mention ids_tokens="13-14" string="the tunnel" id_sentence="31" />
      </mentions>
    </coreference>
    <coreference id="5" type="NOMINAL">
      <referenced ids_tokens="25-26-27-28-29-30-31-32-33-34" string="a passage large enough to walk through and shake hands" id_sentence="1" />
      <mentions>
        <mention ids_tokens="3-4" string="the passage" id_sentence="22" />
      </mentions>
    </coreference>
    <coreference id="9" type="NOMINAL">
      <referenced ids_tokens="10-11-12" string="our two countries" id_sentence="3" />
      <mentions>
        <mention ids_tokens="15-16" string="their countries" id_sentence="21" />
      </mentions>
    </coreference>
    <coreference id="10" type="NOMINAL">
      <referenced ids_tokens="1-2" string="The breakthrough" id_sentence="4" />
      <mentions>
        <mention ids_tokens="1" string="It" id_sentence="5" />
      </mentions>
    </coreference>
    <coreference id="11" type="NOMINAL">
      <referenced ids_tokens="7-8-9-10-11" string="Europe 's biggest engineering project" id_sentence="5" />
      <mentions>
        <mention ids_tokens="7-8" string="the project" id_sentence="27" />
      </mentions>
    </coreference>
    <coreference id="12" type="PROPER">
      <referenced ids_tokens="4-5" string="Graham Fagg" id_sentence="6" />
      <mentions>
        <mention ids_tokens="1" string="Fagg" id_sentence="21" />
        <mention ids_tokens="6" string="Fagg" id_sentence="23" />
        <mention ids_tokens="1" string="Fagg" id_sentence="26" />
      </mentions>
    </coreference>
    <coreference id="13" type="PROPER">
      <referenced ids_tokens="15-16" string="Philippe Cozette" id_sentence="6" />
      <mentions>
        <mention ids_tokens="3" string="Cozette" id_sentence="21" />
        <mention ids_tokens="5" string="Cozette" id_sentence="24" />
        <mention ids_tokens="10" string="Cozette" id_sentence="26" />
      </mentions>
    </coreference>
    <coreference id="16" type="NOMINAL">
      <referenced ids_tokens="2" string="jackhammers" id_sentence="6" />
      <mentions>
        <mention ids_tokens="11" string="their" id_sentence="7" />
      </mentions>
    </coreference>
    <coreference id="17" type="PROPER">
      <referenced ids_tokens="4-5-6-7-8-9-10-11-12-13-14-15-16-17-18-19-20-21-22-23" string="Graham Fagg , 42 , of Dover , England , and Philippe Cozette , 37 , of Calais , France" id_sentence="6" />
      <mentions>
        <mention ids_tokens="1-3" string="Fagg and Cozette" id_sentence="21" />
        <mention ids_tokens="15" string="their" id_sentence="21" />
        <mention ids_tokens="15" string="they" id_sentence="22" />
        <mention ids_tokens="18" string="their" id_sentence="22" />
      </mentions>
    </coreference>
    <coreference id="20" type="NOMINAL">
      <referenced ids_tokens="1-2-3" string="Saturday 's handshake" id_sentence="13" />
      <mentions>
        <mention ids_tokens="25-26" string="the handshake" id_sentence="25" />
      </mentions>
    </coreference>
    <coreference id="22" type="PROPER">
      <referenced ids_tokens="4-5" string="Britain 's" id_sentence="20" />
      <mentions>
        <mention ids_tokens="2" string="Britain" id_sentence="30" />
        <mention ids_tokens="10" string="its" id_sentence="30" />
      </mentions>
    </coreference>
    <coreference id="23" type="PROPER">
      <referenced ids_tokens="1-2" string="Michel Delebarre" id_sentence="25" />
      <mentions>
        <mention ids_tokens="12" string="Delebarre" id_sentence="26" />
      </mentions>
    </coreference>
    <coreference id="24" type="PROPER">
      <referenced ids_tokens="4-5" string="Malcolm Rifkind" id_sentence="25" />
      <mentions>
        <mention ids_tokens="3" string="Rifkind" id_sentence="26" />
      </mentions>
    </coreference>
    <coreference id="25" type="LIST">
      <referenced ids_tokens="1-2-3-4-5-6-7-8-9-10-11-12" string="Michel Delebarre and Malcolm Rifkind , the French and British transportation ministers" id_sentence="25" />
      <mentions>
        <mention ids_tokens="10-12" string="Cozette and Delebarre" id_sentence="26" />
      </mentions>
    </coreference>
  </coreferences>
</document>
