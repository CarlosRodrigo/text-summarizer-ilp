<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="AP901031-0024">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>Workmen tunneling under the English Channel have created the first land link between Britain and the Continent, connecting 31 miles of tunnel in a prodigious feat of engineering and finance.</content>
      <tokens>
        <token id="1" string="Workmen" lemma="workmen" stem="workmen" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="tunneling" lemma="tunneling" stem="tunnel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="under" lemma="under" stem="under" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="English" lemma="English" stem="english" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="6" string="Channel" lemma="Channel" stem="channel" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="7" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="created" lemma="create" stem="creat" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="true" is_refers="false" />
        <token id="11" string="land" lemma="land" stem="land" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="link" lemma="link" stem="link" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="between" lemma="between" stem="between" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Britain" lemma="Britain" stem="britain" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Continent" lemma="continent" stem="contin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="connecting" lemma="connect" stem="connect" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="31" lemma="31" stem="31" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="21" string="miles" lemma="mile" stem="mile" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="23" string="tunnel" lemma="tunnel" stem="tunnel" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="prodigious" lemma="prodigious" stem="prodigi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="feat" lemma="feat" stem="feat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="engineering" lemma="engineering" stem="engin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="finance" lemma="finance" stem="financ" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (JJ Workmen) (NN tunneling)) (PP (IN under) (NP (DT the) (NNP English) (NNP Channel)))) (VP (VBP have) (VP (VBN created) (NP (NP (DT the) (JJ first) (NN land) (NN link)) (PP (IN between) (NP (NP (NNP Britain)) (CC and) (NP (DT the) (NN Continent))))) (, ,) (S (VP (VBG connecting) (NP (NP (CD 31) (NNS miles)) (PP (IN of) (NP (NN tunnel)))) (PP (IN in) (NP (NP (DT a) (JJ prodigious) (NN feat)) (PP (IN of) (NP (NN engineering) (CC and) (NN finance))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="31 miles" type="NP">
          <tokens>
            <token id="20" string="31" />
            <token id="21" string="miles" />
          </tokens>
        </chunking>
        <chunking id="2" string="Workmen tunneling under the English Channel" type="NP">
          <tokens>
            <token id="1" string="Workmen" />
            <token id="2" string="tunneling" />
            <token id="3" string="under" />
            <token id="4" string="the" />
            <token id="5" string="English" />
            <token id="6" string="Channel" />
          </tokens>
        </chunking>
        <chunking id="3" string="the first land link" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="first" />
            <token id="11" string="land" />
            <token id="12" string="link" />
          </tokens>
        </chunking>
        <chunking id="4" string="engineering and finance" type="NP">
          <tokens>
            <token id="29" string="engineering" />
            <token id="30" string="and" />
            <token id="31" string="finance" />
          </tokens>
        </chunking>
        <chunking id="5" string="Britain" type="NP">
          <tokens>
            <token id="14" string="Britain" />
          </tokens>
        </chunking>
        <chunking id="6" string="a prodigious feat of engineering and finance" type="NP">
          <tokens>
            <token id="25" string="a" />
            <token id="26" string="prodigious" />
            <token id="27" string="feat" />
            <token id="28" string="of" />
            <token id="29" string="engineering" />
            <token id="30" string="and" />
            <token id="31" string="finance" />
          </tokens>
        </chunking>
        <chunking id="7" string="31 miles of tunnel" type="NP">
          <tokens>
            <token id="20" string="31" />
            <token id="21" string="miles" />
            <token id="22" string="of" />
            <token id="23" string="tunnel" />
          </tokens>
        </chunking>
        <chunking id="8" string="connecting 31 miles of tunnel in a prodigious feat of engineering and finance" type="VP">
          <tokens>
            <token id="19" string="connecting" />
            <token id="20" string="31" />
            <token id="21" string="miles" />
            <token id="22" string="of" />
            <token id="23" string="tunnel" />
            <token id="24" string="in" />
            <token id="25" string="a" />
            <token id="26" string="prodigious" />
            <token id="27" string="feat" />
            <token id="28" string="of" />
            <token id="29" string="engineering" />
            <token id="30" string="and" />
            <token id="31" string="finance" />
          </tokens>
        </chunking>
        <chunking id="9" string="tunnel" type="NP">
          <tokens>
            <token id="23" string="tunnel" />
          </tokens>
        </chunking>
        <chunking id="10" string="created the first land link between Britain and the Continent , connecting 31 miles of tunnel in a prodigious feat of engineering and finance" type="VP">
          <tokens>
            <token id="8" string="created" />
            <token id="9" string="the" />
            <token id="10" string="first" />
            <token id="11" string="land" />
            <token id="12" string="link" />
            <token id="13" string="between" />
            <token id="14" string="Britain" />
            <token id="15" string="and" />
            <token id="16" string="the" />
            <token id="17" string="Continent" />
            <token id="18" string="," />
            <token id="19" string="connecting" />
            <token id="20" string="31" />
            <token id="21" string="miles" />
            <token id="22" string="of" />
            <token id="23" string="tunnel" />
            <token id="24" string="in" />
            <token id="25" string="a" />
            <token id="26" string="prodigious" />
            <token id="27" string="feat" />
            <token id="28" string="of" />
            <token id="29" string="engineering" />
            <token id="30" string="and" />
            <token id="31" string="finance" />
          </tokens>
        </chunking>
        <chunking id="11" string="the first land link between Britain and the Continent" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="first" />
            <token id="11" string="land" />
            <token id="12" string="link" />
            <token id="13" string="between" />
            <token id="14" string="Britain" />
            <token id="15" string="and" />
            <token id="16" string="the" />
            <token id="17" string="Continent" />
          </tokens>
        </chunking>
        <chunking id="12" string="Britain and the Continent" type="NP">
          <tokens>
            <token id="14" string="Britain" />
            <token id="15" string="and" />
            <token id="16" string="the" />
            <token id="17" string="Continent" />
          </tokens>
        </chunking>
        <chunking id="13" string="the English Channel" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="English" />
            <token id="6" string="Channel" />
          </tokens>
        </chunking>
        <chunking id="14" string="have created the first land link between Britain and the Continent , connecting 31 miles of tunnel in a prodigious feat of engineering and finance" type="VP">
          <tokens>
            <token id="7" string="have" />
            <token id="8" string="created" />
            <token id="9" string="the" />
            <token id="10" string="first" />
            <token id="11" string="land" />
            <token id="12" string="link" />
            <token id="13" string="between" />
            <token id="14" string="Britain" />
            <token id="15" string="and" />
            <token id="16" string="the" />
            <token id="17" string="Continent" />
            <token id="18" string="," />
            <token id="19" string="connecting" />
            <token id="20" string="31" />
            <token id="21" string="miles" />
            <token id="22" string="of" />
            <token id="23" string="tunnel" />
            <token id="24" string="in" />
            <token id="25" string="a" />
            <token id="26" string="prodigious" />
            <token id="27" string="feat" />
            <token id="28" string="of" />
            <token id="29" string="engineering" />
            <token id="30" string="and" />
            <token id="31" string="finance" />
          </tokens>
        </chunking>
        <chunking id="15" string="Workmen tunneling" type="NP">
          <tokens>
            <token id="1" string="Workmen" />
            <token id="2" string="tunneling" />
          </tokens>
        </chunking>
        <chunking id="16" string="the Continent" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="Continent" />
          </tokens>
        </chunking>
        <chunking id="17" string="a prodigious feat" type="NP">
          <tokens>
            <token id="25" string="a" />
            <token id="26" string="prodigious" />
            <token id="27" string="feat" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="2">tunneling</governor>
          <dependent id="1">Workmen</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">created</governor>
          <dependent id="2">tunneling</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">Channel</governor>
          <dependent id="3">under</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">Channel</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Channel</governor>
          <dependent id="5">English</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">tunneling</governor>
          <dependent id="6">Channel</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">created</governor>
          <dependent id="7">have</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">created</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">link</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">link</governor>
          <dependent id="10">first</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">link</governor>
          <dependent id="11">land</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">created</governor>
          <dependent id="12">link</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">Britain</governor>
          <dependent id="13">between</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">link</governor>
          <dependent id="14">Britain</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="14">Britain</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">Continent</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">Britain</governor>
          <dependent id="17">Continent</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="8">created</governor>
          <dependent id="19">connecting</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="21">miles</governor>
          <dependent id="20">31</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">connecting</governor>
          <dependent id="21">miles</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">tunnel</governor>
          <dependent id="22">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">miles</governor>
          <dependent id="23">tunnel</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">feat</governor>
          <dependent id="24">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">feat</governor>
          <dependent id="25">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="27">feat</governor>
          <dependent id="26">prodigious</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">connecting</governor>
          <dependent id="27">feat</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">engineering</governor>
          <dependent id="28">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">feat</governor>
          <dependent id="29">engineering</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="29">engineering</governor>
          <dependent id="30">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="29">engineering</governor>
          <dependent id="31">finance</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="10" string="first" />
          </tokens>
        </entity>
        <entity id="2" string="English Channel" type="MISC" score="0.0">
          <tokens>
            <token id="5" string="English" />
            <token id="6" string="Channel" />
          </tokens>
        </entity>
        <entity id="3" string="Britain" type="LOCATION" score="0.0">
          <tokens>
            <token id="14" string="Britain" />
          </tokens>
        </entity>
        <entity id="4" string="31" type="NUMBER" score="0.0">
          <tokens>
            <token id="20" string="31" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>TransManche Link, the construction consortium building the ``Chunnel&amp;apost;&amp;apost; said the historic linkup occurred at 8:25 p.m. Tuesday when British workers sent a probe 2 inches in diameter through to their French colleagues.</content>
      <tokens>
        <token id="1" string="TransManche" lemma="TransManche" stem="transmanch" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="Link" lemma="Link" stem="link" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="construction" lemma="construction" stem="construct" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="consortium" lemma="consortium" stem="consortium" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="building" lemma="build" stem="build" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Chunnel" lemma="Chunnel" stem="chunnel" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="historic" lemma="historic" stem="histor" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="linkup" lemma="linkup" stem="linkup" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="occurred" lemma="occur" stem="occur" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="8:25" lemma="8:25" stem="8:25" pos="CD" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="19" string="p.m." lemma="p.m." stem="p.m." pos="NN" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="20" string="Tuesday" lemma="Tuesday" stem="tuesdai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="21" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="British" lemma="british" stem="british" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="true" is_refers="false" />
        <token id="23" string="workers" lemma="worker" stem="worker" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="sent" lemma="send" stem="sent" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="probe" lemma="probe" stem="probe" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="2" lemma="2" stem="2" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="28" string="inches" lemma="inch" stem="inch" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="diameter" lemma="diameter" stem="diamet" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="French" lemma="french" stem="french" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="35" string="colleagues" lemma="colleague" stem="colleagu" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP TransManche) (NNP Link)) (, ,) (NP (NP (DT the) (NN construction) (NN consortium)) (VP (VBG building) (NP (DT the) (`` ``) (NNP Chunnel) ('' ''))))) (VP (VBD said) (SBAR (S (NP (DT the) (JJ historic) (NN linkup)) (VP (VBD occurred) (PP (IN at) (NP (CD 8:25) (NN p.m.))) (NP-TMP (NNP Tuesday)) (SBAR (WHADVP (WRB when)) (S (NP (JJ British) (NNS workers)) (VP (VBD sent) (NP (DT a) (NN probe)) (NP (NP (CD 2) (NNS inches)) (PP (IN in) (NP (NN diameter)))) (PP (IN through) (PP (TO to) (NP (PRP$ their) (JJ French) (NNS colleagues))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="British workers" type="NP">
          <tokens>
            <token id="22" string="British" />
            <token id="23" string="workers" />
          </tokens>
        </chunking>
        <chunking id="2" string="8:25 p.m." type="NP">
          <tokens>
            <token id="18" string="8:25" />
            <token id="19" string="p.m." />
          </tokens>
        </chunking>
        <chunking id="3" string="the historic linkup occurred at 8:25 p.m. Tuesday when British workers sent a probe 2 inches in diameter through to their French colleagues" type="SBAR">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="historic" />
            <token id="15" string="linkup" />
            <token id="16" string="occurred" />
            <token id="17" string="at" />
            <token id="18" string="8:25" />
            <token id="19" string="p.m." />
            <token id="20" string="Tuesday" />
            <token id="21" string="when" />
            <token id="22" string="British" />
            <token id="23" string="workers" />
            <token id="24" string="sent" />
            <token id="25" string="a" />
            <token id="26" string="probe" />
            <token id="27" string="2" />
            <token id="28" string="inches" />
            <token id="29" string="in" />
            <token id="30" string="diameter" />
            <token id="31" string="through" />
            <token id="32" string="to" />
            <token id="33" string="their" />
            <token id="34" string="French" />
            <token id="35" string="colleagues" />
          </tokens>
        </chunking>
        <chunking id="4" string="TransManche Link , the construction consortium building the `` Chunnel ''" type="NP">
          <tokens>
            <token id="1" string="TransManche" />
            <token id="2" string="Link" />
            <token id="3" string="," />
            <token id="4" string="the" />
            <token id="5" string="construction" />
            <token id="6" string="consortium" />
            <token id="7" string="building" />
            <token id="8" string="the" />
            <token id="9" string="``" />
            <token id="10" string="Chunnel" />
            <token id="11" string="''" />
          </tokens>
        </chunking>
        <chunking id="5" string="the historic linkup" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="historic" />
            <token id="15" string="linkup" />
          </tokens>
        </chunking>
        <chunking id="6" string="a probe" type="NP">
          <tokens>
            <token id="25" string="a" />
            <token id="26" string="probe" />
          </tokens>
        </chunking>
        <chunking id="7" string="their French colleagues" type="NP">
          <tokens>
            <token id="33" string="their" />
            <token id="34" string="French" />
            <token id="35" string="colleagues" />
          </tokens>
        </chunking>
        <chunking id="8" string="the construction consortium building the `` Chunnel ''" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="construction" />
            <token id="6" string="consortium" />
            <token id="7" string="building" />
            <token id="8" string="the" />
            <token id="9" string="``" />
            <token id="10" string="Chunnel" />
            <token id="11" string="''" />
          </tokens>
        </chunking>
        <chunking id="9" string="when" type="WHADVP">
          <tokens>
            <token id="21" string="when" />
          </tokens>
        </chunking>
        <chunking id="10" string="2 inches" type="NP">
          <tokens>
            <token id="27" string="2" />
            <token id="28" string="inches" />
          </tokens>
        </chunking>
        <chunking id="11" string="said the historic linkup occurred at 8:25 p.m. Tuesday when British workers sent a probe 2 inches in diameter through to their French colleagues" type="VP">
          <tokens>
            <token id="12" string="said" />
            <token id="13" string="the" />
            <token id="14" string="historic" />
            <token id="15" string="linkup" />
            <token id="16" string="occurred" />
            <token id="17" string="at" />
            <token id="18" string="8:25" />
            <token id="19" string="p.m." />
            <token id="20" string="Tuesday" />
            <token id="21" string="when" />
            <token id="22" string="British" />
            <token id="23" string="workers" />
            <token id="24" string="sent" />
            <token id="25" string="a" />
            <token id="26" string="probe" />
            <token id="27" string="2" />
            <token id="28" string="inches" />
            <token id="29" string="in" />
            <token id="30" string="diameter" />
            <token id="31" string="through" />
            <token id="32" string="to" />
            <token id="33" string="their" />
            <token id="34" string="French" />
            <token id="35" string="colleagues" />
          </tokens>
        </chunking>
        <chunking id="12" string="when British workers sent a probe 2 inches in diameter through to their French colleagues" type="SBAR">
          <tokens>
            <token id="21" string="when" />
            <token id="22" string="British" />
            <token id="23" string="workers" />
            <token id="24" string="sent" />
            <token id="25" string="a" />
            <token id="26" string="probe" />
            <token id="27" string="2" />
            <token id="28" string="inches" />
            <token id="29" string="in" />
            <token id="30" string="diameter" />
            <token id="31" string="through" />
            <token id="32" string="to" />
            <token id="33" string="their" />
            <token id="34" string="French" />
            <token id="35" string="colleagues" />
          </tokens>
        </chunking>
        <chunking id="13" string="diameter" type="NP">
          <tokens>
            <token id="30" string="diameter" />
          </tokens>
        </chunking>
        <chunking id="14" string="2 inches in diameter" type="NP">
          <tokens>
            <token id="27" string="2" />
            <token id="28" string="inches" />
            <token id="29" string="in" />
            <token id="30" string="diameter" />
          </tokens>
        </chunking>
        <chunking id="15" string="the `` Chunnel ''" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="``" />
            <token id="10" string="Chunnel" />
            <token id="11" string="''" />
          </tokens>
        </chunking>
        <chunking id="16" string="the construction consortium" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="construction" />
            <token id="6" string="consortium" />
          </tokens>
        </chunking>
        <chunking id="17" string="occurred at 8:25 p.m. Tuesday when British workers sent a probe 2 inches in diameter through to their French colleagues" type="VP">
          <tokens>
            <token id="16" string="occurred" />
            <token id="17" string="at" />
            <token id="18" string="8:25" />
            <token id="19" string="p.m." />
            <token id="20" string="Tuesday" />
            <token id="21" string="when" />
            <token id="22" string="British" />
            <token id="23" string="workers" />
            <token id="24" string="sent" />
            <token id="25" string="a" />
            <token id="26" string="probe" />
            <token id="27" string="2" />
            <token id="28" string="inches" />
            <token id="29" string="in" />
            <token id="30" string="diameter" />
            <token id="31" string="through" />
            <token id="32" string="to" />
            <token id="33" string="their" />
            <token id="34" string="French" />
            <token id="35" string="colleagues" />
          </tokens>
        </chunking>
        <chunking id="18" string="sent a probe 2 inches in diameter through to their French colleagues" type="VP">
          <tokens>
            <token id="24" string="sent" />
            <token id="25" string="a" />
            <token id="26" string="probe" />
            <token id="27" string="2" />
            <token id="28" string="inches" />
            <token id="29" string="in" />
            <token id="30" string="diameter" />
            <token id="31" string="through" />
            <token id="32" string="to" />
            <token id="33" string="their" />
            <token id="34" string="French" />
            <token id="35" string="colleagues" />
          </tokens>
        </chunking>
        <chunking id="19" string="TransManche Link" type="NP">
          <tokens>
            <token id="1" string="TransManche" />
            <token id="2" string="Link" />
          </tokens>
        </chunking>
        <chunking id="20" string="building the `` Chunnel ''" type="VP">
          <tokens>
            <token id="7" string="building" />
            <token id="8" string="the" />
            <token id="9" string="``" />
            <token id="10" string="Chunnel" />
            <token id="11" string="''" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Link</governor>
          <dependent id="1">TransManche</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">said</governor>
          <dependent id="2">Link</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">consortium</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">consortium</governor>
          <dependent id="5">construction</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="2">Link</governor>
          <dependent id="6">consortium</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="6">consortium</governor>
          <dependent id="7">building</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">Chunnel</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">building</governor>
          <dependent id="10">Chunnel</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">said</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">linkup</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">linkup</governor>
          <dependent id="14">historic</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">occurred</governor>
          <dependent id="15">linkup</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="12">said</governor>
          <dependent id="16">occurred</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">p.m.</governor>
          <dependent id="17">at</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="19">p.m.</governor>
          <dependent id="18">8:25</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">occurred</governor>
          <dependent id="19">p.m.</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="16">occurred</governor>
          <dependent id="20">Tuesday</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="24">sent</governor>
          <dependent id="21">when</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">workers</governor>
          <dependent id="22">British</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">sent</governor>
          <dependent id="23">workers</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="16">occurred</governor>
          <dependent id="24">sent</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">probe</governor>
          <dependent id="25">a</dependent>
        </dependency>
        <dependency type="iobj">
          <governor id="24">sent</governor>
          <dependent id="26">probe</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="28">inches</governor>
          <dependent id="27">2</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="24">sent</governor>
          <dependent id="28">inches</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">diameter</governor>
          <dependent id="29">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">inches</governor>
          <dependent id="30">diameter</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">colleagues</governor>
          <dependent id="31">through</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">colleagues</governor>
          <dependent id="32">to</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="35">colleagues</governor>
          <dependent id="33">their</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="35">colleagues</governor>
          <dependent id="34">French</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">sent</governor>
          <dependent id="35">colleagues</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="French" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="34" string="French" />
          </tokens>
        </entity>
        <entity id="2" string="2" type="NUMBER" score="0.0">
          <tokens>
            <token id="27" string="2" />
          </tokens>
        </entity>
        <entity id="3" string="8:25 p.m." type="TIME" score="0.0">
          <tokens>
            <token id="18" string="8:25" />
            <token id="19" string="p.m." />
          </tokens>
        </entity>
        <entity id="4" string="British" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="22" string="British" />
          </tokens>
        </entity>
        <entity id="5" string="Tuesday" type="DATE" score="0.0">
          <tokens>
            <token id="20" string="Tuesday" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>Linking England and France, the tunnel symbolizes the growing unification of Europe.</content>
      <tokens>
        <token id="1" string="Linking" lemma="link" stem="link" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="England" lemma="England" stem="england" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="3" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="France" lemma="France" stem="franc" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="tunnel" lemma="tunnel" stem="tunnel" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="symbolizes" lemma="symbolize" stem="symbol" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="growing" lemma="grow" stem="grow" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="unification" lemma="unification" stem="unif" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Europe" lemma="Europe" stem="europ" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (VBG Linking) (NP (NNP England) (CC and) (NNP France)))) (, ,) (NP (DT the) (NN tunnel)) (VP (VBZ symbolizes) (NP (NP (DT the) (VBG growing) (NN unification)) (PP (IN of) (NP (NNP Europe))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Europe" type="NP">
          <tokens>
            <token id="13" string="Europe" />
          </tokens>
        </chunking>
        <chunking id="2" string="the growing unification of Europe" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="growing" />
            <token id="11" string="unification" />
            <token id="12" string="of" />
            <token id="13" string="Europe" />
          </tokens>
        </chunking>
        <chunking id="3" string="Linking England and France" type="VP">
          <tokens>
            <token id="1" string="Linking" />
            <token id="2" string="England" />
            <token id="3" string="and" />
            <token id="4" string="France" />
          </tokens>
        </chunking>
        <chunking id="4" string="England and France" type="NP">
          <tokens>
            <token id="2" string="England" />
            <token id="3" string="and" />
            <token id="4" string="France" />
          </tokens>
        </chunking>
        <chunking id="5" string="the growing unification" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="growing" />
            <token id="11" string="unification" />
          </tokens>
        </chunking>
        <chunking id="6" string="the tunnel" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="tunnel" />
          </tokens>
        </chunking>
        <chunking id="7" string="symbolizes the growing unification of Europe" type="VP">
          <tokens>
            <token id="8" string="symbolizes" />
            <token id="9" string="the" />
            <token id="10" string="growing" />
            <token id="11" string="unification" />
            <token id="12" string="of" />
            <token id="13" string="Europe" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advcl">
          <governor id="8">symbolizes</governor>
          <dependent id="1">Linking</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="1">Linking</governor>
          <dependent id="2">England</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">England</governor>
          <dependent id="3">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">England</governor>
          <dependent id="4">France</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">tunnel</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">symbolizes</governor>
          <dependent id="7">tunnel</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">symbolizes</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">unification</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">unification</governor>
          <dependent id="10">growing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">symbolizes</governor>
          <dependent id="11">unification</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Europe</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">unification</governor>
          <dependent id="13">Europe</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Europe" type="LOCATION" score="0.0">
          <tokens>
            <token id="13" string="Europe" />
          </tokens>
        </entity>
        <entity id="2" string="England" type="LOCATION" score="0.0">
          <tokens>
            <token id="2" string="England" />
          </tokens>
        </entity>
        <entity id="3" string="France" type="LOCATION" score="0.0">
          <tokens>
            <token id="4" string="France" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>It also fulfills a dream of Napoleon, who wanted to send his armies through the tunnel to conquer Britain.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="fulfills" lemma="fulfil" stem="fulfil" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="dream" lemma="dream" stem="dream" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Napoleon" lemma="Napoleon" stem="napoleon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="wanted" lemma="want" stem="want" pos="VBD" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="send" lemma="send" stem="send" pos="VB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="armies" lemma="army" stem="armi" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="tunnel" lemma="tunnel" stem="tunnel" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="conquer" lemma="conquer" stem="conquer" pos="VB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="Britain" lemma="Britain" stem="britain" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP It)) (ADVP (RB also)) (VP (VBZ fulfills) (NP (NP (DT a) (NN dream)) (PP (IN of) (NP (NP (NNP Napoleon)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBD wanted) (S (VP (TO to) (VP (VB send) (NP (PRP$ his) (NNS armies)) (PP (IN through) (NP (DT the) (NN tunnel) (S (VP (TO to) (VP (VB conquer) (NP (NNP Britain))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="to conquer Britain" type="VP">
          <tokens>
            <token id="18" string="to" />
            <token id="19" string="conquer" />
            <token id="20" string="Britain" />
          </tokens>
        </chunking>
        <chunking id="2" string="who wanted to send his armies through the tunnel to conquer Britain" type="SBAR">
          <tokens>
            <token id="9" string="who" />
            <token id="10" string="wanted" />
            <token id="11" string="to" />
            <token id="12" string="send" />
            <token id="13" string="his" />
            <token id="14" string="armies" />
            <token id="15" string="through" />
            <token id="16" string="the" />
            <token id="17" string="tunnel" />
            <token id="18" string="to" />
            <token id="19" string="conquer" />
            <token id="20" string="Britain" />
          </tokens>
        </chunking>
        <chunking id="3" string="the tunnel to conquer Britain" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="tunnel" />
            <token id="18" string="to" />
            <token id="19" string="conquer" />
            <token id="20" string="Britain" />
          </tokens>
        </chunking>
        <chunking id="4" string="conquer Britain" type="VP">
          <tokens>
            <token id="19" string="conquer" />
            <token id="20" string="Britain" />
          </tokens>
        </chunking>
        <chunking id="5" string="fulfills a dream of Napoleon , who wanted to send his armies through the tunnel to conquer Britain" type="VP">
          <tokens>
            <token id="3" string="fulfills" />
            <token id="4" string="a" />
            <token id="5" string="dream" />
            <token id="6" string="of" />
            <token id="7" string="Napoleon" />
            <token id="8" string="," />
            <token id="9" string="who" />
            <token id="10" string="wanted" />
            <token id="11" string="to" />
            <token id="12" string="send" />
            <token id="13" string="his" />
            <token id="14" string="armies" />
            <token id="15" string="through" />
            <token id="16" string="the" />
            <token id="17" string="tunnel" />
            <token id="18" string="to" />
            <token id="19" string="conquer" />
            <token id="20" string="Britain" />
          </tokens>
        </chunking>
        <chunking id="6" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="7" string="Britain" type="NP">
          <tokens>
            <token id="20" string="Britain" />
          </tokens>
        </chunking>
        <chunking id="8" string="Napoleon" type="NP">
          <tokens>
            <token id="7" string="Napoleon" />
          </tokens>
        </chunking>
        <chunking id="9" string="a dream" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="dream" />
          </tokens>
        </chunking>
        <chunking id="10" string="Napoleon , who wanted to send his armies through the tunnel to conquer Britain" type="NP">
          <tokens>
            <token id="7" string="Napoleon" />
            <token id="8" string="," />
            <token id="9" string="who" />
            <token id="10" string="wanted" />
            <token id="11" string="to" />
            <token id="12" string="send" />
            <token id="13" string="his" />
            <token id="14" string="armies" />
            <token id="15" string="through" />
            <token id="16" string="the" />
            <token id="17" string="tunnel" />
            <token id="18" string="to" />
            <token id="19" string="conquer" />
            <token id="20" string="Britain" />
          </tokens>
        </chunking>
        <chunking id="11" string="to send his armies through the tunnel to conquer Britain" type="VP">
          <tokens>
            <token id="11" string="to" />
            <token id="12" string="send" />
            <token id="13" string="his" />
            <token id="14" string="armies" />
            <token id="15" string="through" />
            <token id="16" string="the" />
            <token id="17" string="tunnel" />
            <token id="18" string="to" />
            <token id="19" string="conquer" />
            <token id="20" string="Britain" />
          </tokens>
        </chunking>
        <chunking id="12" string="send his armies through the tunnel to conquer Britain" type="VP">
          <tokens>
            <token id="12" string="send" />
            <token id="13" string="his" />
            <token id="14" string="armies" />
            <token id="15" string="through" />
            <token id="16" string="the" />
            <token id="17" string="tunnel" />
            <token id="18" string="to" />
            <token id="19" string="conquer" />
            <token id="20" string="Britain" />
          </tokens>
        </chunking>
        <chunking id="13" string="a dream of Napoleon , who wanted to send his armies through the tunnel to conquer Britain" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="dream" />
            <token id="6" string="of" />
            <token id="7" string="Napoleon" />
            <token id="8" string="," />
            <token id="9" string="who" />
            <token id="10" string="wanted" />
            <token id="11" string="to" />
            <token id="12" string="send" />
            <token id="13" string="his" />
            <token id="14" string="armies" />
            <token id="15" string="through" />
            <token id="16" string="the" />
            <token id="17" string="tunnel" />
            <token id="18" string="to" />
            <token id="19" string="conquer" />
            <token id="20" string="Britain" />
          </tokens>
        </chunking>
        <chunking id="14" string="his armies" type="NP">
          <tokens>
            <token id="13" string="his" />
            <token id="14" string="armies" />
          </tokens>
        </chunking>
        <chunking id="15" string="wanted to send his armies through the tunnel to conquer Britain" type="VP">
          <tokens>
            <token id="10" string="wanted" />
            <token id="11" string="to" />
            <token id="12" string="send" />
            <token id="13" string="his" />
            <token id="14" string="armies" />
            <token id="15" string="through" />
            <token id="16" string="the" />
            <token id="17" string="tunnel" />
            <token id="18" string="to" />
            <token id="19" string="conquer" />
            <token id="20" string="Britain" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">fulfills</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">fulfills</governor>
          <dependent id="2">also</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">fulfills</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">dream</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">fulfills</governor>
          <dependent id="5">dream</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">Napoleon</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">dream</governor>
          <dependent id="7">Napoleon</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">wanted</governor>
          <dependent id="9">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="7">Napoleon</governor>
          <dependent id="10">wanted</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">send</governor>
          <dependent id="11">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="10">wanted</governor>
          <dependent id="12">send</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="14">armies</governor>
          <dependent id="13">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">send</governor>
          <dependent id="14">armies</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">tunnel</governor>
          <dependent id="15">through</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">tunnel</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">send</governor>
          <dependent id="17">tunnel</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">conquer</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="17">tunnel</governor>
          <dependent id="19">conquer</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">conquer</governor>
          <dependent id="20">Britain</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Britain" type="LOCATION" score="0.0">
          <tokens>
            <token id="20" string="Britain" />
          </tokens>
        </entity>
        <entity id="2" string="Napoleon" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Napoleon" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>Eurotunnel PLC, the Anglo-French consortium overseeing the world&amp;apost;s largest engineering project, plans for high-speed trains to pass through the Channel Tunnel in June 1993.</content>
      <tokens>
        <token id="1" string="Eurotunnel" lemma="Eurotunnel" stem="eurotunnel" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="2" string="PLC" lemma="PLC" stem="plc" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Anglo-French" lemma="anglo-french" stem="anglo-french" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="6" string="consortium" lemma="consortium" stem="consortium" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="overseeing" lemma="oversee" stem="overse" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="largest" lemma="largest" stem="largest" pos="JJS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="engineering" lemma="engineering" stem="engin" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="project" lemma="project" stem="project" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="plans" lemma="plan" stem="plan" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="high-speed" lemma="high-speed" stem="high-spe" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="trains" lemma="train" stem="train" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="pass" lemma="pass" stem="pass" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="Channel" lemma="Channel" stem="channel" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="24" string="Tunnel" lemma="tunnel" stem="tunnel" pos="NN" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="25" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="June" lemma="June" stem="june" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="27" string="1993" lemma="1993" stem="1993" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (NP (NP (NNP Eurotunnel) (NNP PLC)) (, ,) (NP (NP (DT the) (JJ Anglo-French) (NN consortium)) (VP (VBG overseeing) (NP (NP (NP (DT the) (NN world) (POS 's)) (JJS largest) (NN engineering) (NN project)) (, ,) (NP (NP (NNS plans)) (PP (IN for) (NP (JJ high-speed) (NNS trains))))) (S (VP (TO to) (VP (VB pass) (PP (IN through) (NP (DT the) (NNP Channel) (NN Tunnel))) (PP (IN in) (NP (NNP June) (CD 1993)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="overseeing the world 's largest engineering project , plans for high-speed trains to pass through the Channel Tunnel in June 1993" type="VP">
          <tokens>
            <token id="7" string="overseeing" />
            <token id="8" string="the" />
            <token id="9" string="world" />
            <token id="10" string="'s" />
            <token id="11" string="largest" />
            <token id="12" string="engineering" />
            <token id="13" string="project" />
            <token id="14" string="," />
            <token id="15" string="plans" />
            <token id="16" string="for" />
            <token id="17" string="high-speed" />
            <token id="18" string="trains" />
            <token id="19" string="to" />
            <token id="20" string="pass" />
            <token id="21" string="through" />
            <token id="22" string="the" />
            <token id="23" string="Channel" />
            <token id="24" string="Tunnel" />
            <token id="25" string="in" />
            <token id="26" string="June" />
            <token id="27" string="1993" />
          </tokens>
        </chunking>
        <chunking id="2" string="the Anglo-French consortium" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="Anglo-French" />
            <token id="6" string="consortium" />
          </tokens>
        </chunking>
        <chunking id="3" string="the world 's largest engineering project" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="world" />
            <token id="10" string="'s" />
            <token id="11" string="largest" />
            <token id="12" string="engineering" />
            <token id="13" string="project" />
          </tokens>
        </chunking>
        <chunking id="4" string="pass through the Channel Tunnel in June 1993" type="VP">
          <tokens>
            <token id="20" string="pass" />
            <token id="21" string="through" />
            <token id="22" string="the" />
            <token id="23" string="Channel" />
            <token id="24" string="Tunnel" />
            <token id="25" string="in" />
            <token id="26" string="June" />
            <token id="27" string="1993" />
          </tokens>
        </chunking>
        <chunking id="5" string="to pass through the Channel Tunnel in June 1993" type="VP">
          <tokens>
            <token id="19" string="to" />
            <token id="20" string="pass" />
            <token id="21" string="through" />
            <token id="22" string="the" />
            <token id="23" string="Channel" />
            <token id="24" string="Tunnel" />
            <token id="25" string="in" />
            <token id="26" string="June" />
            <token id="27" string="1993" />
          </tokens>
        </chunking>
        <chunking id="6" string="the world 's largest engineering project , plans for high-speed trains" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="world" />
            <token id="10" string="'s" />
            <token id="11" string="largest" />
            <token id="12" string="engineering" />
            <token id="13" string="project" />
            <token id="14" string="," />
            <token id="15" string="plans" />
            <token id="16" string="for" />
            <token id="17" string="high-speed" />
            <token id="18" string="trains" />
          </tokens>
        </chunking>
        <chunking id="7" string="June 1993" type="NP">
          <tokens>
            <token id="26" string="June" />
            <token id="27" string="1993" />
          </tokens>
        </chunking>
        <chunking id="8" string="plans for high-speed trains" type="NP">
          <tokens>
            <token id="15" string="plans" />
            <token id="16" string="for" />
            <token id="17" string="high-speed" />
            <token id="18" string="trains" />
          </tokens>
        </chunking>
        <chunking id="9" string="the Channel Tunnel" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="Channel" />
            <token id="24" string="Tunnel" />
          </tokens>
        </chunking>
        <chunking id="10" string="the Anglo-French consortium overseeing the world 's largest engineering project , plans for high-speed trains to pass through the Channel Tunnel in June 1993" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="Anglo-French" />
            <token id="6" string="consortium" />
            <token id="7" string="overseeing" />
            <token id="8" string="the" />
            <token id="9" string="world" />
            <token id="10" string="'s" />
            <token id="11" string="largest" />
            <token id="12" string="engineering" />
            <token id="13" string="project" />
            <token id="14" string="," />
            <token id="15" string="plans" />
            <token id="16" string="for" />
            <token id="17" string="high-speed" />
            <token id="18" string="trains" />
            <token id="19" string="to" />
            <token id="20" string="pass" />
            <token id="21" string="through" />
            <token id="22" string="the" />
            <token id="23" string="Channel" />
            <token id="24" string="Tunnel" />
            <token id="25" string="in" />
            <token id="26" string="June" />
            <token id="27" string="1993" />
          </tokens>
        </chunking>
        <chunking id="11" string="plans" type="NP">
          <tokens>
            <token id="15" string="plans" />
          </tokens>
        </chunking>
        <chunking id="12" string="high-speed trains" type="NP">
          <tokens>
            <token id="17" string="high-speed" />
            <token id="18" string="trains" />
          </tokens>
        </chunking>
        <chunking id="13" string="Eurotunnel PLC , the Anglo-French consortium overseeing the world 's largest engineering project , plans for high-speed trains to pass through the Channel Tunnel in June 1993 ." type="NP">
          <tokens>
            <token id="1" string="Eurotunnel" />
            <token id="2" string="PLC" />
            <token id="3" string="," />
            <token id="4" string="the" />
            <token id="5" string="Anglo-French" />
            <token id="6" string="consortium" />
            <token id="7" string="overseeing" />
            <token id="8" string="the" />
            <token id="9" string="world" />
            <token id="10" string="'s" />
            <token id="11" string="largest" />
            <token id="12" string="engineering" />
            <token id="13" string="project" />
            <token id="14" string="," />
            <token id="15" string="plans" />
            <token id="16" string="for" />
            <token id="17" string="high-speed" />
            <token id="18" string="trains" />
            <token id="19" string="to" />
            <token id="20" string="pass" />
            <token id="21" string="through" />
            <token id="22" string="the" />
            <token id="23" string="Channel" />
            <token id="24" string="Tunnel" />
            <token id="25" string="in" />
            <token id="26" string="June" />
            <token id="27" string="1993" />
            <token id="28" string="." />
          </tokens>
        </chunking>
        <chunking id="14" string="Eurotunnel PLC" type="NP">
          <tokens>
            <token id="1" string="Eurotunnel" />
            <token id="2" string="PLC" />
          </tokens>
        </chunking>
        <chunking id="15" string="the world 's" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="world" />
            <token id="10" string="'s" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">PLC</governor>
          <dependent id="1">Eurotunnel</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">PLC</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">consortium</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">consortium</governor>
          <dependent id="5">Anglo-French</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="2">PLC</governor>
          <dependent id="6">consortium</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="6">consortium</governor>
          <dependent id="7">overseeing</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">world</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="13">project</governor>
          <dependent id="9">world</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">world</governor>
          <dependent id="10">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">project</governor>
          <dependent id="11">largest</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">project</governor>
          <dependent id="12">engineering</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">overseeing</governor>
          <dependent id="13">project</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="13">project</governor>
          <dependent id="15">plans</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">trains</governor>
          <dependent id="16">for</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">trains</governor>
          <dependent id="17">high-speed</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">plans</governor>
          <dependent id="18">trains</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="20">pass</governor>
          <dependent id="19">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="7">overseeing</governor>
          <dependent id="20">pass</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">Tunnel</governor>
          <dependent id="21">through</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">Tunnel</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">Tunnel</governor>
          <dependent id="23">Channel</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">pass</governor>
          <dependent id="24">Tunnel</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">June</governor>
          <dependent id="25">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">pass</governor>
          <dependent id="26">June</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="26">June</governor>
          <dependent id="27">1993</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Anglo-French" type="MISC" score="0.0">
          <tokens>
            <token id="5" string="Anglo-French" />
          </tokens>
        </entity>
        <entity id="2" string="Eurotunnel PLC" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="1" string="Eurotunnel" />
            <token id="2" string="PLC" />
          </tokens>
        </entity>
        <entity id="3" string="June 1993" type="DATE" score="0.0">
          <tokens>
            <token id="26" string="June" />
            <token id="27" string="1993" />
          </tokens>
        </entity>
        <entity id="4" string="Channel Tunnel" type="LOCATION" score="0.0">
          <tokens>
            <token id="23" string="Channel" />
            <token id="24" string="Tunnel" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="false">
      <content>Eventually a train trip from Paris to London should take three hours.</content>
      <tokens>
        <token id="1" string="Eventually" lemma="eventually" stem="eventual" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="train" lemma="train" stem="train" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="trip" lemma="trip" stem="trip" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Paris" lemma="Paris" stem="pari" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="London" lemma="London" stem="london" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="9" string="should" lemma="should" stem="should" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="take" lemma="take" stem="take" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="three" lemma="three" stem="three" pos="CD" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="12" string="hours" lemma="hour" stem="hour" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Eventually)) (NP (NP (DT a) (NN train) (NN trip)) (PP (IN from) (NP (NP (NNP Paris)) (PP (TO to) (NP (NNP London)))))) (VP (MD should) (VP (VB take) (NP (CD three) (NNS hours)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a train trip from Paris to London" type="NP">
          <tokens>
            <token id="2" string="a" />
            <token id="3" string="train" />
            <token id="4" string="trip" />
            <token id="5" string="from" />
            <token id="6" string="Paris" />
            <token id="7" string="to" />
            <token id="8" string="London" />
          </tokens>
        </chunking>
        <chunking id="2" string="Paris to London" type="NP">
          <tokens>
            <token id="6" string="Paris" />
            <token id="7" string="to" />
            <token id="8" string="London" />
          </tokens>
        </chunking>
        <chunking id="3" string="London" type="NP">
          <tokens>
            <token id="8" string="London" />
          </tokens>
        </chunking>
        <chunking id="4" string="should take three hours" type="VP">
          <tokens>
            <token id="9" string="should" />
            <token id="10" string="take" />
            <token id="11" string="three" />
            <token id="12" string="hours" />
          </tokens>
        </chunking>
        <chunking id="5" string="take three hours" type="VP">
          <tokens>
            <token id="10" string="take" />
            <token id="11" string="three" />
            <token id="12" string="hours" />
          </tokens>
        </chunking>
        <chunking id="6" string="three hours" type="NP">
          <tokens>
            <token id="11" string="three" />
            <token id="12" string="hours" />
          </tokens>
        </chunking>
        <chunking id="7" string="a train trip" type="NP">
          <tokens>
            <token id="2" string="a" />
            <token id="3" string="train" />
            <token id="4" string="trip" />
          </tokens>
        </chunking>
        <chunking id="8" string="Paris" type="NP">
          <tokens>
            <token id="6" string="Paris" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="10">take</governor>
          <dependent id="1">Eventually</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">trip</governor>
          <dependent id="2">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">trip</governor>
          <dependent id="3">train</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">take</governor>
          <dependent id="4">trip</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">Paris</governor>
          <dependent id="5">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">trip</governor>
          <dependent id="6">Paris</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">London</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">Paris</governor>
          <dependent id="8">London</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="10">take</governor>
          <dependent id="9">should</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">take</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="12">hours</governor>
          <dependent id="11">three</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">take</governor>
          <dependent id="12">hours</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="London" type="LOCATION" score="0.0">
          <tokens>
            <token id="8" string="London" />
          </tokens>
        </entity>
        <entity id="2" string="three hours" type="DURATION" score="0.0">
          <tokens>
            <token id="11" string="three" />
            <token id="12" string="hours" />
          </tokens>
        </entity>
        <entity id="3" string="Paris" type="LOCATION" score="0.0">
          <tokens>
            <token id="6" string="Paris" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>Despite her countrymen&amp;apost;s fears of losing their ancient moat against Europe, British Prime Minister Margaret Thatcher described the breakthrough as ``a very exciting moment.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="Despite" lemma="despite" stem="despit" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="3" string="countrymen" lemma="countryman" stem="countrymen" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="fears" lemma="fear" stem="fear" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="losing" lemma="lose" stem="lose" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="ancient" lemma="ancient" stem="ancient" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="moat" lemma="moat" stem="moat" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Europe" lemma="Europe" stem="europ" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="British" lemma="British" stem="british" pos="NNP" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="true" is_refers="false" />
        <token id="15" string="Prime" lemma="Prime" stem="prime" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="Minister" lemma="Minister" stem="minist" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="true" is_refers="false" />
        <token id="17" string="Margaret" lemma="Margaret" stem="margaret" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="18" string="Thatcher" lemma="Thatcher" stem="thatcher" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="19" string="described" lemma="describe" stem="describ" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="breakthrough" lemma="breakthrough" stem="breakthrough" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="very" lemma="very" stem="veri" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="exciting" lemma="exciting" stem="excit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="moment" lemma="moment" stem="moment" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN Despite) (NP (NP (NP (PRP$ her) (NNS countrymen) (POS 's)) (NNS fears)) (PP (IN of) (S (VP (VBG losing) (NP (PRP$ their) (JJ ancient) (NN moat)) (PP (IN against) (NP (NNP Europe)))))))) (, ,) (NP (NNP British) (NNP Prime) (NNP Minister) (NNP Margaret) (NNP Thatcher)) (VP (VBD described) (NP (DT the) (NN breakthrough)) (PP (IN as) (`` ``) (NP (DT a) (ADJP (RB very) (JJ exciting)) (NN moment)))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="her countrymen 's" type="NP">
          <tokens>
            <token id="2" string="her" />
            <token id="3" string="countrymen" />
            <token id="4" string="'s" />
          </tokens>
        </chunking>
        <chunking id="2" string="a very exciting moment" type="NP">
          <tokens>
            <token id="24" string="a" />
            <token id="25" string="very" />
            <token id="26" string="exciting" />
            <token id="27" string="moment" />
          </tokens>
        </chunking>
        <chunking id="3" string="her countrymen 's fears" type="NP">
          <tokens>
            <token id="2" string="her" />
            <token id="3" string="countrymen" />
            <token id="4" string="'s" />
            <token id="5" string="fears" />
          </tokens>
        </chunking>
        <chunking id="4" string="British Prime Minister Margaret Thatcher" type="NP">
          <tokens>
            <token id="14" string="British" />
            <token id="15" string="Prime" />
            <token id="16" string="Minister" />
            <token id="17" string="Margaret" />
            <token id="18" string="Thatcher" />
          </tokens>
        </chunking>
        <chunking id="5" string="the breakthrough" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="breakthrough" />
          </tokens>
        </chunking>
        <chunking id="6" string="losing their ancient moat against Europe" type="VP">
          <tokens>
            <token id="7" string="losing" />
            <token id="8" string="their" />
            <token id="9" string="ancient" />
            <token id="10" string="moat" />
            <token id="11" string="against" />
            <token id="12" string="Europe" />
          </tokens>
        </chunking>
        <chunking id="7" string="Europe" type="NP">
          <tokens>
            <token id="12" string="Europe" />
          </tokens>
        </chunking>
        <chunking id="8" string="their ancient moat" type="NP">
          <tokens>
            <token id="8" string="their" />
            <token id="9" string="ancient" />
            <token id="10" string="moat" />
          </tokens>
        </chunking>
        <chunking id="9" string="very exciting" type="ADJP">
          <tokens>
            <token id="25" string="very" />
            <token id="26" string="exciting" />
          </tokens>
        </chunking>
        <chunking id="10" string="her countrymen 's fears of losing their ancient moat against Europe" type="NP">
          <tokens>
            <token id="2" string="her" />
            <token id="3" string="countrymen" />
            <token id="4" string="'s" />
            <token id="5" string="fears" />
            <token id="6" string="of" />
            <token id="7" string="losing" />
            <token id="8" string="their" />
            <token id="9" string="ancient" />
            <token id="10" string="moat" />
            <token id="11" string="against" />
            <token id="12" string="Europe" />
          </tokens>
        </chunking>
        <chunking id="11" string="described the breakthrough as `` a very exciting moment" type="VP">
          <tokens>
            <token id="19" string="described" />
            <token id="20" string="the" />
            <token id="21" string="breakthrough" />
            <token id="22" string="as" />
            <token id="23" string="``" />
            <token id="24" string="a" />
            <token id="25" string="very" />
            <token id="26" string="exciting" />
            <token id="27" string="moment" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="5">fears</governor>
          <dependent id="1">Despite</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="3">countrymen</governor>
          <dependent id="2">her</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">fears</governor>
          <dependent id="3">countrymen</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">countrymen</governor>
          <dependent id="4">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">described</governor>
          <dependent id="5">fears</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">losing</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="5">fears</governor>
          <dependent id="7">losing</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="10">moat</governor>
          <dependent id="8">their</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">moat</governor>
          <dependent id="9">ancient</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">losing</governor>
          <dependent id="10">moat</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">Europe</governor>
          <dependent id="11">against</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">losing</governor>
          <dependent id="12">Europe</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Thatcher</governor>
          <dependent id="14">British</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Thatcher</governor>
          <dependent id="15">Prime</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Thatcher</governor>
          <dependent id="16">Minister</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Thatcher</governor>
          <dependent id="17">Margaret</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">described</governor>
          <dependent id="18">Thatcher</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="19">described</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">breakthrough</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">described</governor>
          <dependent id="21">breakthrough</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">moment</governor>
          <dependent id="22">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">moment</governor>
          <dependent id="24">a</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="26">exciting</governor>
          <dependent id="25">very</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="27">moment</governor>
          <dependent id="26">exciting</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">described</governor>
          <dependent id="27">moment</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="British" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="14" string="British" />
          </tokens>
        </entity>
        <entity id="2" string="Europe" type="LOCATION" score="0.0">
          <tokens>
            <token id="12" string="Europe" />
          </tokens>
        </entity>
        <entity id="3" string="Margaret Thatcher" type="PERSON" score="0.0">
          <tokens>
            <token id="17" string="Margaret" />
            <token id="18" string="Thatcher" />
          </tokens>
        </entity>
        <entity id="4" string="Minister" type="TITLE" score="0.0">
          <tokens>
            <token id="16" string="Minister" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>``It is an example of what Europe is about,&amp;apost;&amp;apost; she said in London.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="example" lemma="example" stem="exampl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="Europe" lemma="Europe" stem="europ" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="9" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="about" lemma="about" stem="about" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="London" lemma="London" stem="london" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP It)) (VP (VBZ is) (NP (NP (DT an) (NN example)) (PP (IN of) (SBAR (WHNP (WP what)) (S (NP (NNP Europe)) (VP (VBZ is) (RB about)))))))) (, ,) ('' '') (NP (PRP she)) (VP (VBD said) (PP (IN in) (NP (NNP London)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="an example" type="NP">
          <tokens>
            <token id="4" string="an" />
            <token id="5" string="example" />
          </tokens>
        </chunking>
        <chunking id="2" string="what Europe is about" type="SBAR">
          <tokens>
            <token id="7" string="what" />
            <token id="8" string="Europe" />
            <token id="9" string="is" />
            <token id="10" string="about" />
          </tokens>
        </chunking>
        <chunking id="3" string="an example of what Europe is about" type="NP">
          <tokens>
            <token id="4" string="an" />
            <token id="5" string="example" />
            <token id="6" string="of" />
            <token id="7" string="what" />
            <token id="8" string="Europe" />
            <token id="9" string="is" />
            <token id="10" string="about" />
          </tokens>
        </chunking>
        <chunking id="4" string="Europe" type="NP">
          <tokens>
            <token id="8" string="Europe" />
          </tokens>
        </chunking>
        <chunking id="5" string="London" type="NP">
          <tokens>
            <token id="16" string="London" />
          </tokens>
        </chunking>
        <chunking id="6" string="said in London" type="VP">
          <tokens>
            <token id="14" string="said" />
            <token id="15" string="in" />
            <token id="16" string="London" />
          </tokens>
        </chunking>
        <chunking id="7" string="It" type="NP">
          <tokens>
            <token id="2" string="It" />
          </tokens>
        </chunking>
        <chunking id="8" string="is an example of what Europe is about" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="an" />
            <token id="5" string="example" />
            <token id="6" string="of" />
            <token id="7" string="what" />
            <token id="8" string="Europe" />
            <token id="9" string="is" />
            <token id="10" string="about" />
          </tokens>
        </chunking>
        <chunking id="9" string="is about" type="VP">
          <tokens>
            <token id="9" string="is" />
            <token id="10" string="about" />
          </tokens>
        </chunking>
        <chunking id="10" string="she" type="NP">
          <tokens>
            <token id="13" string="she" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">example</governor>
          <dependent id="2">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">example</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">example</governor>
          <dependent id="4">an</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="14">said</governor>
          <dependent id="5">example</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">is</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">is</governor>
          <dependent id="7">what</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">is</governor>
          <dependent id="8">Europe</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="5">example</governor>
          <dependent id="9">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">is</governor>
          <dependent id="10">about</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">said</governor>
          <dependent id="13">she</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">said</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">London</governor>
          <dependent id="15">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">said</governor>
          <dependent id="16">London</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Europe" type="LOCATION" score="0.0">
          <tokens>
            <token id="8" string="Europe" />
          </tokens>
        </entity>
        <entity id="2" string="London" type="LOCATION" score="0.0">
          <tokens>
            <token id="16" string="London" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>``This is Europe in practice.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="This" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Europe" lemma="Europe" stem="europ" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="5" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="practice" lemma="practice" stem="practic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (DT This)) (VP (VBZ is) (NP (NP (NNP Europe)) (PP (IN in) (NP (NN practice))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="practice" type="NP">
          <tokens>
            <token id="6" string="practice" />
          </tokens>
        </chunking>
        <chunking id="2" string="Europe" type="NP">
          <tokens>
            <token id="4" string="Europe" />
          </tokens>
        </chunking>
        <chunking id="3" string="is Europe in practice" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="Europe" />
            <token id="5" string="in" />
            <token id="6" string="practice" />
          </tokens>
        </chunking>
        <chunking id="4" string="Europe in practice" type="NP">
          <tokens>
            <token id="4" string="Europe" />
            <token id="5" string="in" />
            <token id="6" string="practice" />
          </tokens>
        </chunking>
        <chunking id="5" string="This" type="NP">
          <tokens>
            <token id="2" string="This" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">Europe</governor>
          <dependent id="2">This</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">Europe</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">Europe</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">practice</governor>
          <dependent id="5">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">Europe</governor>
          <dependent id="6">practice</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Europe" type="LOCATION" score="0.0">
          <tokens>
            <token id="4" string="Europe" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="10" has_coreference="false">
      <content>In London, the conservative Daily Express newspaper noted today that Britons will be able to walk to France for the first time since the Ice Age.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="London" lemma="London" stem="london" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="conservative" lemma="conservative" stem="conserv" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="6" string="Daily" lemma="Daily" stem="daili" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="7" string="Express" lemma="Express" stem="express" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="8" string="newspaper" lemma="newspaper" stem="newspap" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="noted" lemma="note" stem="note" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="today" lemma="today" stem="todai" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="11" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Britons" lemma="Britons" stem="briton" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="13" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="able" lemma="able" stem="abl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="walk" lemma="walk" stem="walk" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="France" lemma="France" stem="franc" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="20" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="23" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="since" lemma="since" stem="sinc" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="Ice" lemma="Ice" stem="ice" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="Age" lemma="Age" stem="age" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (NNP London))) (, ,) (NP (DT the) (JJ conservative) (NNP Daily) (NNP Express) (NN newspaper)) (VP (VBD noted) (NP-TMP (NN today)) (SBAR (WHNP (WDT that)) (S (NP (NNPS Britons)) (VP (MD will) (VP (VB be) (ADJP (JJ able) (S (VP (TO to) (VP (VB walk) (PP (TO to) (NP (NNP France))) (PP (IN for) (NP (NP (DT the) (JJ first) (NN time)) (PP (IN since) (NP (DT the) (NNP Ice) (NNP Age)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="to walk to France for the first time since the Ice Age" type="VP">
          <tokens>
            <token id="16" string="to" />
            <token id="17" string="walk" />
            <token id="18" string="to" />
            <token id="19" string="France" />
            <token id="20" string="for" />
            <token id="21" string="the" />
            <token id="22" string="first" />
            <token id="23" string="time" />
            <token id="24" string="since" />
            <token id="25" string="the" />
            <token id="26" string="Ice" />
            <token id="27" string="Age" />
          </tokens>
        </chunking>
        <chunking id="2" string="that Britons will be able to walk to France for the first time since the Ice Age" type="SBAR">
          <tokens>
            <token id="11" string="that" />
            <token id="12" string="Britons" />
            <token id="13" string="will" />
            <token id="14" string="be" />
            <token id="15" string="able" />
            <token id="16" string="to" />
            <token id="17" string="walk" />
            <token id="18" string="to" />
            <token id="19" string="France" />
            <token id="20" string="for" />
            <token id="21" string="the" />
            <token id="22" string="first" />
            <token id="23" string="time" />
            <token id="24" string="since" />
            <token id="25" string="the" />
            <token id="26" string="Ice" />
            <token id="27" string="Age" />
          </tokens>
        </chunking>
        <chunking id="3" string="the Ice Age" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="Ice" />
            <token id="27" string="Age" />
          </tokens>
        </chunking>
        <chunking id="4" string="noted today that Britons will be able to walk to France for the first time since the Ice Age" type="VP">
          <tokens>
            <token id="9" string="noted" />
            <token id="10" string="today" />
            <token id="11" string="that" />
            <token id="12" string="Britons" />
            <token id="13" string="will" />
            <token id="14" string="be" />
            <token id="15" string="able" />
            <token id="16" string="to" />
            <token id="17" string="walk" />
            <token id="18" string="to" />
            <token id="19" string="France" />
            <token id="20" string="for" />
            <token id="21" string="the" />
            <token id="22" string="first" />
            <token id="23" string="time" />
            <token id="24" string="since" />
            <token id="25" string="the" />
            <token id="26" string="Ice" />
            <token id="27" string="Age" />
          </tokens>
        </chunking>
        <chunking id="5" string="the first time since the Ice Age" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="first" />
            <token id="23" string="time" />
            <token id="24" string="since" />
            <token id="25" string="the" />
            <token id="26" string="Ice" />
            <token id="27" string="Age" />
          </tokens>
        </chunking>
        <chunking id="6" string="able to walk to France for the first time since the Ice Age" type="ADJP">
          <tokens>
            <token id="15" string="able" />
            <token id="16" string="to" />
            <token id="17" string="walk" />
            <token id="18" string="to" />
            <token id="19" string="France" />
            <token id="20" string="for" />
            <token id="21" string="the" />
            <token id="22" string="first" />
            <token id="23" string="time" />
            <token id="24" string="since" />
            <token id="25" string="the" />
            <token id="26" string="Ice" />
            <token id="27" string="Age" />
          </tokens>
        </chunking>
        <chunking id="7" string="the first time" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="first" />
            <token id="23" string="time" />
          </tokens>
        </chunking>
        <chunking id="8" string="be able to walk to France for the first time since the Ice Age" type="VP">
          <tokens>
            <token id="14" string="be" />
            <token id="15" string="able" />
            <token id="16" string="to" />
            <token id="17" string="walk" />
            <token id="18" string="to" />
            <token id="19" string="France" />
            <token id="20" string="for" />
            <token id="21" string="the" />
            <token id="22" string="first" />
            <token id="23" string="time" />
            <token id="24" string="since" />
            <token id="25" string="the" />
            <token id="26" string="Ice" />
            <token id="27" string="Age" />
          </tokens>
        </chunking>
        <chunking id="9" string="London" type="NP">
          <tokens>
            <token id="2" string="London" />
          </tokens>
        </chunking>
        <chunking id="10" string="Britons" type="NP">
          <tokens>
            <token id="12" string="Britons" />
          </tokens>
        </chunking>
        <chunking id="11" string="the conservative Daily Express newspaper" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="conservative" />
            <token id="6" string="Daily" />
            <token id="7" string="Express" />
            <token id="8" string="newspaper" />
          </tokens>
        </chunking>
        <chunking id="12" string="will be able to walk to France for the first time since the Ice Age" type="VP">
          <tokens>
            <token id="13" string="will" />
            <token id="14" string="be" />
            <token id="15" string="able" />
            <token id="16" string="to" />
            <token id="17" string="walk" />
            <token id="18" string="to" />
            <token id="19" string="France" />
            <token id="20" string="for" />
            <token id="21" string="the" />
            <token id="22" string="first" />
            <token id="23" string="time" />
            <token id="24" string="since" />
            <token id="25" string="the" />
            <token id="26" string="Ice" />
            <token id="27" string="Age" />
          </tokens>
        </chunking>
        <chunking id="13" string="France" type="NP">
          <tokens>
            <token id="19" string="France" />
          </tokens>
        </chunking>
        <chunking id="14" string="walk to France for the first time since the Ice Age" type="VP">
          <tokens>
            <token id="17" string="walk" />
            <token id="18" string="to" />
            <token id="19" string="France" />
            <token id="20" string="for" />
            <token id="21" string="the" />
            <token id="22" string="first" />
            <token id="23" string="time" />
            <token id="24" string="since" />
            <token id="25" string="the" />
            <token id="26" string="Ice" />
            <token id="27" string="Age" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">London</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">noted</governor>
          <dependent id="2">London</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">newspaper</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">newspaper</governor>
          <dependent id="5">conservative</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">newspaper</governor>
          <dependent id="6">Daily</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">newspaper</governor>
          <dependent id="7">Express</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">noted</governor>
          <dependent id="8">newspaper</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">noted</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="9">noted</governor>
          <dependent id="10">today</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">walk</governor>
          <dependent id="11">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">able</governor>
          <dependent id="12">Britons</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="15">able</governor>
          <dependent id="13">will</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="15">able</governor>
          <dependent id="14">be</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="9">noted</governor>
          <dependent id="15">able</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">walk</governor>
          <dependent id="16">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="15">able</governor>
          <dependent id="17">walk</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">France</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">walk</governor>
          <dependent id="19">France</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">time</governor>
          <dependent id="20">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">time</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">time</governor>
          <dependent id="22">first</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">walk</governor>
          <dependent id="23">time</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">Age</governor>
          <dependent id="24">since</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">Age</governor>
          <dependent id="25">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">Age</governor>
          <dependent id="26">Ice</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">time</governor>
          <dependent id="27">Age</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="22" string="first" />
          </tokens>
        </entity>
        <entity id="2" string="conservative" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="5" string="conservative" />
          </tokens>
        </entity>
        <entity id="3" string="today" type="DATE" score="0.0">
          <tokens>
            <token id="10" string="today" />
          </tokens>
        </entity>
        <entity id="4" string="London" type="LOCATION" score="0.0">
          <tokens>
            <token id="2" string="London" />
          </tokens>
        </entity>
        <entity id="5" string="Britons" type="MISC" score="0.0">
          <tokens>
            <token id="12" string="Britons" />
          </tokens>
        </entity>
        <entity id="6" string="France" type="LOCATION" score="0.0">
          <tokens>
            <token id="19" string="France" />
          </tokens>
        </entity>
        <entity id="7" string="Daily Express" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="6" string="Daily" />
            <token id="7" string="Express" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>``This is a hugely historic moment because it means, in effect, that Britain is no longer an island,&amp;apost;&amp;apost; a construction union official in Calais said.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="This" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="hugely" lemma="hugely" stem="huge" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="historic" lemma="historic" stem="histor" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="moment" lemma="moment" stem="moment" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="means" lemma="mean" stem="mean" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="effect" lemma="effect" stem="effect" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="Britain" lemma="Britain" stem="britain" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="17" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="no" lemma="no" stem="no" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="longer" lemma="longer" stem="longer" pos="RBR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="island" lemma="island" stem="island" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="construction" lemma="construction" stem="construct" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="union" lemma="union" stem="union" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="official" lemma="official" stem="offici" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="Calais" lemma="Calais" stem="calai" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="30" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (DT This)) (VP (VBZ is) (NP (DT a) (ADJP (RB hugely) (JJ historic)) (NN moment)) (SBAR (IN because) (S (NP (PRP it)) (VP (VBZ means)))) (, ,) (PP (IN in) (NP (NN effect))) (, ,) (SBAR (IN that) (S (NP (NNP Britain)) (VP (VBZ is) (ADVP (RB no) (RBR longer)) (NP (DT an) (NN island))))))) (, ,) ('' '') (NP (NP (DT a) (NN construction) (NN union) (NN official)) (PP (IN in) (NP (NNP Calais)))) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="means" type="VP">
          <tokens>
            <token id="10" string="means" />
          </tokens>
        </chunking>
        <chunking id="2" string="Calais" type="NP">
          <tokens>
            <token id="29" string="Calais" />
          </tokens>
        </chunking>
        <chunking id="3" string="a construction union official" type="NP">
          <tokens>
            <token id="24" string="a" />
            <token id="25" string="construction" />
            <token id="26" string="union" />
            <token id="27" string="official" />
          </tokens>
        </chunking>
        <chunking id="4" string="a hugely historic moment" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="hugely" />
            <token id="6" string="historic" />
            <token id="7" string="moment" />
          </tokens>
        </chunking>
        <chunking id="5" string="it" type="NP">
          <tokens>
            <token id="9" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="Britain" type="NP">
          <tokens>
            <token id="16" string="Britain" />
          </tokens>
        </chunking>
        <chunking id="7" string="hugely historic" type="ADJP">
          <tokens>
            <token id="5" string="hugely" />
            <token id="6" string="historic" />
          </tokens>
        </chunking>
        <chunking id="8" string="is no longer an island" type="VP">
          <tokens>
            <token id="17" string="is" />
            <token id="18" string="no" />
            <token id="19" string="longer" />
            <token id="20" string="an" />
            <token id="21" string="island" />
          </tokens>
        </chunking>
        <chunking id="9" string="because it means" type="SBAR">
          <tokens>
            <token id="8" string="because" />
            <token id="9" string="it" />
            <token id="10" string="means" />
          </tokens>
        </chunking>
        <chunking id="10" string="an island" type="NP">
          <tokens>
            <token id="20" string="an" />
            <token id="21" string="island" />
          </tokens>
        </chunking>
        <chunking id="11" string="is a hugely historic moment because it means , in effect , that Britain is no longer an island" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="a" />
            <token id="5" string="hugely" />
            <token id="6" string="historic" />
            <token id="7" string="moment" />
            <token id="8" string="because" />
            <token id="9" string="it" />
            <token id="10" string="means" />
            <token id="11" string="," />
            <token id="12" string="in" />
            <token id="13" string="effect" />
            <token id="14" string="," />
            <token id="15" string="that" />
            <token id="16" string="Britain" />
            <token id="17" string="is" />
            <token id="18" string="no" />
            <token id="19" string="longer" />
            <token id="20" string="an" />
            <token id="21" string="island" />
          </tokens>
        </chunking>
        <chunking id="12" string="effect" type="NP">
          <tokens>
            <token id="13" string="effect" />
          </tokens>
        </chunking>
        <chunking id="13" string="that Britain is no longer an island" type="SBAR">
          <tokens>
            <token id="15" string="that" />
            <token id="16" string="Britain" />
            <token id="17" string="is" />
            <token id="18" string="no" />
            <token id="19" string="longer" />
            <token id="20" string="an" />
            <token id="21" string="island" />
          </tokens>
        </chunking>
        <chunking id="14" string="a construction union official in Calais" type="NP">
          <tokens>
            <token id="24" string="a" />
            <token id="25" string="construction" />
            <token id="26" string="union" />
            <token id="27" string="official" />
            <token id="28" string="in" />
            <token id="29" string="Calais" />
          </tokens>
        </chunking>
        <chunking id="15" string="This" type="NP">
          <tokens>
            <token id="2" string="This" />
          </tokens>
        </chunking>
        <chunking id="16" string="said" type="VP">
          <tokens>
            <token id="30" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="7">moment</governor>
          <dependent id="2">This</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">moment</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">moment</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">historic</governor>
          <dependent id="5">hugely</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">moment</governor>
          <dependent id="6">historic</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="30">said</governor>
          <dependent id="7">moment</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">means</governor>
          <dependent id="8">because</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">means</governor>
          <dependent id="9">it</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="7">moment</governor>
          <dependent id="10">means</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">effect</governor>
          <dependent id="12">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">moment</governor>
          <dependent id="13">effect</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="21">island</governor>
          <dependent id="15">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">island</governor>
          <dependent id="16">Britain</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="21">island</governor>
          <dependent id="17">is</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="19">longer</governor>
          <dependent id="18">no</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="21">island</governor>
          <dependent id="19">longer</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">island</governor>
          <dependent id="20">an</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">moment</governor>
          <dependent id="21">island</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">official</governor>
          <dependent id="24">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">official</governor>
          <dependent id="25">construction</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">official</governor>
          <dependent id="26">union</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="30">said</governor>
          <dependent id="27">official</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">Calais</governor>
          <dependent id="28">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">official</governor>
          <dependent id="29">Calais</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="30">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Calais" type="LOCATION" score="0.0">
          <tokens>
            <token id="29" string="Calais" />
          </tokens>
        </entity>
        <entity id="2" string="Britain" type="LOCATION" score="0.0">
          <tokens>
            <token id="16" string="Britain" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>Threading a spinning probe the width of a garden hose through 100 yards of chalk under the Channel bears the first tangible fruit in three years of drilling.</content>
      <tokens>
        <token id="1" string="Threading" lemma="thread" stem="thread" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="spinning" lemma="spin" stem="spin" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="probe" lemma="probe" stem="probe" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="width" lemma="width" stem="width" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="garden" lemma="garden" stem="garden" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="hose" lemma="hose" stem="hose" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="100" lemma="100" stem="100" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="13" string="yards" lemma="yard" stem="yard" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="chalk" lemma="chalk" stem="chalk" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="under" lemma="under" stem="under" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="Channel" lemma="Channel" stem="channel" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="19" string="bears" lemma="bear" stem="bear" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="22" string="tangible" lemma="tangible" stem="tangibl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="fruit" lemma="fruit" stem="fruit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="three" lemma="three" stem="three" pos="CD" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="26" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="27" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="drilling" lemma="drilling" stem="drill" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (VBG Threading) (NP (DT a) (VBG spinning) (NN probe)) (PP (NP (DT the) (NN width)) (IN of) (NP (DT a) (NN garden) (NN hose))) (PP (IN through) (NP (NP (CD 100) (NNS yards)) (PP (IN of) (NP (NN chalk))))) (PP (IN under) (NP (DT the) (NNP Channel))))) (VP (VBZ bears) (NP (NP (DT the) (JJ first) (JJ tangible) (NN fruit)) (PP (IN in) (NP (NP (CD three) (NNS years)) (PP (IN of) (NP (NN drilling))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a spinning probe" type="NP">
          <tokens>
            <token id="2" string="a" />
            <token id="3" string="spinning" />
            <token id="4" string="probe" />
          </tokens>
        </chunking>
        <chunking id="2" string="three years" type="NP">
          <tokens>
            <token id="25" string="three" />
            <token id="26" string="years" />
          </tokens>
        </chunking>
        <chunking id="3" string="bears the first tangible fruit in three years of drilling" type="VP">
          <tokens>
            <token id="19" string="bears" />
            <token id="20" string="the" />
            <token id="21" string="first" />
            <token id="22" string="tangible" />
            <token id="23" string="fruit" />
            <token id="24" string="in" />
            <token id="25" string="three" />
            <token id="26" string="years" />
            <token id="27" string="of" />
            <token id="28" string="drilling" />
          </tokens>
        </chunking>
        <chunking id="4" string="the first tangible fruit in three years of drilling" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="first" />
            <token id="22" string="tangible" />
            <token id="23" string="fruit" />
            <token id="24" string="in" />
            <token id="25" string="three" />
            <token id="26" string="years" />
            <token id="27" string="of" />
            <token id="28" string="drilling" />
          </tokens>
        </chunking>
        <chunking id="5" string="100 yards of chalk" type="NP">
          <tokens>
            <token id="12" string="100" />
            <token id="13" string="yards" />
            <token id="14" string="of" />
            <token id="15" string="chalk" />
          </tokens>
        </chunking>
        <chunking id="6" string="100 yards" type="NP">
          <tokens>
            <token id="12" string="100" />
            <token id="13" string="yards" />
          </tokens>
        </chunking>
        <chunking id="7" string="drilling" type="NP">
          <tokens>
            <token id="28" string="drilling" />
          </tokens>
        </chunking>
        <chunking id="8" string="Threading a spinning probe the width of a garden hose through 100 yards of chalk under the Channel" type="VP">
          <tokens>
            <token id="1" string="Threading" />
            <token id="2" string="a" />
            <token id="3" string="spinning" />
            <token id="4" string="probe" />
            <token id="5" string="the" />
            <token id="6" string="width" />
            <token id="7" string="of" />
            <token id="8" string="a" />
            <token id="9" string="garden" />
            <token id="10" string="hose" />
            <token id="11" string="through" />
            <token id="12" string="100" />
            <token id="13" string="yards" />
            <token id="14" string="of" />
            <token id="15" string="chalk" />
            <token id="16" string="under" />
            <token id="17" string="the" />
            <token id="18" string="Channel" />
          </tokens>
        </chunking>
        <chunking id="9" string="three years of drilling" type="NP">
          <tokens>
            <token id="25" string="three" />
            <token id="26" string="years" />
            <token id="27" string="of" />
            <token id="28" string="drilling" />
          </tokens>
        </chunking>
        <chunking id="10" string="the Channel" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="Channel" />
          </tokens>
        </chunking>
        <chunking id="11" string="chalk" type="NP">
          <tokens>
            <token id="15" string="chalk" />
          </tokens>
        </chunking>
        <chunking id="12" string="a garden hose" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="garden" />
            <token id="10" string="hose" />
          </tokens>
        </chunking>
        <chunking id="13" string="the width" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="width" />
          </tokens>
        </chunking>
        <chunking id="14" string="the first tangible fruit" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="first" />
            <token id="22" string="tangible" />
            <token id="23" string="fruit" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="csubj">
          <governor id="19">bears</governor>
          <dependent id="1">Threading</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">probe</governor>
          <dependent id="2">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">probe</governor>
          <dependent id="3">spinning</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="1">Threading</governor>
          <dependent id="4">probe</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">width</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Threading</governor>
          <dependent id="6">width</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">width</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">hose</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">hose</governor>
          <dependent id="9">garden</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="6">width</governor>
          <dependent id="10">hose</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">yards</governor>
          <dependent id="11">through</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="13">yards</governor>
          <dependent id="12">100</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Threading</governor>
          <dependent id="13">yards</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">chalk</governor>
          <dependent id="14">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">yards</governor>
          <dependent id="15">chalk</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">Channel</governor>
          <dependent id="16">under</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">Channel</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Threading</governor>
          <dependent id="18">Channel</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="19">bears</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">fruit</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">fruit</governor>
          <dependent id="21">first</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">fruit</governor>
          <dependent id="22">tangible</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">bears</governor>
          <dependent id="23">fruit</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">years</governor>
          <dependent id="24">in</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="26">years</governor>
          <dependent id="25">three</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">fruit</governor>
          <dependent id="26">years</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">drilling</governor>
          <dependent id="27">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">years</governor>
          <dependent id="28">drilling</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="100" type="NUMBER" score="0.0">
          <tokens>
            <token id="12" string="100" />
          </tokens>
        </entity>
        <entity id="2" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="21" string="first" />
          </tokens>
        </entity>
        <entity id="3" string="three years" type="DURATION" score="0.0">
          <tokens>
            <token id="25" string="three" />
            <token id="26" string="years" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>Champagne corks popped and workers danced jigs after French drillers phoned news of the probe&amp;apost;s arrival to their British counterparts.</content>
      <tokens>
        <token id="1" string="Champagne" lemma="champagne" stem="champagn" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="corks" lemma="cork" stem="cork" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="popped" lemma="pop" stem="pop" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="workers" lemma="worker" stem="worker" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="danced" lemma="dance" stem="danc" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="jigs" lemma="jig" stem="jig" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="French" lemma="french" stem="french" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="10" string="drillers" lemma="driller" stem="driller" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="phoned" lemma="phone" stem="phone" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="news" lemma="news" stem="new" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="probe" lemma="probe" stem="probe" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="arrival" lemma="arrival" stem="arriv" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="British" lemma="british" stem="british" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="21" string="counterparts" lemma="counterpart" stem="counterpart" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NN Champagne) (NNS corks)) (VP (VBN popped))) (CC and) (S (NP (NNS workers)) (VP (VBD danced) (NP (NNS jigs)) (PP (IN after) (NP (NP (JJ French) (NNS drillers)) (VP (VBN phoned) (NP (NP (NN news)) (PP (IN of) (NP (NP (DT the) (NN probe) (POS 's)) (NN arrival)))) (PP (TO to) (NP (PRP$ their) (JJ British) (NNS counterparts)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="news" type="NP">
          <tokens>
            <token id="12" string="news" />
          </tokens>
        </chunking>
        <chunking id="2" string="French drillers phoned news of the probe 's arrival to their British counterparts" type="NP">
          <tokens>
            <token id="9" string="French" />
            <token id="10" string="drillers" />
            <token id="11" string="phoned" />
            <token id="12" string="news" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="probe" />
            <token id="16" string="'s" />
            <token id="17" string="arrival" />
            <token id="18" string="to" />
            <token id="19" string="their" />
            <token id="20" string="British" />
            <token id="21" string="counterparts" />
          </tokens>
        </chunking>
        <chunking id="3" string="the probe 's arrival" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="probe" />
            <token id="16" string="'s" />
            <token id="17" string="arrival" />
          </tokens>
        </chunking>
        <chunking id="4" string="popped" type="VP">
          <tokens>
            <token id="3" string="popped" />
          </tokens>
        </chunking>
        <chunking id="5" string="phoned news of the probe 's arrival to their British counterparts" type="VP">
          <tokens>
            <token id="11" string="phoned" />
            <token id="12" string="news" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="probe" />
            <token id="16" string="'s" />
            <token id="17" string="arrival" />
            <token id="18" string="to" />
            <token id="19" string="their" />
            <token id="20" string="British" />
            <token id="21" string="counterparts" />
          </tokens>
        </chunking>
        <chunking id="6" string="news of the probe 's arrival" type="NP">
          <tokens>
            <token id="12" string="news" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="probe" />
            <token id="16" string="'s" />
            <token id="17" string="arrival" />
          </tokens>
        </chunking>
        <chunking id="7" string="their British counterparts" type="NP">
          <tokens>
            <token id="19" string="their" />
            <token id="20" string="British" />
            <token id="21" string="counterparts" />
          </tokens>
        </chunking>
        <chunking id="8" string="Champagne corks" type="NP">
          <tokens>
            <token id="1" string="Champagne" />
            <token id="2" string="corks" />
          </tokens>
        </chunking>
        <chunking id="9" string="jigs" type="NP">
          <tokens>
            <token id="7" string="jigs" />
          </tokens>
        </chunking>
        <chunking id="10" string="French drillers" type="NP">
          <tokens>
            <token id="9" string="French" />
            <token id="10" string="drillers" />
          </tokens>
        </chunking>
        <chunking id="11" string="workers" type="NP">
          <tokens>
            <token id="5" string="workers" />
          </tokens>
        </chunking>
        <chunking id="12" string="the probe 's" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="probe" />
            <token id="16" string="'s" />
          </tokens>
        </chunking>
        <chunking id="13" string="danced jigs after French drillers phoned news of the probe 's arrival to their British counterparts" type="VP">
          <tokens>
            <token id="6" string="danced" />
            <token id="7" string="jigs" />
            <token id="8" string="after" />
            <token id="9" string="French" />
            <token id="10" string="drillers" />
            <token id="11" string="phoned" />
            <token id="12" string="news" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="probe" />
            <token id="16" string="'s" />
            <token id="17" string="arrival" />
            <token id="18" string="to" />
            <token id="19" string="their" />
            <token id="20" string="British" />
            <token id="21" string="counterparts" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">corks</governor>
          <dependent id="1">Champagne</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">popped</governor>
          <dependent id="2">corks</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">popped</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">popped</governor>
          <dependent id="4">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">danced</governor>
          <dependent id="5">workers</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">popped</governor>
          <dependent id="6">danced</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">danced</governor>
          <dependent id="7">jigs</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">drillers</governor>
          <dependent id="8">after</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">drillers</governor>
          <dependent id="9">French</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">danced</governor>
          <dependent id="10">drillers</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="10">drillers</governor>
          <dependent id="11">phoned</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">phoned</governor>
          <dependent id="12">news</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">arrival</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">probe</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="17">arrival</governor>
          <dependent id="15">probe</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">probe</governor>
          <dependent id="16">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">news</governor>
          <dependent id="17">arrival</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">counterparts</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="21">counterparts</governor>
          <dependent id="19">their</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">counterparts</governor>
          <dependent id="20">British</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">phoned</governor>
          <dependent id="21">counterparts</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="French" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="9" string="French" />
          </tokens>
        </entity>
        <entity id="2" string="British" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="20" string="British" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="14" has_coreference="false">
      <content>Initial tests indicated the two halves were 20 inches out of alignment.</content>
      <tokens>
        <token id="1" string="Initial" lemma="initial" stem="initial" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="tests" lemma="test" stem="test" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="indicated" lemma="indicate" stem="indic" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="6" string="halves" lemma="half" stem="halv" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="20" lemma="20" stem="20" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="9" string="inches" lemma="inch" stem="inch" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="out" lemma="out" stem="out" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="alignment" lemma="alignment" stem="align" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (JJ Initial) (NNS tests)) (VP (VBD indicated) (SBAR (S (NP (DT the) (CD two) (NNS halves)) (VP (VBD were) (ADVP (NP (CD 20) (NNS inches)) (IN out)) (PP (IN of) (NP (NN alignment))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="were 20 inches out of alignment" type="VP">
          <tokens>
            <token id="7" string="were" />
            <token id="8" string="20" />
            <token id="9" string="inches" />
            <token id="10" string="out" />
            <token id="11" string="of" />
            <token id="12" string="alignment" />
          </tokens>
        </chunking>
        <chunking id="2" string="the two halves were 20 inches out of alignment" type="SBAR">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="two" />
            <token id="6" string="halves" />
            <token id="7" string="were" />
            <token id="8" string="20" />
            <token id="9" string="inches" />
            <token id="10" string="out" />
            <token id="11" string="of" />
            <token id="12" string="alignment" />
          </tokens>
        </chunking>
        <chunking id="3" string="the two halves" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="two" />
            <token id="6" string="halves" />
          </tokens>
        </chunking>
        <chunking id="4" string="indicated the two halves were 20 inches out of alignment" type="VP">
          <tokens>
            <token id="3" string="indicated" />
            <token id="4" string="the" />
            <token id="5" string="two" />
            <token id="6" string="halves" />
            <token id="7" string="were" />
            <token id="8" string="20" />
            <token id="9" string="inches" />
            <token id="10" string="out" />
            <token id="11" string="of" />
            <token id="12" string="alignment" />
          </tokens>
        </chunking>
        <chunking id="5" string="Initial tests" type="NP">
          <tokens>
            <token id="1" string="Initial" />
            <token id="2" string="tests" />
          </tokens>
        </chunking>
        <chunking id="6" string="alignment" type="NP">
          <tokens>
            <token id="12" string="alignment" />
          </tokens>
        </chunking>
        <chunking id="7" string="20 inches" type="NP">
          <tokens>
            <token id="8" string="20" />
            <token id="9" string="inches" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="2">tests</governor>
          <dependent id="1">Initial</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">indicated</governor>
          <dependent id="2">tests</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">indicated</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">halves</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="6">halves</governor>
          <dependent id="5">two</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">alignment</governor>
          <dependent id="6">halves</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="12">alignment</governor>
          <dependent id="7">were</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="9">inches</governor>
          <dependent id="8">20</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">alignment</governor>
          <dependent id="9">inches</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">inches</governor>
          <dependent id="10">out</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">alignment</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">indicated</governor>
          <dependent id="12">alignment</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="5" string="two" />
          </tokens>
        </entity>
        <entity id="2" string="20" type="NUMBER" score="0.0">
          <tokens>
            <token id="8" string="20" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="15" has_coreference="false">
      <content>Technicians will be more certain Wednesday, but they called the rough line-up ``exceptional.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="Technicians" lemma="technician" stem="technician" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="certain" lemma="certain" stem="certain" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="Wednesday" lemma="Wednesday" stem="wednesdai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="called" lemma="call" stem="call" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="rough" lemma="rough" stem="rough" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="line-up" lemma="line-up" stem="line-up" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="exceptional" lemma="exceptional" stem="except" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NNS Technicians)) (VP (MD will) (VP (VB be) (ADJP (RBR more) (JJ certain)) (NP-TMP (NNP Wednesday))))) (, ,) (CC but) (S (NP (PRP they)) (VP (VBD called) (S (NP (DT the) (JJ rough) (NN line-up)) (`` ``) (ADJP (JJ exceptional))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="they" type="NP">
          <tokens>
            <token id="9" string="they" />
          </tokens>
        </chunking>
        <chunking id="2" string="more certain" type="ADJP">
          <tokens>
            <token id="4" string="more" />
            <token id="5" string="certain" />
          </tokens>
        </chunking>
        <chunking id="3" string="exceptional" type="ADJP">
          <tokens>
            <token id="15" string="exceptional" />
          </tokens>
        </chunking>
        <chunking id="4" string="called the rough line-up `` exceptional" type="VP">
          <tokens>
            <token id="10" string="called" />
            <token id="11" string="the" />
            <token id="12" string="rough" />
            <token id="13" string="line-up" />
            <token id="14" string="``" />
            <token id="15" string="exceptional" />
          </tokens>
        </chunking>
        <chunking id="5" string="be more certain Wednesday" type="VP">
          <tokens>
            <token id="3" string="be" />
            <token id="4" string="more" />
            <token id="5" string="certain" />
            <token id="6" string="Wednesday" />
          </tokens>
        </chunking>
        <chunking id="6" string="Technicians" type="NP">
          <tokens>
            <token id="1" string="Technicians" />
          </tokens>
        </chunking>
        <chunking id="7" string="will be more certain Wednesday" type="VP">
          <tokens>
            <token id="2" string="will" />
            <token id="3" string="be" />
            <token id="4" string="more" />
            <token id="5" string="certain" />
            <token id="6" string="Wednesday" />
          </tokens>
        </chunking>
        <chunking id="8" string="the rough line-up" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="rough" />
            <token id="13" string="line-up" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">certain</governor>
          <dependent id="1">Technicians</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">certain</governor>
          <dependent id="2">will</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">certain</governor>
          <dependent id="3">be</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">certain</governor>
          <dependent id="4">more</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">certain</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="5">certain</governor>
          <dependent id="6">Wednesday</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">certain</governor>
          <dependent id="8">but</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">called</governor>
          <dependent id="9">they</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">certain</governor>
          <dependent id="10">called</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">line-up</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">line-up</governor>
          <dependent id="12">rough</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="15">exceptional</governor>
          <dependent id="13">line-up</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="10">called</governor>
          <dependent id="15">exceptional</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Wednesday" type="DATE" score="0.0">
          <tokens>
            <token id="6" string="Wednesday" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>The workers will now bore out a one-yard hole.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="workers" lemma="worker" stem="worker" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="5" string="bore" lemma="bear" stem="bore" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="one-yard" lemma="one-yard" stem="one-yard" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="hole" lemma="hole" stem="hole" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NNS workers)) (VP (MD will) (S (ADVP (RB now)) (VP (VBN bore) (PRT (RP out)) (NP (DT a) (JJ one-yard) (NN hole))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a one-yard hole" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="one-yard" />
            <token id="9" string="hole" />
          </tokens>
        </chunking>
        <chunking id="2" string="bore out a one-yard hole" type="VP">
          <tokens>
            <token id="5" string="bore" />
            <token id="6" string="out" />
            <token id="7" string="a" />
            <token id="8" string="one-yard" />
            <token id="9" string="hole" />
          </tokens>
        </chunking>
        <chunking id="3" string="will now bore out a one-yard hole" type="VP">
          <tokens>
            <token id="3" string="will" />
            <token id="4" string="now" />
            <token id="5" string="bore" />
            <token id="6" string="out" />
            <token id="7" string="a" />
            <token id="8" string="one-yard" />
            <token id="9" string="hole" />
          </tokens>
        </chunking>
        <chunking id="4" string="The workers" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="workers" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">workers</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">will</governor>
          <dependent id="2">workers</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">will</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">bore</governor>
          <dependent id="4">now</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="3">will</governor>
          <dependent id="5">bore</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="5">bore</governor>
          <dependent id="6">out</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">hole</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">hole</governor>
          <dependent id="8">one-yard</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">bore</governor>
          <dependent id="9">hole</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="now" type="DATE" score="0.0">
          <tokens>
            <token id="4" string="now" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="17" has_coreference="false">
      <content>Tunnelers are expected to walk through and greet each other with handshakes in a few weeks.</content>
      <tokens>
        <token id="1" string="Tunnelers" lemma="tunneler" stem="tunnel" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="expected" lemma="expect" stem="expect" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="walk" lemma="walk" stem="walk" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="greet" lemma="greet" stem="greet" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="each" lemma="each" stem="each" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="handshakes" lemma="handshake" stem="handshak" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="15" string="few" lemma="few" stem="few" pos="JJ" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="16" string="weeks" lemma="week" stem="week" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNS Tunnelers)) (VP (VBP are) (VP (VBN expected) (S (VP (TO to) (VP (VP (VB walk) (PP (IN through))) (CC and) (VP (VB greet) (NP (DT each) (JJ other)) (PP (IN with) (NP (NP (NNS handshakes)) (PP (IN in) (NP (DT a) (JJ few) (NNS weeks))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="handshakes in a few weeks" type="NP">
          <tokens>
            <token id="12" string="handshakes" />
            <token id="13" string="in" />
            <token id="14" string="a" />
            <token id="15" string="few" />
            <token id="16" string="weeks" />
          </tokens>
        </chunking>
        <chunking id="2" string="expected to walk through and greet each other with handshakes in a few weeks" type="VP">
          <tokens>
            <token id="3" string="expected" />
            <token id="4" string="to" />
            <token id="5" string="walk" />
            <token id="6" string="through" />
            <token id="7" string="and" />
            <token id="8" string="greet" />
            <token id="9" string="each" />
            <token id="10" string="other" />
            <token id="11" string="with" />
            <token id="12" string="handshakes" />
            <token id="13" string="in" />
            <token id="14" string="a" />
            <token id="15" string="few" />
            <token id="16" string="weeks" />
          </tokens>
        </chunking>
        <chunking id="3" string="walk through" type="VP">
          <tokens>
            <token id="5" string="walk" />
            <token id="6" string="through" />
          </tokens>
        </chunking>
        <chunking id="4" string="each other" type="NP">
          <tokens>
            <token id="9" string="each" />
            <token id="10" string="other" />
          </tokens>
        </chunking>
        <chunking id="5" string="handshakes" type="NP">
          <tokens>
            <token id="12" string="handshakes" />
          </tokens>
        </chunking>
        <chunking id="6" string="greet each other with handshakes in a few weeks" type="VP">
          <tokens>
            <token id="8" string="greet" />
            <token id="9" string="each" />
            <token id="10" string="other" />
            <token id="11" string="with" />
            <token id="12" string="handshakes" />
            <token id="13" string="in" />
            <token id="14" string="a" />
            <token id="15" string="few" />
            <token id="16" string="weeks" />
          </tokens>
        </chunking>
        <chunking id="7" string="are expected to walk through and greet each other with handshakes in a few weeks" type="VP">
          <tokens>
            <token id="2" string="are" />
            <token id="3" string="expected" />
            <token id="4" string="to" />
            <token id="5" string="walk" />
            <token id="6" string="through" />
            <token id="7" string="and" />
            <token id="8" string="greet" />
            <token id="9" string="each" />
            <token id="10" string="other" />
            <token id="11" string="with" />
            <token id="12" string="handshakes" />
            <token id="13" string="in" />
            <token id="14" string="a" />
            <token id="15" string="few" />
            <token id="16" string="weeks" />
          </tokens>
        </chunking>
        <chunking id="8" string="a few weeks" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="few" />
            <token id="16" string="weeks" />
          </tokens>
        </chunking>
        <chunking id="9" string="walk through and greet each other with handshakes in a few weeks" type="VP">
          <tokens>
            <token id="5" string="walk" />
            <token id="6" string="through" />
            <token id="7" string="and" />
            <token id="8" string="greet" />
            <token id="9" string="each" />
            <token id="10" string="other" />
            <token id="11" string="with" />
            <token id="12" string="handshakes" />
            <token id="13" string="in" />
            <token id="14" string="a" />
            <token id="15" string="few" />
            <token id="16" string="weeks" />
          </tokens>
        </chunking>
        <chunking id="10" string="to walk through and greet each other with handshakes in a few weeks" type="VP">
          <tokens>
            <token id="4" string="to" />
            <token id="5" string="walk" />
            <token id="6" string="through" />
            <token id="7" string="and" />
            <token id="8" string="greet" />
            <token id="9" string="each" />
            <token id="10" string="other" />
            <token id="11" string="with" />
            <token id="12" string="handshakes" />
            <token id="13" string="in" />
            <token id="14" string="a" />
            <token id="15" string="few" />
            <token id="16" string="weeks" />
          </tokens>
        </chunking>
        <chunking id="11" string="Tunnelers" type="NP">
          <tokens>
            <token id="1" string="Tunnelers" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="3">expected</governor>
          <dependent id="1">Tunnelers</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="3">expected</governor>
          <dependent id="2">are</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">expected</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">walk</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">expected</governor>
          <dependent id="5">walk</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">walk</governor>
          <dependent id="6">through</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">walk</governor>
          <dependent id="7">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">walk</governor>
          <dependent id="8">greet</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">other</governor>
          <dependent id="9">each</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">greet</governor>
          <dependent id="10">other</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">handshakes</governor>
          <dependent id="11">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">greet</governor>
          <dependent id="12">handshakes</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">weeks</governor>
          <dependent id="13">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">weeks</governor>
          <dependent id="14">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">weeks</governor>
          <dependent id="15">few</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">handshakes</governor>
          <dependent id="16">weeks</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="a few weeks" type="DURATION" score="0.0">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="few" />
            <token id="16" string="weeks" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="18" has_coreference="true">
      <content>The tunneling machine on the French side will then guide itself by laser toward the British machine, ensuring perfect alignment.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="tunneling" lemma="tunneling" stem="tunnel" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="machine" lemma="machine" stem="machin" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="French" lemma="french" stem="french" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="true" is_refers="false" />
        <token id="7" string="side" lemma="side" stem="side" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="guide" lemma="guide" stem="guid" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="itself" lemma="itself" stem="itself" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="laser" lemma="laser" stem="laser" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="toward" lemma="toward" stem="toward" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="British" lemma="british" stem="british" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="17" string="machine" lemma="machine" stem="machin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="ensuring" lemma="ensure" stem="ensur" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="perfect" lemma="perfect" stem="perfect" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="alignment" lemma="alignment" stem="align" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (NN tunneling) (NN machine)) (PP (IN on) (NP (DT the) (JJ French) (NN side)))) (VP (MD will) (RB then) (VP (VB guide) (NP (PRP itself)) (PP (IN by) (NP (NP (NN laser)) (PP (IN toward) (NP (DT the) (JJ British) (NN machine))))) (, ,) (S (VP (VBG ensuring) (NP (JJ perfect) (NN alignment)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="itself" type="NP">
          <tokens>
            <token id="11" string="itself" />
          </tokens>
        </chunking>
        <chunking id="2" string="the British machine" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="British" />
            <token id="17" string="machine" />
          </tokens>
        </chunking>
        <chunking id="3" string="will then guide itself by laser toward the British machine , ensuring perfect alignment" type="VP">
          <tokens>
            <token id="8" string="will" />
            <token id="9" string="then" />
            <token id="10" string="guide" />
            <token id="11" string="itself" />
            <token id="12" string="by" />
            <token id="13" string="laser" />
            <token id="14" string="toward" />
            <token id="15" string="the" />
            <token id="16" string="British" />
            <token id="17" string="machine" />
            <token id="18" string="," />
            <token id="19" string="ensuring" />
            <token id="20" string="perfect" />
            <token id="21" string="alignment" />
          </tokens>
        </chunking>
        <chunking id="4" string="guide itself by laser toward the British machine , ensuring perfect alignment" type="VP">
          <tokens>
            <token id="10" string="guide" />
            <token id="11" string="itself" />
            <token id="12" string="by" />
            <token id="13" string="laser" />
            <token id="14" string="toward" />
            <token id="15" string="the" />
            <token id="16" string="British" />
            <token id="17" string="machine" />
            <token id="18" string="," />
            <token id="19" string="ensuring" />
            <token id="20" string="perfect" />
            <token id="21" string="alignment" />
          </tokens>
        </chunking>
        <chunking id="5" string="laser" type="NP">
          <tokens>
            <token id="13" string="laser" />
          </tokens>
        </chunking>
        <chunking id="6" string="ensuring perfect alignment" type="VP">
          <tokens>
            <token id="19" string="ensuring" />
            <token id="20" string="perfect" />
            <token id="21" string="alignment" />
          </tokens>
        </chunking>
        <chunking id="7" string="the French side" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="French" />
            <token id="7" string="side" />
          </tokens>
        </chunking>
        <chunking id="8" string="The tunneling machine" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="tunneling" />
            <token id="3" string="machine" />
          </tokens>
        </chunking>
        <chunking id="9" string="laser toward the British machine" type="NP">
          <tokens>
            <token id="13" string="laser" />
            <token id="14" string="toward" />
            <token id="15" string="the" />
            <token id="16" string="British" />
            <token id="17" string="machine" />
          </tokens>
        </chunking>
        <chunking id="10" string="perfect alignment" type="NP">
          <tokens>
            <token id="20" string="perfect" />
            <token id="21" string="alignment" />
          </tokens>
        </chunking>
        <chunking id="11" string="The tunneling machine on the French side" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="tunneling" />
            <token id="3" string="machine" />
            <token id="4" string="on" />
            <token id="5" string="the" />
            <token id="6" string="French" />
            <token id="7" string="side" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">machine</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">machine</governor>
          <dependent id="2">tunneling</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">guide</governor>
          <dependent id="3">machine</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">side</governor>
          <dependent id="4">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">side</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">side</governor>
          <dependent id="6">French</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">machine</governor>
          <dependent id="7">side</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="10">guide</governor>
          <dependent id="8">will</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">guide</governor>
          <dependent id="9">then</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">guide</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">guide</governor>
          <dependent id="11">itself</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">laser</governor>
          <dependent id="12">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">guide</governor>
          <dependent id="13">laser</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">machine</governor>
          <dependent id="14">toward</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">machine</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">machine</governor>
          <dependent id="16">British</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">laser</governor>
          <dependent id="17">machine</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="10">guide</governor>
          <dependent id="19">ensuring</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">alignment</governor>
          <dependent id="20">perfect</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">ensuring</governor>
          <dependent id="21">alignment</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="French" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="6" string="French" />
          </tokens>
        </entity>
        <entity id="2" string="British" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="16" string="British" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="19" has_coreference="true">
      <content>Thatcher and French President Francois Mitterrand will meet mid-tunnel on Jan. 26.</content>
      <tokens>
        <token id="1" string="Thatcher" lemma="Thatcher" stem="thatcher" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="French" lemma="French" stem="french" pos="NNP" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="4" string="President" lemma="President" stem="presid" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="false" is_refers="false" />
        <token id="5" string="Francois" lemma="Francois" stem="francoi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="6" string="Mitterrand" lemma="Mitterrand" stem="mitterrand" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="7" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="meet" lemma="meet" stem="meet" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="mid-tunnel" lemma="mid-tunnel" stem="mid-tunnel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Jan." lemma="Jan." stem="jan." pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="12" string="26" lemma="26" stem="26" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Thatcher) (CC and) (NNP French) (NNP President) (NNP Francois) (NNP Mitterrand)) (VP (MD will) (VP (VB meet) (NP (NN mid-tunnel)) (PP (IN on) (NP (NNP Jan.) (CD 26))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="will meet mid-tunnel on Jan. 26" type="VP">
          <tokens>
            <token id="7" string="will" />
            <token id="8" string="meet" />
            <token id="9" string="mid-tunnel" />
            <token id="10" string="on" />
            <token id="11" string="Jan." />
            <token id="12" string="26" />
          </tokens>
        </chunking>
        <chunking id="2" string="meet mid-tunnel on Jan. 26" type="VP">
          <tokens>
            <token id="8" string="meet" />
            <token id="9" string="mid-tunnel" />
            <token id="10" string="on" />
            <token id="11" string="Jan." />
            <token id="12" string="26" />
          </tokens>
        </chunking>
        <chunking id="3" string="mid-tunnel" type="NP">
          <tokens>
            <token id="9" string="mid-tunnel" />
          </tokens>
        </chunking>
        <chunking id="4" string="Thatcher and French President Francois Mitterrand" type="NP">
          <tokens>
            <token id="1" string="Thatcher" />
            <token id="2" string="and" />
            <token id="3" string="French" />
            <token id="4" string="President" />
            <token id="5" string="Francois" />
            <token id="6" string="Mitterrand" />
          </tokens>
        </chunking>
        <chunking id="5" string="Jan. 26" type="NP">
          <tokens>
            <token id="11" string="Jan." />
            <token id="12" string="26" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="6">Mitterrand</governor>
          <dependent id="1">Thatcher</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="1">Thatcher</governor>
          <dependent id="2">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="1">Thatcher</governor>
          <dependent id="3">French</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Mitterrand</governor>
          <dependent id="4">President</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Mitterrand</governor>
          <dependent id="5">Francois</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">meet</governor>
          <dependent id="6">Mitterrand</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">meet</governor>
          <dependent id="7">will</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">meet</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">meet</governor>
          <dependent id="9">mid-tunnel</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Jan.</governor>
          <dependent id="10">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">meet</governor>
          <dependent id="11">Jan.</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="11">Jan.</governor>
          <dependent id="12">26</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="French" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="3" string="French" />
          </tokens>
        </entity>
        <entity id="2" string="Francois Mitterrand" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Francois" />
            <token id="6" string="Mitterrand" />
          </tokens>
        </entity>
        <entity id="3" string="Thatcher" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Thatcher" />
          </tokens>
        </entity>
        <entity id="4" string="Jan. 26" type="DATE" score="0.0">
          <tokens>
            <token id="11" string="Jan." />
            <token id="12" string="26" />
          </tokens>
        </entity>
        <entity id="5" string="President" type="TITLE" score="0.0">
          <tokens>
            <token id="4" string="President" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="20" has_coreference="true">
      <content>The linkup came on the maintenance tunnel, the smallest of three tunnels being dug.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="linkup" lemma="linkup" stem="linkup" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="came" lemma="come" stem="came" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="maintenance" lemma="maintenance" stem="mainten" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="tunnel" lemma="tunnel" stem="tunnel" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="smallest" lemma="smallest" stem="smallest" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="three" lemma="three" stem="three" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="13" string="tunnels" lemma="tunnel" stem="tunnel" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="being" lemma="be" stem="be" pos="VBG" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="dug" lemma="dig" stem="dug" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN linkup)) (VP (VBD came) (PP (IN on) (NP (NP (DT the) (NN maintenance) (NN tunnel)) (, ,) (NP (NP (DT the) (JJS smallest)) (PP (IN of) (NP (NP (CD three) (NNS tunnels)) (VP (VBG being) (VP (VBN dug))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the maintenance tunnel , the smallest of three tunnels being dug" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="maintenance" />
            <token id="7" string="tunnel" />
            <token id="8" string="," />
            <token id="9" string="the" />
            <token id="10" string="smallest" />
            <token id="11" string="of" />
            <token id="12" string="three" />
            <token id="13" string="tunnels" />
            <token id="14" string="being" />
            <token id="15" string="dug" />
          </tokens>
        </chunking>
        <chunking id="2" string="the maintenance tunnel" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="maintenance" />
            <token id="7" string="tunnel" />
          </tokens>
        </chunking>
        <chunking id="3" string="three tunnels" type="NP">
          <tokens>
            <token id="12" string="three" />
            <token id="13" string="tunnels" />
          </tokens>
        </chunking>
        <chunking id="4" string="dug" type="VP">
          <tokens>
            <token id="15" string="dug" />
          </tokens>
        </chunking>
        <chunking id="5" string="the smallest" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="smallest" />
          </tokens>
        </chunking>
        <chunking id="6" string="The linkup" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="linkup" />
          </tokens>
        </chunking>
        <chunking id="7" string="the smallest of three tunnels being dug" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="smallest" />
            <token id="11" string="of" />
            <token id="12" string="three" />
            <token id="13" string="tunnels" />
            <token id="14" string="being" />
            <token id="15" string="dug" />
          </tokens>
        </chunking>
        <chunking id="8" string="three tunnels being dug" type="NP">
          <tokens>
            <token id="12" string="three" />
            <token id="13" string="tunnels" />
            <token id="14" string="being" />
            <token id="15" string="dug" />
          </tokens>
        </chunking>
        <chunking id="9" string="being dug" type="VP">
          <tokens>
            <token id="14" string="being" />
            <token id="15" string="dug" />
          </tokens>
        </chunking>
        <chunking id="10" string="came on the maintenance tunnel , the smallest of three tunnels being dug" type="VP">
          <tokens>
            <token id="3" string="came" />
            <token id="4" string="on" />
            <token id="5" string="the" />
            <token id="6" string="maintenance" />
            <token id="7" string="tunnel" />
            <token id="8" string="," />
            <token id="9" string="the" />
            <token id="10" string="smallest" />
            <token id="11" string="of" />
            <token id="12" string="three" />
            <token id="13" string="tunnels" />
            <token id="14" string="being" />
            <token id="15" string="dug" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">linkup</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">came</governor>
          <dependent id="2">linkup</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">came</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">tunnel</governor>
          <dependent id="4">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">tunnel</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">tunnel</governor>
          <dependent id="6">maintenance</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">came</governor>
          <dependent id="7">tunnel</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">smallest</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="7">tunnel</governor>
          <dependent id="10">smallest</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">tunnels</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="13">tunnels</governor>
          <dependent id="12">three</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">smallest</governor>
          <dependent id="13">tunnels</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="15">dug</governor>
          <dependent id="14">being</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="13">tunnels</governor>
          <dependent id="15">dug</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="three" type="NUMBER" score="0.0">
          <tokens>
            <token id="12" string="three" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="21" has_coreference="false">
      <content>The other two will handle rail traffic - freight and special piggy-back trains that will carry passengers and cars.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="4" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="handle" lemma="handle" stem="handl" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="rail" lemma="rail" stem="rail" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="traffic" lemma="traffic" stem="traffic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="-" lemma="-" stem="-" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="freight" lemma="freight" stem="freight" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="special" lemma="special" stem="special" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="piggy-back" lemma="piggy-back" stem="piggy-back" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="trains" lemma="train" stem="train" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="carry" lemma="carry" stem="carri" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="passengers" lemma="passenger" stem="passeng" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="cars" lemma="car" stem="car" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (JJ other) (CD two)) (VP (MD will) (VP (VB handle) (NP (NP (NN rail) (NN traffic)) (: -) (NP (NP (NN freight) (CC and) (JJ special) (NN piggy-back) (NNS trains)) (SBAR (WHNP (WDT that)) (S (VP (MD will) (VP (VB carry) (NP (NNS passengers) (CC and) (NNS cars)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="The other two" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="other" />
            <token id="3" string="two" />
          </tokens>
        </chunking>
        <chunking id="2" string="carry passengers and cars" type="VP">
          <tokens>
            <token id="16" string="carry" />
            <token id="17" string="passengers" />
            <token id="18" string="and" />
            <token id="19" string="cars" />
          </tokens>
        </chunking>
        <chunking id="3" string="will carry passengers and cars" type="VP">
          <tokens>
            <token id="15" string="will" />
            <token id="16" string="carry" />
            <token id="17" string="passengers" />
            <token id="18" string="and" />
            <token id="19" string="cars" />
          </tokens>
        </chunking>
        <chunking id="4" string="freight and special piggy-back trains" type="NP">
          <tokens>
            <token id="9" string="freight" />
            <token id="10" string="and" />
            <token id="11" string="special" />
            <token id="12" string="piggy-back" />
            <token id="13" string="trains" />
          </tokens>
        </chunking>
        <chunking id="5" string="that will carry passengers and cars" type="SBAR">
          <tokens>
            <token id="14" string="that" />
            <token id="15" string="will" />
            <token id="16" string="carry" />
            <token id="17" string="passengers" />
            <token id="18" string="and" />
            <token id="19" string="cars" />
          </tokens>
        </chunking>
        <chunking id="6" string="passengers and cars" type="NP">
          <tokens>
            <token id="17" string="passengers" />
            <token id="18" string="and" />
            <token id="19" string="cars" />
          </tokens>
        </chunking>
        <chunking id="7" string="handle rail traffic - freight and special piggy-back trains that will carry passengers and cars" type="VP">
          <tokens>
            <token id="5" string="handle" />
            <token id="6" string="rail" />
            <token id="7" string="traffic" />
            <token id="8" string="-" />
            <token id="9" string="freight" />
            <token id="10" string="and" />
            <token id="11" string="special" />
            <token id="12" string="piggy-back" />
            <token id="13" string="trains" />
            <token id="14" string="that" />
            <token id="15" string="will" />
            <token id="16" string="carry" />
            <token id="17" string="passengers" />
            <token id="18" string="and" />
            <token id="19" string="cars" />
          </tokens>
        </chunking>
        <chunking id="8" string="rail traffic" type="NP">
          <tokens>
            <token id="6" string="rail" />
            <token id="7" string="traffic" />
          </tokens>
        </chunking>
        <chunking id="9" string="freight and special piggy-back trains that will carry passengers and cars" type="NP">
          <tokens>
            <token id="9" string="freight" />
            <token id="10" string="and" />
            <token id="11" string="special" />
            <token id="12" string="piggy-back" />
            <token id="13" string="trains" />
            <token id="14" string="that" />
            <token id="15" string="will" />
            <token id="16" string="carry" />
            <token id="17" string="passengers" />
            <token id="18" string="and" />
            <token id="19" string="cars" />
          </tokens>
        </chunking>
        <chunking id="10" string="will handle rail traffic - freight and special piggy-back trains that will carry passengers and cars" type="VP">
          <tokens>
            <token id="4" string="will" />
            <token id="5" string="handle" />
            <token id="6" string="rail" />
            <token id="7" string="traffic" />
            <token id="8" string="-" />
            <token id="9" string="freight" />
            <token id="10" string="and" />
            <token id="11" string="special" />
            <token id="12" string="piggy-back" />
            <token id="13" string="trains" />
            <token id="14" string="that" />
            <token id="15" string="will" />
            <token id="16" string="carry" />
            <token id="17" string="passengers" />
            <token id="18" string="and" />
            <token id="19" string="cars" />
          </tokens>
        </chunking>
        <chunking id="11" string="rail traffic - freight and special piggy-back trains that will carry passengers and cars" type="NP">
          <tokens>
            <token id="6" string="rail" />
            <token id="7" string="traffic" />
            <token id="8" string="-" />
            <token id="9" string="freight" />
            <token id="10" string="and" />
            <token id="11" string="special" />
            <token id="12" string="piggy-back" />
            <token id="13" string="trains" />
            <token id="14" string="that" />
            <token id="15" string="will" />
            <token id="16" string="carry" />
            <token id="17" string="passengers" />
            <token id="18" string="and" />
            <token id="19" string="cars" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">two</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">two</governor>
          <dependent id="2">other</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">handle</governor>
          <dependent id="3">two</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">handle</governor>
          <dependent id="4">will</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">handle</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">traffic</governor>
          <dependent id="6">rail</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">handle</governor>
          <dependent id="7">traffic</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">trains</governor>
          <dependent id="9">freight</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">freight</governor>
          <dependent id="10">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">freight</governor>
          <dependent id="11">special</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">trains</governor>
          <dependent id="12">piggy-back</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="7">traffic</governor>
          <dependent id="13">trains</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">carry</governor>
          <dependent id="14">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">carry</governor>
          <dependent id="15">will</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="13">trains</governor>
          <dependent id="16">carry</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">carry</governor>
          <dependent id="17">passengers</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="17">passengers</governor>
          <dependent id="18">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">passengers</governor>
          <dependent id="19">cars</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="3" string="two" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="22" has_coreference="false">
      <content>About 80 percent of all the drilling is now complete.</content>
      <tokens>
        <token id="1" string="About" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="80" lemma="80" stem="80" pos="CD" type="Number" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="3" string="percent" lemma="percent" stem="percent" pos="NN" type="Word" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="all" lemma="all" stem="all" pos="PDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="drilling" lemma="drilling" stem="drill" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="10" string="complete" lemma="complete" stem="complet" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN About) (NP (CD 80))) (NP (NP (NN percent)) (PP (IN of) (NP (PDT all) (DT the) (NN drilling)))) (VP (VBZ is) (ADVP (RB now)) (ADJP (JJ complete))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="all the drilling" type="NP">
          <tokens>
            <token id="5" string="all" />
            <token id="6" string="the" />
            <token id="7" string="drilling" />
          </tokens>
        </chunking>
        <chunking id="2" string="percent of all the drilling" type="NP">
          <tokens>
            <token id="3" string="percent" />
            <token id="4" string="of" />
            <token id="5" string="all" />
            <token id="6" string="the" />
            <token id="7" string="drilling" />
          </tokens>
        </chunking>
        <chunking id="3" string="80" type="NP">
          <tokens>
            <token id="2" string="80" />
          </tokens>
        </chunking>
        <chunking id="4" string="percent" type="NP">
          <tokens>
            <token id="3" string="percent" />
          </tokens>
        </chunking>
        <chunking id="5" string="complete" type="ADJP">
          <tokens>
            <token id="10" string="complete" />
          </tokens>
        </chunking>
        <chunking id="6" string="is now complete" type="VP">
          <tokens>
            <token id="8" string="is" />
            <token id="9" string="now" />
            <token id="10" string="complete" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">80</governor>
          <dependent id="1">About</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">complete</governor>
          <dependent id="2">80</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">complete</governor>
          <dependent id="3">percent</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">drilling</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="det:predet">
          <governor id="7">drilling</governor>
          <dependent id="5">all</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">drilling</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">percent</governor>
          <dependent id="7">drilling</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="10">complete</governor>
          <dependent id="8">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">complete</governor>
          <dependent id="9">now</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">complete</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="now" type="DATE" score="0.0">
          <tokens>
            <token id="9" string="now" />
          </tokens>
        </entity>
        <entity id="2" string="80 percent" type="PERCENT" score="0.0">
          <tokens>
            <token id="2" string="80" />
            <token id="3" string="percent" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="23" has_coreference="true">
      <content>Eight workers suffered injures, two seriously, about 90 minutes after Tuesday&amp;apost;s linkup when a tractor rolled over on them in a service gallery, authorities in nearby Sangatte reported.</content>
      <tokens>
        <token id="1" string="Eight" lemma="eight" stem="eight" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="2" string="workers" lemma="worker" stem="worker" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="suffered" lemma="suffer" stem="suffer" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="injures" lemma="injure" stem="injur" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="7" string="seriously" lemma="seriously" stem="serious" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="10" string="90" lemma="90" stem="90" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="11" string="minutes" lemma="minute" stem="minut" pos="NNS" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="12" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="13" string="Tuesday" lemma="Tuesday" stem="tuesdai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="14" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="linkup" lemma="linkup" stem="linkup" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="tractor" lemma="tractor" stem="tractor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="rolled" lemma="roll" stem="roll" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="over" lemma="over" stem="over" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="service" lemma="service" stem="servic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="gallery" lemma="gallery" stem="galleri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="authorities" lemma="authority" stem="author" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="nearby" lemma="nearby" stem="nearbi" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="31" string="Sangatte" lemma="Sangatte" stem="sangatt" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="32" string="reported" lemma="report" stem="report" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (CD Eight) (NNS workers)) (VP (VBD suffered) (SBAR (S (VP (VBZ injures) (, ,) (ADVP (NP (CD two)) (RB seriously)) (, ,) (PP (IN about) (NP (NP (CD 90) (NNS minutes)) (PP (IN after) (NP (NP (NNP Tuesday) (POS 's)) (NN linkup))) (SBAR (WHADVP (WRB when)) (S (NP (DT a) (NN tractor)) (VP (VBD rolled) (PRT (RP over)) (PP (IN on) (NP (PRP them))) (PP (IN in) (NP (DT a) (NN service) (NN gallery))))))))))))) (, ,) (NP (NP (NNS authorities)) (PP (IN in) (NP (JJ nearby) (NNP Sangatte)))) (VP (VBD reported)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a tractor" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="tractor" />
          </tokens>
        </chunking>
        <chunking id="2" string="Tuesday 's" type="NP">
          <tokens>
            <token id="13" string="Tuesday" />
            <token id="14" string="'s" />
          </tokens>
        </chunking>
        <chunking id="3" string="two" type="NP">
          <tokens>
            <token id="6" string="two" />
          </tokens>
        </chunking>
        <chunking id="4" string="injures , two seriously , about 90 minutes after Tuesday 's linkup when a tractor rolled over on them in a service gallery" type="SBAR">
          <tokens>
            <token id="4" string="injures" />
            <token id="5" string="," />
            <token id="6" string="two" />
            <token id="7" string="seriously" />
            <token id="8" string="," />
            <token id="9" string="about" />
            <token id="10" string="90" />
            <token id="11" string="minutes" />
            <token id="12" string="after" />
            <token id="13" string="Tuesday" />
            <token id="14" string="'s" />
            <token id="15" string="linkup" />
            <token id="16" string="when" />
            <token id="17" string="a" />
            <token id="18" string="tractor" />
            <token id="19" string="rolled" />
            <token id="20" string="over" />
            <token id="21" string="on" />
            <token id="22" string="them" />
            <token id="23" string="in" />
            <token id="24" string="a" />
            <token id="25" string="service" />
            <token id="26" string="gallery" />
          </tokens>
        </chunking>
        <chunking id="5" string="a service gallery" type="NP">
          <tokens>
            <token id="24" string="a" />
            <token id="25" string="service" />
            <token id="26" string="gallery" />
          </tokens>
        </chunking>
        <chunking id="6" string="suffered injures , two seriously , about 90 minutes after Tuesday 's linkup when a tractor rolled over on them in a service gallery" type="VP">
          <tokens>
            <token id="3" string="suffered" />
            <token id="4" string="injures" />
            <token id="5" string="," />
            <token id="6" string="two" />
            <token id="7" string="seriously" />
            <token id="8" string="," />
            <token id="9" string="about" />
            <token id="10" string="90" />
            <token id="11" string="minutes" />
            <token id="12" string="after" />
            <token id="13" string="Tuesday" />
            <token id="14" string="'s" />
            <token id="15" string="linkup" />
            <token id="16" string="when" />
            <token id="17" string="a" />
            <token id="18" string="tractor" />
            <token id="19" string="rolled" />
            <token id="20" string="over" />
            <token id="21" string="on" />
            <token id="22" string="them" />
            <token id="23" string="in" />
            <token id="24" string="a" />
            <token id="25" string="service" />
            <token id="26" string="gallery" />
          </tokens>
        </chunking>
        <chunking id="7" string="them" type="NP">
          <tokens>
            <token id="22" string="them" />
          </tokens>
        </chunking>
        <chunking id="8" string="nearby Sangatte" type="NP">
          <tokens>
            <token id="30" string="nearby" />
            <token id="31" string="Sangatte" />
          </tokens>
        </chunking>
        <chunking id="9" string="when" type="WHADVP">
          <tokens>
            <token id="16" string="when" />
          </tokens>
        </chunking>
        <chunking id="10" string="authorities" type="NP">
          <tokens>
            <token id="28" string="authorities" />
          </tokens>
        </chunking>
        <chunking id="11" string="Eight workers" type="NP">
          <tokens>
            <token id="1" string="Eight" />
            <token id="2" string="workers" />
          </tokens>
        </chunking>
        <chunking id="12" string="Tuesday 's linkup" type="NP">
          <tokens>
            <token id="13" string="Tuesday" />
            <token id="14" string="'s" />
            <token id="15" string="linkup" />
          </tokens>
        </chunking>
        <chunking id="13" string="rolled over on them in a service gallery" type="VP">
          <tokens>
            <token id="19" string="rolled" />
            <token id="20" string="over" />
            <token id="21" string="on" />
            <token id="22" string="them" />
            <token id="23" string="in" />
            <token id="24" string="a" />
            <token id="25" string="service" />
            <token id="26" string="gallery" />
          </tokens>
        </chunking>
        <chunking id="14" string="authorities in nearby Sangatte" type="NP">
          <tokens>
            <token id="28" string="authorities" />
            <token id="29" string="in" />
            <token id="30" string="nearby" />
            <token id="31" string="Sangatte" />
          </tokens>
        </chunking>
        <chunking id="15" string="90 minutes" type="NP">
          <tokens>
            <token id="10" string="90" />
            <token id="11" string="minutes" />
          </tokens>
        </chunking>
        <chunking id="16" string="reported" type="VP">
          <tokens>
            <token id="32" string="reported" />
          </tokens>
        </chunking>
        <chunking id="17" string="when a tractor rolled over on them in a service gallery" type="SBAR">
          <tokens>
            <token id="16" string="when" />
            <token id="17" string="a" />
            <token id="18" string="tractor" />
            <token id="19" string="rolled" />
            <token id="20" string="over" />
            <token id="21" string="on" />
            <token id="22" string="them" />
            <token id="23" string="in" />
            <token id="24" string="a" />
            <token id="25" string="service" />
            <token id="26" string="gallery" />
          </tokens>
        </chunking>
        <chunking id="18" string="90 minutes after Tuesday 's linkup when a tractor rolled over on them in a service gallery" type="NP">
          <tokens>
            <token id="10" string="90" />
            <token id="11" string="minutes" />
            <token id="12" string="after" />
            <token id="13" string="Tuesday" />
            <token id="14" string="'s" />
            <token id="15" string="linkup" />
            <token id="16" string="when" />
            <token id="17" string="a" />
            <token id="18" string="tractor" />
            <token id="19" string="rolled" />
            <token id="20" string="over" />
            <token id="21" string="on" />
            <token id="22" string="them" />
            <token id="23" string="in" />
            <token id="24" string="a" />
            <token id="25" string="service" />
            <token id="26" string="gallery" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nummod">
          <governor id="2">workers</governor>
          <dependent id="1">Eight</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">suffered</governor>
          <dependent id="2">workers</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="32">reported</governor>
          <dependent id="3">suffered</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">suffered</governor>
          <dependent id="4">injures</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="7">seriously</governor>
          <dependent id="6">two</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">injures</governor>
          <dependent id="7">seriously</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">minutes</governor>
          <dependent id="9">about</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="11">minutes</governor>
          <dependent id="10">90</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">injures</governor>
          <dependent id="11">minutes</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">linkup</governor>
          <dependent id="12">after</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="15">linkup</governor>
          <dependent id="13">Tuesday</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Tuesday</governor>
          <dependent id="14">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">minutes</governor>
          <dependent id="15">linkup</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="19">rolled</governor>
          <dependent id="16">when</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">tractor</governor>
          <dependent id="17">a</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">rolled</governor>
          <dependent id="18">tractor</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="11">minutes</governor>
          <dependent id="19">rolled</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="19">rolled</governor>
          <dependent id="20">over</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">them</governor>
          <dependent id="21">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">rolled</governor>
          <dependent id="22">them</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">gallery</governor>
          <dependent id="23">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">gallery</governor>
          <dependent id="24">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">gallery</governor>
          <dependent id="25">service</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">rolled</governor>
          <dependent id="26">gallery</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="32">reported</governor>
          <dependent id="28">authorities</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">Sangatte</governor>
          <dependent id="29">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="31">Sangatte</governor>
          <dependent id="30">nearby</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">authorities</governor>
          <dependent id="31">Sangatte</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="32">reported</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Eight" type="NUMBER" score="0.0">
          <tokens>
            <token id="1" string="Eight" />
          </tokens>
        </entity>
        <entity id="2" string="about 90 minutes after Tuesday" type="DATE" score="0.0">
          <tokens>
            <token id="9" string="about" />
            <token id="10" string="90" />
            <token id="11" string="minutes" />
            <token id="12" string="after" />
            <token id="13" string="Tuesday" />
          </tokens>
        </entity>
        <entity id="3" string="Sangatte" type="LOCATION" score="0.0">
          <tokens>
            <token id="31" string="Sangatte" />
          </tokens>
        </entity>
        <entity id="4" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="6" string="two" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="24" has_coreference="false">
      <content>Since the tunnel construction began in 1987 there have been seven accidental deaths on the British side and two on the French side.</content>
      <tokens>
        <token id="1" string="Since" lemma="since" stem="sinc" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="tunnel" lemma="tunnel" stem="tunnel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="construction" lemma="construction" stem="construct" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="began" lemma="begin" stem="began" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="1987" lemma="1987" stem="1987" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="8" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="seven" lemma="seven" stem="seven" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="12" string="accidental" lemma="accidental" stem="accident" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="deaths" lemma="death" stem="death" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="British" lemma="british" stem="british" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="true" is_refers="false" />
        <token id="17" string="side" lemma="side" stem="side" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="20" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="French" lemma="french" stem="french" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="23" string="side" lemma="side" stem="side" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN Since) (S (NP (DT the) (NN tunnel) (NN construction)) (VP (VBD began) (PP (IN in) (NP (CD 1987)))))) (NP (EX there)) (VP (VBP have) (VP (VBN been) (NP (NP (CD seven) (JJ accidental) (NNS deaths)) (PP (IN on) (NP (NP (DT the) (JJ British) (NN side)) (CC and) (NP (CD two))))) (PP (IN on) (NP (DT the) (JJ French) (NN side))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="seven accidental deaths" type="NP">
          <tokens>
            <token id="11" string="seven" />
            <token id="12" string="accidental" />
            <token id="13" string="deaths" />
          </tokens>
        </chunking>
        <chunking id="2" string="seven accidental deaths on the British side and two" type="NP">
          <tokens>
            <token id="11" string="seven" />
            <token id="12" string="accidental" />
            <token id="13" string="deaths" />
            <token id="14" string="on" />
            <token id="15" string="the" />
            <token id="16" string="British" />
            <token id="17" string="side" />
            <token id="18" string="and" />
            <token id="19" string="two" />
          </tokens>
        </chunking>
        <chunking id="3" string="the French side" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="French" />
            <token id="23" string="side" />
          </tokens>
        </chunking>
        <chunking id="4" string="two" type="NP">
          <tokens>
            <token id="19" string="two" />
          </tokens>
        </chunking>
        <chunking id="5" string="the tunnel construction" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="tunnel" />
            <token id="4" string="construction" />
          </tokens>
        </chunking>
        <chunking id="6" string="there" type="NP">
          <tokens>
            <token id="8" string="there" />
          </tokens>
        </chunking>
        <chunking id="7" string="1987" type="NP">
          <tokens>
            <token id="7" string="1987" />
          </tokens>
        </chunking>
        <chunking id="8" string="began in 1987" type="VP">
          <tokens>
            <token id="5" string="began" />
            <token id="6" string="in" />
            <token id="7" string="1987" />
          </tokens>
        </chunking>
        <chunking id="9" string="the British side and two" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="British" />
            <token id="17" string="side" />
            <token id="18" string="and" />
            <token id="19" string="two" />
          </tokens>
        </chunking>
        <chunking id="10" string="Since the tunnel construction began in 1987" type="SBAR">
          <tokens>
            <token id="1" string="Since" />
            <token id="2" string="the" />
            <token id="3" string="tunnel" />
            <token id="4" string="construction" />
            <token id="5" string="began" />
            <token id="6" string="in" />
            <token id="7" string="1987" />
          </tokens>
        </chunking>
        <chunking id="11" string="the British side" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="British" />
            <token id="17" string="side" />
          </tokens>
        </chunking>
        <chunking id="12" string="have been seven accidental deaths on the British side and two on the French side" type="VP">
          <tokens>
            <token id="9" string="have" />
            <token id="10" string="been" />
            <token id="11" string="seven" />
            <token id="12" string="accidental" />
            <token id="13" string="deaths" />
            <token id="14" string="on" />
            <token id="15" string="the" />
            <token id="16" string="British" />
            <token id="17" string="side" />
            <token id="18" string="and" />
            <token id="19" string="two" />
            <token id="20" string="on" />
            <token id="21" string="the" />
            <token id="22" string="French" />
            <token id="23" string="side" />
          </tokens>
        </chunking>
        <chunking id="13" string="been seven accidental deaths on the British side and two on the French side" type="VP">
          <tokens>
            <token id="10" string="been" />
            <token id="11" string="seven" />
            <token id="12" string="accidental" />
            <token id="13" string="deaths" />
            <token id="14" string="on" />
            <token id="15" string="the" />
            <token id="16" string="British" />
            <token id="17" string="side" />
            <token id="18" string="and" />
            <token id="19" string="two" />
            <token id="20" string="on" />
            <token id="21" string="the" />
            <token id="22" string="French" />
            <token id="23" string="side" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="5">began</governor>
          <dependent id="1">Since</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">construction</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">construction</governor>
          <dependent id="3">tunnel</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">began</governor>
          <dependent id="4">construction</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="13">deaths</governor>
          <dependent id="5">began</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">1987</governor>
          <dependent id="6">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">began</governor>
          <dependent id="7">1987</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="13">deaths</governor>
          <dependent id="8">there</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="13">deaths</governor>
          <dependent id="9">have</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="13">deaths</governor>
          <dependent id="10">been</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="13">deaths</governor>
          <dependent id="11">seven</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">deaths</governor>
          <dependent id="12">accidental</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">deaths</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">side</governor>
          <dependent id="14">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">side</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">side</governor>
          <dependent id="16">British</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">deaths</governor>
          <dependent id="17">side</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="17">side</governor>
          <dependent id="18">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">side</governor>
          <dependent id="19">two</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">side</governor>
          <dependent id="20">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">side</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">side</governor>
          <dependent id="22">French</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">deaths</governor>
          <dependent id="23">side</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="French" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="22" string="French" />
          </tokens>
        </entity>
        <entity id="2" string="1987" type="DATE" score="0.0">
          <tokens>
            <token id="7" string="1987" />
          </tokens>
        </entity>
        <entity id="3" string="British" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="16" string="British" />
          </tokens>
        </entity>
        <entity id="4" string="seven" type="NUMBER" score="0.0">
          <tokens>
            <token id="11" string="seven" />
          </tokens>
        </entity>
        <entity id="5" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="19" string="two" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="25" has_coreference="true">
      <content>The tunnel&amp;apost;s cost has soared from an initial estimate of $9.4 billion to $16.7 billion, including an extra $1.97 billion in case of unforeseen cost overruns.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="tunnel" lemma="tunnel" stem="tunnel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="cost" lemma="cost" stem="cost" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="soared" lemma="soar" stem="soar" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="initial" lemma="initial" stem="initi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="estimate" lemma="estimate" stem="estim" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="13" string="9.4" lemma="9.4" stem="9.4" pos="CD" type="Number" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="14" string="billion" lemma="billion" stem="billion" pos="CD" type="Word" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="17" string="16.7" lemma="16.7" stem="16.7" pos="CD" type="Number" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="18" string="billion" lemma="billion" stem="billion" pos="CD" type="Word" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="including" lemma="include" stem="includ" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="extra" lemma="extra" stem="extra" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="24" string="1.97" lemma="1.97" stem="1.97" pos="CD" type="Number" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="25" string="billion" lemma="billion" stem="billion" pos="CD" type="Word" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="26" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="unforeseen" lemma="unforeseen" stem="unforeseen" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="cost" lemma="cost" stem="cost" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="overruns" lemma="overrun" stem="overrun" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (NN tunnel) (POS 's)) (NN cost)) (VP (VBZ has) (VP (VBN soared) (PP (IN from) (NP (NP (DT an) (JJ initial) (NN estimate)) (PP (IN of) (NP (QP ($ $) (CD 9.4) (CD billion) (TO to) ($ $) (CD 16.7) (CD billion)))) (, ,) (PP (VBG including) (NP (NP (DT an) (JJ extra) (QP ($ $) (CD 1.97) (CD billion))) (PP (IN in) (NP (NP (NN case)) (PP (IN of) (NP (JJ unforeseen) (NN cost) (NNS overruns))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="an extra $ 1.97 billion" type="NP">
          <tokens>
            <token id="21" string="an" />
            <token id="22" string="extra" />
            <token id="23" string="$" />
            <token id="24" string="1.97" />
            <token id="25" string="billion" />
          </tokens>
        </chunking>
        <chunking id="2" string="case" type="NP">
          <tokens>
            <token id="27" string="case" />
          </tokens>
        </chunking>
        <chunking id="3" string="The tunnel 's cost" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="tunnel" />
            <token id="3" string="'s" />
            <token id="4" string="cost" />
          </tokens>
        </chunking>
        <chunking id="4" string="has soared from an initial estimate of $ 9.4 billion to $ 16.7 billion , including an extra $ 1.97 billion in case of unforeseen cost overruns" type="VP">
          <tokens>
            <token id="5" string="has" />
            <token id="6" string="soared" />
            <token id="7" string="from" />
            <token id="8" string="an" />
            <token id="9" string="initial" />
            <token id="10" string="estimate" />
            <token id="11" string="of" />
            <token id="12" string="$" />
            <token id="13" string="9.4" />
            <token id="14" string="billion" />
            <token id="15" string="to" />
            <token id="16" string="$" />
            <token id="17" string="16.7" />
            <token id="18" string="billion" />
            <token id="19" string="," />
            <token id="20" string="including" />
            <token id="21" string="an" />
            <token id="22" string="extra" />
            <token id="23" string="$" />
            <token id="24" string="1.97" />
            <token id="25" string="billion" />
            <token id="26" string="in" />
            <token id="27" string="case" />
            <token id="28" string="of" />
            <token id="29" string="unforeseen" />
            <token id="30" string="cost" />
            <token id="31" string="overruns" />
          </tokens>
        </chunking>
        <chunking id="5" string="The tunnel 's" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="tunnel" />
            <token id="3" string="'s" />
          </tokens>
        </chunking>
        <chunking id="6" string="$ 9.4 billion to $ 16.7 billion" type="NP">
          <tokens>
            <token id="12" string="$" />
            <token id="13" string="9.4" />
            <token id="14" string="billion" />
            <token id="15" string="to" />
            <token id="16" string="$" />
            <token id="17" string="16.7" />
            <token id="18" string="billion" />
          </tokens>
        </chunking>
        <chunking id="7" string="an initial estimate of $ 9.4 billion to $ 16.7 billion , including an extra $ 1.97 billion in case of unforeseen cost overruns" type="NP">
          <tokens>
            <token id="8" string="an" />
            <token id="9" string="initial" />
            <token id="10" string="estimate" />
            <token id="11" string="of" />
            <token id="12" string="$" />
            <token id="13" string="9.4" />
            <token id="14" string="billion" />
            <token id="15" string="to" />
            <token id="16" string="$" />
            <token id="17" string="16.7" />
            <token id="18" string="billion" />
            <token id="19" string="," />
            <token id="20" string="including" />
            <token id="21" string="an" />
            <token id="22" string="extra" />
            <token id="23" string="$" />
            <token id="24" string="1.97" />
            <token id="25" string="billion" />
            <token id="26" string="in" />
            <token id="27" string="case" />
            <token id="28" string="of" />
            <token id="29" string="unforeseen" />
            <token id="30" string="cost" />
            <token id="31" string="overruns" />
          </tokens>
        </chunking>
        <chunking id="8" string="soared from an initial estimate of $ 9.4 billion to $ 16.7 billion , including an extra $ 1.97 billion in case of unforeseen cost overruns" type="VP">
          <tokens>
            <token id="6" string="soared" />
            <token id="7" string="from" />
            <token id="8" string="an" />
            <token id="9" string="initial" />
            <token id="10" string="estimate" />
            <token id="11" string="of" />
            <token id="12" string="$" />
            <token id="13" string="9.4" />
            <token id="14" string="billion" />
            <token id="15" string="to" />
            <token id="16" string="$" />
            <token id="17" string="16.7" />
            <token id="18" string="billion" />
            <token id="19" string="," />
            <token id="20" string="including" />
            <token id="21" string="an" />
            <token id="22" string="extra" />
            <token id="23" string="$" />
            <token id="24" string="1.97" />
            <token id="25" string="billion" />
            <token id="26" string="in" />
            <token id="27" string="case" />
            <token id="28" string="of" />
            <token id="29" string="unforeseen" />
            <token id="30" string="cost" />
            <token id="31" string="overruns" />
          </tokens>
        </chunking>
        <chunking id="9" string="an extra $ 1.97 billion in case of unforeseen cost overruns" type="NP">
          <tokens>
            <token id="21" string="an" />
            <token id="22" string="extra" />
            <token id="23" string="$" />
            <token id="24" string="1.97" />
            <token id="25" string="billion" />
            <token id="26" string="in" />
            <token id="27" string="case" />
            <token id="28" string="of" />
            <token id="29" string="unforeseen" />
            <token id="30" string="cost" />
            <token id="31" string="overruns" />
          </tokens>
        </chunking>
        <chunking id="10" string="an initial estimate" type="NP">
          <tokens>
            <token id="8" string="an" />
            <token id="9" string="initial" />
            <token id="10" string="estimate" />
          </tokens>
        </chunking>
        <chunking id="11" string="case of unforeseen cost overruns" type="NP">
          <tokens>
            <token id="27" string="case" />
            <token id="28" string="of" />
            <token id="29" string="unforeseen" />
            <token id="30" string="cost" />
            <token id="31" string="overruns" />
          </tokens>
        </chunking>
        <chunking id="12" string="unforeseen cost overruns" type="NP">
          <tokens>
            <token id="29" string="unforeseen" />
            <token id="30" string="cost" />
            <token id="31" string="overruns" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">tunnel</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">cost</governor>
          <dependent id="2">tunnel</dependent>
        </dependency>
        <dependency type="case">
          <governor id="2">tunnel</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">soared</governor>
          <dependent id="4">cost</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">soared</governor>
          <dependent id="5">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">soared</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">estimate</governor>
          <dependent id="7">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">estimate</governor>
          <dependent id="8">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">estimate</governor>
          <dependent id="9">initial</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">soared</governor>
          <dependent id="10">estimate</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">$</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="16">$</governor>
          <dependent id="12">$</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">$</governor>
          <dependent id="13">9.4</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">$</governor>
          <dependent id="14">billion</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="16">$</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">estimate</governor>
          <dependent id="16">$</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">billion</governor>
          <dependent id="17">16.7</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="16">$</governor>
          <dependent id="18">billion</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">$</governor>
          <dependent id="20">including</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">$</governor>
          <dependent id="21">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">$</governor>
          <dependent id="22">extra</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">estimate</governor>
          <dependent id="23">$</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">billion</governor>
          <dependent id="24">1.97</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="23">$</governor>
          <dependent id="25">billion</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">overruns</governor>
          <dependent id="26">in</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="26">in</governor>
          <dependent id="27">case</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="26">in</governor>
          <dependent id="28">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="31">overruns</governor>
          <dependent id="29">unforeseen</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">overruns</governor>
          <dependent id="30">cost</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">$</governor>
          <dependent id="31">overruns</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="$ 9.4 billion" type="MONEY" score="0.0">
          <tokens>
            <token id="12" string="$" />
            <token id="13" string="9.4" />
            <token id="14" string="billion" />
          </tokens>
        </entity>
        <entity id="2" string="$ 16.7 billion" type="MONEY" score="0.0">
          <tokens>
            <token id="16" string="$" />
            <token id="17" string="16.7" />
            <token id="18" string="billion" />
          </tokens>
        </entity>
        <entity id="3" string="$ 1.97 billion" type="MONEY" score="0.0">
          <tokens>
            <token id="23" string="$" />
            <token id="24" string="1.97" />
            <token id="25" string="billion" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="26" has_coreference="false">
      <content>The digging is accomplished by gargantuan boring machines that bring to mind images from Japanese monster movies.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="digging" lemma="digging" stem="dig" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="accomplished" lemma="accomplish" stem="accomplish" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="gargantuan" lemma="gargantuan" stem="gargantuan" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="boring" lemma="boring" stem="bore" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="machines" lemma="machine" stem="machin" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="bring" lemma="bring" stem="bring" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="mind" lemma="mind" stem="mind" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="images" lemma="image" stem="imag" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="Japanese" lemma="japanese" stem="japanes" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="16" string="monster" lemma="monster" stem="monster" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="movies" lemma="movie" stem="movi" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN digging)) (VP (VBZ is) (VP (VBN accomplished) (PP (IN by) (NP (NP (JJ gargantuan) (JJ boring) (NNS machines)) (SBAR (WHNP (WDT that)) (S (VP (VBP bring) (S (VP (TO to) (VP (VB mind) (NP (NNS images)) (PP (IN from) (NP (JJ Japanese) (NN monster) (NNS movies))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="The digging" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="digging" />
          </tokens>
        </chunking>
        <chunking id="2" string="gargantuan boring machines that bring to mind images from Japanese monster movies" type="NP">
          <tokens>
            <token id="6" string="gargantuan" />
            <token id="7" string="boring" />
            <token id="8" string="machines" />
            <token id="9" string="that" />
            <token id="10" string="bring" />
            <token id="11" string="to" />
            <token id="12" string="mind" />
            <token id="13" string="images" />
            <token id="14" string="from" />
            <token id="15" string="Japanese" />
            <token id="16" string="monster" />
            <token id="17" string="movies" />
          </tokens>
        </chunking>
        <chunking id="3" string="bring to mind images from Japanese monster movies" type="VP">
          <tokens>
            <token id="10" string="bring" />
            <token id="11" string="to" />
            <token id="12" string="mind" />
            <token id="13" string="images" />
            <token id="14" string="from" />
            <token id="15" string="Japanese" />
            <token id="16" string="monster" />
            <token id="17" string="movies" />
          </tokens>
        </chunking>
        <chunking id="4" string="mind images from Japanese monster movies" type="VP">
          <tokens>
            <token id="12" string="mind" />
            <token id="13" string="images" />
            <token id="14" string="from" />
            <token id="15" string="Japanese" />
            <token id="16" string="monster" />
            <token id="17" string="movies" />
          </tokens>
        </chunking>
        <chunking id="5" string="Japanese monster movies" type="NP">
          <tokens>
            <token id="15" string="Japanese" />
            <token id="16" string="monster" />
            <token id="17" string="movies" />
          </tokens>
        </chunking>
        <chunking id="6" string="to mind images from Japanese monster movies" type="VP">
          <tokens>
            <token id="11" string="to" />
            <token id="12" string="mind" />
            <token id="13" string="images" />
            <token id="14" string="from" />
            <token id="15" string="Japanese" />
            <token id="16" string="monster" />
            <token id="17" string="movies" />
          </tokens>
        </chunking>
        <chunking id="7" string="that bring to mind images from Japanese monster movies" type="SBAR">
          <tokens>
            <token id="9" string="that" />
            <token id="10" string="bring" />
            <token id="11" string="to" />
            <token id="12" string="mind" />
            <token id="13" string="images" />
            <token id="14" string="from" />
            <token id="15" string="Japanese" />
            <token id="16" string="monster" />
            <token id="17" string="movies" />
          </tokens>
        </chunking>
        <chunking id="8" string="is accomplished by gargantuan boring machines that bring to mind images from Japanese monster movies" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="accomplished" />
            <token id="5" string="by" />
            <token id="6" string="gargantuan" />
            <token id="7" string="boring" />
            <token id="8" string="machines" />
            <token id="9" string="that" />
            <token id="10" string="bring" />
            <token id="11" string="to" />
            <token id="12" string="mind" />
            <token id="13" string="images" />
            <token id="14" string="from" />
            <token id="15" string="Japanese" />
            <token id="16" string="monster" />
            <token id="17" string="movies" />
          </tokens>
        </chunking>
        <chunking id="9" string="gargantuan boring machines" type="NP">
          <tokens>
            <token id="6" string="gargantuan" />
            <token id="7" string="boring" />
            <token id="8" string="machines" />
          </tokens>
        </chunking>
        <chunking id="10" string="images" type="NP">
          <tokens>
            <token id="13" string="images" />
          </tokens>
        </chunking>
        <chunking id="11" string="accomplished by gargantuan boring machines that bring to mind images from Japanese monster movies" type="VP">
          <tokens>
            <token id="4" string="accomplished" />
            <token id="5" string="by" />
            <token id="6" string="gargantuan" />
            <token id="7" string="boring" />
            <token id="8" string="machines" />
            <token id="9" string="that" />
            <token id="10" string="bring" />
            <token id="11" string="to" />
            <token id="12" string="mind" />
            <token id="13" string="images" />
            <token id="14" string="from" />
            <token id="15" string="Japanese" />
            <token id="16" string="monster" />
            <token id="17" string="movies" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">digging</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="4">accomplished</governor>
          <dependent id="2">digging</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="4">accomplished</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">accomplished</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">machines</governor>
          <dependent id="5">by</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">machines</governor>
          <dependent id="6">gargantuan</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">machines</governor>
          <dependent id="7">boring</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">accomplished</governor>
          <dependent id="8">machines</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">bring</governor>
          <dependent id="9">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="8">machines</governor>
          <dependent id="10">bring</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">mind</governor>
          <dependent id="11">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="10">bring</governor>
          <dependent id="12">mind</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">mind</governor>
          <dependent id="13">images</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">movies</governor>
          <dependent id="14">from</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">movies</governor>
          <dependent id="15">Japanese</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">movies</governor>
          <dependent id="16">monster</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">mind</governor>
          <dependent id="17">movies</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Japanese" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="15" string="Japanese" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="27" has_coreference="false">
      <content>Each resembles a gnawing worm, some three-stories high, with a spinning drill of hundreds of blades.</content>
      <tokens>
        <token id="1" string="Each" lemma="each" stem="each" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="resembles" lemma="resemble" stem="resembl" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="gnawing" lemma="gnawing" stem="gnaw" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="worm" lemma="worm" stem="worm" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="three-stories" lemma="three-stories" stem="three-stori" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="high" lemma="high" stem="high" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="spinning" lemma="spin" stem="spin" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="drill" lemma="drill" stem="drill" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="hundreds" lemma="hundred" stem="hundr" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="blades" lemma="blade" stem="blade" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT Each)) (VP (VBZ resembles) (NP (NP (DT a) (NN gnawing) (NN worm)) (, ,) (ADJP (DT some) (JJ three-stories) (JJ high)) (, ,) (PP (IN with) (NP (NP (DT a) (VBG spinning) (NN drill)) (PP (IN of) (NP (NP (NNS hundreds)) (PP (IN of) (NP (NNS blades))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Each" type="NP">
          <tokens>
            <token id="1" string="Each" />
          </tokens>
        </chunking>
        <chunking id="2" string="blades" type="NP">
          <tokens>
            <token id="18" string="blades" />
          </tokens>
        </chunking>
        <chunking id="3" string="a spinning drill" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="spinning" />
            <token id="14" string="drill" />
          </tokens>
        </chunking>
        <chunking id="4" string="a spinning drill of hundreds of blades" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="spinning" />
            <token id="14" string="drill" />
            <token id="15" string="of" />
            <token id="16" string="hundreds" />
            <token id="17" string="of" />
            <token id="18" string="blades" />
          </tokens>
        </chunking>
        <chunking id="5" string="hundreds" type="NP">
          <tokens>
            <token id="16" string="hundreds" />
          </tokens>
        </chunking>
        <chunking id="6" string="a gnawing worm , some three-stories high , with a spinning drill of hundreds of blades" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="gnawing" />
            <token id="5" string="worm" />
            <token id="6" string="," />
            <token id="7" string="some" />
            <token id="8" string="three-stories" />
            <token id="9" string="high" />
            <token id="10" string="," />
            <token id="11" string="with" />
            <token id="12" string="a" />
            <token id="13" string="spinning" />
            <token id="14" string="drill" />
            <token id="15" string="of" />
            <token id="16" string="hundreds" />
            <token id="17" string="of" />
            <token id="18" string="blades" />
          </tokens>
        </chunking>
        <chunking id="7" string="hundreds of blades" type="NP">
          <tokens>
            <token id="16" string="hundreds" />
            <token id="17" string="of" />
            <token id="18" string="blades" />
          </tokens>
        </chunking>
        <chunking id="8" string="resembles a gnawing worm , some three-stories high , with a spinning drill of hundreds of blades" type="VP">
          <tokens>
            <token id="2" string="resembles" />
            <token id="3" string="a" />
            <token id="4" string="gnawing" />
            <token id="5" string="worm" />
            <token id="6" string="," />
            <token id="7" string="some" />
            <token id="8" string="three-stories" />
            <token id="9" string="high" />
            <token id="10" string="," />
            <token id="11" string="with" />
            <token id="12" string="a" />
            <token id="13" string="spinning" />
            <token id="14" string="drill" />
            <token id="15" string="of" />
            <token id="16" string="hundreds" />
            <token id="17" string="of" />
            <token id="18" string="blades" />
          </tokens>
        </chunking>
        <chunking id="9" string="a gnawing worm" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="gnawing" />
            <token id="5" string="worm" />
          </tokens>
        </chunking>
        <chunking id="10" string="some three-stories high" type="ADJP">
          <tokens>
            <token id="7" string="some" />
            <token id="8" string="three-stories" />
            <token id="9" string="high" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">resembles</governor>
          <dependent id="1">Each</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">resembles</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">worm</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">worm</governor>
          <dependent id="4">gnawing</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="2">resembles</governor>
          <dependent id="5">worm</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">high</governor>
          <dependent id="7">some</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">high</governor>
          <dependent id="8">three-stories</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">worm</governor>
          <dependent id="9">high</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">drill</governor>
          <dependent id="11">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">drill</governor>
          <dependent id="12">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">drill</governor>
          <dependent id="13">spinning</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">worm</governor>
          <dependent id="14">drill</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">hundreds</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">drill</governor>
          <dependent id="16">hundreds</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">blades</governor>
          <dependent id="17">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">hundreds</governor>
          <dependent id="18">blades</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="28" has_coreference="true">
      <content>Mechanical legs slap together the concrete tunnel lining in the wake of the advancing drill head.</content>
      <tokens>
        <token id="1" string="Mechanical" lemma="mechanical" stem="mechan" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="legs" lemma="leg" stem="leg" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="slap" lemma="slap" stem="slap" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="together" lemma="together" stem="togeth" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="concrete" lemma="concrete" stem="concret" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="tunnel" lemma="tunnel" stem="tunnel" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="lining" lemma="lining" stem="line" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="wake" lemma="wake" stem="wake" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="advancing" lemma="advance" stem="advanc" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="drill" lemma="drill" stem="drill" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="head" lemma="head" stem="head" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (JJ Mechanical) (NNS legs)) (VP (NN slap) (NP (NP (ADVP (RB together)) (DT the) (JJ concrete) (NN tunnel) (NN lining)) (PP (IN in) (NP (NP (DT the) (NN wake)) (PP (IN of) (NP (DT the) (VBG advancing) (NN drill) (NN head))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="together the concrete tunnel lining in the wake of the advancing drill head" type="NP">
          <tokens>
            <token id="4" string="together" />
            <token id="5" string="the" />
            <token id="6" string="concrete" />
            <token id="7" string="tunnel" />
            <token id="8" string="lining" />
            <token id="9" string="in" />
            <token id="10" string="the" />
            <token id="11" string="wake" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="advancing" />
            <token id="15" string="drill" />
            <token id="16" string="head" />
          </tokens>
        </chunking>
        <chunking id="2" string="slap together the concrete tunnel lining in the wake of the advancing drill head" type="VP">
          <tokens>
            <token id="3" string="slap" />
            <token id="4" string="together" />
            <token id="5" string="the" />
            <token id="6" string="concrete" />
            <token id="7" string="tunnel" />
            <token id="8" string="lining" />
            <token id="9" string="in" />
            <token id="10" string="the" />
            <token id="11" string="wake" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="advancing" />
            <token id="15" string="drill" />
            <token id="16" string="head" />
          </tokens>
        </chunking>
        <chunking id="3" string="the wake of the advancing drill head" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="wake" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="advancing" />
            <token id="15" string="drill" />
            <token id="16" string="head" />
          </tokens>
        </chunking>
        <chunking id="4" string="the wake" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="wake" />
          </tokens>
        </chunking>
        <chunking id="5" string="Mechanical legs" type="NP">
          <tokens>
            <token id="1" string="Mechanical" />
            <token id="2" string="legs" />
          </tokens>
        </chunking>
        <chunking id="6" string="together the concrete tunnel lining" type="NP">
          <tokens>
            <token id="4" string="together" />
            <token id="5" string="the" />
            <token id="6" string="concrete" />
            <token id="7" string="tunnel" />
            <token id="8" string="lining" />
          </tokens>
        </chunking>
        <chunking id="7" string="the advancing drill head" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="advancing" />
            <token id="15" string="drill" />
            <token id="16" string="head" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="2">legs</governor>
          <dependent id="1">Mechanical</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">slap</governor>
          <dependent id="2">legs</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">slap</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">lining</governor>
          <dependent id="4">together</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">lining</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">lining</governor>
          <dependent id="6">concrete</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">lining</governor>
          <dependent id="7">tunnel</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">slap</governor>
          <dependent id="8">lining</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">wake</governor>
          <dependent id="9">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">wake</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">lining</governor>
          <dependent id="11">wake</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">head</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">head</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">head</governor>
          <dependent id="14">advancing</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">head</governor>
          <dependent id="15">drill</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">wake</governor>
          <dependent id="16">head</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="29" has_coreference="true">
      <content>Whhen its work is done, the drilling machine on the French side will be hauled out in pieces.</content>
      <tokens>
        <token id="1" string="Whhen" lemma="whhen" stem="whhen" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="work" lemma="work" stem="work" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="done" lemma="do" stem="done" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="drilling" lemma="drilling" stem="drill" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="machine" lemma="machine" stem="machin" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="French" lemma="french" stem="french" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="true" is_refers="false" />
        <token id="13" string="side" lemma="side" stem="side" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="hauled" lemma="haul" stem="haul" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="pieces" lemma="piece" stem="piec" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (VB Whhen) (SBAR (S (NP (PRP$ its) (NN work)) (VP (VBZ is) (VP (VBN done))))))) (, ,) (NP (NP (DT the) (NN drilling) (NN machine)) (PP (IN on) (NP (DT the) (JJ French) (NN side)))) (VP (MD will) (VP (VB be) (VP (VBN hauled) (PRT (RP out)) (PP (IN in) (NP (NNS pieces)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="its work is done" type="SBAR">
          <tokens>
            <token id="2" string="its" />
            <token id="3" string="work" />
            <token id="4" string="is" />
            <token id="5" string="done" />
          </tokens>
        </chunking>
        <chunking id="2" string="pieces" type="NP">
          <tokens>
            <token id="19" string="pieces" />
          </tokens>
        </chunking>
        <chunking id="3" string="hauled out in pieces" type="VP">
          <tokens>
            <token id="16" string="hauled" />
            <token id="17" string="out" />
            <token id="18" string="in" />
            <token id="19" string="pieces" />
          </tokens>
        </chunking>
        <chunking id="4" string="will be hauled out in pieces" type="VP">
          <tokens>
            <token id="14" string="will" />
            <token id="15" string="be" />
            <token id="16" string="hauled" />
            <token id="17" string="out" />
            <token id="18" string="in" />
            <token id="19" string="pieces" />
          </tokens>
        </chunking>
        <chunking id="5" string="be hauled out in pieces" type="VP">
          <tokens>
            <token id="15" string="be" />
            <token id="16" string="hauled" />
            <token id="17" string="out" />
            <token id="18" string="in" />
            <token id="19" string="pieces" />
          </tokens>
        </chunking>
        <chunking id="6" string="the drilling machine on the French side" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="drilling" />
            <token id="9" string="machine" />
            <token id="10" string="on" />
            <token id="11" string="the" />
            <token id="12" string="French" />
            <token id="13" string="side" />
          </tokens>
        </chunking>
        <chunking id="7" string="the French side" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="French" />
            <token id="13" string="side" />
          </tokens>
        </chunking>
        <chunking id="8" string="Whhen its work is done" type="VP">
          <tokens>
            <token id="1" string="Whhen" />
            <token id="2" string="its" />
            <token id="3" string="work" />
            <token id="4" string="is" />
            <token id="5" string="done" />
          </tokens>
        </chunking>
        <chunking id="9" string="is done" type="VP">
          <tokens>
            <token id="4" string="is" />
            <token id="5" string="done" />
          </tokens>
        </chunking>
        <chunking id="10" string="its work" type="NP">
          <tokens>
            <token id="2" string="its" />
            <token id="3" string="work" />
          </tokens>
        </chunking>
        <chunking id="11" string="done" type="VP">
          <tokens>
            <token id="5" string="done" />
          </tokens>
        </chunking>
        <chunking id="12" string="the drilling machine" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="drilling" />
            <token id="9" string="machine" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="ccomp">
          <governor id="16">hauled</governor>
          <dependent id="1">Whhen</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="3">work</governor>
          <dependent id="2">its</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="5">done</governor>
          <dependent id="3">work</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="5">done</governor>
          <dependent id="4">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="1">Whhen</governor>
          <dependent id="5">done</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">machine</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">machine</governor>
          <dependent id="8">drilling</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="16">hauled</governor>
          <dependent id="9">machine</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">side</governor>
          <dependent id="10">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">side</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">side</governor>
          <dependent id="12">French</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">machine</governor>
          <dependent id="13">side</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">hauled</governor>
          <dependent id="14">will</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="16">hauled</governor>
          <dependent id="15">be</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="16">hauled</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="16">hauled</governor>
          <dependent id="17">out</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">pieces</governor>
          <dependent id="18">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">hauled</governor>
          <dependent id="19">pieces</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="French" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="12" string="French" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="30" has_coreference="false">
      <content>The one on the British side will dig a side passage, and be buried in cement.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="3" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="British" lemma="british" stem="british" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="6" string="side" lemma="side" stem="side" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="dig" lemma="dig" stem="dig" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="side" lemma="side" stem="side" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="passage" lemma="passage" stem="passag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="buried" lemma="bury" stem="buri" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="cement" lemma="cement" stem="cement" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (CD one)) (PP (IN on) (NP (DT the) (JJ British) (NN side)))) (VP (MD will) (VP (VP (VB dig) (NP (DT a) (JJ side) (NN passage))) (, ,) (CC and) (VP (VB be) (VP (VBN buried) (PP (IN in) (NP (NN cement))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="The one" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="one" />
          </tokens>
        </chunking>
        <chunking id="2" string="buried in cement" type="VP">
          <tokens>
            <token id="15" string="buried" />
            <token id="16" string="in" />
            <token id="17" string="cement" />
          </tokens>
        </chunking>
        <chunking id="3" string="a side passage" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="side" />
            <token id="11" string="passage" />
          </tokens>
        </chunking>
        <chunking id="4" string="the British side" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="British" />
            <token id="6" string="side" />
          </tokens>
        </chunking>
        <chunking id="5" string="dig a side passage , and be buried in cement" type="VP">
          <tokens>
            <token id="8" string="dig" />
            <token id="9" string="a" />
            <token id="10" string="side" />
            <token id="11" string="passage" />
            <token id="12" string="," />
            <token id="13" string="and" />
            <token id="14" string="be" />
            <token id="15" string="buried" />
            <token id="16" string="in" />
            <token id="17" string="cement" />
          </tokens>
        </chunking>
        <chunking id="6" string="be buried in cement" type="VP">
          <tokens>
            <token id="14" string="be" />
            <token id="15" string="buried" />
            <token id="16" string="in" />
            <token id="17" string="cement" />
          </tokens>
        </chunking>
        <chunking id="7" string="dig a side passage" type="VP">
          <tokens>
            <token id="8" string="dig" />
            <token id="9" string="a" />
            <token id="10" string="side" />
            <token id="11" string="passage" />
          </tokens>
        </chunking>
        <chunking id="8" string="will dig a side passage , and be buried in cement" type="VP">
          <tokens>
            <token id="7" string="will" />
            <token id="8" string="dig" />
            <token id="9" string="a" />
            <token id="10" string="side" />
            <token id="11" string="passage" />
            <token id="12" string="," />
            <token id="13" string="and" />
            <token id="14" string="be" />
            <token id="15" string="buried" />
            <token id="16" string="in" />
            <token id="17" string="cement" />
          </tokens>
        </chunking>
        <chunking id="9" string="cement" type="NP">
          <tokens>
            <token id="17" string="cement" />
          </tokens>
        </chunking>
        <chunking id="10" string="The one on the British side" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="one" />
            <token id="3" string="on" />
            <token id="4" string="the" />
            <token id="5" string="British" />
            <token id="6" string="side" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">one</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">dig</governor>
          <dependent id="2">one</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">side</governor>
          <dependent id="3">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">side</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">side</governor>
          <dependent id="5">British</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">one</governor>
          <dependent id="6">side</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">dig</governor>
          <dependent id="7">will</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">dig</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">passage</governor>
          <dependent id="9">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">passage</governor>
          <dependent id="10">side</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">dig</governor>
          <dependent id="11">passage</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">dig</governor>
          <dependent id="13">and</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="15">buried</governor>
          <dependent id="14">be</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">dig</governor>
          <dependent id="15">buried</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">cement</governor>
          <dependent id="16">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">buried</governor>
          <dependent id="17">cement</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="British" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="5" string="British" />
          </tokens>
        </entity>
        <entity id="2" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="2" string="one" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="31" has_coreference="true">
      <content>Officials say it is too costly to extricate the machine.</content>
      <tokens>
        <token id="1" string="Officials" lemma="official" stem="official" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="say" lemma="say" stem="sai" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="too" lemma="too" stem="too" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="costly" lemma="costly" stem="costli" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="extricate" lemma="extricate" stem="extric" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="machine" lemma="machine" stem="machin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNS Officials)) (VP (VBP say) (SBAR (S (NP (PRP it)) (VP (VBZ is) (ADJP (RB too) (JJ costly)) (S (VP (TO to) (VP (VB extricate) (NP (DT the) (NN machine))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="to extricate the machine" type="VP">
          <tokens>
            <token id="7" string="to" />
            <token id="8" string="extricate" />
            <token id="9" string="the" />
            <token id="10" string="machine" />
          </tokens>
        </chunking>
        <chunking id="2" string="is too costly to extricate the machine" type="VP">
          <tokens>
            <token id="4" string="is" />
            <token id="5" string="too" />
            <token id="6" string="costly" />
            <token id="7" string="to" />
            <token id="8" string="extricate" />
            <token id="9" string="the" />
            <token id="10" string="machine" />
          </tokens>
        </chunking>
        <chunking id="3" string="Officials" type="NP">
          <tokens>
            <token id="1" string="Officials" />
          </tokens>
        </chunking>
        <chunking id="4" string="extricate the machine" type="VP">
          <tokens>
            <token id="8" string="extricate" />
            <token id="9" string="the" />
            <token id="10" string="machine" />
          </tokens>
        </chunking>
        <chunking id="5" string="say it is too costly to extricate the machine" type="VP">
          <tokens>
            <token id="2" string="say" />
            <token id="3" string="it" />
            <token id="4" string="is" />
            <token id="5" string="too" />
            <token id="6" string="costly" />
            <token id="7" string="to" />
            <token id="8" string="extricate" />
            <token id="9" string="the" />
            <token id="10" string="machine" />
          </tokens>
        </chunking>
        <chunking id="6" string="it is too costly to extricate the machine" type="SBAR">
          <tokens>
            <token id="3" string="it" />
            <token id="4" string="is" />
            <token id="5" string="too" />
            <token id="6" string="costly" />
            <token id="7" string="to" />
            <token id="8" string="extricate" />
            <token id="9" string="the" />
            <token id="10" string="machine" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="3" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="too costly" type="ADJP">
          <tokens>
            <token id="5" string="too" />
            <token id="6" string="costly" />
          </tokens>
        </chunking>
        <chunking id="9" string="the machine" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="machine" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">say</governor>
          <dependent id="1">Officials</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">say</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">costly</governor>
          <dependent id="3">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">costly</governor>
          <dependent id="4">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">costly</governor>
          <dependent id="5">too</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">say</governor>
          <dependent id="6">costly</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">extricate</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">costly</governor>
          <dependent id="8">extricate</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">machine</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">extricate</governor>
          <dependent id="10">machine</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="32" has_coreference="true">
      <content>The tunnels were joined 13{ miles southeast of Folkestone, England, the British terminus near Dover, and 10 miles northwest of Sangatte, near Calais.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="tunnels" lemma="tunnel" stem="tunnel" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="joined" lemma="join" stem="join" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="13" lemma="13" stem="13" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="6" string="{" lemma="-lcb-" stem="{" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="miles" lemma="mile" stem="mile" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="southeast" lemma="southeast" stem="southeast" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="Folkestone" lemma="Folkestone" stem="folkeston" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="England" lemma="England" stem="england" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="British" lemma="british" stem="british" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="16" string="terminus" lemma="terminus" stem="terminu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="near" lemma="near" stem="near" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="Dover" lemma="Dover" stem="dover" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="10" lemma="10" stem="10" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="22" string="miles" lemma="mile" stem="mile" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="northwest" lemma="northwest" stem="northwest" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="Sangatte" lemma="Sangatte" stem="sangatt" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="26" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="near" lemma="near" stem="near" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="Calais" lemma="Calais" stem="calai" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NNS tunnels)) (VP (VBD were) (VP (VBN joined) (S (NP (NP (NP (CD 13)) (-LRB- -LCB-) (NP (NP (NNS miles) (NN southeast)) (PP (IN of) (NP (NNP Folkestone) (, ,) (NNP England))))) (, ,) (NP (NP (DT the) (JJ British) (NN terminus)) (PP (IN near) (NP (NNP Dover)))) (, ,) (CC and) (ADVP (NP (CD 10) (NNS miles)) (RB northwest) (PP (IN of) (NP (NNP Sangatte)))) (, ,))) (PP (IN near) (NP (NNP Calais))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="13" type="NP">
          <tokens>
            <token id="5" string="13" />
          </tokens>
        </chunking>
        <chunking id="2" string="Calais" type="NP">
          <tokens>
            <token id="28" string="Calais" />
          </tokens>
        </chunking>
        <chunking id="3" string="were joined 13 -LCB- miles southeast of Folkestone , England , the British terminus near Dover , and 10 miles northwest of Sangatte , near Calais" type="VP">
          <tokens>
            <token id="3" string="were" />
            <token id="4" string="joined" />
            <token id="5" string="13" />
            <token id="6" string="{" />
            <token id="7" string="miles" />
            <token id="8" string="southeast" />
            <token id="9" string="of" />
            <token id="10" string="Folkestone" />
            <token id="11" string="," />
            <token id="12" string="England" />
            <token id="13" string="," />
            <token id="14" string="the" />
            <token id="15" string="British" />
            <token id="16" string="terminus" />
            <token id="17" string="near" />
            <token id="18" string="Dover" />
            <token id="19" string="," />
            <token id="20" string="and" />
            <token id="21" string="10" />
            <token id="22" string="miles" />
            <token id="23" string="northwest" />
            <token id="24" string="of" />
            <token id="25" string="Sangatte" />
            <token id="26" string="," />
            <token id="27" string="near" />
            <token id="28" string="Calais" />
          </tokens>
        </chunking>
        <chunking id="4" string="Dover" type="NP">
          <tokens>
            <token id="18" string="Dover" />
          </tokens>
        </chunking>
        <chunking id="5" string="Sangatte" type="NP">
          <tokens>
            <token id="25" string="Sangatte" />
          </tokens>
        </chunking>
        <chunking id="6" string="the British terminus" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="British" />
            <token id="16" string="terminus" />
          </tokens>
        </chunking>
        <chunking id="7" string="13 -LCB- miles southeast of Folkestone , England , the British terminus near Dover , and 10 miles northwest of Sangatte ," type="NP">
          <tokens>
            <token id="5" string="13" />
            <token id="6" string="{" />
            <token id="7" string="miles" />
            <token id="8" string="southeast" />
            <token id="9" string="of" />
            <token id="10" string="Folkestone" />
            <token id="11" string="," />
            <token id="12" string="England" />
            <token id="13" string="," />
            <token id="14" string="the" />
            <token id="15" string="British" />
            <token id="16" string="terminus" />
            <token id="17" string="near" />
            <token id="18" string="Dover" />
            <token id="19" string="," />
            <token id="20" string="and" />
            <token id="21" string="10" />
            <token id="22" string="miles" />
            <token id="23" string="northwest" />
            <token id="24" string="of" />
            <token id="25" string="Sangatte" />
            <token id="26" string="," />
          </tokens>
        </chunking>
        <chunking id="8" string="13 -LCB- miles southeast of Folkestone , England" type="NP">
          <tokens>
            <token id="5" string="13" />
            <token id="6" string="{" />
            <token id="7" string="miles" />
            <token id="8" string="southeast" />
            <token id="9" string="of" />
            <token id="10" string="Folkestone" />
            <token id="11" string="," />
            <token id="12" string="England" />
          </tokens>
        </chunking>
        <chunking id="9" string="the British terminus near Dover" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="British" />
            <token id="16" string="terminus" />
            <token id="17" string="near" />
            <token id="18" string="Dover" />
          </tokens>
        </chunking>
        <chunking id="10" string="10 miles" type="NP">
          <tokens>
            <token id="21" string="10" />
            <token id="22" string="miles" />
          </tokens>
        </chunking>
        <chunking id="11" string="joined 13 -LCB- miles southeast of Folkestone , England , the British terminus near Dover , and 10 miles northwest of Sangatte , near Calais" type="VP">
          <tokens>
            <token id="4" string="joined" />
            <token id="5" string="13" />
            <token id="6" string="{" />
            <token id="7" string="miles" />
            <token id="8" string="southeast" />
            <token id="9" string="of" />
            <token id="10" string="Folkestone" />
            <token id="11" string="," />
            <token id="12" string="England" />
            <token id="13" string="," />
            <token id="14" string="the" />
            <token id="15" string="British" />
            <token id="16" string="terminus" />
            <token id="17" string="near" />
            <token id="18" string="Dover" />
            <token id="19" string="," />
            <token id="20" string="and" />
            <token id="21" string="10" />
            <token id="22" string="miles" />
            <token id="23" string="northwest" />
            <token id="24" string="of" />
            <token id="25" string="Sangatte" />
            <token id="26" string="," />
            <token id="27" string="near" />
            <token id="28" string="Calais" />
          </tokens>
        </chunking>
        <chunking id="12" string="miles southeast of Folkestone , England" type="NP">
          <tokens>
            <token id="7" string="miles" />
            <token id="8" string="southeast" />
            <token id="9" string="of" />
            <token id="10" string="Folkestone" />
            <token id="11" string="," />
            <token id="12" string="England" />
          </tokens>
        </chunking>
        <chunking id="13" string="miles southeast" type="NP">
          <tokens>
            <token id="7" string="miles" />
            <token id="8" string="southeast" />
          </tokens>
        </chunking>
        <chunking id="14" string="The tunnels" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="tunnels" />
          </tokens>
        </chunking>
        <chunking id="15" string="Folkestone , England" type="NP">
          <tokens>
            <token id="10" string="Folkestone" />
            <token id="11" string="," />
            <token id="12" string="England" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">tunnels</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="4">joined</governor>
          <dependent id="2">tunnels</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="4">joined</governor>
          <dependent id="3">were</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">joined</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">joined</governor>
          <dependent id="5">13</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">southeast</governor>
          <dependent id="7">miles</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="5">13</governor>
          <dependent id="8">southeast</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">England</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">England</governor>
          <dependent id="10">Folkestone</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">southeast</governor>
          <dependent id="12">England</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">terminus</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">terminus</governor>
          <dependent id="15">British</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="5">13</governor>
          <dependent id="16">terminus</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">Dover</governor>
          <dependent id="17">near</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">terminus</governor>
          <dependent id="18">Dover</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">13</governor>
          <dependent id="20">and</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="22">miles</governor>
          <dependent id="21">10</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="23">northwest</governor>
          <dependent id="22">miles</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">13</governor>
          <dependent id="23">northwest</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">Sangatte</governor>
          <dependent id="24">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">northwest</governor>
          <dependent id="25">Sangatte</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">Calais</governor>
          <dependent id="27">near</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">joined</governor>
          <dependent id="28">Calais</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="13" type="NUMBER" score="0.0">
          <tokens>
            <token id="5" string="13" />
          </tokens>
        </entity>
        <entity id="2" string="Calais" type="LOCATION" score="0.0">
          <tokens>
            <token id="28" string="Calais" />
          </tokens>
        </entity>
        <entity id="3" string="British" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="15" string="British" />
          </tokens>
        </entity>
        <entity id="4" string="Dover" type="LOCATION" score="0.0">
          <tokens>
            <token id="18" string="Dover" />
          </tokens>
        </entity>
        <entity id="5" string="Sangatte" type="LOCATION" score="0.0">
          <tokens>
            <token id="25" string="Sangatte" />
          </tokens>
        </entity>
        <entity id="6" string="Folkestone" type="LOCATION" score="0.0">
          <tokens>
            <token id="10" string="Folkestone" />
          </tokens>
        </entity>
        <entity id="7" string="England" type="LOCATION" score="0.0">
          <tokens>
            <token id="12" string="England" />
          </tokens>
        </entity>
        <entity id="8" string="10" type="NUMBER" score="0.0">
          <tokens>
            <token id="21" string="10" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="33" has_coreference="true">
      <content>The tunnel starts a few miles inland on each side, accounting for its total length of 31 miles.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="tunnel" lemma="tunnel" stem="tunnel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="starts" lemma="start" stem="start" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="few" lemma="few" stem="few" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="miles" lemma="mile" stem="mile" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="inland" lemma="inland" stem="inland" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="each" lemma="each" stem="each" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="side" lemma="side" stem="side" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="accounting" lemma="account" stem="account" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="total" lemma="total" stem="total" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="length" lemma="length" stem="length" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="31" lemma="31" stem="31" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="true" />
        <token id="19" string="miles" lemma="mile" stem="mile" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN tunnel)) (VP (VBZ starts) (ADVP (NP (DT a) (JJ few) (NNS miles)) (RB inland)) (PP (IN on) (NP (DT each) (NN side))) (, ,) (PP (VBG accounting) (PP (IN for) (NP (NP (PRP$ its) (JJ total) (NN length)) (PP (IN of) (NP (CD 31) (NNS miles))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="its total length of 31 miles" type="NP">
          <tokens>
            <token id="14" string="its" />
            <token id="15" string="total" />
            <token id="16" string="length" />
            <token id="17" string="of" />
            <token id="18" string="31" />
            <token id="19" string="miles" />
          </tokens>
        </chunking>
        <chunking id="2" string="31 miles" type="NP">
          <tokens>
            <token id="18" string="31" />
            <token id="19" string="miles" />
          </tokens>
        </chunking>
        <chunking id="3" string="a few miles" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="few" />
            <token id="6" string="miles" />
          </tokens>
        </chunking>
        <chunking id="4" string="starts a few miles inland on each side , accounting for its total length of 31 miles" type="VP">
          <tokens>
            <token id="3" string="starts" />
            <token id="4" string="a" />
            <token id="5" string="few" />
            <token id="6" string="miles" />
            <token id="7" string="inland" />
            <token id="8" string="on" />
            <token id="9" string="each" />
            <token id="10" string="side" />
            <token id="11" string="," />
            <token id="12" string="accounting" />
            <token id="13" string="for" />
            <token id="14" string="its" />
            <token id="15" string="total" />
            <token id="16" string="length" />
            <token id="17" string="of" />
            <token id="18" string="31" />
            <token id="19" string="miles" />
          </tokens>
        </chunking>
        <chunking id="5" string="The tunnel" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="tunnel" />
          </tokens>
        </chunking>
        <chunking id="6" string="its total length" type="NP">
          <tokens>
            <token id="14" string="its" />
            <token id="15" string="total" />
            <token id="16" string="length" />
          </tokens>
        </chunking>
        <chunking id="7" string="each side" type="NP">
          <tokens>
            <token id="9" string="each" />
            <token id="10" string="side" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">tunnel</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">starts</governor>
          <dependent id="2">tunnel</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">starts</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">miles</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">miles</governor>
          <dependent id="5">few</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="7">inland</governor>
          <dependent id="6">miles</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">starts</governor>
          <dependent id="7">inland</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">side</governor>
          <dependent id="8">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">side</governor>
          <dependent id="9">each</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">starts</governor>
          <dependent id="10">side</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">length</governor>
          <dependent id="12">accounting</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">length</governor>
          <dependent id="13">for</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="16">length</governor>
          <dependent id="14">its</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">length</governor>
          <dependent id="15">total</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">starts</governor>
          <dependent id="16">length</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">miles</governor>
          <dependent id="17">of</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="19">miles</governor>
          <dependent id="18">31</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">length</governor>
          <dependent id="19">miles</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="31" type="NUMBER" score="0.0">
          <tokens>
            <token id="18" string="31" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="34" has_coreference="false">
      <content>Militant workers on the French side are striking for more pay and began a work slowdown Thursday, threatening to stall the link-up.</content>
      <tokens>
        <token id="1" string="Militant" lemma="militant" stem="milit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="workers" lemma="worker" stem="worker" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="French" lemma="french" stem="french" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="6" string="side" lemma="side" stem="side" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="striking" lemma="striking" stem="strike" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="more" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="pay" lemma="pay" stem="pai" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="began" lemma="begin" stem="began" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="work" lemma="work" stem="work" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="slowdown" lemma="slowdown" stem="slowdown" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="Thursday" lemma="Thursday" stem="thursdai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="threatening" lemma="threaten" stem="threaten" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="stall" lemma="stall" stem="stall" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="link-up" lemma="link-up" stem="link-up" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (JJ Militant) (NNS workers)) (PP (IN on) (NP (DT the) (JJ French) (NN side)))) (VP (VP (VBP are) (ADJP (JJ striking) (PP (IN for) (NP (JJR more) (NN pay))))) (CC and) (VP (VBD began) (NP (DT a) (NN work) (NN slowdown)) (NP-TMP (NNP Thursday)) (, ,) (S (VP (VBG threatening) (S (VP (TO to) (VP (VB stall) (NP (DT the) (NN link-up))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="threatening to stall the link-up" type="VP">
          <tokens>
            <token id="19" string="threatening" />
            <token id="20" string="to" />
            <token id="21" string="stall" />
            <token id="22" string="the" />
            <token id="23" string="link-up" />
          </tokens>
        </chunking>
        <chunking id="2" string="a work slowdown" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="work" />
            <token id="16" string="slowdown" />
          </tokens>
        </chunking>
        <chunking id="3" string="more pay" type="NP">
          <tokens>
            <token id="10" string="more" />
            <token id="11" string="pay" />
          </tokens>
        </chunking>
        <chunking id="4" string="are striking for more pay" type="VP">
          <tokens>
            <token id="7" string="are" />
            <token id="8" string="striking" />
            <token id="9" string="for" />
            <token id="10" string="more" />
            <token id="11" string="pay" />
          </tokens>
        </chunking>
        <chunking id="5" string="the French side" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="French" />
            <token id="6" string="side" />
          </tokens>
        </chunking>
        <chunking id="6" string="to stall the link-up" type="VP">
          <tokens>
            <token id="20" string="to" />
            <token id="21" string="stall" />
            <token id="22" string="the" />
            <token id="23" string="link-up" />
          </tokens>
        </chunking>
        <chunking id="7" string="striking for more pay" type="ADJP">
          <tokens>
            <token id="8" string="striking" />
            <token id="9" string="for" />
            <token id="10" string="more" />
            <token id="11" string="pay" />
          </tokens>
        </chunking>
        <chunking id="8" string="Militant workers" type="NP">
          <tokens>
            <token id="1" string="Militant" />
            <token id="2" string="workers" />
          </tokens>
        </chunking>
        <chunking id="9" string="Militant workers on the French side" type="NP">
          <tokens>
            <token id="1" string="Militant" />
            <token id="2" string="workers" />
            <token id="3" string="on" />
            <token id="4" string="the" />
            <token id="5" string="French" />
            <token id="6" string="side" />
          </tokens>
        </chunking>
        <chunking id="10" string="the link-up" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="link-up" />
          </tokens>
        </chunking>
        <chunking id="11" string="began a work slowdown Thursday , threatening to stall the link-up" type="VP">
          <tokens>
            <token id="13" string="began" />
            <token id="14" string="a" />
            <token id="15" string="work" />
            <token id="16" string="slowdown" />
            <token id="17" string="Thursday" />
            <token id="18" string="," />
            <token id="19" string="threatening" />
            <token id="20" string="to" />
            <token id="21" string="stall" />
            <token id="22" string="the" />
            <token id="23" string="link-up" />
          </tokens>
        </chunking>
        <chunking id="12" string="are striking for more pay and began a work slowdown Thursday , threatening to stall the link-up" type="VP">
          <tokens>
            <token id="7" string="are" />
            <token id="8" string="striking" />
            <token id="9" string="for" />
            <token id="10" string="more" />
            <token id="11" string="pay" />
            <token id="12" string="and" />
            <token id="13" string="began" />
            <token id="14" string="a" />
            <token id="15" string="work" />
            <token id="16" string="slowdown" />
            <token id="17" string="Thursday" />
            <token id="18" string="," />
            <token id="19" string="threatening" />
            <token id="20" string="to" />
            <token id="21" string="stall" />
            <token id="22" string="the" />
            <token id="23" string="link-up" />
          </tokens>
        </chunking>
        <chunking id="13" string="stall the link-up" type="VP">
          <tokens>
            <token id="21" string="stall" />
            <token id="22" string="the" />
            <token id="23" string="link-up" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="2">workers</governor>
          <dependent id="1">Militant</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">striking</governor>
          <dependent id="2">workers</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">side</governor>
          <dependent id="3">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">side</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">side</governor>
          <dependent id="5">French</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">workers</governor>
          <dependent id="6">side</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="8">striking</governor>
          <dependent id="7">are</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">striking</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">pay</governor>
          <dependent id="9">for</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">pay</governor>
          <dependent id="10">more</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">striking</governor>
          <dependent id="11">pay</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">striking</governor>
          <dependent id="12">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">striking</governor>
          <dependent id="13">began</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">slowdown</governor>
          <dependent id="14">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">slowdown</governor>
          <dependent id="15">work</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">began</governor>
          <dependent id="16">slowdown</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="13">began</governor>
          <dependent id="17">Thursday</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="13">began</governor>
          <dependent id="19">threatening</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="21">stall</governor>
          <dependent id="20">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="19">threatening</governor>
          <dependent id="21">stall</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">link-up</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">stall</governor>
          <dependent id="23">link-up</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="French" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="5" string="French" />
          </tokens>
        </entity>
        <entity id="2" string="Thursday" type="DATE" score="0.0">
          <tokens>
            <token id="17" string="Thursday" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="35" has_coreference="true">
      <content>But it came off on schedule.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="came" lemma="come" stem="came" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="off" lemma="off" stem="off" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="schedule" lemma="schedule" stem="schedul" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (PRP it)) (VP (VBD came) (PRT (RP off)) (PP (IN on) (NP (NN schedule)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="schedule" type="NP">
          <tokens>
            <token id="6" string="schedule" />
          </tokens>
        </chunking>
        <chunking id="2" string="came off on schedule" type="VP">
          <tokens>
            <token id="3" string="came" />
            <token id="4" string="off" />
            <token id="5" string="on" />
            <token id="6" string="schedule" />
          </tokens>
        </chunking>
        <chunking id="3" string="it" type="NP">
          <tokens>
            <token id="2" string="it" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="3">came</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">came</governor>
          <dependent id="2">it</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">came</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="3">came</governor>
          <dependent id="4">off</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">schedule</governor>
          <dependent id="5">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">came</governor>
          <dependent id="6">schedule</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="36" has_coreference="true">
      <content>Eurotunnel PLC announced Oct. 8 that it had reached an agreement with its banks on $3.5 billion in new credit.</content>
      <tokens>
        <token id="1" string="Eurotunnel" lemma="Eurotunnel" stem="eurotunnel" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="2" string="PLC" lemma="PLC" stem="plc" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="3" string="announced" lemma="announce" stem="announc" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="Oct." lemma="Oct." stem="oct." pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="5" string="8" lemma="8" stem="8" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="6" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="reached" lemma="reach" stem="reach" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="agreement" lemma="agreement" stem="agreement" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="banks" lemma="bank" stem="bank" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="17" string="3.5" lemma="3.5" stem="3.5" pos="CD" type="Number" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="18" string="billion" lemma="billion" stem="billion" pos="CD" type="Word" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="19" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="new" lemma="new" stem="new" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="credit" lemma="credit" stem="credit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Eurotunnel) (NNP PLC)) (VP (VBD announced) (NP-TMP (NNP Oct.) (CD 8)) (SBAR (IN that) (S (NP (PRP it)) (VP (VBD had) (VP (VBN reached) (NP (NP (DT an) (NN agreement)) (PP (IN with) (NP (PRP$ its) (NNS banks)))) (PP (IN on) (NP (QP ($ $) (CD 3.5) (CD billion)))) (PP (IN in) (NP (JJ new) (NN credit)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="reached an agreement with its banks on $ 3.5 billion in new credit" type="VP">
          <tokens>
            <token id="9" string="reached" />
            <token id="10" string="an" />
            <token id="11" string="agreement" />
            <token id="12" string="with" />
            <token id="13" string="its" />
            <token id="14" string="banks" />
            <token id="15" string="on" />
            <token id="16" string="$" />
            <token id="17" string="3.5" />
            <token id="18" string="billion" />
            <token id="19" string="in" />
            <token id="20" string="new" />
            <token id="21" string="credit" />
          </tokens>
        </chunking>
        <chunking id="2" string="an agreement with its banks" type="NP">
          <tokens>
            <token id="10" string="an" />
            <token id="11" string="agreement" />
            <token id="12" string="with" />
            <token id="13" string="its" />
            <token id="14" string="banks" />
          </tokens>
        </chunking>
        <chunking id="3" string="$ 3.5 billion" type="NP">
          <tokens>
            <token id="16" string="$" />
            <token id="17" string="3.5" />
            <token id="18" string="billion" />
          </tokens>
        </chunking>
        <chunking id="4" string="announced Oct. 8 that it had reached an agreement with its banks on $ 3.5 billion in new credit" type="VP">
          <tokens>
            <token id="3" string="announced" />
            <token id="4" string="Oct." />
            <token id="5" string="8" />
            <token id="6" string="that" />
            <token id="7" string="it" />
            <token id="8" string="had" />
            <token id="9" string="reached" />
            <token id="10" string="an" />
            <token id="11" string="agreement" />
            <token id="12" string="with" />
            <token id="13" string="its" />
            <token id="14" string="banks" />
            <token id="15" string="on" />
            <token id="16" string="$" />
            <token id="17" string="3.5" />
            <token id="18" string="billion" />
            <token id="19" string="in" />
            <token id="20" string="new" />
            <token id="21" string="credit" />
          </tokens>
        </chunking>
        <chunking id="5" string="it" type="NP">
          <tokens>
            <token id="7" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="its banks" type="NP">
          <tokens>
            <token id="13" string="its" />
            <token id="14" string="banks" />
          </tokens>
        </chunking>
        <chunking id="7" string="that it had reached an agreement with its banks on $ 3.5 billion in new credit" type="SBAR">
          <tokens>
            <token id="6" string="that" />
            <token id="7" string="it" />
            <token id="8" string="had" />
            <token id="9" string="reached" />
            <token id="10" string="an" />
            <token id="11" string="agreement" />
            <token id="12" string="with" />
            <token id="13" string="its" />
            <token id="14" string="banks" />
            <token id="15" string="on" />
            <token id="16" string="$" />
            <token id="17" string="3.5" />
            <token id="18" string="billion" />
            <token id="19" string="in" />
            <token id="20" string="new" />
            <token id="21" string="credit" />
          </tokens>
        </chunking>
        <chunking id="8" string="Eurotunnel PLC" type="NP">
          <tokens>
            <token id="1" string="Eurotunnel" />
            <token id="2" string="PLC" />
          </tokens>
        </chunking>
        <chunking id="9" string="an agreement" type="NP">
          <tokens>
            <token id="10" string="an" />
            <token id="11" string="agreement" />
          </tokens>
        </chunking>
        <chunking id="10" string="had reached an agreement with its banks on $ 3.5 billion in new credit" type="VP">
          <tokens>
            <token id="8" string="had" />
            <token id="9" string="reached" />
            <token id="10" string="an" />
            <token id="11" string="agreement" />
            <token id="12" string="with" />
            <token id="13" string="its" />
            <token id="14" string="banks" />
            <token id="15" string="on" />
            <token id="16" string="$" />
            <token id="17" string="3.5" />
            <token id="18" string="billion" />
            <token id="19" string="in" />
            <token id="20" string="new" />
            <token id="21" string="credit" />
          </tokens>
        </chunking>
        <chunking id="11" string="new credit" type="NP">
          <tokens>
            <token id="20" string="new" />
            <token id="21" string="credit" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">PLC</governor>
          <dependent id="1">Eurotunnel</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">announced</governor>
          <dependent id="2">PLC</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">announced</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="3">announced</governor>
          <dependent id="4">Oct.</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="4">Oct.</governor>
          <dependent id="5">8</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">reached</governor>
          <dependent id="6">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">reached</governor>
          <dependent id="7">it</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">reached</governor>
          <dependent id="8">had</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">announced</governor>
          <dependent id="9">reached</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">agreement</governor>
          <dependent id="10">an</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">reached</governor>
          <dependent id="11">agreement</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">banks</governor>
          <dependent id="12">with</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="14">banks</governor>
          <dependent id="13">its</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">agreement</governor>
          <dependent id="14">banks</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">$</governor>
          <dependent id="15">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">reached</governor>
          <dependent id="16">$</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">billion</governor>
          <dependent id="17">3.5</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="16">$</governor>
          <dependent id="18">billion</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">credit</governor>
          <dependent id="19">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">credit</governor>
          <dependent id="20">new</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">reached</governor>
          <dependent id="21">credit</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Oct. 8" type="DATE" score="0.0">
          <tokens>
            <token id="4" string="Oct." />
            <token id="5" string="8" />
          </tokens>
        </entity>
        <entity id="2" string="$ 3.5 billion" type="MONEY" score="0.0">
          <tokens>
            <token id="16" string="$" />
            <token id="17" string="3.5" />
            <token id="18" string="billion" />
          </tokens>
        </entity>
        <entity id="3" string="Eurotunnel PLC" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="1" string="Eurotunnel" />
            <token id="2" string="PLC" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="37" has_coreference="false">
      <content>More than 200 banks are involved in financing the world&amp;apost;s costliest tunnel.</content>
      <tokens>
        <token id="1" string="More" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="200" lemma="200" stem="200" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="4" string="banks" lemma="bank" stem="bank" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="involved" lemma="involve" stem="involv" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="financing" lemma="finance" stem="financ" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="costliest" lemma="costliest" stem="costliest" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="tunnel" lemma="tunnel" stem="tunnel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (QP (JJR More) (IN than) (CD 200)) (NNS banks)) (VP (VBP are) (ADJP (VBN involved) (PP (IN in) (S (VP (VBG financing) (NP (NP (DT the) (NN world) (POS 's)) (JJS costliest) (NN tunnel))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the world 's costliest tunnel" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="world" />
            <token id="11" string="'s" />
            <token id="12" string="costliest" />
            <token id="13" string="tunnel" />
          </tokens>
        </chunking>
        <chunking id="2" string="financing the world 's costliest tunnel" type="VP">
          <tokens>
            <token id="8" string="financing" />
            <token id="9" string="the" />
            <token id="10" string="world" />
            <token id="11" string="'s" />
            <token id="12" string="costliest" />
            <token id="13" string="tunnel" />
          </tokens>
        </chunking>
        <chunking id="3" string="involved in financing the world 's costliest tunnel" type="ADJP">
          <tokens>
            <token id="6" string="involved" />
            <token id="7" string="in" />
            <token id="8" string="financing" />
            <token id="9" string="the" />
            <token id="10" string="world" />
            <token id="11" string="'s" />
            <token id="12" string="costliest" />
            <token id="13" string="tunnel" />
          </tokens>
        </chunking>
        <chunking id="4" string="are involved in financing the world 's costliest tunnel" type="VP">
          <tokens>
            <token id="5" string="are" />
            <token id="6" string="involved" />
            <token id="7" string="in" />
            <token id="8" string="financing" />
            <token id="9" string="the" />
            <token id="10" string="world" />
            <token id="11" string="'s" />
            <token id="12" string="costliest" />
            <token id="13" string="tunnel" />
          </tokens>
        </chunking>
        <chunking id="5" string="More than 200 banks" type="NP">
          <tokens>
            <token id="1" string="More" />
            <token id="2" string="than" />
            <token id="3" string="200" />
            <token id="4" string="banks" />
          </tokens>
        </chunking>
        <chunking id="6" string="the world 's" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="world" />
            <token id="11" string="'s" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="3">200</governor>
          <dependent id="1">More</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="1">More</governor>
          <dependent id="2">than</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="4">banks</governor>
          <dependent id="3">200</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="6">involved</governor>
          <dependent id="4">banks</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="6">involved</governor>
          <dependent id="5">are</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">involved</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">financing</governor>
          <dependent id="7">in</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="6">involved</governor>
          <dependent id="8">financing</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">world</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="13">tunnel</governor>
          <dependent id="10">world</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">world</governor>
          <dependent id="11">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">tunnel</governor>
          <dependent id="12">costliest</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">financing</governor>
          <dependent id="13">tunnel</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="200" type="NUMBER" score="0.0">
          <tokens>
            <token id="3" string="200" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="38" has_coreference="false">
      <content>The three-hour Paris-to-London trip would be comparable to flying, if transport to and from airports is included, and is half the time of the present car-ferry journey.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="three-hour" lemma="three-hour" stem="three-hour" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="3" string="Paris-to-London" lemma="Paris-to-London" stem="paris-to-london" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="trip" lemma="trip" stem="trip" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="comparable" lemma="comparable" stem="compar" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="flying" lemma="fly" stem="fly" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="transport" lemma="transport" stem="transport" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="airports" lemma="airport" stem="airport" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="included" lemma="include" stem="includ" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="half" lemma="half" stem="half" pos="PDT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="present" lemma="present" stem="present" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="28" string="car-ferry" lemma="car-ferry" stem="car-ferri" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="journey" lemma="journey" stem="journei" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (JJ three-hour) (NNP Paris-to-London) (NN trip)) (VP (MD would) (VP (VB be) (ADJP (JJ comparable) (PP (TO to) (S (VP (VBG flying))))) (, ,) (SBAR (IN if) (S (NP (NP (NN transport)) (PP (TO to) (CC and) (IN from) (NP (NNS airports)))) (VP (VP (VBZ is) (VP (VBN included))) (, ,) (CC and) (VP (VBZ is) (NP (NP (PDT half) (DT the) (NN time)) (PP (IN of) (NP (DT the) (JJ present) (JJ car-ferry) (NN journey)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="if transport to and from airports is included , and is half the time of the present car-ferry journey" type="SBAR">
          <tokens>
            <token id="11" string="if" />
            <token id="12" string="transport" />
            <token id="13" string="to" />
            <token id="14" string="and" />
            <token id="15" string="from" />
            <token id="16" string="airports" />
            <token id="17" string="is" />
            <token id="18" string="included" />
            <token id="19" string="," />
            <token id="20" string="and" />
            <token id="21" string="is" />
            <token id="22" string="half" />
            <token id="23" string="the" />
            <token id="24" string="time" />
            <token id="25" string="of" />
            <token id="26" string="the" />
            <token id="27" string="present" />
            <token id="28" string="car-ferry" />
            <token id="29" string="journey" />
          </tokens>
        </chunking>
        <chunking id="2" string="airports" type="NP">
          <tokens>
            <token id="16" string="airports" />
          </tokens>
        </chunking>
        <chunking id="3" string="is included , and is half the time of the present car-ferry journey" type="VP">
          <tokens>
            <token id="17" string="is" />
            <token id="18" string="included" />
            <token id="19" string="," />
            <token id="20" string="and" />
            <token id="21" string="is" />
            <token id="22" string="half" />
            <token id="23" string="the" />
            <token id="24" string="time" />
            <token id="25" string="of" />
            <token id="26" string="the" />
            <token id="27" string="present" />
            <token id="28" string="car-ferry" />
            <token id="29" string="journey" />
          </tokens>
        </chunking>
        <chunking id="4" string="half the time of the present car-ferry journey" type="NP">
          <tokens>
            <token id="22" string="half" />
            <token id="23" string="the" />
            <token id="24" string="time" />
            <token id="25" string="of" />
            <token id="26" string="the" />
            <token id="27" string="present" />
            <token id="28" string="car-ferry" />
            <token id="29" string="journey" />
          </tokens>
        </chunking>
        <chunking id="5" string="is half the time of the present car-ferry journey" type="VP">
          <tokens>
            <token id="21" string="is" />
            <token id="22" string="half" />
            <token id="23" string="the" />
            <token id="24" string="time" />
            <token id="25" string="of" />
            <token id="26" string="the" />
            <token id="27" string="present" />
            <token id="28" string="car-ferry" />
            <token id="29" string="journey" />
          </tokens>
        </chunking>
        <chunking id="6" string="would be comparable to flying , if transport to and from airports is included , and is half the time of the present car-ferry journey" type="VP">
          <tokens>
            <token id="5" string="would" />
            <token id="6" string="be" />
            <token id="7" string="comparable" />
            <token id="8" string="to" />
            <token id="9" string="flying" />
            <token id="10" string="," />
            <token id="11" string="if" />
            <token id="12" string="transport" />
            <token id="13" string="to" />
            <token id="14" string="and" />
            <token id="15" string="from" />
            <token id="16" string="airports" />
            <token id="17" string="is" />
            <token id="18" string="included" />
            <token id="19" string="," />
            <token id="20" string="and" />
            <token id="21" string="is" />
            <token id="22" string="half" />
            <token id="23" string="the" />
            <token id="24" string="time" />
            <token id="25" string="of" />
            <token id="26" string="the" />
            <token id="27" string="present" />
            <token id="28" string="car-ferry" />
            <token id="29" string="journey" />
          </tokens>
        </chunking>
        <chunking id="7" string="transport" type="NP">
          <tokens>
            <token id="12" string="transport" />
          </tokens>
        </chunking>
        <chunking id="8" string="is included" type="VP">
          <tokens>
            <token id="17" string="is" />
            <token id="18" string="included" />
          </tokens>
        </chunking>
        <chunking id="9" string="be comparable to flying , if transport to and from airports is included , and is half the time of the present car-ferry journey" type="VP">
          <tokens>
            <token id="6" string="be" />
            <token id="7" string="comparable" />
            <token id="8" string="to" />
            <token id="9" string="flying" />
            <token id="10" string="," />
            <token id="11" string="if" />
            <token id="12" string="transport" />
            <token id="13" string="to" />
            <token id="14" string="and" />
            <token id="15" string="from" />
            <token id="16" string="airports" />
            <token id="17" string="is" />
            <token id="18" string="included" />
            <token id="19" string="," />
            <token id="20" string="and" />
            <token id="21" string="is" />
            <token id="22" string="half" />
            <token id="23" string="the" />
            <token id="24" string="time" />
            <token id="25" string="of" />
            <token id="26" string="the" />
            <token id="27" string="present" />
            <token id="28" string="car-ferry" />
            <token id="29" string="journey" />
          </tokens>
        </chunking>
        <chunking id="10" string="half the time" type="NP">
          <tokens>
            <token id="22" string="half" />
            <token id="23" string="the" />
            <token id="24" string="time" />
          </tokens>
        </chunking>
        <chunking id="11" string="transport to and from airports" type="NP">
          <tokens>
            <token id="12" string="transport" />
            <token id="13" string="to" />
            <token id="14" string="and" />
            <token id="15" string="from" />
            <token id="16" string="airports" />
          </tokens>
        </chunking>
        <chunking id="12" string="flying" type="VP">
          <tokens>
            <token id="9" string="flying" />
          </tokens>
        </chunking>
        <chunking id="13" string="The three-hour Paris-to-London trip" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="three-hour" />
            <token id="3" string="Paris-to-London" />
            <token id="4" string="trip" />
          </tokens>
        </chunking>
        <chunking id="14" string="included" type="VP">
          <tokens>
            <token id="18" string="included" />
          </tokens>
        </chunking>
        <chunking id="15" string="the present car-ferry journey" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="present" />
            <token id="28" string="car-ferry" />
            <token id="29" string="journey" />
          </tokens>
        </chunking>
        <chunking id="16" string="comparable to flying" type="ADJP">
          <tokens>
            <token id="7" string="comparable" />
            <token id="8" string="to" />
            <token id="9" string="flying" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="4">trip</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">trip</governor>
          <dependent id="2">three-hour</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">trip</governor>
          <dependent id="3">Paris-to-London</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">comparable</governor>
          <dependent id="4">trip</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">comparable</governor>
          <dependent id="5">would</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">comparable</governor>
          <dependent id="6">be</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">comparable</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">flying</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="7">comparable</governor>
          <dependent id="9">flying</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">included</governor>
          <dependent id="11">if</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">transport</governor>
          <dependent id="12">transport</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="18">included</governor>
          <dependent id="12">transport</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">airports</governor>
          <dependent id="13">to</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">to</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">to</governor>
          <dependent id="15">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">transport</governor>
          <dependent id="16">airports</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">transport</governor>
          <dependent id="16">airports</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="18">included</governor>
          <dependent id="17">is</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="7">comparable</governor>
          <dependent id="18">included</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="18">included</governor>
          <dependent id="20">and</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="24">time</governor>
          <dependent id="21">is</dependent>
        </dependency>
        <dependency type="det:predet">
          <governor id="24">time</governor>
          <dependent id="22">half</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">time</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="18">included</governor>
          <dependent id="24">time</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">journey</governor>
          <dependent id="25">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">journey</governor>
          <dependent id="26">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="29">journey</governor>
          <dependent id="27">present</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="29">journey</governor>
          <dependent id="28">car-ferry</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">time</governor>
          <dependent id="29">journey</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="three-hour" type="DURATION" score="0.0">
          <tokens>
            <token id="2" string="three-hour" />
          </tokens>
        </entity>
        <entity id="2" string="present" type="DATE" score="0.0">
          <tokens>
            <token id="27" string="present" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="39" has_coreference="false">
      <content>Officials estimate the tunnel trains may carry 28 million passengers in the first year of operation.</content>
      <tokens>
        <token id="1" string="Officials" lemma="official" stem="official" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="estimate" lemma="estimate" stem="estim" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="tunnel" lemma="tunnel" stem="tunnel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="trains" lemma="train" stem="train" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="may" lemma="may" stem="mai" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="carry" lemma="carry" stem="carri" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="28" lemma="28" stem="28" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="9" string="million" lemma="million" stem="million" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="10" string="passengers" lemma="passenger" stem="passeng" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="13" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="14" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="operation" lemma="operation" stem="oper" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNS Officials)) (VP (VBP estimate) (SBAR (S (NP (DT the) (NN tunnel) (NNS trains)) (VP (MD may) (VP (VB carry) (NP (QP (CD 28) (CD million)) (NNS passengers)) (PP (IN in) (NP (NP (DT the) (JJ first) (NN year)) (PP (IN of) (NP (NN operation)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the first year" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="first" />
            <token id="14" string="year" />
          </tokens>
        </chunking>
        <chunking id="2" string="estimate the tunnel trains may carry 28 million passengers in the first year of operation" type="VP">
          <tokens>
            <token id="2" string="estimate" />
            <token id="3" string="the" />
            <token id="4" string="tunnel" />
            <token id="5" string="trains" />
            <token id="6" string="may" />
            <token id="7" string="carry" />
            <token id="8" string="28" />
            <token id="9" string="million" />
            <token id="10" string="passengers" />
            <token id="11" string="in" />
            <token id="12" string="the" />
            <token id="13" string="first" />
            <token id="14" string="year" />
            <token id="15" string="of" />
            <token id="16" string="operation" />
          </tokens>
        </chunking>
        <chunking id="3" string="the first year of operation" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="first" />
            <token id="14" string="year" />
            <token id="15" string="of" />
            <token id="16" string="operation" />
          </tokens>
        </chunking>
        <chunking id="4" string="the tunnel trains may carry 28 million passengers in the first year of operation" type="SBAR">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="tunnel" />
            <token id="5" string="trains" />
            <token id="6" string="may" />
            <token id="7" string="carry" />
            <token id="8" string="28" />
            <token id="9" string="million" />
            <token id="10" string="passengers" />
            <token id="11" string="in" />
            <token id="12" string="the" />
            <token id="13" string="first" />
            <token id="14" string="year" />
            <token id="15" string="of" />
            <token id="16" string="operation" />
          </tokens>
        </chunking>
        <chunking id="5" string="may carry 28 million passengers in the first year of operation" type="VP">
          <tokens>
            <token id="6" string="may" />
            <token id="7" string="carry" />
            <token id="8" string="28" />
            <token id="9" string="million" />
            <token id="10" string="passengers" />
            <token id="11" string="in" />
            <token id="12" string="the" />
            <token id="13" string="first" />
            <token id="14" string="year" />
            <token id="15" string="of" />
            <token id="16" string="operation" />
          </tokens>
        </chunking>
        <chunking id="6" string="28 million passengers" type="NP">
          <tokens>
            <token id="8" string="28" />
            <token id="9" string="million" />
            <token id="10" string="passengers" />
          </tokens>
        </chunking>
        <chunking id="7" string="Officials" type="NP">
          <tokens>
            <token id="1" string="Officials" />
          </tokens>
        </chunking>
        <chunking id="8" string="carry 28 million passengers in the first year of operation" type="VP">
          <tokens>
            <token id="7" string="carry" />
            <token id="8" string="28" />
            <token id="9" string="million" />
            <token id="10" string="passengers" />
            <token id="11" string="in" />
            <token id="12" string="the" />
            <token id="13" string="first" />
            <token id="14" string="year" />
            <token id="15" string="of" />
            <token id="16" string="operation" />
          </tokens>
        </chunking>
        <chunking id="9" string="the tunnel trains" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="tunnel" />
            <token id="5" string="trains" />
          </tokens>
        </chunking>
        <chunking id="10" string="operation" type="NP">
          <tokens>
            <token id="16" string="operation" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">estimate</governor>
          <dependent id="1">Officials</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">estimate</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">trains</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">trains</governor>
          <dependent id="4">tunnel</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">carry</governor>
          <dependent id="5">trains</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">carry</governor>
          <dependent id="6">may</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">estimate</governor>
          <dependent id="7">carry</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">million</governor>
          <dependent id="8">28</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="10">passengers</governor>
          <dependent id="9">million</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">carry</governor>
          <dependent id="10">passengers</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">year</governor>
          <dependent id="11">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">year</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">year</governor>
          <dependent id="13">first</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">carry</governor>
          <dependent id="14">year</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">operation</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">year</governor>
          <dependent id="16">operation</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="the first year" type="DATE" score="0.0">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="first" />
            <token id="14" string="year" />
          </tokens>
        </entity>
        <entity id="2" string="28 million" type="NUMBER" score="0.0">
          <tokens>
            <token id="8" string="28" />
            <token id="9" string="million" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="40" has_coreference="true">
      <content>Eurotunnel doesn&amp;apost;t expect a profit until the end of the century.</content>
      <tokens>
        <token id="1" string="Eurotunnel" lemma="Eurotunnel" stem="eurotunnel" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="2" string="does" lemma="do" stem="doe" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="expect" lemma="expect" stem="expect" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="profit" lemma="profit" stem="profit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="until" lemma="until" stem="until" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="9" string="end" lemma="end" stem="end" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="12" string="century" lemma="century" stem="centuri" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Eurotunnel)) (VP (VBZ does) (RB n't) (VP (VB expect) (NP (DT a) (NN profit)) (PP (IN until) (NP (NP (DT the) (NN end)) (PP (IN of) (NP (DT the) (NN century))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a profit" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="profit" />
          </tokens>
        </chunking>
        <chunking id="2" string="the end" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="end" />
          </tokens>
        </chunking>
        <chunking id="3" string="the end of the century" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="end" />
            <token id="10" string="of" />
            <token id="11" string="the" />
            <token id="12" string="century" />
          </tokens>
        </chunking>
        <chunking id="4" string="Eurotunnel" type="NP">
          <tokens>
            <token id="1" string="Eurotunnel" />
          </tokens>
        </chunking>
        <chunking id="5" string="does n't expect a profit until the end of the century" type="VP">
          <tokens>
            <token id="2" string="does" />
            <token id="3" string="n't" />
            <token id="4" string="expect" />
            <token id="5" string="a" />
            <token id="6" string="profit" />
            <token id="7" string="until" />
            <token id="8" string="the" />
            <token id="9" string="end" />
            <token id="10" string="of" />
            <token id="11" string="the" />
            <token id="12" string="century" />
          </tokens>
        </chunking>
        <chunking id="6" string="expect a profit until the end of the century" type="VP">
          <tokens>
            <token id="4" string="expect" />
            <token id="5" string="a" />
            <token id="6" string="profit" />
            <token id="7" string="until" />
            <token id="8" string="the" />
            <token id="9" string="end" />
            <token id="10" string="of" />
            <token id="11" string="the" />
            <token id="12" string="century" />
          </tokens>
        </chunking>
        <chunking id="7" string="the century" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="century" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">expect</governor>
          <dependent id="1">Eurotunnel</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">expect</governor>
          <dependent id="2">does</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="4">expect</governor>
          <dependent id="3">n't</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">expect</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">profit</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">expect</governor>
          <dependent id="6">profit</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">end</governor>
          <dependent id="7">until</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">end</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">expect</governor>
          <dependent id="9">end</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">century</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">century</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">end</governor>
          <dependent id="12">century</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="the end of the century" type="DATE" score="0.0">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="end" />
            <token id="10" string="of" />
            <token id="11" string="the" />
            <token id="12" string="century" />
          </tokens>
        </entity>
        <entity id="2" string="Eurotunnel" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="1" string="Eurotunnel" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="41" has_coreference="true">
      <content>France hopes the project will revitalize depressed northern regions.</content>
      <tokens>
        <token id="1" string="France" lemma="France" stem="franc" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="2" string="hopes" lemma="hope" stem="hope" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="project" lemma="project" stem="project" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="revitalize" lemma="revitalize" stem="revit" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="depressed" lemma="depressed" stem="depress" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="northern" lemma="northern" stem="northern" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="regions" lemma="region" stem="region" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP France)) (VP (VBZ hopes) (SBAR (S (NP (DT the) (NN project)) (VP (MD will) (VP (VB revitalize) (NP (JJ depressed) (JJ northern) (NNS regions))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="will revitalize depressed northern regions" type="VP">
          <tokens>
            <token id="5" string="will" />
            <token id="6" string="revitalize" />
            <token id="7" string="depressed" />
            <token id="8" string="northern" />
            <token id="9" string="regions" />
          </tokens>
        </chunking>
        <chunking id="2" string="depressed northern regions" type="NP">
          <tokens>
            <token id="7" string="depressed" />
            <token id="8" string="northern" />
            <token id="9" string="regions" />
          </tokens>
        </chunking>
        <chunking id="3" string="hopes the project will revitalize depressed northern regions" type="VP">
          <tokens>
            <token id="2" string="hopes" />
            <token id="3" string="the" />
            <token id="4" string="project" />
            <token id="5" string="will" />
            <token id="6" string="revitalize" />
            <token id="7" string="depressed" />
            <token id="8" string="northern" />
            <token id="9" string="regions" />
          </tokens>
        </chunking>
        <chunking id="4" string="the project" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="project" />
          </tokens>
        </chunking>
        <chunking id="5" string="revitalize depressed northern regions" type="VP">
          <tokens>
            <token id="6" string="revitalize" />
            <token id="7" string="depressed" />
            <token id="8" string="northern" />
            <token id="9" string="regions" />
          </tokens>
        </chunking>
        <chunking id="6" string="the project will revitalize depressed northern regions" type="SBAR">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="project" />
            <token id="5" string="will" />
            <token id="6" string="revitalize" />
            <token id="7" string="depressed" />
            <token id="8" string="northern" />
            <token id="9" string="regions" />
          </tokens>
        </chunking>
        <chunking id="7" string="France" type="NP">
          <tokens>
            <token id="1" string="France" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">hopes</governor>
          <dependent id="1">France</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">hopes</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">project</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">revitalize</governor>
          <dependent id="4">project</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">revitalize</governor>
          <dependent id="5">will</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">hopes</governor>
          <dependent id="6">revitalize</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">regions</governor>
          <dependent id="7">depressed</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">regions</governor>
          <dependent id="8">northern</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">revitalize</governor>
          <dependent id="9">regions</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="France" type="LOCATION" score="0.0">
          <tokens>
            <token id="1" string="France" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="42" has_coreference="false">
      <content>But many Britons fear an influx of continental ills ranging from terrorists to rabid animals.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="many" lemma="many" stem="mani" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Britons" lemma="Britons" stem="briton" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="4" string="fear" lemma="fear" stem="fear" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="influx" lemma="influx" stem="influx" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="continental" lemma="continental" stem="continent" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="ills" lemma="ill" stem="ill" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="ranging" lemma="range" stem="rang" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="terrorists" lemma="terrorist" stem="terrorist" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="rabid" lemma="rabid" stem="rabid" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="animals" lemma="animal" stem="anim" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (JJ many) (NNPS Britons)) (VP (VBP fear) (NP (NP (DT an) (NN influx)) (PP (IN of) (NP (NP (JJ continental) (NNS ills)) (VP (VBG ranging) (PP (IN from) (NP (NNS terrorists))) (PP (TO to) (NP (JJ rabid) (NNS animals)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="an influx" type="NP">
          <tokens>
            <token id="5" string="an" />
            <token id="6" string="influx" />
          </tokens>
        </chunking>
        <chunking id="2" string="fear an influx of continental ills ranging from terrorists to rabid animals" type="VP">
          <tokens>
            <token id="4" string="fear" />
            <token id="5" string="an" />
            <token id="6" string="influx" />
            <token id="7" string="of" />
            <token id="8" string="continental" />
            <token id="9" string="ills" />
            <token id="10" string="ranging" />
            <token id="11" string="from" />
            <token id="12" string="terrorists" />
            <token id="13" string="to" />
            <token id="14" string="rabid" />
            <token id="15" string="animals" />
          </tokens>
        </chunking>
        <chunking id="3" string="continental ills ranging from terrorists to rabid animals" type="NP">
          <tokens>
            <token id="8" string="continental" />
            <token id="9" string="ills" />
            <token id="10" string="ranging" />
            <token id="11" string="from" />
            <token id="12" string="terrorists" />
            <token id="13" string="to" />
            <token id="14" string="rabid" />
            <token id="15" string="animals" />
          </tokens>
        </chunking>
        <chunking id="4" string="continental ills" type="NP">
          <tokens>
            <token id="8" string="continental" />
            <token id="9" string="ills" />
          </tokens>
        </chunking>
        <chunking id="5" string="rabid animals" type="NP">
          <tokens>
            <token id="14" string="rabid" />
            <token id="15" string="animals" />
          </tokens>
        </chunking>
        <chunking id="6" string="an influx of continental ills ranging from terrorists to rabid animals" type="NP">
          <tokens>
            <token id="5" string="an" />
            <token id="6" string="influx" />
            <token id="7" string="of" />
            <token id="8" string="continental" />
            <token id="9" string="ills" />
            <token id="10" string="ranging" />
            <token id="11" string="from" />
            <token id="12" string="terrorists" />
            <token id="13" string="to" />
            <token id="14" string="rabid" />
            <token id="15" string="animals" />
          </tokens>
        </chunking>
        <chunking id="7" string="terrorists" type="NP">
          <tokens>
            <token id="12" string="terrorists" />
          </tokens>
        </chunking>
        <chunking id="8" string="ranging from terrorists to rabid animals" type="VP">
          <tokens>
            <token id="10" string="ranging" />
            <token id="11" string="from" />
            <token id="12" string="terrorists" />
            <token id="13" string="to" />
            <token id="14" string="rabid" />
            <token id="15" string="animals" />
          </tokens>
        </chunking>
        <chunking id="9" string="many Britons" type="NP">
          <tokens>
            <token id="2" string="many" />
            <token id="3" string="Britons" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="4">fear</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">Britons</governor>
          <dependent id="2">many</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">fear</governor>
          <dependent id="3">Britons</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">fear</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">influx</governor>
          <dependent id="5">an</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">fear</governor>
          <dependent id="6">influx</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">ills</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">ills</governor>
          <dependent id="8">continental</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">influx</governor>
          <dependent id="9">ills</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="9">ills</governor>
          <dependent id="10">ranging</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">terrorists</governor>
          <dependent id="11">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">ranging</governor>
          <dependent id="12">terrorists</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">animals</governor>
          <dependent id="13">to</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">animals</governor>
          <dependent id="14">rabid</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">ranging</governor>
          <dependent id="15">animals</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Britons" type="MISC" score="0.0">
          <tokens>
            <token id="3" string="Britons" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="43" has_coreference="true">
      <content>Britain warned Napoleon not to try to build the tunnel; digging was started subsequently in 1882 and 1974, but both efforts failed.</content>
      <tokens>
        <token id="1" string="Britain" lemma="Britain" stem="britain" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="2" string="warned" lemma="warn" stem="warn" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Napoleon" lemma="Napoleon" stem="napoleon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="4" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="try" lemma="try" stem="try" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="build" lemma="build" stem="build" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="tunnel" lemma="tunnel" stem="tunnel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="digging" lemma="digging" stem="dig" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="started" lemma="start" stem="start" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="subsequently" lemma="subsequently" stem="subsequ" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="1882" lemma="1882" stem="1882" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="18" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="1974" lemma="1974" stem="1974" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="both" lemma="both" stem="both" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="efforts" lemma="effort" stem="effort" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="failed" lemma="fail" stem="fail" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NNP Britain)) (VP (VBD warned) (S (NP (NNP Napoleon)) (RB not) (VP (TO to) (VP (VB try) (S (VP (TO to) (VP (VB build) (NP (DT the) (NN tunnel)))))))))) (: ;) (S (S (NP (NN digging)) (VP (VBD was) (VP (VBN started) (ADVP (RB subsequently)) (PP (IN in) (NP (CD 1882) (CC and) (CD 1974)))))) (, ,) (CC but) (S (NP (DT both) (NNS efforts)) (VP (VBD failed)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="was started subsequently in 1882 and 1974" type="VP">
          <tokens>
            <token id="13" string="was" />
            <token id="14" string="started" />
            <token id="15" string="subsequently" />
            <token id="16" string="in" />
            <token id="17" string="1882" />
            <token id="18" string="and" />
            <token id="19" string="1974" />
          </tokens>
        </chunking>
        <chunking id="2" string="build the tunnel" type="VP">
          <tokens>
            <token id="8" string="build" />
            <token id="9" string="the" />
            <token id="10" string="tunnel" />
          </tokens>
        </chunking>
        <chunking id="3" string="failed" type="VP">
          <tokens>
            <token id="24" string="failed" />
          </tokens>
        </chunking>
        <chunking id="4" string="Britain" type="NP">
          <tokens>
            <token id="1" string="Britain" />
          </tokens>
        </chunking>
        <chunking id="5" string="digging" type="NP">
          <tokens>
            <token id="12" string="digging" />
          </tokens>
        </chunking>
        <chunking id="6" string="Napoleon" type="NP">
          <tokens>
            <token id="3" string="Napoleon" />
          </tokens>
        </chunking>
        <chunking id="7" string="try to build the tunnel" type="VP">
          <tokens>
            <token id="6" string="try" />
            <token id="7" string="to" />
            <token id="8" string="build" />
            <token id="9" string="the" />
            <token id="10" string="tunnel" />
          </tokens>
        </chunking>
        <chunking id="8" string="1882 and 1974" type="NP">
          <tokens>
            <token id="17" string="1882" />
            <token id="18" string="and" />
            <token id="19" string="1974" />
          </tokens>
        </chunking>
        <chunking id="9" string="warned Napoleon not to try to build the tunnel" type="VP">
          <tokens>
            <token id="2" string="warned" />
            <token id="3" string="Napoleon" />
            <token id="4" string="not" />
            <token id="5" string="to" />
            <token id="6" string="try" />
            <token id="7" string="to" />
            <token id="8" string="build" />
            <token id="9" string="the" />
            <token id="10" string="tunnel" />
          </tokens>
        </chunking>
        <chunking id="10" string="to build the tunnel" type="VP">
          <tokens>
            <token id="7" string="to" />
            <token id="8" string="build" />
            <token id="9" string="the" />
            <token id="10" string="tunnel" />
          </tokens>
        </chunking>
        <chunking id="11" string="both efforts" type="NP">
          <tokens>
            <token id="22" string="both" />
            <token id="23" string="efforts" />
          </tokens>
        </chunking>
        <chunking id="12" string="started subsequently in 1882 and 1974" type="VP">
          <tokens>
            <token id="14" string="started" />
            <token id="15" string="subsequently" />
            <token id="16" string="in" />
            <token id="17" string="1882" />
            <token id="18" string="and" />
            <token id="19" string="1974" />
          </tokens>
        </chunking>
        <chunking id="13" string="to try to build the tunnel" type="VP">
          <tokens>
            <token id="5" string="to" />
            <token id="6" string="try" />
            <token id="7" string="to" />
            <token id="8" string="build" />
            <token id="9" string="the" />
            <token id="10" string="tunnel" />
          </tokens>
        </chunking>
        <chunking id="14" string="the tunnel" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="tunnel" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">warned</governor>
          <dependent id="1">Britain</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">warned</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">warned</governor>
          <dependent id="3">Napoleon</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="6">try</governor>
          <dependent id="4">not</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">try</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="2">warned</governor>
          <dependent id="6">try</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">build</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">try</governor>
          <dependent id="8">build</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">tunnel</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">build</governor>
          <dependent id="10">tunnel</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="14">started</governor>
          <dependent id="12">digging</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="14">started</governor>
          <dependent id="13">was</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="2">warned</governor>
          <dependent id="14">started</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">started</governor>
          <dependent id="15">subsequently</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">1882</governor>
          <dependent id="16">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">started</governor>
          <dependent id="17">1882</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="17">1882</governor>
          <dependent id="18">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">1882</governor>
          <dependent id="19">1974</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="14">started</governor>
          <dependent id="21">but</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">efforts</governor>
          <dependent id="22">both</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">failed</governor>
          <dependent id="23">efforts</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">started</governor>
          <dependent id="24">failed</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1974" type="DATE" score="0.0">
          <tokens>
            <token id="19" string="1974" />
          </tokens>
        </entity>
        <entity id="2" string="1882" type="DATE" score="0.0">
          <tokens>
            <token id="17" string="1882" />
          </tokens>
        </entity>
        <entity id="3" string="Britain" type="LOCATION" score="0.0">
          <tokens>
            <token id="1" string="Britain" />
          </tokens>
        </entity>
        <entity id="4" string="Napoleon" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Napoleon" />
          </tokens>
        </entity>
      </entities>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="2" type="PROPER">
      <referenced ids_tokens="14" string="Britain" id_sentence="1" />
      <mentions>
        <mention ids_tokens="20-21" string="an island" id_sentence="11" />
      </mentions>
    </coreference>
    <coreference id="4" type="PROPER">
      <referenced ids_tokens="4-5-6" string="the English Channel" id_sentence="1" />
      <mentions>
        <mention ids_tokens="17-18" string="the Channel" id_sentence="12" />
      </mentions>
    </coreference>
    <coreference id="5" type="NOMINAL">
      <referenced ids_tokens="20-21-22-23" string="31 miles of tunnel" id_sentence="1" />
      <mentions>
        <mention ids_tokens="18-19" string="31 miles" id_sentence="33" />
      </mentions>
    </coreference>
    <coreference id="7" type="NOMINAL">
      <referenced ids_tokens="13-14-15" string="the historic linkup" id_sentence="2" />
      <mentions>
        <mention ids_tokens="1-2" string="The linkup" id_sentence="20" />
      </mentions>
    </coreference>
    <coreference id="8" type="PROPER">
      <referenced ids_tokens="20" string="Tuesday" id_sentence="2" />
      <mentions>
        <mention ids_tokens="13-14" string="Tuesday's" id_sentence="23" />
      </mentions>
    </coreference>
    <coreference id="9" type="NOMINAL">
      <referenced ids_tokens="22-23" string="British workers" id_sentence="2" />
      <mentions>
        <mention ids_tokens="5" string="workers" id_sentence="13" />
        <mention ids_tokens="19" string="their" id_sentence="13" />
        <mention ids_tokens="1-2" string="The workers" id_sentence="16" />
      </mentions>
    </coreference>
    <coreference id="10" type="PROPER">
      <referenced ids_tokens="2" string="England" id_sentence="3" />
      <mentions>
        <mention ids_tokens="1" string="It" id_sentence="4" />
      </mentions>
    </coreference>
    <coreference id="13" type="NOMINAL">
      <referenced ids_tokens="6-7" string="the tunnel" id_sentence="3" />
      <mentions>
        <mention ids_tokens="1-3" string="The tunnel's" id_sentence="25" />
        <mention ids_tokens="14" string="its" id_sentence="33" />
      </mentions>
    </coreference>
    <coreference id="14" type="PROPER">
      <referenced ids_tokens="7-8-9-10-11-12-13-14-15-16-17-18-19-20" string="Napoleon , who wanted to send his armies through the tunnel to conquer Britain" id_sentence="4" />
      <mentions>
        <mention ids_tokens="3" string="Napoleon" id_sentence="43" />
      </mentions>
    </coreference>
    <coreference id="15" type="PROPER">
      <referenced ids_tokens="1-2" string="Eurotunnel PLC" id_sentence="5" />
      <mentions>
        <mention ids_tokens="7" string="it" id_sentence="36" />
        <mention ids_tokens="13" string="its" id_sentence="36" />
        <mention ids_tokens="1" string="Eurotunnel" id_sentence="40" />
      </mentions>
    </coreference>
    <coreference id="16" type="PROPER">
      <referenced ids_tokens="5" string="Anglo-French" id_sentence="5" />
      <mentions>
        <mention ids_tokens="2" string="her" id_sentence="7" />
        <mention ids_tokens="13" string="she" id_sentence="8" />
      </mentions>
    </coreference>
    <coreference id="17" type="NOMINAL">
      <referenced ids_tokens="8-9-10-11-12-13" string="the world 's largest engineering project" id_sentence="5" />
      <mentions>
        <mention ids_tokens="3-4" string="the project" id_sentence="41" />
      </mentions>
    </coreference>
    <coreference id="21" type="NOMINAL">
      <referenced ids_tokens="8-9-10" string="their ancient moat" id_sentence="7" />
      <mentions>
        <mention ids_tokens="2" string="It" id_sentence="8" />
        <mention ids_tokens="4-10" string="an example of what Europe is about" id_sentence="8" />
      </mentions>
    </coreference>
    <coreference id="22" type="PROPER">
      <referenced ids_tokens="14-15-16-17-18" string="British Prime Minister Margaret Thatcher" id_sentence="7" />
      <mentions>
        <mention ids_tokens="1" string="Thatcher" id_sentence="19" />
      </mentions>
    </coreference>
    <coreference id="23" type="PROPER">
      <referenced ids_tokens="4-5-6" string="Europe in practice" id_sentence="9" />
      <mentions>
        <mention ids_tokens="2" string="This" id_sentence="11" />
        <mention ids_tokens="4-7" string="a hugely historic moment" id_sentence="11" />
        <mention ids_tokens="9" string="it" id_sentence="11" />
      </mentions>
    </coreference>
    <coreference id="25" type="NOMINAL">
      <referenced ids_tokens="2-3-4" string="a spinning probe" id_sentence="12" />
      <mentions>
        <mention ids_tokens="14-16" string="the probe's" id_sentence="13" />
      </mentions>
    </coreference>
    <coreference id="29" type="NOMINAL">
      <referenced ids_tokens="5-6-7" string="the French side" id_sentence="18" />
      <mentions>
        <mention ids_tokens="2" string="it" id_sentence="35" />
      </mentions>
    </coreference>
    <coreference id="31" type="NOMINAL">
      <referenced ids_tokens="12-13-14-15" string="three tunnels being dug" id_sentence="20" />
      <mentions>
        <mention ids_tokens="1-2" string="The tunnels" id_sentence="32" />
      </mentions>
    </coreference>
    <coreference id="33" type="PROPER">
      <referenced ids_tokens="30-31" string="nearby Sangatte" id_sentence="23" />
      <mentions>
        <mention ids_tokens="25" string="Sangatte" id_sentence="32" />
      </mentions>
    </coreference>
    <coreference id="35" type="NOMINAL">
      <referenced ids_tokens="4-5-6-7-8-9-10-11-12-13-14-15-16" string="together the concrete tunnel lining in the wake of the advancing drill head" id_sentence="28" />
      <mentions>
        <mention ids_tokens="2" string="its" id_sentence="29" />
      </mentions>
    </coreference>
    <coreference id="36" type="NOMINAL">
      <referenced ids_tokens="7-8-9-10-11-12-13" string="the drilling machine on the French side" id_sentence="29" />
      <mentions>
        <mention ids_tokens="9-10" string="the machine" id_sentence="31" />
      </mentions>
    </coreference>
  </coreferences>
</document>
