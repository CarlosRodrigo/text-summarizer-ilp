<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="LA030489-0068">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>A white Long Beach police officer who allegedly pushed a black man through a plate-glass window during an arrest that was secretly videotaped by a television crew acknowledged Friday that he made errors in his official report.</content>
      <tokens>
        <token id="1" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="white" lemma="white" stem="white" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="Long" lemma="long" stem="long" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="Beach" lemma="Beach" stem="beach" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="officer" lemma="officer" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="allegedly" lemma="allegedly" stem="allegedli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="pushed" lemma="push" stem="push" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="black" lemma="black" stem="black" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="man" lemma="man" stem="man" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="15" string="plate-glass" lemma="plate-glass" stem="plate-glass" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="16" string="window" lemma="window" stem="window" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="17" string="during" lemma="during" stem="dure" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="arrest" lemma="arrest" stem="arrest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="secretly" lemma="secretly" stem="secretli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="23" string="videotaped" lemma="videotape" stem="videotap" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="24" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="26" string="television" lemma="television" stem="televis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="27" string="crew" lemma="crew" stem="crew" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="28" string="acknowledged" lemma="acknowledge" stem="acknowledg" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="Friday" lemma="Friday" stem="fridai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="30" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="32" string="made" lemma="make" stem="made" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="errors" lemma="error" stem="error" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="36" string="official" lemma="official" stem="offici" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="report" lemma="report" stem="report" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT A) (JJ white) (JJ Long) (NNP Beach) (NN police) (NN officer)) (SBAR (WHNP (WP who)) (S (ADVP (RB allegedly)) (VP (VBD pushed) (NP (DT a) (JJ black) (NN man)) (PP (IN through) (NP (DT a) (JJ plate-glass) (NN window))) (PP (IN during) (NP (NP (DT an) (NN arrest)) (SBAR (WHNP (WDT that)) (S (VP (VBD was) (ADVP (RB secretly)) (VP (VBN videotaped) (PP (IN by) (NP (DT a) (NN television) (NN crew))))))))))))) (VP (VBD acknowledged) (NP-TMP (NNP Friday)) (SBAR (IN that) (S (NP (PRP he)) (VP (VBD made) (NP (NNS errors)) (PP (IN in) (NP (PRP$ his) (JJ official) (NN report))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="his official report" type="NP">
          <tokens>
            <token id="35" string="his" />
            <token id="36" string="official" />
            <token id="37" string="report" />
          </tokens>
        </chunking>
        <chunking id="2" string="made errors in his official report" type="VP">
          <tokens>
            <token id="32" string="made" />
            <token id="33" string="errors" />
            <token id="34" string="in" />
            <token id="35" string="his" />
            <token id="36" string="official" />
            <token id="37" string="report" />
          </tokens>
        </chunking>
        <chunking id="3" string="pushed a black man through a plate-glass window during an arrest that was secretly videotaped by a television crew" type="VP">
          <tokens>
            <token id="9" string="pushed" />
            <token id="10" string="a" />
            <token id="11" string="black" />
            <token id="12" string="man" />
            <token id="13" string="through" />
            <token id="14" string="a" />
            <token id="15" string="plate-glass" />
            <token id="16" string="window" />
            <token id="17" string="during" />
            <token id="18" string="an" />
            <token id="19" string="arrest" />
            <token id="20" string="that" />
            <token id="21" string="was" />
            <token id="22" string="secretly" />
            <token id="23" string="videotaped" />
            <token id="24" string="by" />
            <token id="25" string="a" />
            <token id="26" string="television" />
            <token id="27" string="crew" />
          </tokens>
        </chunking>
        <chunking id="4" string="A white Long Beach police officer" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="white" />
            <token id="3" string="Long" />
            <token id="4" string="Beach" />
            <token id="5" string="police" />
            <token id="6" string="officer" />
          </tokens>
        </chunking>
        <chunking id="5" string="that was secretly videotaped by a television crew" type="SBAR">
          <tokens>
            <token id="20" string="that" />
            <token id="21" string="was" />
            <token id="22" string="secretly" />
            <token id="23" string="videotaped" />
            <token id="24" string="by" />
            <token id="25" string="a" />
            <token id="26" string="television" />
            <token id="27" string="crew" />
          </tokens>
        </chunking>
        <chunking id="6" string="an arrest" type="NP">
          <tokens>
            <token id="18" string="an" />
            <token id="19" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="7" string="a television crew" type="NP">
          <tokens>
            <token id="25" string="a" />
            <token id="26" string="television" />
            <token id="27" string="crew" />
          </tokens>
        </chunking>
        <chunking id="8" string="A white Long Beach police officer who allegedly pushed a black man through a plate-glass window during an arrest that was secretly videotaped by a television crew" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="white" />
            <token id="3" string="Long" />
            <token id="4" string="Beach" />
            <token id="5" string="police" />
            <token id="6" string="officer" />
            <token id="7" string="who" />
            <token id="8" string="allegedly" />
            <token id="9" string="pushed" />
            <token id="10" string="a" />
            <token id="11" string="black" />
            <token id="12" string="man" />
            <token id="13" string="through" />
            <token id="14" string="a" />
            <token id="15" string="plate-glass" />
            <token id="16" string="window" />
            <token id="17" string="during" />
            <token id="18" string="an" />
            <token id="19" string="arrest" />
            <token id="20" string="that" />
            <token id="21" string="was" />
            <token id="22" string="secretly" />
            <token id="23" string="videotaped" />
            <token id="24" string="by" />
            <token id="25" string="a" />
            <token id="26" string="television" />
            <token id="27" string="crew" />
          </tokens>
        </chunking>
        <chunking id="9" string="acknowledged Friday that he made errors in his official report" type="VP">
          <tokens>
            <token id="28" string="acknowledged" />
            <token id="29" string="Friday" />
            <token id="30" string="that" />
            <token id="31" string="he" />
            <token id="32" string="made" />
            <token id="33" string="errors" />
            <token id="34" string="in" />
            <token id="35" string="his" />
            <token id="36" string="official" />
            <token id="37" string="report" />
          </tokens>
        </chunking>
        <chunking id="10" string="videotaped by a television crew" type="VP">
          <tokens>
            <token id="23" string="videotaped" />
            <token id="24" string="by" />
            <token id="25" string="a" />
            <token id="26" string="television" />
            <token id="27" string="crew" />
          </tokens>
        </chunking>
        <chunking id="11" string="who allegedly pushed a black man through a plate-glass window during an arrest that was secretly videotaped by a television crew" type="SBAR">
          <tokens>
            <token id="7" string="who" />
            <token id="8" string="allegedly" />
            <token id="9" string="pushed" />
            <token id="10" string="a" />
            <token id="11" string="black" />
            <token id="12" string="man" />
            <token id="13" string="through" />
            <token id="14" string="a" />
            <token id="15" string="plate-glass" />
            <token id="16" string="window" />
            <token id="17" string="during" />
            <token id="18" string="an" />
            <token id="19" string="arrest" />
            <token id="20" string="that" />
            <token id="21" string="was" />
            <token id="22" string="secretly" />
            <token id="23" string="videotaped" />
            <token id="24" string="by" />
            <token id="25" string="a" />
            <token id="26" string="television" />
            <token id="27" string="crew" />
          </tokens>
        </chunking>
        <chunking id="12" string="was secretly videotaped by a television crew" type="VP">
          <tokens>
            <token id="21" string="was" />
            <token id="22" string="secretly" />
            <token id="23" string="videotaped" />
            <token id="24" string="by" />
            <token id="25" string="a" />
            <token id="26" string="television" />
            <token id="27" string="crew" />
          </tokens>
        </chunking>
        <chunking id="13" string="an arrest that was secretly videotaped by a television crew" type="NP">
          <tokens>
            <token id="18" string="an" />
            <token id="19" string="arrest" />
            <token id="20" string="that" />
            <token id="21" string="was" />
            <token id="22" string="secretly" />
            <token id="23" string="videotaped" />
            <token id="24" string="by" />
            <token id="25" string="a" />
            <token id="26" string="television" />
            <token id="27" string="crew" />
          </tokens>
        </chunking>
        <chunking id="14" string="he" type="NP">
          <tokens>
            <token id="31" string="he" />
          </tokens>
        </chunking>
        <chunking id="15" string="a black man" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="black" />
            <token id="12" string="man" />
          </tokens>
        </chunking>
        <chunking id="16" string="a plate-glass window" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="plate-glass" />
            <token id="16" string="window" />
          </tokens>
        </chunking>
        <chunking id="17" string="that he made errors in his official report" type="SBAR">
          <tokens>
            <token id="30" string="that" />
            <token id="31" string="he" />
            <token id="32" string="made" />
            <token id="33" string="errors" />
            <token id="34" string="in" />
            <token id="35" string="his" />
            <token id="36" string="official" />
            <token id="37" string="report" />
          </tokens>
        </chunking>
        <chunking id="18" string="errors" type="NP">
          <tokens>
            <token id="33" string="errors" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="6">officer</governor>
          <dependent id="1">A</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">officer</governor>
          <dependent id="2">white</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">officer</governor>
          <dependent id="3">Long</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">officer</governor>
          <dependent id="4">Beach</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">officer</governor>
          <dependent id="5">police</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="28">acknowledged</governor>
          <dependent id="6">officer</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">pushed</governor>
          <dependent id="7">who</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">pushed</governor>
          <dependent id="8">allegedly</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="6">officer</governor>
          <dependent id="9">pushed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">man</governor>
          <dependent id="10">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">man</governor>
          <dependent id="11">black</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">pushed</governor>
          <dependent id="12">man</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">window</governor>
          <dependent id="13">through</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">window</governor>
          <dependent id="14">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">window</governor>
          <dependent id="15">plate-glass</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">pushed</governor>
          <dependent id="16">window</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">arrest</governor>
          <dependent id="17">during</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">arrest</governor>
          <dependent id="18">an</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">pushed</governor>
          <dependent id="19">arrest</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="23">videotaped</governor>
          <dependent id="20">that</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="23">videotaped</governor>
          <dependent id="21">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="23">videotaped</governor>
          <dependent id="22">secretly</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="19">arrest</governor>
          <dependent id="23">videotaped</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">crew</governor>
          <dependent id="24">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">crew</governor>
          <dependent id="25">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">crew</governor>
          <dependent id="26">television</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">videotaped</governor>
          <dependent id="27">crew</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="28">acknowledged</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="28">acknowledged</governor>
          <dependent id="29">Friday</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="32">made</governor>
          <dependent id="30">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="32">made</governor>
          <dependent id="31">he</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="28">acknowledged</governor>
          <dependent id="32">made</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="32">made</governor>
          <dependent id="33">errors</dependent>
        </dependency>
        <dependency type="case">
          <governor id="37">report</governor>
          <dependent id="34">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="37">report</governor>
          <dependent id="35">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="37">report</governor>
          <dependent id="36">official</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="32">made</governor>
          <dependent id="37">report</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Friday" type="DATE" score="0.0">
          <tokens>
            <token id="29" string="Friday" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>Officer Mark Dickey, speaking publicly for the first time since the Jan. 14 incident, told a state Senate oversight committee in sworn testimony that he had so little faith in his own report that he would not want it used against him if he were suspected of a crime.</content>
      <tokens>
        <token id="1" string="Officer" lemma="Officer" stem="officer" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="Mark" lemma="Mark" stem="mark" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="Dickey" lemma="Dickey" stem="dickei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="speaking" lemma="speak" stem="speak" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="publicly" lemma="publicly" stem="publicli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="true" is_refers="false" />
        <token id="10" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="since" lemma="since" stem="sinc" pos="IN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="Jan." lemma="Jan." stem="jan." pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="14" string="14" lemma="14" stem="14" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="15" string="incident" lemma="incident" stem="incid" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="told" lemma="tell" stem="told" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="state" lemma="state" stem="state" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="Senate" lemma="Senate" stem="senat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="21" string="oversight" lemma="oversight" stem="oversight" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="committee" lemma="committee" stem="committe" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="sworn" lemma="swear" stem="sworn" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="25" string="testimony" lemma="testimony" stem="testimoni" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="26" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="27" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="28" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="29" string="so" lemma="so" stem="so" pos="RB" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="30" string="little" lemma="little" stem="littl" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="31" string="faith" lemma="faith" stem="faith" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="32" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="33" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="34" string="own" lemma="own" stem="own" pos="JJ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="35" string="report" lemma="report" stem="report" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="36" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="want" lemma="want" stem="want" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="used" lemma="use" stem="us" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="46" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="47" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="48" string="suspected" lemma="suspect" stem="suspect" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="49" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="50" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="51" string="crime" lemma="crime" stem="crime" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="52" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Officer) (NNP Mark) (NNP Dickey)) (, ,) (VP (VBG speaking) (ADVP (RB publicly)) (PP (IN for) (NP (NP (DT the) (JJ first) (NN time)) (PP (IN since) (NP (DT the) (NNP Jan.) (CD 14) (NN incident)))))) (, ,)) (VP (VBD told) (NP (DT a) (NN state)) (PP (NP (NNP Senate) (NN oversight) (NN committee)) (IN in) (NP (VBN sworn) (NN testimony) (SBAR (IN that) (S (NP (PRP he)) (VP (VBD had) (NP (ADJP (RB so) (JJ little)) (NN faith)) (PP (IN in) (NP (PRP$ his) (JJ own) (NN report)))))))) (SBAR (IN that) (S (NP (PRP he)) (VP (MD would) (RB not) (VP (VB want) (S (NP (PRP it)) (VP (VBN used) (PP (IN against) (NP (PRP him))))) (SBAR (IN if) (S (NP (PRP he)) (VP (VBD were) (VP (VBN suspected) (PP (IN of) (NP (DT a) (NN crime)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="would not want it used against him if he were suspected of a crime" type="VP">
          <tokens>
            <token id="38" string="would" />
            <token id="39" string="not" />
            <token id="40" string="want" />
            <token id="41" string="it" />
            <token id="42" string="used" />
            <token id="43" string="against" />
            <token id="44" string="him" />
            <token id="45" string="if" />
            <token id="46" string="he" />
            <token id="47" string="were" />
            <token id="48" string="suspected" />
            <token id="49" string="of" />
            <token id="50" string="a" />
            <token id="51" string="crime" />
          </tokens>
        </chunking>
        <chunking id="2" string="the first time since the Jan. 14 incident" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="first" />
            <token id="10" string="time" />
            <token id="11" string="since" />
            <token id="12" string="the" />
            <token id="13" string="Jan." />
            <token id="14" string="14" />
            <token id="15" string="incident" />
          </tokens>
        </chunking>
        <chunking id="3" string="it" type="NP">
          <tokens>
            <token id="41" string="it" />
          </tokens>
        </chunking>
        <chunking id="4" string="the Jan. 14 incident" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="Jan." />
            <token id="14" string="14" />
            <token id="15" string="incident" />
          </tokens>
        </chunking>
        <chunking id="5" string="his own report" type="NP">
          <tokens>
            <token id="33" string="his" />
            <token id="34" string="own" />
            <token id="35" string="report" />
          </tokens>
        </chunking>
        <chunking id="6" string="if he were suspected of a crime" type="SBAR">
          <tokens>
            <token id="45" string="if" />
            <token id="46" string="he" />
            <token id="47" string="were" />
            <token id="48" string="suspected" />
            <token id="49" string="of" />
            <token id="50" string="a" />
            <token id="51" string="crime" />
          </tokens>
        </chunking>
        <chunking id="7" string="Officer Mark Dickey , speaking publicly for the first time since the Jan. 14 incident ," type="NP">
          <tokens>
            <token id="1" string="Officer" />
            <token id="2" string="Mark" />
            <token id="3" string="Dickey" />
            <token id="4" string="," />
            <token id="5" string="speaking" />
            <token id="6" string="publicly" />
            <token id="7" string="for" />
            <token id="8" string="the" />
            <token id="9" string="first" />
            <token id="10" string="time" />
            <token id="11" string="since" />
            <token id="12" string="the" />
            <token id="13" string="Jan." />
            <token id="14" string="14" />
            <token id="15" string="incident" />
            <token id="16" string="," />
          </tokens>
        </chunking>
        <chunking id="8" string="a crime" type="NP">
          <tokens>
            <token id="50" string="a" />
            <token id="51" string="crime" />
          </tokens>
        </chunking>
        <chunking id="9" string="a state" type="NP">
          <tokens>
            <token id="18" string="a" />
            <token id="19" string="state" />
          </tokens>
        </chunking>
        <chunking id="10" string="used against him" type="VP">
          <tokens>
            <token id="42" string="used" />
            <token id="43" string="against" />
            <token id="44" string="him" />
          </tokens>
        </chunking>
        <chunking id="11" string="suspected of a crime" type="VP">
          <tokens>
            <token id="48" string="suspected" />
            <token id="49" string="of" />
            <token id="50" string="a" />
            <token id="51" string="crime" />
          </tokens>
        </chunking>
        <chunking id="12" string="were suspected of a crime" type="VP">
          <tokens>
            <token id="47" string="were" />
            <token id="48" string="suspected" />
            <token id="49" string="of" />
            <token id="50" string="a" />
            <token id="51" string="crime" />
          </tokens>
        </chunking>
        <chunking id="13" string="had so little faith in his own report" type="VP">
          <tokens>
            <token id="28" string="had" />
            <token id="29" string="so" />
            <token id="30" string="little" />
            <token id="31" string="faith" />
            <token id="32" string="in" />
            <token id="33" string="his" />
            <token id="34" string="own" />
            <token id="35" string="report" />
          </tokens>
        </chunking>
        <chunking id="14" string="he" type="NP">
          <tokens>
            <token id="27" string="he" />
          </tokens>
        </chunking>
        <chunking id="15" string="want it used against him if he were suspected of a crime" type="VP">
          <tokens>
            <token id="40" string="want" />
            <token id="41" string="it" />
            <token id="42" string="used" />
            <token id="43" string="against" />
            <token id="44" string="him" />
            <token id="45" string="if" />
            <token id="46" string="he" />
            <token id="47" string="were" />
            <token id="48" string="suspected" />
            <token id="49" string="of" />
            <token id="50" string="a" />
            <token id="51" string="crime" />
          </tokens>
        </chunking>
        <chunking id="16" string="that he would not want it used against him if he were suspected of a crime" type="SBAR">
          <tokens>
            <token id="36" string="that" />
            <token id="37" string="he" />
            <token id="38" string="would" />
            <token id="39" string="not" />
            <token id="40" string="want" />
            <token id="41" string="it" />
            <token id="42" string="used" />
            <token id="43" string="against" />
            <token id="44" string="him" />
            <token id="45" string="if" />
            <token id="46" string="he" />
            <token id="47" string="were" />
            <token id="48" string="suspected" />
            <token id="49" string="of" />
            <token id="50" string="a" />
            <token id="51" string="crime" />
          </tokens>
        </chunking>
        <chunking id="17" string="Senate oversight committee" type="NP">
          <tokens>
            <token id="20" string="Senate" />
            <token id="21" string="oversight" />
            <token id="22" string="committee" />
          </tokens>
        </chunking>
        <chunking id="18" string="so little faith" type="NP">
          <tokens>
            <token id="29" string="so" />
            <token id="30" string="little" />
            <token id="31" string="faith" />
          </tokens>
        </chunking>
        <chunking id="19" string="that he had so little faith in his own report" type="SBAR">
          <tokens>
            <token id="26" string="that" />
            <token id="27" string="he" />
            <token id="28" string="had" />
            <token id="29" string="so" />
            <token id="30" string="little" />
            <token id="31" string="faith" />
            <token id="32" string="in" />
            <token id="33" string="his" />
            <token id="34" string="own" />
            <token id="35" string="report" />
          </tokens>
        </chunking>
        <chunking id="20" string="so little" type="ADJP">
          <tokens>
            <token id="29" string="so" />
            <token id="30" string="little" />
          </tokens>
        </chunking>
        <chunking id="21" string="him" type="NP">
          <tokens>
            <token id="44" string="him" />
          </tokens>
        </chunking>
        <chunking id="22" string="the first time" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="first" />
            <token id="10" string="time" />
          </tokens>
        </chunking>
        <chunking id="23" string="Officer Mark Dickey" type="NP">
          <tokens>
            <token id="1" string="Officer" />
            <token id="2" string="Mark" />
            <token id="3" string="Dickey" />
          </tokens>
        </chunking>
        <chunking id="24" string="speaking publicly for the first time since the Jan. 14 incident" type="VP">
          <tokens>
            <token id="5" string="speaking" />
            <token id="6" string="publicly" />
            <token id="7" string="for" />
            <token id="8" string="the" />
            <token id="9" string="first" />
            <token id="10" string="time" />
            <token id="11" string="since" />
            <token id="12" string="the" />
            <token id="13" string="Jan." />
            <token id="14" string="14" />
            <token id="15" string="incident" />
          </tokens>
        </chunking>
        <chunking id="25" string="told a state Senate oversight committee in sworn testimony that he had so little faith in his own report that he would not want it used against him if he were suspected of a crime" type="VP">
          <tokens>
            <token id="17" string="told" />
            <token id="18" string="a" />
            <token id="19" string="state" />
            <token id="20" string="Senate" />
            <token id="21" string="oversight" />
            <token id="22" string="committee" />
            <token id="23" string="in" />
            <token id="24" string="sworn" />
            <token id="25" string="testimony" />
            <token id="26" string="that" />
            <token id="27" string="he" />
            <token id="28" string="had" />
            <token id="29" string="so" />
            <token id="30" string="little" />
            <token id="31" string="faith" />
            <token id="32" string="in" />
            <token id="33" string="his" />
            <token id="34" string="own" />
            <token id="35" string="report" />
            <token id="36" string="that" />
            <token id="37" string="he" />
            <token id="38" string="would" />
            <token id="39" string="not" />
            <token id="40" string="want" />
            <token id="41" string="it" />
            <token id="42" string="used" />
            <token id="43" string="against" />
            <token id="44" string="him" />
            <token id="45" string="if" />
            <token id="46" string="he" />
            <token id="47" string="were" />
            <token id="48" string="suspected" />
            <token id="49" string="of" />
            <token id="50" string="a" />
            <token id="51" string="crime" />
          </tokens>
        </chunking>
        <chunking id="26" string="sworn testimony that he had so little faith in his own report" type="NP">
          <tokens>
            <token id="24" string="sworn" />
            <token id="25" string="testimony" />
            <token id="26" string="that" />
            <token id="27" string="he" />
            <token id="28" string="had" />
            <token id="29" string="so" />
            <token id="30" string="little" />
            <token id="31" string="faith" />
            <token id="32" string="in" />
            <token id="33" string="his" />
            <token id="34" string="own" />
            <token id="35" string="report" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">Dickey</governor>
          <dependent id="1">Officer</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Dickey</governor>
          <dependent id="2">Mark</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">told</governor>
          <dependent id="3">Dickey</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="3">Dickey</governor>
          <dependent id="5">speaking</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">speaking</governor>
          <dependent id="6">publicly</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">time</governor>
          <dependent id="7">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">time</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">time</governor>
          <dependent id="9">first</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">speaking</governor>
          <dependent id="10">time</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">incident</governor>
          <dependent id="11">since</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">incident</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">incident</governor>
          <dependent id="13">Jan.</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="15">incident</governor>
          <dependent id="14">14</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">time</governor>
          <dependent id="15">incident</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="17">told</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">state</governor>
          <dependent id="18">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">told</governor>
          <dependent id="19">state</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">committee</governor>
          <dependent id="20">Senate</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">committee</governor>
          <dependent id="21">oversight</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">told</governor>
          <dependent id="22">committee</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">committee</governor>
          <dependent id="23">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">testimony</governor>
          <dependent id="24">sworn</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="22">committee</governor>
          <dependent id="25">testimony</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="28">had</governor>
          <dependent id="26">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="28">had</governor>
          <dependent id="27">he</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="25">testimony</governor>
          <dependent id="28">had</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="30">little</governor>
          <dependent id="29">so</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="31">faith</governor>
          <dependent id="30">little</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="28">had</governor>
          <dependent id="31">faith</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">report</governor>
          <dependent id="32">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="35">report</governor>
          <dependent id="33">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="35">report</governor>
          <dependent id="34">own</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">had</governor>
          <dependent id="35">report</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="40">want</governor>
          <dependent id="36">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="40">want</governor>
          <dependent id="37">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="40">want</governor>
          <dependent id="38">would</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="40">want</governor>
          <dependent id="39">not</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="17">told</governor>
          <dependent id="40">want</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="42">used</governor>
          <dependent id="41">it</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="40">want</governor>
          <dependent id="42">used</dependent>
        </dependency>
        <dependency type="case">
          <governor id="44">him</governor>
          <dependent id="43">against</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="42">used</governor>
          <dependent id="44">him</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="48">suspected</governor>
          <dependent id="45">if</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="48">suspected</governor>
          <dependent id="46">he</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="48">suspected</governor>
          <dependent id="47">were</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="40">want</governor>
          <dependent id="48">suspected</dependent>
        </dependency>
        <dependency type="case">
          <governor id="51">crime</governor>
          <dependent id="49">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="51">crime</governor>
          <dependent id="50">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="48">suspected</governor>
          <dependent id="51">crime</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="9" string="first" />
          </tokens>
        </entity>
        <entity id="2" string="Senate" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="20" string="Senate" />
          </tokens>
        </entity>
        <entity id="3" string="Jan. 14" type="DATE" score="0.0">
          <tokens>
            <token id="13" string="Jan." />
            <token id="14" string="14" />
          </tokens>
        </entity>
        <entity id="4" string="Mark Dickey" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Mark" />
            <token id="3" string="Dickey" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>He blamed the discrepancies on a faulty memory, saying he wrote the report more than three hours after the altercation occurred.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="blamed" lemma="blame" stem="blame" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="discrepancies" lemma="discrepancy" stem="discrep" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="faulty" lemma="faulty" stem="faulti" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="memory" lemma="memory" stem="memori" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="saying" lemma="say" stem="sai" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="wrote" lemma="write" stem="wrote" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="report" lemma="report" stem="report" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="16" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="17" string="three" lemma="three" stem="three" pos="CD" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="18" string="hours" lemma="hour" stem="hour" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="19" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="altercation" lemma="altercation" stem="alterc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="occurred" lemma="occur" stem="occur" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VBD blamed) (NP (DT the) (NNS discrepancies)) (PP (IN on) (NP (DT a) (JJ faulty) (NN memory))) (, ,) (S (VP (VBG saying) (SBAR (S (NP (PRP he)) (VP (VBD wrote) (NP (DT the) (NN report)) (SBAR (NP (QP (RBR more) (IN than) (CD three)) (NNS hours)) (IN after) (S (NP (DT the) (NN altercation)) (VP (VBD occurred)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="blamed the discrepancies on a faulty memory , saying he wrote the report more than three hours after the altercation occurred" type="VP">
          <tokens>
            <token id="2" string="blamed" />
            <token id="3" string="the" />
            <token id="4" string="discrepancies" />
            <token id="5" string="on" />
            <token id="6" string="a" />
            <token id="7" string="faulty" />
            <token id="8" string="memory" />
            <token id="9" string="," />
            <token id="10" string="saying" />
            <token id="11" string="he" />
            <token id="12" string="wrote" />
            <token id="13" string="the" />
            <token id="14" string="report" />
            <token id="15" string="more" />
            <token id="16" string="than" />
            <token id="17" string="three" />
            <token id="18" string="hours" />
            <token id="19" string="after" />
            <token id="20" string="the" />
            <token id="21" string="altercation" />
            <token id="22" string="occurred" />
          </tokens>
        </chunking>
        <chunking id="2" string="occurred" type="VP">
          <tokens>
            <token id="22" string="occurred" />
          </tokens>
        </chunking>
        <chunking id="3" string="more than three hours after the altercation occurred" type="SBAR">
          <tokens>
            <token id="15" string="more" />
            <token id="16" string="than" />
            <token id="17" string="three" />
            <token id="18" string="hours" />
            <token id="19" string="after" />
            <token id="20" string="the" />
            <token id="21" string="altercation" />
            <token id="22" string="occurred" />
          </tokens>
        </chunking>
        <chunking id="4" string="wrote the report more than three hours after the altercation occurred" type="VP">
          <tokens>
            <token id="12" string="wrote" />
            <token id="13" string="the" />
            <token id="14" string="report" />
            <token id="15" string="more" />
            <token id="16" string="than" />
            <token id="17" string="three" />
            <token id="18" string="hours" />
            <token id="19" string="after" />
            <token id="20" string="the" />
            <token id="21" string="altercation" />
            <token id="22" string="occurred" />
          </tokens>
        </chunking>
        <chunking id="5" string="saying he wrote the report more than three hours after the altercation occurred" type="VP">
          <tokens>
            <token id="10" string="saying" />
            <token id="11" string="he" />
            <token id="12" string="wrote" />
            <token id="13" string="the" />
            <token id="14" string="report" />
            <token id="15" string="more" />
            <token id="16" string="than" />
            <token id="17" string="three" />
            <token id="18" string="hours" />
            <token id="19" string="after" />
            <token id="20" string="the" />
            <token id="21" string="altercation" />
            <token id="22" string="occurred" />
          </tokens>
        </chunking>
        <chunking id="6" string="the altercation" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="altercation" />
          </tokens>
        </chunking>
        <chunking id="7" string="a faulty memory" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="faulty" />
            <token id="8" string="memory" />
          </tokens>
        </chunking>
        <chunking id="8" string="the discrepancies" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="discrepancies" />
          </tokens>
        </chunking>
        <chunking id="9" string="he wrote the report more than three hours after the altercation occurred" type="SBAR">
          <tokens>
            <token id="11" string="he" />
            <token id="12" string="wrote" />
            <token id="13" string="the" />
            <token id="14" string="report" />
            <token id="15" string="more" />
            <token id="16" string="than" />
            <token id="17" string="three" />
            <token id="18" string="hours" />
            <token id="19" string="after" />
            <token id="20" string="the" />
            <token id="21" string="altercation" />
            <token id="22" string="occurred" />
          </tokens>
        </chunking>
        <chunking id="10" string="more than three hours" type="NP">
          <tokens>
            <token id="15" string="more" />
            <token id="16" string="than" />
            <token id="17" string="three" />
            <token id="18" string="hours" />
          </tokens>
        </chunking>
        <chunking id="11" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="12" string="he" type="NP">
          <tokens>
            <token id="11" string="he" />
          </tokens>
        </chunking>
        <chunking id="13" string="the report" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="report" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">blamed</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">blamed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">discrepancies</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">blamed</governor>
          <dependent id="4">discrepancies</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">memory</governor>
          <dependent id="5">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">memory</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">memory</governor>
          <dependent id="7">faulty</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">blamed</governor>
          <dependent id="8">memory</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="2">blamed</governor>
          <dependent id="10">saying</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">wrote</governor>
          <dependent id="11">he</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">saying</governor>
          <dependent id="12">wrote</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">report</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">wrote</governor>
          <dependent id="14">report</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="17">three</governor>
          <dependent id="15">more</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="15">more</governor>
          <dependent id="16">than</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="18">hours</governor>
          <dependent id="17">three</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="22">occurred</governor>
          <dependent id="18">hours</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">occurred</governor>
          <dependent id="19">after</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">altercation</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">occurred</governor>
          <dependent id="21">altercation</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="12">wrote</governor>
          <dependent id="22">occurred</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="more than three hours" type="DURATION" score="0.0">
          <tokens>
            <token id="15" string="more" />
            <token id="16" string="than" />
            <token id="17" string="three" />
            <token id="18" string="hours" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>Dickey, who was testifying under subpoena, admitted under questioning that the black man, Don Jackson, never used profanity during the arrest as Dickey had indicated in his report.</content>
      <tokens>
        <token id="1" string="Dickey" lemma="Dickey" stem="dickei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="testifying" lemma="testify" stem="testifi" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="under" lemma="under" stem="under" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="subpoena" lemma="subpoena" stem="subpoena" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="admitted" lemma="admit" stem="admit" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="under" lemma="under" stem="under" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="questioning" lemma="question" stem="question" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="black" lemma="black" stem="black" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="man" lemma="man" stem="man" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Don" lemma="Don" stem="don" pos="NNP" type="Word" isStopWord="true" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="18" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="used" lemma="use" stem="us" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="profanity" lemma="profanity" stem="profan" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="during" lemma="during" stem="dure" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="25" string="arrest" lemma="arrest" stem="arrest" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="26" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="Dickey" lemma="Dickey" stem="dickei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="28" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="indicated" lemma="indicate" stem="indic" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="32" string="report" lemma="report" stem="report" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Dickey)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBD was) (VP (VBG testifying) (PP (IN under) (NP (NN subpoena))))))) (, ,)) (VP (VBN admitted) (PP (IN under) (S (VP (VBG questioning) (SBAR (IN that) (S (NP (NP (DT the) (JJ black) (NN man)) (, ,) (NP (NNP Don) (NNP Jackson)) (, ,)) (ADVP (RB never)) (VP (VBN used) (NP (NN profanity)) (PP (IN during) (NP (DT the) (NN arrest))) (SBAR (IN as) (S (NP (NNP Dickey)) (VP (VBD had) (VP (VBN indicated) (PP (IN in) (NP (PRP$ his) (NN report)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="subpoena" type="NP">
          <tokens>
            <token id="7" string="subpoena" />
          </tokens>
        </chunking>
        <chunking id="2" string="his report" type="NP">
          <tokens>
            <token id="31" string="his" />
            <token id="32" string="report" />
          </tokens>
        </chunking>
        <chunking id="3" string="profanity" type="NP">
          <tokens>
            <token id="22" string="profanity" />
          </tokens>
        </chunking>
        <chunking id="4" string="admitted under questioning that the black man , Don Jackson , never used profanity during the arrest as Dickey had indicated in his report" type="VP">
          <tokens>
            <token id="9" string="admitted" />
            <token id="10" string="under" />
            <token id="11" string="questioning" />
            <token id="12" string="that" />
            <token id="13" string="the" />
            <token id="14" string="black" />
            <token id="15" string="man" />
            <token id="16" string="," />
            <token id="17" string="Don" />
            <token id="18" string="Jackson" />
            <token id="19" string="," />
            <token id="20" string="never" />
            <token id="21" string="used" />
            <token id="22" string="profanity" />
            <token id="23" string="during" />
            <token id="24" string="the" />
            <token id="25" string="arrest" />
            <token id="26" string="as" />
            <token id="27" string="Dickey" />
            <token id="28" string="had" />
            <token id="29" string="indicated" />
            <token id="30" string="in" />
            <token id="31" string="his" />
            <token id="32" string="report" />
          </tokens>
        </chunking>
        <chunking id="5" string="who was testifying under subpoena" type="SBAR">
          <tokens>
            <token id="3" string="who" />
            <token id="4" string="was" />
            <token id="5" string="testifying" />
            <token id="6" string="under" />
            <token id="7" string="subpoena" />
          </tokens>
        </chunking>
        <chunking id="6" string="the arrest" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="7" string="Don Jackson" type="NP">
          <tokens>
            <token id="17" string="Don" />
            <token id="18" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="8" string="as Dickey had indicated in his report" type="SBAR">
          <tokens>
            <token id="26" string="as" />
            <token id="27" string="Dickey" />
            <token id="28" string="had" />
            <token id="29" string="indicated" />
            <token id="30" string="in" />
            <token id="31" string="his" />
            <token id="32" string="report" />
          </tokens>
        </chunking>
        <chunking id="9" string="the black man , Don Jackson ," type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="black" />
            <token id="15" string="man" />
            <token id="16" string="," />
            <token id="17" string="Don" />
            <token id="18" string="Jackson" />
            <token id="19" string="," />
          </tokens>
        </chunking>
        <chunking id="10" string="the black man" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="black" />
            <token id="15" string="man" />
          </tokens>
        </chunking>
        <chunking id="11" string="questioning that the black man , Don Jackson , never used profanity during the arrest as Dickey had indicated in his report" type="VP">
          <tokens>
            <token id="11" string="questioning" />
            <token id="12" string="that" />
            <token id="13" string="the" />
            <token id="14" string="black" />
            <token id="15" string="man" />
            <token id="16" string="," />
            <token id="17" string="Don" />
            <token id="18" string="Jackson" />
            <token id="19" string="," />
            <token id="20" string="never" />
            <token id="21" string="used" />
            <token id="22" string="profanity" />
            <token id="23" string="during" />
            <token id="24" string="the" />
            <token id="25" string="arrest" />
            <token id="26" string="as" />
            <token id="27" string="Dickey" />
            <token id="28" string="had" />
            <token id="29" string="indicated" />
            <token id="30" string="in" />
            <token id="31" string="his" />
            <token id="32" string="report" />
          </tokens>
        </chunking>
        <chunking id="12" string="used profanity during the arrest as Dickey had indicated in his report" type="VP">
          <tokens>
            <token id="21" string="used" />
            <token id="22" string="profanity" />
            <token id="23" string="during" />
            <token id="24" string="the" />
            <token id="25" string="arrest" />
            <token id="26" string="as" />
            <token id="27" string="Dickey" />
            <token id="28" string="had" />
            <token id="29" string="indicated" />
            <token id="30" string="in" />
            <token id="31" string="his" />
            <token id="32" string="report" />
          </tokens>
        </chunking>
        <chunking id="13" string="Dickey , who was testifying under subpoena ," type="NP">
          <tokens>
            <token id="1" string="Dickey" />
            <token id="2" string="," />
            <token id="3" string="who" />
            <token id="4" string="was" />
            <token id="5" string="testifying" />
            <token id="6" string="under" />
            <token id="7" string="subpoena" />
            <token id="8" string="," />
          </tokens>
        </chunking>
        <chunking id="14" string="was testifying under subpoena" type="VP">
          <tokens>
            <token id="4" string="was" />
            <token id="5" string="testifying" />
            <token id="6" string="under" />
            <token id="7" string="subpoena" />
          </tokens>
        </chunking>
        <chunking id="15" string="had indicated in his report" type="VP">
          <tokens>
            <token id="28" string="had" />
            <token id="29" string="indicated" />
            <token id="30" string="in" />
            <token id="31" string="his" />
            <token id="32" string="report" />
          </tokens>
        </chunking>
        <chunking id="16" string="testifying under subpoena" type="VP">
          <tokens>
            <token id="5" string="testifying" />
            <token id="6" string="under" />
            <token id="7" string="subpoena" />
          </tokens>
        </chunking>
        <chunking id="17" string="Dickey" type="NP">
          <tokens>
            <token id="1" string="Dickey" />
          </tokens>
        </chunking>
        <chunking id="18" string="that the black man , Don Jackson , never used profanity during the arrest as Dickey had indicated in his report" type="SBAR">
          <tokens>
            <token id="12" string="that" />
            <token id="13" string="the" />
            <token id="14" string="black" />
            <token id="15" string="man" />
            <token id="16" string="," />
            <token id="17" string="Don" />
            <token id="18" string="Jackson" />
            <token id="19" string="," />
            <token id="20" string="never" />
            <token id="21" string="used" />
            <token id="22" string="profanity" />
            <token id="23" string="during" />
            <token id="24" string="the" />
            <token id="25" string="arrest" />
            <token id="26" string="as" />
            <token id="27" string="Dickey" />
            <token id="28" string="had" />
            <token id="29" string="indicated" />
            <token id="30" string="in" />
            <token id="31" string="his" />
            <token id="32" string="report" />
          </tokens>
        </chunking>
        <chunking id="19" string="indicated in his report" type="VP">
          <tokens>
            <token id="29" string="indicated" />
            <token id="30" string="in" />
            <token id="31" string="his" />
            <token id="32" string="report" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="9">admitted</governor>
          <dependent id="1">Dickey</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">testifying</governor>
          <dependent id="3">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">testifying</governor>
          <dependent id="4">was</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="1">Dickey</governor>
          <dependent id="5">testifying</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">subpoena</governor>
          <dependent id="6">under</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">testifying</governor>
          <dependent id="7">subpoena</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">admitted</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">questioning</governor>
          <dependent id="10">under</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="9">admitted</governor>
          <dependent id="11">questioning</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="21">used</governor>
          <dependent id="12">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">man</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">man</governor>
          <dependent id="14">black</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">used</governor>
          <dependent id="15">man</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Jackson</governor>
          <dependent id="17">Don</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="15">man</governor>
          <dependent id="18">Jackson</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="21">used</governor>
          <dependent id="20">never</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">questioning</governor>
          <dependent id="21">used</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">used</governor>
          <dependent id="22">profanity</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">arrest</governor>
          <dependent id="23">during</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">arrest</governor>
          <dependent id="24">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">used</governor>
          <dependent id="25">arrest</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="29">indicated</governor>
          <dependent id="26">as</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">indicated</governor>
          <dependent id="27">Dickey</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="29">indicated</governor>
          <dependent id="28">had</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="21">used</governor>
          <dependent id="29">indicated</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">report</governor>
          <dependent id="30">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="32">report</governor>
          <dependent id="31">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">indicated</governor>
          <dependent id="32">report</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Don Jackson" type="PERSON" score="0.0">
          <tokens>
            <token id="17" string="Don" />
            <token id="18" string="Jackson" />
          </tokens>
        </entity>
        <entity id="2" string="Dickey" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Dickey" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>Dickey also admitted that he intended to inflict pain on Jackson when he put handcuffs on him as a way to control him.</content>
      <tokens>
        <token id="1" string="Dickey" lemma="Dickey" stem="dickei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="admitted" lemma="admit" stem="admit" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="intended" lemma="intend" stem="intend" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="inflict" lemma="inflict" stem="inflict" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="pain" lemma="pain" stem="pain" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="12" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="put" lemma="put" stem="put" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="handcuffs" lemma="handcuffs" stem="handcuff" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="way" lemma="way" stem="wai" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="control" lemma="control" stem="control" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Dickey)) (ADVP (RB also)) (VP (VBD admitted) (SBAR (IN that) (S (NP (PRP he)) (VP (VBD intended) (S (VP (TO to) (VP (VB inflict) (NP (NN pain)) (PP (IN on) (NP (NNP Jackson))) (SBAR (WHADVP (WRB when)) (S (NP (PRP he)) (VP (VBD put) (NP (NNS handcuffs)) (PP (IN on) (NP (PRP him))) (PP (IN as) (NP (DT a) (NN way) (S (VP (TO to) (VP (VB control) (NP (PRP him))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="admitted that he intended to inflict pain on Jackson when he put handcuffs on him as a way to control him" type="VP">
          <tokens>
            <token id="3" string="admitted" />
            <token id="4" string="that" />
            <token id="5" string="he" />
            <token id="6" string="intended" />
            <token id="7" string="to" />
            <token id="8" string="inflict" />
            <token id="9" string="pain" />
            <token id="10" string="on" />
            <token id="11" string="Jackson" />
            <token id="12" string="when" />
            <token id="13" string="he" />
            <token id="14" string="put" />
            <token id="15" string="handcuffs" />
            <token id="16" string="on" />
            <token id="17" string="him" />
            <token id="18" string="as" />
            <token id="19" string="a" />
            <token id="20" string="way" />
            <token id="21" string="to" />
            <token id="22" string="control" />
            <token id="23" string="him" />
          </tokens>
        </chunking>
        <chunking id="2" string="pain" type="NP">
          <tokens>
            <token id="9" string="pain" />
          </tokens>
        </chunking>
        <chunking id="3" string="when he put handcuffs on him as a way to control him" type="SBAR">
          <tokens>
            <token id="12" string="when" />
            <token id="13" string="he" />
            <token id="14" string="put" />
            <token id="15" string="handcuffs" />
            <token id="16" string="on" />
            <token id="17" string="him" />
            <token id="18" string="as" />
            <token id="19" string="a" />
            <token id="20" string="way" />
            <token id="21" string="to" />
            <token id="22" string="control" />
            <token id="23" string="him" />
          </tokens>
        </chunking>
        <chunking id="4" string="control him" type="VP">
          <tokens>
            <token id="22" string="control" />
            <token id="23" string="him" />
          </tokens>
        </chunking>
        <chunking id="5" string="that he intended to inflict pain on Jackson when he put handcuffs on him as a way to control him" type="SBAR">
          <tokens>
            <token id="4" string="that" />
            <token id="5" string="he" />
            <token id="6" string="intended" />
            <token id="7" string="to" />
            <token id="8" string="inflict" />
            <token id="9" string="pain" />
            <token id="10" string="on" />
            <token id="11" string="Jackson" />
            <token id="12" string="when" />
            <token id="13" string="he" />
            <token id="14" string="put" />
            <token id="15" string="handcuffs" />
            <token id="16" string="on" />
            <token id="17" string="him" />
            <token id="18" string="as" />
            <token id="19" string="a" />
            <token id="20" string="way" />
            <token id="21" string="to" />
            <token id="22" string="control" />
            <token id="23" string="him" />
          </tokens>
        </chunking>
        <chunking id="6" string="a way to control him" type="NP">
          <tokens>
            <token id="19" string="a" />
            <token id="20" string="way" />
            <token id="21" string="to" />
            <token id="22" string="control" />
            <token id="23" string="him" />
          </tokens>
        </chunking>
        <chunking id="7" string="intended to inflict pain on Jackson when he put handcuffs on him as a way to control him" type="VP">
          <tokens>
            <token id="6" string="intended" />
            <token id="7" string="to" />
            <token id="8" string="inflict" />
            <token id="9" string="pain" />
            <token id="10" string="on" />
            <token id="11" string="Jackson" />
            <token id="12" string="when" />
            <token id="13" string="he" />
            <token id="14" string="put" />
            <token id="15" string="handcuffs" />
            <token id="16" string="on" />
            <token id="17" string="him" />
            <token id="18" string="as" />
            <token id="19" string="a" />
            <token id="20" string="way" />
            <token id="21" string="to" />
            <token id="22" string="control" />
            <token id="23" string="him" />
          </tokens>
        </chunking>
        <chunking id="8" string="Jackson" type="NP">
          <tokens>
            <token id="11" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="9" string="him" type="NP">
          <tokens>
            <token id="17" string="him" />
          </tokens>
        </chunking>
        <chunking id="10" string="handcuffs" type="NP">
          <tokens>
            <token id="15" string="handcuffs" />
          </tokens>
        </chunking>
        <chunking id="11" string="to control him" type="VP">
          <tokens>
            <token id="21" string="to" />
            <token id="22" string="control" />
            <token id="23" string="him" />
          </tokens>
        </chunking>
        <chunking id="12" string="when" type="WHADVP">
          <tokens>
            <token id="12" string="when" />
          </tokens>
        </chunking>
        <chunking id="13" string="inflict pain on Jackson when he put handcuffs on him as a way to control him" type="VP">
          <tokens>
            <token id="8" string="inflict" />
            <token id="9" string="pain" />
            <token id="10" string="on" />
            <token id="11" string="Jackson" />
            <token id="12" string="when" />
            <token id="13" string="he" />
            <token id="14" string="put" />
            <token id="15" string="handcuffs" />
            <token id="16" string="on" />
            <token id="17" string="him" />
            <token id="18" string="as" />
            <token id="19" string="a" />
            <token id="20" string="way" />
            <token id="21" string="to" />
            <token id="22" string="control" />
            <token id="23" string="him" />
          </tokens>
        </chunking>
        <chunking id="14" string="to inflict pain on Jackson when he put handcuffs on him as a way to control him" type="VP">
          <tokens>
            <token id="7" string="to" />
            <token id="8" string="inflict" />
            <token id="9" string="pain" />
            <token id="10" string="on" />
            <token id="11" string="Jackson" />
            <token id="12" string="when" />
            <token id="13" string="he" />
            <token id="14" string="put" />
            <token id="15" string="handcuffs" />
            <token id="16" string="on" />
            <token id="17" string="him" />
            <token id="18" string="as" />
            <token id="19" string="a" />
            <token id="20" string="way" />
            <token id="21" string="to" />
            <token id="22" string="control" />
            <token id="23" string="him" />
          </tokens>
        </chunking>
        <chunking id="15" string="put handcuffs on him as a way to control him" type="VP">
          <tokens>
            <token id="14" string="put" />
            <token id="15" string="handcuffs" />
            <token id="16" string="on" />
            <token id="17" string="him" />
            <token id="18" string="as" />
            <token id="19" string="a" />
            <token id="20" string="way" />
            <token id="21" string="to" />
            <token id="22" string="control" />
            <token id="23" string="him" />
          </tokens>
        </chunking>
        <chunking id="16" string="he" type="NP">
          <tokens>
            <token id="5" string="he" />
          </tokens>
        </chunking>
        <chunking id="17" string="Dickey" type="NP">
          <tokens>
            <token id="1" string="Dickey" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">admitted</governor>
          <dependent id="1">Dickey</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">admitted</governor>
          <dependent id="2">also</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">admitted</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">intended</governor>
          <dependent id="4">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">intended</governor>
          <dependent id="5">he</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">admitted</governor>
          <dependent id="6">intended</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">inflict</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">intended</governor>
          <dependent id="8">inflict</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">inflict</governor>
          <dependent id="9">pain</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Jackson</governor>
          <dependent id="10">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">inflict</governor>
          <dependent id="11">Jackson</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">put</governor>
          <dependent id="12">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">put</governor>
          <dependent id="13">he</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="8">inflict</governor>
          <dependent id="14">put</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">put</governor>
          <dependent id="15">handcuffs</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">him</governor>
          <dependent id="16">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">put</governor>
          <dependent id="17">him</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">way</governor>
          <dependent id="18">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">way</governor>
          <dependent id="19">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">put</governor>
          <dependent id="20">way</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">control</governor>
          <dependent id="21">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="20">way</governor>
          <dependent id="22">control</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">control</governor>
          <dependent id="23">him</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Jackson" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Jackson" />
          </tokens>
        </entity>
        <entity id="2" string="Dickey" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Dickey" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>Police Misconduct Allegations Sen. Daniel Boatwright (D-Concord), chairman of the Senate Select Committee on State Procurement and Expenditure Practices, called the hearing into the incident to review allegations of police misconduct in Long Beach.</content>
      <tokens>
        <token id="1" string="Police" lemma="Police" stem="polic" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="Misconduct" lemma="Misconduct" stem="misconduct" pos="NNP" type="Word" isStopWord="false" ner="CRIMINAL_CHARGE" is_referenced="true" is_refers="false" />
        <token id="3" string="Allegations" lemma="Allegations" stem="allegat" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="Sen." lemma="Sen." stem="sen." pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="Daniel" lemma="Daniel" stem="daniel" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="6" string="Boatwright" lemma="Boatwright" stem="boatwright" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="7" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="D-Concord" lemma="D-Concord" stem="d-concord" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="chairman" lemma="chairman" stem="chairman" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="Senate" lemma="Senate" stem="senat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="15" string="Select" lemma="Select" stem="select" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="16" string="Committee" lemma="Committee" stem="committe" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="17" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="18" string="State" lemma="State" stem="state" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="19" string="Procurement" lemma="Procurement" stem="procur" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="20" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="Expenditure" lemma="Expenditure" stem="expenditur" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="Practices" lemma="Practices" stem="practic" pos="NNPS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="called" lemma="call" stem="call" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="26" string="hearing" lemma="hearing" stem="hear" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="27" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="29" string="incident" lemma="incident" stem="incid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="30" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="review" lemma="review" stem="review" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="allegations" lemma="allegation" stem="alleg" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="misconduct" lemma="misconduct" stem="misconduct" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="Long" lemma="Long" stem="long" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="38" string="Beach" lemma="Beach" stem="beach" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="39" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Police) (NNP Misconduct) (NNP Allegations) (NNP Sen.) (NNP Daniel) (NNP Boatwright)) (PRN (-LRB- -LRB-) (NP (NNP D-Concord)) (-RRB- -RRB-)) (, ,) (NP (NP (NN chairman)) (PP (IN of) (NP (NP (DT the) (NNP Senate) (NNP Select) (NNP Committee)) (PP (IN on) (NP (NNP State) (NNP Procurement) (CC and) (NNP Expenditure) (NNPS Practices)))))) (, ,)) (VP (VBD called) (NP (DT the) (NN hearing)) (PP (IN into) (NP (DT the) (NN incident))) (S (VP (TO to) (VP (VB review) (NP (NP (NNS allegations)) (PP (IN of) (NP (NN police) (NN misconduct)))) (PP (IN in) (NP (NNP Long) (NNP Beach))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the Senate Select Committee on State Procurement and Expenditure Practices" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="Senate" />
            <token id="15" string="Select" />
            <token id="16" string="Committee" />
            <token id="17" string="on" />
            <token id="18" string="State" />
            <token id="19" string="Procurement" />
            <token id="20" string="and" />
            <token id="21" string="Expenditure" />
            <token id="22" string="Practices" />
          </tokens>
        </chunking>
        <chunking id="2" string="chairman of the Senate Select Committee on State Procurement and Expenditure Practices" type="NP">
          <tokens>
            <token id="11" string="chairman" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="Senate" />
            <token id="15" string="Select" />
            <token id="16" string="Committee" />
            <token id="17" string="on" />
            <token id="18" string="State" />
            <token id="19" string="Procurement" />
            <token id="20" string="and" />
            <token id="21" string="Expenditure" />
            <token id="22" string="Practices" />
          </tokens>
        </chunking>
        <chunking id="3" string="allegations of police misconduct" type="NP">
          <tokens>
            <token id="32" string="allegations" />
            <token id="33" string="of" />
            <token id="34" string="police" />
            <token id="35" string="misconduct" />
          </tokens>
        </chunking>
        <chunking id="4" string="chairman" type="NP">
          <tokens>
            <token id="11" string="chairman" />
          </tokens>
        </chunking>
        <chunking id="5" string="the Senate Select Committee" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="Senate" />
            <token id="15" string="Select" />
            <token id="16" string="Committee" />
          </tokens>
        </chunking>
        <chunking id="6" string="to review allegations of police misconduct in Long Beach" type="VP">
          <tokens>
            <token id="30" string="to" />
            <token id="31" string="review" />
            <token id="32" string="allegations" />
            <token id="33" string="of" />
            <token id="34" string="police" />
            <token id="35" string="misconduct" />
            <token id="36" string="in" />
            <token id="37" string="Long" />
            <token id="38" string="Beach" />
          </tokens>
        </chunking>
        <chunking id="7" string="Police Misconduct Allegations Sen. Daniel Boatwright -LRB- D-Concord -RRB- , chairman of the Senate Select Committee on State Procurement and Expenditure Practices ," type="NP">
          <tokens>
            <token id="1" string="Police" />
            <token id="2" string="Misconduct" />
            <token id="3" string="Allegations" />
            <token id="4" string="Sen." />
            <token id="5" string="Daniel" />
            <token id="6" string="Boatwright" />
            <token id="7" string="(" />
            <token id="8" string="D-Concord" />
            <token id="9" string=")" />
            <token id="10" string="," />
            <token id="11" string="chairman" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="Senate" />
            <token id="15" string="Select" />
            <token id="16" string="Committee" />
            <token id="17" string="on" />
            <token id="18" string="State" />
            <token id="19" string="Procurement" />
            <token id="20" string="and" />
            <token id="21" string="Expenditure" />
            <token id="22" string="Practices" />
            <token id="23" string="," />
          </tokens>
        </chunking>
        <chunking id="8" string="review allegations of police misconduct in Long Beach" type="VP">
          <tokens>
            <token id="31" string="review" />
            <token id="32" string="allegations" />
            <token id="33" string="of" />
            <token id="34" string="police" />
            <token id="35" string="misconduct" />
            <token id="36" string="in" />
            <token id="37" string="Long" />
            <token id="38" string="Beach" />
          </tokens>
        </chunking>
        <chunking id="9" string="the hearing" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="hearing" />
          </tokens>
        </chunking>
        <chunking id="10" string="police misconduct" type="NP">
          <tokens>
            <token id="34" string="police" />
            <token id="35" string="misconduct" />
          </tokens>
        </chunking>
        <chunking id="11" string="allegations" type="NP">
          <tokens>
            <token id="32" string="allegations" />
          </tokens>
        </chunking>
        <chunking id="12" string="State Procurement and Expenditure Practices" type="NP">
          <tokens>
            <token id="18" string="State" />
            <token id="19" string="Procurement" />
            <token id="20" string="and" />
            <token id="21" string="Expenditure" />
            <token id="22" string="Practices" />
          </tokens>
        </chunking>
        <chunking id="13" string="Police Misconduct Allegations Sen. Daniel Boatwright" type="NP">
          <tokens>
            <token id="1" string="Police" />
            <token id="2" string="Misconduct" />
            <token id="3" string="Allegations" />
            <token id="4" string="Sen." />
            <token id="5" string="Daniel" />
            <token id="6" string="Boatwright" />
          </tokens>
        </chunking>
        <chunking id="14" string="Long Beach" type="NP">
          <tokens>
            <token id="37" string="Long" />
            <token id="38" string="Beach" />
          </tokens>
        </chunking>
        <chunking id="15" string="D-Concord" type="NP">
          <tokens>
            <token id="8" string="D-Concord" />
          </tokens>
        </chunking>
        <chunking id="16" string="called the hearing into the incident to review allegations of police misconduct in Long Beach" type="VP">
          <tokens>
            <token id="24" string="called" />
            <token id="25" string="the" />
            <token id="26" string="hearing" />
            <token id="27" string="into" />
            <token id="28" string="the" />
            <token id="29" string="incident" />
            <token id="30" string="to" />
            <token id="31" string="review" />
            <token id="32" string="allegations" />
            <token id="33" string="of" />
            <token id="34" string="police" />
            <token id="35" string="misconduct" />
            <token id="36" string="in" />
            <token id="37" string="Long" />
            <token id="38" string="Beach" />
          </tokens>
        </chunking>
        <chunking id="17" string="the incident" type="NP">
          <tokens>
            <token id="28" string="the" />
            <token id="29" string="incident" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="6">Boatwright</governor>
          <dependent id="1">Police</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Boatwright</governor>
          <dependent id="2">Misconduct</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Boatwright</governor>
          <dependent id="3">Allegations</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Boatwright</governor>
          <dependent id="4">Sen.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Boatwright</governor>
          <dependent id="5">Daniel</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">called</governor>
          <dependent id="6">Boatwright</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="6">Boatwright</governor>
          <dependent id="8">D-Concord</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="6">Boatwright</governor>
          <dependent id="11">chairman</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">Committee</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">Committee</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Committee</governor>
          <dependent id="14">Senate</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Committee</governor>
          <dependent id="15">Select</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">chairman</governor>
          <dependent id="16">Committee</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">Procurement</governor>
          <dependent id="17">on</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">Procurement</governor>
          <dependent id="18">State</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">Committee</governor>
          <dependent id="19">Procurement</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="19">Procurement</governor>
          <dependent id="20">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">Practices</governor>
          <dependent id="21">Expenditure</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="19">Procurement</governor>
          <dependent id="22">Practices</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="24">called</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">hearing</governor>
          <dependent id="25">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="24">called</governor>
          <dependent id="26">hearing</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">incident</governor>
          <dependent id="27">into</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">incident</governor>
          <dependent id="28">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">called</governor>
          <dependent id="29">incident</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="31">review</governor>
          <dependent id="30">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="24">called</governor>
          <dependent id="31">review</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="31">review</governor>
          <dependent id="32">allegations</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">misconduct</governor>
          <dependent id="33">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="35">misconduct</governor>
          <dependent id="34">police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="32">allegations</governor>
          <dependent id="35">misconduct</dependent>
        </dependency>
        <dependency type="case">
          <governor id="38">Beach</governor>
          <dependent id="36">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="38">Beach</governor>
          <dependent id="37">Long</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">review</governor>
          <dependent id="38">Beach</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Daniel Boatwright" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Daniel" />
            <token id="6" string="Boatwright" />
          </tokens>
        </entity>
        <entity id="2" string="Misconduct" type="CRIMINAL_CHARGE" score="0.0">
          <tokens>
            <token id="2" string="Misconduct" />
          </tokens>
        </entity>
        <entity id="3" string="Senate Select Committee on State Procurement" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="14" string="Senate" />
            <token id="15" string="Select" />
            <token id="16" string="Committee" />
            <token id="17" string="on" />
            <token id="18" string="State" />
            <token id="19" string="Procurement" />
          </tokens>
        </entity>
        <entity id="4" string="Long Beach" type="LOCATION" score="0.0">
          <tokens>
            <token id="37" string="Long" />
            <token id="38" string="Beach" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>The legislative committee monitors state funds disbursed to police departments by the state Police Officer Standards and Training Commission.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="legislative" lemma="legislative" stem="legisl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="committee" lemma="committee" stem="committe" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="monitors" lemma="monitor" stem="monitor" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="state" lemma="state" stem="state" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="funds" lemma="fund" stem="fund" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="disbursed" lemma="disburse" stem="disburs" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="police" lemma="police" stem="polic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="departments" lemma="department" stem="depart" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="state" lemma="state" stem="state" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="Police" lemma="Police" stem="polic" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="Officer" lemma="Officer" stem="officer" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="Standards" lemma="Standards" stem="standard" pos="NNPS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Training" lemma="Training" stem="train" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="19" string="Commission" lemma="Commission" stem="commiss" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (JJ legislative) (NN committee)) (VP (VBZ monitors) (NP (NP (NN state) (NNS funds)) (VP (VBN disbursed) (PP (TO to) (NP (NNS police) (NNS departments))) (PP (IN by) (NP (DT the) (NN state) (NNP Police) (NNP Officer) (NNPS Standards) (CC and) (NNP Training) (NNP Commission)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="state funds" type="NP">
          <tokens>
            <token id="5" string="state" />
            <token id="6" string="funds" />
          </tokens>
        </chunking>
        <chunking id="2" string="monitors state funds disbursed to police departments by the state Police Officer Standards and Training Commission" type="VP">
          <tokens>
            <token id="4" string="monitors" />
            <token id="5" string="state" />
            <token id="6" string="funds" />
            <token id="7" string="disbursed" />
            <token id="8" string="to" />
            <token id="9" string="police" />
            <token id="10" string="departments" />
            <token id="11" string="by" />
            <token id="12" string="the" />
            <token id="13" string="state" />
            <token id="14" string="Police" />
            <token id="15" string="Officer" />
            <token id="16" string="Standards" />
            <token id="17" string="and" />
            <token id="18" string="Training" />
            <token id="19" string="Commission" />
          </tokens>
        </chunking>
        <chunking id="3" string="disbursed to police departments by the state Police Officer Standards and Training Commission" type="VP">
          <tokens>
            <token id="7" string="disbursed" />
            <token id="8" string="to" />
            <token id="9" string="police" />
            <token id="10" string="departments" />
            <token id="11" string="by" />
            <token id="12" string="the" />
            <token id="13" string="state" />
            <token id="14" string="Police" />
            <token id="15" string="Officer" />
            <token id="16" string="Standards" />
            <token id="17" string="and" />
            <token id="18" string="Training" />
            <token id="19" string="Commission" />
          </tokens>
        </chunking>
        <chunking id="4" string="The legislative committee" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="legislative" />
            <token id="3" string="committee" />
          </tokens>
        </chunking>
        <chunking id="5" string="the state Police Officer Standards and Training Commission" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="state" />
            <token id="14" string="Police" />
            <token id="15" string="Officer" />
            <token id="16" string="Standards" />
            <token id="17" string="and" />
            <token id="18" string="Training" />
            <token id="19" string="Commission" />
          </tokens>
        </chunking>
        <chunking id="6" string="state funds disbursed to police departments by the state Police Officer Standards and Training Commission" type="NP">
          <tokens>
            <token id="5" string="state" />
            <token id="6" string="funds" />
            <token id="7" string="disbursed" />
            <token id="8" string="to" />
            <token id="9" string="police" />
            <token id="10" string="departments" />
            <token id="11" string="by" />
            <token id="12" string="the" />
            <token id="13" string="state" />
            <token id="14" string="Police" />
            <token id="15" string="Officer" />
            <token id="16" string="Standards" />
            <token id="17" string="and" />
            <token id="18" string="Training" />
            <token id="19" string="Commission" />
          </tokens>
        </chunking>
        <chunking id="7" string="police departments" type="NP">
          <tokens>
            <token id="9" string="police" />
            <token id="10" string="departments" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">committee</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">committee</governor>
          <dependent id="2">legislative</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">monitors</governor>
          <dependent id="3">committee</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">monitors</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">funds</governor>
          <dependent id="5">state</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">monitors</governor>
          <dependent id="6">funds</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="6">funds</governor>
          <dependent id="7">disbursed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">departments</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">departments</governor>
          <dependent id="9">police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">disbursed</governor>
          <dependent id="10">departments</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">Standards</governor>
          <dependent id="11">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">Standards</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Standards</governor>
          <dependent id="13">state</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Standards</governor>
          <dependent id="14">Police</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Standards</governor>
          <dependent id="15">Officer</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">disbursed</governor>
          <dependent id="16">Standards</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="16">Standards</governor>
          <dependent id="17">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">Commission</governor>
          <dependent id="18">Training</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">Standards</governor>
          <dependent id="19">Commission</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Training Commission" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="18" string="Training" />
            <token id="19" string="Commission" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>The incident received nationwide attention after a camera hidden in Jackson&amp;apost;s car videotaped the arrest, during which Dickey swore at Jackson after stopping his car for an alleged traffic violation and then appeared to push his head through a plate-glass window.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="incident" lemma="incident" stem="incid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="received" lemma="receive" stem="receiv" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="nationwide" lemma="nationwide" stem="nationwid" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="attention" lemma="attention" stem="attent" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="camera" lemma="camera" stem="camera" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="hidden" lemma="hide" stem="hidden" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="12" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="13" string="car" lemma="car" stem="car" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="videotaped" lemma="videotape" stem="videotap" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="arrest" lemma="arrest" stem="arrest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="during" lemma="during" stem="dure" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="Dickey" lemma="Dickey" stem="dickei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="21" string="swore" lemma="swear" stem="swore" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="22" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="24" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="stopping" lemma="stop" stem="stop" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="26" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="27" string="car" lemma="car" stem="car" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="28" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="29" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="30" string="alleged" lemma="alleged" stem="alleg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="31" string="traffic" lemma="traffic" stem="traffic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="32" string="violation" lemma="violation" stem="violat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="33" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="34" string="then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="35" string="appeared" lemma="appear" stem="appear" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="36" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="37" string="push" lemma="push" stem="push" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="38" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="39" string="head" lemma="head" stem="head" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="40" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="41" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="42" string="plate-glass" lemma="plate-glass" stem="plate-glass" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="43" string="window" lemma="window" stem="window" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="44" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (NN incident)) (VP (VBN received) (NP (JJ nationwide) (NN attention)) (PP (IN after) (NP (NP (DT a) (NN camera)) (VP (VBN hidden) (PP (IN in) (NP (NP (NNP Jackson) (POS 's)) (NN car)))))))) (VP (VBD videotaped) (NP (NP (DT the) (NN arrest)) (, ,) (SBAR (WHPP (IN during) (WHNP (WDT which))) (S (NP (NNP Dickey)) (VP (VP (VBD swore) (PP (IN at) (NP (NNP Jackson))) (PP (IN after) (S (VP (VBG stopping) (NP (PRP$ his) (NN car)) (PP (IN for) (NP (DT an) (JJ alleged) (NN traffic) (NN violation))))))) (CC and) (VP (ADVP (RB then)) (VBD appeared) (S (VP (TO to) (VP (VB push) (NP (PRP$ his) (NN head)) (PP (IN through) (NP (DT a) (JJ plate-glass) (NN window)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="during which Dickey swore at Jackson after stopping his car for an alleged traffic violation and then appeared to push his head through a plate-glass window" type="SBAR">
          <tokens>
            <token id="18" string="during" />
            <token id="19" string="which" />
            <token id="20" string="Dickey" />
            <token id="21" string="swore" />
            <token id="22" string="at" />
            <token id="23" string="Jackson" />
            <token id="24" string="after" />
            <token id="25" string="stopping" />
            <token id="26" string="his" />
            <token id="27" string="car" />
            <token id="28" string="for" />
            <token id="29" string="an" />
            <token id="30" string="alleged" />
            <token id="31" string="traffic" />
            <token id="32" string="violation" />
            <token id="33" string="and" />
            <token id="34" string="then" />
            <token id="35" string="appeared" />
            <token id="36" string="to" />
            <token id="37" string="push" />
            <token id="38" string="his" />
            <token id="39" string="head" />
            <token id="40" string="through" />
            <token id="41" string="a" />
            <token id="42" string="plate-glass" />
            <token id="43" string="window" />
          </tokens>
        </chunking>
        <chunking id="2" string="received nationwide attention after a camera hidden in Jackson 's car" type="VP">
          <tokens>
            <token id="3" string="received" />
            <token id="4" string="nationwide" />
            <token id="5" string="attention" />
            <token id="6" string="after" />
            <token id="7" string="a" />
            <token id="8" string="camera" />
            <token id="9" string="hidden" />
            <token id="10" string="in" />
            <token id="11" string="Jackson" />
            <token id="12" string="'s" />
            <token id="13" string="car" />
          </tokens>
        </chunking>
        <chunking id="3" string="nationwide attention" type="NP">
          <tokens>
            <token id="4" string="nationwide" />
            <token id="5" string="attention" />
          </tokens>
        </chunking>
        <chunking id="4" string="the arrest" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="5" string="The incident" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="incident" />
          </tokens>
        </chunking>
        <chunking id="6" string="hidden in Jackson 's car" type="VP">
          <tokens>
            <token id="9" string="hidden" />
            <token id="10" string="in" />
            <token id="11" string="Jackson" />
            <token id="12" string="'s" />
            <token id="13" string="car" />
          </tokens>
        </chunking>
        <chunking id="7" string="an alleged traffic violation" type="NP">
          <tokens>
            <token id="29" string="an" />
            <token id="30" string="alleged" />
            <token id="31" string="traffic" />
            <token id="32" string="violation" />
          </tokens>
        </chunking>
        <chunking id="8" string="stopping his car for an alleged traffic violation" type="VP">
          <tokens>
            <token id="25" string="stopping" />
            <token id="26" string="his" />
            <token id="27" string="car" />
            <token id="28" string="for" />
            <token id="29" string="an" />
            <token id="30" string="alleged" />
            <token id="31" string="traffic" />
            <token id="32" string="violation" />
          </tokens>
        </chunking>
        <chunking id="9" string="swore at Jackson after stopping his car for an alleged traffic violation and then appeared to push his head through a plate-glass window" type="VP">
          <tokens>
            <token id="21" string="swore" />
            <token id="22" string="at" />
            <token id="23" string="Jackson" />
            <token id="24" string="after" />
            <token id="25" string="stopping" />
            <token id="26" string="his" />
            <token id="27" string="car" />
            <token id="28" string="for" />
            <token id="29" string="an" />
            <token id="30" string="alleged" />
            <token id="31" string="traffic" />
            <token id="32" string="violation" />
            <token id="33" string="and" />
            <token id="34" string="then" />
            <token id="35" string="appeared" />
            <token id="36" string="to" />
            <token id="37" string="push" />
            <token id="38" string="his" />
            <token id="39" string="head" />
            <token id="40" string="through" />
            <token id="41" string="a" />
            <token id="42" string="plate-glass" />
            <token id="43" string="window" />
          </tokens>
        </chunking>
        <chunking id="10" string="his head" type="NP">
          <tokens>
            <token id="38" string="his" />
            <token id="39" string="head" />
          </tokens>
        </chunking>
        <chunking id="11" string="to push his head through a plate-glass window" type="VP">
          <tokens>
            <token id="36" string="to" />
            <token id="37" string="push" />
            <token id="38" string="his" />
            <token id="39" string="head" />
            <token id="40" string="through" />
            <token id="41" string="a" />
            <token id="42" string="plate-glass" />
            <token id="43" string="window" />
          </tokens>
        </chunking>
        <chunking id="12" string="Jackson 's" type="NP">
          <tokens>
            <token id="11" string="Jackson" />
            <token id="12" string="'s" />
          </tokens>
        </chunking>
        <chunking id="13" string="Dickey" type="NP">
          <tokens>
            <token id="20" string="Dickey" />
          </tokens>
        </chunking>
        <chunking id="14" string="Jackson 's car" type="NP">
          <tokens>
            <token id="11" string="Jackson" />
            <token id="12" string="'s" />
            <token id="13" string="car" />
          </tokens>
        </chunking>
        <chunking id="15" string="a camera hidden in Jackson 's car" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="camera" />
            <token id="9" string="hidden" />
            <token id="10" string="in" />
            <token id="11" string="Jackson" />
            <token id="12" string="'s" />
            <token id="13" string="car" />
          </tokens>
        </chunking>
        <chunking id="16" string="videotaped the arrest , during which Dickey swore at Jackson after stopping his car for an alleged traffic violation and then appeared to push his head through a plate-glass window" type="VP">
          <tokens>
            <token id="14" string="videotaped" />
            <token id="15" string="the" />
            <token id="16" string="arrest" />
            <token id="17" string="," />
            <token id="18" string="during" />
            <token id="19" string="which" />
            <token id="20" string="Dickey" />
            <token id="21" string="swore" />
            <token id="22" string="at" />
            <token id="23" string="Jackson" />
            <token id="24" string="after" />
            <token id="25" string="stopping" />
            <token id="26" string="his" />
            <token id="27" string="car" />
            <token id="28" string="for" />
            <token id="29" string="an" />
            <token id="30" string="alleged" />
            <token id="31" string="traffic" />
            <token id="32" string="violation" />
            <token id="33" string="and" />
            <token id="34" string="then" />
            <token id="35" string="appeared" />
            <token id="36" string="to" />
            <token id="37" string="push" />
            <token id="38" string="his" />
            <token id="39" string="head" />
            <token id="40" string="through" />
            <token id="41" string="a" />
            <token id="42" string="plate-glass" />
            <token id="43" string="window" />
          </tokens>
        </chunking>
        <chunking id="17" string="Jackson" type="NP">
          <tokens>
            <token id="23" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="18" string="then appeared to push his head through a plate-glass window" type="VP">
          <tokens>
            <token id="34" string="then" />
            <token id="35" string="appeared" />
            <token id="36" string="to" />
            <token id="37" string="push" />
            <token id="38" string="his" />
            <token id="39" string="head" />
            <token id="40" string="through" />
            <token id="41" string="a" />
            <token id="42" string="plate-glass" />
            <token id="43" string="window" />
          </tokens>
        </chunking>
        <chunking id="19" string="push his head through a plate-glass window" type="VP">
          <tokens>
            <token id="37" string="push" />
            <token id="38" string="his" />
            <token id="39" string="head" />
            <token id="40" string="through" />
            <token id="41" string="a" />
            <token id="42" string="plate-glass" />
            <token id="43" string="window" />
          </tokens>
        </chunking>
        <chunking id="20" string="a camera" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="camera" />
          </tokens>
        </chunking>
        <chunking id="21" string="the arrest , during which Dickey swore at Jackson after stopping his car for an alleged traffic violation and then appeared to push his head through a plate-glass window" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="arrest" />
            <token id="17" string="," />
            <token id="18" string="during" />
            <token id="19" string="which" />
            <token id="20" string="Dickey" />
            <token id="21" string="swore" />
            <token id="22" string="at" />
            <token id="23" string="Jackson" />
            <token id="24" string="after" />
            <token id="25" string="stopping" />
            <token id="26" string="his" />
            <token id="27" string="car" />
            <token id="28" string="for" />
            <token id="29" string="an" />
            <token id="30" string="alleged" />
            <token id="31" string="traffic" />
            <token id="32" string="violation" />
            <token id="33" string="and" />
            <token id="34" string="then" />
            <token id="35" string="appeared" />
            <token id="36" string="to" />
            <token id="37" string="push" />
            <token id="38" string="his" />
            <token id="39" string="head" />
            <token id="40" string="through" />
            <token id="41" string="a" />
            <token id="42" string="plate-glass" />
            <token id="43" string="window" />
          </tokens>
        </chunking>
        <chunking id="22" string="his car" type="NP">
          <tokens>
            <token id="26" string="his" />
            <token id="27" string="car" />
          </tokens>
        </chunking>
        <chunking id="23" string="The incident received nationwide attention after a camera hidden in Jackson 's car" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="incident" />
            <token id="3" string="received" />
            <token id="4" string="nationwide" />
            <token id="5" string="attention" />
            <token id="6" string="after" />
            <token id="7" string="a" />
            <token id="8" string="camera" />
            <token id="9" string="hidden" />
            <token id="10" string="in" />
            <token id="11" string="Jackson" />
            <token id="12" string="'s" />
            <token id="13" string="car" />
          </tokens>
        </chunking>
        <chunking id="24" string="swore at Jackson after stopping his car for an alleged traffic violation" type="VP">
          <tokens>
            <token id="21" string="swore" />
            <token id="22" string="at" />
            <token id="23" string="Jackson" />
            <token id="24" string="after" />
            <token id="25" string="stopping" />
            <token id="26" string="his" />
            <token id="27" string="car" />
            <token id="28" string="for" />
            <token id="29" string="an" />
            <token id="30" string="alleged" />
            <token id="31" string="traffic" />
            <token id="32" string="violation" />
          </tokens>
        </chunking>
        <chunking id="25" string="a plate-glass window" type="NP">
          <tokens>
            <token id="41" string="a" />
            <token id="42" string="plate-glass" />
            <token id="43" string="window" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">incident</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">videotaped</governor>
          <dependent id="2">incident</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="2">incident</governor>
          <dependent id="3">received</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">attention</governor>
          <dependent id="4">nationwide</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">received</governor>
          <dependent id="5">attention</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">camera</governor>
          <dependent id="6">after</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">camera</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">received</governor>
          <dependent id="8">camera</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="8">camera</governor>
          <dependent id="9">hidden</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">car</governor>
          <dependent id="10">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="13">car</governor>
          <dependent id="11">Jackson</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Jackson</governor>
          <dependent id="12">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">hidden</governor>
          <dependent id="13">car</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">videotaped</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">arrest</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">videotaped</governor>
          <dependent id="16">arrest</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">which</governor>
          <dependent id="18">during</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">swore</governor>
          <dependent id="19">which</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">swore</governor>
          <dependent id="20">Dickey</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="16">arrest</governor>
          <dependent id="21">swore</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">Jackson</governor>
          <dependent id="22">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">swore</governor>
          <dependent id="23">Jackson</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="25">stopping</governor>
          <dependent id="24">after</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="21">swore</governor>
          <dependent id="25">stopping</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="27">car</governor>
          <dependent id="26">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="25">stopping</governor>
          <dependent id="27">car</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">violation</governor>
          <dependent id="28">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="32">violation</governor>
          <dependent id="29">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="32">violation</governor>
          <dependent id="30">alleged</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="32">violation</governor>
          <dependent id="31">traffic</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">stopping</governor>
          <dependent id="32">violation</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="21">swore</governor>
          <dependent id="33">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="35">appeared</governor>
          <dependent id="34">then</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="21">swore</governor>
          <dependent id="35">appeared</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="37">push</governor>
          <dependent id="36">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="35">appeared</governor>
          <dependent id="37">push</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="39">head</governor>
          <dependent id="38">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="37">push</governor>
          <dependent id="39">head</dependent>
        </dependency>
        <dependency type="case">
          <governor id="43">window</governor>
          <dependent id="40">through</dependent>
        </dependency>
        <dependency type="det">
          <governor id="43">window</governor>
          <dependent id="41">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="43">window</governor>
          <dependent id="42">plate-glass</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="37">push</governor>
          <dependent id="43">window</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Jackson" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Jackson" />
          </tokens>
        </entity>
        <entity id="2" string="Dickey" type="PERSON" score="0.0">
          <tokens>
            <token id="20" string="Dickey" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>Jackson, a Hawthorne police sergeant on disability leave and a self-styled crusader against police brutality, had gone to Long Beach that night with an NBC television crew following in a separate vehicle in what he termed a &amp;quot;sting&amp;quot; operation to validate reports of racism and brutality by Long Beach police officers.</content>
      <tokens>
        <token id="1" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="Hawthorne" lemma="Hawthorne" stem="hawthorn" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="5" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="sergeant" lemma="sergeant" stem="sergeant" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="disability" lemma="disability" stem="disabl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="leave" lemma="leave" stem="leav" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="self-styled" lemma="self-styled" stem="self-styl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="crusader" lemma="crusader" stem="crusad" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="brutality" lemma="brutality" stem="brutal" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="gone" lemma="go" stem="gone" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="Long" lemma="Long" stem="long" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="22" string="Beach" lemma="Beach" stem="beach" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="23" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="night" lemma="night" stem="night" pos="NN" type="Word" isStopWord="false" ner="TIME" is_referenced="true" is_refers="false" />
        <token id="25" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="26" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="27" string="NBC" lemma="NBC" stem="nbc" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="28" string="television" lemma="television" stem="televis" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="29" string="crew" lemma="crew" stem="crew" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="30" string="following" lemma="follow" stem="follow" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="separate" lemma="separate" stem="separ" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="vehicle" lemma="vehicle" stem="vehicl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="38" string="termed" lemma="term" stem="term" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="sting" lemma="sting" stem="sting" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="operation" lemma="operation" stem="oper" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="44" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="validate" lemma="validate" stem="valid" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="46" string="reports" lemma="report" stem="report" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="47" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="48" string="racism" lemma="racism" stem="racism" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="49" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="50" string="brutality" lemma="brutality" stem="brutal" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="51" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="52" string="Long" lemma="Long" stem="long" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="53" string="Beach" lemma="Beach" stem="beach" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="54" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="55" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="56" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Jackson)) (, ,) (NP (NP (NP (DT a) (NAC (NNP Hawthorne)) (NN police) (NN sergeant)) (PP (IN on) (NP (NN disability) (NN leave)))) (CC and) (NP (NP (DT a) (JJ self-styled) (NN crusader)) (PP (IN against) (NP (NN police) (NN brutality))))) (, ,)) (VP (VBD had) (VP (VBN gone) (PP (TO to) (NP (NP (NNP Long) (NNP Beach)) (PP (IN that) (NP (NP (NN night)) (PP (IN with) (NP (DT an) (NNP NBC) (NN television) (NN crew))))))) (PP (VBG following) (PP (IN in) (NP (NP (DT a) (JJ separate) (NN vehicle)) (SBAR (WHPP (IN in) (WHNP (WP what))) (S (NP (PRP he)) (VP (VBD termed) (NP (DT a) (`` ``) (NN sting) ('' '') (NN operation)) (S (VP (TO to) (VP (VB validate) (NP (NP (NNS reports)) (PP (IN of) (NP (NN racism) (CC and) (NN brutality)))) (PP (IN by) (NP (NNP Long) (NNP Beach) (NN police) (NNS officers)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a Hawthorne police sergeant on disability leave" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="Hawthorne" />
            <token id="5" string="police" />
            <token id="6" string="sergeant" />
            <token id="7" string="on" />
            <token id="8" string="disability" />
            <token id="9" string="leave" />
          </tokens>
        </chunking>
        <chunking id="2" string="a `` sting '' operation" type="NP">
          <tokens>
            <token id="39" string="a" />
            <token id="40" string="&quot;" />
            <token id="41" string="sting" />
            <token id="42" string="&quot;" />
            <token id="43" string="operation" />
          </tokens>
        </chunking>
        <chunking id="3" string="gone to Long Beach that night with an NBC television crew following in a separate vehicle in what he termed a `` sting '' operation to validate reports of racism and brutality by Long Beach police officers" type="VP">
          <tokens>
            <token id="19" string="gone" />
            <token id="20" string="to" />
            <token id="21" string="Long" />
            <token id="22" string="Beach" />
            <token id="23" string="that" />
            <token id="24" string="night" />
            <token id="25" string="with" />
            <token id="26" string="an" />
            <token id="27" string="NBC" />
            <token id="28" string="television" />
            <token id="29" string="crew" />
            <token id="30" string="following" />
            <token id="31" string="in" />
            <token id="32" string="a" />
            <token id="33" string="separate" />
            <token id="34" string="vehicle" />
            <token id="35" string="in" />
            <token id="36" string="what" />
            <token id="37" string="he" />
            <token id="38" string="termed" />
            <token id="39" string="a" />
            <token id="40" string="&quot;" />
            <token id="41" string="sting" />
            <token id="42" string="&quot;" />
            <token id="43" string="operation" />
            <token id="44" string="to" />
            <token id="45" string="validate" />
            <token id="46" string="reports" />
            <token id="47" string="of" />
            <token id="48" string="racism" />
            <token id="49" string="and" />
            <token id="50" string="brutality" />
            <token id="51" string="by" />
            <token id="52" string="Long" />
            <token id="53" string="Beach" />
            <token id="54" string="police" />
            <token id="55" string="officers" />
          </tokens>
        </chunking>
        <chunking id="4" string="a self-styled crusader" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="self-styled" />
            <token id="13" string="crusader" />
          </tokens>
        </chunking>
        <chunking id="5" string="Long Beach that night with an NBC television crew" type="NP">
          <tokens>
            <token id="21" string="Long" />
            <token id="22" string="Beach" />
            <token id="23" string="that" />
            <token id="24" string="night" />
            <token id="25" string="with" />
            <token id="26" string="an" />
            <token id="27" string="NBC" />
            <token id="28" string="television" />
            <token id="29" string="crew" />
          </tokens>
        </chunking>
        <chunking id="6" string="night" type="NP">
          <tokens>
            <token id="24" string="night" />
          </tokens>
        </chunking>
        <chunking id="7" string="Long Beach police officers" type="NP">
          <tokens>
            <token id="52" string="Long" />
            <token id="53" string="Beach" />
            <token id="54" string="police" />
            <token id="55" string="officers" />
          </tokens>
        </chunking>
        <chunking id="8" string="a Hawthorne police sergeant" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="Hawthorne" />
            <token id="5" string="police" />
            <token id="6" string="sergeant" />
          </tokens>
        </chunking>
        <chunking id="9" string="reports of racism and brutality" type="NP">
          <tokens>
            <token id="46" string="reports" />
            <token id="47" string="of" />
            <token id="48" string="racism" />
            <token id="49" string="and" />
            <token id="50" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="10" string="to validate reports of racism and brutality by Long Beach police officers" type="VP">
          <tokens>
            <token id="44" string="to" />
            <token id="45" string="validate" />
            <token id="46" string="reports" />
            <token id="47" string="of" />
            <token id="48" string="racism" />
            <token id="49" string="and" />
            <token id="50" string="brutality" />
            <token id="51" string="by" />
            <token id="52" string="Long" />
            <token id="53" string="Beach" />
            <token id="54" string="police" />
            <token id="55" string="officers" />
          </tokens>
        </chunking>
        <chunking id="11" string="Long Beach" type="NP">
          <tokens>
            <token id="21" string="Long" />
            <token id="22" string="Beach" />
          </tokens>
        </chunking>
        <chunking id="12" string="he" type="NP">
          <tokens>
            <token id="37" string="he" />
          </tokens>
        </chunking>
        <chunking id="13" string="termed a `` sting '' operation to validate reports of racism and brutality by Long Beach police officers" type="VP">
          <tokens>
            <token id="38" string="termed" />
            <token id="39" string="a" />
            <token id="40" string="&quot;" />
            <token id="41" string="sting" />
            <token id="42" string="&quot;" />
            <token id="43" string="operation" />
            <token id="44" string="to" />
            <token id="45" string="validate" />
            <token id="46" string="reports" />
            <token id="47" string="of" />
            <token id="48" string="racism" />
            <token id="49" string="and" />
            <token id="50" string="brutality" />
            <token id="51" string="by" />
            <token id="52" string="Long" />
            <token id="53" string="Beach" />
            <token id="54" string="police" />
            <token id="55" string="officers" />
          </tokens>
        </chunking>
        <chunking id="14" string="disability leave" type="NP">
          <tokens>
            <token id="8" string="disability" />
            <token id="9" string="leave" />
          </tokens>
        </chunking>
        <chunking id="15" string="had gone to Long Beach that night with an NBC television crew following in a separate vehicle in what he termed a `` sting '' operation to validate reports of racism and brutality by Long Beach police officers" type="VP">
          <tokens>
            <token id="18" string="had" />
            <token id="19" string="gone" />
            <token id="20" string="to" />
            <token id="21" string="Long" />
            <token id="22" string="Beach" />
            <token id="23" string="that" />
            <token id="24" string="night" />
            <token id="25" string="with" />
            <token id="26" string="an" />
            <token id="27" string="NBC" />
            <token id="28" string="television" />
            <token id="29" string="crew" />
            <token id="30" string="following" />
            <token id="31" string="in" />
            <token id="32" string="a" />
            <token id="33" string="separate" />
            <token id="34" string="vehicle" />
            <token id="35" string="in" />
            <token id="36" string="what" />
            <token id="37" string="he" />
            <token id="38" string="termed" />
            <token id="39" string="a" />
            <token id="40" string="&quot;" />
            <token id="41" string="sting" />
            <token id="42" string="&quot;" />
            <token id="43" string="operation" />
            <token id="44" string="to" />
            <token id="45" string="validate" />
            <token id="46" string="reports" />
            <token id="47" string="of" />
            <token id="48" string="racism" />
            <token id="49" string="and" />
            <token id="50" string="brutality" />
            <token id="51" string="by" />
            <token id="52" string="Long" />
            <token id="53" string="Beach" />
            <token id="54" string="police" />
            <token id="55" string="officers" />
          </tokens>
        </chunking>
        <chunking id="16" string="reports" type="NP">
          <tokens>
            <token id="46" string="reports" />
          </tokens>
        </chunking>
        <chunking id="17" string="a separate vehicle in what he termed a `` sting '' operation to validate reports of racism and brutality by Long Beach police officers" type="NP">
          <tokens>
            <token id="32" string="a" />
            <token id="33" string="separate" />
            <token id="34" string="vehicle" />
            <token id="35" string="in" />
            <token id="36" string="what" />
            <token id="37" string="he" />
            <token id="38" string="termed" />
            <token id="39" string="a" />
            <token id="40" string="&quot;" />
            <token id="41" string="sting" />
            <token id="42" string="&quot;" />
            <token id="43" string="operation" />
            <token id="44" string="to" />
            <token id="45" string="validate" />
            <token id="46" string="reports" />
            <token id="47" string="of" />
            <token id="48" string="racism" />
            <token id="49" string="and" />
            <token id="50" string="brutality" />
            <token id="51" string="by" />
            <token id="52" string="Long" />
            <token id="53" string="Beach" />
            <token id="54" string="police" />
            <token id="55" string="officers" />
          </tokens>
        </chunking>
        <chunking id="18" string="validate reports of racism and brutality by Long Beach police officers" type="VP">
          <tokens>
            <token id="45" string="validate" />
            <token id="46" string="reports" />
            <token id="47" string="of" />
            <token id="48" string="racism" />
            <token id="49" string="and" />
            <token id="50" string="brutality" />
            <token id="51" string="by" />
            <token id="52" string="Long" />
            <token id="53" string="Beach" />
            <token id="54" string="police" />
            <token id="55" string="officers" />
          </tokens>
        </chunking>
        <chunking id="19" string="Jackson" type="NP">
          <tokens>
            <token id="1" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="20" string="Jackson , a Hawthorne police sergeant on disability leave and a self-styled crusader against police brutality ," type="NP">
          <tokens>
            <token id="1" string="Jackson" />
            <token id="2" string="," />
            <token id="3" string="a" />
            <token id="4" string="Hawthorne" />
            <token id="5" string="police" />
            <token id="6" string="sergeant" />
            <token id="7" string="on" />
            <token id="8" string="disability" />
            <token id="9" string="leave" />
            <token id="10" string="and" />
            <token id="11" string="a" />
            <token id="12" string="self-styled" />
            <token id="13" string="crusader" />
            <token id="14" string="against" />
            <token id="15" string="police" />
            <token id="16" string="brutality" />
            <token id="17" string="," />
          </tokens>
        </chunking>
        <chunking id="21" string="an NBC television crew" type="NP">
          <tokens>
            <token id="26" string="an" />
            <token id="27" string="NBC" />
            <token id="28" string="television" />
            <token id="29" string="crew" />
          </tokens>
        </chunking>
        <chunking id="22" string="a separate vehicle" type="NP">
          <tokens>
            <token id="32" string="a" />
            <token id="33" string="separate" />
            <token id="34" string="vehicle" />
          </tokens>
        </chunking>
        <chunking id="23" string="a self-styled crusader against police brutality" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="self-styled" />
            <token id="13" string="crusader" />
            <token id="14" string="against" />
            <token id="15" string="police" />
            <token id="16" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="24" string="racism and brutality" type="NP">
          <tokens>
            <token id="48" string="racism" />
            <token id="49" string="and" />
            <token id="50" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="25" string="a Hawthorne police sergeant on disability leave and a self-styled crusader against police brutality" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="Hawthorne" />
            <token id="5" string="police" />
            <token id="6" string="sergeant" />
            <token id="7" string="on" />
            <token id="8" string="disability" />
            <token id="9" string="leave" />
            <token id="10" string="and" />
            <token id="11" string="a" />
            <token id="12" string="self-styled" />
            <token id="13" string="crusader" />
            <token id="14" string="against" />
            <token id="15" string="police" />
            <token id="16" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="26" string="police brutality" type="NP">
          <tokens>
            <token id="15" string="police" />
            <token id="16" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="27" string="night with an NBC television crew" type="NP">
          <tokens>
            <token id="24" string="night" />
            <token id="25" string="with" />
            <token id="26" string="an" />
            <token id="27" string="NBC" />
            <token id="28" string="television" />
            <token id="29" string="crew" />
          </tokens>
        </chunking>
        <chunking id="28" string="in what he termed a `` sting '' operation to validate reports of racism and brutality by Long Beach police officers" type="SBAR">
          <tokens>
            <token id="35" string="in" />
            <token id="36" string="what" />
            <token id="37" string="he" />
            <token id="38" string="termed" />
            <token id="39" string="a" />
            <token id="40" string="&quot;" />
            <token id="41" string="sting" />
            <token id="42" string="&quot;" />
            <token id="43" string="operation" />
            <token id="44" string="to" />
            <token id="45" string="validate" />
            <token id="46" string="reports" />
            <token id="47" string="of" />
            <token id="48" string="racism" />
            <token id="49" string="and" />
            <token id="50" string="brutality" />
            <token id="51" string="by" />
            <token id="52" string="Long" />
            <token id="53" string="Beach" />
            <token id="54" string="police" />
            <token id="55" string="officers" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="19">gone</governor>
          <dependent id="1">Jackson</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">sergeant</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="6">sergeant</governor>
          <dependent id="4">Hawthorne</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">sergeant</governor>
          <dependent id="5">police</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="1">Jackson</governor>
          <dependent id="6">sergeant</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">leave</governor>
          <dependent id="7">on</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">leave</governor>
          <dependent id="8">disability</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">sergeant</governor>
          <dependent id="9">leave</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">sergeant</governor>
          <dependent id="10">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">crusader</governor>
          <dependent id="11">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">crusader</governor>
          <dependent id="12">self-styled</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">sergeant</governor>
          <dependent id="13">crusader</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">brutality</governor>
          <dependent id="14">against</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">brutality</governor>
          <dependent id="15">police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">crusader</governor>
          <dependent id="16">brutality</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="19">gone</governor>
          <dependent id="18">had</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="19">gone</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">Beach</governor>
          <dependent id="20">to</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">Beach</governor>
          <dependent id="21">Long</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">gone</governor>
          <dependent id="22">Beach</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">night</governor>
          <dependent id="23">that</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">Beach</governor>
          <dependent id="24">night</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">crew</governor>
          <dependent id="25">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">crew</governor>
          <dependent id="26">an</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="29">crew</governor>
          <dependent id="27">NBC</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="29">crew</governor>
          <dependent id="28">television</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">night</governor>
          <dependent id="29">crew</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">vehicle</governor>
          <dependent id="30">following</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">vehicle</governor>
          <dependent id="31">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="34">vehicle</governor>
          <dependent id="32">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="34">vehicle</governor>
          <dependent id="33">separate</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="19">gone</governor>
          <dependent id="34">vehicle</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">what</governor>
          <dependent id="35">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="38">termed</governor>
          <dependent id="36">what</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="38">termed</governor>
          <dependent id="37">he</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="34">vehicle</governor>
          <dependent id="38">termed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="43">operation</governor>
          <dependent id="39">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="43">operation</governor>
          <dependent id="41">sting</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="38">termed</governor>
          <dependent id="43">operation</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="45">validate</governor>
          <dependent id="44">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="38">termed</governor>
          <dependent id="45">validate</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="45">validate</governor>
          <dependent id="46">reports</dependent>
        </dependency>
        <dependency type="case">
          <governor id="48">racism</governor>
          <dependent id="47">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="46">reports</governor>
          <dependent id="48">racism</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="48">racism</governor>
          <dependent id="49">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="48">racism</governor>
          <dependent id="50">brutality</dependent>
        </dependency>
        <dependency type="case">
          <governor id="55">officers</governor>
          <dependent id="51">by</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="55">officers</governor>
          <dependent id="52">Long</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="55">officers</governor>
          <dependent id="53">Beach</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="55">officers</governor>
          <dependent id="54">police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="45">validate</governor>
          <dependent id="55">officers</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Long Beach" type="LOCATION" score="0.0">
          <tokens>
            <token id="21" string="Long" />
            <token id="22" string="Beach" />
          </tokens>
        </entity>
        <entity id="2" string="night" type="TIME" score="0.0">
          <tokens>
            <token id="24" string="night" />
          </tokens>
        </entity>
        <entity id="3" string="Jackson" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Jackson" />
          </tokens>
        </entity>
        <entity id="4" string="Hawthorne" type="LOCATION" score="0.0">
          <tokens>
            <token id="4" string="Hawthorne" />
          </tokens>
        </entity>
        <entity id="5" string="NBC" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="27" string="NBC" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>Investigations have been launched by the FBI, the Los Angeles County district attorney&amp;apost;s office and the Long Beach Police Department.</content>
      <tokens>
        <token id="1" string="Investigations" lemma="investigation" stem="investig" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="launched" lemma="launch" stem="launch" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="FBI" lemma="FBI" stem="fbi" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Los" lemma="Los" stem="lo" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="11" string="Angeles" lemma="Angeles" stem="angele" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="12" string="County" lemma="County" stem="counti" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="13" string="district" lemma="district" stem="district" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="attorney" lemma="attorney" stem="attornei" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="office" lemma="office" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="Long" lemma="Long" stem="long" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="20" string="Beach" lemma="Beach" stem="beach" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="21" string="Police" lemma="Police" stem="polic" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="22" string="Department" lemma="Department" stem="depart" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNS Investigations)) (VP (VBP have) (VP (VBN been) (VP (VBN launched) (PP (IN by) (NP (NP (DT the) (NNP FBI)) (, ,) (NP (NP (NP (DT the) (NNP Los) (NNP Angeles) (NNP County) (NN district) (NN attorney) (POS 's)) (NN office)) (CC and) (NP (DT the) (NNP Long) (NNP Beach) (NNP Police) (NNP Department)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the FBI , the Los Angeles County district attorney 's office and the Long Beach Police Department" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="FBI" />
            <token id="8" string="," />
            <token id="9" string="the" />
            <token id="10" string="Los" />
            <token id="11" string="Angeles" />
            <token id="12" string="County" />
            <token id="13" string="district" />
            <token id="14" string="attorney" />
            <token id="15" string="'s" />
            <token id="16" string="office" />
            <token id="17" string="and" />
            <token id="18" string="the" />
            <token id="19" string="Long" />
            <token id="20" string="Beach" />
            <token id="21" string="Police" />
            <token id="22" string="Department" />
          </tokens>
        </chunking>
        <chunking id="2" string="the Los Angeles County district attorney 's office" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="Los" />
            <token id="11" string="Angeles" />
            <token id="12" string="County" />
            <token id="13" string="district" />
            <token id="14" string="attorney" />
            <token id="15" string="'s" />
            <token id="16" string="office" />
          </tokens>
        </chunking>
        <chunking id="3" string="the Long Beach Police Department" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="Long" />
            <token id="20" string="Beach" />
            <token id="21" string="Police" />
            <token id="22" string="Department" />
          </tokens>
        </chunking>
        <chunking id="4" string="have been launched by the FBI , the Los Angeles County district attorney 's office and the Long Beach Police Department" type="VP">
          <tokens>
            <token id="2" string="have" />
            <token id="3" string="been" />
            <token id="4" string="launched" />
            <token id="5" string="by" />
            <token id="6" string="the" />
            <token id="7" string="FBI" />
            <token id="8" string="," />
            <token id="9" string="the" />
            <token id="10" string="Los" />
            <token id="11" string="Angeles" />
            <token id="12" string="County" />
            <token id="13" string="district" />
            <token id="14" string="attorney" />
            <token id="15" string="'s" />
            <token id="16" string="office" />
            <token id="17" string="and" />
            <token id="18" string="the" />
            <token id="19" string="Long" />
            <token id="20" string="Beach" />
            <token id="21" string="Police" />
            <token id="22" string="Department" />
          </tokens>
        </chunking>
        <chunking id="5" string="the Los Angeles County district attorney 's" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="Los" />
            <token id="11" string="Angeles" />
            <token id="12" string="County" />
            <token id="13" string="district" />
            <token id="14" string="attorney" />
            <token id="15" string="'s" />
          </tokens>
        </chunking>
        <chunking id="6" string="the FBI" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="FBI" />
          </tokens>
        </chunking>
        <chunking id="7" string="launched by the FBI , the Los Angeles County district attorney 's office and the Long Beach Police Department" type="VP">
          <tokens>
            <token id="4" string="launched" />
            <token id="5" string="by" />
            <token id="6" string="the" />
            <token id="7" string="FBI" />
            <token id="8" string="," />
            <token id="9" string="the" />
            <token id="10" string="Los" />
            <token id="11" string="Angeles" />
            <token id="12" string="County" />
            <token id="13" string="district" />
            <token id="14" string="attorney" />
            <token id="15" string="'s" />
            <token id="16" string="office" />
            <token id="17" string="and" />
            <token id="18" string="the" />
            <token id="19" string="Long" />
            <token id="20" string="Beach" />
            <token id="21" string="Police" />
            <token id="22" string="Department" />
          </tokens>
        </chunking>
        <chunking id="8" string="been launched by the FBI , the Los Angeles County district attorney 's office and the Long Beach Police Department" type="VP">
          <tokens>
            <token id="3" string="been" />
            <token id="4" string="launched" />
            <token id="5" string="by" />
            <token id="6" string="the" />
            <token id="7" string="FBI" />
            <token id="8" string="," />
            <token id="9" string="the" />
            <token id="10" string="Los" />
            <token id="11" string="Angeles" />
            <token id="12" string="County" />
            <token id="13" string="district" />
            <token id="14" string="attorney" />
            <token id="15" string="'s" />
            <token id="16" string="office" />
            <token id="17" string="and" />
            <token id="18" string="the" />
            <token id="19" string="Long" />
            <token id="20" string="Beach" />
            <token id="21" string="Police" />
            <token id="22" string="Department" />
          </tokens>
        </chunking>
        <chunking id="9" string="the Los Angeles County district attorney 's office and the Long Beach Police Department" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="Los" />
            <token id="11" string="Angeles" />
            <token id="12" string="County" />
            <token id="13" string="district" />
            <token id="14" string="attorney" />
            <token id="15" string="'s" />
            <token id="16" string="office" />
            <token id="17" string="and" />
            <token id="18" string="the" />
            <token id="19" string="Long" />
            <token id="20" string="Beach" />
            <token id="21" string="Police" />
            <token id="22" string="Department" />
          </tokens>
        </chunking>
        <chunking id="10" string="Investigations" type="NP">
          <tokens>
            <token id="1" string="Investigations" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="4">launched</governor>
          <dependent id="1">Investigations</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">launched</governor>
          <dependent id="2">have</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="4">launched</governor>
          <dependent id="3">been</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">launched</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">FBI</governor>
          <dependent id="5">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">FBI</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">launched</governor>
          <dependent id="7">FBI</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">attorney</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">attorney</governor>
          <dependent id="10">Los</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">attorney</governor>
          <dependent id="11">Angeles</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">attorney</governor>
          <dependent id="12">County</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">attorney</governor>
          <dependent id="13">district</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="16">office</governor>
          <dependent id="14">attorney</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">attorney</governor>
          <dependent id="15">'s</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="7">FBI</governor>
          <dependent id="16">office</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="16">office</governor>
          <dependent id="17">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">Department</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">Department</governor>
          <dependent id="19">Long</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">Department</governor>
          <dependent id="20">Beach</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">Department</governor>
          <dependent id="21">Police</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">office</governor>
          <dependent id="22">Department</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Long Beach Police Department" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="19" string="Long" />
            <token id="20" string="Beach" />
            <token id="21" string="Police" />
            <token id="22" string="Department" />
          </tokens>
        </entity>
        <entity id="2" string="Los Angeles County" type="LOCATION" score="0.0">
          <tokens>
            <token id="10" string="Los" />
            <token id="11" string="Angeles" />
            <token id="12" string="County" />
          </tokens>
        </entity>
        <entity id="3" string="FBI" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="7" string="FBI" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>Dickey has been temporarily reassigned to a desk job, and Jackson was charged with interfering with a police officer.</content>
      <tokens>
        <token id="1" string="Dickey" lemma="Dickey" stem="dickei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="temporarily" lemma="temporarily" stem="temporarili" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="reassigned" lemma="reassign" stem="reassign" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="desk" lemma="desk" stem="desk" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="job" lemma="job" stem="job" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="13" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="charged" lemma="charge" stem="charg" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="interfering" lemma="interfere" stem="interf" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="officer" lemma="officer" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NNP Dickey)) (VP (VBZ has) (VP (VBN been) (VP (ADVP (RB temporarily)) (VBN reassigned) (PP (TO to) (NP (DT a) (NN desk) (NN job))))))) (, ,) (CC and) (S (NP (NNP Jackson)) (VP (VBD was) (VP (VBN charged) (PP (IN with) (S (VP (VBG interfering) (PP (IN with) (NP (DT a) (NN police) (NN officer))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="been temporarily reassigned to a desk job" type="VP">
          <tokens>
            <token id="3" string="been" />
            <token id="4" string="temporarily" />
            <token id="5" string="reassigned" />
            <token id="6" string="to" />
            <token id="7" string="a" />
            <token id="8" string="desk" />
            <token id="9" string="job" />
          </tokens>
        </chunking>
        <chunking id="2" string="a police officer" type="NP">
          <tokens>
            <token id="18" string="a" />
            <token id="19" string="police" />
            <token id="20" string="officer" />
          </tokens>
        </chunking>
        <chunking id="3" string="a desk job" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="desk" />
            <token id="9" string="job" />
          </tokens>
        </chunking>
        <chunking id="4" string="was charged with interfering with a police officer" type="VP">
          <tokens>
            <token id="13" string="was" />
            <token id="14" string="charged" />
            <token id="15" string="with" />
            <token id="16" string="interfering" />
            <token id="17" string="with" />
            <token id="18" string="a" />
            <token id="19" string="police" />
            <token id="20" string="officer" />
          </tokens>
        </chunking>
        <chunking id="5" string="Jackson" type="NP">
          <tokens>
            <token id="12" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="6" string="interfering with a police officer" type="VP">
          <tokens>
            <token id="16" string="interfering" />
            <token id="17" string="with" />
            <token id="18" string="a" />
            <token id="19" string="police" />
            <token id="20" string="officer" />
          </tokens>
        </chunking>
        <chunking id="7" string="has been temporarily reassigned to a desk job" type="VP">
          <tokens>
            <token id="2" string="has" />
            <token id="3" string="been" />
            <token id="4" string="temporarily" />
            <token id="5" string="reassigned" />
            <token id="6" string="to" />
            <token id="7" string="a" />
            <token id="8" string="desk" />
            <token id="9" string="job" />
          </tokens>
        </chunking>
        <chunking id="8" string="temporarily reassigned to a desk job" type="VP">
          <tokens>
            <token id="4" string="temporarily" />
            <token id="5" string="reassigned" />
            <token id="6" string="to" />
            <token id="7" string="a" />
            <token id="8" string="desk" />
            <token id="9" string="job" />
          </tokens>
        </chunking>
        <chunking id="9" string="Dickey" type="NP">
          <tokens>
            <token id="1" string="Dickey" />
          </tokens>
        </chunking>
        <chunking id="10" string="charged with interfering with a police officer" type="VP">
          <tokens>
            <token id="14" string="charged" />
            <token id="15" string="with" />
            <token id="16" string="interfering" />
            <token id="17" string="with" />
            <token id="18" string="a" />
            <token id="19" string="police" />
            <token id="20" string="officer" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="5">reassigned</governor>
          <dependent id="1">Dickey</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">reassigned</governor>
          <dependent id="2">has</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="5">reassigned</governor>
          <dependent id="3">been</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">reassigned</governor>
          <dependent id="4">temporarily</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">reassigned</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">job</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">job</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">job</governor>
          <dependent id="8">desk</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">reassigned</governor>
          <dependent id="9">job</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">reassigned</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="14">charged</governor>
          <dependent id="12">Jackson</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="14">charged</governor>
          <dependent id="13">was</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">reassigned</governor>
          <dependent id="14">charged</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">interfering</governor>
          <dependent id="15">with</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="14">charged</governor>
          <dependent id="16">interfering</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">officer</governor>
          <dependent id="17">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">officer</governor>
          <dependent id="18">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">officer</governor>
          <dependent id="19">police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">interfering</governor>
          <dependent id="20">officer</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Jackson" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Jackson" />
          </tokens>
        </entity>
        <entity id="2" string="Dickey" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Dickey" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>At the hearing, Boatwright repeatedly played the videotape while committee members and about 50 observers watched on television monitors and Dickey and Jackson commented on each scene.</content>
      <tokens>
        <token id="1" string="At" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="hearing" lemma="hearing" stem="hear" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Boatwright" lemma="Boatwright" stem="boatwright" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="6" string="repeatedly" lemma="repeatedly" stem="repeatedli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="played" lemma="play" stem="plai" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="videotape" lemma="videotape" stem="videotap" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="while" lemma="while" stem="while" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="committee" lemma="committee" stem="committe" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="members" lemma="member" stem="member" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="50" lemma="50" stem="50" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="16" string="observers" lemma="observer" stem="observ" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="watched" lemma="watch" stem="watch" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="television" lemma="television" stem="televis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="monitors" lemma="monitor" stem="monitor" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="Dickey" lemma="Dickey" stem="dickei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="23" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="25" string="commented" lemma="comment" stem="comment" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="each" lemma="each" stem="each" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="scene" lemma="scene" stem="scene" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN At) (NP (DT the) (NN hearing))) (, ,) (S (NP (NNP Boatwright)) (ADVP (RB repeatedly)) (VP (VBD played) (NP (DT the) (NN videotape)) (PP (PP (IN while) (NP (NN committee) (NNS members))) (CC and) (PP (IN about) (NP (NP (CD 50) (NNS observers)) (VP (VBN watched) (PP (IN on) (NP (NN television) (NNS monitors))))))))) (CC and) (S (NP (NNP Dickey) (CC and) (NNP Jackson)) (VP (VBD commented) (PP (IN on) (NP (DT each) (NN scene))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="committee members" type="NP">
          <tokens>
            <token id="11" string="committee" />
            <token id="12" string="members" />
          </tokens>
        </chunking>
        <chunking id="2" string="played the videotape while committee members and about 50 observers watched on television monitors" type="VP">
          <tokens>
            <token id="7" string="played" />
            <token id="8" string="the" />
            <token id="9" string="videotape" />
            <token id="10" string="while" />
            <token id="11" string="committee" />
            <token id="12" string="members" />
            <token id="13" string="and" />
            <token id="14" string="about" />
            <token id="15" string="50" />
            <token id="16" string="observers" />
            <token id="17" string="watched" />
            <token id="18" string="on" />
            <token id="19" string="television" />
            <token id="20" string="monitors" />
          </tokens>
        </chunking>
        <chunking id="3" string="Dickey and Jackson" type="NP">
          <tokens>
            <token id="22" string="Dickey" />
            <token id="23" string="and" />
            <token id="24" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="4" string="commented on each scene" type="VP">
          <tokens>
            <token id="25" string="commented" />
            <token id="26" string="on" />
            <token id="27" string="each" />
            <token id="28" string="scene" />
          </tokens>
        </chunking>
        <chunking id="5" string="the videotape" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="videotape" />
          </tokens>
        </chunking>
        <chunking id="6" string="Boatwright" type="NP">
          <tokens>
            <token id="5" string="Boatwright" />
          </tokens>
        </chunking>
        <chunking id="7" string="50 observers watched on television monitors" type="NP">
          <tokens>
            <token id="15" string="50" />
            <token id="16" string="observers" />
            <token id="17" string="watched" />
            <token id="18" string="on" />
            <token id="19" string="television" />
            <token id="20" string="monitors" />
          </tokens>
        </chunking>
        <chunking id="8" string="watched on television monitors" type="VP">
          <tokens>
            <token id="17" string="watched" />
            <token id="18" string="on" />
            <token id="19" string="television" />
            <token id="20" string="monitors" />
          </tokens>
        </chunking>
        <chunking id="9" string="the hearing" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="hearing" />
          </tokens>
        </chunking>
        <chunking id="10" string="50 observers" type="NP">
          <tokens>
            <token id="15" string="50" />
            <token id="16" string="observers" />
          </tokens>
        </chunking>
        <chunking id="11" string="each scene" type="NP">
          <tokens>
            <token id="27" string="each" />
            <token id="28" string="scene" />
          </tokens>
        </chunking>
        <chunking id="12" string="television monitors" type="NP">
          <tokens>
            <token id="19" string="television" />
            <token id="20" string="monitors" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">hearing</governor>
          <dependent id="1">At</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">hearing</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">played</governor>
          <dependent id="3">hearing</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">played</governor>
          <dependent id="5">Boatwright</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">played</governor>
          <dependent id="6">repeatedly</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">played</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">played</governor>
          <dependent id="7">played</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">videotape</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">played</governor>
          <dependent id="9">videotape</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">members</governor>
          <dependent id="10">while</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">members</governor>
          <dependent id="11">committee</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">played</governor>
          <dependent id="12">members</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">played</governor>
          <dependent id="13">and</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">observers</governor>
          <dependent id="14">about</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="16">observers</governor>
          <dependent id="15">50</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">played</governor>
          <dependent id="16">observers</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="16">observers</governor>
          <dependent id="17">watched</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">monitors</governor>
          <dependent id="18">on</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">monitors</governor>
          <dependent id="19">television</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">watched</governor>
          <dependent id="20">monitors</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">played</governor>
          <dependent id="21">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">commented</governor>
          <dependent id="22">Dickey</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="22">Dickey</governor>
          <dependent id="23">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="22">Dickey</governor>
          <dependent id="24">Jackson</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">played</governor>
          <dependent id="25">commented</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">scene</governor>
          <dependent id="26">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">scene</governor>
          <dependent id="27">each</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">commented</governor>
          <dependent id="28">scene</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="50" type="NUMBER" score="0.0">
          <tokens>
            <token id="15" string="50" />
          </tokens>
        </entity>
        <entity id="2" string="Jackson" type="PERSON" score="0.0">
          <tokens>
            <token id="24" string="Jackson" />
          </tokens>
        </entity>
        <entity id="3" string="Boatwright" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Boatwright" />
          </tokens>
        </entity>
        <entity id="4" string="Dickey" type="PERSON" score="0.0">
          <tokens>
            <token id="22" string="Dickey" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>Boatwright questioned whether the car in which Jackson was riding was actually weaving -- the stated cause for the traffic stop -- and whether Jackson acted aggressively toward the officers, as Dickey said in his report.</content>
      <tokens>
        <token id="1" string="Boatwright" lemma="Boatwright" stem="boatwright" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="questioned" lemma="question" stem="question" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="whether" lemma="whether" stem="whether" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="car" lemma="car" stem="car" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="9" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="riding" lemma="ride" stem="ride" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="actually" lemma="actually" stem="actual" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="weaving" lemma="weave" stem="weav" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="stated" lemma="state" stem="state" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="cause" lemma="cause" stem="caus" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="traffic" lemma="traffic" stem="traffic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="stop" lemma="stop" stem="stop" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="whether" lemma="whether" stem="whether" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="26" string="acted" lemma="act" stem="act" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="aggressively" lemma="aggressively" stem="aggress" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="toward" lemma="toward" stem="toward" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="30" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="31" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="Dickey" lemma="Dickey" stem="dickei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="34" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="37" string="report" lemma="report" stem="report" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="38" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Boatwright)) (VP (VBD questioned) (SBAR (SBAR (IN whether) (S (NP (NP (DT the) (NN car)) (SBAR (WHPP (IN in) (WHNP (WDT which))) (S (NP (NNP Jackson)) (VP (VBD was) (VP (VBG riding)))))) (VP (VBD was) (ADVP (RB actually)) (VP (VP (VBG weaving)) (PRN (: --) (NP (NP (DT the) (VBN stated) (NN cause)) (PP (IN for) (NP (DT the) (NN traffic) (NN stop)))) (: --)))))) (CC and) (SBAR (IN whether) (S (NP (NNP Jackson)) (VP (VBD acted) (ADVP (RB aggressively)) (PP (IN toward) (NP (DT the) (NNS officers))) (, ,) (SBAR (IN as) (S (NP (NNP Dickey)) (VP (VBD said) (PP (IN in) (NP (PRP$ his) (NN report))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the stated cause for the traffic stop" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="stated" />
            <token id="17" string="cause" />
            <token id="18" string="for" />
            <token id="19" string="the" />
            <token id="20" string="traffic" />
            <token id="21" string="stop" />
          </tokens>
        </chunking>
        <chunking id="2" string="his report" type="NP">
          <tokens>
            <token id="36" string="his" />
            <token id="37" string="report" />
          </tokens>
        </chunking>
        <chunking id="3" string="questioned whether the car in which Jackson was riding was actually weaving -- the stated cause for the traffic stop -- and whether Jackson acted aggressively toward the officers , as Dickey said in his report" type="VP">
          <tokens>
            <token id="2" string="questioned" />
            <token id="3" string="whether" />
            <token id="4" string="the" />
            <token id="5" string="car" />
            <token id="6" string="in" />
            <token id="7" string="which" />
            <token id="8" string="Jackson" />
            <token id="9" string="was" />
            <token id="10" string="riding" />
            <token id="11" string="was" />
            <token id="12" string="actually" />
            <token id="13" string="weaving" />
            <token id="14" string="--" />
            <token id="15" string="the" />
            <token id="16" string="stated" />
            <token id="17" string="cause" />
            <token id="18" string="for" />
            <token id="19" string="the" />
            <token id="20" string="traffic" />
            <token id="21" string="stop" />
            <token id="22" string="--" />
            <token id="23" string="and" />
            <token id="24" string="whether" />
            <token id="25" string="Jackson" />
            <token id="26" string="acted" />
            <token id="27" string="aggressively" />
            <token id="28" string="toward" />
            <token id="29" string="the" />
            <token id="30" string="officers" />
            <token id="31" string="," />
            <token id="32" string="as" />
            <token id="33" string="Dickey" />
            <token id="34" string="said" />
            <token id="35" string="in" />
            <token id="36" string="his" />
            <token id="37" string="report" />
          </tokens>
        </chunking>
        <chunking id="4" string="the stated cause" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="stated" />
            <token id="17" string="cause" />
          </tokens>
        </chunking>
        <chunking id="5" string="the traffic stop" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="traffic" />
            <token id="21" string="stop" />
          </tokens>
        </chunking>
        <chunking id="6" string="whether the car in which Jackson was riding was actually weaving -- the stated cause for the traffic stop -- and whether Jackson acted aggressively toward the officers , as Dickey said in his report" type="SBAR">
          <tokens>
            <token id="3" string="whether" />
            <token id="4" string="the" />
            <token id="5" string="car" />
            <token id="6" string="in" />
            <token id="7" string="which" />
            <token id="8" string="Jackson" />
            <token id="9" string="was" />
            <token id="10" string="riding" />
            <token id="11" string="was" />
            <token id="12" string="actually" />
            <token id="13" string="weaving" />
            <token id="14" string="--" />
            <token id="15" string="the" />
            <token id="16" string="stated" />
            <token id="17" string="cause" />
            <token id="18" string="for" />
            <token id="19" string="the" />
            <token id="20" string="traffic" />
            <token id="21" string="stop" />
            <token id="22" string="--" />
            <token id="23" string="and" />
            <token id="24" string="whether" />
            <token id="25" string="Jackson" />
            <token id="26" string="acted" />
            <token id="27" string="aggressively" />
            <token id="28" string="toward" />
            <token id="29" string="the" />
            <token id="30" string="officers" />
            <token id="31" string="," />
            <token id="32" string="as" />
            <token id="33" string="Dickey" />
            <token id="34" string="said" />
            <token id="35" string="in" />
            <token id="36" string="his" />
            <token id="37" string="report" />
          </tokens>
        </chunking>
        <chunking id="7" string="Jackson" type="NP">
          <tokens>
            <token id="8" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="8" string="whether Jackson acted aggressively toward the officers , as Dickey said in his report" type="SBAR">
          <tokens>
            <token id="24" string="whether" />
            <token id="25" string="Jackson" />
            <token id="26" string="acted" />
            <token id="27" string="aggressively" />
            <token id="28" string="toward" />
            <token id="29" string="the" />
            <token id="30" string="officers" />
            <token id="31" string="," />
            <token id="32" string="as" />
            <token id="33" string="Dickey" />
            <token id="34" string="said" />
            <token id="35" string="in" />
            <token id="36" string="his" />
            <token id="37" string="report" />
          </tokens>
        </chunking>
        <chunking id="9" string="riding" type="VP">
          <tokens>
            <token id="10" string="riding" />
          </tokens>
        </chunking>
        <chunking id="10" string="Boatwright" type="NP">
          <tokens>
            <token id="1" string="Boatwright" />
          </tokens>
        </chunking>
        <chunking id="11" string="the car" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="car" />
          </tokens>
        </chunking>
        <chunking id="12" string="in which Jackson was riding" type="SBAR">
          <tokens>
            <token id="6" string="in" />
            <token id="7" string="which" />
            <token id="8" string="Jackson" />
            <token id="9" string="was" />
            <token id="10" string="riding" />
          </tokens>
        </chunking>
        <chunking id="13" string="acted aggressively toward the officers , as Dickey said in his report" type="VP">
          <tokens>
            <token id="26" string="acted" />
            <token id="27" string="aggressively" />
            <token id="28" string="toward" />
            <token id="29" string="the" />
            <token id="30" string="officers" />
            <token id="31" string="," />
            <token id="32" string="as" />
            <token id="33" string="Dickey" />
            <token id="34" string="said" />
            <token id="35" string="in" />
            <token id="36" string="his" />
            <token id="37" string="report" />
          </tokens>
        </chunking>
        <chunking id="14" string="was actually weaving -- the stated cause for the traffic stop --" type="VP">
          <tokens>
            <token id="11" string="was" />
            <token id="12" string="actually" />
            <token id="13" string="weaving" />
            <token id="14" string="--" />
            <token id="15" string="the" />
            <token id="16" string="stated" />
            <token id="17" string="cause" />
            <token id="18" string="for" />
            <token id="19" string="the" />
            <token id="20" string="traffic" />
            <token id="21" string="stop" />
            <token id="22" string="--" />
          </tokens>
        </chunking>
        <chunking id="15" string="weaving" type="VP">
          <tokens>
            <token id="13" string="weaving" />
          </tokens>
        </chunking>
        <chunking id="16" string="was riding" type="VP">
          <tokens>
            <token id="9" string="was" />
            <token id="10" string="riding" />
          </tokens>
        </chunking>
        <chunking id="17" string="said in his report" type="VP">
          <tokens>
            <token id="34" string="said" />
            <token id="35" string="in" />
            <token id="36" string="his" />
            <token id="37" string="report" />
          </tokens>
        </chunking>
        <chunking id="18" string="the officers" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="officers" />
          </tokens>
        </chunking>
        <chunking id="19" string="as Dickey said in his report" type="SBAR">
          <tokens>
            <token id="32" string="as" />
            <token id="33" string="Dickey" />
            <token id="34" string="said" />
            <token id="35" string="in" />
            <token id="36" string="his" />
            <token id="37" string="report" />
          </tokens>
        </chunking>
        <chunking id="20" string="whether the car in which Jackson was riding was actually weaving -- the stated cause for the traffic stop --" type="SBAR">
          <tokens>
            <token id="3" string="whether" />
            <token id="4" string="the" />
            <token id="5" string="car" />
            <token id="6" string="in" />
            <token id="7" string="which" />
            <token id="8" string="Jackson" />
            <token id="9" string="was" />
            <token id="10" string="riding" />
            <token id="11" string="was" />
            <token id="12" string="actually" />
            <token id="13" string="weaving" />
            <token id="14" string="--" />
            <token id="15" string="the" />
            <token id="16" string="stated" />
            <token id="17" string="cause" />
            <token id="18" string="for" />
            <token id="19" string="the" />
            <token id="20" string="traffic" />
            <token id="21" string="stop" />
            <token id="22" string="--" />
          </tokens>
        </chunking>
        <chunking id="21" string="weaving -- the stated cause for the traffic stop --" type="VP">
          <tokens>
            <token id="13" string="weaving" />
            <token id="14" string="--" />
            <token id="15" string="the" />
            <token id="16" string="stated" />
            <token id="17" string="cause" />
            <token id="18" string="for" />
            <token id="19" string="the" />
            <token id="20" string="traffic" />
            <token id="21" string="stop" />
            <token id="22" string="--" />
          </tokens>
        </chunking>
        <chunking id="22" string="the car in which Jackson was riding" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="car" />
            <token id="6" string="in" />
            <token id="7" string="which" />
            <token id="8" string="Jackson" />
            <token id="9" string="was" />
            <token id="10" string="riding" />
          </tokens>
        </chunking>
        <chunking id="23" string="Dickey" type="NP">
          <tokens>
            <token id="33" string="Dickey" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">questioned</governor>
          <dependent id="1">Boatwright</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">questioned</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">weaving</governor>
          <dependent id="3">whether</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">car</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">weaving</governor>
          <dependent id="5">car</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">which</governor>
          <dependent id="6">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">riding</governor>
          <dependent id="7">which</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">riding</governor>
          <dependent id="8">Jackson</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="10">riding</governor>
          <dependent id="9">was</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="5">car</governor>
          <dependent id="10">riding</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="13">weaving</governor>
          <dependent id="11">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">weaving</governor>
          <dependent id="12">actually</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">questioned</governor>
          <dependent id="13">weaving</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">cause</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">cause</governor>
          <dependent id="16">stated</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="13">weaving</governor>
          <dependent id="17">cause</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">stop</governor>
          <dependent id="18">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">stop</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">stop</governor>
          <dependent id="20">traffic</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">cause</governor>
          <dependent id="21">stop</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">weaving</governor>
          <dependent id="23">and</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="26">acted</governor>
          <dependent id="24">whether</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">acted</governor>
          <dependent id="25">Jackson</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">weaving</governor>
          <dependent id="26">acted</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="26">acted</governor>
          <dependent id="27">aggressively</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">officers</governor>
          <dependent id="28">toward</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">officers</governor>
          <dependent id="29">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">acted</governor>
          <dependent id="30">officers</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="34">said</governor>
          <dependent id="32">as</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="34">said</governor>
          <dependent id="33">Dickey</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="26">acted</governor>
          <dependent id="34">said</dependent>
        </dependency>
        <dependency type="case">
          <governor id="37">report</governor>
          <dependent id="35">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="37">report</governor>
          <dependent id="36">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="34">said</governor>
          <dependent id="37">report</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Jackson" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Jackson" />
          </tokens>
        </entity>
        <entity id="2" string="Boatwright" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Boatwright" />
          </tokens>
        </entity>
        <entity id="3" string="Dickey" type="PERSON" score="0.0">
          <tokens>
            <token id="33" string="Dickey" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>At one point, Boatwright asked Dickey: &amp;quot;You became the judge, jury and executioner as to whether he was challenged to a fight?&amp;quot;</content>
      <tokens>
        <token id="1" string="At" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="3" string="point" lemma="point" stem="point" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Boatwright" lemma="Boatwright" stem="boatwright" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="6" string="asked" lemma="ask" stem="ask" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="Dickey" lemma="Dickey" stem="dickei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="8" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="You" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="became" lemma="become" stem="becam" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="judge" lemma="judge" stem="judg" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="jury" lemma="jury" stem="juri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="executioner" lemma="executioner" stem="execution" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="whether" lemma="whether" stem="whether" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="challenged" lemma="challenge" stem="challeng" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="26" string="fight" lemma="fight" stem="fight" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="27" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN At) (NP (CD one) (NN point))) (, ,) (NP (NNP Boatwright)) (VP (VBD asked) (NP (NNP Dickey)) (: :) (`` ``) (S (NP (PRP You)) (VP (VBD became) (NP (DT the) (NN judge) (, ,) (NN jury) (CC and) (NN executioner)) (PP (IN as) (PP (TO to) (SBAR (IN whether) (S (NP (PRP he)) (VP (VBD was) (VP (VBN challenged) (PP (TO to) (NP (DT a) (NN fight)))))))))))) (. ?) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="was challenged to a fight" type="VP">
          <tokens>
            <token id="22" string="was" />
            <token id="23" string="challenged" />
            <token id="24" string="to" />
            <token id="25" string="a" />
            <token id="26" string="fight" />
          </tokens>
        </chunking>
        <chunking id="2" string="whether he was challenged to a fight" type="SBAR">
          <tokens>
            <token id="20" string="whether" />
            <token id="21" string="he" />
            <token id="22" string="was" />
            <token id="23" string="challenged" />
            <token id="24" string="to" />
            <token id="25" string="a" />
            <token id="26" string="fight" />
          </tokens>
        </chunking>
        <chunking id="3" string="a fight" type="NP">
          <tokens>
            <token id="25" string="a" />
            <token id="26" string="fight" />
          </tokens>
        </chunking>
        <chunking id="4" string="one point" type="NP">
          <tokens>
            <token id="2" string="one" />
            <token id="3" string="point" />
          </tokens>
        </chunking>
        <chunking id="5" string="became the judge , jury and executioner as to whether he was challenged to a fight" type="VP">
          <tokens>
            <token id="11" string="became" />
            <token id="12" string="the" />
            <token id="13" string="judge" />
            <token id="14" string="," />
            <token id="15" string="jury" />
            <token id="16" string="and" />
            <token id="17" string="executioner" />
            <token id="18" string="as" />
            <token id="19" string="to" />
            <token id="20" string="whether" />
            <token id="21" string="he" />
            <token id="22" string="was" />
            <token id="23" string="challenged" />
            <token id="24" string="to" />
            <token id="25" string="a" />
            <token id="26" string="fight" />
          </tokens>
        </chunking>
        <chunking id="6" string="asked Dickey : `` You became the judge , jury and executioner as to whether he was challenged to a fight" type="VP">
          <tokens>
            <token id="6" string="asked" />
            <token id="7" string="Dickey" />
            <token id="8" string=":" />
            <token id="9" string="&quot;" />
            <token id="10" string="You" />
            <token id="11" string="became" />
            <token id="12" string="the" />
            <token id="13" string="judge" />
            <token id="14" string="," />
            <token id="15" string="jury" />
            <token id="16" string="and" />
            <token id="17" string="executioner" />
            <token id="18" string="as" />
            <token id="19" string="to" />
            <token id="20" string="whether" />
            <token id="21" string="he" />
            <token id="22" string="was" />
            <token id="23" string="challenged" />
            <token id="24" string="to" />
            <token id="25" string="a" />
            <token id="26" string="fight" />
          </tokens>
        </chunking>
        <chunking id="7" string="Boatwright" type="NP">
          <tokens>
            <token id="5" string="Boatwright" />
          </tokens>
        </chunking>
        <chunking id="8" string="he" type="NP">
          <tokens>
            <token id="21" string="he" />
          </tokens>
        </chunking>
        <chunking id="9" string="challenged to a fight" type="VP">
          <tokens>
            <token id="23" string="challenged" />
            <token id="24" string="to" />
            <token id="25" string="a" />
            <token id="26" string="fight" />
          </tokens>
        </chunking>
        <chunking id="10" string="Dickey" type="NP">
          <tokens>
            <token id="7" string="Dickey" />
          </tokens>
        </chunking>
        <chunking id="11" string="You" type="NP">
          <tokens>
            <token id="10" string="You" />
          </tokens>
        </chunking>
        <chunking id="12" string="the judge , jury and executioner" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="judge" />
            <token id="14" string="," />
            <token id="15" string="jury" />
            <token id="16" string="and" />
            <token id="17" string="executioner" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">point</governor>
          <dependent id="1">At</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="3">point</governor>
          <dependent id="2">one</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">asked</governor>
          <dependent id="3">point</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">asked</governor>
          <dependent id="5">Boatwright</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">asked</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">asked</governor>
          <dependent id="7">Dickey</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">became</governor>
          <dependent id="10">You</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="6">asked</governor>
          <dependent id="11">became</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">judge</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="11">became</governor>
          <dependent id="13">judge</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">judge</governor>
          <dependent id="15">jury</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">judge</governor>
          <dependent id="16">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">judge</governor>
          <dependent id="17">executioner</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">challenged</governor>
          <dependent id="18">as</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="23">challenged</governor>
          <dependent id="19">to</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="23">challenged</governor>
          <dependent id="20">whether</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="23">challenged</governor>
          <dependent id="21">he</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="23">challenged</governor>
          <dependent id="22">was</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="11">became</governor>
          <dependent id="23">challenged</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">fight</governor>
          <dependent id="24">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">fight</governor>
          <dependent id="25">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">challenged</governor>
          <dependent id="26">fight</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="2" string="one" />
          </tokens>
        </entity>
        <entity id="2" string="Boatwright" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Boatwright" />
          </tokens>
        </entity>
        <entity id="3" string="Dickey" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Dickey" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>&amp;quot;No,&amp;quot; Dickey tersely replied.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="No" lemma="no" stem="no" pos="UH" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Dickey" lemma="Dickey" stem="dickei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="6" string="tersely" lemma="tersely" stem="ters" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="replied" lemma="reply" stem="repli" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (FRAG (INTJ (UH No))) (, ,) ('' '') (NP (NNP Dickey)) (VP (ADVP (RB tersely)) (VBD replied)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="tersely replied" type="VP">
          <tokens>
            <token id="6" string="tersely" />
            <token id="7" string="replied" />
          </tokens>
        </chunking>
        <chunking id="2" string="Dickey" type="NP">
          <tokens>
            <token id="5" string="Dickey" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="dep">
          <governor id="7">replied</governor>
          <dependent id="2">No</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">replied</governor>
          <dependent id="5">Dickey</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">replied</governor>
          <dependent id="6">tersely</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">replied</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Dickey" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Dickey" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>Dickey&amp;apost;s attorney, Michael Hannon, refused to allow Dickey to answer any more questions after nearly three hours of questioning because of what he called the &amp;quot;hostile and badgering&amp;quot; nature of the inquiry.</content>
      <tokens>
        <token id="1" string="Dickey" lemma="Dickey" stem="dickei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="2" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="3" string="attorney" lemma="attorney" stem="attornei" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="Michael" lemma="Michael" stem="michael" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="6" string="Hannon" lemma="Hannon" stem="hannon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="refused" lemma="refuse" stem="refus" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="allow" lemma="allow" stem="allow" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="Dickey" lemma="Dickey" stem="dickei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="12" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="answer" lemma="answer" stem="answer" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="any" lemma="any" stem="ani" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="more" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="questions" lemma="question" stem="question" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="nearly" lemma="nearly" stem="nearli" pos="RB" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="19" string="three" lemma="three" stem="three" pos="CD" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="20" string="hours" lemma="hour" stem="hour" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="21" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="questioning" lemma="question" stem="question" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="27" string="called" lemma="call" stem="call" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="hostile" lemma="hostile" stem="hostil" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="badgering" lemma="badgering" stem="badger" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="nature" lemma="nature" stem="natur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="inquiry" lemma="inquiry" stem="inquiri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NP (NNP Dickey) (POS 's)) (NN attorney)) (, ,) (NP (NNP Michael) (NNP Hannon)) (, ,)) (VP (VBD refused) (S (VP (TO to) (VP (VB allow) (S (NP (NNP Dickey)) (VP (TO to) (VP (VB answer) (NP (DT any) (JJR more) (NNS questions)) (PP (IN after) (NP (NP (QP (RB nearly) (CD three)) (NNS hours)) (PP (IN of) (S (VP (VBG questioning) (SBAR (IN because) (SBAR (WHPP (IN of) (WHNP (WP what))) (S (NP (PRP he)) (VP (VBD called) (NP (DT the) (`` ``) (JJ hostile) (CC and) (NN badgering) ('' '') (NN nature)) (PP (IN of) (NP (DT the) (NN inquiry))))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Michael Hannon" type="NP">
          <tokens>
            <token id="5" string="Michael" />
            <token id="6" string="Hannon" />
          </tokens>
        </chunking>
        <chunking id="2" string="refused to allow Dickey to answer any more questions after nearly three hours of questioning because of what he called the `` hostile and badgering '' nature of the inquiry" type="VP">
          <tokens>
            <token id="8" string="refused" />
            <token id="9" string="to" />
            <token id="10" string="allow" />
            <token id="11" string="Dickey" />
            <token id="12" string="to" />
            <token id="13" string="answer" />
            <token id="14" string="any" />
            <token id="15" string="more" />
            <token id="16" string="questions" />
            <token id="17" string="after" />
            <token id="18" string="nearly" />
            <token id="19" string="three" />
            <token id="20" string="hours" />
            <token id="21" string="of" />
            <token id="22" string="questioning" />
            <token id="23" string="because" />
            <token id="24" string="of" />
            <token id="25" string="what" />
            <token id="26" string="he" />
            <token id="27" string="called" />
            <token id="28" string="the" />
            <token id="29" string="&quot;" />
            <token id="30" string="hostile" />
            <token id="31" string="and" />
            <token id="32" string="badgering" />
            <token id="33" string="&quot;" />
            <token id="34" string="nature" />
            <token id="35" string="of" />
            <token id="36" string="the" />
            <token id="37" string="inquiry" />
          </tokens>
        </chunking>
        <chunking id="3" string="the `` hostile and badgering '' nature" type="NP">
          <tokens>
            <token id="28" string="the" />
            <token id="29" string="&quot;" />
            <token id="30" string="hostile" />
            <token id="31" string="and" />
            <token id="32" string="badgering" />
            <token id="33" string="&quot;" />
            <token id="34" string="nature" />
          </tokens>
        </chunking>
        <chunking id="4" string="Dickey 's" type="NP">
          <tokens>
            <token id="1" string="Dickey" />
            <token id="2" string="'s" />
          </tokens>
        </chunking>
        <chunking id="5" string="to allow Dickey to answer any more questions after nearly three hours of questioning because of what he called the `` hostile and badgering '' nature of the inquiry" type="VP">
          <tokens>
            <token id="9" string="to" />
            <token id="10" string="allow" />
            <token id="11" string="Dickey" />
            <token id="12" string="to" />
            <token id="13" string="answer" />
            <token id="14" string="any" />
            <token id="15" string="more" />
            <token id="16" string="questions" />
            <token id="17" string="after" />
            <token id="18" string="nearly" />
            <token id="19" string="three" />
            <token id="20" string="hours" />
            <token id="21" string="of" />
            <token id="22" string="questioning" />
            <token id="23" string="because" />
            <token id="24" string="of" />
            <token id="25" string="what" />
            <token id="26" string="he" />
            <token id="27" string="called" />
            <token id="28" string="the" />
            <token id="29" string="&quot;" />
            <token id="30" string="hostile" />
            <token id="31" string="and" />
            <token id="32" string="badgering" />
            <token id="33" string="&quot;" />
            <token id="34" string="nature" />
            <token id="35" string="of" />
            <token id="36" string="the" />
            <token id="37" string="inquiry" />
          </tokens>
        </chunking>
        <chunking id="6" string="nearly three hours" type="NP">
          <tokens>
            <token id="18" string="nearly" />
            <token id="19" string="three" />
            <token id="20" string="hours" />
          </tokens>
        </chunking>
        <chunking id="7" string="allow Dickey to answer any more questions after nearly three hours of questioning because of what he called the `` hostile and badgering '' nature of the inquiry" type="VP">
          <tokens>
            <token id="10" string="allow" />
            <token id="11" string="Dickey" />
            <token id="12" string="to" />
            <token id="13" string="answer" />
            <token id="14" string="any" />
            <token id="15" string="more" />
            <token id="16" string="questions" />
            <token id="17" string="after" />
            <token id="18" string="nearly" />
            <token id="19" string="three" />
            <token id="20" string="hours" />
            <token id="21" string="of" />
            <token id="22" string="questioning" />
            <token id="23" string="because" />
            <token id="24" string="of" />
            <token id="25" string="what" />
            <token id="26" string="he" />
            <token id="27" string="called" />
            <token id="28" string="the" />
            <token id="29" string="&quot;" />
            <token id="30" string="hostile" />
            <token id="31" string="and" />
            <token id="32" string="badgering" />
            <token id="33" string="&quot;" />
            <token id="34" string="nature" />
            <token id="35" string="of" />
            <token id="36" string="the" />
            <token id="37" string="inquiry" />
          </tokens>
        </chunking>
        <chunking id="8" string="to answer any more questions after nearly three hours of questioning because of what he called the `` hostile and badgering '' nature of the inquiry" type="VP">
          <tokens>
            <token id="12" string="to" />
            <token id="13" string="answer" />
            <token id="14" string="any" />
            <token id="15" string="more" />
            <token id="16" string="questions" />
            <token id="17" string="after" />
            <token id="18" string="nearly" />
            <token id="19" string="three" />
            <token id="20" string="hours" />
            <token id="21" string="of" />
            <token id="22" string="questioning" />
            <token id="23" string="because" />
            <token id="24" string="of" />
            <token id="25" string="what" />
            <token id="26" string="he" />
            <token id="27" string="called" />
            <token id="28" string="the" />
            <token id="29" string="&quot;" />
            <token id="30" string="hostile" />
            <token id="31" string="and" />
            <token id="32" string="badgering" />
            <token id="33" string="&quot;" />
            <token id="34" string="nature" />
            <token id="35" string="of" />
            <token id="36" string="the" />
            <token id="37" string="inquiry" />
          </tokens>
        </chunking>
        <chunking id="9" string="of what he called the `` hostile and badgering '' nature of the inquiry" type="SBAR">
          <tokens>
            <token id="24" string="of" />
            <token id="25" string="what" />
            <token id="26" string="he" />
            <token id="27" string="called" />
            <token id="28" string="the" />
            <token id="29" string="&quot;" />
            <token id="30" string="hostile" />
            <token id="31" string="and" />
            <token id="32" string="badgering" />
            <token id="33" string="&quot;" />
            <token id="34" string="nature" />
            <token id="35" string="of" />
            <token id="36" string="the" />
            <token id="37" string="inquiry" />
          </tokens>
        </chunking>
        <chunking id="10" string="Dickey 's attorney" type="NP">
          <tokens>
            <token id="1" string="Dickey" />
            <token id="2" string="'s" />
            <token id="3" string="attorney" />
          </tokens>
        </chunking>
        <chunking id="11" string="questioning because of what he called the `` hostile and badgering '' nature of the inquiry" type="VP">
          <tokens>
            <token id="22" string="questioning" />
            <token id="23" string="because" />
            <token id="24" string="of" />
            <token id="25" string="what" />
            <token id="26" string="he" />
            <token id="27" string="called" />
            <token id="28" string="the" />
            <token id="29" string="&quot;" />
            <token id="30" string="hostile" />
            <token id="31" string="and" />
            <token id="32" string="badgering" />
            <token id="33" string="&quot;" />
            <token id="34" string="nature" />
            <token id="35" string="of" />
            <token id="36" string="the" />
            <token id="37" string="inquiry" />
          </tokens>
        </chunking>
        <chunking id="12" string="called the `` hostile and badgering '' nature of the inquiry" type="VP">
          <tokens>
            <token id="27" string="called" />
            <token id="28" string="the" />
            <token id="29" string="&quot;" />
            <token id="30" string="hostile" />
            <token id="31" string="and" />
            <token id="32" string="badgering" />
            <token id="33" string="&quot;" />
            <token id="34" string="nature" />
            <token id="35" string="of" />
            <token id="36" string="the" />
            <token id="37" string="inquiry" />
          </tokens>
        </chunking>
        <chunking id="13" string="Dickey 's attorney , Michael Hannon ," type="NP">
          <tokens>
            <token id="1" string="Dickey" />
            <token id="2" string="'s" />
            <token id="3" string="attorney" />
            <token id="4" string="," />
            <token id="5" string="Michael" />
            <token id="6" string="Hannon" />
            <token id="7" string="," />
          </tokens>
        </chunking>
        <chunking id="14" string="the inquiry" type="NP">
          <tokens>
            <token id="36" string="the" />
            <token id="37" string="inquiry" />
          </tokens>
        </chunking>
        <chunking id="15" string="nearly three hours of questioning because of what he called the `` hostile and badgering '' nature of the inquiry" type="NP">
          <tokens>
            <token id="18" string="nearly" />
            <token id="19" string="three" />
            <token id="20" string="hours" />
            <token id="21" string="of" />
            <token id="22" string="questioning" />
            <token id="23" string="because" />
            <token id="24" string="of" />
            <token id="25" string="what" />
            <token id="26" string="he" />
            <token id="27" string="called" />
            <token id="28" string="the" />
            <token id="29" string="&quot;" />
            <token id="30" string="hostile" />
            <token id="31" string="and" />
            <token id="32" string="badgering" />
            <token id="33" string="&quot;" />
            <token id="34" string="nature" />
            <token id="35" string="of" />
            <token id="36" string="the" />
            <token id="37" string="inquiry" />
          </tokens>
        </chunking>
        <chunking id="16" string="because of what he called the `` hostile and badgering '' nature of the inquiry" type="SBAR">
          <tokens>
            <token id="23" string="because" />
            <token id="24" string="of" />
            <token id="25" string="what" />
            <token id="26" string="he" />
            <token id="27" string="called" />
            <token id="28" string="the" />
            <token id="29" string="&quot;" />
            <token id="30" string="hostile" />
            <token id="31" string="and" />
            <token id="32" string="badgering" />
            <token id="33" string="&quot;" />
            <token id="34" string="nature" />
            <token id="35" string="of" />
            <token id="36" string="the" />
            <token id="37" string="inquiry" />
          </tokens>
        </chunking>
        <chunking id="17" string="answer any more questions after nearly three hours of questioning because of what he called the `` hostile and badgering '' nature of the inquiry" type="VP">
          <tokens>
            <token id="13" string="answer" />
            <token id="14" string="any" />
            <token id="15" string="more" />
            <token id="16" string="questions" />
            <token id="17" string="after" />
            <token id="18" string="nearly" />
            <token id="19" string="three" />
            <token id="20" string="hours" />
            <token id="21" string="of" />
            <token id="22" string="questioning" />
            <token id="23" string="because" />
            <token id="24" string="of" />
            <token id="25" string="what" />
            <token id="26" string="he" />
            <token id="27" string="called" />
            <token id="28" string="the" />
            <token id="29" string="&quot;" />
            <token id="30" string="hostile" />
            <token id="31" string="and" />
            <token id="32" string="badgering" />
            <token id="33" string="&quot;" />
            <token id="34" string="nature" />
            <token id="35" string="of" />
            <token id="36" string="the" />
            <token id="37" string="inquiry" />
          </tokens>
        </chunking>
        <chunking id="18" string="he" type="NP">
          <tokens>
            <token id="26" string="he" />
          </tokens>
        </chunking>
        <chunking id="19" string="any more questions" type="NP">
          <tokens>
            <token id="14" string="any" />
            <token id="15" string="more" />
            <token id="16" string="questions" />
          </tokens>
        </chunking>
        <chunking id="20" string="Dickey" type="NP">
          <tokens>
            <token id="11" string="Dickey" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="3">attorney</governor>
          <dependent id="1">Dickey</dependent>
        </dependency>
        <dependency type="case">
          <governor id="1">Dickey</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">refused</governor>
          <dependent id="3">attorney</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Hannon</governor>
          <dependent id="5">Michael</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="3">attorney</governor>
          <dependent id="6">Hannon</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">refused</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">allow</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="8">refused</governor>
          <dependent id="10">allow</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">allow</governor>
          <dependent id="11">Dickey</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">answer</governor>
          <dependent id="12">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="10">allow</governor>
          <dependent id="13">answer</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">questions</governor>
          <dependent id="14">any</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">questions</governor>
          <dependent id="15">more</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">answer</governor>
          <dependent id="16">questions</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">hours</governor>
          <dependent id="17">after</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="19">three</governor>
          <dependent id="18">nearly</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="20">hours</governor>
          <dependent id="19">three</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">answer</governor>
          <dependent id="20">hours</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">questioning</governor>
          <dependent id="21">of</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="20">hours</governor>
          <dependent id="22">questioning</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="27">called</governor>
          <dependent id="23">because</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">what</governor>
          <dependent id="24">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">called</governor>
          <dependent id="25">what</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">called</governor>
          <dependent id="26">he</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="22">questioning</governor>
          <dependent id="27">called</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">hostile</governor>
          <dependent id="28">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="27">called</governor>
          <dependent id="30">hostile</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="30">hostile</governor>
          <dependent id="31">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="34">nature</governor>
          <dependent id="32">badgering</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="30">hostile</governor>
          <dependent id="34">nature</dependent>
        </dependency>
        <dependency type="case">
          <governor id="37">inquiry</governor>
          <dependent id="35">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="37">inquiry</governor>
          <dependent id="36">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">called</governor>
          <dependent id="37">inquiry</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Michael Hannon" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Michael" />
            <token id="6" string="Hannon" />
          </tokens>
        </entity>
        <entity id="2" string="nearly three hours" type="DURATION" score="0.0">
          <tokens>
            <token id="18" string="nearly" />
            <token id="19" string="three" />
            <token id="20" string="hours" />
          </tokens>
        </entity>
        <entity id="3" string="Dickey" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Dickey" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="17" has_coreference="false">
      <content>&amp;quot;This little kangaroo court gives these politicians a chance to run for office.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="This" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="little" lemma="little" stem="littl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="kangaroo" lemma="kangaroo" stem="kangaroo" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="court" lemma="court" stem="court" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="gives" lemma="give" stem="give" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="these" lemma="these" stem="these" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="politicians" lemma="politician" stem="politician" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="chance" lemma="chance" stem="chanc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="run" lemma="run" stem="run" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="office" lemma="office" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (DT This) (JJ little) (NN kangaroo) (NN court)) (VP (VBZ gives) (NP (DT these) (NNS politicians)) (NP (DT a) (NN chance) (S (VP (TO to) (VP (VB run) (PP (IN for) (NP (NN office)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="This little kangaroo court" type="NP">
          <tokens>
            <token id="2" string="This" />
            <token id="3" string="little" />
            <token id="4" string="kangaroo" />
            <token id="5" string="court" />
          </tokens>
        </chunking>
        <chunking id="2" string="a chance to run for office" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="chance" />
            <token id="11" string="to" />
            <token id="12" string="run" />
            <token id="13" string="for" />
            <token id="14" string="office" />
          </tokens>
        </chunking>
        <chunking id="3" string="run for office" type="VP">
          <tokens>
            <token id="12" string="run" />
            <token id="13" string="for" />
            <token id="14" string="office" />
          </tokens>
        </chunking>
        <chunking id="4" string="these politicians" type="NP">
          <tokens>
            <token id="7" string="these" />
            <token id="8" string="politicians" />
          </tokens>
        </chunking>
        <chunking id="5" string="to run for office" type="VP">
          <tokens>
            <token id="11" string="to" />
            <token id="12" string="run" />
            <token id="13" string="for" />
            <token id="14" string="office" />
          </tokens>
        </chunking>
        <chunking id="6" string="gives these politicians a chance to run for office" type="VP">
          <tokens>
            <token id="6" string="gives" />
            <token id="7" string="these" />
            <token id="8" string="politicians" />
            <token id="9" string="a" />
            <token id="10" string="chance" />
            <token id="11" string="to" />
            <token id="12" string="run" />
            <token id="13" string="for" />
            <token id="14" string="office" />
          </tokens>
        </chunking>
        <chunking id="7" string="office" type="NP">
          <tokens>
            <token id="14" string="office" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="5">court</governor>
          <dependent id="2">This</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">court</governor>
          <dependent id="3">little</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">court</governor>
          <dependent id="4">kangaroo</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">gives</governor>
          <dependent id="5">court</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">gives</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">politicians</governor>
          <dependent id="7">these</dependent>
        </dependency>
        <dependency type="iobj">
          <governor id="6">gives</governor>
          <dependent id="8">politicians</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">chance</governor>
          <dependent id="9">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">gives</governor>
          <dependent id="10">chance</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">run</governor>
          <dependent id="11">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="10">chance</governor>
          <dependent id="12">run</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">office</governor>
          <dependent id="13">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">run</governor>
          <dependent id="14">office</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="18" has_coreference="true">
      <content>Any resemblance between this and a fair hearing is just imaginary,&amp;quot; Hannon told reporters afterward.</content>
      <tokens>
        <token id="1" string="Any" lemma="any" stem="any" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="resemblance" lemma="resemblance" stem="resembl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="between" lemma="between" stem="between" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="fair" lemma="fair" stem="fair" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="hearing" lemma="hearing" stem="hear" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="imaginary" lemma="imaginary" stem="imaginari" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Hannon" lemma="Hannon" stem="hannon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="15" string="told" lemma="tell" stem="told" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="reporters" lemma="reporter" stem="report" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="afterward" lemma="afterward" stem="afterward" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (DT Any) (NN resemblance)) (PP (IN between) (NP (NP (DT this)) (CC and) (NP (DT a) (JJ fair) (NN hearing))))) (VP (VBZ is) (NP (RB just) (JJ imaginary)))) (, ,) ('' '') (NP (NNP Hannon)) (VP (VBD told) (NP (NNS reporters)) (ADVP (RB afterward))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Any resemblance" type="NP">
          <tokens>
            <token id="1" string="Any" />
            <token id="2" string="resemblance" />
          </tokens>
        </chunking>
        <chunking id="2" string="a fair hearing" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="fair" />
            <token id="8" string="hearing" />
          </tokens>
        </chunking>
        <chunking id="3" string="Hannon" type="NP">
          <tokens>
            <token id="14" string="Hannon" />
          </tokens>
        </chunking>
        <chunking id="4" string="reporters" type="NP">
          <tokens>
            <token id="16" string="reporters" />
          </tokens>
        </chunking>
        <chunking id="5" string="just imaginary" type="NP">
          <tokens>
            <token id="10" string="just" />
            <token id="11" string="imaginary" />
          </tokens>
        </chunking>
        <chunking id="6" string="this and a fair hearing" type="NP">
          <tokens>
            <token id="4" string="this" />
            <token id="5" string="and" />
            <token id="6" string="a" />
            <token id="7" string="fair" />
            <token id="8" string="hearing" />
          </tokens>
        </chunking>
        <chunking id="7" string="is just imaginary" type="VP">
          <tokens>
            <token id="9" string="is" />
            <token id="10" string="just" />
            <token id="11" string="imaginary" />
          </tokens>
        </chunking>
        <chunking id="8" string="told reporters afterward" type="VP">
          <tokens>
            <token id="15" string="told" />
            <token id="16" string="reporters" />
            <token id="17" string="afterward" />
          </tokens>
        </chunking>
        <chunking id="9" string="Any resemblance between this and a fair hearing" type="NP">
          <tokens>
            <token id="1" string="Any" />
            <token id="2" string="resemblance" />
            <token id="3" string="between" />
            <token id="4" string="this" />
            <token id="5" string="and" />
            <token id="6" string="a" />
            <token id="7" string="fair" />
            <token id="8" string="hearing" />
          </tokens>
        </chunking>
        <chunking id="10" string="this" type="NP">
          <tokens>
            <token id="4" string="this" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">resemblance</governor>
          <dependent id="1">Any</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">imaginary</governor>
          <dependent id="2">resemblance</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">this</governor>
          <dependent id="3">between</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">resemblance</governor>
          <dependent id="4">this</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">this</governor>
          <dependent id="5">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">hearing</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">hearing</governor>
          <dependent id="7">fair</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">this</governor>
          <dependent id="8">hearing</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="11">imaginary</governor>
          <dependent id="9">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">imaginary</governor>
          <dependent id="10">just</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="15">told</governor>
          <dependent id="11">imaginary</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">told</governor>
          <dependent id="14">Hannon</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">told</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">told</governor>
          <dependent id="16">reporters</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">told</governor>
          <dependent id="17">afterward</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Hannon" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Hannon" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="19" has_coreference="true">
      <content>&amp;quot;They are taking stuff out of context and just badgering him with it.&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="They" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="taking" lemma="take" stem="take" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="stuff" lemma="stuff" stem="stuff" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="out" lemma="out" stem="out" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="context" lemma="context" stem="context" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="badgering" lemma="badger" stem="badger" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP They)) (VP (VBP are) (VP (VP (VBG taking) (NP (NN stuff)) (ADVP (IN out) (PP (IN of) (NP (NN context))))) (CC and) (VP (ADVP (RB just)) (VBG badgering) (NP (PRP him)) (PP (IN with) (NP (PRP it)))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="They" type="NP">
          <tokens>
            <token id="2" string="They" />
          </tokens>
        </chunking>
        <chunking id="2" string="taking stuff out of context" type="VP">
          <tokens>
            <token id="4" string="taking" />
            <token id="5" string="stuff" />
            <token id="6" string="out" />
            <token id="7" string="of" />
            <token id="8" string="context" />
          </tokens>
        </chunking>
        <chunking id="3" string="just badgering him with it" type="VP">
          <tokens>
            <token id="10" string="just" />
            <token id="11" string="badgering" />
            <token id="12" string="him" />
            <token id="13" string="with" />
            <token id="14" string="it" />
          </tokens>
        </chunking>
        <chunking id="4" string="stuff" type="NP">
          <tokens>
            <token id="5" string="stuff" />
          </tokens>
        </chunking>
        <chunking id="5" string="context" type="NP">
          <tokens>
            <token id="8" string="context" />
          </tokens>
        </chunking>
        <chunking id="6" string="him" type="NP">
          <tokens>
            <token id="12" string="him" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="14" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="are taking stuff out of context and just badgering him with it" type="VP">
          <tokens>
            <token id="3" string="are" />
            <token id="4" string="taking" />
            <token id="5" string="stuff" />
            <token id="6" string="out" />
            <token id="7" string="of" />
            <token id="8" string="context" />
            <token id="9" string="and" />
            <token id="10" string="just" />
            <token id="11" string="badgering" />
            <token id="12" string="him" />
            <token id="13" string="with" />
            <token id="14" string="it" />
          </tokens>
        </chunking>
        <chunking id="9" string="taking stuff out of context and just badgering him with it" type="VP">
          <tokens>
            <token id="4" string="taking" />
            <token id="5" string="stuff" />
            <token id="6" string="out" />
            <token id="7" string="of" />
            <token id="8" string="context" />
            <token id="9" string="and" />
            <token id="10" string="just" />
            <token id="11" string="badgering" />
            <token id="12" string="him" />
            <token id="13" string="with" />
            <token id="14" string="it" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">taking</governor>
          <dependent id="2">They</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">taking</governor>
          <dependent id="3">are</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">taking</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">taking</governor>
          <dependent id="5">stuff</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">context</governor>
          <dependent id="6">out</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="6">out</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">taking</governor>
          <dependent id="8">context</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">taking</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">badgering</governor>
          <dependent id="10">just</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">taking</governor>
          <dependent id="11">badgering</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">badgering</governor>
          <dependent id="12">him</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">it</governor>
          <dependent id="13">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">badgering</governor>
          <dependent id="14">it</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="20" has_coreference="true">
      <content>Earlier, under questioning by Boatwright and as the videotape was played, Dickey testified that the alleged infraction for which the Jackson car was stopped -- crossing the center divider -- occurred before it could be seen on a tape shot from the NBC chase vehicle, but he maintained that the tape does show Jackson&amp;apost;s car weaving slowly within the traffic lane.</content>
      <tokens>
        <token id="1" string="Earlier" lemma="earlier" stem="earlier" pos="RBR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="under" lemma="under" stem="under" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="questioning" lemma="question" stem="question" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Boatwright" lemma="Boatwright" stem="boatwright" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="7" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="videotape" lemma="videotape" stem="videotap" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="played" lemma="play" stem="plai" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Dickey" lemma="Dickey" stem="dickei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="15" string="testified" lemma="testify" stem="testifi" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="alleged" lemma="alleged" stem="alleg" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="infraction" lemma="infraction" stem="infract" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="23" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="24" string="car" lemma="car" stem="car" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="25" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="26" string="stopped" lemma="stop" stem="stop" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="27" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="28" string="crossing" lemma="cross" stem="cross" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="29" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="30" string="center" lemma="center" stem="center" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="31" string="divider" lemma="divider" stem="divid" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="32" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="33" string="occurred" lemma="occur" stem="occur" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="before" lemma="before" stem="befor" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="seen" lemma="see" stem="seen" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="tape" lemma="tape" stem="tape" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="shot" lemma="shot" stem="shot" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="NBC" lemma="NBC" stem="nbc" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="46" string="chase" lemma="chase" stem="chase" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="47" string="vehicle" lemma="vehicle" stem="vehicl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="48" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="49" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="50" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="51" string="maintained" lemma="maintain" stem="maintain" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="52" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="53" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="54" string="tape" lemma="tape" stem="tape" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="55" string="does" lemma="do" stem="doe" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="56" string="show" lemma="show" stem="show" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="57" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="58" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="59" string="car" lemma="car" stem="car" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="60" string="weaving" lemma="weave" stem="weav" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="61" string="slowly" lemma="slowly" stem="slowli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="62" string="within" lemma="within" stem="within" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="63" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="64" string="traffic" lemma="traffic" stem="traffic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="65" string="lane" lemma="lane" stem="lane" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="66" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (ADVP (RBR Earlier)) (, ,) (PP (IN under) (S (VP (VBG questioning) (PP (PP (IN by) (NP (NNP Boatwright))) (CC and) (PP (IN as) (NP (NP (DT the) (NN videotape)) (SBAR (S (VP (VBD was) (VP (VBN played))))))))))) (, ,) (NP (NNP Dickey)) (VP (VBD testified) (SBAR (IN that) (S (NP (NP (NP (DT the) (JJ alleged) (NN infraction)) (SBAR (WHPP (IN for) (WHNP (WDT which))) (S (NP (DT the) (NNP Jackson) (NN car)) (VP (VBD was) (VP (VBN stopped)))))) (PRN (: --) (VP (VBG crossing) (NP (DT the) (NN center) (NN divider))) (: --))) (VP (VBD occurred) (SBAR (IN before) (S (NP (PRP it)) (VP (MD could) (VP (VB be) (VP (VBN seen) (PP (IN on) (NP (DT a) (NN tape) (NN shot))) (PP (IN from) (NP (DT the) (NNP NBC) (NN chase) (NN vehicle))))))))))))) (, ,) (CC but) (S (NP (PRP he)) (VP (VBD maintained) (SBAR (IN that) (S (NP (DT the) (NN tape)) (VP (VBZ does) (VP (VB show) (NP (NP (NP (NNP Jackson) (POS 's)) (NN car)) (VP (VBG weaving) (ADVP (RB slowly)) (PP (IN within) (NP (DT the) (NN traffic) (NN lane))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="was stopped" type="VP">
          <tokens>
            <token id="25" string="was" />
            <token id="26" string="stopped" />
          </tokens>
        </chunking>
        <chunking id="2" string="that the tape does show Jackson 's car weaving slowly within the traffic lane" type="SBAR">
          <tokens>
            <token id="52" string="that" />
            <token id="53" string="the" />
            <token id="54" string="tape" />
            <token id="55" string="does" />
            <token id="56" string="show" />
            <token id="57" string="Jackson" />
            <token id="58" string="'s" />
            <token id="59" string="car" />
            <token id="60" string="weaving" />
            <token id="61" string="slowly" />
            <token id="62" string="within" />
            <token id="63" string="the" />
            <token id="64" string="traffic" />
            <token id="65" string="lane" />
          </tokens>
        </chunking>
        <chunking id="3" string="stopped" type="VP">
          <tokens>
            <token id="26" string="stopped" />
          </tokens>
        </chunking>
        <chunking id="4" string="the alleged infraction for which the Jackson car was stopped" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="alleged" />
            <token id="19" string="infraction" />
            <token id="20" string="for" />
            <token id="21" string="which" />
            <token id="22" string="the" />
            <token id="23" string="Jackson" />
            <token id="24" string="car" />
            <token id="25" string="was" />
            <token id="26" string="stopped" />
          </tokens>
        </chunking>
        <chunking id="5" string="it" type="NP">
          <tokens>
            <token id="35" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="the traffic lane" type="NP">
          <tokens>
            <token id="63" string="the" />
            <token id="64" string="traffic" />
            <token id="65" string="lane" />
          </tokens>
        </chunking>
        <chunking id="7" string="crossing the center divider" type="VP">
          <tokens>
            <token id="28" string="crossing" />
            <token id="29" string="the" />
            <token id="30" string="center" />
            <token id="31" string="divider" />
          </tokens>
        </chunking>
        <chunking id="8" string="Boatwright" type="NP">
          <tokens>
            <token id="6" string="Boatwright" />
          </tokens>
        </chunking>
        <chunking id="9" string="played" type="VP">
          <tokens>
            <token id="12" string="played" />
          </tokens>
        </chunking>
        <chunking id="10" string="for which the Jackson car was stopped" type="SBAR">
          <tokens>
            <token id="20" string="for" />
            <token id="21" string="which" />
            <token id="22" string="the" />
            <token id="23" string="Jackson" />
            <token id="24" string="car" />
            <token id="25" string="was" />
            <token id="26" string="stopped" />
          </tokens>
        </chunking>
        <chunking id="11" string="the videotape was played" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="videotape" />
            <token id="11" string="was" />
            <token id="12" string="played" />
          </tokens>
        </chunking>
        <chunking id="12" string="testified that the alleged infraction for which the Jackson car was stopped -- crossing the center divider -- occurred before it could be seen on a tape shot from the NBC chase vehicle" type="VP">
          <tokens>
            <token id="15" string="testified" />
            <token id="16" string="that" />
            <token id="17" string="the" />
            <token id="18" string="alleged" />
            <token id="19" string="infraction" />
            <token id="20" string="for" />
            <token id="21" string="which" />
            <token id="22" string="the" />
            <token id="23" string="Jackson" />
            <token id="24" string="car" />
            <token id="25" string="was" />
            <token id="26" string="stopped" />
            <token id="27" string="--" />
            <token id="28" string="crossing" />
            <token id="29" string="the" />
            <token id="30" string="center" />
            <token id="31" string="divider" />
            <token id="32" string="--" />
            <token id="33" string="occurred" />
            <token id="34" string="before" />
            <token id="35" string="it" />
            <token id="36" string="could" />
            <token id="37" string="be" />
            <token id="38" string="seen" />
            <token id="39" string="on" />
            <token id="40" string="a" />
            <token id="41" string="tape" />
            <token id="42" string="shot" />
            <token id="43" string="from" />
            <token id="44" string="the" />
            <token id="45" string="NBC" />
            <token id="46" string="chase" />
            <token id="47" string="vehicle" />
          </tokens>
        </chunking>
        <chunking id="13" string="be seen on a tape shot from the NBC chase vehicle" type="VP">
          <tokens>
            <token id="37" string="be" />
            <token id="38" string="seen" />
            <token id="39" string="on" />
            <token id="40" string="a" />
            <token id="41" string="tape" />
            <token id="42" string="shot" />
            <token id="43" string="from" />
            <token id="44" string="the" />
            <token id="45" string="NBC" />
            <token id="46" string="chase" />
            <token id="47" string="vehicle" />
          </tokens>
        </chunking>
        <chunking id="14" string="the NBC chase vehicle" type="NP">
          <tokens>
            <token id="44" string="the" />
            <token id="45" string="NBC" />
            <token id="46" string="chase" />
            <token id="47" string="vehicle" />
          </tokens>
        </chunking>
        <chunking id="15" string="before it could be seen on a tape shot from the NBC chase vehicle" type="SBAR">
          <tokens>
            <token id="34" string="before" />
            <token id="35" string="it" />
            <token id="36" string="could" />
            <token id="37" string="be" />
            <token id="38" string="seen" />
            <token id="39" string="on" />
            <token id="40" string="a" />
            <token id="41" string="tape" />
            <token id="42" string="shot" />
            <token id="43" string="from" />
            <token id="44" string="the" />
            <token id="45" string="NBC" />
            <token id="46" string="chase" />
            <token id="47" string="vehicle" />
          </tokens>
        </chunking>
        <chunking id="16" string="the alleged infraction" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="alleged" />
            <token id="19" string="infraction" />
          </tokens>
        </chunking>
        <chunking id="17" string="the center divider" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="center" />
            <token id="31" string="divider" />
          </tokens>
        </chunking>
        <chunking id="18" string="Jackson 's" type="NP">
          <tokens>
            <token id="57" string="Jackson" />
            <token id="58" string="'s" />
          </tokens>
        </chunking>
        <chunking id="19" string="he" type="NP">
          <tokens>
            <token id="50" string="he" />
          </tokens>
        </chunking>
        <chunking id="20" string="Dickey" type="NP">
          <tokens>
            <token id="14" string="Dickey" />
          </tokens>
        </chunking>
        <chunking id="21" string="show Jackson 's car weaving slowly within the traffic lane" type="VP">
          <tokens>
            <token id="56" string="show" />
            <token id="57" string="Jackson" />
            <token id="58" string="'s" />
            <token id="59" string="car" />
            <token id="60" string="weaving" />
            <token id="61" string="slowly" />
            <token id="62" string="within" />
            <token id="63" string="the" />
            <token id="64" string="traffic" />
            <token id="65" string="lane" />
          </tokens>
        </chunking>
        <chunking id="22" string="Jackson 's car" type="NP">
          <tokens>
            <token id="57" string="Jackson" />
            <token id="58" string="'s" />
            <token id="59" string="car" />
          </tokens>
        </chunking>
        <chunking id="23" string="maintained that the tape does show Jackson 's car weaving slowly within the traffic lane" type="VP">
          <tokens>
            <token id="51" string="maintained" />
            <token id="52" string="that" />
            <token id="53" string="the" />
            <token id="54" string="tape" />
            <token id="55" string="does" />
            <token id="56" string="show" />
            <token id="57" string="Jackson" />
            <token id="58" string="'s" />
            <token id="59" string="car" />
            <token id="60" string="weaving" />
            <token id="61" string="slowly" />
            <token id="62" string="within" />
            <token id="63" string="the" />
            <token id="64" string="traffic" />
            <token id="65" string="lane" />
          </tokens>
        </chunking>
        <chunking id="24" string="seen on a tape shot from the NBC chase vehicle" type="VP">
          <tokens>
            <token id="38" string="seen" />
            <token id="39" string="on" />
            <token id="40" string="a" />
            <token id="41" string="tape" />
            <token id="42" string="shot" />
            <token id="43" string="from" />
            <token id="44" string="the" />
            <token id="45" string="NBC" />
            <token id="46" string="chase" />
            <token id="47" string="vehicle" />
          </tokens>
        </chunking>
        <chunking id="25" string="Jackson 's car weaving slowly within the traffic lane" type="NP">
          <tokens>
            <token id="57" string="Jackson" />
            <token id="58" string="'s" />
            <token id="59" string="car" />
            <token id="60" string="weaving" />
            <token id="61" string="slowly" />
            <token id="62" string="within" />
            <token id="63" string="the" />
            <token id="64" string="traffic" />
            <token id="65" string="lane" />
          </tokens>
        </chunking>
        <chunking id="26" string="that the alleged infraction for which the Jackson car was stopped -- crossing the center divider -- occurred before it could be seen on a tape shot from the NBC chase vehicle" type="SBAR">
          <tokens>
            <token id="16" string="that" />
            <token id="17" string="the" />
            <token id="18" string="alleged" />
            <token id="19" string="infraction" />
            <token id="20" string="for" />
            <token id="21" string="which" />
            <token id="22" string="the" />
            <token id="23" string="Jackson" />
            <token id="24" string="car" />
            <token id="25" string="was" />
            <token id="26" string="stopped" />
            <token id="27" string="--" />
            <token id="28" string="crossing" />
            <token id="29" string="the" />
            <token id="30" string="center" />
            <token id="31" string="divider" />
            <token id="32" string="--" />
            <token id="33" string="occurred" />
            <token id="34" string="before" />
            <token id="35" string="it" />
            <token id="36" string="could" />
            <token id="37" string="be" />
            <token id="38" string="seen" />
            <token id="39" string="on" />
            <token id="40" string="a" />
            <token id="41" string="tape" />
            <token id="42" string="shot" />
            <token id="43" string="from" />
            <token id="44" string="the" />
            <token id="45" string="NBC" />
            <token id="46" string="chase" />
            <token id="47" string="vehicle" />
          </tokens>
        </chunking>
        <chunking id="27" string="a tape shot" type="NP">
          <tokens>
            <token id="40" string="a" />
            <token id="41" string="tape" />
            <token id="42" string="shot" />
          </tokens>
        </chunking>
        <chunking id="28" string="the Jackson car" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="Jackson" />
            <token id="24" string="car" />
          </tokens>
        </chunking>
        <chunking id="29" string="the tape" type="NP">
          <tokens>
            <token id="53" string="the" />
            <token id="54" string="tape" />
          </tokens>
        </chunking>
        <chunking id="30" string="does show Jackson 's car weaving slowly within the traffic lane" type="VP">
          <tokens>
            <token id="55" string="does" />
            <token id="56" string="show" />
            <token id="57" string="Jackson" />
            <token id="58" string="'s" />
            <token id="59" string="car" />
            <token id="60" string="weaving" />
            <token id="61" string="slowly" />
            <token id="62" string="within" />
            <token id="63" string="the" />
            <token id="64" string="traffic" />
            <token id="65" string="lane" />
          </tokens>
        </chunking>
        <chunking id="31" string="occurred before it could be seen on a tape shot from the NBC chase vehicle" type="VP">
          <tokens>
            <token id="33" string="occurred" />
            <token id="34" string="before" />
            <token id="35" string="it" />
            <token id="36" string="could" />
            <token id="37" string="be" />
            <token id="38" string="seen" />
            <token id="39" string="on" />
            <token id="40" string="a" />
            <token id="41" string="tape" />
            <token id="42" string="shot" />
            <token id="43" string="from" />
            <token id="44" string="the" />
            <token id="45" string="NBC" />
            <token id="46" string="chase" />
            <token id="47" string="vehicle" />
          </tokens>
        </chunking>
        <chunking id="32" string="was played" type="SBAR">
          <tokens>
            <token id="11" string="was" />
            <token id="12" string="played" />
          </tokens>
        </chunking>
        <chunking id="33" string="could be seen on a tape shot from the NBC chase vehicle" type="VP">
          <tokens>
            <token id="36" string="could" />
            <token id="37" string="be" />
            <token id="38" string="seen" />
            <token id="39" string="on" />
            <token id="40" string="a" />
            <token id="41" string="tape" />
            <token id="42" string="shot" />
            <token id="43" string="from" />
            <token id="44" string="the" />
            <token id="45" string="NBC" />
            <token id="46" string="chase" />
            <token id="47" string="vehicle" />
          </tokens>
        </chunking>
        <chunking id="34" string="questioning by Boatwright and as the videotape was played" type="VP">
          <tokens>
            <token id="4" string="questioning" />
            <token id="5" string="by" />
            <token id="6" string="Boatwright" />
            <token id="7" string="and" />
            <token id="8" string="as" />
            <token id="9" string="the" />
            <token id="10" string="videotape" />
            <token id="11" string="was" />
            <token id="12" string="played" />
          </tokens>
        </chunking>
        <chunking id="35" string="the videotape" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="videotape" />
          </tokens>
        </chunking>
        <chunking id="36" string="the alleged infraction for which the Jackson car was stopped -- crossing the center divider --" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="alleged" />
            <token id="19" string="infraction" />
            <token id="20" string="for" />
            <token id="21" string="which" />
            <token id="22" string="the" />
            <token id="23" string="Jackson" />
            <token id="24" string="car" />
            <token id="25" string="was" />
            <token id="26" string="stopped" />
            <token id="27" string="--" />
            <token id="28" string="crossing" />
            <token id="29" string="the" />
            <token id="30" string="center" />
            <token id="31" string="divider" />
            <token id="32" string="--" />
          </tokens>
        </chunking>
        <chunking id="37" string="weaving slowly within the traffic lane" type="VP">
          <tokens>
            <token id="60" string="weaving" />
            <token id="61" string="slowly" />
            <token id="62" string="within" />
            <token id="63" string="the" />
            <token id="64" string="traffic" />
            <token id="65" string="lane" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="15">testified</governor>
          <dependent id="1">Earlier</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="4">questioning</governor>
          <dependent id="3">under</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">questioning</governor>
          <dependent id="4">questioning</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="15">testified</governor>
          <dependent id="4">questioning</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">Boatwright</governor>
          <dependent id="5">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">questioning</governor>
          <dependent id="6">Boatwright</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">questioning</governor>
          <dependent id="7">and</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">videotape</governor>
          <dependent id="8">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">videotape</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">questioning</governor>
          <dependent id="10">videotape</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="12">played</governor>
          <dependent id="11">was</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="10">videotape</governor>
          <dependent id="12">played</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">testified</governor>
          <dependent id="14">Dickey</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">testified</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="33">occurred</governor>
          <dependent id="16">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">infraction</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">infraction</governor>
          <dependent id="18">alleged</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="33">occurred</governor>
          <dependent id="19">infraction</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">which</governor>
          <dependent id="20">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">stopped</governor>
          <dependent id="21">which</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">car</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">car</governor>
          <dependent id="23">Jackson</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="26">stopped</governor>
          <dependent id="24">car</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="26">stopped</governor>
          <dependent id="25">was</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="19">infraction</governor>
          <dependent id="26">stopped</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="19">infraction</governor>
          <dependent id="28">crossing</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">divider</governor>
          <dependent id="29">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">divider</governor>
          <dependent id="30">center</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="28">crossing</governor>
          <dependent id="31">divider</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="15">testified</governor>
          <dependent id="33">occurred</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="38">seen</governor>
          <dependent id="34">before</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="38">seen</governor>
          <dependent id="35">it</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="38">seen</governor>
          <dependent id="36">could</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="38">seen</governor>
          <dependent id="37">be</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="33">occurred</governor>
          <dependent id="38">seen</dependent>
        </dependency>
        <dependency type="case">
          <governor id="42">shot</governor>
          <dependent id="39">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="42">shot</governor>
          <dependent id="40">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="42">shot</governor>
          <dependent id="41">tape</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="38">seen</governor>
          <dependent id="42">shot</dependent>
        </dependency>
        <dependency type="case">
          <governor id="47">vehicle</governor>
          <dependent id="43">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="47">vehicle</governor>
          <dependent id="44">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="47">vehicle</governor>
          <dependent id="45">NBC</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="47">vehicle</governor>
          <dependent id="46">chase</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="38">seen</governor>
          <dependent id="47">vehicle</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="15">testified</governor>
          <dependent id="49">but</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="51">maintained</governor>
          <dependent id="50">he</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="15">testified</governor>
          <dependent id="51">maintained</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="56">show</governor>
          <dependent id="52">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="54">tape</governor>
          <dependent id="53">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="56">show</governor>
          <dependent id="54">tape</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="56">show</governor>
          <dependent id="55">does</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="51">maintained</governor>
          <dependent id="56">show</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="59">car</governor>
          <dependent id="57">Jackson</dependent>
        </dependency>
        <dependency type="case">
          <governor id="57">Jackson</governor>
          <dependent id="58">'s</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="56">show</governor>
          <dependent id="59">car</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="59">car</governor>
          <dependent id="60">weaving</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="60">weaving</governor>
          <dependent id="61">slowly</dependent>
        </dependency>
        <dependency type="case">
          <governor id="65">lane</governor>
          <dependent id="62">within</dependent>
        </dependency>
        <dependency type="det">
          <governor id="65">lane</governor>
          <dependent id="63">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="65">lane</governor>
          <dependent id="64">traffic</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="60">weaving</governor>
          <dependent id="65">lane</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Jackson" type="PERSON" score="0.0">
          <tokens>
            <token id="23" string="Jackson" />
          </tokens>
        </entity>
        <entity id="2" string="Boatwright" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Boatwright" />
          </tokens>
        </entity>
        <entity id="3" string="Dickey" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Dickey" />
          </tokens>
        </entity>
        <entity id="4" string="NBC" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="45" string="NBC" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="21" has_coreference="true">
      <content>Boatwright, standing in front of the television monitor, pointed out that a videotape shot from the Jackson car&amp;apost;s rear window shows the street lights passing by in a consistent pattern -- indicating the car was not weaving.</content>
      <tokens>
        <token id="1" string="Boatwright" lemma="Boatwright" stem="boatwright" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="standing" lemma="stand" stem="stand" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="front" lemma="front" stem="front" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="television" lemma="television" stem="televis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="monitor" lemma="monitor" stem="monitor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="pointed" lemma="point" stem="point" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="videotape" lemma="videotape" stem="videotap" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="shot" lemma="shot" stem="shot" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="19" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="20" string="car" lemma="car" stem="car" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="21" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="22" string="rear" lemma="rear" stem="rear" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="window" lemma="window" stem="window" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="shows" lemma="show" stem="show" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="street" lemma="street" stem="street" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="lights" lemma="light" stem="light" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="passing" lemma="pass" stem="pass" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="consistent" lemma="consistent" stem="consist" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="pattern" lemma="pattern" stem="pattern" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="indicating" lemma="indicate" stem="indic" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="37" string="car" lemma="car" stem="car" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="38" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="weaving" lemma="weave" stem="weav" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Boatwright)) (, ,) (S (VP (VBG standing) (PP (IN in) (NP (NP (NN front)) (PP (IN of) (NP (DT the) (NN television) (NN monitor))))))) (, ,) (VP (VBD pointed) (PRT (RP out)) (SBAR (IN that) (S (NP (NP (DT a) (NN videotape) (NN shot)) (PP (IN from) (NP (NP (DT the) (NNP Jackson) (NN car) (POS 's)) (NN rear) (NN window)))) (VP (VBZ shows) (S (NP (DT the) (NN street) (NNS lights)) (VP (VBG passing) (PP (IN by) (PP (IN in) (NP (DT a) (JJ consistent) (NN pattern)))))) (: --) (S (VP (VBG indicating) (SBAR (S (NP (DT the) (NN car)) (VP (VBD was) (RB not) (VP (VBG weaving))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="shows the street lights passing by in a consistent pattern -- indicating the car was not weaving" type="VP">
          <tokens>
            <token id="24" string="shows" />
            <token id="25" string="the" />
            <token id="26" string="street" />
            <token id="27" string="lights" />
            <token id="28" string="passing" />
            <token id="29" string="by" />
            <token id="30" string="in" />
            <token id="31" string="a" />
            <token id="32" string="consistent" />
            <token id="33" string="pattern" />
            <token id="34" string="--" />
            <token id="35" string="indicating" />
            <token id="36" string="the" />
            <token id="37" string="car" />
            <token id="38" string="was" />
            <token id="39" string="not" />
            <token id="40" string="weaving" />
          </tokens>
        </chunking>
        <chunking id="2" string="standing in front of the television monitor" type="VP">
          <tokens>
            <token id="3" string="standing" />
            <token id="4" string="in" />
            <token id="5" string="front" />
            <token id="6" string="of" />
            <token id="7" string="the" />
            <token id="8" string="television" />
            <token id="9" string="monitor" />
          </tokens>
        </chunking>
        <chunking id="3" string="the Jackson car 's rear window" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="Jackson" />
            <token id="20" string="car" />
            <token id="21" string="'s" />
            <token id="22" string="rear" />
            <token id="23" string="window" />
          </tokens>
        </chunking>
        <chunking id="4" string="the street lights" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="street" />
            <token id="27" string="lights" />
          </tokens>
        </chunking>
        <chunking id="5" string="the car was not weaving" type="SBAR">
          <tokens>
            <token id="36" string="the" />
            <token id="37" string="car" />
            <token id="38" string="was" />
            <token id="39" string="not" />
            <token id="40" string="weaving" />
          </tokens>
        </chunking>
        <chunking id="6" string="a consistent pattern" type="NP">
          <tokens>
            <token id="31" string="a" />
            <token id="32" string="consistent" />
            <token id="33" string="pattern" />
          </tokens>
        </chunking>
        <chunking id="7" string="front of the television monitor" type="NP">
          <tokens>
            <token id="5" string="front" />
            <token id="6" string="of" />
            <token id="7" string="the" />
            <token id="8" string="television" />
            <token id="9" string="monitor" />
          </tokens>
        </chunking>
        <chunking id="8" string="Boatwright" type="NP">
          <tokens>
            <token id="1" string="Boatwright" />
          </tokens>
        </chunking>
        <chunking id="9" string="the car" type="NP">
          <tokens>
            <token id="36" string="the" />
            <token id="37" string="car" />
          </tokens>
        </chunking>
        <chunking id="10" string="pointed out that a videotape shot from the Jackson car 's rear window shows the street lights passing by in a consistent pattern -- indicating the car was not weaving" type="VP">
          <tokens>
            <token id="11" string="pointed" />
            <token id="12" string="out" />
            <token id="13" string="that" />
            <token id="14" string="a" />
            <token id="15" string="videotape" />
            <token id="16" string="shot" />
            <token id="17" string="from" />
            <token id="18" string="the" />
            <token id="19" string="Jackson" />
            <token id="20" string="car" />
            <token id="21" string="'s" />
            <token id="22" string="rear" />
            <token id="23" string="window" />
            <token id="24" string="shows" />
            <token id="25" string="the" />
            <token id="26" string="street" />
            <token id="27" string="lights" />
            <token id="28" string="passing" />
            <token id="29" string="by" />
            <token id="30" string="in" />
            <token id="31" string="a" />
            <token id="32" string="consistent" />
            <token id="33" string="pattern" />
            <token id="34" string="--" />
            <token id="35" string="indicating" />
            <token id="36" string="the" />
            <token id="37" string="car" />
            <token id="38" string="was" />
            <token id="39" string="not" />
            <token id="40" string="weaving" />
          </tokens>
        </chunking>
        <chunking id="11" string="was not weaving" type="VP">
          <tokens>
            <token id="38" string="was" />
            <token id="39" string="not" />
            <token id="40" string="weaving" />
          </tokens>
        </chunking>
        <chunking id="12" string="weaving" type="VP">
          <tokens>
            <token id="40" string="weaving" />
          </tokens>
        </chunking>
        <chunking id="13" string="passing by in a consistent pattern" type="VP">
          <tokens>
            <token id="28" string="passing" />
            <token id="29" string="by" />
            <token id="30" string="in" />
            <token id="31" string="a" />
            <token id="32" string="consistent" />
            <token id="33" string="pattern" />
          </tokens>
        </chunking>
        <chunking id="14" string="that a videotape shot from the Jackson car 's rear window shows the street lights passing by in a consistent pattern -- indicating the car was not weaving" type="SBAR">
          <tokens>
            <token id="13" string="that" />
            <token id="14" string="a" />
            <token id="15" string="videotape" />
            <token id="16" string="shot" />
            <token id="17" string="from" />
            <token id="18" string="the" />
            <token id="19" string="Jackson" />
            <token id="20" string="car" />
            <token id="21" string="'s" />
            <token id="22" string="rear" />
            <token id="23" string="window" />
            <token id="24" string="shows" />
            <token id="25" string="the" />
            <token id="26" string="street" />
            <token id="27" string="lights" />
            <token id="28" string="passing" />
            <token id="29" string="by" />
            <token id="30" string="in" />
            <token id="31" string="a" />
            <token id="32" string="consistent" />
            <token id="33" string="pattern" />
            <token id="34" string="--" />
            <token id="35" string="indicating" />
            <token id="36" string="the" />
            <token id="37" string="car" />
            <token id="38" string="was" />
            <token id="39" string="not" />
            <token id="40" string="weaving" />
          </tokens>
        </chunking>
        <chunking id="15" string="a videotape shot" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="videotape" />
            <token id="16" string="shot" />
          </tokens>
        </chunking>
        <chunking id="16" string="front" type="NP">
          <tokens>
            <token id="5" string="front" />
          </tokens>
        </chunking>
        <chunking id="17" string="a videotape shot from the Jackson car 's rear window" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="videotape" />
            <token id="16" string="shot" />
            <token id="17" string="from" />
            <token id="18" string="the" />
            <token id="19" string="Jackson" />
            <token id="20" string="car" />
            <token id="21" string="'s" />
            <token id="22" string="rear" />
            <token id="23" string="window" />
          </tokens>
        </chunking>
        <chunking id="18" string="the Jackson car 's" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="Jackson" />
            <token id="20" string="car" />
            <token id="21" string="'s" />
          </tokens>
        </chunking>
        <chunking id="19" string="indicating the car was not weaving" type="VP">
          <tokens>
            <token id="35" string="indicating" />
            <token id="36" string="the" />
            <token id="37" string="car" />
            <token id="38" string="was" />
            <token id="39" string="not" />
            <token id="40" string="weaving" />
          </tokens>
        </chunking>
        <chunking id="20" string="the television monitor" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="television" />
            <token id="9" string="monitor" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="11">pointed</governor>
          <dependent id="1">Boatwright</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="11">pointed</governor>
          <dependent id="3">standing</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">monitor</governor>
          <dependent id="4">in</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="4">in</governor>
          <dependent id="5">front</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="4">in</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">monitor</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">monitor</governor>
          <dependent id="8">television</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">standing</governor>
          <dependent id="9">monitor</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">pointed</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="11">pointed</governor>
          <dependent id="12">out</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="24">shows</governor>
          <dependent id="13">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">shot</governor>
          <dependent id="14">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">shot</governor>
          <dependent id="15">videotape</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">shows</governor>
          <dependent id="16">shot</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">window</governor>
          <dependent id="17">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">car</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">car</governor>
          <dependent id="19">Jackson</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="23">window</governor>
          <dependent id="20">car</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">car</governor>
          <dependent id="21">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">window</governor>
          <dependent id="22">rear</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">shot</governor>
          <dependent id="23">window</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">pointed</governor>
          <dependent id="24">shows</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">lights</governor>
          <dependent id="25">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">lights</governor>
          <dependent id="26">street</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="28">passing</governor>
          <dependent id="27">lights</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="24">shows</governor>
          <dependent id="28">passing</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">pattern</governor>
          <dependent id="29">by</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">pattern</governor>
          <dependent id="30">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="33">pattern</governor>
          <dependent id="31">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="33">pattern</governor>
          <dependent id="32">consistent</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">passing</governor>
          <dependent id="33">pattern</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="24">shows</governor>
          <dependent id="35">indicating</dependent>
        </dependency>
        <dependency type="det">
          <governor id="37">car</governor>
          <dependent id="36">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="40">weaving</governor>
          <dependent id="37">car</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="40">weaving</governor>
          <dependent id="38">was</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="40">weaving</governor>
          <dependent id="39">not</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="35">indicating</governor>
          <dependent id="40">weaving</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Jackson" type="PERSON" score="0.0">
          <tokens>
            <token id="19" string="Jackson" />
          </tokens>
        </entity>
        <entity id="2" string="Boatwright" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Boatwright" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="22" has_coreference="true">
      <content>Dickey acknowledged that the police car he was driving &amp;quot;was weaving all over, too&amp;quot; as it tailed Jackson&amp;apost;s car.</content>
      <tokens>
        <token id="1" string="Dickey" lemma="Dickey" stem="dickei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="acknowledged" lemma="acknowledge" stem="acknowledg" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="car" lemma="car" stem="car" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="8" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="driving" lemma="drive" stem="drive" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="weaving" lemma="weave" stem="weav" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="over" lemma="over" stem="over" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="too" lemma="too" stem="too" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="tailed" lemma="tail" stem="tail" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="22" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="car" lemma="car" stem="car" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Dickey)) (VP (VBD acknowledged) (SBAR (IN that) (S (NP (NP (DT the) (NN police) (NN car)) (SBAR (S (NP (PRP he)) (VP (VBD was) (VP (VBG driving)))))) (`` ``) (VP (VBD was) (VP (VBG weaving) (ADVP (DT all) (RB over)) (, ,) (ADVP (RB too)) ('' '') (SBAR (IN as) (S (NP (PRP it)) (VP (VBD tailed) (NP (NP (NNP Jackson) (POS 's)) (NN car)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="was weaving all over , too '' as it tailed Jackson 's car" type="VP">
          <tokens>
            <token id="11" string="was" />
            <token id="12" string="weaving" />
            <token id="13" string="all" />
            <token id="14" string="over" />
            <token id="15" string="," />
            <token id="16" string="too" />
            <token id="17" string="&quot;" />
            <token id="18" string="as" />
            <token id="19" string="it" />
            <token id="20" string="tailed" />
            <token id="21" string="Jackson" />
            <token id="22" string="'s" />
            <token id="23" string="car" />
          </tokens>
        </chunking>
        <chunking id="2" string="Jackson 's car" type="NP">
          <tokens>
            <token id="21" string="Jackson" />
            <token id="22" string="'s" />
            <token id="23" string="car" />
          </tokens>
        </chunking>
        <chunking id="3" string="the police car he was driving" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="police" />
            <token id="6" string="car" />
            <token id="7" string="he" />
            <token id="8" string="was" />
            <token id="9" string="driving" />
          </tokens>
        </chunking>
        <chunking id="4" string="it" type="NP">
          <tokens>
            <token id="19" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="acknowledged that the police car he was driving `` was weaving all over , too '' as it tailed Jackson 's car" type="VP">
          <tokens>
            <token id="2" string="acknowledged" />
            <token id="3" string="that" />
            <token id="4" string="the" />
            <token id="5" string="police" />
            <token id="6" string="car" />
            <token id="7" string="he" />
            <token id="8" string="was" />
            <token id="9" string="driving" />
            <token id="10" string="&quot;" />
            <token id="11" string="was" />
            <token id="12" string="weaving" />
            <token id="13" string="all" />
            <token id="14" string="over" />
            <token id="15" string="," />
            <token id="16" string="too" />
            <token id="17" string="&quot;" />
            <token id="18" string="as" />
            <token id="19" string="it" />
            <token id="20" string="tailed" />
            <token id="21" string="Jackson" />
            <token id="22" string="'s" />
            <token id="23" string="car" />
          </tokens>
        </chunking>
        <chunking id="6" string="the police car" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="police" />
            <token id="6" string="car" />
          </tokens>
        </chunking>
        <chunking id="7" string="driving" type="VP">
          <tokens>
            <token id="9" string="driving" />
          </tokens>
        </chunking>
        <chunking id="8" string="he was driving" type="SBAR">
          <tokens>
            <token id="7" string="he" />
            <token id="8" string="was" />
            <token id="9" string="driving" />
          </tokens>
        </chunking>
        <chunking id="9" string="was driving" type="VP">
          <tokens>
            <token id="8" string="was" />
            <token id="9" string="driving" />
          </tokens>
        </chunking>
        <chunking id="10" string="weaving all over , too '' as it tailed Jackson 's car" type="VP">
          <tokens>
            <token id="12" string="weaving" />
            <token id="13" string="all" />
            <token id="14" string="over" />
            <token id="15" string="," />
            <token id="16" string="too" />
            <token id="17" string="&quot;" />
            <token id="18" string="as" />
            <token id="19" string="it" />
            <token id="20" string="tailed" />
            <token id="21" string="Jackson" />
            <token id="22" string="'s" />
            <token id="23" string="car" />
          </tokens>
        </chunking>
        <chunking id="11" string="that the police car he was driving `` was weaving all over , too '' as it tailed Jackson 's car" type="SBAR">
          <tokens>
            <token id="3" string="that" />
            <token id="4" string="the" />
            <token id="5" string="police" />
            <token id="6" string="car" />
            <token id="7" string="he" />
            <token id="8" string="was" />
            <token id="9" string="driving" />
            <token id="10" string="&quot;" />
            <token id="11" string="was" />
            <token id="12" string="weaving" />
            <token id="13" string="all" />
            <token id="14" string="over" />
            <token id="15" string="," />
            <token id="16" string="too" />
            <token id="17" string="&quot;" />
            <token id="18" string="as" />
            <token id="19" string="it" />
            <token id="20" string="tailed" />
            <token id="21" string="Jackson" />
            <token id="22" string="'s" />
            <token id="23" string="car" />
          </tokens>
        </chunking>
        <chunking id="12" string="as it tailed Jackson 's car" type="SBAR">
          <tokens>
            <token id="18" string="as" />
            <token id="19" string="it" />
            <token id="20" string="tailed" />
            <token id="21" string="Jackson" />
            <token id="22" string="'s" />
            <token id="23" string="car" />
          </tokens>
        </chunking>
        <chunking id="13" string="tailed Jackson 's car" type="VP">
          <tokens>
            <token id="20" string="tailed" />
            <token id="21" string="Jackson" />
            <token id="22" string="'s" />
            <token id="23" string="car" />
          </tokens>
        </chunking>
        <chunking id="14" string="Jackson 's" type="NP">
          <tokens>
            <token id="21" string="Jackson" />
            <token id="22" string="'s" />
          </tokens>
        </chunking>
        <chunking id="15" string="he" type="NP">
          <tokens>
            <token id="7" string="he" />
          </tokens>
        </chunking>
        <chunking id="16" string="Dickey" type="NP">
          <tokens>
            <token id="1" string="Dickey" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">acknowledged</governor>
          <dependent id="1">Dickey</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">acknowledged</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">weaving</governor>
          <dependent id="3">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">car</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">car</governor>
          <dependent id="5">police</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">weaving</governor>
          <dependent id="6">car</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">driving</governor>
          <dependent id="7">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">driving</governor>
          <dependent id="8">was</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="6">car</governor>
          <dependent id="9">driving</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">weaving</governor>
          <dependent id="11">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">acknowledged</governor>
          <dependent id="12">weaving</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="14">over</governor>
          <dependent id="13">all</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">weaving</governor>
          <dependent id="14">over</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">weaving</governor>
          <dependent id="16">too</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="20">tailed</governor>
          <dependent id="18">as</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">tailed</governor>
          <dependent id="19">it</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="12">weaving</governor>
          <dependent id="20">tailed</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="23">car</governor>
          <dependent id="21">Jackson</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">Jackson</governor>
          <dependent id="22">'s</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">tailed</governor>
          <dependent id="23">car</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Jackson" type="PERSON" score="0.0">
          <tokens>
            <token id="21" string="Jackson" />
          </tokens>
        </entity>
        <entity id="2" string="Dickey" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Dickey" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="23" has_coreference="true">
      <content>Jackson, also testifying under subpoena, said that he and Jeff Hill, an off-duty federal corrections officer who drove the car, took great care not to break traffic laws when they cruised along Pacific Coast Highway in Long Beach.</content>
      <tokens>
        <token id="1" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="testifying" lemma="testify" stem="testifi" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="under" lemma="under" stem="under" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="subpoena" lemma="subpoena" stem="subpoena" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="Jeff" lemma="Jeff" stem="jeff" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="13" string="Hill" lemma="Hill" stem="hill" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="off-duty" lemma="off-duty" stem="off-duti" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="federal" lemma="federal" stem="feder" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="corrections" lemma="correction" stem="correct" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="officer" lemma="officer" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="drove" lemma="drive" stem="drove" pos="VBD" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="23" string="car" lemma="car" stem="car" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="took" lemma="take" stem="took" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="great" lemma="great" stem="great" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="care" lemma="care" stem="care" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="break" lemma="break" stem="break" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="traffic" lemma="traffic" stem="traffic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="laws" lemma="law" stem="law" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="cruised" lemma="cruise" stem="cruis" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="along" lemma="along" stem="along" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="Pacific" lemma="Pacific" stem="pacif" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="38" string="Coast" lemma="Coast" stem="coast" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="39" string="Highway" lemma="Highway" stem="highwai" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="40" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="Long" lemma="Long" stem="long" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="42" string="Beach" lemma="Beach" stem="beach" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="43" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Jackson)) (, ,) (VP (ADVP (RB also)) (VBG testifying) (PP (IN under) (NP (NN subpoena)))) (, ,)) (VP (VBD said) (SBAR (IN that) (S (NP (NP (NP (PRP he)) (CC and) (NP (NNP Jeff) (NNP Hill))) (, ,) (NP (NP (DT an) (JJ off-duty) (JJ federal) (NNS corrections) (NN officer)) (SBAR (WHNP (WP who)) (S (VP (VBD drove) (NP (DT the) (NN car)))))) (, ,)) (VP (VBD took) (NP (JJ great) (NN care)) (S (RB not) (VP (TO to) (VP (VB break) (NP (NN traffic) (NNS laws)) (SBAR (WHADVP (WRB when)) (S (NP (PRP they)) (VP (VBD cruised) (PP (IN along) (NP (NP (NNP Pacific) (NNP Coast) (NNP Highway)) (PP (IN in) (NP (NNP Long) (NNP Beach))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="also testifying under subpoena" type="VP">
          <tokens>
            <token id="3" string="also" />
            <token id="4" string="testifying" />
            <token id="5" string="under" />
            <token id="6" string="subpoena" />
          </tokens>
        </chunking>
        <chunking id="2" string="Jackson , also testifying under subpoena ," type="NP">
          <tokens>
            <token id="1" string="Jackson" />
            <token id="2" string="," />
            <token id="3" string="also" />
            <token id="4" string="testifying" />
            <token id="5" string="under" />
            <token id="6" string="subpoena" />
            <token id="7" string="," />
          </tokens>
        </chunking>
        <chunking id="3" string="break traffic laws when they cruised along Pacific Coast Highway in Long Beach" type="VP">
          <tokens>
            <token id="30" string="break" />
            <token id="31" string="traffic" />
            <token id="32" string="laws" />
            <token id="33" string="when" />
            <token id="34" string="they" />
            <token id="35" string="cruised" />
            <token id="36" string="along" />
            <token id="37" string="Pacific" />
            <token id="38" string="Coast" />
            <token id="39" string="Highway" />
            <token id="40" string="in" />
            <token id="41" string="Long" />
            <token id="42" string="Beach" />
          </tokens>
        </chunking>
        <chunking id="4" string="that he and Jeff Hill , an off-duty federal corrections officer who drove the car , took great care not to break traffic laws when they cruised along Pacific Coast Highway in Long Beach" type="SBAR">
          <tokens>
            <token id="9" string="that" />
            <token id="10" string="he" />
            <token id="11" string="and" />
            <token id="12" string="Jeff" />
            <token id="13" string="Hill" />
            <token id="14" string="," />
            <token id="15" string="an" />
            <token id="16" string="off-duty" />
            <token id="17" string="federal" />
            <token id="18" string="corrections" />
            <token id="19" string="officer" />
            <token id="20" string="who" />
            <token id="21" string="drove" />
            <token id="22" string="the" />
            <token id="23" string="car" />
            <token id="24" string="," />
            <token id="25" string="took" />
            <token id="26" string="great" />
            <token id="27" string="care" />
            <token id="28" string="not" />
            <token id="29" string="to" />
            <token id="30" string="break" />
            <token id="31" string="traffic" />
            <token id="32" string="laws" />
            <token id="33" string="when" />
            <token id="34" string="they" />
            <token id="35" string="cruised" />
            <token id="36" string="along" />
            <token id="37" string="Pacific" />
            <token id="38" string="Coast" />
            <token id="39" string="Highway" />
            <token id="40" string="in" />
            <token id="41" string="Long" />
            <token id="42" string="Beach" />
          </tokens>
        </chunking>
        <chunking id="5" string="traffic laws" type="NP">
          <tokens>
            <token id="31" string="traffic" />
            <token id="32" string="laws" />
          </tokens>
        </chunking>
        <chunking id="6" string="cruised along Pacific Coast Highway in Long Beach" type="VP">
          <tokens>
            <token id="35" string="cruised" />
            <token id="36" string="along" />
            <token id="37" string="Pacific" />
            <token id="38" string="Coast" />
            <token id="39" string="Highway" />
            <token id="40" string="in" />
            <token id="41" string="Long" />
            <token id="42" string="Beach" />
          </tokens>
        </chunking>
        <chunking id="7" string="when they cruised along Pacific Coast Highway in Long Beach" type="SBAR">
          <tokens>
            <token id="33" string="when" />
            <token id="34" string="they" />
            <token id="35" string="cruised" />
            <token id="36" string="along" />
            <token id="37" string="Pacific" />
            <token id="38" string="Coast" />
            <token id="39" string="Highway" />
            <token id="40" string="in" />
            <token id="41" string="Long" />
            <token id="42" string="Beach" />
          </tokens>
        </chunking>
        <chunking id="8" string="Long Beach" type="NP">
          <tokens>
            <token id="41" string="Long" />
            <token id="42" string="Beach" />
          </tokens>
        </chunking>
        <chunking id="9" string="an off-duty federal corrections officer" type="NP">
          <tokens>
            <token id="15" string="an" />
            <token id="16" string="off-duty" />
            <token id="17" string="federal" />
            <token id="18" string="corrections" />
            <token id="19" string="officer" />
          </tokens>
        </chunking>
        <chunking id="10" string="he" type="NP">
          <tokens>
            <token id="10" string="he" />
          </tokens>
        </chunking>
        <chunking id="11" string="took great care not to break traffic laws when they cruised along Pacific Coast Highway in Long Beach" type="VP">
          <tokens>
            <token id="25" string="took" />
            <token id="26" string="great" />
            <token id="27" string="care" />
            <token id="28" string="not" />
            <token id="29" string="to" />
            <token id="30" string="break" />
            <token id="31" string="traffic" />
            <token id="32" string="laws" />
            <token id="33" string="when" />
            <token id="34" string="they" />
            <token id="35" string="cruised" />
            <token id="36" string="along" />
            <token id="37" string="Pacific" />
            <token id="38" string="Coast" />
            <token id="39" string="Highway" />
            <token id="40" string="in" />
            <token id="41" string="Long" />
            <token id="42" string="Beach" />
          </tokens>
        </chunking>
        <chunking id="12" string="great care" type="NP">
          <tokens>
            <token id="26" string="great" />
            <token id="27" string="care" />
          </tokens>
        </chunking>
        <chunking id="13" string="who drove the car" type="SBAR">
          <tokens>
            <token id="20" string="who" />
            <token id="21" string="drove" />
            <token id="22" string="the" />
            <token id="23" string="car" />
          </tokens>
        </chunking>
        <chunking id="14" string="subpoena" type="NP">
          <tokens>
            <token id="6" string="subpoena" />
          </tokens>
        </chunking>
        <chunking id="15" string="he and Jeff Hill" type="NP">
          <tokens>
            <token id="10" string="he" />
            <token id="11" string="and" />
            <token id="12" string="Jeff" />
            <token id="13" string="Hill" />
          </tokens>
        </chunking>
        <chunking id="16" string="Jeff Hill" type="NP">
          <tokens>
            <token id="12" string="Jeff" />
            <token id="13" string="Hill" />
          </tokens>
        </chunking>
        <chunking id="17" string="drove the car" type="VP">
          <tokens>
            <token id="21" string="drove" />
            <token id="22" string="the" />
            <token id="23" string="car" />
          </tokens>
        </chunking>
        <chunking id="18" string="Pacific Coast Highway in Long Beach" type="NP">
          <tokens>
            <token id="37" string="Pacific" />
            <token id="38" string="Coast" />
            <token id="39" string="Highway" />
            <token id="40" string="in" />
            <token id="41" string="Long" />
            <token id="42" string="Beach" />
          </tokens>
        </chunking>
        <chunking id="19" string="Jackson" type="NP">
          <tokens>
            <token id="1" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="20" string="to break traffic laws when they cruised along Pacific Coast Highway in Long Beach" type="VP">
          <tokens>
            <token id="29" string="to" />
            <token id="30" string="break" />
            <token id="31" string="traffic" />
            <token id="32" string="laws" />
            <token id="33" string="when" />
            <token id="34" string="they" />
            <token id="35" string="cruised" />
            <token id="36" string="along" />
            <token id="37" string="Pacific" />
            <token id="38" string="Coast" />
            <token id="39" string="Highway" />
            <token id="40" string="in" />
            <token id="41" string="Long" />
            <token id="42" string="Beach" />
          </tokens>
        </chunking>
        <chunking id="21" string="he and Jeff Hill , an off-duty federal corrections officer who drove the car ," type="NP">
          <tokens>
            <token id="10" string="he" />
            <token id="11" string="and" />
            <token id="12" string="Jeff" />
            <token id="13" string="Hill" />
            <token id="14" string="," />
            <token id="15" string="an" />
            <token id="16" string="off-duty" />
            <token id="17" string="federal" />
            <token id="18" string="corrections" />
            <token id="19" string="officer" />
            <token id="20" string="who" />
            <token id="21" string="drove" />
            <token id="22" string="the" />
            <token id="23" string="car" />
            <token id="24" string="," />
          </tokens>
        </chunking>
        <chunking id="22" string="the car" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="car" />
          </tokens>
        </chunking>
        <chunking id="23" string="when" type="WHADVP">
          <tokens>
            <token id="33" string="when" />
          </tokens>
        </chunking>
        <chunking id="24" string="they" type="NP">
          <tokens>
            <token id="34" string="they" />
          </tokens>
        </chunking>
        <chunking id="25" string="Pacific Coast Highway" type="NP">
          <tokens>
            <token id="37" string="Pacific" />
            <token id="38" string="Coast" />
            <token id="39" string="Highway" />
          </tokens>
        </chunking>
        <chunking id="26" string="an off-duty federal corrections officer who drove the car" type="NP">
          <tokens>
            <token id="15" string="an" />
            <token id="16" string="off-duty" />
            <token id="17" string="federal" />
            <token id="18" string="corrections" />
            <token id="19" string="officer" />
            <token id="20" string="who" />
            <token id="21" string="drove" />
            <token id="22" string="the" />
            <token id="23" string="car" />
          </tokens>
        </chunking>
        <chunking id="27" string="said that he and Jeff Hill , an off-duty federal corrections officer who drove the car , took great care not to break traffic laws when they cruised along Pacific Coast Highway in Long Beach" type="VP">
          <tokens>
            <token id="8" string="said" />
            <token id="9" string="that" />
            <token id="10" string="he" />
            <token id="11" string="and" />
            <token id="12" string="Jeff" />
            <token id="13" string="Hill" />
            <token id="14" string="," />
            <token id="15" string="an" />
            <token id="16" string="off-duty" />
            <token id="17" string="federal" />
            <token id="18" string="corrections" />
            <token id="19" string="officer" />
            <token id="20" string="who" />
            <token id="21" string="drove" />
            <token id="22" string="the" />
            <token id="23" string="car" />
            <token id="24" string="," />
            <token id="25" string="took" />
            <token id="26" string="great" />
            <token id="27" string="care" />
            <token id="28" string="not" />
            <token id="29" string="to" />
            <token id="30" string="break" />
            <token id="31" string="traffic" />
            <token id="32" string="laws" />
            <token id="33" string="when" />
            <token id="34" string="they" />
            <token id="35" string="cruised" />
            <token id="36" string="along" />
            <token id="37" string="Pacific" />
            <token id="38" string="Coast" />
            <token id="39" string="Highway" />
            <token id="40" string="in" />
            <token id="41" string="Long" />
            <token id="42" string="Beach" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="8">said</governor>
          <dependent id="1">Jackson</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">testifying</governor>
          <dependent id="3">also</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="1">Jackson</governor>
          <dependent id="4">testifying</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">subpoena</governor>
          <dependent id="5">under</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">testifying</governor>
          <dependent id="6">subpoena</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">said</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="25">took</governor>
          <dependent id="9">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">took</governor>
          <dependent id="10">he</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">he</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Hill</governor>
          <dependent id="12">Jeff</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">he</governor>
          <dependent id="13">Hill</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">officer</governor>
          <dependent id="15">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">officer</governor>
          <dependent id="16">off-duty</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">officer</governor>
          <dependent id="17">federal</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">officer</governor>
          <dependent id="18">corrections</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="10">he</governor>
          <dependent id="19">officer</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">drove</governor>
          <dependent id="20">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="19">officer</governor>
          <dependent id="21">drove</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">car</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">drove</governor>
          <dependent id="23">car</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="8">said</governor>
          <dependent id="25">took</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="27">care</governor>
          <dependent id="26">great</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="25">took</governor>
          <dependent id="27">care</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="30">break</governor>
          <dependent id="28">not</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="30">break</governor>
          <dependent id="29">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="25">took</governor>
          <dependent id="30">break</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="32">laws</governor>
          <dependent id="31">traffic</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="30">break</governor>
          <dependent id="32">laws</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="35">cruised</governor>
          <dependent id="33">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="35">cruised</governor>
          <dependent id="34">they</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="30">break</governor>
          <dependent id="35">cruised</dependent>
        </dependency>
        <dependency type="case">
          <governor id="39">Highway</governor>
          <dependent id="36">along</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="39">Highway</governor>
          <dependent id="37">Pacific</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="39">Highway</governor>
          <dependent id="38">Coast</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="35">cruised</governor>
          <dependent id="39">Highway</dependent>
        </dependency>
        <dependency type="case">
          <governor id="42">Beach</governor>
          <dependent id="40">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="42">Beach</governor>
          <dependent id="41">Long</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="39">Highway</governor>
          <dependent id="42">Beach</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Long Beach" type="LOCATION" score="0.0">
          <tokens>
            <token id="41" string="Long" />
            <token id="42" string="Beach" />
          </tokens>
        </entity>
        <entity id="2" string="Jeff Hill" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Jeff" />
            <token id="13" string="Hill" />
          </tokens>
        </entity>
        <entity id="3" string="Jackson" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Jackson" />
          </tokens>
        </entity>
        <entity id="4" string="Pacific Coast Highway" type="LOCATION" score="0.0">
          <tokens>
            <token id="37" string="Pacific" />
            <token id="38" string="Coast" />
            <token id="39" string="Highway" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="24" has_coreference="true">
      <content>He alleged that in addition to pushing his face into the glass, Dickey hurt him by bending his fingers while handcuffing him and pushed his face into the hood of the police car.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="alleged" lemma="allege" stem="alleg" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="addition" lemma="addition" stem="addit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="pushing" lemma="push" stem="push" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="9" string="face" lemma="face" stem="face" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="glass" lemma="glass" stem="glass" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Dickey" lemma="Dickey" stem="dickei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="15" string="hurt" lemma="hurt" stem="hurt" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="bending" lemma="bend" stem="bend" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="fingers" lemma="finger" stem="finger" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="while" lemma="while" stem="while" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="handcuffing" lemma="handcuff" stem="handcuf" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="pushed" lemma="push" stem="push" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="27" string="face" lemma="face" stem="face" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="hood" lemma="hood" stem="hood" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="33" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="34" string="car" lemma="car" stem="car" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="35" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VBD alleged) (SBAR (IN that) (S (PP (IN in) (NP (NP (NN addition)) (PP (TO to) (S (VP (VBG pushing) (NP (PRP$ his) (NN face)) (PP (IN into) (NP (DT the) (NN glass)))))))) (, ,) (NP (NNP Dickey)) (VP (VP (VBD hurt) (NP (PRP him)) (PP (IN by) (S (VP (VBG bending) (NP (PRP$ his) (NNS fingers)) (PP (IN while) (S (VP (VBG handcuffing) (NP (PRP him))))))))) (CC and) (VP (VBD pushed) (NP (PRP$ his) (NN face)) (PP (IN into) (NP (NP (DT the) (NN hood)) (PP (IN of) (NP (DT the) (NN police) (NN car)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="pushed his face into the hood of the police car" type="VP">
          <tokens>
            <token id="25" string="pushed" />
            <token id="26" string="his" />
            <token id="27" string="face" />
            <token id="28" string="into" />
            <token id="29" string="the" />
            <token id="30" string="hood" />
            <token id="31" string="of" />
            <token id="32" string="the" />
            <token id="33" string="police" />
            <token id="34" string="car" />
          </tokens>
        </chunking>
        <chunking id="2" string="that in addition to pushing his face into the glass , Dickey hurt him by bending his fingers while handcuffing him and pushed his face into the hood of the police car" type="SBAR">
          <tokens>
            <token id="3" string="that" />
            <token id="4" string="in" />
            <token id="5" string="addition" />
            <token id="6" string="to" />
            <token id="7" string="pushing" />
            <token id="8" string="his" />
            <token id="9" string="face" />
            <token id="10" string="into" />
            <token id="11" string="the" />
            <token id="12" string="glass" />
            <token id="13" string="," />
            <token id="14" string="Dickey" />
            <token id="15" string="hurt" />
            <token id="16" string="him" />
            <token id="17" string="by" />
            <token id="18" string="bending" />
            <token id="19" string="his" />
            <token id="20" string="fingers" />
            <token id="21" string="while" />
            <token id="22" string="handcuffing" />
            <token id="23" string="him" />
            <token id="24" string="and" />
            <token id="25" string="pushed" />
            <token id="26" string="his" />
            <token id="27" string="face" />
            <token id="28" string="into" />
            <token id="29" string="the" />
            <token id="30" string="hood" />
            <token id="31" string="of" />
            <token id="32" string="the" />
            <token id="33" string="police" />
            <token id="34" string="car" />
          </tokens>
        </chunking>
        <chunking id="3" string="the glass" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="glass" />
          </tokens>
        </chunking>
        <chunking id="4" string="bending his fingers while handcuffing him" type="VP">
          <tokens>
            <token id="18" string="bending" />
            <token id="19" string="his" />
            <token id="20" string="fingers" />
            <token id="21" string="while" />
            <token id="22" string="handcuffing" />
            <token id="23" string="him" />
          </tokens>
        </chunking>
        <chunking id="5" string="his fingers" type="NP">
          <tokens>
            <token id="19" string="his" />
            <token id="20" string="fingers" />
          </tokens>
        </chunking>
        <chunking id="6" string="him" type="NP">
          <tokens>
            <token id="16" string="him" />
          </tokens>
        </chunking>
        <chunking id="7" string="hurt him by bending his fingers while handcuffing him and pushed his face into the hood of the police car" type="VP">
          <tokens>
            <token id="15" string="hurt" />
            <token id="16" string="him" />
            <token id="17" string="by" />
            <token id="18" string="bending" />
            <token id="19" string="his" />
            <token id="20" string="fingers" />
            <token id="21" string="while" />
            <token id="22" string="handcuffing" />
            <token id="23" string="him" />
            <token id="24" string="and" />
            <token id="25" string="pushed" />
            <token id="26" string="his" />
            <token id="27" string="face" />
            <token id="28" string="into" />
            <token id="29" string="the" />
            <token id="30" string="hood" />
            <token id="31" string="of" />
            <token id="32" string="the" />
            <token id="33" string="police" />
            <token id="34" string="car" />
          </tokens>
        </chunking>
        <chunking id="8" string="the police car" type="NP">
          <tokens>
            <token id="32" string="the" />
            <token id="33" string="police" />
            <token id="34" string="car" />
          </tokens>
        </chunking>
        <chunking id="9" string="his face" type="NP">
          <tokens>
            <token id="8" string="his" />
            <token id="9" string="face" />
          </tokens>
        </chunking>
        <chunking id="10" string="addition to pushing his face into the glass" type="NP">
          <tokens>
            <token id="5" string="addition" />
            <token id="6" string="to" />
            <token id="7" string="pushing" />
            <token id="8" string="his" />
            <token id="9" string="face" />
            <token id="10" string="into" />
            <token id="11" string="the" />
            <token id="12" string="glass" />
          </tokens>
        </chunking>
        <chunking id="11" string="handcuffing him" type="VP">
          <tokens>
            <token id="22" string="handcuffing" />
            <token id="23" string="him" />
          </tokens>
        </chunking>
        <chunking id="12" string="pushing his face into the glass" type="VP">
          <tokens>
            <token id="7" string="pushing" />
            <token id="8" string="his" />
            <token id="9" string="face" />
            <token id="10" string="into" />
            <token id="11" string="the" />
            <token id="12" string="glass" />
          </tokens>
        </chunking>
        <chunking id="13" string="the hood" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="hood" />
          </tokens>
        </chunking>
        <chunking id="14" string="addition" type="NP">
          <tokens>
            <token id="5" string="addition" />
          </tokens>
        </chunking>
        <chunking id="15" string="hurt him by bending his fingers while handcuffing him" type="VP">
          <tokens>
            <token id="15" string="hurt" />
            <token id="16" string="him" />
            <token id="17" string="by" />
            <token id="18" string="bending" />
            <token id="19" string="his" />
            <token id="20" string="fingers" />
            <token id="21" string="while" />
            <token id="22" string="handcuffing" />
            <token id="23" string="him" />
          </tokens>
        </chunking>
        <chunking id="16" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="17" string="the hood of the police car" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="hood" />
            <token id="31" string="of" />
            <token id="32" string="the" />
            <token id="33" string="police" />
            <token id="34" string="car" />
          </tokens>
        </chunking>
        <chunking id="18" string="alleged that in addition to pushing his face into the glass , Dickey hurt him by bending his fingers while handcuffing him and pushed his face into the hood of the police car" type="VP">
          <tokens>
            <token id="2" string="alleged" />
            <token id="3" string="that" />
            <token id="4" string="in" />
            <token id="5" string="addition" />
            <token id="6" string="to" />
            <token id="7" string="pushing" />
            <token id="8" string="his" />
            <token id="9" string="face" />
            <token id="10" string="into" />
            <token id="11" string="the" />
            <token id="12" string="glass" />
            <token id="13" string="," />
            <token id="14" string="Dickey" />
            <token id="15" string="hurt" />
            <token id="16" string="him" />
            <token id="17" string="by" />
            <token id="18" string="bending" />
            <token id="19" string="his" />
            <token id="20" string="fingers" />
            <token id="21" string="while" />
            <token id="22" string="handcuffing" />
            <token id="23" string="him" />
            <token id="24" string="and" />
            <token id="25" string="pushed" />
            <token id="26" string="his" />
            <token id="27" string="face" />
            <token id="28" string="into" />
            <token id="29" string="the" />
            <token id="30" string="hood" />
            <token id="31" string="of" />
            <token id="32" string="the" />
            <token id="33" string="police" />
            <token id="34" string="car" />
          </tokens>
        </chunking>
        <chunking id="19" string="Dickey" type="NP">
          <tokens>
            <token id="14" string="Dickey" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">alleged</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">alleged</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">hurt</governor>
          <dependent id="3">that</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">pushing</governor>
          <dependent id="4">in</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="4">in</governor>
          <dependent id="5">addition</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="4">in</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="15">hurt</governor>
          <dependent id="7">pushing</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="9">face</governor>
          <dependent id="8">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">pushing</governor>
          <dependent id="9">face</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">glass</governor>
          <dependent id="10">into</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">glass</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">pushing</governor>
          <dependent id="12">glass</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">hurt</governor>
          <dependent id="14">Dickey</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">alleged</governor>
          <dependent id="15">hurt</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">hurt</governor>
          <dependent id="16">him</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">bending</governor>
          <dependent id="17">by</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="15">hurt</governor>
          <dependent id="18">bending</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="20">fingers</governor>
          <dependent id="19">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">bending</governor>
          <dependent id="20">fingers</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">handcuffing</governor>
          <dependent id="21">while</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="18">bending</governor>
          <dependent id="22">handcuffing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">handcuffing</governor>
          <dependent id="23">him</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="15">hurt</governor>
          <dependent id="24">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="15">hurt</governor>
          <dependent id="25">pushed</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="27">face</governor>
          <dependent id="26">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="25">pushed</governor>
          <dependent id="27">face</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">hood</governor>
          <dependent id="28">into</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">hood</governor>
          <dependent id="29">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">pushed</governor>
          <dependent id="30">hood</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">car</governor>
          <dependent id="31">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="34">car</governor>
          <dependent id="32">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="34">car</governor>
          <dependent id="33">police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">hood</governor>
          <dependent id="34">car</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Dickey" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Dickey" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="25" has_coreference="true">
      <content>Also, Jackson alleged, officers refused three requests to loosen his handcuffs as he was taken to the police station.</content>
      <tokens>
        <token id="1" string="Also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="4" string="alleged" lemma="allege" stem="alleg" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="refused" lemma="refuse" stem="refus" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="three" lemma="three" stem="three" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="9" string="requests" lemma="request" stem="request" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="loosen" lemma="loosen" stem="loosen" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="13" string="handcuffs" lemma="handcuffs" stem="handcuff" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="taken" lemma="take" stem="taken" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="station" lemma="station" stem="station" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Also)) (PRN (, ,) (NP (NNP Jackson)) (VP (VBD alleged)) (, ,)) (NP (NNS officers)) (VP (VBD refused) (NP (CD three) (NNS requests)) (S (VP (TO to) (VP (VB loosen) (NP (PRP$ his) (NNS handcuffs)) (SBAR (IN as) (S (NP (PRP he)) (VP (VBD was) (VP (VBN taken) (PP (TO to) (NP (DT the) (NN police) (NN station))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="three requests" type="NP">
          <tokens>
            <token id="8" string="three" />
            <token id="9" string="requests" />
          </tokens>
        </chunking>
        <chunking id="2" string="loosen his handcuffs as he was taken to the police station" type="VP">
          <tokens>
            <token id="11" string="loosen" />
            <token id="12" string="his" />
            <token id="13" string="handcuffs" />
            <token id="14" string="as" />
            <token id="15" string="he" />
            <token id="16" string="was" />
            <token id="17" string="taken" />
            <token id="18" string="to" />
            <token id="19" string="the" />
            <token id="20" string="police" />
            <token id="21" string="station" />
          </tokens>
        </chunking>
        <chunking id="3" string="to loosen his handcuffs as he was taken to the police station" type="VP">
          <tokens>
            <token id="10" string="to" />
            <token id="11" string="loosen" />
            <token id="12" string="his" />
            <token id="13" string="handcuffs" />
            <token id="14" string="as" />
            <token id="15" string="he" />
            <token id="16" string="was" />
            <token id="17" string="taken" />
            <token id="18" string="to" />
            <token id="19" string="the" />
            <token id="20" string="police" />
            <token id="21" string="station" />
          </tokens>
        </chunking>
        <chunking id="4" string="the police station" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="police" />
            <token id="21" string="station" />
          </tokens>
        </chunking>
        <chunking id="5" string="alleged" type="VP">
          <tokens>
            <token id="4" string="alleged" />
          </tokens>
        </chunking>
        <chunking id="6" string="refused three requests to loosen his handcuffs as he was taken to the police station" type="VP">
          <tokens>
            <token id="7" string="refused" />
            <token id="8" string="three" />
            <token id="9" string="requests" />
            <token id="10" string="to" />
            <token id="11" string="loosen" />
            <token id="12" string="his" />
            <token id="13" string="handcuffs" />
            <token id="14" string="as" />
            <token id="15" string="he" />
            <token id="16" string="was" />
            <token id="17" string="taken" />
            <token id="18" string="to" />
            <token id="19" string="the" />
            <token id="20" string="police" />
            <token id="21" string="station" />
          </tokens>
        </chunking>
        <chunking id="7" string="was taken to the police station" type="VP">
          <tokens>
            <token id="16" string="was" />
            <token id="17" string="taken" />
            <token id="18" string="to" />
            <token id="19" string="the" />
            <token id="20" string="police" />
            <token id="21" string="station" />
          </tokens>
        </chunking>
        <chunking id="8" string="Jackson" type="NP">
          <tokens>
            <token id="3" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="9" string="taken to the police station" type="VP">
          <tokens>
            <token id="17" string="taken" />
            <token id="18" string="to" />
            <token id="19" string="the" />
            <token id="20" string="police" />
            <token id="21" string="station" />
          </tokens>
        </chunking>
        <chunking id="10" string="he" type="NP">
          <tokens>
            <token id="15" string="he" />
          </tokens>
        </chunking>
        <chunking id="11" string="officers" type="NP">
          <tokens>
            <token id="6" string="officers" />
          </tokens>
        </chunking>
        <chunking id="12" string="as he was taken to the police station" type="SBAR">
          <tokens>
            <token id="14" string="as" />
            <token id="15" string="he" />
            <token id="16" string="was" />
            <token id="17" string="taken" />
            <token id="18" string="to" />
            <token id="19" string="the" />
            <token id="20" string="police" />
            <token id="21" string="station" />
          </tokens>
        </chunking>
        <chunking id="13" string="his handcuffs" type="NP">
          <tokens>
            <token id="12" string="his" />
            <token id="13" string="handcuffs" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="7">refused</governor>
          <dependent id="1">Also</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">alleged</governor>
          <dependent id="3">Jackson</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="7">refused</governor>
          <dependent id="4">alleged</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">refused</governor>
          <dependent id="6">officers</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">refused</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="9">requests</governor>
          <dependent id="8">three</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">refused</governor>
          <dependent id="9">requests</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">loosen</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="7">refused</governor>
          <dependent id="11">loosen</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="13">handcuffs</governor>
          <dependent id="12">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">loosen</governor>
          <dependent id="13">handcuffs</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">taken</governor>
          <dependent id="14">as</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="17">taken</governor>
          <dependent id="15">he</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="17">taken</governor>
          <dependent id="16">was</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="11">loosen</governor>
          <dependent id="17">taken</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">station</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">station</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">station</governor>
          <dependent id="20">police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">taken</governor>
          <dependent id="21">station</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Jackson" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Jackson" />
          </tokens>
        </entity>
        <entity id="2" string="three" type="NUMBER" score="0.0">
          <tokens>
            <token id="8" string="three" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="26" has_coreference="true">
      <content>Dickey&amp;apost;s eight-page police report, which was provided to reporters, states that Jackson was arrested for saying &amp;quot;offensive words,&amp;quot; an allegation that was later dropped.</content>
      <tokens>
        <token id="1" string="Dickey" lemma="Dickey" stem="dickei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="eight-page" lemma="eight-page" stem="eight-pag" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="report" lemma="report" stem="report" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="provided" lemma="provide" stem="provid" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="reporters" lemma="reporter" stem="report" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="states" lemma="state" stem="state" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="16" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="arrested" lemma="arrest" stem="arrest" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="saying" lemma="say" stem="sai" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="offensive" lemma="offensive" stem="offens" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="words" lemma="word" stem="word" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="allegation" lemma="allegation" stem="alleg" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="later" lemma="later" stem="later" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="dropped" lemma="drop" stem="drop" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (NP (NP (NP (NP (NNP Dickey) (POS 's)) (JJ eight-page) (NN police) (NN report)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBD was) (VP (VBN provided) (PP (TO to) (NP (NNS reporters))))))) (, ,)) (NP (NP (NNS states)) (SBAR (WHNP (WDT that)) (S (NP (NNP Jackson)) (VP (VBD was) (VP (VBN arrested) (PP (IN for) (S (VP (VBG saying) (NP (`` ``) (NP (JJ offensive) (NNS words)) (, ,) ('' '') (NP (NP (DT an) (NN allegation)) (SBAR (WHNP (WDT that)) (S (VP (VBD was) (VP (ADVP (RB later)) (VBN dropped))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Dickey 's eight-page police report" type="NP">
          <tokens>
            <token id="1" string="Dickey" />
            <token id="2" string="'s" />
            <token id="3" string="eight-page" />
            <token id="4" string="police" />
            <token id="5" string="report" />
          </tokens>
        </chunking>
        <chunking id="2" string="reporters" type="NP">
          <tokens>
            <token id="11" string="reporters" />
          </tokens>
        </chunking>
        <chunking id="3" string="Dickey 's eight-page police report , which was provided to reporters , states that Jackson was arrested for saying `` offensive words , '' an allegation that was later dropped ." type="NP">
          <tokens>
            <token id="1" string="Dickey" />
            <token id="2" string="'s" />
            <token id="3" string="eight-page" />
            <token id="4" string="police" />
            <token id="5" string="report" />
            <token id="6" string="," />
            <token id="7" string="which" />
            <token id="8" string="was" />
            <token id="9" string="provided" />
            <token id="10" string="to" />
            <token id="11" string="reporters" />
            <token id="12" string="," />
            <token id="13" string="states" />
            <token id="14" string="that" />
            <token id="15" string="Jackson" />
            <token id="16" string="was" />
            <token id="17" string="arrested" />
            <token id="18" string="for" />
            <token id="19" string="saying" />
            <token id="20" string="&quot;" />
            <token id="21" string="offensive" />
            <token id="22" string="words" />
            <token id="23" string="," />
            <token id="24" string="&quot;" />
            <token id="25" string="an" />
            <token id="26" string="allegation" />
            <token id="27" string="that" />
            <token id="28" string="was" />
            <token id="29" string="later" />
            <token id="30" string="dropped" />
            <token id="31" string="." />
          </tokens>
        </chunking>
        <chunking id="4" string="Dickey 's eight-page police report , which was provided to reporters ," type="NP">
          <tokens>
            <token id="1" string="Dickey" />
            <token id="2" string="'s" />
            <token id="3" string="eight-page" />
            <token id="4" string="police" />
            <token id="5" string="report" />
            <token id="6" string="," />
            <token id="7" string="which" />
            <token id="8" string="was" />
            <token id="9" string="provided" />
            <token id="10" string="to" />
            <token id="11" string="reporters" />
            <token id="12" string="," />
          </tokens>
        </chunking>
        <chunking id="5" string="Dickey 's" type="NP">
          <tokens>
            <token id="1" string="Dickey" />
            <token id="2" string="'s" />
          </tokens>
        </chunking>
        <chunking id="6" string="saying `` offensive words , '' an allegation that was later dropped" type="VP">
          <tokens>
            <token id="19" string="saying" />
            <token id="20" string="&quot;" />
            <token id="21" string="offensive" />
            <token id="22" string="words" />
            <token id="23" string="," />
            <token id="24" string="&quot;" />
            <token id="25" string="an" />
            <token id="26" string="allegation" />
            <token id="27" string="that" />
            <token id="28" string="was" />
            <token id="29" string="later" />
            <token id="30" string="dropped" />
          </tokens>
        </chunking>
        <chunking id="7" string="states that Jackson was arrested for saying `` offensive words , '' an allegation that was later dropped" type="NP">
          <tokens>
            <token id="13" string="states" />
            <token id="14" string="that" />
            <token id="15" string="Jackson" />
            <token id="16" string="was" />
            <token id="17" string="arrested" />
            <token id="18" string="for" />
            <token id="19" string="saying" />
            <token id="20" string="&quot;" />
            <token id="21" string="offensive" />
            <token id="22" string="words" />
            <token id="23" string="," />
            <token id="24" string="&quot;" />
            <token id="25" string="an" />
            <token id="26" string="allegation" />
            <token id="27" string="that" />
            <token id="28" string="was" />
            <token id="29" string="later" />
            <token id="30" string="dropped" />
          </tokens>
        </chunking>
        <chunking id="8" string="arrested for saying `` offensive words , '' an allegation that was later dropped" type="VP">
          <tokens>
            <token id="17" string="arrested" />
            <token id="18" string="for" />
            <token id="19" string="saying" />
            <token id="20" string="&quot;" />
            <token id="21" string="offensive" />
            <token id="22" string="words" />
            <token id="23" string="," />
            <token id="24" string="&quot;" />
            <token id="25" string="an" />
            <token id="26" string="allegation" />
            <token id="27" string="that" />
            <token id="28" string="was" />
            <token id="29" string="later" />
            <token id="30" string="dropped" />
          </tokens>
        </chunking>
        <chunking id="9" string="that was later dropped" type="SBAR">
          <tokens>
            <token id="27" string="that" />
            <token id="28" string="was" />
            <token id="29" string="later" />
            <token id="30" string="dropped" />
          </tokens>
        </chunking>
        <chunking id="10" string="that Jackson was arrested for saying `` offensive words , '' an allegation that was later dropped" type="SBAR">
          <tokens>
            <token id="14" string="that" />
            <token id="15" string="Jackson" />
            <token id="16" string="was" />
            <token id="17" string="arrested" />
            <token id="18" string="for" />
            <token id="19" string="saying" />
            <token id="20" string="&quot;" />
            <token id="21" string="offensive" />
            <token id="22" string="words" />
            <token id="23" string="," />
            <token id="24" string="&quot;" />
            <token id="25" string="an" />
            <token id="26" string="allegation" />
            <token id="27" string="that" />
            <token id="28" string="was" />
            <token id="29" string="later" />
            <token id="30" string="dropped" />
          </tokens>
        </chunking>
        <chunking id="11" string="was later dropped" type="VP">
          <tokens>
            <token id="28" string="was" />
            <token id="29" string="later" />
            <token id="30" string="dropped" />
          </tokens>
        </chunking>
        <chunking id="12" string="Jackson" type="NP">
          <tokens>
            <token id="15" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="13" string="states" type="NP">
          <tokens>
            <token id="13" string="states" />
          </tokens>
        </chunking>
        <chunking id="14" string="was arrested for saying `` offensive words , '' an allegation that was later dropped" type="VP">
          <tokens>
            <token id="16" string="was" />
            <token id="17" string="arrested" />
            <token id="18" string="for" />
            <token id="19" string="saying" />
            <token id="20" string="&quot;" />
            <token id="21" string="offensive" />
            <token id="22" string="words" />
            <token id="23" string="," />
            <token id="24" string="&quot;" />
            <token id="25" string="an" />
            <token id="26" string="allegation" />
            <token id="27" string="that" />
            <token id="28" string="was" />
            <token id="29" string="later" />
            <token id="30" string="dropped" />
          </tokens>
        </chunking>
        <chunking id="15" string="an allegation" type="NP">
          <tokens>
            <token id="25" string="an" />
            <token id="26" string="allegation" />
          </tokens>
        </chunking>
        <chunking id="16" string="later dropped" type="VP">
          <tokens>
            <token id="29" string="later" />
            <token id="30" string="dropped" />
          </tokens>
        </chunking>
        <chunking id="17" string="provided to reporters" type="VP">
          <tokens>
            <token id="9" string="provided" />
            <token id="10" string="to" />
            <token id="11" string="reporters" />
          </tokens>
        </chunking>
        <chunking id="18" string="`` offensive words , '' an allegation that was later dropped" type="NP">
          <tokens>
            <token id="20" string="&quot;" />
            <token id="21" string="offensive" />
            <token id="22" string="words" />
            <token id="23" string="," />
            <token id="24" string="&quot;" />
            <token id="25" string="an" />
            <token id="26" string="allegation" />
            <token id="27" string="that" />
            <token id="28" string="was" />
            <token id="29" string="later" />
            <token id="30" string="dropped" />
          </tokens>
        </chunking>
        <chunking id="19" string="an allegation that was later dropped" type="NP">
          <tokens>
            <token id="25" string="an" />
            <token id="26" string="allegation" />
            <token id="27" string="that" />
            <token id="28" string="was" />
            <token id="29" string="later" />
            <token id="30" string="dropped" />
          </tokens>
        </chunking>
        <chunking id="20" string="which was provided to reporters" type="SBAR">
          <tokens>
            <token id="7" string="which" />
            <token id="8" string="was" />
            <token id="9" string="provided" />
            <token id="10" string="to" />
            <token id="11" string="reporters" />
          </tokens>
        </chunking>
        <chunking id="21" string="offensive words" type="NP">
          <tokens>
            <token id="21" string="offensive" />
            <token id="22" string="words" />
          </tokens>
        </chunking>
        <chunking id="22" string="was provided to reporters" type="VP">
          <tokens>
            <token id="8" string="was" />
            <token id="9" string="provided" />
            <token id="10" string="to" />
            <token id="11" string="reporters" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="5">report</governor>
          <dependent id="1">Dickey</dependent>
        </dependency>
        <dependency type="case">
          <governor id="1">Dickey</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">report</governor>
          <dependent id="3">eight-page</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">report</governor>
          <dependent id="4">police</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">report</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="9">provided</governor>
          <dependent id="7">which</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="9">provided</governor>
          <dependent id="8">was</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="5">report</governor>
          <dependent id="9">provided</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">reporters</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">provided</governor>
          <dependent id="11">reporters</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="5">report</governor>
          <dependent id="13">states</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">arrested</governor>
          <dependent id="14">that</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="17">arrested</governor>
          <dependent id="15">Jackson</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="17">arrested</governor>
          <dependent id="16">was</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="13">states</governor>
          <dependent id="17">arrested</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">saying</governor>
          <dependent id="18">for</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="17">arrested</governor>
          <dependent id="19">saying</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">words</governor>
          <dependent id="21">offensive</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">saying</governor>
          <dependent id="22">words</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">allegation</governor>
          <dependent id="25">an</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="22">words</governor>
          <dependent id="26">allegation</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="30">dropped</governor>
          <dependent id="27">that</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="30">dropped</governor>
          <dependent id="28">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="30">dropped</governor>
          <dependent id="29">later</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="26">allegation</governor>
          <dependent id="30">dropped</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Jackson" type="PERSON" score="0.0">
          <tokens>
            <token id="15" string="Jackson" />
          </tokens>
        </entity>
        <entity id="2" string="Dickey" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Dickey" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="27" has_coreference="true">
      <content>But Dickey conceded at the hearing that it was he, not Jackson, who uttered obscenities.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Dickey" lemma="Dickey" stem="dickei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="conceded" lemma="concede" stem="conced" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="hearing" lemma="hearing" stem="hear" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="uttered" lemma="utter" stem="utter" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="obscenities" lemma="obscenity" stem="obscen" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (NNP Dickey)) (VP (VBD conceded) (PP (IN at) (NP (DT the) (NN hearing))) (SBAR (IN that) (S (NP (PRP it)) (VP (VBD was) (NP (NP (PRP he)) (, ,) (RB not) (NP (NNP Jackson)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBD uttered) (NP (NNS obscenities)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="was he , not Jackson , who uttered obscenities" type="VP">
          <tokens>
            <token id="9" string="was" />
            <token id="10" string="he" />
            <token id="11" string="," />
            <token id="12" string="not" />
            <token id="13" string="Jackson" />
            <token id="14" string="," />
            <token id="15" string="who" />
            <token id="16" string="uttered" />
            <token id="17" string="obscenities" />
          </tokens>
        </chunking>
        <chunking id="2" string="conceded at the hearing that it was he , not Jackson , who uttered obscenities" type="VP">
          <tokens>
            <token id="3" string="conceded" />
            <token id="4" string="at" />
            <token id="5" string="the" />
            <token id="6" string="hearing" />
            <token id="7" string="that" />
            <token id="8" string="it" />
            <token id="9" string="was" />
            <token id="10" string="he" />
            <token id="11" string="," />
            <token id="12" string="not" />
            <token id="13" string="Jackson" />
            <token id="14" string="," />
            <token id="15" string="who" />
            <token id="16" string="uttered" />
            <token id="17" string="obscenities" />
          </tokens>
        </chunking>
        <chunking id="3" string="who uttered obscenities" type="SBAR">
          <tokens>
            <token id="15" string="who" />
            <token id="16" string="uttered" />
            <token id="17" string="obscenities" />
          </tokens>
        </chunking>
        <chunking id="4" string="uttered obscenities" type="VP">
          <tokens>
            <token id="16" string="uttered" />
            <token id="17" string="obscenities" />
          </tokens>
        </chunking>
        <chunking id="5" string="that it was he , not Jackson , who uttered obscenities" type="SBAR">
          <tokens>
            <token id="7" string="that" />
            <token id="8" string="it" />
            <token id="9" string="was" />
            <token id="10" string="he" />
            <token id="11" string="," />
            <token id="12" string="not" />
            <token id="13" string="Jackson" />
            <token id="14" string="," />
            <token id="15" string="who" />
            <token id="16" string="uttered" />
            <token id="17" string="obscenities" />
          </tokens>
        </chunking>
        <chunking id="6" string="it" type="NP">
          <tokens>
            <token id="8" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="Jackson" type="NP">
          <tokens>
            <token id="13" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="8" string="he , not Jackson , who uttered obscenities" type="NP">
          <tokens>
            <token id="10" string="he" />
            <token id="11" string="," />
            <token id="12" string="not" />
            <token id="13" string="Jackson" />
            <token id="14" string="," />
            <token id="15" string="who" />
            <token id="16" string="uttered" />
            <token id="17" string="obscenities" />
          </tokens>
        </chunking>
        <chunking id="9" string="he" type="NP">
          <tokens>
            <token id="10" string="he" />
          </tokens>
        </chunking>
        <chunking id="10" string="the hearing" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="hearing" />
          </tokens>
        </chunking>
        <chunking id="11" string="obscenities" type="NP">
          <tokens>
            <token id="17" string="obscenities" />
          </tokens>
        </chunking>
        <chunking id="12" string="Dickey" type="NP">
          <tokens>
            <token id="2" string="Dickey" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="3">conceded</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">conceded</governor>
          <dependent id="2">Dickey</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">conceded</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">hearing</governor>
          <dependent id="4">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">hearing</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">conceded</governor>
          <dependent id="6">hearing</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">he</governor>
          <dependent id="7">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">he</governor>
          <dependent id="8">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="10">he</governor>
          <dependent id="9">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">conceded</governor>
          <dependent id="10">he</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="13">Jackson</governor>
          <dependent id="12">not</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="10">he</governor>
          <dependent id="13">Jackson</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">uttered</governor>
          <dependent id="15">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="10">he</governor>
          <dependent id="16">uttered</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">uttered</governor>
          <dependent id="17">obscenities</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Jackson" type="PERSON" score="0.0">
          <tokens>
            <token id="13" string="Jackson" />
          </tokens>
        </entity>
        <entity id="2" string="Dickey" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Dickey" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="28" has_coreference="true">
      <content>No Taunts Heard The report states that Jackson challenged the officer to fight, although Jackson never is heard taunting the officer on the tape.</content>
      <tokens>
        <token id="1" string="No" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="2" string="Taunts" lemma="Taunts" stem="taunt" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="3" string="Heard" lemma="Heard" stem="heard" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="4" string="The" lemma="The" stem="the" pos="NNP" type="Word" isStopWord="true" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="5" string="report" lemma="report" stem="report" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="states" lemma="state" stem="state" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="9" string="challenged" lemma="challenge" stem="challeng" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="officer" lemma="officer" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="fight" lemma="fight" stem="fight" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="although" lemma="although" stem="although" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="17" string="never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="heard" lemma="hear" stem="heard" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="taunting" lemma="taunt" stem="taunt" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="officer" lemma="officer" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="23" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="tape" lemma="tape" stem="tape" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT No) (NNP Taunts) (NNP Heard) (NNP The) (NN report)) (VP (VBZ states) (SBAR (IN that) (S (NP (NNP Jackson)) (VP (VBD challenged) (NP (DT the) (NN officer)) (S (VP (TO to) (VP (VB fight)))) (, ,) (SBAR (IN although) (S (NP (NNP Jackson)) (ADVP (RB never)) (VP (VBZ is) (VP (VBN heard) (S (VP (VBG taunting) (NP (DT the) (NN officer)) (PP (IN on) (NP (DT the) (NN tape))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="fight" type="VP">
          <tokens>
            <token id="13" string="fight" />
          </tokens>
        </chunking>
        <chunking id="2" string="heard taunting the officer on the tape" type="VP">
          <tokens>
            <token id="19" string="heard" />
            <token id="20" string="taunting" />
            <token id="21" string="the" />
            <token id="22" string="officer" />
            <token id="23" string="on" />
            <token id="24" string="the" />
            <token id="25" string="tape" />
          </tokens>
        </chunking>
        <chunking id="3" string="Jackson" type="NP">
          <tokens>
            <token id="8" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="4" string="the officer" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="officer" />
          </tokens>
        </chunking>
        <chunking id="5" string="is heard taunting the officer on the tape" type="VP">
          <tokens>
            <token id="18" string="is" />
            <token id="19" string="heard" />
            <token id="20" string="taunting" />
            <token id="21" string="the" />
            <token id="22" string="officer" />
            <token id="23" string="on" />
            <token id="24" string="the" />
            <token id="25" string="tape" />
          </tokens>
        </chunking>
        <chunking id="6" string="challenged the officer to fight , although Jackson never is heard taunting the officer on the tape" type="VP">
          <tokens>
            <token id="9" string="challenged" />
            <token id="10" string="the" />
            <token id="11" string="officer" />
            <token id="12" string="to" />
            <token id="13" string="fight" />
            <token id="14" string="," />
            <token id="15" string="although" />
            <token id="16" string="Jackson" />
            <token id="17" string="never" />
            <token id="18" string="is" />
            <token id="19" string="heard" />
            <token id="20" string="taunting" />
            <token id="21" string="the" />
            <token id="22" string="officer" />
            <token id="23" string="on" />
            <token id="24" string="the" />
            <token id="25" string="tape" />
          </tokens>
        </chunking>
        <chunking id="7" string="to fight" type="VP">
          <tokens>
            <token id="12" string="to" />
            <token id="13" string="fight" />
          </tokens>
        </chunking>
        <chunking id="8" string="states that Jackson challenged the officer to fight , although Jackson never is heard taunting the officer on the tape" type="VP">
          <tokens>
            <token id="6" string="states" />
            <token id="7" string="that" />
            <token id="8" string="Jackson" />
            <token id="9" string="challenged" />
            <token id="10" string="the" />
            <token id="11" string="officer" />
            <token id="12" string="to" />
            <token id="13" string="fight" />
            <token id="14" string="," />
            <token id="15" string="although" />
            <token id="16" string="Jackson" />
            <token id="17" string="never" />
            <token id="18" string="is" />
            <token id="19" string="heard" />
            <token id="20" string="taunting" />
            <token id="21" string="the" />
            <token id="22" string="officer" />
            <token id="23" string="on" />
            <token id="24" string="the" />
            <token id="25" string="tape" />
          </tokens>
        </chunking>
        <chunking id="9" string="that Jackson challenged the officer to fight , although Jackson never is heard taunting the officer on the tape" type="SBAR">
          <tokens>
            <token id="7" string="that" />
            <token id="8" string="Jackson" />
            <token id="9" string="challenged" />
            <token id="10" string="the" />
            <token id="11" string="officer" />
            <token id="12" string="to" />
            <token id="13" string="fight" />
            <token id="14" string="," />
            <token id="15" string="although" />
            <token id="16" string="Jackson" />
            <token id="17" string="never" />
            <token id="18" string="is" />
            <token id="19" string="heard" />
            <token id="20" string="taunting" />
            <token id="21" string="the" />
            <token id="22" string="officer" />
            <token id="23" string="on" />
            <token id="24" string="the" />
            <token id="25" string="tape" />
          </tokens>
        </chunking>
        <chunking id="10" string="taunting the officer on the tape" type="VP">
          <tokens>
            <token id="20" string="taunting" />
            <token id="21" string="the" />
            <token id="22" string="officer" />
            <token id="23" string="on" />
            <token id="24" string="the" />
            <token id="25" string="tape" />
          </tokens>
        </chunking>
        <chunking id="11" string="the tape" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="tape" />
          </tokens>
        </chunking>
        <chunking id="12" string="No Taunts Heard The report" type="NP">
          <tokens>
            <token id="1" string="No" />
            <token id="2" string="Taunts" />
            <token id="3" string="Heard" />
            <token id="4" string="The" />
            <token id="5" string="report" />
          </tokens>
        </chunking>
        <chunking id="13" string="although Jackson never is heard taunting the officer on the tape" type="SBAR">
          <tokens>
            <token id="15" string="although" />
            <token id="16" string="Jackson" />
            <token id="17" string="never" />
            <token id="18" string="is" />
            <token id="19" string="heard" />
            <token id="20" string="taunting" />
            <token id="21" string="the" />
            <token id="22" string="officer" />
            <token id="23" string="on" />
            <token id="24" string="the" />
            <token id="25" string="tape" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="neg">
          <governor id="5">report</governor>
          <dependent id="1">No</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">report</governor>
          <dependent id="2">Taunts</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">report</governor>
          <dependent id="3">Heard</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">report</governor>
          <dependent id="4">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">states</governor>
          <dependent id="5">report</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">states</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">challenged</governor>
          <dependent id="7">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">challenged</governor>
          <dependent id="8">Jackson</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">states</governor>
          <dependent id="9">challenged</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">officer</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">challenged</governor>
          <dependent id="11">officer</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">fight</governor>
          <dependent id="12">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="9">challenged</governor>
          <dependent id="13">fight</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">heard</governor>
          <dependent id="15">although</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="19">heard</governor>
          <dependent id="16">Jackson</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="19">heard</governor>
          <dependent id="17">never</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="19">heard</governor>
          <dependent id="18">is</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="9">challenged</governor>
          <dependent id="19">heard</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="19">heard</governor>
          <dependent id="20">taunting</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">officer</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">taunting</governor>
          <dependent id="22">officer</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">tape</governor>
          <dependent id="23">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">tape</governor>
          <dependent id="24">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">taunting</governor>
          <dependent id="25">tape</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Jackson" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Jackson" />
          </tokens>
        </entity>
        <entity id="2" string="No Taunts Heard The" type="MISC" score="0.0">
          <tokens>
            <token id="1" string="No" />
            <token id="2" string="Taunts" />
            <token id="3" string="Heard" />
            <token id="4" string="The" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="29" has_coreference="true">
      <content>&amp;quot;There can be a fight without a verbal challenge,&amp;quot; Dickey said, adding that Jackson&amp;apost;s fists were clenched at his sides.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="There" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="fight" lemma="fight" stem="fight" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="without" lemma="without" stem="without" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="verbal" lemma="verbal" stem="verbal" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="challenge" lemma="challenge" stem="challeng" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Dickey" lemma="Dickey" stem="dickei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="14" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="adding" lemma="add" stem="ad" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="19" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="fists" lemma="fist" stem="fist" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="clenched" lemma="clench" stem="clench" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="sides" lemma="side" stem="side" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (EX There)) (VP (MD can) (VP (VB be) (NP (DT a) (NN fight)) (PP (IN without) (NP (DT a) (JJ verbal) (NN challenge)))))) (, ,) ('' '') (NP (NNP Dickey)) (VP (VBD said) (, ,) (S (VP (VBG adding) (SBAR (IN that) (S (NP (NP (NNP Jackson) (POS 's)) (NNS fists)) (VP (VBD were) (VP (VBN clenched) (PP (IN at) (NP (PRP$ his) (NNS sides)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a verbal challenge" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="verbal" />
            <token id="10" string="challenge" />
          </tokens>
        </chunking>
        <chunking id="2" string="be a fight without a verbal challenge" type="VP">
          <tokens>
            <token id="4" string="be" />
            <token id="5" string="a" />
            <token id="6" string="fight" />
            <token id="7" string="without" />
            <token id="8" string="a" />
            <token id="9" string="verbal" />
            <token id="10" string="challenge" />
          </tokens>
        </chunking>
        <chunking id="3" string="Jackson 's fists" type="NP">
          <tokens>
            <token id="18" string="Jackson" />
            <token id="19" string="'s" />
            <token id="20" string="fists" />
          </tokens>
        </chunking>
        <chunking id="4" string="that Jackson 's fists were clenched at his sides" type="SBAR">
          <tokens>
            <token id="17" string="that" />
            <token id="18" string="Jackson" />
            <token id="19" string="'s" />
            <token id="20" string="fists" />
            <token id="21" string="were" />
            <token id="22" string="clenched" />
            <token id="23" string="at" />
            <token id="24" string="his" />
            <token id="25" string="sides" />
          </tokens>
        </chunking>
        <chunking id="5" string="can be a fight without a verbal challenge" type="VP">
          <tokens>
            <token id="3" string="can" />
            <token id="4" string="be" />
            <token id="5" string="a" />
            <token id="6" string="fight" />
            <token id="7" string="without" />
            <token id="8" string="a" />
            <token id="9" string="verbal" />
            <token id="10" string="challenge" />
          </tokens>
        </chunking>
        <chunking id="6" string="There" type="NP">
          <tokens>
            <token id="2" string="There" />
          </tokens>
        </chunking>
        <chunking id="7" string="were clenched at his sides" type="VP">
          <tokens>
            <token id="21" string="were" />
            <token id="22" string="clenched" />
            <token id="23" string="at" />
            <token id="24" string="his" />
            <token id="25" string="sides" />
          </tokens>
        </chunking>
        <chunking id="8" string="a fight" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="fight" />
          </tokens>
        </chunking>
        <chunking id="9" string="adding that Jackson 's fists were clenched at his sides" type="VP">
          <tokens>
            <token id="16" string="adding" />
            <token id="17" string="that" />
            <token id="18" string="Jackson" />
            <token id="19" string="'s" />
            <token id="20" string="fists" />
            <token id="21" string="were" />
            <token id="22" string="clenched" />
            <token id="23" string="at" />
            <token id="24" string="his" />
            <token id="25" string="sides" />
          </tokens>
        </chunking>
        <chunking id="10" string="Jackson 's" type="NP">
          <tokens>
            <token id="18" string="Jackson" />
            <token id="19" string="'s" />
          </tokens>
        </chunking>
        <chunking id="11" string="clenched at his sides" type="VP">
          <tokens>
            <token id="22" string="clenched" />
            <token id="23" string="at" />
            <token id="24" string="his" />
            <token id="25" string="sides" />
          </tokens>
        </chunking>
        <chunking id="12" string="his sides" type="NP">
          <tokens>
            <token id="24" string="his" />
            <token id="25" string="sides" />
          </tokens>
        </chunking>
        <chunking id="13" string="said , adding that Jackson 's fists were clenched at his sides" type="VP">
          <tokens>
            <token id="14" string="said" />
            <token id="15" string="," />
            <token id="16" string="adding" />
            <token id="17" string="that" />
            <token id="18" string="Jackson" />
            <token id="19" string="'s" />
            <token id="20" string="fists" />
            <token id="21" string="were" />
            <token id="22" string="clenched" />
            <token id="23" string="at" />
            <token id="24" string="his" />
            <token id="25" string="sides" />
          </tokens>
        </chunking>
        <chunking id="14" string="Dickey" type="NP">
          <tokens>
            <token id="13" string="Dickey" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="expl">
          <governor id="6">fight</governor>
          <dependent id="2">There</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">fight</governor>
          <dependent id="3">can</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">fight</governor>
          <dependent id="4">be</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">fight</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="14">said</governor>
          <dependent id="6">fight</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">challenge</governor>
          <dependent id="7">without</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">challenge</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">challenge</governor>
          <dependent id="9">verbal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">fight</governor>
          <dependent id="10">challenge</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">said</governor>
          <dependent id="13">Dickey</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">said</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="14">said</governor>
          <dependent id="16">adding</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">clenched</governor>
          <dependent id="17">that</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="20">fists</governor>
          <dependent id="18">Jackson</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">Jackson</governor>
          <dependent id="19">'s</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="22">clenched</governor>
          <dependent id="20">fists</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="22">clenched</governor>
          <dependent id="21">were</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="16">adding</governor>
          <dependent id="22">clenched</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">sides</governor>
          <dependent id="23">at</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="25">sides</governor>
          <dependent id="24">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">clenched</governor>
          <dependent id="25">sides</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Jackson" type="PERSON" score="0.0">
          <tokens>
            <token id="18" string="Jackson" />
          </tokens>
        </entity>
        <entity id="2" string="Dickey" type="PERSON" score="0.0">
          <tokens>
            <token id="13" string="Dickey" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="30" has_coreference="true">
      <content>Dickey said that he was swearing to try to alleviate his fear.</content>
      <tokens>
        <token id="1" string="Dickey" lemma="Dickey" stem="dickei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="swearing" lemma="swearing" stem="swear" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="try" lemma="try" stem="try" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="alleviate" lemma="alleviate" stem="allevi" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="fear" lemma="fear" stem="fear" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Dickey)) (VP (VBD said) (SBAR (IN that) (S (NP (PRP he)) (VP (VBD was) (NP (NN swearing) (S (VP (TO to) (VP (VB try) (S (VP (TO to) (VP (VB alleviate) (NP (PRP$ his) (NN fear))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="swearing to try to alleviate his fear" type="NP">
          <tokens>
            <token id="6" string="swearing" />
            <token id="7" string="to" />
            <token id="8" string="try" />
            <token id="9" string="to" />
            <token id="10" string="alleviate" />
            <token id="11" string="his" />
            <token id="12" string="fear" />
          </tokens>
        </chunking>
        <chunking id="2" string="said that he was swearing to try to alleviate his fear" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="that" />
            <token id="4" string="he" />
            <token id="5" string="was" />
            <token id="6" string="swearing" />
            <token id="7" string="to" />
            <token id="8" string="try" />
            <token id="9" string="to" />
            <token id="10" string="alleviate" />
            <token id="11" string="his" />
            <token id="12" string="fear" />
          </tokens>
        </chunking>
        <chunking id="3" string="his fear" type="NP">
          <tokens>
            <token id="11" string="his" />
            <token id="12" string="fear" />
          </tokens>
        </chunking>
        <chunking id="4" string="alleviate his fear" type="VP">
          <tokens>
            <token id="10" string="alleviate" />
            <token id="11" string="his" />
            <token id="12" string="fear" />
          </tokens>
        </chunking>
        <chunking id="5" string="that he was swearing to try to alleviate his fear" type="SBAR">
          <tokens>
            <token id="3" string="that" />
            <token id="4" string="he" />
            <token id="5" string="was" />
            <token id="6" string="swearing" />
            <token id="7" string="to" />
            <token id="8" string="try" />
            <token id="9" string="to" />
            <token id="10" string="alleviate" />
            <token id="11" string="his" />
            <token id="12" string="fear" />
          </tokens>
        </chunking>
        <chunking id="6" string="try to alleviate his fear" type="VP">
          <tokens>
            <token id="8" string="try" />
            <token id="9" string="to" />
            <token id="10" string="alleviate" />
            <token id="11" string="his" />
            <token id="12" string="fear" />
          </tokens>
        </chunking>
        <chunking id="7" string="he" type="NP">
          <tokens>
            <token id="4" string="he" />
          </tokens>
        </chunking>
        <chunking id="8" string="to alleviate his fear" type="VP">
          <tokens>
            <token id="9" string="to" />
            <token id="10" string="alleviate" />
            <token id="11" string="his" />
            <token id="12" string="fear" />
          </tokens>
        </chunking>
        <chunking id="9" string="was swearing to try to alleviate his fear" type="VP">
          <tokens>
            <token id="5" string="was" />
            <token id="6" string="swearing" />
            <token id="7" string="to" />
            <token id="8" string="try" />
            <token id="9" string="to" />
            <token id="10" string="alleviate" />
            <token id="11" string="his" />
            <token id="12" string="fear" />
          </tokens>
        </chunking>
        <chunking id="10" string="to try to alleviate his fear" type="VP">
          <tokens>
            <token id="7" string="to" />
            <token id="8" string="try" />
            <token id="9" string="to" />
            <token id="10" string="alleviate" />
            <token id="11" string="his" />
            <token id="12" string="fear" />
          </tokens>
        </chunking>
        <chunking id="11" string="Dickey" type="NP">
          <tokens>
            <token id="1" string="Dickey" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">Dickey</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">swearing</governor>
          <dependent id="3">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">swearing</governor>
          <dependent id="4">he</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">swearing</governor>
          <dependent id="5">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="6">swearing</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">try</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="6">swearing</governor>
          <dependent id="8">try</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">alleviate</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="8">try</governor>
          <dependent id="10">alleviate</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="12">fear</governor>
          <dependent id="11">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">alleviate</governor>
          <dependent id="12">fear</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Dickey" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Dickey" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="31" has_coreference="true">
      <content>He testified that he thought Jackson, who immediately stepped out of the car after it came to a halt, might be trying to provide a diversion for an armed partner in the car.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="testified" lemma="testify" stem="testifi" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="thought" lemma="think" stem="thought" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="immediately" lemma="immediately" stem="immedi" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="stepped" lemma="step" stem="step" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="out" lemma="out" stem="out" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="car" lemma="car" stem="car" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="came" lemma="come" stem="came" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="halt" lemma="halt" stem="halt" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="might" lemma="might" stem="might" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="trying" lemma="try" stem="try" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="provide" lemma="provide" stem="provid" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="diversion" lemma="diversion" stem="divers" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="armed" lemma="armed" stem="arm" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="partner" lemma="partner" stem="partner" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="35" string="car" lemma="car" stem="car" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="36" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VBD testified) (SBAR (IN that) (S (NP (PRP he)) (VP (VBD thought) (SBAR (S (NP (NP (NNP Jackson)) (, ,) (SBAR (WHNP (WP who)) (S (ADVP (RB immediately)) (VP (VBD stepped) (ADVP (IN out) (PP (IN of) (NP (DT the) (NN car)))) (SBAR (IN after) (S (NP (PRP it)) (VP (VBD came) (PP (TO to) (NP (DT a) (NN halt))))))))) (, ,)) (VP (MD might) (VP (VB be) (VP (VBG trying) (S (VP (TO to) (VP (VB provide) (NP (DT a) (NN diversion)) (PP (IN for) (NP (NP (DT an) (JJ armed) (NN partner)) (PP (IN in) (NP (DT the) (NN car))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="testified that he thought Jackson , who immediately stepped out of the car after it came to a halt , might be trying to provide a diversion for an armed partner in the car" type="VP">
          <tokens>
            <token id="2" string="testified" />
            <token id="3" string="that" />
            <token id="4" string="he" />
            <token id="5" string="thought" />
            <token id="6" string="Jackson" />
            <token id="7" string="," />
            <token id="8" string="who" />
            <token id="9" string="immediately" />
            <token id="10" string="stepped" />
            <token id="11" string="out" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="car" />
            <token id="15" string="after" />
            <token id="16" string="it" />
            <token id="17" string="came" />
            <token id="18" string="to" />
            <token id="19" string="a" />
            <token id="20" string="halt" />
            <token id="21" string="," />
            <token id="22" string="might" />
            <token id="23" string="be" />
            <token id="24" string="trying" />
            <token id="25" string="to" />
            <token id="26" string="provide" />
            <token id="27" string="a" />
            <token id="28" string="diversion" />
            <token id="29" string="for" />
            <token id="30" string="an" />
            <token id="31" string="armed" />
            <token id="32" string="partner" />
            <token id="33" string="in" />
            <token id="34" string="the" />
            <token id="35" string="car" />
          </tokens>
        </chunking>
        <chunking id="2" string="thought Jackson , who immediately stepped out of the car after it came to a halt , might be trying to provide a diversion for an armed partner in the car" type="VP">
          <tokens>
            <token id="5" string="thought" />
            <token id="6" string="Jackson" />
            <token id="7" string="," />
            <token id="8" string="who" />
            <token id="9" string="immediately" />
            <token id="10" string="stepped" />
            <token id="11" string="out" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="car" />
            <token id="15" string="after" />
            <token id="16" string="it" />
            <token id="17" string="came" />
            <token id="18" string="to" />
            <token id="19" string="a" />
            <token id="20" string="halt" />
            <token id="21" string="," />
            <token id="22" string="might" />
            <token id="23" string="be" />
            <token id="24" string="trying" />
            <token id="25" string="to" />
            <token id="26" string="provide" />
            <token id="27" string="a" />
            <token id="28" string="diversion" />
            <token id="29" string="for" />
            <token id="30" string="an" />
            <token id="31" string="armed" />
            <token id="32" string="partner" />
            <token id="33" string="in" />
            <token id="34" string="the" />
            <token id="35" string="car" />
          </tokens>
        </chunking>
        <chunking id="3" string="stepped out of the car after it came to a halt" type="VP">
          <tokens>
            <token id="10" string="stepped" />
            <token id="11" string="out" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="car" />
            <token id="15" string="after" />
            <token id="16" string="it" />
            <token id="17" string="came" />
            <token id="18" string="to" />
            <token id="19" string="a" />
            <token id="20" string="halt" />
          </tokens>
        </chunking>
        <chunking id="4" string="Jackson , who immediately stepped out of the car after it came to a halt ," type="NP">
          <tokens>
            <token id="6" string="Jackson" />
            <token id="7" string="," />
            <token id="8" string="who" />
            <token id="9" string="immediately" />
            <token id="10" string="stepped" />
            <token id="11" string="out" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="car" />
            <token id="15" string="after" />
            <token id="16" string="it" />
            <token id="17" string="came" />
            <token id="18" string="to" />
            <token id="19" string="a" />
            <token id="20" string="halt" />
            <token id="21" string="," />
          </tokens>
        </chunking>
        <chunking id="5" string="came to a halt" type="VP">
          <tokens>
            <token id="17" string="came" />
            <token id="18" string="to" />
            <token id="19" string="a" />
            <token id="20" string="halt" />
          </tokens>
        </chunking>
        <chunking id="6" string="a halt" type="NP">
          <tokens>
            <token id="19" string="a" />
            <token id="20" string="halt" />
          </tokens>
        </chunking>
        <chunking id="7" string="trying to provide a diversion for an armed partner in the car" type="VP">
          <tokens>
            <token id="24" string="trying" />
            <token id="25" string="to" />
            <token id="26" string="provide" />
            <token id="27" string="a" />
            <token id="28" string="diversion" />
            <token id="29" string="for" />
            <token id="30" string="an" />
            <token id="31" string="armed" />
            <token id="32" string="partner" />
            <token id="33" string="in" />
            <token id="34" string="the" />
            <token id="35" string="car" />
          </tokens>
        </chunking>
        <chunking id="8" string="Jackson" type="NP">
          <tokens>
            <token id="6" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="9" string="it" type="NP">
          <tokens>
            <token id="16" string="it" />
          </tokens>
        </chunking>
        <chunking id="10" string="an armed partner in the car" type="NP">
          <tokens>
            <token id="30" string="an" />
            <token id="31" string="armed" />
            <token id="32" string="partner" />
            <token id="33" string="in" />
            <token id="34" string="the" />
            <token id="35" string="car" />
          </tokens>
        </chunking>
        <chunking id="11" string="after it came to a halt" type="SBAR">
          <tokens>
            <token id="15" string="after" />
            <token id="16" string="it" />
            <token id="17" string="came" />
            <token id="18" string="to" />
            <token id="19" string="a" />
            <token id="20" string="halt" />
          </tokens>
        </chunking>
        <chunking id="12" string="Jackson , who immediately stepped out of the car after it came to a halt , might be trying to provide a diversion for an armed partner in the car" type="SBAR">
          <tokens>
            <token id="6" string="Jackson" />
            <token id="7" string="," />
            <token id="8" string="who" />
            <token id="9" string="immediately" />
            <token id="10" string="stepped" />
            <token id="11" string="out" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="car" />
            <token id="15" string="after" />
            <token id="16" string="it" />
            <token id="17" string="came" />
            <token id="18" string="to" />
            <token id="19" string="a" />
            <token id="20" string="halt" />
            <token id="21" string="," />
            <token id="22" string="might" />
            <token id="23" string="be" />
            <token id="24" string="trying" />
            <token id="25" string="to" />
            <token id="26" string="provide" />
            <token id="27" string="a" />
            <token id="28" string="diversion" />
            <token id="29" string="for" />
            <token id="30" string="an" />
            <token id="31" string="armed" />
            <token id="32" string="partner" />
            <token id="33" string="in" />
            <token id="34" string="the" />
            <token id="35" string="car" />
          </tokens>
        </chunking>
        <chunking id="13" string="the car" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="car" />
          </tokens>
        </chunking>
        <chunking id="14" string="be trying to provide a diversion for an armed partner in the car" type="VP">
          <tokens>
            <token id="23" string="be" />
            <token id="24" string="trying" />
            <token id="25" string="to" />
            <token id="26" string="provide" />
            <token id="27" string="a" />
            <token id="28" string="diversion" />
            <token id="29" string="for" />
            <token id="30" string="an" />
            <token id="31" string="armed" />
            <token id="32" string="partner" />
            <token id="33" string="in" />
            <token id="34" string="the" />
            <token id="35" string="car" />
          </tokens>
        </chunking>
        <chunking id="15" string="to provide a diversion for an armed partner in the car" type="VP">
          <tokens>
            <token id="25" string="to" />
            <token id="26" string="provide" />
            <token id="27" string="a" />
            <token id="28" string="diversion" />
            <token id="29" string="for" />
            <token id="30" string="an" />
            <token id="31" string="armed" />
            <token id="32" string="partner" />
            <token id="33" string="in" />
            <token id="34" string="the" />
            <token id="35" string="car" />
          </tokens>
        </chunking>
        <chunking id="16" string="provide a diversion for an armed partner in the car" type="VP">
          <tokens>
            <token id="26" string="provide" />
            <token id="27" string="a" />
            <token id="28" string="diversion" />
            <token id="29" string="for" />
            <token id="30" string="an" />
            <token id="31" string="armed" />
            <token id="32" string="partner" />
            <token id="33" string="in" />
            <token id="34" string="the" />
            <token id="35" string="car" />
          </tokens>
        </chunking>
        <chunking id="17" string="an armed partner" type="NP">
          <tokens>
            <token id="30" string="an" />
            <token id="31" string="armed" />
            <token id="32" string="partner" />
          </tokens>
        </chunking>
        <chunking id="18" string="a diversion" type="NP">
          <tokens>
            <token id="27" string="a" />
            <token id="28" string="diversion" />
          </tokens>
        </chunking>
        <chunking id="19" string="that he thought Jackson , who immediately stepped out of the car after it came to a halt , might be trying to provide a diversion for an armed partner in the car" type="SBAR">
          <tokens>
            <token id="3" string="that" />
            <token id="4" string="he" />
            <token id="5" string="thought" />
            <token id="6" string="Jackson" />
            <token id="7" string="," />
            <token id="8" string="who" />
            <token id="9" string="immediately" />
            <token id="10" string="stepped" />
            <token id="11" string="out" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="car" />
            <token id="15" string="after" />
            <token id="16" string="it" />
            <token id="17" string="came" />
            <token id="18" string="to" />
            <token id="19" string="a" />
            <token id="20" string="halt" />
            <token id="21" string="," />
            <token id="22" string="might" />
            <token id="23" string="be" />
            <token id="24" string="trying" />
            <token id="25" string="to" />
            <token id="26" string="provide" />
            <token id="27" string="a" />
            <token id="28" string="diversion" />
            <token id="29" string="for" />
            <token id="30" string="an" />
            <token id="31" string="armed" />
            <token id="32" string="partner" />
            <token id="33" string="in" />
            <token id="34" string="the" />
            <token id="35" string="car" />
          </tokens>
        </chunking>
        <chunking id="20" string="who immediately stepped out of the car after it came to a halt" type="SBAR">
          <tokens>
            <token id="8" string="who" />
            <token id="9" string="immediately" />
            <token id="10" string="stepped" />
            <token id="11" string="out" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="car" />
            <token id="15" string="after" />
            <token id="16" string="it" />
            <token id="17" string="came" />
            <token id="18" string="to" />
            <token id="19" string="a" />
            <token id="20" string="halt" />
          </tokens>
        </chunking>
        <chunking id="21" string="might be trying to provide a diversion for an armed partner in the car" type="VP">
          <tokens>
            <token id="22" string="might" />
            <token id="23" string="be" />
            <token id="24" string="trying" />
            <token id="25" string="to" />
            <token id="26" string="provide" />
            <token id="27" string="a" />
            <token id="28" string="diversion" />
            <token id="29" string="for" />
            <token id="30" string="an" />
            <token id="31" string="armed" />
            <token id="32" string="partner" />
            <token id="33" string="in" />
            <token id="34" string="the" />
            <token id="35" string="car" />
          </tokens>
        </chunking>
        <chunking id="22" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="23" string="he" type="NP">
          <tokens>
            <token id="4" string="he" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">testified</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">testified</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">thought</governor>
          <dependent id="3">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">thought</governor>
          <dependent id="4">he</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">testified</governor>
          <dependent id="5">thought</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">trying</governor>
          <dependent id="6">Jackson</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">stepped</governor>
          <dependent id="8">who</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">stepped</governor>
          <dependent id="9">immediately</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="6">Jackson</governor>
          <dependent id="10">stepped</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">car</governor>
          <dependent id="11">out</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="11">out</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">car</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">stepped</governor>
          <dependent id="14">car</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">came</governor>
          <dependent id="15">after</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">came</governor>
          <dependent id="16">it</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="10">stepped</governor>
          <dependent id="17">came</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">halt</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">halt</governor>
          <dependent id="19">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">came</governor>
          <dependent id="20">halt</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="24">trying</governor>
          <dependent id="22">might</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="24">trying</governor>
          <dependent id="23">be</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">thought</governor>
          <dependent id="24">trying</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="26">provide</governor>
          <dependent id="25">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="24">trying</governor>
          <dependent id="26">provide</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">diversion</governor>
          <dependent id="27">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="26">provide</governor>
          <dependent id="28">diversion</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">partner</governor>
          <dependent id="29">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="32">partner</governor>
          <dependent id="30">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="32">partner</governor>
          <dependent id="31">armed</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">provide</governor>
          <dependent id="32">partner</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">car</governor>
          <dependent id="33">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="35">car</governor>
          <dependent id="34">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="32">partner</governor>
          <dependent id="35">car</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Jackson" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Jackson" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="32" has_coreference="true">
      <content>He said his actions were an attempt to &amp;quot;accomplish my No. 1 job that night: to go home in one piece.&amp;quot;</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="actions" lemma="action" stem="action" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="attempt" lemma="attempt" stem="attempt" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="accomplish" lemma="accomplish" stem="accomplish" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="my" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="No." lemma="no." stem="no." pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="1" lemma="1" stem="1" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="14" string="job" lemma="job" stem="job" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="night" lemma="night" stem="night" pos="NN" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="true" />
        <token id="17" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="go" lemma="go" stem="go" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="home" lemma="home" stem="home" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="23" string="piece" lemma="piece" stem="piec" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VBD said) (SBAR (S (NP (PRP$ his) (NNS actions)) (VP (VBD were) (NP (NP (DT an) (NN attempt) (S (VP (TO to) (`` ``) (VP (VB accomplish) (NP (NP (PRP$ my) (NN No.) (CD 1) (NN job)) (SBAR (WHNP (WDT that)))) (NP-TMP (NN night)))))) (: :) (S (VP (TO to) (VP (VB go) (NP (NN home)) (PP (IN in) (NP (CD one) (NN piece))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="to go home in one piece" type="VP">
          <tokens>
            <token id="18" string="to" />
            <token id="19" string="go" />
            <token id="20" string="home" />
            <token id="21" string="in" />
            <token id="22" string="one" />
            <token id="23" string="piece" />
          </tokens>
        </chunking>
        <chunking id="2" string="my No. 1 job" type="NP">
          <tokens>
            <token id="11" string="my" />
            <token id="12" string="No." />
            <token id="13" string="1" />
            <token id="14" string="job" />
          </tokens>
        </chunking>
        <chunking id="3" string="his actions" type="NP">
          <tokens>
            <token id="3" string="his" />
            <token id="4" string="actions" />
          </tokens>
        </chunking>
        <chunking id="4" string="to `` accomplish my No. 1 job that night" type="VP">
          <tokens>
            <token id="8" string="to" />
            <token id="9" string="&quot;" />
            <token id="10" string="accomplish" />
            <token id="11" string="my" />
            <token id="12" string="No." />
            <token id="13" string="1" />
            <token id="14" string="job" />
            <token id="15" string="that" />
            <token id="16" string="night" />
          </tokens>
        </chunking>
        <chunking id="5" string="my No. 1 job that" type="NP">
          <tokens>
            <token id="11" string="my" />
            <token id="12" string="No." />
            <token id="13" string="1" />
            <token id="14" string="job" />
            <token id="15" string="that" />
          </tokens>
        </chunking>
        <chunking id="6" string="said his actions were an attempt to `` accomplish my No. 1 job that night : to go home in one piece" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="his" />
            <token id="4" string="actions" />
            <token id="5" string="were" />
            <token id="6" string="an" />
            <token id="7" string="attempt" />
            <token id="8" string="to" />
            <token id="9" string="&quot;" />
            <token id="10" string="accomplish" />
            <token id="11" string="my" />
            <token id="12" string="No." />
            <token id="13" string="1" />
            <token id="14" string="job" />
            <token id="15" string="that" />
            <token id="16" string="night" />
            <token id="17" string=":" />
            <token id="18" string="to" />
            <token id="19" string="go" />
            <token id="20" string="home" />
            <token id="21" string="in" />
            <token id="22" string="one" />
            <token id="23" string="piece" />
          </tokens>
        </chunking>
        <chunking id="7" string="one piece" type="NP">
          <tokens>
            <token id="22" string="one" />
            <token id="23" string="piece" />
          </tokens>
        </chunking>
        <chunking id="8" string="were an attempt to `` accomplish my No. 1 job that night : to go home in one piece" type="VP">
          <tokens>
            <token id="5" string="were" />
            <token id="6" string="an" />
            <token id="7" string="attempt" />
            <token id="8" string="to" />
            <token id="9" string="&quot;" />
            <token id="10" string="accomplish" />
            <token id="11" string="my" />
            <token id="12" string="No." />
            <token id="13" string="1" />
            <token id="14" string="job" />
            <token id="15" string="that" />
            <token id="16" string="night" />
            <token id="17" string=":" />
            <token id="18" string="to" />
            <token id="19" string="go" />
            <token id="20" string="home" />
            <token id="21" string="in" />
            <token id="22" string="one" />
            <token id="23" string="piece" />
          </tokens>
        </chunking>
        <chunking id="9" string="an attempt to `` accomplish my No. 1 job that night : to go home in one piece" type="NP">
          <tokens>
            <token id="6" string="an" />
            <token id="7" string="attempt" />
            <token id="8" string="to" />
            <token id="9" string="&quot;" />
            <token id="10" string="accomplish" />
            <token id="11" string="my" />
            <token id="12" string="No." />
            <token id="13" string="1" />
            <token id="14" string="job" />
            <token id="15" string="that" />
            <token id="16" string="night" />
            <token id="17" string=":" />
            <token id="18" string="to" />
            <token id="19" string="go" />
            <token id="20" string="home" />
            <token id="21" string="in" />
            <token id="22" string="one" />
            <token id="23" string="piece" />
          </tokens>
        </chunking>
        <chunking id="10" string="home" type="NP">
          <tokens>
            <token id="20" string="home" />
          </tokens>
        </chunking>
        <chunking id="11" string="his actions were an attempt to `` accomplish my No. 1 job that night : to go home in one piece" type="SBAR">
          <tokens>
            <token id="3" string="his" />
            <token id="4" string="actions" />
            <token id="5" string="were" />
            <token id="6" string="an" />
            <token id="7" string="attempt" />
            <token id="8" string="to" />
            <token id="9" string="&quot;" />
            <token id="10" string="accomplish" />
            <token id="11" string="my" />
            <token id="12" string="No." />
            <token id="13" string="1" />
            <token id="14" string="job" />
            <token id="15" string="that" />
            <token id="16" string="night" />
            <token id="17" string=":" />
            <token id="18" string="to" />
            <token id="19" string="go" />
            <token id="20" string="home" />
            <token id="21" string="in" />
            <token id="22" string="one" />
            <token id="23" string="piece" />
          </tokens>
        </chunking>
        <chunking id="12" string="that" type="SBAR">
          <tokens>
            <token id="15" string="that" />
          </tokens>
        </chunking>
        <chunking id="13" string="go home in one piece" type="VP">
          <tokens>
            <token id="19" string="go" />
            <token id="20" string="home" />
            <token id="21" string="in" />
            <token id="22" string="one" />
            <token id="23" string="piece" />
          </tokens>
        </chunking>
        <chunking id="14" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="15" string="an attempt to `` accomplish my No. 1 job that night" type="NP">
          <tokens>
            <token id="6" string="an" />
            <token id="7" string="attempt" />
            <token id="8" string="to" />
            <token id="9" string="&quot;" />
            <token id="10" string="accomplish" />
            <token id="11" string="my" />
            <token id="12" string="No." />
            <token id="13" string="1" />
            <token id="14" string="job" />
            <token id="15" string="that" />
            <token id="16" string="night" />
          </tokens>
        </chunking>
        <chunking id="16" string="accomplish my No. 1 job that night" type="VP">
          <tokens>
            <token id="10" string="accomplish" />
            <token id="11" string="my" />
            <token id="12" string="No." />
            <token id="13" string="1" />
            <token id="14" string="job" />
            <token id="15" string="that" />
            <token id="16" string="night" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">actions</governor>
          <dependent id="3">his</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">attempt</governor>
          <dependent id="4">actions</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">attempt</governor>
          <dependent id="5">were</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">attempt</governor>
          <dependent id="6">an</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="7">attempt</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">accomplish</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="7">attempt</governor>
          <dependent id="10">accomplish</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="14">job</governor>
          <dependent id="11">my</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">job</governor>
          <dependent id="12">No.</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="14">job</governor>
          <dependent id="13">1</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">accomplish</governor>
          <dependent id="14">job</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="14">job</governor>
          <dependent id="15">that</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="10">accomplish</governor>
          <dependent id="16">night</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">go</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="7">attempt</governor>
          <dependent id="19">go</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">go</governor>
          <dependent id="20">home</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">piece</governor>
          <dependent id="21">in</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="23">piece</governor>
          <dependent id="22">one</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">go</governor>
          <dependent id="23">piece</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1" type="NUMBER" score="0.0">
          <tokens>
            <token id="13" string="1" />
          </tokens>
        </entity>
        <entity id="2" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="22" string="one" />
          </tokens>
        </entity>
        <entity id="3" string="night" type="TIME" score="0.0">
          <tokens>
            <token id="16" string="night" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="33" has_coreference="true">
      <content>At one point in the proceeding, Boatwright had Dickey and Jackson weighed in an attempt to show that Jackson is shorter and weighs less than the officer.</content>
      <tokens>
        <token id="1" string="At" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="3" string="point" lemma="point" stem="point" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="proceeding" lemma="proceeding" stem="proceed" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Boatwright" lemma="Boatwright" stem="boatwright" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="9" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Dickey" lemma="Dickey" stem="dickei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="13" string="weighed" lemma="weigh" stem="weigh" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="attempt" lemma="attempt" stem="attempt" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="show" lemma="show" stem="show" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="21" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="shorter" lemma="shorter" stem="shorter" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="weighs" lemma="weigh" stem="weigh" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="less" lemma="less" stem="less" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="28" string="officer" lemma="officer" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN At) (NP (NP (CD one) (NN point)) (PP (IN in) (NP (DT the) (NN proceeding))))) (, ,) (NP (NNP Boatwright)) (VP (VP (VBD had) (S (NP (NNP Dickey) (CC and) (NNP Jackson)) (VP (VBD weighed) (PP (IN in) (NP (DT an) (NN attempt))) (S (VP (TO to) (VP (VB show) (SBAR (IN that) (S (NP (NNP Jackson)) (VP (VBZ is) (ADJP (JJR shorter))))))))))) (CC and) (VP (VBZ weighs) (NP (JJR less)) (PP (IN than) (NP (DT the) (NN officer))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="show that Jackson is shorter" type="VP">
          <tokens>
            <token id="18" string="show" />
            <token id="19" string="that" />
            <token id="20" string="Jackson" />
            <token id="21" string="is" />
            <token id="22" string="shorter" />
          </tokens>
        </chunking>
        <chunking id="2" string="the proceeding" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="proceeding" />
          </tokens>
        </chunking>
        <chunking id="3" string="one point" type="NP">
          <tokens>
            <token id="2" string="one" />
            <token id="3" string="point" />
          </tokens>
        </chunking>
        <chunking id="4" string="one point in the proceeding" type="NP">
          <tokens>
            <token id="2" string="one" />
            <token id="3" string="point" />
            <token id="4" string="in" />
            <token id="5" string="the" />
            <token id="6" string="proceeding" />
          </tokens>
        </chunking>
        <chunking id="5" string="Jackson" type="NP">
          <tokens>
            <token id="20" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="6" string="less" type="NP">
          <tokens>
            <token id="25" string="less" />
          </tokens>
        </chunking>
        <chunking id="7" string="the officer" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="officer" />
          </tokens>
        </chunking>
        <chunking id="8" string="is shorter" type="VP">
          <tokens>
            <token id="21" string="is" />
            <token id="22" string="shorter" />
          </tokens>
        </chunking>
        <chunking id="9" string="Boatwright" type="NP">
          <tokens>
            <token id="8" string="Boatwright" />
          </tokens>
        </chunking>
        <chunking id="10" string="had Dickey and Jackson weighed in an attempt to show that Jackson is shorter and weighs less than the officer" type="VP">
          <tokens>
            <token id="9" string="had" />
            <token id="10" string="Dickey" />
            <token id="11" string="and" />
            <token id="12" string="Jackson" />
            <token id="13" string="weighed" />
            <token id="14" string="in" />
            <token id="15" string="an" />
            <token id="16" string="attempt" />
            <token id="17" string="to" />
            <token id="18" string="show" />
            <token id="19" string="that" />
            <token id="20" string="Jackson" />
            <token id="21" string="is" />
            <token id="22" string="shorter" />
            <token id="23" string="and" />
            <token id="24" string="weighs" />
            <token id="25" string="less" />
            <token id="26" string="than" />
            <token id="27" string="the" />
            <token id="28" string="officer" />
          </tokens>
        </chunking>
        <chunking id="11" string="weighed in an attempt to show that Jackson is shorter" type="VP">
          <tokens>
            <token id="13" string="weighed" />
            <token id="14" string="in" />
            <token id="15" string="an" />
            <token id="16" string="attempt" />
            <token id="17" string="to" />
            <token id="18" string="show" />
            <token id="19" string="that" />
            <token id="20" string="Jackson" />
            <token id="21" string="is" />
            <token id="22" string="shorter" />
          </tokens>
        </chunking>
        <chunking id="12" string="to show that Jackson is shorter" type="VP">
          <tokens>
            <token id="17" string="to" />
            <token id="18" string="show" />
            <token id="19" string="that" />
            <token id="20" string="Jackson" />
            <token id="21" string="is" />
            <token id="22" string="shorter" />
          </tokens>
        </chunking>
        <chunking id="13" string="Dickey and Jackson" type="NP">
          <tokens>
            <token id="10" string="Dickey" />
            <token id="11" string="and" />
            <token id="12" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="14" string="an attempt" type="NP">
          <tokens>
            <token id="15" string="an" />
            <token id="16" string="attempt" />
          </tokens>
        </chunking>
        <chunking id="15" string="that Jackson is shorter" type="SBAR">
          <tokens>
            <token id="19" string="that" />
            <token id="20" string="Jackson" />
            <token id="21" string="is" />
            <token id="22" string="shorter" />
          </tokens>
        </chunking>
        <chunking id="16" string="weighs less than the officer" type="VP">
          <tokens>
            <token id="24" string="weighs" />
            <token id="25" string="less" />
            <token id="26" string="than" />
            <token id="27" string="the" />
            <token id="28" string="officer" />
          </tokens>
        </chunking>
        <chunking id="17" string="had Dickey and Jackson weighed in an attempt to show that Jackson is shorter" type="VP">
          <tokens>
            <token id="9" string="had" />
            <token id="10" string="Dickey" />
            <token id="11" string="and" />
            <token id="12" string="Jackson" />
            <token id="13" string="weighed" />
            <token id="14" string="in" />
            <token id="15" string="an" />
            <token id="16" string="attempt" />
            <token id="17" string="to" />
            <token id="18" string="show" />
            <token id="19" string="that" />
            <token id="20" string="Jackson" />
            <token id="21" string="is" />
            <token id="22" string="shorter" />
          </tokens>
        </chunking>
        <chunking id="18" string="shorter" type="ADJP">
          <tokens>
            <token id="22" string="shorter" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">point</governor>
          <dependent id="1">At</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="3">point</governor>
          <dependent id="2">one</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">had</governor>
          <dependent id="3">point</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">proceeding</governor>
          <dependent id="4">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">proceeding</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">point</governor>
          <dependent id="6">proceeding</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">had</governor>
          <dependent id="8">Boatwright</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">had</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">weighed</governor>
          <dependent id="10">Dickey</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">Dickey</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">Dickey</governor>
          <dependent id="12">Jackson</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="9">had</governor>
          <dependent id="13">weighed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">attempt</governor>
          <dependent id="14">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">attempt</governor>
          <dependent id="15">an</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">weighed</governor>
          <dependent id="16">attempt</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">show</governor>
          <dependent id="17">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="13">weighed</governor>
          <dependent id="18">show</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">shorter</governor>
          <dependent id="19">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">shorter</governor>
          <dependent id="20">Jackson</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="22">shorter</governor>
          <dependent id="21">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="18">show</governor>
          <dependent id="22">shorter</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">had</governor>
          <dependent id="23">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">had</governor>
          <dependent id="24">weighs</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="24">weighs</governor>
          <dependent id="25">less</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">officer</governor>
          <dependent id="26">than</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">officer</governor>
          <dependent id="27">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">weighs</governor>
          <dependent id="28">officer</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="2" string="one" />
          </tokens>
        </entity>
        <entity id="2" string="Jackson" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Jackson" />
          </tokens>
        </entity>
        <entity id="3" string="Boatwright" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Boatwright" />
          </tokens>
        </entity>
        <entity id="4" string="Dickey" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Dickey" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="34" has_coreference="true">
      <content>At another point, Boatwright assumed the role of Dickey and had Dickey play Jackson in trying to demonstrate the type of hold Dickey used on Jackson during the arrest.</content>
      <tokens>
        <token id="1" string="At" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="another" lemma="another" stem="anoth" pos="DT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="point" lemma="point" stem="point" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Boatwright" lemma="Boatwright" stem="boatwright" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="6" string="assumed" lemma="assume" stem="assum" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="role" lemma="role" stem="role" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Dickey" lemma="Dickey" stem="dickei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Dickey" lemma="Dickey" stem="dickei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="14" string="play" lemma="play" stem="plai" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="16" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="trying" lemma="try" stem="try" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="demonstrate" lemma="demonstrate" stem="demonstr" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="21" string="type" lemma="type" stem="type" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="22" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="23" string="hold" lemma="hold" stem="hold" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="24" string="Dickey" lemma="Dickey" stem="dickei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="25" string="used" lemma="use" stem="us" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="26" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="27" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="28" string="during" lemma="during" stem="dure" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="29" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="30" string="arrest" lemma="arrest" stem="arrest" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="31" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN At) (NP (DT another) (NN point))) (, ,) (NP (NNP Boatwright)) (VP (VP (VBD assumed) (NP (NP (DT the) (NN role)) (PP (IN of) (NP (NNP Dickey))))) (CC and) (VP (VBD had) (S (NP (NNP Dickey)) (VP (VB play) (NP (NP (NNP Jackson)) (PP (IN in) (S (VP (VBG trying) (S (VP (TO to) (VP (VB demonstrate) (NP (NP (DT the) (NN type)) (PP (IN of) (NP (NP (NN hold) (NNP Dickey)) (VP (VBN used) (PP (IN on) (NP (NNP Jackson))) (PP (IN during) (NP (DT the) (NN arrest)))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the role of Dickey" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="role" />
            <token id="9" string="of" />
            <token id="10" string="Dickey" />
          </tokens>
        </chunking>
        <chunking id="2" string="used on Jackson during the arrest" type="VP">
          <tokens>
            <token id="25" string="used" />
            <token id="26" string="on" />
            <token id="27" string="Jackson" />
            <token id="28" string="during" />
            <token id="29" string="the" />
            <token id="30" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="3" string="hold Dickey used on Jackson during the arrest" type="NP">
          <tokens>
            <token id="23" string="hold" />
            <token id="24" string="Dickey" />
            <token id="25" string="used" />
            <token id="26" string="on" />
            <token id="27" string="Jackson" />
            <token id="28" string="during" />
            <token id="29" string="the" />
            <token id="30" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="4" string="the role" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="role" />
          </tokens>
        </chunking>
        <chunking id="5" string="the arrest" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="6" string="Jackson" type="NP">
          <tokens>
            <token id="15" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="7" string="the type" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="type" />
          </tokens>
        </chunking>
        <chunking id="8" string="Boatwright" type="NP">
          <tokens>
            <token id="5" string="Boatwright" />
          </tokens>
        </chunking>
        <chunking id="9" string="Jackson in trying to demonstrate the type of hold Dickey used on Jackson during the arrest" type="NP">
          <tokens>
            <token id="15" string="Jackson" />
            <token id="16" string="in" />
            <token id="17" string="trying" />
            <token id="18" string="to" />
            <token id="19" string="demonstrate" />
            <token id="20" string="the" />
            <token id="21" string="type" />
            <token id="22" string="of" />
            <token id="23" string="hold" />
            <token id="24" string="Dickey" />
            <token id="25" string="used" />
            <token id="26" string="on" />
            <token id="27" string="Jackson" />
            <token id="28" string="during" />
            <token id="29" string="the" />
            <token id="30" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="10" string="demonstrate the type of hold Dickey used on Jackson during the arrest" type="VP">
          <tokens>
            <token id="19" string="demonstrate" />
            <token id="20" string="the" />
            <token id="21" string="type" />
            <token id="22" string="of" />
            <token id="23" string="hold" />
            <token id="24" string="Dickey" />
            <token id="25" string="used" />
            <token id="26" string="on" />
            <token id="27" string="Jackson" />
            <token id="28" string="during" />
            <token id="29" string="the" />
            <token id="30" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="11" string="the type of hold Dickey used on Jackson during the arrest" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="type" />
            <token id="22" string="of" />
            <token id="23" string="hold" />
            <token id="24" string="Dickey" />
            <token id="25" string="used" />
            <token id="26" string="on" />
            <token id="27" string="Jackson" />
            <token id="28" string="during" />
            <token id="29" string="the" />
            <token id="30" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="12" string="assumed the role of Dickey" type="VP">
          <tokens>
            <token id="6" string="assumed" />
            <token id="7" string="the" />
            <token id="8" string="role" />
            <token id="9" string="of" />
            <token id="10" string="Dickey" />
          </tokens>
        </chunking>
        <chunking id="13" string="had Dickey play Jackson in trying to demonstrate the type of hold Dickey used on Jackson during the arrest" type="VP">
          <tokens>
            <token id="12" string="had" />
            <token id="13" string="Dickey" />
            <token id="14" string="play" />
            <token id="15" string="Jackson" />
            <token id="16" string="in" />
            <token id="17" string="trying" />
            <token id="18" string="to" />
            <token id="19" string="demonstrate" />
            <token id="20" string="the" />
            <token id="21" string="type" />
            <token id="22" string="of" />
            <token id="23" string="hold" />
            <token id="24" string="Dickey" />
            <token id="25" string="used" />
            <token id="26" string="on" />
            <token id="27" string="Jackson" />
            <token id="28" string="during" />
            <token id="29" string="the" />
            <token id="30" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="14" string="trying to demonstrate the type of hold Dickey used on Jackson during the arrest" type="VP">
          <tokens>
            <token id="17" string="trying" />
            <token id="18" string="to" />
            <token id="19" string="demonstrate" />
            <token id="20" string="the" />
            <token id="21" string="type" />
            <token id="22" string="of" />
            <token id="23" string="hold" />
            <token id="24" string="Dickey" />
            <token id="25" string="used" />
            <token id="26" string="on" />
            <token id="27" string="Jackson" />
            <token id="28" string="during" />
            <token id="29" string="the" />
            <token id="30" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="15" string="to demonstrate the type of hold Dickey used on Jackson during the arrest" type="VP">
          <tokens>
            <token id="18" string="to" />
            <token id="19" string="demonstrate" />
            <token id="20" string="the" />
            <token id="21" string="type" />
            <token id="22" string="of" />
            <token id="23" string="hold" />
            <token id="24" string="Dickey" />
            <token id="25" string="used" />
            <token id="26" string="on" />
            <token id="27" string="Jackson" />
            <token id="28" string="during" />
            <token id="29" string="the" />
            <token id="30" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="16" string="play Jackson in trying to demonstrate the type of hold Dickey used on Jackson during the arrest" type="VP">
          <tokens>
            <token id="14" string="play" />
            <token id="15" string="Jackson" />
            <token id="16" string="in" />
            <token id="17" string="trying" />
            <token id="18" string="to" />
            <token id="19" string="demonstrate" />
            <token id="20" string="the" />
            <token id="21" string="type" />
            <token id="22" string="of" />
            <token id="23" string="hold" />
            <token id="24" string="Dickey" />
            <token id="25" string="used" />
            <token id="26" string="on" />
            <token id="27" string="Jackson" />
            <token id="28" string="during" />
            <token id="29" string="the" />
            <token id="30" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="17" string="another point" type="NP">
          <tokens>
            <token id="2" string="another" />
            <token id="3" string="point" />
          </tokens>
        </chunking>
        <chunking id="18" string="assumed the role of Dickey and had Dickey play Jackson in trying to demonstrate the type of hold Dickey used on Jackson during the arrest" type="VP">
          <tokens>
            <token id="6" string="assumed" />
            <token id="7" string="the" />
            <token id="8" string="role" />
            <token id="9" string="of" />
            <token id="10" string="Dickey" />
            <token id="11" string="and" />
            <token id="12" string="had" />
            <token id="13" string="Dickey" />
            <token id="14" string="play" />
            <token id="15" string="Jackson" />
            <token id="16" string="in" />
            <token id="17" string="trying" />
            <token id="18" string="to" />
            <token id="19" string="demonstrate" />
            <token id="20" string="the" />
            <token id="21" string="type" />
            <token id="22" string="of" />
            <token id="23" string="hold" />
            <token id="24" string="Dickey" />
            <token id="25" string="used" />
            <token id="26" string="on" />
            <token id="27" string="Jackson" />
            <token id="28" string="during" />
            <token id="29" string="the" />
            <token id="30" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="19" string="hold Dickey" type="NP">
          <tokens>
            <token id="23" string="hold" />
            <token id="24" string="Dickey" />
          </tokens>
        </chunking>
        <chunking id="20" string="Dickey" type="NP">
          <tokens>
            <token id="10" string="Dickey" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">point</governor>
          <dependent id="1">At</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">point</governor>
          <dependent id="2">another</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">assumed</governor>
          <dependent id="3">point</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">assumed</governor>
          <dependent id="5">Boatwright</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">assumed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">role</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">assumed</governor>
          <dependent id="8">role</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">Dickey</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">role</governor>
          <dependent id="10">Dickey</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">assumed</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">assumed</governor>
          <dependent id="12">had</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">play</governor>
          <dependent id="13">Dickey</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="12">had</governor>
          <dependent id="14">play</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">play</governor>
          <dependent id="15">Jackson</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">trying</governor>
          <dependent id="16">in</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="15">Jackson</governor>
          <dependent id="17">trying</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">demonstrate</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="17">trying</governor>
          <dependent id="19">demonstrate</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">type</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">demonstrate</governor>
          <dependent id="21">type</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">Dickey</governor>
          <dependent id="22">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">Dickey</governor>
          <dependent id="23">hold</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">type</governor>
          <dependent id="24">Dickey</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="24">Dickey</governor>
          <dependent id="25">used</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">Jackson</governor>
          <dependent id="26">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">used</governor>
          <dependent id="27">Jackson</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">arrest</governor>
          <dependent id="28">during</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">arrest</governor>
          <dependent id="29">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">used</governor>
          <dependent id="30">arrest</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Jackson" type="PERSON" score="0.0">
          <tokens>
            <token id="15" string="Jackson" />
          </tokens>
        </entity>
        <entity id="2" string="Boatwright" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Boatwright" />
          </tokens>
        </entity>
        <entity id="3" string="Dickey" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Dickey" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="35" has_coreference="true">
      <content>Boatwright contended that in using that type of hold the officer would have had to push Jackson into the window deliberately.</content>
      <tokens>
        <token id="1" string="Boatwright" lemma="Boatwright" stem="boatwright" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="contended" lemma="contend" stem="contend" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="using" lemma="use" stem="us" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="type" lemma="type" stem="type" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="hold" lemma="hold" stem="hold" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="officer" lemma="officer" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="had" lemma="have" stem="had" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="push" lemma="push" stem="push" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="18" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="window" lemma="window" stem="window" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="21" string="deliberately" lemma="deliberately" stem="deliber" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Boatwright)) (VP (VBD contended) (SBAR (IN that) (S (PP (IN in) (S (VP (VBG using) (PP (IN that) (NP (NP (NN type)) (PP (IN of) (NP (NN hold)))))))) (NP (DT the) (NN officer)) (VP (MD would) (VP (VB have) (VP (VBN had) (S (VP (TO to) (VP (VB push) (NP (NNP Jackson)) (PP (IN into) (NP (DT the) (NN window))) (ADVP (RB deliberately))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the window" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="window" />
          </tokens>
        </chunking>
        <chunking id="2" string="to push Jackson into the window deliberately" type="VP">
          <tokens>
            <token id="15" string="to" />
            <token id="16" string="push" />
            <token id="17" string="Jackson" />
            <token id="18" string="into" />
            <token id="19" string="the" />
            <token id="20" string="window" />
            <token id="21" string="deliberately" />
          </tokens>
        </chunking>
        <chunking id="3" string="have had to push Jackson into the window deliberately" type="VP">
          <tokens>
            <token id="13" string="have" />
            <token id="14" string="had" />
            <token id="15" string="to" />
            <token id="16" string="push" />
            <token id="17" string="Jackson" />
            <token id="18" string="into" />
            <token id="19" string="the" />
            <token id="20" string="window" />
            <token id="21" string="deliberately" />
          </tokens>
        </chunking>
        <chunking id="4" string="the officer" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="officer" />
          </tokens>
        </chunking>
        <chunking id="5" string="Jackson" type="NP">
          <tokens>
            <token id="17" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="6" string="Boatwright" type="NP">
          <tokens>
            <token id="1" string="Boatwright" />
          </tokens>
        </chunking>
        <chunking id="7" string="would have had to push Jackson into the window deliberately" type="VP">
          <tokens>
            <token id="12" string="would" />
            <token id="13" string="have" />
            <token id="14" string="had" />
            <token id="15" string="to" />
            <token id="16" string="push" />
            <token id="17" string="Jackson" />
            <token id="18" string="into" />
            <token id="19" string="the" />
            <token id="20" string="window" />
            <token id="21" string="deliberately" />
          </tokens>
        </chunking>
        <chunking id="8" string="hold" type="NP">
          <tokens>
            <token id="9" string="hold" />
          </tokens>
        </chunking>
        <chunking id="9" string="type" type="NP">
          <tokens>
            <token id="7" string="type" />
          </tokens>
        </chunking>
        <chunking id="10" string="contended that in using that type of hold the officer would have had to push Jackson into the window deliberately" type="VP">
          <tokens>
            <token id="2" string="contended" />
            <token id="3" string="that" />
            <token id="4" string="in" />
            <token id="5" string="using" />
            <token id="6" string="that" />
            <token id="7" string="type" />
            <token id="8" string="of" />
            <token id="9" string="hold" />
            <token id="10" string="the" />
            <token id="11" string="officer" />
            <token id="12" string="would" />
            <token id="13" string="have" />
            <token id="14" string="had" />
            <token id="15" string="to" />
            <token id="16" string="push" />
            <token id="17" string="Jackson" />
            <token id="18" string="into" />
            <token id="19" string="the" />
            <token id="20" string="window" />
            <token id="21" string="deliberately" />
          </tokens>
        </chunking>
        <chunking id="11" string="had to push Jackson into the window deliberately" type="VP">
          <tokens>
            <token id="14" string="had" />
            <token id="15" string="to" />
            <token id="16" string="push" />
            <token id="17" string="Jackson" />
            <token id="18" string="into" />
            <token id="19" string="the" />
            <token id="20" string="window" />
            <token id="21" string="deliberately" />
          </tokens>
        </chunking>
        <chunking id="12" string="type of hold" type="NP">
          <tokens>
            <token id="7" string="type" />
            <token id="8" string="of" />
            <token id="9" string="hold" />
          </tokens>
        </chunking>
        <chunking id="13" string="push Jackson into the window deliberately" type="VP">
          <tokens>
            <token id="16" string="push" />
            <token id="17" string="Jackson" />
            <token id="18" string="into" />
            <token id="19" string="the" />
            <token id="20" string="window" />
            <token id="21" string="deliberately" />
          </tokens>
        </chunking>
        <chunking id="14" string="that in using that type of hold the officer would have had to push Jackson into the window deliberately" type="SBAR">
          <tokens>
            <token id="3" string="that" />
            <token id="4" string="in" />
            <token id="5" string="using" />
            <token id="6" string="that" />
            <token id="7" string="type" />
            <token id="8" string="of" />
            <token id="9" string="hold" />
            <token id="10" string="the" />
            <token id="11" string="officer" />
            <token id="12" string="would" />
            <token id="13" string="have" />
            <token id="14" string="had" />
            <token id="15" string="to" />
            <token id="16" string="push" />
            <token id="17" string="Jackson" />
            <token id="18" string="into" />
            <token id="19" string="the" />
            <token id="20" string="window" />
            <token id="21" string="deliberately" />
          </tokens>
        </chunking>
        <chunking id="15" string="using that type of hold" type="VP">
          <tokens>
            <token id="5" string="using" />
            <token id="6" string="that" />
            <token id="7" string="type" />
            <token id="8" string="of" />
            <token id="9" string="hold" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">contended</governor>
          <dependent id="1">Boatwright</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">contended</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">had</governor>
          <dependent id="3">that</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">using</governor>
          <dependent id="4">in</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="14">had</governor>
          <dependent id="5">using</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">type</governor>
          <dependent id="6">that</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">using</governor>
          <dependent id="7">type</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">hold</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">type</governor>
          <dependent id="9">hold</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">officer</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">had</governor>
          <dependent id="11">officer</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="14">had</governor>
          <dependent id="12">would</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="14">had</governor>
          <dependent id="13">have</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">contended</governor>
          <dependent id="14">had</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">push</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="14">had</governor>
          <dependent id="16">push</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">push</governor>
          <dependent id="17">Jackson</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">window</governor>
          <dependent id="18">into</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">window</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">push</governor>
          <dependent id="20">window</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">push</governor>
          <dependent id="21">deliberately</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Jackson" type="PERSON" score="0.0">
          <tokens>
            <token id="17" string="Jackson" />
          </tokens>
        </entity>
        <entity id="2" string="Boatwright" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Boatwright" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="36" has_coreference="true">
      <content>Dickey denied it.</content>
      <tokens>
        <token id="1" string="Dickey" lemma="Dickey" stem="dickei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="denied" lemma="deny" stem="deni" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Dickey)) (VP (VBD denied) (NP (PRP it))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="denied it" type="VP">
          <tokens>
            <token id="2" string="denied" />
            <token id="3" string="it" />
          </tokens>
        </chunking>
        <chunking id="2" string="it" type="NP">
          <tokens>
            <token id="3" string="it" />
          </tokens>
        </chunking>
        <chunking id="3" string="Dickey" type="NP">
          <tokens>
            <token id="1" string="Dickey" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">denied</governor>
          <dependent id="1">Dickey</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">denied</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">denied</governor>
          <dependent id="3">it</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Dickey" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Dickey" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="37" has_coreference="true">
      <content>The officer said Jackson&amp;apost;s face crashed through the window when Jackson suddenly pulled forward.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="officer" lemma="officer" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="5" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="face" lemma="face" stem="face" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="crashed" lemma="crash" stem="crash" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="window" lemma="window" stem="window" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="13" string="suddenly" lemma="suddenly" stem="suddenli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="pulled" lemma="pull" stem="pull" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="forward" lemma="forward" stem="forward" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN officer)) (VP (VBD said) (SBAR (S (NP (NP (NNP Jackson) (POS 's)) (NN face)) (VP (VBD crashed) (PP (IN through) (NP (DT the) (NN window))) (SBAR (WHADVP (WRB when)) (S (NP (NNP Jackson)) (ADVP (RB suddenly)) (VP (VBD pulled) (ADVP (RB forward))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="The officer" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="officer" />
          </tokens>
        </chunking>
        <chunking id="2" string="the window" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="window" />
          </tokens>
        </chunking>
        <chunking id="3" string="Jackson 's face" type="NP">
          <tokens>
            <token id="4" string="Jackson" />
            <token id="5" string="'s" />
            <token id="6" string="face" />
          </tokens>
        </chunking>
        <chunking id="4" string="said Jackson 's face crashed through the window when Jackson suddenly pulled forward" type="VP">
          <tokens>
            <token id="3" string="said" />
            <token id="4" string="Jackson" />
            <token id="5" string="'s" />
            <token id="6" string="face" />
            <token id="7" string="crashed" />
            <token id="8" string="through" />
            <token id="9" string="the" />
            <token id="10" string="window" />
            <token id="11" string="when" />
            <token id="12" string="Jackson" />
            <token id="13" string="suddenly" />
            <token id="14" string="pulled" />
            <token id="15" string="forward" />
          </tokens>
        </chunking>
        <chunking id="5" string="when Jackson suddenly pulled forward" type="SBAR">
          <tokens>
            <token id="11" string="when" />
            <token id="12" string="Jackson" />
            <token id="13" string="suddenly" />
            <token id="14" string="pulled" />
            <token id="15" string="forward" />
          </tokens>
        </chunking>
        <chunking id="6" string="Jackson 's face crashed through the window when Jackson suddenly pulled forward" type="SBAR">
          <tokens>
            <token id="4" string="Jackson" />
            <token id="5" string="'s" />
            <token id="6" string="face" />
            <token id="7" string="crashed" />
            <token id="8" string="through" />
            <token id="9" string="the" />
            <token id="10" string="window" />
            <token id="11" string="when" />
            <token id="12" string="Jackson" />
            <token id="13" string="suddenly" />
            <token id="14" string="pulled" />
            <token id="15" string="forward" />
          </tokens>
        </chunking>
        <chunking id="7" string="Jackson" type="NP">
          <tokens>
            <token id="12" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="8" string="Jackson 's" type="NP">
          <tokens>
            <token id="4" string="Jackson" />
            <token id="5" string="'s" />
          </tokens>
        </chunking>
        <chunking id="9" string="pulled forward" type="VP">
          <tokens>
            <token id="14" string="pulled" />
            <token id="15" string="forward" />
          </tokens>
        </chunking>
        <chunking id="10" string="when" type="WHADVP">
          <tokens>
            <token id="11" string="when" />
          </tokens>
        </chunking>
        <chunking id="11" string="crashed through the window when Jackson suddenly pulled forward" type="VP">
          <tokens>
            <token id="7" string="crashed" />
            <token id="8" string="through" />
            <token id="9" string="the" />
            <token id="10" string="window" />
            <token id="11" string="when" />
            <token id="12" string="Jackson" />
            <token id="13" string="suddenly" />
            <token id="14" string="pulled" />
            <token id="15" string="forward" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">officer</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">said</governor>
          <dependent id="2">officer</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">said</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="6">face</governor>
          <dependent id="4">Jackson</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">Jackson</governor>
          <dependent id="5">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">crashed</governor>
          <dependent id="6">face</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">said</governor>
          <dependent id="7">crashed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">window</governor>
          <dependent id="8">through</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">window</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">crashed</governor>
          <dependent id="10">window</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">pulled</governor>
          <dependent id="11">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">pulled</governor>
          <dependent id="12">Jackson</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">pulled</governor>
          <dependent id="13">suddenly</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="7">crashed</governor>
          <dependent id="14">pulled</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">pulled</governor>
          <dependent id="15">forward</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Jackson" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Jackson" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="38" has_coreference="true">
      <content>Jackson, according to Dickey, struck the window with his elbows and not with his face as Jackson contends.</content>
      <tokens>
        <token id="1" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="according" lemma="accord" stem="accord" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Dickey" lemma="Dickey" stem="dickei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="struck" lemma="strike" stem="struck" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="window" lemma="window" stem="window" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="elbows" lemma="elbow" stem="elbow" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="face" lemma="face" stem="face" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="20" string="contends" lemma="contend" stem="contend" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Jackson)) (, ,) (PP (VBG according) (PP (TO to) (NP (NNP Dickey)))) (, ,) (VP (VBD struck) (NP (DT the) (NN window)) (PP (PP (IN with) (NP (PRP$ his) (NNS elbows))) (CC and) (RB not) (PP (IN with) (NP (PRP$ his) (NN face)))) (SBAR (IN as) (S (NP (NNP Jackson)) (VP (VBZ contends))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="struck the window with his elbows and not with his face as Jackson contends" type="VP">
          <tokens>
            <token id="7" string="struck" />
            <token id="8" string="the" />
            <token id="9" string="window" />
            <token id="10" string="with" />
            <token id="11" string="his" />
            <token id="12" string="elbows" />
            <token id="13" string="and" />
            <token id="14" string="not" />
            <token id="15" string="with" />
            <token id="16" string="his" />
            <token id="17" string="face" />
            <token id="18" string="as" />
            <token id="19" string="Jackson" />
            <token id="20" string="contends" />
          </tokens>
        </chunking>
        <chunking id="2" string="the window" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="window" />
          </tokens>
        </chunking>
        <chunking id="3" string="his elbows" type="NP">
          <tokens>
            <token id="11" string="his" />
            <token id="12" string="elbows" />
          </tokens>
        </chunking>
        <chunking id="4" string="his face" type="NP">
          <tokens>
            <token id="16" string="his" />
            <token id="17" string="face" />
          </tokens>
        </chunking>
        <chunking id="5" string="contends" type="VP">
          <tokens>
            <token id="20" string="contends" />
          </tokens>
        </chunking>
        <chunking id="6" string="as Jackson contends" type="SBAR">
          <tokens>
            <token id="18" string="as" />
            <token id="19" string="Jackson" />
            <token id="20" string="contends" />
          </tokens>
        </chunking>
        <chunking id="7" string="Jackson" type="NP">
          <tokens>
            <token id="1" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="8" string="Dickey" type="NP">
          <tokens>
            <token id="5" string="Dickey" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="7">struck</governor>
          <dependent id="1">Jackson</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">Dickey</governor>
          <dependent id="3">according</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="3">according</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">struck</governor>
          <dependent id="5">Dickey</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">struck</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">struck</governor>
          <dependent id="7">struck</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">window</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">struck</governor>
          <dependent id="9">window</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">elbows</governor>
          <dependent id="10">with</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="12">elbows</governor>
          <dependent id="11">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">struck</governor>
          <dependent id="12">elbows</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">struck</governor>
          <dependent id="13">and</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="17">face</governor>
          <dependent id="14">not</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">face</governor>
          <dependent id="15">with</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="17">face</governor>
          <dependent id="16">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">struck</governor>
          <dependent id="17">face</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="20">contends</governor>
          <dependent id="18">as</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">contends</governor>
          <dependent id="19">Jackson</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="7">struck</governor>
          <dependent id="20">contends</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Jackson" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Jackson" />
          </tokens>
        </entity>
        <entity id="2" string="Dickey" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Dickey" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="39" has_coreference="true">
      <content>Dickey, who cut his hand, noted that Jackson suffered no facial injuries when the glass shattered.</content>
      <tokens>
        <token id="1" string="Dickey" lemma="Dickey" stem="dickei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="cut" lemma="cut" stem="cut" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="hand" lemma="hand" stem="hand" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="noted" lemma="note" stem="note" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="11" string="suffered" lemma="suffer" stem="suffer" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="facial" lemma="facial" stem="facial" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="injuries" lemma="injury" stem="injuri" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="glass" lemma="glass" stem="glass" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="shattered" lemma="shatter" stem="shatter" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Dickey)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBD cut) (NP (PRP$ his) (NN hand))))) (, ,)) (VP (VBD noted) (SBAR (IN that) (S (NP (NNP Jackson)) (VP (VBD suffered) (NP (DT no) (JJ facial) (NNS injuries)) (SBAR (WHADVP (WRB when)) (S (NP (DT the) (NN glass)) (VP (VBN shattered)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="when the glass shattered" type="SBAR">
          <tokens>
            <token id="15" string="when" />
            <token id="16" string="the" />
            <token id="17" string="glass" />
            <token id="18" string="shattered" />
          </tokens>
        </chunking>
        <chunking id="2" string="his hand" type="NP">
          <tokens>
            <token id="5" string="his" />
            <token id="6" string="hand" />
          </tokens>
        </chunking>
        <chunking id="3" string="that Jackson suffered no facial injuries when the glass shattered" type="SBAR">
          <tokens>
            <token id="9" string="that" />
            <token id="10" string="Jackson" />
            <token id="11" string="suffered" />
            <token id="12" string="no" />
            <token id="13" string="facial" />
            <token id="14" string="injuries" />
            <token id="15" string="when" />
            <token id="16" string="the" />
            <token id="17" string="glass" />
            <token id="18" string="shattered" />
          </tokens>
        </chunking>
        <chunking id="4" string="noted that Jackson suffered no facial injuries when the glass shattered" type="VP">
          <tokens>
            <token id="8" string="noted" />
            <token id="9" string="that" />
            <token id="10" string="Jackson" />
            <token id="11" string="suffered" />
            <token id="12" string="no" />
            <token id="13" string="facial" />
            <token id="14" string="injuries" />
            <token id="15" string="when" />
            <token id="16" string="the" />
            <token id="17" string="glass" />
            <token id="18" string="shattered" />
          </tokens>
        </chunking>
        <chunking id="5" string="the glass" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="glass" />
          </tokens>
        </chunking>
        <chunking id="6" string="Jackson" type="NP">
          <tokens>
            <token id="10" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="7" string="Dickey , who cut his hand ," type="NP">
          <tokens>
            <token id="1" string="Dickey" />
            <token id="2" string="," />
            <token id="3" string="who" />
            <token id="4" string="cut" />
            <token id="5" string="his" />
            <token id="6" string="hand" />
            <token id="7" string="," />
          </tokens>
        </chunking>
        <chunking id="8" string="when" type="WHADVP">
          <tokens>
            <token id="15" string="when" />
          </tokens>
        </chunking>
        <chunking id="9" string="shattered" type="VP">
          <tokens>
            <token id="18" string="shattered" />
          </tokens>
        </chunking>
        <chunking id="10" string="suffered no facial injuries when the glass shattered" type="VP">
          <tokens>
            <token id="11" string="suffered" />
            <token id="12" string="no" />
            <token id="13" string="facial" />
            <token id="14" string="injuries" />
            <token id="15" string="when" />
            <token id="16" string="the" />
            <token id="17" string="glass" />
            <token id="18" string="shattered" />
          </tokens>
        </chunking>
        <chunking id="11" string="no facial injuries" type="NP">
          <tokens>
            <token id="12" string="no" />
            <token id="13" string="facial" />
            <token id="14" string="injuries" />
          </tokens>
        </chunking>
        <chunking id="12" string="cut his hand" type="VP">
          <tokens>
            <token id="4" string="cut" />
            <token id="5" string="his" />
            <token id="6" string="hand" />
          </tokens>
        </chunking>
        <chunking id="13" string="Dickey" type="NP">
          <tokens>
            <token id="1" string="Dickey" />
          </tokens>
        </chunking>
        <chunking id="14" string="who cut his hand" type="SBAR">
          <tokens>
            <token id="3" string="who" />
            <token id="4" string="cut" />
            <token id="5" string="his" />
            <token id="6" string="hand" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="8">noted</governor>
          <dependent id="1">Dickey</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">cut</governor>
          <dependent id="3">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="1">Dickey</governor>
          <dependent id="4">cut</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="6">hand</governor>
          <dependent id="5">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">cut</governor>
          <dependent id="6">hand</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">noted</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">suffered</governor>
          <dependent id="9">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">suffered</governor>
          <dependent id="10">Jackson</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="8">noted</governor>
          <dependent id="11">suffered</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="14">injuries</governor>
          <dependent id="12">no</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">injuries</governor>
          <dependent id="13">facial</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">suffered</governor>
          <dependent id="14">injuries</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">shattered</governor>
          <dependent id="15">when</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">glass</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">shattered</governor>
          <dependent id="17">glass</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="11">suffered</governor>
          <dependent id="18">shattered</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Jackson" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Jackson" />
          </tokens>
        </entity>
        <entity id="2" string="Dickey" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Dickey" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="40" has_coreference="true">
      <content>Jackson, in his testimony, defended his self-appointed role as a police anti-brutality activist, saying &amp;quot;my duty is to uphold the law and I am doing that in the highest tradition.&amp;quot;</content>
      <tokens>
        <token id="1" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="testimony" lemma="testimony" stem="testimoni" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="defended" lemma="defend" stem="defend" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="self-appointed" lemma="self-appointed" stem="self-appoint" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="role" lemma="role" stem="role" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="anti-brutality" lemma="anti-brutality" stem="anti-brut" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="activist" lemma="activist" stem="activist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="saying" lemma="say" stem="sai" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="my" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="duty" lemma="duty" stem="duti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="uphold" lemma="uphold" stem="uphold" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="law" lemma="law" stem="law" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="28" string="am" lemma="be" stem="am" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="doing" lemma="do" stem="do" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="highest" lemma="highest" stem="highest" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="tradition" lemma="tradition" stem="tradit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NNP Jackson)) (, ,) (PP (IN in) (NP (PRP$ his) (NN testimony))) (, ,) (VP (VBD defended) (NP (PRP$ his) (JJ self-appointed) (NN role)) (PP (IN as) (NP (DT a) (NN police) (JJ anti-brutality) (NN activist))) (, ,) (S (VP (VBG saying) (S (`` ``) (NP (PRP$ my) (NN duty)) (VP (VBZ is) (S (VP (TO to) (VP (VB uphold) (NP (DT the) (NN law))))))))))) (CC and) (S (NP (PRP I)) (VP (VBP am) (VP (VBG doing) (IN that) (PP (IN in) (NP (DT the) (JJS highest) (NN tradition)))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="the highest tradition" type="NP">
          <tokens>
            <token id="32" string="the" />
            <token id="33" string="highest" />
            <token id="34" string="tradition" />
          </tokens>
        </chunking>
        <chunking id="2" string="his testimony" type="NP">
          <tokens>
            <token id="4" string="his" />
            <token id="5" string="testimony" />
          </tokens>
        </chunking>
        <chunking id="3" string="to uphold the law" type="VP">
          <tokens>
            <token id="22" string="to" />
            <token id="23" string="uphold" />
            <token id="24" string="the" />
            <token id="25" string="law" />
          </tokens>
        </chunking>
        <chunking id="4" string="uphold the law" type="VP">
          <tokens>
            <token id="23" string="uphold" />
            <token id="24" string="the" />
            <token id="25" string="law" />
          </tokens>
        </chunking>
        <chunking id="5" string="I" type="NP">
          <tokens>
            <token id="27" string="I" />
          </tokens>
        </chunking>
        <chunking id="6" string="Jackson" type="NP">
          <tokens>
            <token id="1" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="7" string="his self-appointed role" type="NP">
          <tokens>
            <token id="8" string="his" />
            <token id="9" string="self-appointed" />
            <token id="10" string="role" />
          </tokens>
        </chunking>
        <chunking id="8" string="is to uphold the law" type="VP">
          <tokens>
            <token id="21" string="is" />
            <token id="22" string="to" />
            <token id="23" string="uphold" />
            <token id="24" string="the" />
            <token id="25" string="law" />
          </tokens>
        </chunking>
        <chunking id="9" string="defended his self-appointed role as a police anti-brutality activist , saying `` my duty is to uphold the law" type="VP">
          <tokens>
            <token id="7" string="defended" />
            <token id="8" string="his" />
            <token id="9" string="self-appointed" />
            <token id="10" string="role" />
            <token id="11" string="as" />
            <token id="12" string="a" />
            <token id="13" string="police" />
            <token id="14" string="anti-brutality" />
            <token id="15" string="activist" />
            <token id="16" string="," />
            <token id="17" string="saying" />
            <token id="18" string="&quot;" />
            <token id="19" string="my" />
            <token id="20" string="duty" />
            <token id="21" string="is" />
            <token id="22" string="to" />
            <token id="23" string="uphold" />
            <token id="24" string="the" />
            <token id="25" string="law" />
          </tokens>
        </chunking>
        <chunking id="10" string="am doing that in the highest tradition" type="VP">
          <tokens>
            <token id="28" string="am" />
            <token id="29" string="doing" />
            <token id="30" string="that" />
            <token id="31" string="in" />
            <token id="32" string="the" />
            <token id="33" string="highest" />
            <token id="34" string="tradition" />
          </tokens>
        </chunking>
        <chunking id="11" string="the law" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="law" />
          </tokens>
        </chunking>
        <chunking id="12" string="my duty" type="NP">
          <tokens>
            <token id="19" string="my" />
            <token id="20" string="duty" />
          </tokens>
        </chunking>
        <chunking id="13" string="saying `` my duty is to uphold the law" type="VP">
          <tokens>
            <token id="17" string="saying" />
            <token id="18" string="&quot;" />
            <token id="19" string="my" />
            <token id="20" string="duty" />
            <token id="21" string="is" />
            <token id="22" string="to" />
            <token id="23" string="uphold" />
            <token id="24" string="the" />
            <token id="25" string="law" />
          </tokens>
        </chunking>
        <chunking id="14" string="a police anti-brutality activist" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="police" />
            <token id="14" string="anti-brutality" />
            <token id="15" string="activist" />
          </tokens>
        </chunking>
        <chunking id="15" string="doing that in the highest tradition" type="VP">
          <tokens>
            <token id="29" string="doing" />
            <token id="30" string="that" />
            <token id="31" string="in" />
            <token id="32" string="the" />
            <token id="33" string="highest" />
            <token id="34" string="tradition" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="7">defended</governor>
          <dependent id="1">Jackson</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">testimony</governor>
          <dependent id="3">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">testimony</governor>
          <dependent id="4">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">defended</governor>
          <dependent id="5">testimony</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">defended</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="10">role</governor>
          <dependent id="8">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">role</governor>
          <dependent id="9">self-appointed</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">defended</governor>
          <dependent id="10">role</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">activist</governor>
          <dependent id="11">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">activist</governor>
          <dependent id="12">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">activist</governor>
          <dependent id="13">police</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">activist</governor>
          <dependent id="14">anti-brutality</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">defended</governor>
          <dependent id="15">activist</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="7">defended</governor>
          <dependent id="17">saying</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="20">duty</governor>
          <dependent id="19">my</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">is</governor>
          <dependent id="20">duty</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="17">saying</governor>
          <dependent id="21">is</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="23">uphold</governor>
          <dependent id="22">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="21">is</governor>
          <dependent id="23">uphold</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">law</governor>
          <dependent id="24">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="23">uphold</governor>
          <dependent id="25">law</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">defended</governor>
          <dependent id="26">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">doing</governor>
          <dependent id="27">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="29">doing</governor>
          <dependent id="28">am</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">defended</governor>
          <dependent id="29">doing</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="29">doing</governor>
          <dependent id="30">that</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">tradition</governor>
          <dependent id="31">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="34">tradition</governor>
          <dependent id="32">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="34">tradition</governor>
          <dependent id="33">highest</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">doing</governor>
          <dependent id="34">tradition</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Jackson" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Jackson" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="41" has_coreference="true">
      <content>He said he is troubled, though, that Long Beach police are investigating his background on the Hawthorne Police Department rather than concentrating on the incident.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="troubled" lemma="trouble" stem="troubl" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="though" lemma="though" stem="though" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Long" lemma="Long" stem="long" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="11" string="Beach" lemma="Beach" stem="beach" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="12" string="police" lemma="police" stem="polic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="investigating" lemma="investigate" stem="investig" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="background" lemma="background" stem="background" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="Hawthorne" lemma="Hawthorne" stem="hawthorn" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="20" string="Police" lemma="Police" stem="polic" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="21" string="Department" lemma="Department" stem="depart" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="22" string="rather" lemma="rather" stem="rather" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="concentrating" lemma="concentrate" stem="concentr" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="27" string="incident" lemma="incident" stem="incid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VP (VBD said) (SBAR (S (NP (PRP he)) (VP (VBZ is) (ADJP (VBN troubled) (PRN (, ,) (ADVP (IN though)) (, ,)) (SBAR (IN that) (S (NP (NNP Long) (NNP Beach) (NNS police)) (VP (VBP are) (VP (VBG investigating) (NP (PRP$ his) (NN background)) (PP (IN on) (NP (DT the) (NNP Hawthorne) (NNP Police) (NNP Department)))))))))))) (CONJP (RB rather) (IN than)) (VP (VBG concentrating) (PP (IN on) (NP (DT the) (NN incident))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="he is troubled , though , that Long Beach police are investigating his background on the Hawthorne Police Department" type="SBAR">
          <tokens>
            <token id="3" string="he" />
            <token id="4" string="is" />
            <token id="5" string="troubled" />
            <token id="6" string="," />
            <token id="7" string="though" />
            <token id="8" string="," />
            <token id="9" string="that" />
            <token id="10" string="Long" />
            <token id="11" string="Beach" />
            <token id="12" string="police" />
            <token id="13" string="are" />
            <token id="14" string="investigating" />
            <token id="15" string="his" />
            <token id="16" string="background" />
            <token id="17" string="on" />
            <token id="18" string="the" />
            <token id="19" string="Hawthorne" />
            <token id="20" string="Police" />
            <token id="21" string="Department" />
          </tokens>
        </chunking>
        <chunking id="2" string="are investigating his background on the Hawthorne Police Department" type="VP">
          <tokens>
            <token id="13" string="are" />
            <token id="14" string="investigating" />
            <token id="15" string="his" />
            <token id="16" string="background" />
            <token id="17" string="on" />
            <token id="18" string="the" />
            <token id="19" string="Hawthorne" />
            <token id="20" string="Police" />
            <token id="21" string="Department" />
          </tokens>
        </chunking>
        <chunking id="3" string="said he is troubled , though , that Long Beach police are investigating his background on the Hawthorne Police Department" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="he" />
            <token id="4" string="is" />
            <token id="5" string="troubled" />
            <token id="6" string="," />
            <token id="7" string="though" />
            <token id="8" string="," />
            <token id="9" string="that" />
            <token id="10" string="Long" />
            <token id="11" string="Beach" />
            <token id="12" string="police" />
            <token id="13" string="are" />
            <token id="14" string="investigating" />
            <token id="15" string="his" />
            <token id="16" string="background" />
            <token id="17" string="on" />
            <token id="18" string="the" />
            <token id="19" string="Hawthorne" />
            <token id="20" string="Police" />
            <token id="21" string="Department" />
          </tokens>
        </chunking>
        <chunking id="4" string="his background" type="NP">
          <tokens>
            <token id="15" string="his" />
            <token id="16" string="background" />
          </tokens>
        </chunking>
        <chunking id="5" string="Long Beach police" type="NP">
          <tokens>
            <token id="10" string="Long" />
            <token id="11" string="Beach" />
            <token id="12" string="police" />
          </tokens>
        </chunking>
        <chunking id="6" string="is troubled , though , that Long Beach police are investigating his background on the Hawthorne Police Department" type="VP">
          <tokens>
            <token id="4" string="is" />
            <token id="5" string="troubled" />
            <token id="6" string="," />
            <token id="7" string="though" />
            <token id="8" string="," />
            <token id="9" string="that" />
            <token id="10" string="Long" />
            <token id="11" string="Beach" />
            <token id="12" string="police" />
            <token id="13" string="are" />
            <token id="14" string="investigating" />
            <token id="15" string="his" />
            <token id="16" string="background" />
            <token id="17" string="on" />
            <token id="18" string="the" />
            <token id="19" string="Hawthorne" />
            <token id="20" string="Police" />
            <token id="21" string="Department" />
          </tokens>
        </chunking>
        <chunking id="7" string="investigating his background on the Hawthorne Police Department" type="VP">
          <tokens>
            <token id="14" string="investigating" />
            <token id="15" string="his" />
            <token id="16" string="background" />
            <token id="17" string="on" />
            <token id="18" string="the" />
            <token id="19" string="Hawthorne" />
            <token id="20" string="Police" />
            <token id="21" string="Department" />
          </tokens>
        </chunking>
        <chunking id="8" string="concentrating on the incident" type="VP">
          <tokens>
            <token id="24" string="concentrating" />
            <token id="25" string="on" />
            <token id="26" string="the" />
            <token id="27" string="incident" />
          </tokens>
        </chunking>
        <chunking id="9" string="that Long Beach police are investigating his background on the Hawthorne Police Department" type="SBAR">
          <tokens>
            <token id="9" string="that" />
            <token id="10" string="Long" />
            <token id="11" string="Beach" />
            <token id="12" string="police" />
            <token id="13" string="are" />
            <token id="14" string="investigating" />
            <token id="15" string="his" />
            <token id="16" string="background" />
            <token id="17" string="on" />
            <token id="18" string="the" />
            <token id="19" string="Hawthorne" />
            <token id="20" string="Police" />
            <token id="21" string="Department" />
          </tokens>
        </chunking>
        <chunking id="10" string="troubled , though , that Long Beach police are investigating his background on the Hawthorne Police Department" type="ADJP">
          <tokens>
            <token id="5" string="troubled" />
            <token id="6" string="," />
            <token id="7" string="though" />
            <token id="8" string="," />
            <token id="9" string="that" />
            <token id="10" string="Long" />
            <token id="11" string="Beach" />
            <token id="12" string="police" />
            <token id="13" string="are" />
            <token id="14" string="investigating" />
            <token id="15" string="his" />
            <token id="16" string="background" />
            <token id="17" string="on" />
            <token id="18" string="the" />
            <token id="19" string="Hawthorne" />
            <token id="20" string="Police" />
            <token id="21" string="Department" />
          </tokens>
        </chunking>
        <chunking id="11" string="the Hawthorne Police Department" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="Hawthorne" />
            <token id="20" string="Police" />
            <token id="21" string="Department" />
          </tokens>
        </chunking>
        <chunking id="12" string="said he is troubled , though , that Long Beach police are investigating his background on the Hawthorne Police Department rather than concentrating on the incident" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="he" />
            <token id="4" string="is" />
            <token id="5" string="troubled" />
            <token id="6" string="," />
            <token id="7" string="though" />
            <token id="8" string="," />
            <token id="9" string="that" />
            <token id="10" string="Long" />
            <token id="11" string="Beach" />
            <token id="12" string="police" />
            <token id="13" string="are" />
            <token id="14" string="investigating" />
            <token id="15" string="his" />
            <token id="16" string="background" />
            <token id="17" string="on" />
            <token id="18" string="the" />
            <token id="19" string="Hawthorne" />
            <token id="20" string="Police" />
            <token id="21" string="Department" />
            <token id="22" string="rather" />
            <token id="23" string="than" />
            <token id="24" string="concentrating" />
            <token id="25" string="on" />
            <token id="26" string="the" />
            <token id="27" string="incident" />
          </tokens>
        </chunking>
        <chunking id="13" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="14" string="he" type="NP">
          <tokens>
            <token id="3" string="he" />
          </tokens>
        </chunking>
        <chunking id="15" string="the incident" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="incident" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="5">troubled</governor>
          <dependent id="3">he</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="5">troubled</governor>
          <dependent id="4">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="5">troubled</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="5">troubled</governor>
          <dependent id="7">though</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">investigating</governor>
          <dependent id="9">that</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">police</governor>
          <dependent id="10">Long</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">police</governor>
          <dependent id="11">Beach</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">investigating</governor>
          <dependent id="12">police</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="14">investigating</governor>
          <dependent id="13">are</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">troubled</governor>
          <dependent id="14">investigating</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="16">background</governor>
          <dependent id="15">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">investigating</governor>
          <dependent id="16">background</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">Department</governor>
          <dependent id="17">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">Department</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">Department</governor>
          <dependent id="19">Hawthorne</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">Department</governor>
          <dependent id="20">Police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">investigating</governor>
          <dependent id="21">Department</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">said</governor>
          <dependent id="22">rather</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="22">rather</governor>
          <dependent id="23">than</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">said</governor>
          <dependent id="24">concentrating</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">incident</governor>
          <dependent id="25">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">incident</governor>
          <dependent id="26">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">concentrating</governor>
          <dependent id="27">incident</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Long Beach" type="LOCATION" score="0.0">
          <tokens>
            <token id="10" string="Long" />
            <token id="11" string="Beach" />
          </tokens>
        </entity>
        <entity id="2" string="Hawthorne Police Department" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="19" string="Hawthorne" />
            <token id="20" string="Police" />
            <token id="21" string="Department" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="42" has_coreference="true">
      <content>Boatwright adjourned the hearing, which was held at the Hall of Administration in downtown Los Angeles, after about six hours of testimony.</content>
      <tokens>
        <token id="1" string="Boatwright" lemma="Boatwright" stem="boatwright" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="adjourned" lemma="adjourn" stem="adjourn" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="hearing" lemma="hearing" stem="hear" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="held" lemma="hold" stem="held" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="Hall" lemma="hall" stem="hall" pos="NN" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="13" string="Administration" lemma="administration" stem="administr" pos="NN" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="14" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="downtown" lemma="downtown" stem="downtown" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="Los" lemma="Los" stem="lo" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="17" string="Angeles" lemma="Angeles" stem="angele" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="true" />
        <token id="21" string="six" lemma="six" stem="six" pos="CD" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="true" />
        <token id="22" string="hours" lemma="hour" stem="hour" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="true" />
        <token id="23" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="testimony" lemma="testimony" stem="testimoni" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Boatwright)) (VP (VBD adjourned) (NP (NP (DT the) (NN hearing)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBD was) (VP (VBN held) (PP (IN at) (NP (NP (DT the) (NN Hall)) (PP (IN of) (NP (NN Administration))))) (PP (IN in) (NP (NN downtown) (NNP Los) (NNP Angeles))) (, ,) (PP (IN after) (IN about) (NP (NP (CD six) (NNS hours)) (PP (IN of) (NP (NN testimony))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Administration" type="NP">
          <tokens>
            <token id="13" string="Administration" />
          </tokens>
        </chunking>
        <chunking id="2" string="held at the Hall of Administration in downtown Los Angeles , after about six hours of testimony" type="VP">
          <tokens>
            <token id="8" string="held" />
            <token id="9" string="at" />
            <token id="10" string="the" />
            <token id="11" string="Hall" />
            <token id="12" string="of" />
            <token id="13" string="Administration" />
            <token id="14" string="in" />
            <token id="15" string="downtown" />
            <token id="16" string="Los" />
            <token id="17" string="Angeles" />
            <token id="18" string="," />
            <token id="19" string="after" />
            <token id="20" string="about" />
            <token id="21" string="six" />
            <token id="22" string="hours" />
            <token id="23" string="of" />
            <token id="24" string="testimony" />
          </tokens>
        </chunking>
        <chunking id="3" string="six hours of testimony" type="NP">
          <tokens>
            <token id="21" string="six" />
            <token id="22" string="hours" />
            <token id="23" string="of" />
            <token id="24" string="testimony" />
          </tokens>
        </chunking>
        <chunking id="4" string="the Hall" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="Hall" />
          </tokens>
        </chunking>
        <chunking id="5" string="Boatwright" type="NP">
          <tokens>
            <token id="1" string="Boatwright" />
          </tokens>
        </chunking>
        <chunking id="6" string="was held at the Hall of Administration in downtown Los Angeles , after about six hours of testimony" type="VP">
          <tokens>
            <token id="7" string="was" />
            <token id="8" string="held" />
            <token id="9" string="at" />
            <token id="10" string="the" />
            <token id="11" string="Hall" />
            <token id="12" string="of" />
            <token id="13" string="Administration" />
            <token id="14" string="in" />
            <token id="15" string="downtown" />
            <token id="16" string="Los" />
            <token id="17" string="Angeles" />
            <token id="18" string="," />
            <token id="19" string="after" />
            <token id="20" string="about" />
            <token id="21" string="six" />
            <token id="22" string="hours" />
            <token id="23" string="of" />
            <token id="24" string="testimony" />
          </tokens>
        </chunking>
        <chunking id="7" string="the hearing" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="hearing" />
          </tokens>
        </chunking>
        <chunking id="8" string="testimony" type="NP">
          <tokens>
            <token id="24" string="testimony" />
          </tokens>
        </chunking>
        <chunking id="9" string="downtown Los Angeles" type="NP">
          <tokens>
            <token id="15" string="downtown" />
            <token id="16" string="Los" />
            <token id="17" string="Angeles" />
          </tokens>
        </chunking>
        <chunking id="10" string="the hearing , which was held at the Hall of Administration in downtown Los Angeles , after about six hours of testimony" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="hearing" />
            <token id="5" string="," />
            <token id="6" string="which" />
            <token id="7" string="was" />
            <token id="8" string="held" />
            <token id="9" string="at" />
            <token id="10" string="the" />
            <token id="11" string="Hall" />
            <token id="12" string="of" />
            <token id="13" string="Administration" />
            <token id="14" string="in" />
            <token id="15" string="downtown" />
            <token id="16" string="Los" />
            <token id="17" string="Angeles" />
            <token id="18" string="," />
            <token id="19" string="after" />
            <token id="20" string="about" />
            <token id="21" string="six" />
            <token id="22" string="hours" />
            <token id="23" string="of" />
            <token id="24" string="testimony" />
          </tokens>
        </chunking>
        <chunking id="11" string="which was held at the Hall of Administration in downtown Los Angeles , after about six hours of testimony" type="SBAR">
          <tokens>
            <token id="6" string="which" />
            <token id="7" string="was" />
            <token id="8" string="held" />
            <token id="9" string="at" />
            <token id="10" string="the" />
            <token id="11" string="Hall" />
            <token id="12" string="of" />
            <token id="13" string="Administration" />
            <token id="14" string="in" />
            <token id="15" string="downtown" />
            <token id="16" string="Los" />
            <token id="17" string="Angeles" />
            <token id="18" string="," />
            <token id="19" string="after" />
            <token id="20" string="about" />
            <token id="21" string="six" />
            <token id="22" string="hours" />
            <token id="23" string="of" />
            <token id="24" string="testimony" />
          </tokens>
        </chunking>
        <chunking id="12" string="adjourned the hearing , which was held at the Hall of Administration in downtown Los Angeles , after about six hours of testimony" type="VP">
          <tokens>
            <token id="2" string="adjourned" />
            <token id="3" string="the" />
            <token id="4" string="hearing" />
            <token id="5" string="," />
            <token id="6" string="which" />
            <token id="7" string="was" />
            <token id="8" string="held" />
            <token id="9" string="at" />
            <token id="10" string="the" />
            <token id="11" string="Hall" />
            <token id="12" string="of" />
            <token id="13" string="Administration" />
            <token id="14" string="in" />
            <token id="15" string="downtown" />
            <token id="16" string="Los" />
            <token id="17" string="Angeles" />
            <token id="18" string="," />
            <token id="19" string="after" />
            <token id="20" string="about" />
            <token id="21" string="six" />
            <token id="22" string="hours" />
            <token id="23" string="of" />
            <token id="24" string="testimony" />
          </tokens>
        </chunking>
        <chunking id="13" string="six hours" type="NP">
          <tokens>
            <token id="21" string="six" />
            <token id="22" string="hours" />
          </tokens>
        </chunking>
        <chunking id="14" string="the Hall of Administration" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="Hall" />
            <token id="12" string="of" />
            <token id="13" string="Administration" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">adjourned</governor>
          <dependent id="1">Boatwright</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">adjourned</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">hearing</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">adjourned</governor>
          <dependent id="4">hearing</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="8">held</governor>
          <dependent id="6">which</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="8">held</governor>
          <dependent id="7">was</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="4">hearing</governor>
          <dependent id="8">held</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Hall</governor>
          <dependent id="9">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">Hall</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">held</governor>
          <dependent id="11">Hall</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Administration</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">Hall</governor>
          <dependent id="13">Administration</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">Angeles</governor>
          <dependent id="14">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">Angeles</governor>
          <dependent id="15">downtown</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">Angeles</governor>
          <dependent id="16">Los</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">held</governor>
          <dependent id="17">Angeles</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">hours</governor>
          <dependent id="19">after</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">hours</governor>
          <dependent id="20">about</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="22">hours</governor>
          <dependent id="21">six</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">held</governor>
          <dependent id="22">hours</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">testimony</governor>
          <dependent id="23">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">hours</governor>
          <dependent id="24">testimony</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Hall of Administration" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="11" string="Hall" />
            <token id="12" string="of" />
            <token id="13" string="Administration" />
          </tokens>
        </entity>
        <entity id="2" string="about six hours" type="DURATION" score="0.0">
          <tokens>
            <token id="20" string="about" />
            <token id="21" string="six" />
            <token id="22" string="hours" />
          </tokens>
        </entity>
        <entity id="3" string="Los Angeles" type="LOCATION" score="0.0">
          <tokens>
            <token id="16" string="Los" />
            <token id="17" string="Angeles" />
          </tokens>
        </entity>
        <entity id="4" string="Boatwright" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Boatwright" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="43" has_coreference="true">
      <content>He said it would reconvene later to hear from the additional witnesses.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="reconvene" lemma="reconvene" stem="reconven" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="later" lemma="later" stem="later" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="hear" lemma="hear" stem="hear" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="additional" lemma="additional" stem="addit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="witnesses" lemma="witness" stem="wit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VBD said) (SBAR (S (NP (PRP it)) (VP (MD would) (VP (VB reconvene) (ADVP (RB later)) (S (VP (TO to) (VP (VB hear) (PP (IN from) (NP (DT the) (JJ additional) (NNS witnesses))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="said it would reconvene later to hear from the additional witnesses" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="it" />
            <token id="4" string="would" />
            <token id="5" string="reconvene" />
            <token id="6" string="later" />
            <token id="7" string="to" />
            <token id="8" string="hear" />
            <token id="9" string="from" />
            <token id="10" string="the" />
            <token id="11" string="additional" />
            <token id="12" string="witnesses" />
          </tokens>
        </chunking>
        <chunking id="2" string="hear from the additional witnesses" type="VP">
          <tokens>
            <token id="8" string="hear" />
            <token id="9" string="from" />
            <token id="10" string="the" />
            <token id="11" string="additional" />
            <token id="12" string="witnesses" />
          </tokens>
        </chunking>
        <chunking id="3" string="it would reconvene later to hear from the additional witnesses" type="SBAR">
          <tokens>
            <token id="3" string="it" />
            <token id="4" string="would" />
            <token id="5" string="reconvene" />
            <token id="6" string="later" />
            <token id="7" string="to" />
            <token id="8" string="hear" />
            <token id="9" string="from" />
            <token id="10" string="the" />
            <token id="11" string="additional" />
            <token id="12" string="witnesses" />
          </tokens>
        </chunking>
        <chunking id="4" string="to hear from the additional witnesses" type="VP">
          <tokens>
            <token id="7" string="to" />
            <token id="8" string="hear" />
            <token id="9" string="from" />
            <token id="10" string="the" />
            <token id="11" string="additional" />
            <token id="12" string="witnesses" />
          </tokens>
        </chunking>
        <chunking id="5" string="the additional witnesses" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="additional" />
            <token id="12" string="witnesses" />
          </tokens>
        </chunking>
        <chunking id="6" string="it" type="NP">
          <tokens>
            <token id="3" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="would reconvene later to hear from the additional witnesses" type="VP">
          <tokens>
            <token id="4" string="would" />
            <token id="5" string="reconvene" />
            <token id="6" string="later" />
            <token id="7" string="to" />
            <token id="8" string="hear" />
            <token id="9" string="from" />
            <token id="10" string="the" />
            <token id="11" string="additional" />
            <token id="12" string="witnesses" />
          </tokens>
        </chunking>
        <chunking id="8" string="reconvene later to hear from the additional witnesses" type="VP">
          <tokens>
            <token id="5" string="reconvene" />
            <token id="6" string="later" />
            <token id="7" string="to" />
            <token id="8" string="hear" />
            <token id="9" string="from" />
            <token id="10" string="the" />
            <token id="11" string="additional" />
            <token id="12" string="witnesses" />
          </tokens>
        </chunking>
        <chunking id="9" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">reconvene</governor>
          <dependent id="3">it</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">reconvene</governor>
          <dependent id="4">would</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="5">reconvene</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">reconvene</governor>
          <dependent id="6">later</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">hear</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">reconvene</governor>
          <dependent id="8">hear</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">witnesses</governor>
          <dependent id="9">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">witnesses</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">witnesses</governor>
          <dependent id="11">additional</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">hear</governor>
          <dependent id="12">witnesses</dependent>
        </dependency>
      </dependencies>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="1" type="PROPER">
      <referenced ids_tokens="15" string="Officer" id_sentence="7" />
      <mentions>
        <mention ids_tokens="1-27" string="A white Long Beach police officer who allegedly pushed a black man through a plate-glass window during an arrest that was secretly videotaped by a television crew" id_sentence="1" />
        <mention ids_tokens="31" string="he" id_sentence="1" />
        <mention ids_tokens="35" string="his" id_sentence="1" />
      </mentions>
    </coreference>
    <coreference id="3" type="PROPER">
      <referenced ids_tokens="2-3" string="Mark Dickey" id_sentence="2" />
      <mentions>
        <mention ids_tokens="1" string="He" id_sentence="3" />
        <mention ids_tokens="11" string="he" id_sentence="3" />
        <mention ids_tokens="1-7" string="Dickey , who was testifying under subpoena" id_sentence="4" />
        <mention ids_tokens="1" string="Dickey" id_sentence="4" />
        <mention ids_tokens="27" string="Dickey" id_sentence="4" />
        <mention ids_tokens="31" string="his" id_sentence="4" />
        <mention ids_tokens="1" string="Dickey" id_sentence="5" />
        <mention ids_tokens="5" string="he" id_sentence="5" />
        <mention ids_tokens="20" string="Dickey" id_sentence="8" />
        <mention ids_tokens="26" string="his" id_sentence="8" />
        <mention ids_tokens="38" string="his" id_sentence="8" />
        <mention ids_tokens="1" string="Dickey" id_sentence="11" />
        <mention ids_tokens="22" string="Dickey" id_sentence="12" />
        <mention ids_tokens="33" string="Dickey" id_sentence="13" />
        <mention ids_tokens="36" string="his" id_sentence="13" />
        <mention ids_tokens="7" string="Dickey" id_sentence="14" />
        <mention ids_tokens="5" string="Dickey" id_sentence="15" />
        <mention ids_tokens="1-2" string="Dickey's" id_sentence="16" />
        <mention ids_tokens="11" string="Dickey" id_sentence="16" />
        <mention ids_tokens="26" string="he" id_sentence="16" />
        <mention ids_tokens="14" string="Dickey" id_sentence="20" />
        <mention ids_tokens="1" string="Dickey" id_sentence="22" />
        <mention ids_tokens="7" string="he" id_sentence="22" />
        <mention ids_tokens="14" string="Dickey" id_sentence="24" />
        <mention ids_tokens="1-2" string="Dickey's" id_sentence="26" />
        <mention ids_tokens="2" string="Dickey" id_sentence="27" />
        <mention ids_tokens="10-17" string="he , not Jackson , who uttered obscenities" id_sentence="27" />
        <mention ids_tokens="10" string="he" id_sentence="27" />
        <mention ids_tokens="13" string="Dickey" id_sentence="29" />
        <mention ids_tokens="1" string="Dickey" id_sentence="30" />
        <mention ids_tokens="4" string="he" id_sentence="30" />
        <mention ids_tokens="11" string="his" id_sentence="30" />
        <mention ids_tokens="1" string="He" id_sentence="31" />
        <mention ids_tokens="4" string="he" id_sentence="31" />
        <mention ids_tokens="1" string="He" id_sentence="32" />
        <mention ids_tokens="3" string="his" id_sentence="32" />
        <mention ids_tokens="11" string="my" id_sentence="32" />
        <mention ids_tokens="10" string="Dickey" id_sentence="33" />
        <mention ids_tokens="10" string="Dickey" id_sentence="34" />
        <mention ids_tokens="13" string="Dickey" id_sentence="34" />
        <mention ids_tokens="1" string="Dickey" id_sentence="36" />
        <mention ids_tokens="5" string="Dickey" id_sentence="38" />
        <mention ids_tokens="1-6" string="Dickey , who cut his hand" id_sentence="39" />
        <mention ids_tokens="1" string="Dickey" id_sentence="39" />
        <mention ids_tokens="5" string="his" id_sentence="39" />
      </mentions>
    </coreference>
    <coreference id="5" type="NOMINAL">
      <referenced ids_tokens="12-13-14-15" string="the Jan. 14 incident" id_sentence="2" />
      <mentions>
        <mention ids_tokens="28-29" string="the incident" id_sentence="6" />
        <mention ids_tokens="26-27" string="the incident" id_sentence="41" />
      </mentions>
    </coreference>
    <coreference id="6" type="NOMINAL">
      <referenced ids_tokens="24-25-26-27-28-29-30-31-32-33-34-35" string="sworn testimony that he had so little faith in his own report" id_sentence="2" />
      <mentions>
        <mention ids_tokens="4-5" string="his testimony" id_sentence="40" />
      </mentions>
    </coreference>
    <coreference id="7" type="NOMINAL">
      <referenced ids_tokens="33-34-35" string="his own report" id_sentence="2" />
      <mentions>
        <mention ids_tokens="13-14" string="the report" id_sentence="3" />
        <mention ids_tokens="31-32" string="his report" id_sentence="4" />
        <mention ids_tokens="36-37" string="his report" id_sentence="13" />
      </mentions>
    </coreference>
    <coreference id="8" type="PROPER">
      <referenced ids_tokens="17-18" string="Don Jackson" id_sentence="4" />
      <mentions>
        <mention ids_tokens="11" string="Jackson" id_sentence="5" />
        <mention ids_tokens="13" string="he" id_sentence="5" />
        <mention ids_tokens="17" string="him" id_sentence="5" />
        <mention ids_tokens="23" string="him" id_sentence="5" />
        <mention ids_tokens="11-12" string="Jackson's" id_sentence="8" />
        <mention ids_tokens="23" string="Jackson" id_sentence="8" />
        <mention ids_tokens="1-16" string="Jackson , a Hawthorne police sergeant on disability leave and a self-styled crusader against police brutality" id_sentence="9" />
        <mention ids_tokens="1" string="Jackson" id_sentence="9" />
        <mention ids_tokens="3-16" string="a Hawthorne police sergeant on disability leave and a self-styled crusader against police brutality" id_sentence="9" />
        <mention ids_tokens="3-9" string="a Hawthorne police sergeant on disability leave" id_sentence="9" />
        <mention ids_tokens="37" string="he" id_sentence="9" />
        <mention ids_tokens="12" string="Jackson" id_sentence="11" />
        <mention ids_tokens="22-24" string="Dickey and Jackson" id_sentence="12" />
        <mention ids_tokens="24" string="Jackson" id_sentence="12" />
        <mention ids_tokens="8" string="Jackson" id_sentence="13" />
        <mention ids_tokens="25" string="Jackson" id_sentence="13" />
        <mention ids_tokens="23" string="Jackson" id_sentence="20" />
        <mention ids_tokens="57-58" string="Jackson's" id_sentence="20" />
        <mention ids_tokens="19" string="Jackson" id_sentence="21" />
        <mention ids_tokens="21-22" string="Jackson's" id_sentence="22" />
        <mention ids_tokens="1-6" string="Jackson , also testifying under subpoena" id_sentence="23" />
        <mention ids_tokens="1" string="Jackson" id_sentence="23" />
        <mention ids_tokens="10" string="he" id_sentence="23" />
        <mention ids_tokens="1" string="He" id_sentence="24" />
        <mention ids_tokens="8" string="his" id_sentence="24" />
        <mention ids_tokens="16" string="him" id_sentence="24" />
        <mention ids_tokens="19" string="his" id_sentence="24" />
        <mention ids_tokens="23" string="him" id_sentence="24" />
        <mention ids_tokens="26" string="his" id_sentence="24" />
        <mention ids_tokens="3" string="Jackson" id_sentence="25" />
        <mention ids_tokens="12" string="his" id_sentence="25" />
        <mention ids_tokens="15" string="he" id_sentence="25" />
        <mention ids_tokens="15" string="Jackson" id_sentence="26" />
        <mention ids_tokens="13" string="Jackson" id_sentence="27" />
        <mention ids_tokens="8" string="Jackson" id_sentence="28" />
        <mention ids_tokens="16" string="Jackson" id_sentence="28" />
        <mention ids_tokens="18-19" string="Jackson's" id_sentence="29" />
        <mention ids_tokens="24" string="his" id_sentence="29" />
        <mention ids_tokens="6-20" string="Jackson , who immediately stepped out of the car after it came to a halt" id_sentence="31" />
        <mention ids_tokens="6" string="Jackson" id_sentence="31" />
        <mention ids_tokens="10-12" string="Dickey and Jackson" id_sentence="33" />
        <mention ids_tokens="12" string="Jackson" id_sentence="33" />
        <mention ids_tokens="20" string="Jackson" id_sentence="33" />
        <mention ids_tokens="15-30" string="Jackson in trying to demonstrate the type of hold Dickey used on Jackson during the arrest" id_sentence="34" />
        <mention ids_tokens="23-30" string="hold Dickey used on Jackson during the arrest" id_sentence="34" />
        <mention ids_tokens="27" string="Jackson" id_sentence="34" />
        <mention ids_tokens="17" string="Jackson" id_sentence="35" />
        <mention ids_tokens="4-5" string="Jackson's" id_sentence="37" />
        <mention ids_tokens="12" string="Jackson" id_sentence="37" />
        <mention ids_tokens="1" string="Jackson" id_sentence="38" />
        <mention ids_tokens="11" string="his" id_sentence="38" />
        <mention ids_tokens="16" string="his" id_sentence="38" />
        <mention ids_tokens="19" string="Jackson" id_sentence="38" />
        <mention ids_tokens="10" string="Jackson" id_sentence="39" />
        <mention ids_tokens="1" string="Jackson" id_sentence="40" />
        <mention ids_tokens="4" string="his" id_sentence="40" />
        <mention ids_tokens="8" string="his" id_sentence="40" />
        <mention ids_tokens="1" string="He" id_sentence="41" />
        <mention ids_tokens="3" string="he" id_sentence="41" />
        <mention ids_tokens="15" string="his" id_sentence="41" />
      </mentions>
    </coreference>
    <coreference id="9" type="NOMINAL">
      <referenced ids_tokens="24-25" string="the arrest" id_sentence="4" />
      <mentions>
        <mention ids_tokens="15-43" string="the arrest , during which Dickey swore at Jackson after stopping his car for an alleged traffic violation and then appeared to push his head through a plate-glass window" id_sentence="8" />
      </mentions>
    </coreference>
    <coreference id="10" type="NOMINAL">
      <referenced ids_tokens="12-13" string="his handcuffs" id_sentence="25" />
      <mentions>
        <mention ids_tokens="15" string="handcuffs" id_sentence="5" />
      </mentions>
    </coreference>
    <coreference id="11" type="NOMINAL">
      <referenced ids_tokens="20-21-22-23-24-25-26-27-28-29-30" string="the type of hold Dickey used on Jackson during the arrest" id_sentence="34" />
      <mentions>
        <mention ids_tokens="7-9" string="type of hold" id_sentence="35" />
        <mention ids_tokens="3" string="it" id_sentence="36" />
      </mentions>
    </coreference>
    <coreference id="13" type="PROPER">
      <referenced ids_tokens="1-2-3-4-5-6-7-8-9-10-11-12-13-14-15-16-17-18-19-20-21-22" string="Police Misconduct Allegations Sen. Daniel Boatwright ( D-Concord ) , chairman of the Senate Select Committee on State Procurement and Expenditure Practices" id_sentence="6" />
      <mentions>
        <mention ids_tokens="5" string="Boatwright" id_sentence="12" />
        <mention ids_tokens="1" string="Boatwright" id_sentence="13" />
        <mention ids_tokens="5" string="Boatwright" id_sentence="14" />
        <mention ids_tokens="21" string="he" id_sentence="14" />
        <mention ids_tokens="6" string="Boatwright" id_sentence="20" />
        <mention ids_tokens="50" string="he" id_sentence="20" />
        <mention ids_tokens="1" string="Boatwright" id_sentence="21" />
        <mention ids_tokens="8" string="Boatwright" id_sentence="33" />
        <mention ids_tokens="5" string="Boatwright" id_sentence="34" />
        <mention ids_tokens="1" string="Boatwright" id_sentence="35" />
        <mention ids_tokens="1" string="Boatwright" id_sentence="42" />
        <mention ids_tokens="1" string="He" id_sentence="43" />
      </mentions>
    </coreference>
    <coreference id="14" type="NOMINAL">
      <referenced ids_tokens="25-26" string="the hearing" id_sentence="6" />
      <mentions>
        <mention ids_tokens="3-24" string="the hearing , which was held at the Hall of Administration in downtown Los Angeles , after about six hours of testimony" id_sentence="42" />
        <mention ids_tokens="3" string="it" id_sentence="43" />
      </mentions>
    </coreference>
    <coreference id="16" type="NOMINAL">
      <referenced ids_tokens="12-13-14" string="no facial injuries" id_sentence="39" />
      <mentions>
        <mention ids_tokens="19" string="my" id_sentence="40" />
        <mention ids_tokens="27" string="I" id_sentence="40" />
      </mentions>
    </coreference>
    <coreference id="18" type="PROPER">
      <referenced ids_tokens="24-25-26-27-28-29" string="night with an NBC television crew" id_sentence="9" />
      <mentions>
        <mention ids_tokens="16" string="night" id_sentence="32" />
      </mentions>
    </coreference>
    <coreference id="19" type="NOMINAL">
      <referenced ids_tokens="52-53-54-55" string="Long Beach police officers" id_sentence="9" />
      <mentions>
        <mention ids_tokens="29-30" string="the officers" id_sentence="13" />
        <mention ids_tokens="6" string="officers" id_sentence="25" />
      </mentions>
    </coreference>
    <coreference id="21" type="PROPER">
      <referenced ids_tokens="10-11-12" string="Los Angeles County" id_sentence="10" />
      <mentions>
        <mention ids_tokens="16-17" string="Los Angeles" id_sentence="42" />
      </mentions>
    </coreference>
    <coreference id="22" type="NOMINAL">
      <referenced ids_tokens="22-23-24" string="the Jackson car" id_sentence="20" />
      <mentions>
        <mention ids_tokens="4-10" string="the car in which Jackson was riding" id_sentence="13" />
        <mention ids_tokens="18-21" string="the Jackson car's" id_sentence="21" />
        <mention ids_tokens="36-37" string="the car" id_sentence="21" />
        <mention ids_tokens="22-23" string="the car" id_sentence="23" />
        <mention ids_tokens="13-14" string="the car" id_sentence="31" />
        <mention ids_tokens="16" string="it" id_sentence="31" />
        <mention ids_tokens="34-35" string="the car" id_sentence="31" />
      </mentions>
    </coreference>
    <coreference id="24" type="NOMINAL">
      <referenced ids_tokens="1-2-3-4-5-6" string="Dickey 's attorney , Michael Hannon" id_sentence="16" />
      <mentions>
        <mention ids_tokens="12" string="him" id_sentence="19" />
      </mentions>
    </coreference>
    <coreference id="25" type="PROPER">
      <referenced ids_tokens="5-6" string="Michael Hannon" id_sentence="16" />
      <mentions>
        <mention ids_tokens="14" string="Hannon" id_sentence="18" />
      </mentions>
    </coreference>
    <coreference id="26" type="NOMINAL">
      <referenced ids_tokens="4" string="this" id_sentence="18" />
      <mentions>
        <mention ids_tokens="2" string="They" id_sentence="19" />
      </mentions>
    </coreference>
    <coreference id="27" type="NOMINAL">
      <referenced ids_tokens="6-7-8" string="a fair hearing" id_sentence="18" />
      <mentions>
        <mention ids_tokens="14" string="it" id_sentence="19" />
      </mentions>
    </coreference>
    <coreference id="31" type="NOMINAL">
      <referenced ids_tokens="18-19-20-21-22-23" string="the Jackson car 's rear window" id_sentence="21" />
      <mentions>
        <mention ids_tokens="19-20" string="the window" id_sentence="35" />
        <mention ids_tokens="9-10" string="the window" id_sentence="37" />
        <mention ids_tokens="8-9" string="the window" id_sentence="38" />
      </mentions>
    </coreference>
    <coreference id="32" type="NOMINAL">
      <referenced ids_tokens="4-5-6-7-8-9" string="the police car he was driving" id_sentence="22" />
      <mentions>
        <mention ids_tokens="32-34" string="the police car" id_sentence="24" />
      </mentions>
    </coreference>
    <coreference id="34" type="NOMINAL">
      <referenced ids_tokens="15-16-17-18-19-20-21-22-23" string="an off-duty federal corrections officer who drove the car" id_sentence="23" />
      <mentions>
        <mention ids_tokens="10-11" string="the officer" id_sentence="28" />
        <mention ids_tokens="21-22" string="the officer" id_sentence="28" />
        <mention ids_tokens="27-28" string="the officer" id_sentence="33" />
        <mention ids_tokens="10-11" string="the officer" id_sentence="35" />
        <mention ids_tokens="1-2" string="The officer" id_sentence="37" />
      </mentions>
    </coreference>
  </coreferences>
</document>
