<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="WSJ910710-0148">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>While the commission stopped short of blaming Chief Gates for these problems, it said that no chief should serve more than two consecutive five-year terms, and that Mr. Gates, having served 13 years, should therefore turn in his badge following a transition period.</content>
      <tokens>
        <token id="1" string="While" lemma="while" stem="while" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="commission" lemma="commission" stem="commiss" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="stopped" lemma="stop" stem="stop" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="short" lemma="short" stem="short" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="blaming" lemma="blame" stem="blame" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="Chief" lemma="Chief" stem="chief" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="true" is_refers="false" />
        <token id="9" string="Gates" lemma="Gates" stem="gate" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="these" lemma="these" stem="these" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="problems" lemma="problem" stem="problem" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="chief" lemma="chief" stem="chief" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="should" lemma="should" stem="should" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="serve" lemma="serve" stem="serv" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="more" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="24" string="consecutive" lemma="consecutive" stem="consecut" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="five-year" lemma="five-year" stem="five-year" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="26" string="terms" lemma="term" stem="term" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="Mr." lemma="Mr." stem="mr." pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="31" string="Gates" lemma="Gates" stem="gate" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="32" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="having" lemma="have" stem="have" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="served" lemma="serve" stem="serv" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="13" lemma="13" stem="13" pos="CD" type="Number" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="36" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="37" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="should" lemma="should" stem="should" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="therefore" lemma="therefore" stem="therefor" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="turn" lemma="turn" stem="turn" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="badge" lemma="badge" stem="badg" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="44" string="following" lemma="follow" stem="follow" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="45" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="46" string="transition" lemma="transition" stem="transit" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="47" string="period" lemma="period" stem="period" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="48" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN While) (S (NP (DT the) (NN commission)) (VP (VBD stopped) (ADVP (RB short)) (PP (IN of) (S (VP (VBG blaming) (NP (NP (NNP Chief) (NNP Gates)) (PP (IN for) (NP (DT these) (NNS problems)))))))))) (, ,) (NP (PRP it)) (VP (VBD said) (SBAR (SBAR (IN that) (S (NP (DT no) (NN chief)) (VP (MD should) (VP (VB serve) (NP (QP (JJR more) (IN than) (CD two)) (JJ consecutive) (JJ five-year) (NNS terms)))))) (, ,) (CC and) (SBAR (IN that) (S (NP (NNP Mr.) (NNP Gates)) (, ,) (S (VP (VBG having) (VP (VBN served) (NP-TMP (CD 13) (NNS years))))) (, ,) (VP (MD should) (ADVP (RB therefore)) (VP (VB turn) (PP (IN in) (NP (NP (PRP$ his) (NN badge)) (PP (VBG following) (NP (DT a) (NN transition) (NN period))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="stopped short of blaming Chief Gates for these problems" type="VP">
          <tokens>
            <token id="4" string="stopped" />
            <token id="5" string="short" />
            <token id="6" string="of" />
            <token id="7" string="blaming" />
            <token id="8" string="Chief" />
            <token id="9" string="Gates" />
            <token id="10" string="for" />
            <token id="11" string="these" />
            <token id="12" string="problems" />
          </tokens>
        </chunking>
        <chunking id="2" string="the commission" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="commission" />
          </tokens>
        </chunking>
        <chunking id="3" string="While the commission stopped short of blaming Chief Gates for these problems" type="SBAR">
          <tokens>
            <token id="1" string="While" />
            <token id="2" string="the" />
            <token id="3" string="commission" />
            <token id="4" string="stopped" />
            <token id="5" string="short" />
            <token id="6" string="of" />
            <token id="7" string="blaming" />
            <token id="8" string="Chief" />
            <token id="9" string="Gates" />
            <token id="10" string="for" />
            <token id="11" string="these" />
            <token id="12" string="problems" />
          </tokens>
        </chunking>
        <chunking id="4" string="more than two consecutive five-year terms" type="NP">
          <tokens>
            <token id="21" string="more" />
            <token id="22" string="than" />
            <token id="23" string="two" />
            <token id="24" string="consecutive" />
            <token id="25" string="five-year" />
            <token id="26" string="terms" />
          </tokens>
        </chunking>
        <chunking id="5" string="Chief Gates" type="NP">
          <tokens>
            <token id="8" string="Chief" />
            <token id="9" string="Gates" />
          </tokens>
        </chunking>
        <chunking id="6" string="it" type="NP">
          <tokens>
            <token id="14" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="Chief Gates for these problems" type="NP">
          <tokens>
            <token id="8" string="Chief" />
            <token id="9" string="Gates" />
            <token id="10" string="for" />
            <token id="11" string="these" />
            <token id="12" string="problems" />
          </tokens>
        </chunking>
        <chunking id="8" string="should serve more than two consecutive five-year terms" type="VP">
          <tokens>
            <token id="19" string="should" />
            <token id="20" string="serve" />
            <token id="21" string="more" />
            <token id="22" string="than" />
            <token id="23" string="two" />
            <token id="24" string="consecutive" />
            <token id="25" string="five-year" />
            <token id="26" string="terms" />
          </tokens>
        </chunking>
        <chunking id="9" string="served 13 years" type="VP">
          <tokens>
            <token id="34" string="served" />
            <token id="35" string="13" />
            <token id="36" string="years" />
          </tokens>
        </chunking>
        <chunking id="10" string="these problems" type="NP">
          <tokens>
            <token id="11" string="these" />
            <token id="12" string="problems" />
          </tokens>
        </chunking>
        <chunking id="11" string="that no chief should serve more than two consecutive five-year terms , and that Mr. Gates , having served 13 years , should therefore turn in his badge following a transition period" type="SBAR">
          <tokens>
            <token id="16" string="that" />
            <token id="17" string="no" />
            <token id="18" string="chief" />
            <token id="19" string="should" />
            <token id="20" string="serve" />
            <token id="21" string="more" />
            <token id="22" string="than" />
            <token id="23" string="two" />
            <token id="24" string="consecutive" />
            <token id="25" string="five-year" />
            <token id="26" string="terms" />
            <token id="27" string="," />
            <token id="28" string="and" />
            <token id="29" string="that" />
            <token id="30" string="Mr." />
            <token id="31" string="Gates" />
            <token id="32" string="," />
            <token id="33" string="having" />
            <token id="34" string="served" />
            <token id="35" string="13" />
            <token id="36" string="years" />
            <token id="37" string="," />
            <token id="38" string="should" />
            <token id="39" string="therefore" />
            <token id="40" string="turn" />
            <token id="41" string="in" />
            <token id="42" string="his" />
            <token id="43" string="badge" />
            <token id="44" string="following" />
            <token id="45" string="a" />
            <token id="46" string="transition" />
            <token id="47" string="period" />
          </tokens>
        </chunking>
        <chunking id="12" string="no chief" type="NP">
          <tokens>
            <token id="17" string="no" />
            <token id="18" string="chief" />
          </tokens>
        </chunking>
        <chunking id="13" string="having served 13 years" type="VP">
          <tokens>
            <token id="33" string="having" />
            <token id="34" string="served" />
            <token id="35" string="13" />
            <token id="36" string="years" />
          </tokens>
        </chunking>
        <chunking id="14" string="should therefore turn in his badge following a transition period" type="VP">
          <tokens>
            <token id="38" string="should" />
            <token id="39" string="therefore" />
            <token id="40" string="turn" />
            <token id="41" string="in" />
            <token id="42" string="his" />
            <token id="43" string="badge" />
            <token id="44" string="following" />
            <token id="45" string="a" />
            <token id="46" string="transition" />
            <token id="47" string="period" />
          </tokens>
        </chunking>
        <chunking id="15" string="his badge following a transition period" type="NP">
          <tokens>
            <token id="42" string="his" />
            <token id="43" string="badge" />
            <token id="44" string="following" />
            <token id="45" string="a" />
            <token id="46" string="transition" />
            <token id="47" string="period" />
          </tokens>
        </chunking>
        <chunking id="16" string="turn in his badge following a transition period" type="VP">
          <tokens>
            <token id="40" string="turn" />
            <token id="41" string="in" />
            <token id="42" string="his" />
            <token id="43" string="badge" />
            <token id="44" string="following" />
            <token id="45" string="a" />
            <token id="46" string="transition" />
            <token id="47" string="period" />
          </tokens>
        </chunking>
        <chunking id="17" string="his badge" type="NP">
          <tokens>
            <token id="42" string="his" />
            <token id="43" string="badge" />
          </tokens>
        </chunking>
        <chunking id="18" string="a transition period" type="NP">
          <tokens>
            <token id="45" string="a" />
            <token id="46" string="transition" />
            <token id="47" string="period" />
          </tokens>
        </chunking>
        <chunking id="19" string="blaming Chief Gates for these problems" type="VP">
          <tokens>
            <token id="7" string="blaming" />
            <token id="8" string="Chief" />
            <token id="9" string="Gates" />
            <token id="10" string="for" />
            <token id="11" string="these" />
            <token id="12" string="problems" />
          </tokens>
        </chunking>
        <chunking id="20" string="serve more than two consecutive five-year terms" type="VP">
          <tokens>
            <token id="20" string="serve" />
            <token id="21" string="more" />
            <token id="22" string="than" />
            <token id="23" string="two" />
            <token id="24" string="consecutive" />
            <token id="25" string="five-year" />
            <token id="26" string="terms" />
          </tokens>
        </chunking>
        <chunking id="21" string="Mr. Gates" type="NP">
          <tokens>
            <token id="30" string="Mr." />
            <token id="31" string="Gates" />
          </tokens>
        </chunking>
        <chunking id="22" string="that no chief should serve more than two consecutive five-year terms" type="SBAR">
          <tokens>
            <token id="16" string="that" />
            <token id="17" string="no" />
            <token id="18" string="chief" />
            <token id="19" string="should" />
            <token id="20" string="serve" />
            <token id="21" string="more" />
            <token id="22" string="than" />
            <token id="23" string="two" />
            <token id="24" string="consecutive" />
            <token id="25" string="five-year" />
            <token id="26" string="terms" />
          </tokens>
        </chunking>
        <chunking id="23" string="said that no chief should serve more than two consecutive five-year terms , and that Mr. Gates , having served 13 years , should therefore turn in his badge following a transition period" type="VP">
          <tokens>
            <token id="15" string="said" />
            <token id="16" string="that" />
            <token id="17" string="no" />
            <token id="18" string="chief" />
            <token id="19" string="should" />
            <token id="20" string="serve" />
            <token id="21" string="more" />
            <token id="22" string="than" />
            <token id="23" string="two" />
            <token id="24" string="consecutive" />
            <token id="25" string="five-year" />
            <token id="26" string="terms" />
            <token id="27" string="," />
            <token id="28" string="and" />
            <token id="29" string="that" />
            <token id="30" string="Mr." />
            <token id="31" string="Gates" />
            <token id="32" string="," />
            <token id="33" string="having" />
            <token id="34" string="served" />
            <token id="35" string="13" />
            <token id="36" string="years" />
            <token id="37" string="," />
            <token id="38" string="should" />
            <token id="39" string="therefore" />
            <token id="40" string="turn" />
            <token id="41" string="in" />
            <token id="42" string="his" />
            <token id="43" string="badge" />
            <token id="44" string="following" />
            <token id="45" string="a" />
            <token id="46" string="transition" />
            <token id="47" string="period" />
          </tokens>
        </chunking>
        <chunking id="24" string="that Mr. Gates , having served 13 years , should therefore turn in his badge following a transition period" type="SBAR">
          <tokens>
            <token id="29" string="that" />
            <token id="30" string="Mr." />
            <token id="31" string="Gates" />
            <token id="32" string="," />
            <token id="33" string="having" />
            <token id="34" string="served" />
            <token id="35" string="13" />
            <token id="36" string="years" />
            <token id="37" string="," />
            <token id="38" string="should" />
            <token id="39" string="therefore" />
            <token id="40" string="turn" />
            <token id="41" string="in" />
            <token id="42" string="his" />
            <token id="43" string="badge" />
            <token id="44" string="following" />
            <token id="45" string="a" />
            <token id="46" string="transition" />
            <token id="47" string="period" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="4">stopped</governor>
          <dependent id="1">While</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">commission</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">stopped</governor>
          <dependent id="3">commission</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="15">said</governor>
          <dependent id="4">stopped</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">stopped</governor>
          <dependent id="5">short</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">blaming</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">stopped</governor>
          <dependent id="7">blaming</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Gates</governor>
          <dependent id="8">Chief</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">blaming</governor>
          <dependent id="9">Gates</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">problems</governor>
          <dependent id="10">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">problems</governor>
          <dependent id="11">these</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">Gates</governor>
          <dependent id="12">problems</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">said</governor>
          <dependent id="14">it</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">said</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="20">serve</governor>
          <dependent id="16">that</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="18">chief</governor>
          <dependent id="17">no</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">serve</governor>
          <dependent id="18">chief</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="20">serve</governor>
          <dependent id="19">should</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="15">said</governor>
          <dependent id="20">serve</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="23">two</governor>
          <dependent id="21">more</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="21">more</governor>
          <dependent id="22">than</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="26">terms</governor>
          <dependent id="23">two</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">terms</governor>
          <dependent id="24">consecutive</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">terms</governor>
          <dependent id="25">five-year</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">serve</governor>
          <dependent id="26">terms</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="20">serve</governor>
          <dependent id="28">and</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="40">turn</governor>
          <dependent id="29">that</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">Gates</governor>
          <dependent id="30">Mr.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="40">turn</governor>
          <dependent id="31">Gates</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="34">served</governor>
          <dependent id="33">having</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="40">turn</governor>
          <dependent id="34">served</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="36">years</governor>
          <dependent id="35">13</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="34">served</governor>
          <dependent id="36">years</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="40">turn</governor>
          <dependent id="38">should</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="40">turn</governor>
          <dependent id="39">therefore</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="20">serve</governor>
          <dependent id="40">turn</dependent>
        </dependency>
        <dependency type="case">
          <governor id="43">badge</governor>
          <dependent id="41">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="43">badge</governor>
          <dependent id="42">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="40">turn</governor>
          <dependent id="43">badge</dependent>
        </dependency>
        <dependency type="case">
          <governor id="47">period</governor>
          <dependent id="44">following</dependent>
        </dependency>
        <dependency type="det">
          <governor id="47">period</governor>
          <dependent id="45">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="47">period</governor>
          <dependent id="46">transition</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="43">badge</governor>
          <dependent id="47">period</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Gates" type="PERSON" score="0.0">
          <tokens>
            <token id="31" string="Gates" />
          </tokens>
        </entity>
        <entity id="2" string="Chief" type="TITLE" score="0.0">
          <tokens>
            <token id="8" string="Chief" />
          </tokens>
        </entity>
        <entity id="3" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="23" string="two" />
          </tokens>
        </entity>
        <entity id="4" string="five-year" type="DURATION" score="0.0">
          <tokens>
            <token id="25" string="five-year" />
          </tokens>
        </entity>
        <entity id="5" string="13 years" type="DURATION" score="0.0">
          <tokens>
            <token id="35" string="13" />
            <token id="36" string="years" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>But the chief, who has remained steadfast through repeated calls from community leaders for his ouster, said later: &amp;quot;I don&amp;apost;t expect to just run away&amp;quot; from the job.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="chief" lemma="chief" stem="chief" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="remained" lemma="remain" stem="remain" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="steadfast" lemma="steadfast" stem="steadfast" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="repeated" lemma="repeat" stem="repeat" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="calls" lemma="call" stem="call" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="community" lemma="community" stem="commun" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="leaders" lemma="leader" stem="leader" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="ouster" lemma="ouster" stem="ouster" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="later" lemma="later" stem="later" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="expect" lemma="expect" stem="expect" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="run" lemma="run" stem="run" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="away" lemma="away" stem="awai" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="job" lemma="job" stem="job" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (NP (DT the) (NN chief)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBZ has) (VP (VBN remained) (NP (JJ steadfast)) (PP (IN through) (NP (NP (VBN repeated) (NNS calls)) (PP (IN from) (NP (NP (NN community) (NNS leaders)) (PP (IN for) (NP (PRP$ his) (NN ouster))))))))))) (, ,)) (VP (VBD said) (ADVP (RB later)) (: :) (`` ``) (S (NP (PRP I)) (VP (VBP do) (RB n't) (VP (VB expect) (S (VP (TO to) (ADVP (RB just)) (VP (VB run) (ADVP (RB away)) ('' '') (PP (IN from) (NP (DT the) (NN job)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the chief , who has remained steadfast through repeated calls from community leaders for his ouster ," type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="chief" />
            <token id="4" string="," />
            <token id="5" string="who" />
            <token id="6" string="has" />
            <token id="7" string="remained" />
            <token id="8" string="steadfast" />
            <token id="9" string="through" />
            <token id="10" string="repeated" />
            <token id="11" string="calls" />
            <token id="12" string="from" />
            <token id="13" string="community" />
            <token id="14" string="leaders" />
            <token id="15" string="for" />
            <token id="16" string="his" />
            <token id="17" string="ouster" />
            <token id="18" string="," />
          </tokens>
        </chunking>
        <chunking id="2" string="community leaders for his ouster" type="NP">
          <tokens>
            <token id="13" string="community" />
            <token id="14" string="leaders" />
            <token id="15" string="for" />
            <token id="16" string="his" />
            <token id="17" string="ouster" />
          </tokens>
        </chunking>
        <chunking id="3" string="the chief" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="chief" />
          </tokens>
        </chunking>
        <chunking id="4" string="community leaders" type="NP">
          <tokens>
            <token id="13" string="community" />
            <token id="14" string="leaders" />
          </tokens>
        </chunking>
        <chunking id="5" string="his ouster" type="NP">
          <tokens>
            <token id="16" string="his" />
            <token id="17" string="ouster" />
          </tokens>
        </chunking>
        <chunking id="6" string="the job" type="NP">
          <tokens>
            <token id="33" string="the" />
            <token id="34" string="job" />
          </tokens>
        </chunking>
        <chunking id="7" string="I" type="NP">
          <tokens>
            <token id="23" string="I" />
          </tokens>
        </chunking>
        <chunking id="8" string="expect to just run away '' from the job" type="VP">
          <tokens>
            <token id="26" string="expect" />
            <token id="27" string="to" />
            <token id="28" string="just" />
            <token id="29" string="run" />
            <token id="30" string="away" />
            <token id="31" string="&quot;" />
            <token id="32" string="from" />
            <token id="33" string="the" />
            <token id="34" string="job" />
          </tokens>
        </chunking>
        <chunking id="9" string="repeated calls from community leaders for his ouster" type="NP">
          <tokens>
            <token id="10" string="repeated" />
            <token id="11" string="calls" />
            <token id="12" string="from" />
            <token id="13" string="community" />
            <token id="14" string="leaders" />
            <token id="15" string="for" />
            <token id="16" string="his" />
            <token id="17" string="ouster" />
          </tokens>
        </chunking>
        <chunking id="10" string="said later : `` I do n't expect to just run away '' from the job" type="VP">
          <tokens>
            <token id="19" string="said" />
            <token id="20" string="later" />
            <token id="21" string=":" />
            <token id="22" string="&quot;" />
            <token id="23" string="I" />
            <token id="24" string="do" />
            <token id="25" string="n't" />
            <token id="26" string="expect" />
            <token id="27" string="to" />
            <token id="28" string="just" />
            <token id="29" string="run" />
            <token id="30" string="away" />
            <token id="31" string="&quot;" />
            <token id="32" string="from" />
            <token id="33" string="the" />
            <token id="34" string="job" />
          </tokens>
        </chunking>
        <chunking id="11" string="has remained steadfast through repeated calls from community leaders for his ouster" type="VP">
          <tokens>
            <token id="6" string="has" />
            <token id="7" string="remained" />
            <token id="8" string="steadfast" />
            <token id="9" string="through" />
            <token id="10" string="repeated" />
            <token id="11" string="calls" />
            <token id="12" string="from" />
            <token id="13" string="community" />
            <token id="14" string="leaders" />
            <token id="15" string="for" />
            <token id="16" string="his" />
            <token id="17" string="ouster" />
          </tokens>
        </chunking>
        <chunking id="12" string="repeated calls" type="NP">
          <tokens>
            <token id="10" string="repeated" />
            <token id="11" string="calls" />
          </tokens>
        </chunking>
        <chunking id="13" string="steadfast" type="NP">
          <tokens>
            <token id="8" string="steadfast" />
          </tokens>
        </chunking>
        <chunking id="14" string="remained steadfast through repeated calls from community leaders for his ouster" type="VP">
          <tokens>
            <token id="7" string="remained" />
            <token id="8" string="steadfast" />
            <token id="9" string="through" />
            <token id="10" string="repeated" />
            <token id="11" string="calls" />
            <token id="12" string="from" />
            <token id="13" string="community" />
            <token id="14" string="leaders" />
            <token id="15" string="for" />
            <token id="16" string="his" />
            <token id="17" string="ouster" />
          </tokens>
        </chunking>
        <chunking id="15" string="who has remained steadfast through repeated calls from community leaders for his ouster" type="SBAR">
          <tokens>
            <token id="5" string="who" />
            <token id="6" string="has" />
            <token id="7" string="remained" />
            <token id="8" string="steadfast" />
            <token id="9" string="through" />
            <token id="10" string="repeated" />
            <token id="11" string="calls" />
            <token id="12" string="from" />
            <token id="13" string="community" />
            <token id="14" string="leaders" />
            <token id="15" string="for" />
            <token id="16" string="his" />
            <token id="17" string="ouster" />
          </tokens>
        </chunking>
        <chunking id="16" string="to just run away '' from the job" type="VP">
          <tokens>
            <token id="27" string="to" />
            <token id="28" string="just" />
            <token id="29" string="run" />
            <token id="30" string="away" />
            <token id="31" string="&quot;" />
            <token id="32" string="from" />
            <token id="33" string="the" />
            <token id="34" string="job" />
          </tokens>
        </chunking>
        <chunking id="17" string="do n't expect to just run away '' from the job" type="VP">
          <tokens>
            <token id="24" string="do" />
            <token id="25" string="n't" />
            <token id="26" string="expect" />
            <token id="27" string="to" />
            <token id="28" string="just" />
            <token id="29" string="run" />
            <token id="30" string="away" />
            <token id="31" string="&quot;" />
            <token id="32" string="from" />
            <token id="33" string="the" />
            <token id="34" string="job" />
          </tokens>
        </chunking>
        <chunking id="18" string="run away '' from the job" type="VP">
          <tokens>
            <token id="29" string="run" />
            <token id="30" string="away" />
            <token id="31" string="&quot;" />
            <token id="32" string="from" />
            <token id="33" string="the" />
            <token id="34" string="job" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="19">said</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">chief</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">said</governor>
          <dependent id="3">chief</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">remained</governor>
          <dependent id="5">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">remained</governor>
          <dependent id="6">has</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="3">chief</governor>
          <dependent id="7">remained</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="7">remained</governor>
          <dependent id="8">steadfast</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">calls</governor>
          <dependent id="9">through</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">calls</governor>
          <dependent id="10">repeated</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">remained</governor>
          <dependent id="11">calls</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">leaders</governor>
          <dependent id="12">from</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">leaders</governor>
          <dependent id="13">community</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">calls</governor>
          <dependent id="14">leaders</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">ouster</governor>
          <dependent id="15">for</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="17">ouster</governor>
          <dependent id="16">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">leaders</governor>
          <dependent id="17">ouster</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="19">said</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="19">said</governor>
          <dependent id="20">later</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">expect</governor>
          <dependent id="23">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="26">expect</governor>
          <dependent id="24">do</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="26">expect</governor>
          <dependent id="25">n't</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="19">said</governor>
          <dependent id="26">expect</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="29">run</governor>
          <dependent id="27">to</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="29">run</governor>
          <dependent id="28">just</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="26">expect</governor>
          <dependent id="29">run</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="29">run</governor>
          <dependent id="30">away</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">job</governor>
          <dependent id="32">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="34">job</governor>
          <dependent id="33">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">run</governor>
          <dependent id="34">job</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>Nearly one-quarter of 650 officers responding to a commission survey agreed that &amp;quot;racial bias on the part of officers toward minority citizens currently exists and contributes to a negative interaction between police and community,&amp;quot; and in some cases &amp;quot;may lead to the use of excessive force,&amp;quot; the report said.</content>
      <tokens>
        <token id="1" string="Nearly" lemma="nearly" stem="nearli" pos="RB" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="2" string="one-quarter" lemma="one-quarter" stem="one-quart" pos="NN" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="650" lemma="650" stem="650" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="5" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="responding" lemma="respond" stem="respond" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="commission" lemma="commission" stem="commiss" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="survey" lemma="survey" stem="survei" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="agreed" lemma="agree" stem="agre" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="racial" lemma="racial" stem="racial" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="bias" lemma="bias" stem="bia" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="part" lemma="part" stem="part" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="21" string="toward" lemma="toward" stem="toward" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="22" string="minority" lemma="minority" stem="minor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="23" string="citizens" lemma="citizen" stem="citizen" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="24" string="currently" lemma="currently" stem="current" pos="RB" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="25" string="exists" lemma="exist" stem="exist" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="contributes" lemma="contribute" stem="contribut" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="negative" lemma="negative" stem="neg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="interaction" lemma="interaction" stem="interact" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="between" lemma="between" stem="between" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="community" lemma="community" stem="commun" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="cases" lemma="case" stem="case" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="may" lemma="may" stem="mai" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="lead" lemma="lead" stem="lead" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="45" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="46" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="47" string="use" lemma="use" stem="us" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="48" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="49" string="excessive" lemma="excessive" stem="excess" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="50" string="force" lemma="force" stem="forc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="51" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="52" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="53" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="54" string="report" lemma="report" stem="report" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="55" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="56" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (RB Nearly) (NN one-quarter)) (PP (IN of) (NP (NP (CD 650) (NNS officers)) (VP (VBG responding) (PP (TO to) (NP (DT a) (NN commission) (NN survey))))))) (VP (VBD agreed) (SBAR (SBAR (IN that) (S (`` ``) (NP (NP (JJ racial) (NN bias)) (PP (IN on) (NP (NP (DT the) (NN part)) (PP (IN of) (NP (NP (NNS officers)) (PP (IN toward) (NP (NN minority) (NNS citizens)))))))) (ADVP (RB currently)) (VP (VBZ exists) (CC and) (VBZ contributes) (PP (TO to) (NP (NP (DT a) (JJ negative) (NN interaction)) (PP (IN between) (NP (NN police) (CC and) (NN community)))))))) (, ,) ('' '') (CC and) (SBAR (IN in) (S (NP (DT some) (NNS cases)) (`` ``) (VP (MD may) (VP (VB lead) (PP (TO to) (NP (NP (DT the) (NN use)) (PP (IN of) (NP (JJ excessive) (NN force)))))))))))) (, ,) ('' '') (NP (DT the) (NN report)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the part" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="part" />
          </tokens>
        </chunking>
        <chunking id="2" string="that `` racial bias on the part of officers toward minority citizens currently exists and contributes to a negative interaction between police and community" type="SBAR">
          <tokens>
            <token id="12" string="that" />
            <token id="13" string="&quot;" />
            <token id="14" string="racial" />
            <token id="15" string="bias" />
            <token id="16" string="on" />
            <token id="17" string="the" />
            <token id="18" string="part" />
            <token id="19" string="of" />
            <token id="20" string="officers" />
            <token id="21" string="toward" />
            <token id="22" string="minority" />
            <token id="23" string="citizens" />
            <token id="24" string="currently" />
            <token id="25" string="exists" />
            <token id="26" string="and" />
            <token id="27" string="contributes" />
            <token id="28" string="to" />
            <token id="29" string="a" />
            <token id="30" string="negative" />
            <token id="31" string="interaction" />
            <token id="32" string="between" />
            <token id="33" string="police" />
            <token id="34" string="and" />
            <token id="35" string="community" />
          </tokens>
        </chunking>
        <chunking id="3" string="650 officers" type="NP">
          <tokens>
            <token id="4" string="650" />
            <token id="5" string="officers" />
          </tokens>
        </chunking>
        <chunking id="4" string="excessive force" type="NP">
          <tokens>
            <token id="49" string="excessive" />
            <token id="50" string="force" />
          </tokens>
        </chunking>
        <chunking id="5" string="racial bias" type="NP">
          <tokens>
            <token id="14" string="racial" />
            <token id="15" string="bias" />
          </tokens>
        </chunking>
        <chunking id="6" string="lead to the use of excessive force" type="VP">
          <tokens>
            <token id="44" string="lead" />
            <token id="45" string="to" />
            <token id="46" string="the" />
            <token id="47" string="use" />
            <token id="48" string="of" />
            <token id="49" string="excessive" />
            <token id="50" string="force" />
          </tokens>
        </chunking>
        <chunking id="7" string="a negative interaction between police and community" type="NP">
          <tokens>
            <token id="29" string="a" />
            <token id="30" string="negative" />
            <token id="31" string="interaction" />
            <token id="32" string="between" />
            <token id="33" string="police" />
            <token id="34" string="and" />
            <token id="35" string="community" />
          </tokens>
        </chunking>
        <chunking id="8" string="a commission survey" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="commission" />
            <token id="10" string="survey" />
          </tokens>
        </chunking>
        <chunking id="9" string="a negative interaction" type="NP">
          <tokens>
            <token id="29" string="a" />
            <token id="30" string="negative" />
            <token id="31" string="interaction" />
          </tokens>
        </chunking>
        <chunking id="10" string="the use of excessive force" type="NP">
          <tokens>
            <token id="46" string="the" />
            <token id="47" string="use" />
            <token id="48" string="of" />
            <token id="49" string="excessive" />
            <token id="50" string="force" />
          </tokens>
        </chunking>
        <chunking id="11" string="the report" type="NP">
          <tokens>
            <token id="53" string="the" />
            <token id="54" string="report" />
          </tokens>
        </chunking>
        <chunking id="12" string="in some cases `` may lead to the use of excessive force" type="SBAR">
          <tokens>
            <token id="39" string="in" />
            <token id="40" string="some" />
            <token id="41" string="cases" />
            <token id="42" string="&quot;" />
            <token id="43" string="may" />
            <token id="44" string="lead" />
            <token id="45" string="to" />
            <token id="46" string="the" />
            <token id="47" string="use" />
            <token id="48" string="of" />
            <token id="49" string="excessive" />
            <token id="50" string="force" />
          </tokens>
        </chunking>
        <chunking id="13" string="the use" type="NP">
          <tokens>
            <token id="46" string="the" />
            <token id="47" string="use" />
          </tokens>
        </chunking>
        <chunking id="14" string="Nearly one-quarter" type="NP">
          <tokens>
            <token id="1" string="Nearly" />
            <token id="2" string="one-quarter" />
          </tokens>
        </chunking>
        <chunking id="15" string="racial bias on the part of officers toward minority citizens" type="NP">
          <tokens>
            <token id="14" string="racial" />
            <token id="15" string="bias" />
            <token id="16" string="on" />
            <token id="17" string="the" />
            <token id="18" string="part" />
            <token id="19" string="of" />
            <token id="20" string="officers" />
            <token id="21" string="toward" />
            <token id="22" string="minority" />
            <token id="23" string="citizens" />
          </tokens>
        </chunking>
        <chunking id="16" string="police and community" type="NP">
          <tokens>
            <token id="33" string="police" />
            <token id="34" string="and" />
            <token id="35" string="community" />
          </tokens>
        </chunking>
        <chunking id="17" string="exists and contributes to a negative interaction between police and community" type="VP">
          <tokens>
            <token id="25" string="exists" />
            <token id="26" string="and" />
            <token id="27" string="contributes" />
            <token id="28" string="to" />
            <token id="29" string="a" />
            <token id="30" string="negative" />
            <token id="31" string="interaction" />
            <token id="32" string="between" />
            <token id="33" string="police" />
            <token id="34" string="and" />
            <token id="35" string="community" />
          </tokens>
        </chunking>
        <chunking id="18" string="the part of officers toward minority citizens" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="part" />
            <token id="19" string="of" />
            <token id="20" string="officers" />
            <token id="21" string="toward" />
            <token id="22" string="minority" />
            <token id="23" string="citizens" />
          </tokens>
        </chunking>
        <chunking id="19" string="some cases" type="NP">
          <tokens>
            <token id="40" string="some" />
            <token id="41" string="cases" />
          </tokens>
        </chunking>
        <chunking id="20" string="agreed that `` racial bias on the part of officers toward minority citizens currently exists and contributes to a negative interaction between police and community , '' and in some cases `` may lead to the use of excessive force" type="VP">
          <tokens>
            <token id="11" string="agreed" />
            <token id="12" string="that" />
            <token id="13" string="&quot;" />
            <token id="14" string="racial" />
            <token id="15" string="bias" />
            <token id="16" string="on" />
            <token id="17" string="the" />
            <token id="18" string="part" />
            <token id="19" string="of" />
            <token id="20" string="officers" />
            <token id="21" string="toward" />
            <token id="22" string="minority" />
            <token id="23" string="citizens" />
            <token id="24" string="currently" />
            <token id="25" string="exists" />
            <token id="26" string="and" />
            <token id="27" string="contributes" />
            <token id="28" string="to" />
            <token id="29" string="a" />
            <token id="30" string="negative" />
            <token id="31" string="interaction" />
            <token id="32" string="between" />
            <token id="33" string="police" />
            <token id="34" string="and" />
            <token id="35" string="community" />
            <token id="36" string="," />
            <token id="37" string="&quot;" />
            <token id="38" string="and" />
            <token id="39" string="in" />
            <token id="40" string="some" />
            <token id="41" string="cases" />
            <token id="42" string="&quot;" />
            <token id="43" string="may" />
            <token id="44" string="lead" />
            <token id="45" string="to" />
            <token id="46" string="the" />
            <token id="47" string="use" />
            <token id="48" string="of" />
            <token id="49" string="excessive" />
            <token id="50" string="force" />
          </tokens>
        </chunking>
        <chunking id="21" string="that `` racial bias on the part of officers toward minority citizens currently exists and contributes to a negative interaction between police and community , '' and in some cases `` may lead to the use of excessive force" type="SBAR">
          <tokens>
            <token id="12" string="that" />
            <token id="13" string="&quot;" />
            <token id="14" string="racial" />
            <token id="15" string="bias" />
            <token id="16" string="on" />
            <token id="17" string="the" />
            <token id="18" string="part" />
            <token id="19" string="of" />
            <token id="20" string="officers" />
            <token id="21" string="toward" />
            <token id="22" string="minority" />
            <token id="23" string="citizens" />
            <token id="24" string="currently" />
            <token id="25" string="exists" />
            <token id="26" string="and" />
            <token id="27" string="contributes" />
            <token id="28" string="to" />
            <token id="29" string="a" />
            <token id="30" string="negative" />
            <token id="31" string="interaction" />
            <token id="32" string="between" />
            <token id="33" string="police" />
            <token id="34" string="and" />
            <token id="35" string="community" />
            <token id="36" string="," />
            <token id="37" string="&quot;" />
            <token id="38" string="and" />
            <token id="39" string="in" />
            <token id="40" string="some" />
            <token id="41" string="cases" />
            <token id="42" string="&quot;" />
            <token id="43" string="may" />
            <token id="44" string="lead" />
            <token id="45" string="to" />
            <token id="46" string="the" />
            <token id="47" string="use" />
            <token id="48" string="of" />
            <token id="49" string="excessive" />
            <token id="50" string="force" />
          </tokens>
        </chunking>
        <chunking id="22" string="650 officers responding to a commission survey" type="NP">
          <tokens>
            <token id="4" string="650" />
            <token id="5" string="officers" />
            <token id="6" string="responding" />
            <token id="7" string="to" />
            <token id="8" string="a" />
            <token id="9" string="commission" />
            <token id="10" string="survey" />
          </tokens>
        </chunking>
        <chunking id="23" string="responding to a commission survey" type="VP">
          <tokens>
            <token id="6" string="responding" />
            <token id="7" string="to" />
            <token id="8" string="a" />
            <token id="9" string="commission" />
            <token id="10" string="survey" />
          </tokens>
        </chunking>
        <chunking id="24" string="officers toward minority citizens" type="NP">
          <tokens>
            <token id="20" string="officers" />
            <token id="21" string="toward" />
            <token id="22" string="minority" />
            <token id="23" string="citizens" />
          </tokens>
        </chunking>
        <chunking id="25" string="minority citizens" type="NP">
          <tokens>
            <token id="22" string="minority" />
            <token id="23" string="citizens" />
          </tokens>
        </chunking>
        <chunking id="26" string="Nearly one-quarter of 650 officers responding to a commission survey" type="NP">
          <tokens>
            <token id="1" string="Nearly" />
            <token id="2" string="one-quarter" />
            <token id="3" string="of" />
            <token id="4" string="650" />
            <token id="5" string="officers" />
            <token id="6" string="responding" />
            <token id="7" string="to" />
            <token id="8" string="a" />
            <token id="9" string="commission" />
            <token id="10" string="survey" />
          </tokens>
        </chunking>
        <chunking id="27" string="may lead to the use of excessive force" type="VP">
          <tokens>
            <token id="43" string="may" />
            <token id="44" string="lead" />
            <token id="45" string="to" />
            <token id="46" string="the" />
            <token id="47" string="use" />
            <token id="48" string="of" />
            <token id="49" string="excessive" />
            <token id="50" string="force" />
          </tokens>
        </chunking>
        <chunking id="28" string="said" type="VP">
          <tokens>
            <token id="55" string="said" />
          </tokens>
        </chunking>
        <chunking id="29" string="officers" type="NP">
          <tokens>
            <token id="20" string="officers" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="2">one-quarter</governor>
          <dependent id="1">Nearly</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">agreed</governor>
          <dependent id="2">one-quarter</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">officers</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="5">officers</governor>
          <dependent id="4">650</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">one-quarter</governor>
          <dependent id="5">officers</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="5">officers</governor>
          <dependent id="6">responding</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">survey</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">survey</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">survey</governor>
          <dependent id="9">commission</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">responding</governor>
          <dependent id="10">survey</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="55">said</governor>
          <dependent id="11">agreed</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="25">exists</governor>
          <dependent id="12">that</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">bias</governor>
          <dependent id="14">racial</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">exists</governor>
          <dependent id="15">bias</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">part</governor>
          <dependent id="16">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">part</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">bias</governor>
          <dependent id="18">part</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">officers</governor>
          <dependent id="19">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">part</governor>
          <dependent id="20">officers</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">citizens</governor>
          <dependent id="21">toward</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">citizens</governor>
          <dependent id="22">minority</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">officers</governor>
          <dependent id="23">citizens</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="25">exists</governor>
          <dependent id="24">currently</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="11">agreed</governor>
          <dependent id="25">exists</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="25">exists</governor>
          <dependent id="26">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="25">exists</governor>
          <dependent id="27">contributes</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">interaction</governor>
          <dependent id="28">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">interaction</governor>
          <dependent id="29">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="31">interaction</governor>
          <dependent id="30">negative</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">exists</governor>
          <dependent id="31">interaction</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">police</governor>
          <dependent id="32">between</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">interaction</governor>
          <dependent id="33">police</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="33">police</governor>
          <dependent id="34">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="33">police</governor>
          <dependent id="35">community</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="25">exists</governor>
          <dependent id="38">and</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="44">lead</governor>
          <dependent id="39">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="41">cases</governor>
          <dependent id="40">some</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="44">lead</governor>
          <dependent id="41">cases</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="44">lead</governor>
          <dependent id="43">may</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="25">exists</governor>
          <dependent id="44">lead</dependent>
        </dependency>
        <dependency type="case">
          <governor id="47">use</governor>
          <dependent id="45">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="47">use</governor>
          <dependent id="46">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="44">lead</governor>
          <dependent id="47">use</dependent>
        </dependency>
        <dependency type="case">
          <governor id="50">force</governor>
          <dependent id="48">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="50">force</governor>
          <dependent id="49">excessive</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="47">use</governor>
          <dependent id="50">force</dependent>
        </dependency>
        <dependency type="det">
          <governor id="54">report</governor>
          <dependent id="53">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="55">said</governor>
          <dependent id="54">report</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="55">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="650" type="NUMBER" score="0.0">
          <tokens>
            <token id="4" string="650" />
          </tokens>
        </entity>
        <entity id="2" string="currently" type="DATE" score="0.0">
          <tokens>
            <token id="24" string="currently" />
          </tokens>
        </entity>
        <entity id="3" string="Nearly one-quarter" type="DURATION" score="0.0">
          <tokens>
            <token id="1" string="Nearly" />
            <token id="2" string="one-quarter" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="false">
      <content>A scant eight hours is devoted to cultural awareness training at the Los Angeles Police Academy, and many officers who train new recruits in the field openly perpetuate the &amp;quot;siege mentality that alienates patrol officers from the community,&amp;quot; the commission concluded.</content>
      <tokens>
        <token id="1" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="scant" lemma="scant" stem="scant" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="eight" lemma="eight" stem="eight" pos="CD" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="4" string="hours" lemma="hour" stem="hour" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="5" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="devoted" lemma="devote" stem="devot" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="cultural" lemma="cultural" stem="cultur" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="awareness" lemma="awareness" stem="awar" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="training" lemma="training" stem="train" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Los" lemma="Los" stem="lo" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="14" string="Angeles" lemma="Angeles" stem="angele" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="15" string="Police" lemma="Police" stem="polic" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="16" string="Academy" lemma="Academy" stem="academi" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="many" lemma="many" stem="mani" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="train" lemma="train" stem="train" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="new" lemma="new" stem="new" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="recruits" lemma="recruit" stem="recruit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="field" lemma="field" stem="field" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="openly" lemma="openly" stem="openli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="perpetuate" lemma="perpetuate" stem="perpetu" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="siege" lemma="siege" stem="sieg" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="mentality" lemma="mentality" stem="mental" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="alienates" lemma="alienate" stem="alien" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="patrol" lemma="patrol" stem="patrol" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="community" lemma="community" stem="commun" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="commission" lemma="commission" stem="commiss" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="45" string="concluded" lemma="conclude" stem="conclud" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="46" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (S (NP (DT A) (JJ scant) (CD eight) (NNS hours)) (VP (VBZ is) (VP (VBN devoted) (PP (TO to) (NP (NP (JJ cultural) (NN awareness) (NN training)) (PP (IN at) (NP (DT the) (NNP Los) (NNP Angeles) (NNP Police) (NNP Academy)))))))) (, ,) (CC and) (S (NP (NP (JJ many) (NNS officers)) (SBAR (WHNP (WP who)) (S (VP (VBP train) (NP (NP (JJ new) (NNS recruits)) (PP (IN in) (NP (DT the) (NN field)))))))) (ADVP (RB openly)) (VP (VBP perpetuate) (NP (NP (DT the) (`` ``) (NN siege) (NN mentality)) (SBAR (WHNP (WDT that)) (S (VP (VBZ alienates) (NP (NN patrol) (NNS officers)) (PP (IN from) (NP (DT the) (NN community)))))))))) (, ,) ('' '') (NP (DT the) (NN commission)) (VP (VBD concluded)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="who train new recruits in the field" type="SBAR">
          <tokens>
            <token id="21" string="who" />
            <token id="22" string="train" />
            <token id="23" string="new" />
            <token id="24" string="recruits" />
            <token id="25" string="in" />
            <token id="26" string="the" />
            <token id="27" string="field" />
          </tokens>
        </chunking>
        <chunking id="2" string="the commission" type="NP">
          <tokens>
            <token id="43" string="the" />
            <token id="44" string="commission" />
          </tokens>
        </chunking>
        <chunking id="3" string="devoted to cultural awareness training at the Los Angeles Police Academy" type="VP">
          <tokens>
            <token id="6" string="devoted" />
            <token id="7" string="to" />
            <token id="8" string="cultural" />
            <token id="9" string="awareness" />
            <token id="10" string="training" />
            <token id="11" string="at" />
            <token id="12" string="the" />
            <token id="13" string="Los" />
            <token id="14" string="Angeles" />
            <token id="15" string="Police" />
            <token id="16" string="Academy" />
          </tokens>
        </chunking>
        <chunking id="4" string="train new recruits in the field" type="VP">
          <tokens>
            <token id="22" string="train" />
            <token id="23" string="new" />
            <token id="24" string="recruits" />
            <token id="25" string="in" />
            <token id="26" string="the" />
            <token id="27" string="field" />
          </tokens>
        </chunking>
        <chunking id="5" string="alienates patrol officers from the community" type="VP">
          <tokens>
            <token id="35" string="alienates" />
            <token id="36" string="patrol" />
            <token id="37" string="officers" />
            <token id="38" string="from" />
            <token id="39" string="the" />
            <token id="40" string="community" />
          </tokens>
        </chunking>
        <chunking id="6" string="the `` siege mentality" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="&quot;" />
            <token id="32" string="siege" />
            <token id="33" string="mentality" />
          </tokens>
        </chunking>
        <chunking id="7" string="that alienates patrol officers from the community" type="SBAR">
          <tokens>
            <token id="34" string="that" />
            <token id="35" string="alienates" />
            <token id="36" string="patrol" />
            <token id="37" string="officers" />
            <token id="38" string="from" />
            <token id="39" string="the" />
            <token id="40" string="community" />
          </tokens>
        </chunking>
        <chunking id="8" string="A scant eight hours" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="scant" />
            <token id="3" string="eight" />
            <token id="4" string="hours" />
          </tokens>
        </chunking>
        <chunking id="9" string="many officers who train new recruits in the field" type="NP">
          <tokens>
            <token id="19" string="many" />
            <token id="20" string="officers" />
            <token id="21" string="who" />
            <token id="22" string="train" />
            <token id="23" string="new" />
            <token id="24" string="recruits" />
            <token id="25" string="in" />
            <token id="26" string="the" />
            <token id="27" string="field" />
          </tokens>
        </chunking>
        <chunking id="10" string="concluded" type="VP">
          <tokens>
            <token id="45" string="concluded" />
          </tokens>
        </chunking>
        <chunking id="11" string="the `` siege mentality that alienates patrol officers from the community" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="&quot;" />
            <token id="32" string="siege" />
            <token id="33" string="mentality" />
            <token id="34" string="that" />
            <token id="35" string="alienates" />
            <token id="36" string="patrol" />
            <token id="37" string="officers" />
            <token id="38" string="from" />
            <token id="39" string="the" />
            <token id="40" string="community" />
          </tokens>
        </chunking>
        <chunking id="12" string="patrol officers" type="NP">
          <tokens>
            <token id="36" string="patrol" />
            <token id="37" string="officers" />
          </tokens>
        </chunking>
        <chunking id="13" string="cultural awareness training at the Los Angeles Police Academy" type="NP">
          <tokens>
            <token id="8" string="cultural" />
            <token id="9" string="awareness" />
            <token id="10" string="training" />
            <token id="11" string="at" />
            <token id="12" string="the" />
            <token id="13" string="Los" />
            <token id="14" string="Angeles" />
            <token id="15" string="Police" />
            <token id="16" string="Academy" />
          </tokens>
        </chunking>
        <chunking id="14" string="the community" type="NP">
          <tokens>
            <token id="39" string="the" />
            <token id="40" string="community" />
          </tokens>
        </chunking>
        <chunking id="15" string="the field" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="field" />
          </tokens>
        </chunking>
        <chunking id="16" string="is devoted to cultural awareness training at the Los Angeles Police Academy" type="VP">
          <tokens>
            <token id="5" string="is" />
            <token id="6" string="devoted" />
            <token id="7" string="to" />
            <token id="8" string="cultural" />
            <token id="9" string="awareness" />
            <token id="10" string="training" />
            <token id="11" string="at" />
            <token id="12" string="the" />
            <token id="13" string="Los" />
            <token id="14" string="Angeles" />
            <token id="15" string="Police" />
            <token id="16" string="Academy" />
          </tokens>
        </chunking>
        <chunking id="17" string="cultural awareness training" type="NP">
          <tokens>
            <token id="8" string="cultural" />
            <token id="9" string="awareness" />
            <token id="10" string="training" />
          </tokens>
        </chunking>
        <chunking id="18" string="many officers" type="NP">
          <tokens>
            <token id="19" string="many" />
            <token id="20" string="officers" />
          </tokens>
        </chunking>
        <chunking id="19" string="perpetuate the `` siege mentality that alienates patrol officers from the community" type="VP">
          <tokens>
            <token id="29" string="perpetuate" />
            <token id="30" string="the" />
            <token id="31" string="&quot;" />
            <token id="32" string="siege" />
            <token id="33" string="mentality" />
            <token id="34" string="that" />
            <token id="35" string="alienates" />
            <token id="36" string="patrol" />
            <token id="37" string="officers" />
            <token id="38" string="from" />
            <token id="39" string="the" />
            <token id="40" string="community" />
          </tokens>
        </chunking>
        <chunking id="20" string="the Los Angeles Police Academy" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="Los" />
            <token id="14" string="Angeles" />
            <token id="15" string="Police" />
            <token id="16" string="Academy" />
          </tokens>
        </chunking>
        <chunking id="21" string="new recruits" type="NP">
          <tokens>
            <token id="23" string="new" />
            <token id="24" string="recruits" />
          </tokens>
        </chunking>
        <chunking id="22" string="new recruits in the field" type="NP">
          <tokens>
            <token id="23" string="new" />
            <token id="24" string="recruits" />
            <token id="25" string="in" />
            <token id="26" string="the" />
            <token id="27" string="field" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="4">hours</governor>
          <dependent id="1">A</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">hours</governor>
          <dependent id="2">scant</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="4">hours</governor>
          <dependent id="3">eight</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="6">devoted</governor>
          <dependent id="4">hours</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="6">devoted</governor>
          <dependent id="5">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="45">concluded</governor>
          <dependent id="6">devoted</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">training</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">training</governor>
          <dependent id="8">cultural</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">training</governor>
          <dependent id="9">awareness</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">devoted</governor>
          <dependent id="10">training</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">Academy</governor>
          <dependent id="11">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">Academy</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Academy</governor>
          <dependent id="13">Los</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Academy</governor>
          <dependent id="14">Angeles</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Academy</governor>
          <dependent id="15">Police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">training</governor>
          <dependent id="16">Academy</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">devoted</governor>
          <dependent id="18">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">officers</governor>
          <dependent id="19">many</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">perpetuate</governor>
          <dependent id="20">officers</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">train</governor>
          <dependent id="21">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="20">officers</governor>
          <dependent id="22">train</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">recruits</governor>
          <dependent id="23">new</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">train</governor>
          <dependent id="24">recruits</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">field</governor>
          <dependent id="25">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">field</governor>
          <dependent id="26">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">recruits</governor>
          <dependent id="27">field</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="29">perpetuate</governor>
          <dependent id="28">openly</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">devoted</governor>
          <dependent id="29">perpetuate</dependent>
        </dependency>
        <dependency type="det">
          <governor id="33">mentality</governor>
          <dependent id="30">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="33">mentality</governor>
          <dependent id="32">siege</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="29">perpetuate</governor>
          <dependent id="33">mentality</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="35">alienates</governor>
          <dependent id="34">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="33">mentality</governor>
          <dependent id="35">alienates</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="37">officers</governor>
          <dependent id="36">patrol</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="35">alienates</governor>
          <dependent id="37">officers</dependent>
        </dependency>
        <dependency type="case">
          <governor id="40">community</governor>
          <dependent id="38">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="40">community</governor>
          <dependent id="39">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="35">alienates</governor>
          <dependent id="40">community</dependent>
        </dependency>
        <dependency type="det">
          <governor id="44">commission</governor>
          <dependent id="43">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="45">concluded</governor>
          <dependent id="44">commission</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="45">concluded</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Los Angeles Police Academy" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="13" string="Los" />
            <token id="14" string="Angeles" />
            <token id="15" string="Police" />
            <token id="16" string="Academy" />
          </tokens>
        </entity>
        <entity id="2" string="eight hours" type="DURATION" score="0.0">
          <tokens>
            <token id="3" string="eight" />
            <token id="4" string="hours" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>Officers commonly typed racial epithets to one another on their patrol car computer systems, such as: &amp;quot;Sounds like monkey slapping time&amp;quot; and &amp;quot;I almost got me a Mexican last night.&amp;quot;</content>
      <tokens>
        <token id="1" string="Officers" lemma="officer" stem="officer" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="commonly" lemma="commonly" stem="commonli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="typed" lemma="type" stem="type" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="racial" lemma="racial" stem="racial" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="epithets" lemma="epithet" stem="epithet" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="8" string="another" lemma="another" stem="anoth" pos="DT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="patrol" lemma="patrol" stem="patrol" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="car" lemma="car" stem="car" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="computer" lemma="computer" stem="comput" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="systems" lemma="system" stem="system" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="such" lemma="such" stem="such" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="Sounds" lemma="sound" stem="sound" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="monkey" lemma="monkey" stem="monkei" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="slapping" lemma="slapping" stem="slap" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="29" string="almost" lemma="almost" stem="almost" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="got" lemma="get" stem="got" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="32" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="33" string="Mexican" lemma="mexican" stem="mexican" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="34" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="35" string="night" lemma="night" stem="night" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="36" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNS Officers)) (PRN (SINV (ADVP (RB commonly)) (VP (VBD typed) (NP (JJ racial) (NNS epithets)) (PP (TO to) (NP (CD one) (DT another))) (PP (IN on) (NP (PRP$ their) (NN patrol) (NN car)))) (NP (NP (NN computer) (NNS systems)) (, ,) (NP (NP (JJ such)) (PP (IN as)))) (: :))) (`` ``) (VP (VBZ Sounds) (PP (IN like) (NP (NN monkey))) (NP (NP (NN slapping) (NN time)) ('' '') (CC and) (`` ``) (S (NP (PRP I)) (ADVP (RB almost)) (VP (VBD got) (NP (PRP me) (DT a)) (NP-TMP (JJ Mexican) (JJ last) (NN night)))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="Officers" type="NP">
          <tokens>
            <token id="1" string="Officers" />
          </tokens>
        </chunking>
        <chunking id="2" string="monkey" type="NP">
          <tokens>
            <token id="22" string="monkey" />
          </tokens>
        </chunking>
        <chunking id="3" string="slapping time '' and `` I almost got me a Mexican last night" type="NP">
          <tokens>
            <token id="23" string="slapping" />
            <token id="24" string="time" />
            <token id="25" string="&quot;" />
            <token id="26" string="and" />
            <token id="27" string="&quot;" />
            <token id="28" string="I" />
            <token id="29" string="almost" />
            <token id="30" string="got" />
            <token id="31" string="me" />
            <token id="32" string="a" />
            <token id="33" string="Mexican" />
            <token id="34" string="last" />
            <token id="35" string="night" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="28" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="one another" type="NP">
          <tokens>
            <token id="7" string="one" />
            <token id="8" string="another" />
          </tokens>
        </chunking>
        <chunking id="6" string="me a" type="NP">
          <tokens>
            <token id="31" string="me" />
            <token id="32" string="a" />
          </tokens>
        </chunking>
        <chunking id="7" string="such" type="NP">
          <tokens>
            <token id="16" string="such" />
          </tokens>
        </chunking>
        <chunking id="8" string="their patrol car" type="NP">
          <tokens>
            <token id="10" string="their" />
            <token id="11" string="patrol" />
            <token id="12" string="car" />
          </tokens>
        </chunking>
        <chunking id="9" string="typed racial epithets to one another on their patrol car" type="VP">
          <tokens>
            <token id="3" string="typed" />
            <token id="4" string="racial" />
            <token id="5" string="epithets" />
            <token id="6" string="to" />
            <token id="7" string="one" />
            <token id="8" string="another" />
            <token id="9" string="on" />
            <token id="10" string="their" />
            <token id="11" string="patrol" />
            <token id="12" string="car" />
          </tokens>
        </chunking>
        <chunking id="10" string="computer systems" type="NP">
          <tokens>
            <token id="13" string="computer" />
            <token id="14" string="systems" />
          </tokens>
        </chunking>
        <chunking id="11" string="racial epithets" type="NP">
          <tokens>
            <token id="4" string="racial" />
            <token id="5" string="epithets" />
          </tokens>
        </chunking>
        <chunking id="12" string="got me a Mexican last night" type="VP">
          <tokens>
            <token id="30" string="got" />
            <token id="31" string="me" />
            <token id="32" string="a" />
            <token id="33" string="Mexican" />
            <token id="34" string="last" />
            <token id="35" string="night" />
          </tokens>
        </chunking>
        <chunking id="13" string="such as" type="NP">
          <tokens>
            <token id="16" string="such" />
            <token id="17" string="as" />
          </tokens>
        </chunking>
        <chunking id="14" string="computer systems , such as" type="NP">
          <tokens>
            <token id="13" string="computer" />
            <token id="14" string="systems" />
            <token id="15" string="," />
            <token id="16" string="such" />
            <token id="17" string="as" />
          </tokens>
        </chunking>
        <chunking id="15" string="Sounds like monkey slapping time '' and `` I almost got me a Mexican last night" type="VP">
          <tokens>
            <token id="20" string="Sounds" />
            <token id="21" string="like" />
            <token id="22" string="monkey" />
            <token id="23" string="slapping" />
            <token id="24" string="time" />
            <token id="25" string="&quot;" />
            <token id="26" string="and" />
            <token id="27" string="&quot;" />
            <token id="28" string="I" />
            <token id="29" string="almost" />
            <token id="30" string="got" />
            <token id="31" string="me" />
            <token id="32" string="a" />
            <token id="33" string="Mexican" />
            <token id="34" string="last" />
            <token id="35" string="night" />
          </tokens>
        </chunking>
        <chunking id="16" string="slapping time" type="NP">
          <tokens>
            <token id="23" string="slapping" />
            <token id="24" string="time" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="20">Sounds</governor>
          <dependent id="1">Officers</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">typed</governor>
          <dependent id="2">commonly</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="20">Sounds</governor>
          <dependent id="3">typed</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">epithets</governor>
          <dependent id="4">racial</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">typed</governor>
          <dependent id="5">epithets</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">one</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">typed</governor>
          <dependent id="7">one</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="7">one</governor>
          <dependent id="8">another</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">car</governor>
          <dependent id="9">on</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="12">car</governor>
          <dependent id="10">their</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">car</governor>
          <dependent id="11">patrol</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">typed</governor>
          <dependent id="12">car</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">systems</governor>
          <dependent id="13">computer</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">typed</governor>
          <dependent id="14">systems</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="14">systems</governor>
          <dependent id="16">such</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="16">such</governor>
          <dependent id="17">as</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="20">Sounds</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">monkey</governor>
          <dependent id="21">like</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">Sounds</governor>
          <dependent id="22">monkey</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">time</governor>
          <dependent id="23">slapping</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">Sounds</governor>
          <dependent id="24">time</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="24">time</governor>
          <dependent id="26">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="30">got</governor>
          <dependent id="28">I</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="30">got</governor>
          <dependent id="29">almost</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="24">time</governor>
          <dependent id="30">got</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="30">got</governor>
          <dependent id="31">me</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="31">me</governor>
          <dependent id="32">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="35">night</governor>
          <dependent id="33">Mexican</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="35">night</governor>
          <dependent id="34">last</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="30">got</governor>
          <dependent id="35">night</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Mexican" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="33" string="Mexican" />
          </tokens>
        </entity>
        <entity id="2" string="last night" type="DATE" score="0.0">
          <tokens>
            <token id="34" string="last" />
            <token id="35" string="night" />
          </tokens>
        </entity>
        <entity id="3" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="7" string="one" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>Yet supervisors made no effort to monitor or control these messages, evidence of a &amp;quot;significant breakdown in the department&amp;apost;s management responsibility,&amp;quot; the report found.</content>
      <tokens>
        <token id="1" string="Yet" lemma="yet" stem="yet" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="supervisors" lemma="supervisor" stem="supervisor" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="made" lemma="make" stem="made" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="effort" lemma="effort" stem="effort" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="monitor" lemma="monitor" stem="monitor" pos="VB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="control" lemma="control" stem="control" pos="VB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="these" lemma="these" stem="these" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="messages" lemma="message" stem="messag" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="evidence" lemma="evidence" stem="evid" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="significant" lemma="significant" stem="signific" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="breakdown" lemma="breakdown" stem="breakdown" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="department" lemma="department" stem="depart" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="23" string="management" lemma="management" stem="manag" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="responsibility" lemma="responsibility" stem="respons" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="25" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="report" lemma="report" stem="report" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="found" lemma="find" stem="found" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (RB Yet) (NP (NNS supervisors)) (VP (VBD made) (NP (NP (DT no) (NN effort) (S (VP (TO to) (VP (VB monitor) (CC or) (VB control) (NP (NP (DT these) (NNS messages)) (, ,) (NP (NP (NN evidence)) (PP (IN of) (NP (DT a) (`` ``) (JJ significant) (NN breakdown))))) (PP (IN in) (NP (NP (DT the) (NN department) (POS 's)) (NN management) (NN responsibility))))))) (, ,) ('' '') (NP (NP (DT the) (NN report)) (VP (VBN found))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="these messages" type="NP">
          <tokens>
            <token id="10" string="these" />
            <token id="11" string="messages" />
          </tokens>
        </chunking>
        <chunking id="2" string="the report found" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="report" />
            <token id="29" string="found" />
          </tokens>
        </chunking>
        <chunking id="3" string="evidence" type="NP">
          <tokens>
            <token id="13" string="evidence" />
          </tokens>
        </chunking>
        <chunking id="4" string="no effort to monitor or control these messages , evidence of a `` significant breakdown in the department 's management responsibility , '' the report found" type="NP">
          <tokens>
            <token id="4" string="no" />
            <token id="5" string="effort" />
            <token id="6" string="to" />
            <token id="7" string="monitor" />
            <token id="8" string="or" />
            <token id="9" string="control" />
            <token id="10" string="these" />
            <token id="11" string="messages" />
            <token id="12" string="," />
            <token id="13" string="evidence" />
            <token id="14" string="of" />
            <token id="15" string="a" />
            <token id="16" string="&quot;" />
            <token id="17" string="significant" />
            <token id="18" string="breakdown" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="department" />
            <token id="22" string="'s" />
            <token id="23" string="management" />
            <token id="24" string="responsibility" />
            <token id="25" string="," />
            <token id="26" string="&quot;" />
            <token id="27" string="the" />
            <token id="28" string="report" />
            <token id="29" string="found" />
          </tokens>
        </chunking>
        <chunking id="5" string="a `` significant breakdown" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="&quot;" />
            <token id="17" string="significant" />
            <token id="18" string="breakdown" />
          </tokens>
        </chunking>
        <chunking id="6" string="monitor or control these messages , evidence of a `` significant breakdown in the department 's management responsibility" type="VP">
          <tokens>
            <token id="7" string="monitor" />
            <token id="8" string="or" />
            <token id="9" string="control" />
            <token id="10" string="these" />
            <token id="11" string="messages" />
            <token id="12" string="," />
            <token id="13" string="evidence" />
            <token id="14" string="of" />
            <token id="15" string="a" />
            <token id="16" string="&quot;" />
            <token id="17" string="significant" />
            <token id="18" string="breakdown" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="department" />
            <token id="22" string="'s" />
            <token id="23" string="management" />
            <token id="24" string="responsibility" />
          </tokens>
        </chunking>
        <chunking id="7" string="made no effort to monitor or control these messages , evidence of a `` significant breakdown in the department 's management responsibility , '' the report found" type="VP">
          <tokens>
            <token id="3" string="made" />
            <token id="4" string="no" />
            <token id="5" string="effort" />
            <token id="6" string="to" />
            <token id="7" string="monitor" />
            <token id="8" string="or" />
            <token id="9" string="control" />
            <token id="10" string="these" />
            <token id="11" string="messages" />
            <token id="12" string="," />
            <token id="13" string="evidence" />
            <token id="14" string="of" />
            <token id="15" string="a" />
            <token id="16" string="&quot;" />
            <token id="17" string="significant" />
            <token id="18" string="breakdown" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="department" />
            <token id="22" string="'s" />
            <token id="23" string="management" />
            <token id="24" string="responsibility" />
            <token id="25" string="," />
            <token id="26" string="&quot;" />
            <token id="27" string="the" />
            <token id="28" string="report" />
            <token id="29" string="found" />
          </tokens>
        </chunking>
        <chunking id="8" string="found" type="VP">
          <tokens>
            <token id="29" string="found" />
          </tokens>
        </chunking>
        <chunking id="9" string="evidence of a `` significant breakdown" type="NP">
          <tokens>
            <token id="13" string="evidence" />
            <token id="14" string="of" />
            <token id="15" string="a" />
            <token id="16" string="&quot;" />
            <token id="17" string="significant" />
            <token id="18" string="breakdown" />
          </tokens>
        </chunking>
        <chunking id="10" string="these messages , evidence of a `` significant breakdown" type="NP">
          <tokens>
            <token id="10" string="these" />
            <token id="11" string="messages" />
            <token id="12" string="," />
            <token id="13" string="evidence" />
            <token id="14" string="of" />
            <token id="15" string="a" />
            <token id="16" string="&quot;" />
            <token id="17" string="significant" />
            <token id="18" string="breakdown" />
          </tokens>
        </chunking>
        <chunking id="11" string="no effort to monitor or control these messages , evidence of a `` significant breakdown in the department 's management responsibility" type="NP">
          <tokens>
            <token id="4" string="no" />
            <token id="5" string="effort" />
            <token id="6" string="to" />
            <token id="7" string="monitor" />
            <token id="8" string="or" />
            <token id="9" string="control" />
            <token id="10" string="these" />
            <token id="11" string="messages" />
            <token id="12" string="," />
            <token id="13" string="evidence" />
            <token id="14" string="of" />
            <token id="15" string="a" />
            <token id="16" string="&quot;" />
            <token id="17" string="significant" />
            <token id="18" string="breakdown" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="department" />
            <token id="22" string="'s" />
            <token id="23" string="management" />
            <token id="24" string="responsibility" />
          </tokens>
        </chunking>
        <chunking id="12" string="the department 's" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="department" />
            <token id="22" string="'s" />
          </tokens>
        </chunking>
        <chunking id="13" string="the report" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="report" />
          </tokens>
        </chunking>
        <chunking id="14" string="to monitor or control these messages , evidence of a `` significant breakdown in the department 's management responsibility" type="VP">
          <tokens>
            <token id="6" string="to" />
            <token id="7" string="monitor" />
            <token id="8" string="or" />
            <token id="9" string="control" />
            <token id="10" string="these" />
            <token id="11" string="messages" />
            <token id="12" string="," />
            <token id="13" string="evidence" />
            <token id="14" string="of" />
            <token id="15" string="a" />
            <token id="16" string="&quot;" />
            <token id="17" string="significant" />
            <token id="18" string="breakdown" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="department" />
            <token id="22" string="'s" />
            <token id="23" string="management" />
            <token id="24" string="responsibility" />
          </tokens>
        </chunking>
        <chunking id="15" string="the department 's management responsibility" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="department" />
            <token id="22" string="'s" />
            <token id="23" string="management" />
            <token id="24" string="responsibility" />
          </tokens>
        </chunking>
        <chunking id="16" string="supervisors" type="NP">
          <tokens>
            <token id="2" string="supervisors" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="3">made</governor>
          <dependent id="1">Yet</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">made</governor>
          <dependent id="2">supervisors</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">made</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">effort</governor>
          <dependent id="4">no</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">made</governor>
          <dependent id="5">effort</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">monitor</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="5">effort</governor>
          <dependent id="7">monitor</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">monitor</governor>
          <dependent id="8">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">monitor</governor>
          <dependent id="9">control</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">messages</governor>
          <dependent id="10">these</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">monitor</governor>
          <dependent id="11">messages</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="11">messages</governor>
          <dependent id="13">evidence</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">breakdown</governor>
          <dependent id="14">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">breakdown</governor>
          <dependent id="15">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">breakdown</governor>
          <dependent id="17">significant</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">evidence</governor>
          <dependent id="18">breakdown</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">responsibility</governor>
          <dependent id="19">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">department</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="24">responsibility</governor>
          <dependent id="21">department</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">department</governor>
          <dependent id="22">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">responsibility</governor>
          <dependent id="23">management</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">monitor</governor>
          <dependent id="24">responsibility</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">report</governor>
          <dependent id="27">the</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="5">effort</governor>
          <dependent id="28">report</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="28">report</governor>
          <dependent id="29">found</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="7" has_coreference="false">
      <content>The Los Angeles Police Department has long been emulated by others around the country because of its reputation for being efficient and corruption-free.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="Los" lemma="Los" stem="lo" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="3" string="Angeles" lemma="Angeles" stem="angele" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="4" string="Police" lemma="Police" stem="polic" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="5" string="Department" lemma="Department" stem="depart" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="6" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="long" lemma="long" stem="long" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="emulated" lemma="emulate" stem="emul" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="others" lemma="other" stem="other" pos="NNS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="around" lemma="around" stem="around" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="country" lemma="country" stem="countri" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="reputation" lemma="reputation" stem="reput" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="being" lemma="be" stem="be" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="efficient" lemma="efficient" stem="effici" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="corruption-free" lemma="corruption-free" stem="corruption-fre" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NNP Los) (NNP Angeles) (NNP Police) (NNP Department)) (VP (VBZ has) (ADVP (RB long)) (VP (VBN been) (VP (VBN emulated) (PP (IN by) (NP (NP (NNS others)) (PP (IN around) (NP (DT the) (NN country))))) (PP (IN because) (IN of) (NP (NP (PRP$ its) (NN reputation)) (PP (IN for) (S (VP (VBG being) (ADJP (JJ efficient) (CC and) (JJ corruption-free)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="others around the country" type="NP">
          <tokens>
            <token id="11" string="others" />
            <token id="12" string="around" />
            <token id="13" string="the" />
            <token id="14" string="country" />
          </tokens>
        </chunking>
        <chunking id="2" string="The Los Angeles Police Department" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Los" />
            <token id="3" string="Angeles" />
            <token id="4" string="Police" />
            <token id="5" string="Department" />
          </tokens>
        </chunking>
        <chunking id="3" string="efficient and corruption-free" type="ADJP">
          <tokens>
            <token id="21" string="efficient" />
            <token id="22" string="and" />
            <token id="23" string="corruption-free" />
          </tokens>
        </chunking>
        <chunking id="4" string="been emulated by others around the country because of its reputation for being efficient and corruption-free" type="VP">
          <tokens>
            <token id="8" string="been" />
            <token id="9" string="emulated" />
            <token id="10" string="by" />
            <token id="11" string="others" />
            <token id="12" string="around" />
            <token id="13" string="the" />
            <token id="14" string="country" />
            <token id="15" string="because" />
            <token id="16" string="of" />
            <token id="17" string="its" />
            <token id="18" string="reputation" />
            <token id="19" string="for" />
            <token id="20" string="being" />
            <token id="21" string="efficient" />
            <token id="22" string="and" />
            <token id="23" string="corruption-free" />
          </tokens>
        </chunking>
        <chunking id="5" string="the country" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="country" />
          </tokens>
        </chunking>
        <chunking id="6" string="being efficient and corruption-free" type="VP">
          <tokens>
            <token id="20" string="being" />
            <token id="21" string="efficient" />
            <token id="22" string="and" />
            <token id="23" string="corruption-free" />
          </tokens>
        </chunking>
        <chunking id="7" string="its reputation for being efficient and corruption-free" type="NP">
          <tokens>
            <token id="17" string="its" />
            <token id="18" string="reputation" />
            <token id="19" string="for" />
            <token id="20" string="being" />
            <token id="21" string="efficient" />
            <token id="22" string="and" />
            <token id="23" string="corruption-free" />
          </tokens>
        </chunking>
        <chunking id="8" string="its reputation" type="NP">
          <tokens>
            <token id="17" string="its" />
            <token id="18" string="reputation" />
          </tokens>
        </chunking>
        <chunking id="9" string="has long been emulated by others around the country because of its reputation for being efficient and corruption-free" type="VP">
          <tokens>
            <token id="6" string="has" />
            <token id="7" string="long" />
            <token id="8" string="been" />
            <token id="9" string="emulated" />
            <token id="10" string="by" />
            <token id="11" string="others" />
            <token id="12" string="around" />
            <token id="13" string="the" />
            <token id="14" string="country" />
            <token id="15" string="because" />
            <token id="16" string="of" />
            <token id="17" string="its" />
            <token id="18" string="reputation" />
            <token id="19" string="for" />
            <token id="20" string="being" />
            <token id="21" string="efficient" />
            <token id="22" string="and" />
            <token id="23" string="corruption-free" />
          </tokens>
        </chunking>
        <chunking id="10" string="emulated by others around the country because of its reputation for being efficient and corruption-free" type="VP">
          <tokens>
            <token id="9" string="emulated" />
            <token id="10" string="by" />
            <token id="11" string="others" />
            <token id="12" string="around" />
            <token id="13" string="the" />
            <token id="14" string="country" />
            <token id="15" string="because" />
            <token id="16" string="of" />
            <token id="17" string="its" />
            <token id="18" string="reputation" />
            <token id="19" string="for" />
            <token id="20" string="being" />
            <token id="21" string="efficient" />
            <token id="22" string="and" />
            <token id="23" string="corruption-free" />
          </tokens>
        </chunking>
        <chunking id="11" string="others" type="NP">
          <tokens>
            <token id="11" string="others" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="5">Department</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Department</governor>
          <dependent id="2">Los</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Department</governor>
          <dependent id="3">Angeles</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Department</governor>
          <dependent id="4">Police</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="9">emulated</governor>
          <dependent id="5">Department</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">emulated</governor>
          <dependent id="6">has</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">emulated</governor>
          <dependent id="7">long</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="9">emulated</governor>
          <dependent id="8">been</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">emulated</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">others</governor>
          <dependent id="10">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">emulated</governor>
          <dependent id="11">others</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">country</governor>
          <dependent id="12">around</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">country</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">others</governor>
          <dependent id="14">country</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">reputation</governor>
          <dependent id="15">because</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="15">because</governor>
          <dependent id="16">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="18">reputation</governor>
          <dependent id="17">its</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">emulated</governor>
          <dependent id="18">reputation</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="21">efficient</governor>
          <dependent id="19">for</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="21">efficient</governor>
          <dependent id="20">being</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="18">reputation</governor>
          <dependent id="21">efficient</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="21">efficient</governor>
          <dependent id="22">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="21">efficient</governor>
          <dependent id="23">corruption-free</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Los Angeles Police Department" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="2" string="Los" />
            <token id="3" string="Angeles" />
            <token id="4" string="Police" />
            <token id="5" string="Department" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>But the commission called for a shift away from the force&amp;apost;s paramilitaristic, us-against-them style, and said the department must embrace the &amp;quot;community-based&amp;quot; policing style that encourages officers to spend less time in their cars and more time interacting with citizens in the communities they serve.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="commission" lemma="commission" stem="commiss" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="called" lemma="call" stem="call" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="shift" lemma="shift" stem="shift" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="away" lemma="away" stem="awai" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="force" lemma="force" stem="forc" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="paramilitaristic" lemma="paramilitaristic" stem="paramilitarist" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="us-against-them" lemma="us-against-them" stem="us-against-them" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="style" lemma="style" stem="style" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="department" lemma="department" stem="depart" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="22" string="must" lemma="must" stem="must" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="embrace" lemma="embrace" stem="embrac" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="25" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="26" string="community-based" lemma="community-based" stem="community-bas" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="27" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="28" string="policing" lemma="police" stem="polic" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="29" string="style" lemma="style" stem="style" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="30" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="31" string="encourages" lemma="encourage" stem="encourag" pos="VBZ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="32" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="33" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="34" string="spend" lemma="spend" stem="spend" pos="VB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="35" string="less" lemma="less" stem="less" pos="JJR" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="36" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="37" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="38" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="39" string="cars" lemma="car" stem="car" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="40" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="41" string="more" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="42" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="43" string="interacting" lemma="interact" stem="interact" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="44" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="45" string="citizens" lemma="citizen" stem="citizen" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="46" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="47" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="48" string="communities" lemma="community" stem="commun" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="49" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="50" string="serve" lemma="serve" stem="serv" pos="VBP" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="51" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (NP (DT the) (NN commission)) (VP (VP (VBN called) (PP (IN for) (NP (NP (DT a) (NN shift)) (ADVP (RB away) (PP (IN from) (NP (NP (DT the) (NN force) (POS 's)) (JJ paramilitaristic) (, ,) (JJ us-against-them) (NN style))))))) (, ,) (CC and) (VP (VBD said) (NP (DT the) (NN department))))) (VP (MD must) (VP (VB embrace) (NP (NP (DT the) (ADJP (ADJP (ADJP (`` ``) (JJ community-based) ('' '')) (S (VP (VBG policing) (NP (NP (NN style)) (SBAR (WHNP (WDT that)) (S (VP (VBZ encourages) (S (NP (NNS officers)) (VP (TO to) (VP (VB spend) (NP (JJR less) (NN time)) (PP (IN in) (NP (PRP$ their) (NNS cars))))))))))))) (CC and) (ADJP (JJR more))) (NN time)) (VP (VBG interacting) (PP (IN with) (NP (NP (NNS citizens)) (PP (IN in) (NP (NP (DT the) (NNS communities)) (SBAR (S (NP (PRP they)) (VP (VBP serve)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the commission" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="commission" />
          </tokens>
        </chunking>
        <chunking id="2" string="the force 's paramilitaristic , us-against-them style" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="force" />
            <token id="12" string="'s" />
            <token id="13" string="paramilitaristic" />
            <token id="14" string="," />
            <token id="15" string="us-against-them" />
            <token id="16" string="style" />
          </tokens>
        </chunking>
        <chunking id="3" string="called for a shift away from the force 's paramilitaristic , us-against-them style , and said the department" type="VP">
          <tokens>
            <token id="4" string="called" />
            <token id="5" string="for" />
            <token id="6" string="a" />
            <token id="7" string="shift" />
            <token id="8" string="away" />
            <token id="9" string="from" />
            <token id="10" string="the" />
            <token id="11" string="force" />
            <token id="12" string="'s" />
            <token id="13" string="paramilitaristic" />
            <token id="14" string="," />
            <token id="15" string="us-against-them" />
            <token id="16" string="style" />
            <token id="17" string="," />
            <token id="18" string="and" />
            <token id="19" string="said" />
            <token id="20" string="the" />
            <token id="21" string="department" />
          </tokens>
        </chunking>
        <chunking id="4" string="the communities they serve" type="NP">
          <tokens>
            <token id="47" string="the" />
            <token id="48" string="communities" />
            <token id="49" string="they" />
            <token id="50" string="serve" />
          </tokens>
        </chunking>
        <chunking id="5" string="a shift away from the force 's paramilitaristic , us-against-them style" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="shift" />
            <token id="8" string="away" />
            <token id="9" string="from" />
            <token id="10" string="the" />
            <token id="11" string="force" />
            <token id="12" string="'s" />
            <token id="13" string="paramilitaristic" />
            <token id="14" string="," />
            <token id="15" string="us-against-them" />
            <token id="16" string="style" />
          </tokens>
        </chunking>
        <chunking id="6" string="more" type="ADJP">
          <tokens>
            <token id="41" string="more" />
          </tokens>
        </chunking>
        <chunking id="7" string="encourages officers to spend less time in their cars" type="VP">
          <tokens>
            <token id="31" string="encourages" />
            <token id="32" string="officers" />
            <token id="33" string="to" />
            <token id="34" string="spend" />
            <token id="35" string="less" />
            <token id="36" string="time" />
            <token id="37" string="in" />
            <token id="38" string="their" />
            <token id="39" string="cars" />
          </tokens>
        </chunking>
        <chunking id="8" string="the force 's" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="force" />
            <token id="12" string="'s" />
          </tokens>
        </chunking>
        <chunking id="9" string="less time" type="NP">
          <tokens>
            <token id="35" string="less" />
            <token id="36" string="time" />
          </tokens>
        </chunking>
        <chunking id="10" string="said the department" type="VP">
          <tokens>
            <token id="19" string="said" />
            <token id="20" string="the" />
            <token id="21" string="department" />
          </tokens>
        </chunking>
        <chunking id="11" string="the `` community-based '' policing style that encourages officers to spend less time in their cars and more time" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="&quot;" />
            <token id="26" string="community-based" />
            <token id="27" string="&quot;" />
            <token id="28" string="policing" />
            <token id="29" string="style" />
            <token id="30" string="that" />
            <token id="31" string="encourages" />
            <token id="32" string="officers" />
            <token id="33" string="to" />
            <token id="34" string="spend" />
            <token id="35" string="less" />
            <token id="36" string="time" />
            <token id="37" string="in" />
            <token id="38" string="their" />
            <token id="39" string="cars" />
            <token id="40" string="and" />
            <token id="41" string="more" />
            <token id="42" string="time" />
          </tokens>
        </chunking>
        <chunking id="12" string="`` community-based ''" type="ADJP">
          <tokens>
            <token id="25" string="&quot;" />
            <token id="26" string="community-based" />
            <token id="27" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="13" string="the communities" type="NP">
          <tokens>
            <token id="47" string="the" />
            <token id="48" string="communities" />
          </tokens>
        </chunking>
        <chunking id="14" string="the commission called for a shift away from the force 's paramilitaristic , us-against-them style , and said the department" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="commission" />
            <token id="4" string="called" />
            <token id="5" string="for" />
            <token id="6" string="a" />
            <token id="7" string="shift" />
            <token id="8" string="away" />
            <token id="9" string="from" />
            <token id="10" string="the" />
            <token id="11" string="force" />
            <token id="12" string="'s" />
            <token id="13" string="paramilitaristic" />
            <token id="14" string="," />
            <token id="15" string="us-against-them" />
            <token id="16" string="style" />
            <token id="17" string="," />
            <token id="18" string="and" />
            <token id="19" string="said" />
            <token id="20" string="the" />
            <token id="21" string="department" />
          </tokens>
        </chunking>
        <chunking id="15" string="their cars" type="NP">
          <tokens>
            <token id="38" string="their" />
            <token id="39" string="cars" />
          </tokens>
        </chunking>
        <chunking id="16" string="called for a shift away from the force 's paramilitaristic , us-against-them style" type="VP">
          <tokens>
            <token id="4" string="called" />
            <token id="5" string="for" />
            <token id="6" string="a" />
            <token id="7" string="shift" />
            <token id="8" string="away" />
            <token id="9" string="from" />
            <token id="10" string="the" />
            <token id="11" string="force" />
            <token id="12" string="'s" />
            <token id="13" string="paramilitaristic" />
            <token id="14" string="," />
            <token id="15" string="us-against-them" />
            <token id="16" string="style" />
          </tokens>
        </chunking>
        <chunking id="17" string="style" type="NP">
          <tokens>
            <token id="29" string="style" />
          </tokens>
        </chunking>
        <chunking id="18" string="citizens" type="NP">
          <tokens>
            <token id="45" string="citizens" />
          </tokens>
        </chunking>
        <chunking id="19" string="spend less time in their cars" type="VP">
          <tokens>
            <token id="34" string="spend" />
            <token id="35" string="less" />
            <token id="36" string="time" />
            <token id="37" string="in" />
            <token id="38" string="their" />
            <token id="39" string="cars" />
          </tokens>
        </chunking>
        <chunking id="20" string="style that encourages officers to spend less time in their cars" type="NP">
          <tokens>
            <token id="29" string="style" />
            <token id="30" string="that" />
            <token id="31" string="encourages" />
            <token id="32" string="officers" />
            <token id="33" string="to" />
            <token id="34" string="spend" />
            <token id="35" string="less" />
            <token id="36" string="time" />
            <token id="37" string="in" />
            <token id="38" string="their" />
            <token id="39" string="cars" />
          </tokens>
        </chunking>
        <chunking id="21" string="policing style that encourages officers to spend less time in their cars" type="VP">
          <tokens>
            <token id="28" string="policing" />
            <token id="29" string="style" />
            <token id="30" string="that" />
            <token id="31" string="encourages" />
            <token id="32" string="officers" />
            <token id="33" string="to" />
            <token id="34" string="spend" />
            <token id="35" string="less" />
            <token id="36" string="time" />
            <token id="37" string="in" />
            <token id="38" string="their" />
            <token id="39" string="cars" />
          </tokens>
        </chunking>
        <chunking id="22" string="they serve" type="SBAR">
          <tokens>
            <token id="49" string="they" />
            <token id="50" string="serve" />
          </tokens>
        </chunking>
        <chunking id="23" string="serve" type="VP">
          <tokens>
            <token id="50" string="serve" />
          </tokens>
        </chunking>
        <chunking id="24" string="that encourages officers to spend less time in their cars" type="SBAR">
          <tokens>
            <token id="30" string="that" />
            <token id="31" string="encourages" />
            <token id="32" string="officers" />
            <token id="33" string="to" />
            <token id="34" string="spend" />
            <token id="35" string="less" />
            <token id="36" string="time" />
            <token id="37" string="in" />
            <token id="38" string="their" />
            <token id="39" string="cars" />
          </tokens>
        </chunking>
        <chunking id="25" string="`` community-based '' policing style that encourages officers to spend less time in their cars and more" type="ADJP">
          <tokens>
            <token id="25" string="&quot;" />
            <token id="26" string="community-based" />
            <token id="27" string="&quot;" />
            <token id="28" string="policing" />
            <token id="29" string="style" />
            <token id="30" string="that" />
            <token id="31" string="encourages" />
            <token id="32" string="officers" />
            <token id="33" string="to" />
            <token id="34" string="spend" />
            <token id="35" string="less" />
            <token id="36" string="time" />
            <token id="37" string="in" />
            <token id="38" string="their" />
            <token id="39" string="cars" />
            <token id="40" string="and" />
            <token id="41" string="more" />
          </tokens>
        </chunking>
        <chunking id="26" string="citizens in the communities they serve" type="NP">
          <tokens>
            <token id="45" string="citizens" />
            <token id="46" string="in" />
            <token id="47" string="the" />
            <token id="48" string="communities" />
            <token id="49" string="they" />
            <token id="50" string="serve" />
          </tokens>
        </chunking>
        <chunking id="27" string="they" type="NP">
          <tokens>
            <token id="49" string="they" />
          </tokens>
        </chunking>
        <chunking id="28" string="`` community-based '' policing style that encourages officers to spend less time in their cars" type="ADJP">
          <tokens>
            <token id="25" string="&quot;" />
            <token id="26" string="community-based" />
            <token id="27" string="&quot;" />
            <token id="28" string="policing" />
            <token id="29" string="style" />
            <token id="30" string="that" />
            <token id="31" string="encourages" />
            <token id="32" string="officers" />
            <token id="33" string="to" />
            <token id="34" string="spend" />
            <token id="35" string="less" />
            <token id="36" string="time" />
            <token id="37" string="in" />
            <token id="38" string="their" />
            <token id="39" string="cars" />
          </tokens>
        </chunking>
        <chunking id="29" string="the department" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="department" />
          </tokens>
        </chunking>
        <chunking id="30" string="interacting with citizens in the communities they serve" type="VP">
          <tokens>
            <token id="43" string="interacting" />
            <token id="44" string="with" />
            <token id="45" string="citizens" />
            <token id="46" string="in" />
            <token id="47" string="the" />
            <token id="48" string="communities" />
            <token id="49" string="they" />
            <token id="50" string="serve" />
          </tokens>
        </chunking>
        <chunking id="31" string="embrace the `` community-based '' policing style that encourages officers to spend less time in their cars and more time interacting with citizens in the communities they serve" type="VP">
          <tokens>
            <token id="23" string="embrace" />
            <token id="24" string="the" />
            <token id="25" string="&quot;" />
            <token id="26" string="community-based" />
            <token id="27" string="&quot;" />
            <token id="28" string="policing" />
            <token id="29" string="style" />
            <token id="30" string="that" />
            <token id="31" string="encourages" />
            <token id="32" string="officers" />
            <token id="33" string="to" />
            <token id="34" string="spend" />
            <token id="35" string="less" />
            <token id="36" string="time" />
            <token id="37" string="in" />
            <token id="38" string="their" />
            <token id="39" string="cars" />
            <token id="40" string="and" />
            <token id="41" string="more" />
            <token id="42" string="time" />
            <token id="43" string="interacting" />
            <token id="44" string="with" />
            <token id="45" string="citizens" />
            <token id="46" string="in" />
            <token id="47" string="the" />
            <token id="48" string="communities" />
            <token id="49" string="they" />
            <token id="50" string="serve" />
          </tokens>
        </chunking>
        <chunking id="32" string="a shift" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="shift" />
          </tokens>
        </chunking>
        <chunking id="33" string="must embrace the `` community-based '' policing style that encourages officers to spend less time in their cars and more time interacting with citizens in the communities they serve" type="VP">
          <tokens>
            <token id="22" string="must" />
            <token id="23" string="embrace" />
            <token id="24" string="the" />
            <token id="25" string="&quot;" />
            <token id="26" string="community-based" />
            <token id="27" string="&quot;" />
            <token id="28" string="policing" />
            <token id="29" string="style" />
            <token id="30" string="that" />
            <token id="31" string="encourages" />
            <token id="32" string="officers" />
            <token id="33" string="to" />
            <token id="34" string="spend" />
            <token id="35" string="less" />
            <token id="36" string="time" />
            <token id="37" string="in" />
            <token id="38" string="their" />
            <token id="39" string="cars" />
            <token id="40" string="and" />
            <token id="41" string="more" />
            <token id="42" string="time" />
            <token id="43" string="interacting" />
            <token id="44" string="with" />
            <token id="45" string="citizens" />
            <token id="46" string="in" />
            <token id="47" string="the" />
            <token id="48" string="communities" />
            <token id="49" string="they" />
            <token id="50" string="serve" />
          </tokens>
        </chunking>
        <chunking id="34" string="officers" type="NP">
          <tokens>
            <token id="32" string="officers" />
          </tokens>
        </chunking>
        <chunking id="35" string="to spend less time in their cars" type="VP">
          <tokens>
            <token id="33" string="to" />
            <token id="34" string="spend" />
            <token id="35" string="less" />
            <token id="36" string="time" />
            <token id="37" string="in" />
            <token id="38" string="their" />
            <token id="39" string="cars" />
          </tokens>
        </chunking>
        <chunking id="36" string="the `` community-based '' policing style that encourages officers to spend less time in their cars and more time interacting with citizens in the communities they serve" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="&quot;" />
            <token id="26" string="community-based" />
            <token id="27" string="&quot;" />
            <token id="28" string="policing" />
            <token id="29" string="style" />
            <token id="30" string="that" />
            <token id="31" string="encourages" />
            <token id="32" string="officers" />
            <token id="33" string="to" />
            <token id="34" string="spend" />
            <token id="35" string="less" />
            <token id="36" string="time" />
            <token id="37" string="in" />
            <token id="38" string="their" />
            <token id="39" string="cars" />
            <token id="40" string="and" />
            <token id="41" string="more" />
            <token id="42" string="time" />
            <token id="43" string="interacting" />
            <token id="44" string="with" />
            <token id="45" string="citizens" />
            <token id="46" string="in" />
            <token id="47" string="the" />
            <token id="48" string="communities" />
            <token id="49" string="they" />
            <token id="50" string="serve" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="23">embrace</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">commission</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">embrace</governor>
          <dependent id="3">commission</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="3">commission</governor>
          <dependent id="4">called</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">shift</governor>
          <dependent id="5">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">shift</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">called</governor>
          <dependent id="7">shift</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">style</governor>
          <dependent id="8">away</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="8">away</governor>
          <dependent id="9">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">force</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="16">style</governor>
          <dependent id="11">force</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">force</governor>
          <dependent id="12">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">style</governor>
          <dependent id="13">paramilitaristic</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">style</governor>
          <dependent id="15">us-against-them</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">shift</governor>
          <dependent id="16">style</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">called</governor>
          <dependent id="18">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">called</governor>
          <dependent id="19">said</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">department</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">said</governor>
          <dependent id="21">department</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="23">embrace</governor>
          <dependent id="22">must</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="23">embrace</dependent>
        </dependency>
        <dependency type="det">
          <governor id="42">time</governor>
          <dependent id="24">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="42">time</governor>
          <dependent id="26">community-based</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="26">community-based</governor>
          <dependent id="28">policing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="28">policing</governor>
          <dependent id="29">style</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="31">encourages</governor>
          <dependent id="30">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="29">style</governor>
          <dependent id="31">encourages</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="31">encourages</governor>
          <dependent id="32">officers</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="34">spend</governor>
          <dependent id="33">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="31">encourages</governor>
          <dependent id="34">spend</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="36">time</governor>
          <dependent id="35">less</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="34">spend</governor>
          <dependent id="36">time</dependent>
        </dependency>
        <dependency type="case">
          <governor id="39">cars</governor>
          <dependent id="37">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="39">cars</governor>
          <dependent id="38">their</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="34">spend</governor>
          <dependent id="39">cars</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="26">community-based</governor>
          <dependent id="40">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="26">community-based</governor>
          <dependent id="41">more</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="23">embrace</governor>
          <dependent id="42">time</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="42">time</governor>
          <dependent id="43">interacting</dependent>
        </dependency>
        <dependency type="case">
          <governor id="45">citizens</governor>
          <dependent id="44">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="43">interacting</governor>
          <dependent id="45">citizens</dependent>
        </dependency>
        <dependency type="case">
          <governor id="48">communities</governor>
          <dependent id="46">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="48">communities</governor>
          <dependent id="47">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="45">citizens</governor>
          <dependent id="48">communities</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="50">serve</governor>
          <dependent id="49">they</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="48">communities</governor>
          <dependent id="50">serve</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>&amp;quot;This report will be a must-read for police chiefs around the country,&amp;quot; said Hubert Williams, executive director of the Police Foundation, a Washington, D.C., law enforcement research group.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="This" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="report" lemma="report" stem="report" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="must-read" lemma="must-read" stem="must-read" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="10" string="chiefs" lemma="chief" stem="chief" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="11" string="around" lemma="around" stem="around" pos="IN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="13" string="country" lemma="country" stem="countri" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="Hubert" lemma="Hubert" stem="hubert" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="18" string="Williams" lemma="Williams" stem="william" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="executive" lemma="executive" stem="execut" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="director" lemma="director" stem="director" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="Police" lemma="Police" stem="polic" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="25" string="Foundation" lemma="Foundation" stem="foundat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="26" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="Washington" lemma="Washington" stem="washington" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="29" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="D.C." lemma="D.C." stem="d.c." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="31" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="law" lemma="law" stem="law" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="enforcement" lemma="enforcement" stem="enforc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="research" lemma="research" stem="research" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="group" lemma="group" stem="group" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (NP (DT This) (NN report)) (VP (MD will) (VP (VB be) (NP (NP (DT a) (NN must-read)) (PP (IN for) (NP (NP (NN police) (NNS chiefs)) (PP (IN around) (NP (DT the) (NN country))))))))) (, ,) ('' '') (VP (VBD said)) (NP (NP (NNP Hubert) (NNP Williams)) (, ,) (NP (NP (JJ executive) (NN director)) (PP (IN of) (NP (NP (DT the) (NNP Police) (NNP Foundation)) (, ,) (NP (NP (DT a) (NAC (NNP Washington) (, ,) (NNP D.C.) (, ,)) (NN law) (NN enforcement)) (NP (NN research) (NN group))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the Police Foundation" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="Police" />
            <token id="25" string="Foundation" />
          </tokens>
        </chunking>
        <chunking id="2" string="executive director of the Police Foundation , a Washington , D.C. , law enforcement research group" type="NP">
          <tokens>
            <token id="20" string="executive" />
            <token id="21" string="director" />
            <token id="22" string="of" />
            <token id="23" string="the" />
            <token id="24" string="Police" />
            <token id="25" string="Foundation" />
            <token id="26" string="," />
            <token id="27" string="a" />
            <token id="28" string="Washington" />
            <token id="29" string="," />
            <token id="30" string="D.C." />
            <token id="31" string="," />
            <token id="32" string="law" />
            <token id="33" string="enforcement" />
            <token id="34" string="research" />
            <token id="35" string="group" />
          </tokens>
        </chunking>
        <chunking id="3" string="executive director" type="NP">
          <tokens>
            <token id="20" string="executive" />
            <token id="21" string="director" />
          </tokens>
        </chunking>
        <chunking id="4" string="a must-read" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="must-read" />
          </tokens>
        </chunking>
        <chunking id="5" string="police chiefs" type="NP">
          <tokens>
            <token id="9" string="police" />
            <token id="10" string="chiefs" />
          </tokens>
        </chunking>
        <chunking id="6" string="be a must-read for police chiefs around the country" type="VP">
          <tokens>
            <token id="5" string="be" />
            <token id="6" string="a" />
            <token id="7" string="must-read" />
            <token id="8" string="for" />
            <token id="9" string="police" />
            <token id="10" string="chiefs" />
            <token id="11" string="around" />
            <token id="12" string="the" />
            <token id="13" string="country" />
          </tokens>
        </chunking>
        <chunking id="7" string="a Washington , D.C. , law enforcement" type="NP">
          <tokens>
            <token id="27" string="a" />
            <token id="28" string="Washington" />
            <token id="29" string="," />
            <token id="30" string="D.C." />
            <token id="31" string="," />
            <token id="32" string="law" />
            <token id="33" string="enforcement" />
          </tokens>
        </chunking>
        <chunking id="8" string="the Police Foundation , a Washington , D.C. , law enforcement research group" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="Police" />
            <token id="25" string="Foundation" />
            <token id="26" string="," />
            <token id="27" string="a" />
            <token id="28" string="Washington" />
            <token id="29" string="," />
            <token id="30" string="D.C." />
            <token id="31" string="," />
            <token id="32" string="law" />
            <token id="33" string="enforcement" />
            <token id="34" string="research" />
            <token id="35" string="group" />
          </tokens>
        </chunking>
        <chunking id="9" string="a must-read for police chiefs around the country" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="must-read" />
            <token id="8" string="for" />
            <token id="9" string="police" />
            <token id="10" string="chiefs" />
            <token id="11" string="around" />
            <token id="12" string="the" />
            <token id="13" string="country" />
          </tokens>
        </chunking>
        <chunking id="10" string="the country" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="country" />
          </tokens>
        </chunking>
        <chunking id="11" string="will be a must-read for police chiefs around the country" type="VP">
          <tokens>
            <token id="4" string="will" />
            <token id="5" string="be" />
            <token id="6" string="a" />
            <token id="7" string="must-read" />
            <token id="8" string="for" />
            <token id="9" string="police" />
            <token id="10" string="chiefs" />
            <token id="11" string="around" />
            <token id="12" string="the" />
            <token id="13" string="country" />
          </tokens>
        </chunking>
        <chunking id="12" string="police chiefs around the country" type="NP">
          <tokens>
            <token id="9" string="police" />
            <token id="10" string="chiefs" />
            <token id="11" string="around" />
            <token id="12" string="the" />
            <token id="13" string="country" />
          </tokens>
        </chunking>
        <chunking id="13" string="Hubert Williams , executive director of the Police Foundation , a Washington , D.C. , law enforcement research group" type="NP">
          <tokens>
            <token id="17" string="Hubert" />
            <token id="18" string="Williams" />
            <token id="19" string="," />
            <token id="20" string="executive" />
            <token id="21" string="director" />
            <token id="22" string="of" />
            <token id="23" string="the" />
            <token id="24" string="Police" />
            <token id="25" string="Foundation" />
            <token id="26" string="," />
            <token id="27" string="a" />
            <token id="28" string="Washington" />
            <token id="29" string="," />
            <token id="30" string="D.C." />
            <token id="31" string="," />
            <token id="32" string="law" />
            <token id="33" string="enforcement" />
            <token id="34" string="research" />
            <token id="35" string="group" />
          </tokens>
        </chunking>
        <chunking id="14" string="This report" type="NP">
          <tokens>
            <token id="2" string="This" />
            <token id="3" string="report" />
          </tokens>
        </chunking>
        <chunking id="15" string="a Washington , D.C. , law enforcement research group" type="NP">
          <tokens>
            <token id="27" string="a" />
            <token id="28" string="Washington" />
            <token id="29" string="," />
            <token id="30" string="D.C." />
            <token id="31" string="," />
            <token id="32" string="law" />
            <token id="33" string="enforcement" />
            <token id="34" string="research" />
            <token id="35" string="group" />
          </tokens>
        </chunking>
        <chunking id="16" string="research group" type="NP">
          <tokens>
            <token id="34" string="research" />
            <token id="35" string="group" />
          </tokens>
        </chunking>
        <chunking id="17" string="Hubert Williams" type="NP">
          <tokens>
            <token id="17" string="Hubert" />
            <token id="18" string="Williams" />
          </tokens>
        </chunking>
        <chunking id="18" string="said" type="VP">
          <tokens>
            <token id="16" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">report</governor>
          <dependent id="2">This</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">must-read</governor>
          <dependent id="3">report</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">must-read</governor>
          <dependent id="4">will</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">must-read</governor>
          <dependent id="5">be</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">must-read</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="16">said</governor>
          <dependent id="7">must-read</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">chiefs</governor>
          <dependent id="8">for</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">chiefs</governor>
          <dependent id="9">police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">must-read</governor>
          <dependent id="10">chiefs</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">country</governor>
          <dependent id="11">around</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">country</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">chiefs</governor>
          <dependent id="13">country</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="16">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Williams</governor>
          <dependent id="17">Hubert</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">said</governor>
          <dependent id="18">Williams</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">director</governor>
          <dependent id="20">executive</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="18">Williams</governor>
          <dependent id="21">director</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">Foundation</governor>
          <dependent id="22">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">Foundation</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">Foundation</governor>
          <dependent id="24">Police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">director</governor>
          <dependent id="25">Foundation</dependent>
        </dependency>
        <dependency type="det">
          <governor id="33">enforcement</governor>
          <dependent id="27">a</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="33">enforcement</governor>
          <dependent id="28">Washington</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="28">Washington</governor>
          <dependent id="30">D.C.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="33">enforcement</governor>
          <dependent id="32">law</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="25">Foundation</governor>
          <dependent id="33">enforcement</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="35">group</governor>
          <dependent id="34">research</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="33">enforcement</governor>
          <dependent id="35">group</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Washington" type="LOCATION" score="0.0">
          <tokens>
            <token id="28" string="Washington" />
          </tokens>
        </entity>
        <entity id="2" string="Police Foundation" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="24" string="Police" />
            <token id="25" string="Foundation" />
          </tokens>
        </entity>
        <entity id="3" string="D.C." type="LOCATION" score="0.0">
          <tokens>
            <token id="30" string="D.C." />
          </tokens>
        </entity>
        <entity id="4" string="Hubert Williams" type="PERSON" score="0.0">
          <tokens>
            <token id="17" string="Hubert" />
            <token id="18" string="Williams" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="10" has_coreference="false">
      <content>&amp;quot;The word is clear: the public expects high quality law enforcement within the parameters of the law.&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="word" lemma="word" stem="word" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="clear" lemma="clear" stem="clear" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="public" lemma="public" stem="public" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="expects" lemma="expect" stem="expect" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="high" lemma="high" stem="high" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="quality" lemma="quality" stem="qualiti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="law" lemma="law" stem="law" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="enforcement" lemma="enforcement" stem="enforc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="within" lemma="within" stem="within" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="parameters" lemma="parameter" stem="paramet" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="law" lemma="law" stem="law" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (DT The) (NN word)) (VP (VBZ is) (ADJP (JJ clear)))) (: :) (S (NP (DT the) (JJ public)) (VP (VBZ expects) (NP (NP (JJ high) (NN quality) (NN law) (NN enforcement)) (PP (IN within) (NP (NP (DT the) (NNS parameters)) (PP (IN of) (NP (DT the) (NN law)))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="The word" type="NP">
          <tokens>
            <token id="2" string="The" />
            <token id="3" string="word" />
          </tokens>
        </chunking>
        <chunking id="2" string="high quality law enforcement within the parameters of the law" type="NP">
          <tokens>
            <token id="10" string="high" />
            <token id="11" string="quality" />
            <token id="12" string="law" />
            <token id="13" string="enforcement" />
            <token id="14" string="within" />
            <token id="15" string="the" />
            <token id="16" string="parameters" />
            <token id="17" string="of" />
            <token id="18" string="the" />
            <token id="19" string="law" />
          </tokens>
        </chunking>
        <chunking id="3" string="the parameters" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="parameters" />
          </tokens>
        </chunking>
        <chunking id="4" string="the public" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="public" />
          </tokens>
        </chunking>
        <chunking id="5" string="the parameters of the law" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="parameters" />
            <token id="17" string="of" />
            <token id="18" string="the" />
            <token id="19" string="law" />
          </tokens>
        </chunking>
        <chunking id="6" string="the law" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="law" />
          </tokens>
        </chunking>
        <chunking id="7" string="clear" type="ADJP">
          <tokens>
            <token id="5" string="clear" />
          </tokens>
        </chunking>
        <chunking id="8" string="expects high quality law enforcement within the parameters of the law" type="VP">
          <tokens>
            <token id="9" string="expects" />
            <token id="10" string="high" />
            <token id="11" string="quality" />
            <token id="12" string="law" />
            <token id="13" string="enforcement" />
            <token id="14" string="within" />
            <token id="15" string="the" />
            <token id="16" string="parameters" />
            <token id="17" string="of" />
            <token id="18" string="the" />
            <token id="19" string="law" />
          </tokens>
        </chunking>
        <chunking id="9" string="is clear" type="VP">
          <tokens>
            <token id="4" string="is" />
            <token id="5" string="clear" />
          </tokens>
        </chunking>
        <chunking id="10" string="high quality law enforcement" type="NP">
          <tokens>
            <token id="10" string="high" />
            <token id="11" string="quality" />
            <token id="12" string="law" />
            <token id="13" string="enforcement" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">word</governor>
          <dependent id="2">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">clear</governor>
          <dependent id="3">word</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">clear</governor>
          <dependent id="4">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">clear</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">public</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">expects</governor>
          <dependent id="8">public</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="5">clear</governor>
          <dependent id="9">expects</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">enforcement</governor>
          <dependent id="10">high</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">enforcement</governor>
          <dependent id="11">quality</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">enforcement</governor>
          <dependent id="12">law</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">expects</governor>
          <dependent id="13">enforcement</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">parameters</governor>
          <dependent id="14">within</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">parameters</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">enforcement</governor>
          <dependent id="16">parameters</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">law</governor>
          <dependent id="17">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">law</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">parameters</governor>
          <dependent id="19">law</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>Mr. Williams likened the report to the Knapp Commission, a 1970s blue-ribbon study that exposed widespread corruption in the New York Police Department and led to significant improvements there.</content>
      <tokens>
        <token id="1" string="Mr." lemma="Mr." stem="mr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="2" string="Williams" lemma="Williams" stem="william" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="likened" lemma="liken" stem="liken" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="report" lemma="report" stem="report" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Knapp" lemma="Knapp" stem="knapp" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="9" string="Commission" lemma="Commission" stem="commiss" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="1970s" lemma="1970s" stem="1970" pos="CD" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="13" string="blue-ribbon" lemma="blue-ribbon" stem="blue-ribbon" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="study" lemma="study" stem="studi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="exposed" lemma="expose" stem="expos" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="widespread" lemma="widespread" stem="widespread" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="corruption" lemma="corruption" stem="corrupt" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="New" lemma="New" stem="new" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="22" string="York" lemma="York" stem="york" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="23" string="Police" lemma="Police" stem="polic" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="24" string="Department" lemma="Department" stem="depart" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="25" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="led" lemma="lead" stem="led" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="significant" lemma="significant" stem="signific" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="improvements" lemma="improvement" stem="improv" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="there" lemma="there" stem="there" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Mr.) (NNP Williams)) (VP (VBD likened) (NP (DT the) (NN report)) (PP (TO to) (NP (NP (DT the) (NNP Knapp) (NNP Commission)) (, ,) (NP (NP (DT a) (CD 1970s) (JJ blue-ribbon) (NN study)) (SBAR (WHNP (WDT that)) (S (VP (VP (VBD exposed) (NP (JJ widespread) (NN corruption)) (PP (IN in) (NP (DT the) (NNP New) (NNP York) (NNP Police) (NNP Department)))) (CC and) (VP (VBD led) (PP (TO to) (NP (JJ significant) (NNS improvements))) (ADVP (RB there)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="widespread corruption" type="NP">
          <tokens>
            <token id="17" string="widespread" />
            <token id="18" string="corruption" />
          </tokens>
        </chunking>
        <chunking id="2" string="exposed widespread corruption in the New York Police Department" type="VP">
          <tokens>
            <token id="16" string="exposed" />
            <token id="17" string="widespread" />
            <token id="18" string="corruption" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="New" />
            <token id="22" string="York" />
            <token id="23" string="Police" />
            <token id="24" string="Department" />
          </tokens>
        </chunking>
        <chunking id="3" string="significant improvements" type="NP">
          <tokens>
            <token id="28" string="significant" />
            <token id="29" string="improvements" />
          </tokens>
        </chunking>
        <chunking id="4" string="that exposed widespread corruption in the New York Police Department and led to significant improvements there" type="SBAR">
          <tokens>
            <token id="15" string="that" />
            <token id="16" string="exposed" />
            <token id="17" string="widespread" />
            <token id="18" string="corruption" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="New" />
            <token id="22" string="York" />
            <token id="23" string="Police" />
            <token id="24" string="Department" />
            <token id="25" string="and" />
            <token id="26" string="led" />
            <token id="27" string="to" />
            <token id="28" string="significant" />
            <token id="29" string="improvements" />
            <token id="30" string="there" />
          </tokens>
        </chunking>
        <chunking id="5" string="likened the report to the Knapp Commission , a 1970s blue-ribbon study that exposed widespread corruption in the New York Police Department and led to significant improvements there" type="VP">
          <tokens>
            <token id="3" string="likened" />
            <token id="4" string="the" />
            <token id="5" string="report" />
            <token id="6" string="to" />
            <token id="7" string="the" />
            <token id="8" string="Knapp" />
            <token id="9" string="Commission" />
            <token id="10" string="," />
            <token id="11" string="a" />
            <token id="12" string="1970s" />
            <token id="13" string="blue-ribbon" />
            <token id="14" string="study" />
            <token id="15" string="that" />
            <token id="16" string="exposed" />
            <token id="17" string="widespread" />
            <token id="18" string="corruption" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="New" />
            <token id="22" string="York" />
            <token id="23" string="Police" />
            <token id="24" string="Department" />
            <token id="25" string="and" />
            <token id="26" string="led" />
            <token id="27" string="to" />
            <token id="28" string="significant" />
            <token id="29" string="improvements" />
            <token id="30" string="there" />
          </tokens>
        </chunking>
        <chunking id="6" string="a 1970s blue-ribbon study" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="1970s" />
            <token id="13" string="blue-ribbon" />
            <token id="14" string="study" />
          </tokens>
        </chunking>
        <chunking id="7" string="Mr. Williams" type="NP">
          <tokens>
            <token id="1" string="Mr." />
            <token id="2" string="Williams" />
          </tokens>
        </chunking>
        <chunking id="8" string="the Knapp Commission" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="Knapp" />
            <token id="9" string="Commission" />
          </tokens>
        </chunking>
        <chunking id="9" string="a 1970s blue-ribbon study that exposed widespread corruption in the New York Police Department and led to significant improvements there" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="1970s" />
            <token id="13" string="blue-ribbon" />
            <token id="14" string="study" />
            <token id="15" string="that" />
            <token id="16" string="exposed" />
            <token id="17" string="widespread" />
            <token id="18" string="corruption" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="New" />
            <token id="22" string="York" />
            <token id="23" string="Police" />
            <token id="24" string="Department" />
            <token id="25" string="and" />
            <token id="26" string="led" />
            <token id="27" string="to" />
            <token id="28" string="significant" />
            <token id="29" string="improvements" />
            <token id="30" string="there" />
          </tokens>
        </chunking>
        <chunking id="10" string="exposed widespread corruption in the New York Police Department and led to significant improvements there" type="VP">
          <tokens>
            <token id="16" string="exposed" />
            <token id="17" string="widespread" />
            <token id="18" string="corruption" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="New" />
            <token id="22" string="York" />
            <token id="23" string="Police" />
            <token id="24" string="Department" />
            <token id="25" string="and" />
            <token id="26" string="led" />
            <token id="27" string="to" />
            <token id="28" string="significant" />
            <token id="29" string="improvements" />
            <token id="30" string="there" />
          </tokens>
        </chunking>
        <chunking id="11" string="the New York Police Department" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="New" />
            <token id="22" string="York" />
            <token id="23" string="Police" />
            <token id="24" string="Department" />
          </tokens>
        </chunking>
        <chunking id="12" string="the Knapp Commission , a 1970s blue-ribbon study that exposed widespread corruption in the New York Police Department and led to significant improvements there" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="Knapp" />
            <token id="9" string="Commission" />
            <token id="10" string="," />
            <token id="11" string="a" />
            <token id="12" string="1970s" />
            <token id="13" string="blue-ribbon" />
            <token id="14" string="study" />
            <token id="15" string="that" />
            <token id="16" string="exposed" />
            <token id="17" string="widespread" />
            <token id="18" string="corruption" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="New" />
            <token id="22" string="York" />
            <token id="23" string="Police" />
            <token id="24" string="Department" />
            <token id="25" string="and" />
            <token id="26" string="led" />
            <token id="27" string="to" />
            <token id="28" string="significant" />
            <token id="29" string="improvements" />
            <token id="30" string="there" />
          </tokens>
        </chunking>
        <chunking id="13" string="the report" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="report" />
          </tokens>
        </chunking>
        <chunking id="14" string="led to significant improvements there" type="VP">
          <tokens>
            <token id="26" string="led" />
            <token id="27" string="to" />
            <token id="28" string="significant" />
            <token id="29" string="improvements" />
            <token id="30" string="there" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Williams</governor>
          <dependent id="1">Mr.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">likened</governor>
          <dependent id="2">Williams</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">likened</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">report</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">likened</governor>
          <dependent id="5">report</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Commission</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">Commission</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Commission</governor>
          <dependent id="8">Knapp</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">likened</governor>
          <dependent id="9">Commission</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">study</governor>
          <dependent id="11">a</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="14">study</governor>
          <dependent id="12">1970s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">study</governor>
          <dependent id="13">blue-ribbon</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="9">Commission</governor>
          <dependent id="14">study</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">exposed</governor>
          <dependent id="15">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="14">study</governor>
          <dependent id="16">exposed</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">corruption</governor>
          <dependent id="17">widespread</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">exposed</governor>
          <dependent id="18">corruption</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">Department</governor>
          <dependent id="19">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">Department</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">Department</governor>
          <dependent id="21">New</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">Department</governor>
          <dependent id="22">York</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">Department</governor>
          <dependent id="23">Police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">exposed</governor>
          <dependent id="24">Department</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="16">exposed</governor>
          <dependent id="25">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">exposed</governor>
          <dependent id="26">led</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">improvements</governor>
          <dependent id="27">to</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="29">improvements</governor>
          <dependent id="28">significant</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">led</governor>
          <dependent id="29">improvements</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="26">led</governor>
          <dependent id="30">there</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Williams" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Williams" />
          </tokens>
        </entity>
        <entity id="2" string="1970s" type="DATE" score="0.0">
          <tokens>
            <token id="12" string="1970s" />
          </tokens>
        </entity>
        <entity id="3" string="Knapp Commission" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="8" string="Knapp" />
            <token id="9" string="Commission" />
          </tokens>
        </entity>
        <entity id="4" string="New York Police Department" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="21" string="New" />
            <token id="22" string="York" />
            <token id="23" string="Police" />
            <token id="24" string="Department" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>&amp;quot;As troubling as some of our findings are . . . they are not unique to Los Angeles,&amp;quot; said John A. Arguelles, vice chairman of the 10-member Independent Commission on the Los Angeles Police Department.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="As" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="troubling" lemma="troubling" stem="troubl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="our" lemma="we" stem="our" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="findings" lemma="finding" stem="find" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string=". . ." lemma="..." stem=". . ." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="unique" lemma="unique" stem="uniqu" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="Los" lemma="Los" stem="lo" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="17" string="Angeles" lemma="Angeles" stem="angele" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="22" string="A." lemma="A." stem="a." pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="23" string="Arguelles" lemma="Arguelles" stem="arguell" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="vice" lemma="vice" stem="vice" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="chairman" lemma="chairman" stem="chairman" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="10-member" lemma="10-member" stem="10-member" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="Independent" lemma="Independent" stem="independ" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="31" string="Commission" lemma="Commission" stem="commiss" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="32" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="33" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="34" string="Los" lemma="Los" stem="lo" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="35" string="Angeles" lemma="Angeles" stem="angele" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="36" string="Police" lemma="Police" stem="polic" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="37" string="Department" lemma="Department" stem="depart" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="38" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (SBAR (IN As) (S (NP (NP (JJ troubling)) (PP (IN as) (NP (NP (DT some)) (PP (IN of) (NP (PRP$ our) (NNS findings)))))) (VP (VBP are)))) (: ...) (NP (PRP they)) (VP (VBP are) (RB not) (ADJP (JJ unique) (PP (TO to) (NP (NNP Los) (NNP Angeles)))))) (, ,) ('' '') (VP (VBD said)) (NP (NP (NNP John) (NNP A.) (NNP Arguelles)) (, ,) (NP (NP (NN vice) (NN chairman)) (PP (IN of) (NP (NP (DT the) (JJ 10-member) (NNP Independent) (NNP Commission)) (PP (IN on) (NP (DT the) (NNP Los) (NNP Angeles) (NNP Police) (NNP Department))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="As troubling as some of our findings are" type="SBAR">
          <tokens>
            <token id="2" string="As" />
            <token id="3" string="troubling" />
            <token id="4" string="as" />
            <token id="5" string="some" />
            <token id="6" string="of" />
            <token id="7" string="our" />
            <token id="8" string="findings" />
            <token id="9" string="are" />
          </tokens>
        </chunking>
        <chunking id="2" string="our findings" type="NP">
          <tokens>
            <token id="7" string="our" />
            <token id="8" string="findings" />
          </tokens>
        </chunking>
        <chunking id="3" string="vice chairman" type="NP">
          <tokens>
            <token id="25" string="vice" />
            <token id="26" string="chairman" />
          </tokens>
        </chunking>
        <chunking id="4" string="some" type="NP">
          <tokens>
            <token id="5" string="some" />
          </tokens>
        </chunking>
        <chunking id="5" string="troubling" type="NP">
          <tokens>
            <token id="3" string="troubling" />
          </tokens>
        </chunking>
        <chunking id="6" string="John A. Arguelles" type="NP">
          <tokens>
            <token id="21" string="John" />
            <token id="22" string="A." />
            <token id="23" string="Arguelles" />
          </tokens>
        </chunking>
        <chunking id="7" string="the 10-member Independent Commission on the Los Angeles Police Department" type="NP">
          <tokens>
            <token id="28" string="the" />
            <token id="29" string="10-member" />
            <token id="30" string="Independent" />
            <token id="31" string="Commission" />
            <token id="32" string="on" />
            <token id="33" string="the" />
            <token id="34" string="Los" />
            <token id="35" string="Angeles" />
            <token id="36" string="Police" />
            <token id="37" string="Department" />
          </tokens>
        </chunking>
        <chunking id="8" string="they" type="NP">
          <tokens>
            <token id="11" string="they" />
          </tokens>
        </chunking>
        <chunking id="9" string="are not unique to Los Angeles" type="VP">
          <tokens>
            <token id="12" string="are" />
            <token id="13" string="not" />
            <token id="14" string="unique" />
            <token id="15" string="to" />
            <token id="16" string="Los" />
            <token id="17" string="Angeles" />
          </tokens>
        </chunking>
        <chunking id="10" string="John A. Arguelles , vice chairman of the 10-member Independent Commission on the Los Angeles Police Department" type="NP">
          <tokens>
            <token id="21" string="John" />
            <token id="22" string="A." />
            <token id="23" string="Arguelles" />
            <token id="24" string="," />
            <token id="25" string="vice" />
            <token id="26" string="chairman" />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="10-member" />
            <token id="30" string="Independent" />
            <token id="31" string="Commission" />
            <token id="32" string="on" />
            <token id="33" string="the" />
            <token id="34" string="Los" />
            <token id="35" string="Angeles" />
            <token id="36" string="Police" />
            <token id="37" string="Department" />
          </tokens>
        </chunking>
        <chunking id="11" string="are" type="VP">
          <tokens>
            <token id="9" string="are" />
          </tokens>
        </chunking>
        <chunking id="12" string="some of our findings" type="NP">
          <tokens>
            <token id="5" string="some" />
            <token id="6" string="of" />
            <token id="7" string="our" />
            <token id="8" string="findings" />
          </tokens>
        </chunking>
        <chunking id="13" string="troubling as some of our findings" type="NP">
          <tokens>
            <token id="3" string="troubling" />
            <token id="4" string="as" />
            <token id="5" string="some" />
            <token id="6" string="of" />
            <token id="7" string="our" />
            <token id="8" string="findings" />
          </tokens>
        </chunking>
        <chunking id="14" string="unique to Los Angeles" type="ADJP">
          <tokens>
            <token id="14" string="unique" />
            <token id="15" string="to" />
            <token id="16" string="Los" />
            <token id="17" string="Angeles" />
          </tokens>
        </chunking>
        <chunking id="15" string="the 10-member Independent Commission" type="NP">
          <tokens>
            <token id="28" string="the" />
            <token id="29" string="10-member" />
            <token id="30" string="Independent" />
            <token id="31" string="Commission" />
          </tokens>
        </chunking>
        <chunking id="16" string="vice chairman of the 10-member Independent Commission on the Los Angeles Police Department" type="NP">
          <tokens>
            <token id="25" string="vice" />
            <token id="26" string="chairman" />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="10-member" />
            <token id="30" string="Independent" />
            <token id="31" string="Commission" />
            <token id="32" string="on" />
            <token id="33" string="the" />
            <token id="34" string="Los" />
            <token id="35" string="Angeles" />
            <token id="36" string="Police" />
            <token id="37" string="Department" />
          </tokens>
        </chunking>
        <chunking id="17" string="the Los Angeles Police Department" type="NP">
          <tokens>
            <token id="33" string="the" />
            <token id="34" string="Los" />
            <token id="35" string="Angeles" />
            <token id="36" string="Police" />
            <token id="37" string="Department" />
          </tokens>
        </chunking>
        <chunking id="18" string="Los Angeles" type="NP">
          <tokens>
            <token id="16" string="Los" />
            <token id="17" string="Angeles" />
          </tokens>
        </chunking>
        <chunking id="19" string="said" type="VP">
          <tokens>
            <token id="20" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="9">are</governor>
          <dependent id="2">As</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">are</governor>
          <dependent id="3">troubling</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">some</governor>
          <dependent id="4">as</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">troubling</governor>
          <dependent id="5">some</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">findings</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">findings</governor>
          <dependent id="7">our</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">some</governor>
          <dependent id="8">findings</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="14">unique</governor>
          <dependent id="9">are</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">unique</governor>
          <dependent id="11">they</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="14">unique</governor>
          <dependent id="12">are</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="14">unique</governor>
          <dependent id="13">not</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="20">said</governor>
          <dependent id="14">unique</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">Angeles</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">Angeles</governor>
          <dependent id="16">Los</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">unique</governor>
          <dependent id="17">Angeles</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="20">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">Arguelles</governor>
          <dependent id="21">John</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">Arguelles</governor>
          <dependent id="22">A.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">said</governor>
          <dependent id="23">Arguelles</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">chairman</governor>
          <dependent id="25">vice</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="23">Arguelles</governor>
          <dependent id="26">chairman</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">Commission</governor>
          <dependent id="27">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">Commission</governor>
          <dependent id="28">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="31">Commission</governor>
          <dependent id="29">10-member</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">Commission</governor>
          <dependent id="30">Independent</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">chairman</governor>
          <dependent id="31">Commission</dependent>
        </dependency>
        <dependency type="case">
          <governor id="37">Department</governor>
          <dependent id="32">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="37">Department</governor>
          <dependent id="33">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="37">Department</governor>
          <dependent id="34">Los</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="37">Department</governor>
          <dependent id="35">Angeles</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="37">Department</governor>
          <dependent id="36">Police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">Commission</governor>
          <dependent id="37">Department</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Independent Commission on the Los Angeles Police Department" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="30" string="Independent" />
            <token id="31" string="Commission" />
            <token id="32" string="on" />
            <token id="33" string="the" />
            <token id="34" string="Los" />
            <token id="35" string="Angeles" />
            <token id="36" string="Police" />
            <token id="37" string="Department" />
          </tokens>
        </entity>
        <entity id="2" string="John A. Arguelles" type="PERSON" score="0.0">
          <tokens>
            <token id="21" string="John" />
            <token id="22" string="A." />
            <token id="23" string="Arguelles" />
          </tokens>
        </entity>
        <entity id="3" string="Los Angeles" type="LOCATION" score="0.0">
          <tokens>
            <token id="16" string="Los" />
            <token id="17" string="Angeles" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>Among the commission&amp;apost;s recommendations are: -- A commission appointed by the mayor that oversees the department should be reorganized and strengthened, and made responsible for handling citizen complaints.</content>
      <tokens>
        <token id="1" string="Among" lemma="among" stem="among" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="3" string="commission" lemma="commission" stem="commiss" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="4" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="5" string="recommendations" lemma="recommendation" stem="recommend" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="commission" lemma="commission" stem="commiss" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="appointed" lemma="appoint" stem="appoint" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="14" string="mayor" lemma="mayor" stem="mayor" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="15" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="16" string="oversees" lemma="oversee" stem="overse" pos="VBZ" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="department" lemma="department" stem="depart" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="19" string="should" lemma="should" stem="should" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="reorganized" lemma="reorganize" stem="reorgan" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="strengthened" lemma="strengthen" stem="strengthen" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="made" lemma="make" stem="made" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="responsible" lemma="responsible" stem="respons" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="handling" lemma="handle" stem="handl" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="citizen" lemma="citizen" stem="citizen" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="31" string="complaints" lemma="complaint" stem="complaint" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN Among) (NP (NP (NP (DT the) (NN commission) (POS 's)) (NNS recommendations)) (SBAR (S (VP (VBP are) (: :) (: --) (NP (NP (DT A) (NN commission)) (VP (VBN appointed) (PP (IN by) (NP (NP (DT the) (NN mayor)) (SBAR (WHNP (WDT that)) (S (VP (VBZ oversees))))))))))))) (NP (DT the) (NN department)) (VP (VP (MD should) (VP (VB be) (VP (VBN reorganized) (CC and) (VBN strengthened)))) (, ,) (CC and) (VP (VBD made) (ADJP (JJ responsible) (PP (IN for) (S (VP (VBG handling) (NP (NN citizen) (NNS complaints)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the mayor" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="mayor" />
          </tokens>
        </chunking>
        <chunking id="2" string="citizen complaints" type="NP">
          <tokens>
            <token id="30" string="citizen" />
            <token id="31" string="complaints" />
          </tokens>
        </chunking>
        <chunking id="3" string="the commission 's recommendations are : -- A commission appointed by the mayor that oversees" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="commission" />
            <token id="4" string="'s" />
            <token id="5" string="recommendations" />
            <token id="6" string="are" />
            <token id="7" string=":" />
            <token id="8" string="--" />
            <token id="9" string="A" />
            <token id="10" string="commission" />
            <token id="11" string="appointed" />
            <token id="12" string="by" />
            <token id="13" string="the" />
            <token id="14" string="mayor" />
            <token id="15" string="that" />
            <token id="16" string="oversees" />
          </tokens>
        </chunking>
        <chunking id="4" string="A commission appointed by the mayor that oversees" type="NP">
          <tokens>
            <token id="9" string="A" />
            <token id="10" string="commission" />
            <token id="11" string="appointed" />
            <token id="12" string="by" />
            <token id="13" string="the" />
            <token id="14" string="mayor" />
            <token id="15" string="that" />
            <token id="16" string="oversees" />
          </tokens>
        </chunking>
        <chunking id="5" string="oversees" type="VP">
          <tokens>
            <token id="16" string="oversees" />
          </tokens>
        </chunking>
        <chunking id="6" string="responsible for handling citizen complaints" type="ADJP">
          <tokens>
            <token id="27" string="responsible" />
            <token id="28" string="for" />
            <token id="29" string="handling" />
            <token id="30" string="citizen" />
            <token id="31" string="complaints" />
          </tokens>
        </chunking>
        <chunking id="7" string="be reorganized and strengthened" type="VP">
          <tokens>
            <token id="20" string="be" />
            <token id="21" string="reorganized" />
            <token id="22" string="and" />
            <token id="23" string="strengthened" />
          </tokens>
        </chunking>
        <chunking id="8" string="appointed by the mayor that oversees" type="VP">
          <tokens>
            <token id="11" string="appointed" />
            <token id="12" string="by" />
            <token id="13" string="the" />
            <token id="14" string="mayor" />
            <token id="15" string="that" />
            <token id="16" string="oversees" />
          </tokens>
        </chunking>
        <chunking id="9" string="A commission" type="NP">
          <tokens>
            <token id="9" string="A" />
            <token id="10" string="commission" />
          </tokens>
        </chunking>
        <chunking id="10" string="the commission 's" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="commission" />
            <token id="4" string="'s" />
          </tokens>
        </chunking>
        <chunking id="11" string="the mayor that oversees" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="mayor" />
            <token id="15" string="that" />
            <token id="16" string="oversees" />
          </tokens>
        </chunking>
        <chunking id="12" string="should be reorganized and strengthened" type="VP">
          <tokens>
            <token id="19" string="should" />
            <token id="20" string="be" />
            <token id="21" string="reorganized" />
            <token id="22" string="and" />
            <token id="23" string="strengthened" />
          </tokens>
        </chunking>
        <chunking id="13" string="reorganized and strengthened" type="VP">
          <tokens>
            <token id="21" string="reorganized" />
            <token id="22" string="and" />
            <token id="23" string="strengthened" />
          </tokens>
        </chunking>
        <chunking id="14" string="the commission 's recommendations" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="commission" />
            <token id="4" string="'s" />
            <token id="5" string="recommendations" />
          </tokens>
        </chunking>
        <chunking id="15" string="handling citizen complaints" type="VP">
          <tokens>
            <token id="29" string="handling" />
            <token id="30" string="citizen" />
            <token id="31" string="complaints" />
          </tokens>
        </chunking>
        <chunking id="16" string="that oversees" type="SBAR">
          <tokens>
            <token id="15" string="that" />
            <token id="16" string="oversees" />
          </tokens>
        </chunking>
        <chunking id="17" string="the department" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="department" />
          </tokens>
        </chunking>
        <chunking id="18" string="made responsible for handling citizen complaints" type="VP">
          <tokens>
            <token id="26" string="made" />
            <token id="27" string="responsible" />
            <token id="28" string="for" />
            <token id="29" string="handling" />
            <token id="30" string="citizen" />
            <token id="31" string="complaints" />
          </tokens>
        </chunking>
        <chunking id="19" string="are : -- A commission appointed by the mayor that oversees" type="SBAR">
          <tokens>
            <token id="6" string="are" />
            <token id="7" string=":" />
            <token id="8" string="--" />
            <token id="9" string="A" />
            <token id="10" string="commission" />
            <token id="11" string="appointed" />
            <token id="12" string="by" />
            <token id="13" string="the" />
            <token id="14" string="mayor" />
            <token id="15" string="that" />
            <token id="16" string="oversees" />
          </tokens>
        </chunking>
        <chunking id="20" string="should be reorganized and strengthened , and made responsible for handling citizen complaints" type="VP">
          <tokens>
            <token id="19" string="should" />
            <token id="20" string="be" />
            <token id="21" string="reorganized" />
            <token id="22" string="and" />
            <token id="23" string="strengthened" />
            <token id="24" string="," />
            <token id="25" string="and" />
            <token id="26" string="made" />
            <token id="27" string="responsible" />
            <token id="28" string="for" />
            <token id="29" string="handling" />
            <token id="30" string="citizen" />
            <token id="31" string="complaints" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="5">recommendations</governor>
          <dependent id="1">Among</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">commission</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">recommendations</governor>
          <dependent id="3">commission</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">commission</governor>
          <dependent id="4">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">reorganized</governor>
          <dependent id="5">recommendations</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="10">commission</governor>
          <dependent id="6">are</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">commission</governor>
          <dependent id="9">A</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="5">recommendations</governor>
          <dependent id="10">commission</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="10">commission</governor>
          <dependent id="11">appointed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">mayor</governor>
          <dependent id="12">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">mayor</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">appointed</governor>
          <dependent id="14">mayor</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">oversees</governor>
          <dependent id="15">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="14">mayor</governor>
          <dependent id="16">oversees</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">department</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="21">reorganized</governor>
          <dependent id="18">department</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="21">reorganized</governor>
          <dependent id="19">should</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="21">reorganized</governor>
          <dependent id="20">be</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="21">reorganized</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="21">reorganized</governor>
          <dependent id="22">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="21">reorganized</governor>
          <dependent id="23">strengthened</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="21">reorganized</governor>
          <dependent id="25">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="21">reorganized</governor>
          <dependent id="26">made</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="26">made</governor>
          <dependent id="27">responsible</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="29">handling</governor>
          <dependent id="28">for</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="27">responsible</governor>
          <dependent id="29">handling</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">complaints</governor>
          <dependent id="30">citizen</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="29">handling</governor>
          <dependent id="31">complaints</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>It also should be &amp;quot;reconstituted&amp;quot; with members not linked with the current controversy, in the interest of a &amp;quot;fresh start.&amp;quot;</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="should" lemma="should" stem="should" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="reconstituted" lemma="reconstitute" stem="reconstitut" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="members" lemma="member" stem="member" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="linked" lemma="link" stem="link" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="current" lemma="current" stem="current" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="15" string="controversy" lemma="controversy" stem="controversi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="interest" lemma="interest" stem="interest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="fresh" lemma="fresh" stem="fresh" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="start" lemma="start" stem="start" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP It)) (ADVP (RB also)) (VP (MD should) (VP (VB be) (VP (`` ``) (VBN reconstituted) ('' '') (PP (IN with) (NP (NNS members))) (ADVP (RB not) (S (VP (VBN linked) (PP (IN with) (NP (DT the) (JJ current) (NN controversy))) (, ,) (PP (IN in) (NP (NP (DT the) (NN interest)) (PP (IN of) (NP (DT a) (`` ``) (JJ fresh) (NN start))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="the current controversy" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="current" />
            <token id="15" string="controversy" />
          </tokens>
        </chunking>
        <chunking id="2" string="a `` fresh start" type="NP">
          <tokens>
            <token id="21" string="a" />
            <token id="22" string="&quot;" />
            <token id="23" string="fresh" />
            <token id="24" string="start" />
          </tokens>
        </chunking>
        <chunking id="3" string="should be `` reconstituted '' with members not linked with the current controversy , in the interest of a `` fresh start" type="VP">
          <tokens>
            <token id="3" string="should" />
            <token id="4" string="be" />
            <token id="5" string="&quot;" />
            <token id="6" string="reconstituted" />
            <token id="7" string="&quot;" />
            <token id="8" string="with" />
            <token id="9" string="members" />
            <token id="10" string="not" />
            <token id="11" string="linked" />
            <token id="12" string="with" />
            <token id="13" string="the" />
            <token id="14" string="current" />
            <token id="15" string="controversy" />
            <token id="16" string="," />
            <token id="17" string="in" />
            <token id="18" string="the" />
            <token id="19" string="interest" />
            <token id="20" string="of" />
            <token id="21" string="a" />
            <token id="22" string="&quot;" />
            <token id="23" string="fresh" />
            <token id="24" string="start" />
          </tokens>
        </chunking>
        <chunking id="4" string="`` reconstituted '' with members not linked with the current controversy , in the interest of a `` fresh start" type="VP">
          <tokens>
            <token id="5" string="&quot;" />
            <token id="6" string="reconstituted" />
            <token id="7" string="&quot;" />
            <token id="8" string="with" />
            <token id="9" string="members" />
            <token id="10" string="not" />
            <token id="11" string="linked" />
            <token id="12" string="with" />
            <token id="13" string="the" />
            <token id="14" string="current" />
            <token id="15" string="controversy" />
            <token id="16" string="," />
            <token id="17" string="in" />
            <token id="18" string="the" />
            <token id="19" string="interest" />
            <token id="20" string="of" />
            <token id="21" string="a" />
            <token id="22" string="&quot;" />
            <token id="23" string="fresh" />
            <token id="24" string="start" />
          </tokens>
        </chunking>
        <chunking id="5" string="members" type="NP">
          <tokens>
            <token id="9" string="members" />
          </tokens>
        </chunking>
        <chunking id="6" string="the interest" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="interest" />
          </tokens>
        </chunking>
        <chunking id="7" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="8" string="linked with the current controversy , in the interest of a `` fresh start" type="VP">
          <tokens>
            <token id="11" string="linked" />
            <token id="12" string="with" />
            <token id="13" string="the" />
            <token id="14" string="current" />
            <token id="15" string="controversy" />
            <token id="16" string="," />
            <token id="17" string="in" />
            <token id="18" string="the" />
            <token id="19" string="interest" />
            <token id="20" string="of" />
            <token id="21" string="a" />
            <token id="22" string="&quot;" />
            <token id="23" string="fresh" />
            <token id="24" string="start" />
          </tokens>
        </chunking>
        <chunking id="9" string="the interest of a `` fresh start" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="interest" />
            <token id="20" string="of" />
            <token id="21" string="a" />
            <token id="22" string="&quot;" />
            <token id="23" string="fresh" />
            <token id="24" string="start" />
          </tokens>
        </chunking>
        <chunking id="10" string="be `` reconstituted '' with members not linked with the current controversy , in the interest of a `` fresh start" type="VP">
          <tokens>
            <token id="4" string="be" />
            <token id="5" string="&quot;" />
            <token id="6" string="reconstituted" />
            <token id="7" string="&quot;" />
            <token id="8" string="with" />
            <token id="9" string="members" />
            <token id="10" string="not" />
            <token id="11" string="linked" />
            <token id="12" string="with" />
            <token id="13" string="the" />
            <token id="14" string="current" />
            <token id="15" string="controversy" />
            <token id="16" string="," />
            <token id="17" string="in" />
            <token id="18" string="the" />
            <token id="19" string="interest" />
            <token id="20" string="of" />
            <token id="21" string="a" />
            <token id="22" string="&quot;" />
            <token id="23" string="fresh" />
            <token id="24" string="start" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="6">reconstituted</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">reconstituted</governor>
          <dependent id="2">also</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">reconstituted</governor>
          <dependent id="3">should</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="6">reconstituted</governor>
          <dependent id="4">be</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">reconstituted</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">members</governor>
          <dependent id="8">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">reconstituted</governor>
          <dependent id="9">members</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="6">reconstituted</governor>
          <dependent id="10">not</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="10">not</governor>
          <dependent id="11">linked</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">controversy</governor>
          <dependent id="12">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">controversy</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">controversy</governor>
          <dependent id="14">current</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">linked</governor>
          <dependent id="15">controversy</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">interest</governor>
          <dependent id="17">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">interest</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">linked</governor>
          <dependent id="19">interest</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">start</governor>
          <dependent id="20">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">start</governor>
          <dependent id="21">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">start</governor>
          <dependent id="23">fresh</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">interest</governor>
          <dependent id="24">start</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="current" type="DATE" score="0.0">
          <tokens>
            <token id="14" string="current" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>-- A &amp;quot;major overhaul&amp;quot; of the police disciplinary system and the process used by citizens to file complaints against LAPD officers, especially in excessive force cases, is needed.</content>
      <tokens>
        <token id="1" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="major" lemma="major" stem="major" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="overhaul" lemma="overhaul" stem="overhaul" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="disciplinary" lemma="disciplinary" stem="disciplinari" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="system" lemma="system" stem="system" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="process" lemma="process" stem="process" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="used" lemma="use" stem="us" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="citizens" lemma="citizen" stem="citizen" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="file" lemma="file" stem="file" pos="VB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="complaints" lemma="complaint" stem="complaint" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="21" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="LAPD" lemma="LAPD" stem="lapd" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="23" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="25" string="especially" lemma="especially" stem="especi" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="26" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="27" string="excessive" lemma="excessive" stem="excess" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="28" string="force" lemma="force" stem="forc" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="29" string="cases" lemma="case" stem="case" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="30" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="needed" lemma="need" stem="need" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: --) (NP (NP (DT A) (`` ``) (JJ major) (NN overhaul) ('' '')) (PP (IN of) (NP (NP (DT the) (NN police) (JJ disciplinary) (NN system)) (CC and) (NP (NP (DT the) (NN process)) (VP (VBN used) (PP (IN by) (NP (NNS citizens))) (S (VP (TO to) (VP (VB file) (NP (NNS complaints)) (PP (PP (IN against) (NP (NNP LAPD) (NNS officers))) (, ,) (RB especially) (PP (IN in) (NP (JJ excessive) (NN force) (NNS cases))))))))))) (, ,)) (VP (VBZ is) (VP (VBN needed))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="excessive force cases" type="NP">
          <tokens>
            <token id="27" string="excessive" />
            <token id="28" string="force" />
            <token id="29" string="cases" />
          </tokens>
        </chunking>
        <chunking id="2" string="A `` major overhaul '' of the police disciplinary system and the process used by citizens to file complaints against LAPD officers , especially in excessive force cases ," type="NP">
          <tokens>
            <token id="2" string="A" />
            <token id="3" string="&quot;" />
            <token id="4" string="major" />
            <token id="5" string="overhaul" />
            <token id="6" string="&quot;" />
            <token id="7" string="of" />
            <token id="8" string="the" />
            <token id="9" string="police" />
            <token id="10" string="disciplinary" />
            <token id="11" string="system" />
            <token id="12" string="and" />
            <token id="13" string="the" />
            <token id="14" string="process" />
            <token id="15" string="used" />
            <token id="16" string="by" />
            <token id="17" string="citizens" />
            <token id="18" string="to" />
            <token id="19" string="file" />
            <token id="20" string="complaints" />
            <token id="21" string="against" />
            <token id="22" string="LAPD" />
            <token id="23" string="officers" />
            <token id="24" string="," />
            <token id="25" string="especially" />
            <token id="26" string="in" />
            <token id="27" string="excessive" />
            <token id="28" string="force" />
            <token id="29" string="cases" />
            <token id="30" string="," />
          </tokens>
        </chunking>
        <chunking id="3" string="file complaints against LAPD officers , especially in excessive force cases" type="VP">
          <tokens>
            <token id="19" string="file" />
            <token id="20" string="complaints" />
            <token id="21" string="against" />
            <token id="22" string="LAPD" />
            <token id="23" string="officers" />
            <token id="24" string="," />
            <token id="25" string="especially" />
            <token id="26" string="in" />
            <token id="27" string="excessive" />
            <token id="28" string="force" />
            <token id="29" string="cases" />
          </tokens>
        </chunking>
        <chunking id="4" string="complaints" type="NP">
          <tokens>
            <token id="20" string="complaints" />
          </tokens>
        </chunking>
        <chunking id="5" string="needed" type="VP">
          <tokens>
            <token id="32" string="needed" />
          </tokens>
        </chunking>
        <chunking id="6" string="the police disciplinary system" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="police" />
            <token id="10" string="disciplinary" />
            <token id="11" string="system" />
          </tokens>
        </chunking>
        <chunking id="7" string="the police disciplinary system and the process used by citizens to file complaints against LAPD officers , especially in excessive force cases" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="police" />
            <token id="10" string="disciplinary" />
            <token id="11" string="system" />
            <token id="12" string="and" />
            <token id="13" string="the" />
            <token id="14" string="process" />
            <token id="15" string="used" />
            <token id="16" string="by" />
            <token id="17" string="citizens" />
            <token id="18" string="to" />
            <token id="19" string="file" />
            <token id="20" string="complaints" />
            <token id="21" string="against" />
            <token id="22" string="LAPD" />
            <token id="23" string="officers" />
            <token id="24" string="," />
            <token id="25" string="especially" />
            <token id="26" string="in" />
            <token id="27" string="excessive" />
            <token id="28" string="force" />
            <token id="29" string="cases" />
          </tokens>
        </chunking>
        <chunking id="8" string="the process" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="process" />
          </tokens>
        </chunking>
        <chunking id="9" string="to file complaints against LAPD officers , especially in excessive force cases" type="VP">
          <tokens>
            <token id="18" string="to" />
            <token id="19" string="file" />
            <token id="20" string="complaints" />
            <token id="21" string="against" />
            <token id="22" string="LAPD" />
            <token id="23" string="officers" />
            <token id="24" string="," />
            <token id="25" string="especially" />
            <token id="26" string="in" />
            <token id="27" string="excessive" />
            <token id="28" string="force" />
            <token id="29" string="cases" />
          </tokens>
        </chunking>
        <chunking id="10" string="LAPD officers" type="NP">
          <tokens>
            <token id="22" string="LAPD" />
            <token id="23" string="officers" />
          </tokens>
        </chunking>
        <chunking id="11" string="is needed" type="VP">
          <tokens>
            <token id="31" string="is" />
            <token id="32" string="needed" />
          </tokens>
        </chunking>
        <chunking id="12" string="A `` major overhaul ''" type="NP">
          <tokens>
            <token id="2" string="A" />
            <token id="3" string="&quot;" />
            <token id="4" string="major" />
            <token id="5" string="overhaul" />
            <token id="6" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="13" string="used by citizens to file complaints against LAPD officers , especially in excessive force cases" type="VP">
          <tokens>
            <token id="15" string="used" />
            <token id="16" string="by" />
            <token id="17" string="citizens" />
            <token id="18" string="to" />
            <token id="19" string="file" />
            <token id="20" string="complaints" />
            <token id="21" string="against" />
            <token id="22" string="LAPD" />
            <token id="23" string="officers" />
            <token id="24" string="," />
            <token id="25" string="especially" />
            <token id="26" string="in" />
            <token id="27" string="excessive" />
            <token id="28" string="force" />
            <token id="29" string="cases" />
          </tokens>
        </chunking>
        <chunking id="14" string="the process used by citizens to file complaints against LAPD officers , especially in excessive force cases" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="process" />
            <token id="15" string="used" />
            <token id="16" string="by" />
            <token id="17" string="citizens" />
            <token id="18" string="to" />
            <token id="19" string="file" />
            <token id="20" string="complaints" />
            <token id="21" string="against" />
            <token id="22" string="LAPD" />
            <token id="23" string="officers" />
            <token id="24" string="," />
            <token id="25" string="especially" />
            <token id="26" string="in" />
            <token id="27" string="excessive" />
            <token id="28" string="force" />
            <token id="29" string="cases" />
          </tokens>
        </chunking>
        <chunking id="15" string="citizens" type="NP">
          <tokens>
            <token id="17" string="citizens" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="5">overhaul</governor>
          <dependent id="2">A</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">overhaul</governor>
          <dependent id="4">major</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="32">needed</governor>
          <dependent id="5">overhaul</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">system</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">system</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">system</governor>
          <dependent id="9">police</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">system</governor>
          <dependent id="10">disciplinary</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">overhaul</governor>
          <dependent id="11">system</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="11">system</governor>
          <dependent id="12">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">process</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">system</governor>
          <dependent id="14">process</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="14">process</governor>
          <dependent id="15">used</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">citizens</governor>
          <dependent id="16">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">used</governor>
          <dependent id="17">citizens</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">file</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="15">used</governor>
          <dependent id="19">file</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">file</governor>
          <dependent id="20">complaints</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">officers</governor>
          <dependent id="21">against</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">officers</governor>
          <dependent id="22">LAPD</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="19">file</governor>
          <dependent id="23">officers</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="23">officers</governor>
          <dependent id="25">especially</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">cases</governor>
          <dependent id="26">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="29">cases</governor>
          <dependent id="27">excessive</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="29">cases</governor>
          <dependent id="28">force</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">officers</governor>
          <dependent id="29">cases</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="32">needed</governor>
          <dependent id="31">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="32">needed</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="LAPD" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="22" string="LAPD" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>The current system is &amp;quot;skewed against complainants,&amp;quot; by allowing officers&amp;apost; station-house colleagues to investigate complaints, perpetuating a &amp;quot;code of silence&amp;quot; among officers.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="current" lemma="current" stem="current" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="system" lemma="system" stem="system" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="skewed" lemma="skewed" stem="skew" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="complainants" lemma="complainant" stem="complain" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="allowing" lemma="allow" stem="allow" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="station-house" lemma="station-house" stem="station-hous" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="colleagues" lemma="colleague" stem="colleagu" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="investigate" lemma="investigate" stem="investig" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="complaints" lemma="complaint" stem="complaint" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="perpetuating" lemma="perpetuate" stem="perpetu" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="code" lemma="code" stem="code" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="silence" lemma="silence" stem="silenc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="among" lemma="among" stem="among" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (JJ current) (NN system)) (VP (VBZ is) (`` ``) (ADJP (JJ skewed) (PP (IN against) (NP (NP (NNS complainants)) (, ,) ('' '') (PP (IN by) (S (VP (VP (VBG allowing) (NP (NP (NNS officers) (POS ')) (JJ station-house) (NNS colleagues)) (S (VP (TO to) (VP (VB investigate) (NP (NNS complaints)))))) (, ,) (VP (VBG perpetuating) (NP (NP (DT a) (`` ``) (NN code)) (PP (IN of) (NP (NN silence)))) ('' '') (PP (IN among) (NP (NNS officers))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="complainants , '' by allowing officers ' station-house colleagues to investigate complaints , perpetuating a `` code of silence '' among officers" type="NP">
          <tokens>
            <token id="8" string="complainants" />
            <token id="9" string="," />
            <token id="10" string="&quot;" />
            <token id="11" string="by" />
            <token id="12" string="allowing" />
            <token id="13" string="officers" />
            <token id="14" string="'" />
            <token id="15" string="station-house" />
            <token id="16" string="colleagues" />
            <token id="17" string="to" />
            <token id="18" string="investigate" />
            <token id="19" string="complaints" />
            <token id="20" string="," />
            <token id="21" string="perpetuating" />
            <token id="22" string="a" />
            <token id="23" string="&quot;" />
            <token id="24" string="code" />
            <token id="25" string="of" />
            <token id="26" string="silence" />
            <token id="27" string="&quot;" />
            <token id="28" string="among" />
            <token id="29" string="officers" />
          </tokens>
        </chunking>
        <chunking id="2" string="a `` code" type="NP">
          <tokens>
            <token id="22" string="a" />
            <token id="23" string="&quot;" />
            <token id="24" string="code" />
          </tokens>
        </chunking>
        <chunking id="3" string="complainants" type="NP">
          <tokens>
            <token id="8" string="complainants" />
          </tokens>
        </chunking>
        <chunking id="4" string="officers ' station-house colleagues" type="NP">
          <tokens>
            <token id="13" string="officers" />
            <token id="14" string="'" />
            <token id="15" string="station-house" />
            <token id="16" string="colleagues" />
          </tokens>
        </chunking>
        <chunking id="5" string="The current system" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="current" />
            <token id="3" string="system" />
          </tokens>
        </chunking>
        <chunking id="6" string="complaints" type="NP">
          <tokens>
            <token id="19" string="complaints" />
          </tokens>
        </chunking>
        <chunking id="7" string="allowing officers ' station-house colleagues to investigate complaints , perpetuating a `` code of silence '' among officers" type="VP">
          <tokens>
            <token id="12" string="allowing" />
            <token id="13" string="officers" />
            <token id="14" string="'" />
            <token id="15" string="station-house" />
            <token id="16" string="colleagues" />
            <token id="17" string="to" />
            <token id="18" string="investigate" />
            <token id="19" string="complaints" />
            <token id="20" string="," />
            <token id="21" string="perpetuating" />
            <token id="22" string="a" />
            <token id="23" string="&quot;" />
            <token id="24" string="code" />
            <token id="25" string="of" />
            <token id="26" string="silence" />
            <token id="27" string="&quot;" />
            <token id="28" string="among" />
            <token id="29" string="officers" />
          </tokens>
        </chunking>
        <chunking id="8" string="allowing officers ' station-house colleagues to investigate complaints" type="VP">
          <tokens>
            <token id="12" string="allowing" />
            <token id="13" string="officers" />
            <token id="14" string="'" />
            <token id="15" string="station-house" />
            <token id="16" string="colleagues" />
            <token id="17" string="to" />
            <token id="18" string="investigate" />
            <token id="19" string="complaints" />
          </tokens>
        </chunking>
        <chunking id="9" string="is `` skewed against complainants , '' by allowing officers ' station-house colleagues to investigate complaints , perpetuating a `` code of silence '' among officers" type="VP">
          <tokens>
            <token id="4" string="is" />
            <token id="5" string="&quot;" />
            <token id="6" string="skewed" />
            <token id="7" string="against" />
            <token id="8" string="complainants" />
            <token id="9" string="," />
            <token id="10" string="&quot;" />
            <token id="11" string="by" />
            <token id="12" string="allowing" />
            <token id="13" string="officers" />
            <token id="14" string="'" />
            <token id="15" string="station-house" />
            <token id="16" string="colleagues" />
            <token id="17" string="to" />
            <token id="18" string="investigate" />
            <token id="19" string="complaints" />
            <token id="20" string="," />
            <token id="21" string="perpetuating" />
            <token id="22" string="a" />
            <token id="23" string="&quot;" />
            <token id="24" string="code" />
            <token id="25" string="of" />
            <token id="26" string="silence" />
            <token id="27" string="&quot;" />
            <token id="28" string="among" />
            <token id="29" string="officers" />
          </tokens>
        </chunking>
        <chunking id="10" string="skewed against complainants , '' by allowing officers ' station-house colleagues to investigate complaints , perpetuating a `` code of silence '' among officers" type="ADJP">
          <tokens>
            <token id="6" string="skewed" />
            <token id="7" string="against" />
            <token id="8" string="complainants" />
            <token id="9" string="," />
            <token id="10" string="&quot;" />
            <token id="11" string="by" />
            <token id="12" string="allowing" />
            <token id="13" string="officers" />
            <token id="14" string="'" />
            <token id="15" string="station-house" />
            <token id="16" string="colleagues" />
            <token id="17" string="to" />
            <token id="18" string="investigate" />
            <token id="19" string="complaints" />
            <token id="20" string="," />
            <token id="21" string="perpetuating" />
            <token id="22" string="a" />
            <token id="23" string="&quot;" />
            <token id="24" string="code" />
            <token id="25" string="of" />
            <token id="26" string="silence" />
            <token id="27" string="&quot;" />
            <token id="28" string="among" />
            <token id="29" string="officers" />
          </tokens>
        </chunking>
        <chunking id="11" string="officers '" type="NP">
          <tokens>
            <token id="13" string="officers" />
            <token id="14" string="'" />
          </tokens>
        </chunking>
        <chunking id="12" string="to investigate complaints" type="VP">
          <tokens>
            <token id="17" string="to" />
            <token id="18" string="investigate" />
            <token id="19" string="complaints" />
          </tokens>
        </chunking>
        <chunking id="13" string="a `` code of silence" type="NP">
          <tokens>
            <token id="22" string="a" />
            <token id="23" string="&quot;" />
            <token id="24" string="code" />
            <token id="25" string="of" />
            <token id="26" string="silence" />
          </tokens>
        </chunking>
        <chunking id="14" string="silence" type="NP">
          <tokens>
            <token id="26" string="silence" />
          </tokens>
        </chunking>
        <chunking id="15" string="investigate complaints" type="VP">
          <tokens>
            <token id="18" string="investigate" />
            <token id="19" string="complaints" />
          </tokens>
        </chunking>
        <chunking id="16" string="perpetuating a `` code of silence '' among officers" type="VP">
          <tokens>
            <token id="21" string="perpetuating" />
            <token id="22" string="a" />
            <token id="23" string="&quot;" />
            <token id="24" string="code" />
            <token id="25" string="of" />
            <token id="26" string="silence" />
            <token id="27" string="&quot;" />
            <token id="28" string="among" />
            <token id="29" string="officers" />
          </tokens>
        </chunking>
        <chunking id="17" string="officers" type="NP">
          <tokens>
            <token id="29" string="officers" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">system</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">system</governor>
          <dependent id="2">current</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">skewed</governor>
          <dependent id="3">system</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">skewed</governor>
          <dependent id="4">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">skewed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">complainants</governor>
          <dependent id="7">against</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">skewed</governor>
          <dependent id="8">complainants</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">allowing</governor>
          <dependent id="11">by</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="8">complainants</governor>
          <dependent id="12">allowing</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="16">colleagues</governor>
          <dependent id="13">officers</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">officers</governor>
          <dependent id="14">'</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">colleagues</governor>
          <dependent id="15">station-house</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">allowing</governor>
          <dependent id="16">colleagues</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">investigate</governor>
          <dependent id="17">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="12">allowing</governor>
          <dependent id="18">investigate</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">investigate</governor>
          <dependent id="19">complaints</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="12">allowing</governor>
          <dependent id="21">perpetuating</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">code</governor>
          <dependent id="22">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">perpetuating</governor>
          <dependent id="24">code</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">silence</governor>
          <dependent id="25">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">code</governor>
          <dependent id="26">silence</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">officers</governor>
          <dependent id="28">among</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">perpetuating</governor>
          <dependent id="29">officers</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="current" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="current" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="17" has_coreference="true">
      <content>-- A new community-based police force should focus on &amp;quot;service to the public and prevention of crime&amp;quot; as primary tasks rather than amassing arrest statistics.</content>
      <tokens>
        <token id="1" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="new" lemma="new" stem="new" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="community-based" lemma="community-based" stem="community-bas" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="force" lemma="force" stem="forc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="should" lemma="should" stem="should" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="focus" lemma="focus" stem="focu" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="service" lemma="service" stem="servic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="public" lemma="public" stem="public" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="prevention" lemma="prevention" stem="prevent" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="crime" lemma="crime" stem="crime" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="primary" lemma="primary" stem="primari" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="tasks" lemma="task" stem="task" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="rather" lemma="rather" stem="rather" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="amassing" lemma="amass" stem="amass" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="arrest" lemma="arrest" stem="arrest" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="27" string="statistics" lemma="statistics" stem="statist" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: --) (NP (DT A) (JJ new) (JJ community-based) (NN police) (NN force)) (VP (MD should) (VP (VP (VB focus) (PP (IN on) (`` ``) (NP (NP (NP (NN service)) (PP (TO to) (NP (DT the) (JJ public)))) (CC and) (NP (NP (NN prevention)) (PP (IN of) (NP (NN crime))))) ('' '')) (PP (IN as) (NP (JJ primary) (NNS tasks)))) (CONJP (RB rather) (IN than)) (VP (VBG amassing) (NP (NN arrest) (NNS statistics))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="focus on `` service to the public and prevention of crime '' as primary tasks" type="VP">
          <tokens>
            <token id="8" string="focus" />
            <token id="9" string="on" />
            <token id="10" string="&quot;" />
            <token id="11" string="service" />
            <token id="12" string="to" />
            <token id="13" string="the" />
            <token id="14" string="public" />
            <token id="15" string="and" />
            <token id="16" string="prevention" />
            <token id="17" string="of" />
            <token id="18" string="crime" />
            <token id="19" string="&quot;" />
            <token id="20" string="as" />
            <token id="21" string="primary" />
            <token id="22" string="tasks" />
          </tokens>
        </chunking>
        <chunking id="2" string="prevention" type="NP">
          <tokens>
            <token id="16" string="prevention" />
          </tokens>
        </chunking>
        <chunking id="3" string="service to the public and prevention of crime" type="NP">
          <tokens>
            <token id="11" string="service" />
            <token id="12" string="to" />
            <token id="13" string="the" />
            <token id="14" string="public" />
            <token id="15" string="and" />
            <token id="16" string="prevention" />
            <token id="17" string="of" />
            <token id="18" string="crime" />
          </tokens>
        </chunking>
        <chunking id="4" string="the public" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="public" />
          </tokens>
        </chunking>
        <chunking id="5" string="arrest statistics" type="NP">
          <tokens>
            <token id="26" string="arrest" />
            <token id="27" string="statistics" />
          </tokens>
        </chunking>
        <chunking id="6" string="service to the public" type="NP">
          <tokens>
            <token id="11" string="service" />
            <token id="12" string="to" />
            <token id="13" string="the" />
            <token id="14" string="public" />
          </tokens>
        </chunking>
        <chunking id="7" string="amassing arrest statistics" type="VP">
          <tokens>
            <token id="25" string="amassing" />
            <token id="26" string="arrest" />
            <token id="27" string="statistics" />
          </tokens>
        </chunking>
        <chunking id="8" string="should focus on `` service to the public and prevention of crime '' as primary tasks rather than amassing arrest statistics" type="VP">
          <tokens>
            <token id="7" string="should" />
            <token id="8" string="focus" />
            <token id="9" string="on" />
            <token id="10" string="&quot;" />
            <token id="11" string="service" />
            <token id="12" string="to" />
            <token id="13" string="the" />
            <token id="14" string="public" />
            <token id="15" string="and" />
            <token id="16" string="prevention" />
            <token id="17" string="of" />
            <token id="18" string="crime" />
            <token id="19" string="&quot;" />
            <token id="20" string="as" />
            <token id="21" string="primary" />
            <token id="22" string="tasks" />
            <token id="23" string="rather" />
            <token id="24" string="than" />
            <token id="25" string="amassing" />
            <token id="26" string="arrest" />
            <token id="27" string="statistics" />
          </tokens>
        </chunking>
        <chunking id="9" string="service" type="NP">
          <tokens>
            <token id="11" string="service" />
          </tokens>
        </chunking>
        <chunking id="10" string="crime" type="NP">
          <tokens>
            <token id="18" string="crime" />
          </tokens>
        </chunking>
        <chunking id="11" string="prevention of crime" type="NP">
          <tokens>
            <token id="16" string="prevention" />
            <token id="17" string="of" />
            <token id="18" string="crime" />
          </tokens>
        </chunking>
        <chunking id="12" string="focus on `` service to the public and prevention of crime '' as primary tasks rather than amassing arrest statistics" type="VP">
          <tokens>
            <token id="8" string="focus" />
            <token id="9" string="on" />
            <token id="10" string="&quot;" />
            <token id="11" string="service" />
            <token id="12" string="to" />
            <token id="13" string="the" />
            <token id="14" string="public" />
            <token id="15" string="and" />
            <token id="16" string="prevention" />
            <token id="17" string="of" />
            <token id="18" string="crime" />
            <token id="19" string="&quot;" />
            <token id="20" string="as" />
            <token id="21" string="primary" />
            <token id="22" string="tasks" />
            <token id="23" string="rather" />
            <token id="24" string="than" />
            <token id="25" string="amassing" />
            <token id="26" string="arrest" />
            <token id="27" string="statistics" />
          </tokens>
        </chunking>
        <chunking id="13" string="primary tasks" type="NP">
          <tokens>
            <token id="21" string="primary" />
            <token id="22" string="tasks" />
          </tokens>
        </chunking>
        <chunking id="14" string="A new community-based police force" type="NP">
          <tokens>
            <token id="2" string="A" />
            <token id="3" string="new" />
            <token id="4" string="community-based" />
            <token id="5" string="police" />
            <token id="6" string="force" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="6">force</governor>
          <dependent id="2">A</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">force</governor>
          <dependent id="3">new</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">force</governor>
          <dependent id="4">community-based</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">force</governor>
          <dependent id="5">police</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">focus</governor>
          <dependent id="6">force</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">focus</governor>
          <dependent id="7">should</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">focus</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">service</governor>
          <dependent id="9">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">focus</governor>
          <dependent id="11">service</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">public</governor>
          <dependent id="12">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">public</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">service</governor>
          <dependent id="14">public</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="11">service</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">service</governor>
          <dependent id="16">prevention</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">crime</governor>
          <dependent id="17">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">prevention</governor>
          <dependent id="18">crime</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">tasks</governor>
          <dependent id="20">as</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">tasks</governor>
          <dependent id="21">primary</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">focus</governor>
          <dependent id="22">tasks</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">focus</governor>
          <dependent id="23">rather</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="23">rather</governor>
          <dependent id="24">than</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">focus</governor>
          <dependent id="25">amassing</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">statistics</governor>
          <dependent id="26">arrest</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="25">amassing</governor>
          <dependent id="27">statistics</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="18" has_coreference="true">
      <content>However, the commission didn&amp;apost;t address how Los Angeles would pay for this major overhaul, though Mr. Christopher said that &amp;quot;when you see the costs of settlements accelerating&amp;quot; in police misconduct lawsuits as they have in recent years, &amp;quot;I&amp;apost;m not sure there will be a net cost&amp;quot; increase to implement the changes.</content>
      <tokens>
        <token id="1" string="However" lemma="however" stem="howev" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="commission" lemma="commission" stem="commiss" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="address" lemma="address" stem="address" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="how" lemma="how" stem="how" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Los" lemma="Los" stem="lo" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="10" string="Angeles" lemma="Angeles" stem="angele" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="11" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="pay" lemma="pay" stem="pai" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="major" lemma="major" stem="major" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="overhaul" lemma="overhaul" stem="overhaul" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="though" lemma="though" stem="though" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="Mr." lemma="Mr." stem="mr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="Christopher" lemma="Christopher" stem="christoph" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="21" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="26" string="see" lemma="see" stem="see" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="costs" lemma="cost" stem="cost" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="settlements" lemma="settlement" stem="settlement" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="accelerating" lemma="accelerate" stem="acceler" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="misconduct" lemma="misconduct" stem="misconduct" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="lawsuits" lemma="lawsuit" stem="lawsuit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="recent" lemma="recent" stem="recent" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="42" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="43" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="46" string="'m" lemma="be" stem="'m" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="47" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="48" string="sure" lemma="sure" stem="sure" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="49" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="50" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="51" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="52" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="53" string="net" lemma="net" stem="net" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="54" string="cost" lemma="cost" stem="cost" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="55" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="56" string="increase" lemma="increase" stem="increas" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="57" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="58" string="implement" lemma="implement" stem="implement" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="59" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="60" string="changes" lemma="change" stem="chang" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="61" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB However)) (, ,) (NP (DT the) (NN commission)) (VP (VBD did) (RB n't) (VP (VB address) (SBAR (WHADVP (WRB how)) (S (NP (NNP Los) (NNP Angeles)) (VP (MD would) (VP (VB pay) (PP (IN for) (NP (DT this) (JJ major) (NN overhaul))) (, ,) (SBAR (IN though) (S (NP (NNP Mr.) (NNP Christopher)) (VP (VBD said) (SBAR (IN that) (`` ``) (S (SBAR (WHADVP (WRB when)) (S (NP (PRP you)) (VP (VBP see) (S (NP (NP (DT the) (NNS costs)) (PP (IN of) (NP (NNS settlements)))) (VP (VBG accelerating) ('' '') (PP (IN in) (NP (NN police) (NN misconduct) (NNS lawsuits))) (SBAR (IN as) (S (NP (PRP they)) (VP (VBP have) (VP (PP (IN in) (NP (JJ recent) (NNS years)))))))))))) (, ,) (`` ``) (NP (PRP I)) (VP (VBP 'm) (RB not) (ADJP (JJ sure) (SBAR (S (NP (EX there)) (VP (MD will) (VP (VB be) (NP (NP (DT a) (JJ net) (NN cost) ('' '') (NN increase)) (SBAR (S (VP (TO to) (VP (VB implement) (NP (DT the) (NNS changes)))))))))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="accelerating '' in police misconduct lawsuits as they have in recent years" type="VP">
          <tokens>
            <token id="31" string="accelerating" />
            <token id="32" string="&quot;" />
            <token id="33" string="in" />
            <token id="34" string="police" />
            <token id="35" string="misconduct" />
            <token id="36" string="lawsuits" />
            <token id="37" string="as" />
            <token id="38" string="they" />
            <token id="39" string="have" />
            <token id="40" string="in" />
            <token id="41" string="recent" />
            <token id="42" string="years" />
          </tokens>
        </chunking>
        <chunking id="2" string="the commission" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="commission" />
          </tokens>
        </chunking>
        <chunking id="3" string="would pay for this major overhaul , though Mr. Christopher said that `` when you see the costs of settlements accelerating '' in police misconduct lawsuits as they have in recent years , `` I 'm not sure there will be a net cost '' increase to implement the changes" type="VP">
          <tokens>
            <token id="11" string="would" />
            <token id="12" string="pay" />
            <token id="13" string="for" />
            <token id="14" string="this" />
            <token id="15" string="major" />
            <token id="16" string="overhaul" />
            <token id="17" string="," />
            <token id="18" string="though" />
            <token id="19" string="Mr." />
            <token id="20" string="Christopher" />
            <token id="21" string="said" />
            <token id="22" string="that" />
            <token id="23" string="&quot;" />
            <token id="24" string="when" />
            <token id="25" string="you" />
            <token id="26" string="see" />
            <token id="27" string="the" />
            <token id="28" string="costs" />
            <token id="29" string="of" />
            <token id="30" string="settlements" />
            <token id="31" string="accelerating" />
            <token id="32" string="&quot;" />
            <token id="33" string="in" />
            <token id="34" string="police" />
            <token id="35" string="misconduct" />
            <token id="36" string="lawsuits" />
            <token id="37" string="as" />
            <token id="38" string="they" />
            <token id="39" string="have" />
            <token id="40" string="in" />
            <token id="41" string="recent" />
            <token id="42" string="years" />
            <token id="43" string="," />
            <token id="44" string="&quot;" />
            <token id="45" string="I" />
            <token id="46" string="'m" />
            <token id="47" string="not" />
            <token id="48" string="sure" />
            <token id="49" string="there" />
            <token id="50" string="will" />
            <token id="51" string="be" />
            <token id="52" string="a" />
            <token id="53" string="net" />
            <token id="54" string="cost" />
            <token id="55" string="&quot;" />
            <token id="56" string="increase" />
            <token id="57" string="to" />
            <token id="58" string="implement" />
            <token id="59" string="the" />
            <token id="60" string="changes" />
          </tokens>
        </chunking>
        <chunking id="4" string="be a net cost '' increase to implement the changes" type="VP">
          <tokens>
            <token id="51" string="be" />
            <token id="52" string="a" />
            <token id="53" string="net" />
            <token id="54" string="cost" />
            <token id="55" string="&quot;" />
            <token id="56" string="increase" />
            <token id="57" string="to" />
            <token id="58" string="implement" />
            <token id="59" string="the" />
            <token id="60" string="changes" />
          </tokens>
        </chunking>
        <chunking id="5" string="implement the changes" type="VP">
          <tokens>
            <token id="58" string="implement" />
            <token id="59" string="the" />
            <token id="60" string="changes" />
          </tokens>
        </chunking>
        <chunking id="6" string="address how Los Angeles would pay for this major overhaul , though Mr. Christopher said that `` when you see the costs of settlements accelerating '' in police misconduct lawsuits as they have in recent years , `` I 'm not sure there will be a net cost '' increase to implement the changes" type="VP">
          <tokens>
            <token id="7" string="address" />
            <token id="8" string="how" />
            <token id="9" string="Los" />
            <token id="10" string="Angeles" />
            <token id="11" string="would" />
            <token id="12" string="pay" />
            <token id="13" string="for" />
            <token id="14" string="this" />
            <token id="15" string="major" />
            <token id="16" string="overhaul" />
            <token id="17" string="," />
            <token id="18" string="though" />
            <token id="19" string="Mr." />
            <token id="20" string="Christopher" />
            <token id="21" string="said" />
            <token id="22" string="that" />
            <token id="23" string="&quot;" />
            <token id="24" string="when" />
            <token id="25" string="you" />
            <token id="26" string="see" />
            <token id="27" string="the" />
            <token id="28" string="costs" />
            <token id="29" string="of" />
            <token id="30" string="settlements" />
            <token id="31" string="accelerating" />
            <token id="32" string="&quot;" />
            <token id="33" string="in" />
            <token id="34" string="police" />
            <token id="35" string="misconduct" />
            <token id="36" string="lawsuits" />
            <token id="37" string="as" />
            <token id="38" string="they" />
            <token id="39" string="have" />
            <token id="40" string="in" />
            <token id="41" string="recent" />
            <token id="42" string="years" />
            <token id="43" string="," />
            <token id="44" string="&quot;" />
            <token id="45" string="I" />
            <token id="46" string="'m" />
            <token id="47" string="not" />
            <token id="48" string="sure" />
            <token id="49" string="there" />
            <token id="50" string="will" />
            <token id="51" string="be" />
            <token id="52" string="a" />
            <token id="53" string="net" />
            <token id="54" string="cost" />
            <token id="55" string="&quot;" />
            <token id="56" string="increase" />
            <token id="57" string="to" />
            <token id="58" string="implement" />
            <token id="59" string="the" />
            <token id="60" string="changes" />
          </tokens>
        </chunking>
        <chunking id="7" string="'m not sure there will be a net cost '' increase to implement the changes" type="VP">
          <tokens>
            <token id="46" string="'m" />
            <token id="47" string="not" />
            <token id="48" string="sure" />
            <token id="49" string="there" />
            <token id="50" string="will" />
            <token id="51" string="be" />
            <token id="52" string="a" />
            <token id="53" string="net" />
            <token id="54" string="cost" />
            <token id="55" string="&quot;" />
            <token id="56" string="increase" />
            <token id="57" string="to" />
            <token id="58" string="implement" />
            <token id="59" string="the" />
            <token id="60" string="changes" />
          </tokens>
        </chunking>
        <chunking id="8" string="there will be a net cost '' increase to implement the changes" type="SBAR">
          <tokens>
            <token id="49" string="there" />
            <token id="50" string="will" />
            <token id="51" string="be" />
            <token id="52" string="a" />
            <token id="53" string="net" />
            <token id="54" string="cost" />
            <token id="55" string="&quot;" />
            <token id="56" string="increase" />
            <token id="57" string="to" />
            <token id="58" string="implement" />
            <token id="59" string="the" />
            <token id="60" string="changes" />
          </tokens>
        </chunking>
        <chunking id="9" string="that `` when you see the costs of settlements accelerating '' in police misconduct lawsuits as they have in recent years , `` I 'm not sure there will be a net cost '' increase to implement the changes" type="SBAR">
          <tokens>
            <token id="22" string="that" />
            <token id="23" string="&quot;" />
            <token id="24" string="when" />
            <token id="25" string="you" />
            <token id="26" string="see" />
            <token id="27" string="the" />
            <token id="28" string="costs" />
            <token id="29" string="of" />
            <token id="30" string="settlements" />
            <token id="31" string="accelerating" />
            <token id="32" string="&quot;" />
            <token id="33" string="in" />
            <token id="34" string="police" />
            <token id="35" string="misconduct" />
            <token id="36" string="lawsuits" />
            <token id="37" string="as" />
            <token id="38" string="they" />
            <token id="39" string="have" />
            <token id="40" string="in" />
            <token id="41" string="recent" />
            <token id="42" string="years" />
            <token id="43" string="," />
            <token id="44" string="&quot;" />
            <token id="45" string="I" />
            <token id="46" string="'m" />
            <token id="47" string="not" />
            <token id="48" string="sure" />
            <token id="49" string="there" />
            <token id="50" string="will" />
            <token id="51" string="be" />
            <token id="52" string="a" />
            <token id="53" string="net" />
            <token id="54" string="cost" />
            <token id="55" string="&quot;" />
            <token id="56" string="increase" />
            <token id="57" string="to" />
            <token id="58" string="implement" />
            <token id="59" string="the" />
            <token id="60" string="changes" />
          </tokens>
        </chunking>
        <chunking id="10" string="the costs of settlements" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="costs" />
            <token id="29" string="of" />
            <token id="30" string="settlements" />
          </tokens>
        </chunking>
        <chunking id="11" string="there" type="NP">
          <tokens>
            <token id="49" string="there" />
          </tokens>
        </chunking>
        <chunking id="12" string="a net cost '' increase to implement the changes" type="NP">
          <tokens>
            <token id="52" string="a" />
            <token id="53" string="net" />
            <token id="54" string="cost" />
            <token id="55" string="&quot;" />
            <token id="56" string="increase" />
            <token id="57" string="to" />
            <token id="58" string="implement" />
            <token id="59" string="the" />
            <token id="60" string="changes" />
          </tokens>
        </chunking>
        <chunking id="13" string="sure there will be a net cost '' increase to implement the changes" type="ADJP">
          <tokens>
            <token id="48" string="sure" />
            <token id="49" string="there" />
            <token id="50" string="will" />
            <token id="51" string="be" />
            <token id="52" string="a" />
            <token id="53" string="net" />
            <token id="54" string="cost" />
            <token id="55" string="&quot;" />
            <token id="56" string="increase" />
            <token id="57" string="to" />
            <token id="58" string="implement" />
            <token id="59" string="the" />
            <token id="60" string="changes" />
          </tokens>
        </chunking>
        <chunking id="14" string="will be a net cost '' increase to implement the changes" type="VP">
          <tokens>
            <token id="50" string="will" />
            <token id="51" string="be" />
            <token id="52" string="a" />
            <token id="53" string="net" />
            <token id="54" string="cost" />
            <token id="55" string="&quot;" />
            <token id="56" string="increase" />
            <token id="57" string="to" />
            <token id="58" string="implement" />
            <token id="59" string="the" />
            <token id="60" string="changes" />
          </tokens>
        </chunking>
        <chunking id="15" string="the changes" type="NP">
          <tokens>
            <token id="59" string="the" />
            <token id="60" string="changes" />
          </tokens>
        </chunking>
        <chunking id="16" string="said that `` when you see the costs of settlements accelerating '' in police misconduct lawsuits as they have in recent years , `` I 'm not sure there will be a net cost '' increase to implement the changes" type="VP">
          <tokens>
            <token id="21" string="said" />
            <token id="22" string="that" />
            <token id="23" string="&quot;" />
            <token id="24" string="when" />
            <token id="25" string="you" />
            <token id="26" string="see" />
            <token id="27" string="the" />
            <token id="28" string="costs" />
            <token id="29" string="of" />
            <token id="30" string="settlements" />
            <token id="31" string="accelerating" />
            <token id="32" string="&quot;" />
            <token id="33" string="in" />
            <token id="34" string="police" />
            <token id="35" string="misconduct" />
            <token id="36" string="lawsuits" />
            <token id="37" string="as" />
            <token id="38" string="they" />
            <token id="39" string="have" />
            <token id="40" string="in" />
            <token id="41" string="recent" />
            <token id="42" string="years" />
            <token id="43" string="," />
            <token id="44" string="&quot;" />
            <token id="45" string="I" />
            <token id="46" string="'m" />
            <token id="47" string="not" />
            <token id="48" string="sure" />
            <token id="49" string="there" />
            <token id="50" string="will" />
            <token id="51" string="be" />
            <token id="52" string="a" />
            <token id="53" string="net" />
            <token id="54" string="cost" />
            <token id="55" string="&quot;" />
            <token id="56" string="increase" />
            <token id="57" string="to" />
            <token id="58" string="implement" />
            <token id="59" string="the" />
            <token id="60" string="changes" />
          </tokens>
        </chunking>
        <chunking id="17" string="Los Angeles" type="NP">
          <tokens>
            <token id="9" string="Los" />
            <token id="10" string="Angeles" />
          </tokens>
        </chunking>
        <chunking id="18" string="the costs" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="costs" />
          </tokens>
        </chunking>
        <chunking id="19" string="police misconduct lawsuits" type="NP">
          <tokens>
            <token id="34" string="police" />
            <token id="35" string="misconduct" />
            <token id="36" string="lawsuits" />
          </tokens>
        </chunking>
        <chunking id="20" string="settlements" type="NP">
          <tokens>
            <token id="30" string="settlements" />
          </tokens>
        </chunking>
        <chunking id="21" string="did n't address how Los Angeles would pay for this major overhaul , though Mr. Christopher said that `` when you see the costs of settlements accelerating '' in police misconduct lawsuits as they have in recent years , `` I 'm not sure there will be a net cost '' increase to implement the changes" type="VP">
          <tokens>
            <token id="5" string="did" />
            <token id="6" string="n't" />
            <token id="7" string="address" />
            <token id="8" string="how" />
            <token id="9" string="Los" />
            <token id="10" string="Angeles" />
            <token id="11" string="would" />
            <token id="12" string="pay" />
            <token id="13" string="for" />
            <token id="14" string="this" />
            <token id="15" string="major" />
            <token id="16" string="overhaul" />
            <token id="17" string="," />
            <token id="18" string="though" />
            <token id="19" string="Mr." />
            <token id="20" string="Christopher" />
            <token id="21" string="said" />
            <token id="22" string="that" />
            <token id="23" string="&quot;" />
            <token id="24" string="when" />
            <token id="25" string="you" />
            <token id="26" string="see" />
            <token id="27" string="the" />
            <token id="28" string="costs" />
            <token id="29" string="of" />
            <token id="30" string="settlements" />
            <token id="31" string="accelerating" />
            <token id="32" string="&quot;" />
            <token id="33" string="in" />
            <token id="34" string="police" />
            <token id="35" string="misconduct" />
            <token id="36" string="lawsuits" />
            <token id="37" string="as" />
            <token id="38" string="they" />
            <token id="39" string="have" />
            <token id="40" string="in" />
            <token id="41" string="recent" />
            <token id="42" string="years" />
            <token id="43" string="," />
            <token id="44" string="&quot;" />
            <token id="45" string="I" />
            <token id="46" string="'m" />
            <token id="47" string="not" />
            <token id="48" string="sure" />
            <token id="49" string="there" />
            <token id="50" string="will" />
            <token id="51" string="be" />
            <token id="52" string="a" />
            <token id="53" string="net" />
            <token id="54" string="cost" />
            <token id="55" string="&quot;" />
            <token id="56" string="increase" />
            <token id="57" string="to" />
            <token id="58" string="implement" />
            <token id="59" string="the" />
            <token id="60" string="changes" />
          </tokens>
        </chunking>
        <chunking id="22" string="how Los Angeles would pay for this major overhaul , though Mr. Christopher said that `` when you see the costs of settlements accelerating '' in police misconduct lawsuits as they have in recent years , `` I 'm not sure there will be a net cost '' increase to implement the changes" type="SBAR">
          <tokens>
            <token id="8" string="how" />
            <token id="9" string="Los" />
            <token id="10" string="Angeles" />
            <token id="11" string="would" />
            <token id="12" string="pay" />
            <token id="13" string="for" />
            <token id="14" string="this" />
            <token id="15" string="major" />
            <token id="16" string="overhaul" />
            <token id="17" string="," />
            <token id="18" string="though" />
            <token id="19" string="Mr." />
            <token id="20" string="Christopher" />
            <token id="21" string="said" />
            <token id="22" string="that" />
            <token id="23" string="&quot;" />
            <token id="24" string="when" />
            <token id="25" string="you" />
            <token id="26" string="see" />
            <token id="27" string="the" />
            <token id="28" string="costs" />
            <token id="29" string="of" />
            <token id="30" string="settlements" />
            <token id="31" string="accelerating" />
            <token id="32" string="&quot;" />
            <token id="33" string="in" />
            <token id="34" string="police" />
            <token id="35" string="misconduct" />
            <token id="36" string="lawsuits" />
            <token id="37" string="as" />
            <token id="38" string="they" />
            <token id="39" string="have" />
            <token id="40" string="in" />
            <token id="41" string="recent" />
            <token id="42" string="years" />
            <token id="43" string="," />
            <token id="44" string="&quot;" />
            <token id="45" string="I" />
            <token id="46" string="'m" />
            <token id="47" string="not" />
            <token id="48" string="sure" />
            <token id="49" string="there" />
            <token id="50" string="will" />
            <token id="51" string="be" />
            <token id="52" string="a" />
            <token id="53" string="net" />
            <token id="54" string="cost" />
            <token id="55" string="&quot;" />
            <token id="56" string="increase" />
            <token id="57" string="to" />
            <token id="58" string="implement" />
            <token id="59" string="the" />
            <token id="60" string="changes" />
          </tokens>
        </chunking>
        <chunking id="23" string="when you see the costs of settlements accelerating '' in police misconduct lawsuits as they have in recent years" type="SBAR">
          <tokens>
            <token id="24" string="when" />
            <token id="25" string="you" />
            <token id="26" string="see" />
            <token id="27" string="the" />
            <token id="28" string="costs" />
            <token id="29" string="of" />
            <token id="30" string="settlements" />
            <token id="31" string="accelerating" />
            <token id="32" string="&quot;" />
            <token id="33" string="in" />
            <token id="34" string="police" />
            <token id="35" string="misconduct" />
            <token id="36" string="lawsuits" />
            <token id="37" string="as" />
            <token id="38" string="they" />
            <token id="39" string="have" />
            <token id="40" string="in" />
            <token id="41" string="recent" />
            <token id="42" string="years" />
          </tokens>
        </chunking>
        <chunking id="24" string="pay for this major overhaul , though Mr. Christopher said that `` when you see the costs of settlements accelerating '' in police misconduct lawsuits as they have in recent years , `` I 'm not sure there will be a net cost '' increase to implement the changes" type="VP">
          <tokens>
            <token id="12" string="pay" />
            <token id="13" string="for" />
            <token id="14" string="this" />
            <token id="15" string="major" />
            <token id="16" string="overhaul" />
            <token id="17" string="," />
            <token id="18" string="though" />
            <token id="19" string="Mr." />
            <token id="20" string="Christopher" />
            <token id="21" string="said" />
            <token id="22" string="that" />
            <token id="23" string="&quot;" />
            <token id="24" string="when" />
            <token id="25" string="you" />
            <token id="26" string="see" />
            <token id="27" string="the" />
            <token id="28" string="costs" />
            <token id="29" string="of" />
            <token id="30" string="settlements" />
            <token id="31" string="accelerating" />
            <token id="32" string="&quot;" />
            <token id="33" string="in" />
            <token id="34" string="police" />
            <token id="35" string="misconduct" />
            <token id="36" string="lawsuits" />
            <token id="37" string="as" />
            <token id="38" string="they" />
            <token id="39" string="have" />
            <token id="40" string="in" />
            <token id="41" string="recent" />
            <token id="42" string="years" />
            <token id="43" string="," />
            <token id="44" string="&quot;" />
            <token id="45" string="I" />
            <token id="46" string="'m" />
            <token id="47" string="not" />
            <token id="48" string="sure" />
            <token id="49" string="there" />
            <token id="50" string="will" />
            <token id="51" string="be" />
            <token id="52" string="a" />
            <token id="53" string="net" />
            <token id="54" string="cost" />
            <token id="55" string="&quot;" />
            <token id="56" string="increase" />
            <token id="57" string="to" />
            <token id="58" string="implement" />
            <token id="59" string="the" />
            <token id="60" string="changes" />
          </tokens>
        </chunking>
        <chunking id="25" string="Mr. Christopher" type="NP">
          <tokens>
            <token id="19" string="Mr." />
            <token id="20" string="Christopher" />
          </tokens>
        </chunking>
        <chunking id="26" string="I" type="NP">
          <tokens>
            <token id="45" string="I" />
          </tokens>
        </chunking>
        <chunking id="27" string="as they have in recent years" type="SBAR">
          <tokens>
            <token id="37" string="as" />
            <token id="38" string="they" />
            <token id="39" string="have" />
            <token id="40" string="in" />
            <token id="41" string="recent" />
            <token id="42" string="years" />
          </tokens>
        </chunking>
        <chunking id="28" string="how" type="WHADVP">
          <tokens>
            <token id="8" string="how" />
          </tokens>
        </chunking>
        <chunking id="29" string="when" type="WHADVP">
          <tokens>
            <token id="24" string="when" />
          </tokens>
        </chunking>
        <chunking id="30" string="have in recent years" type="VP">
          <tokens>
            <token id="39" string="have" />
            <token id="40" string="in" />
            <token id="41" string="recent" />
            <token id="42" string="years" />
          </tokens>
        </chunking>
        <chunking id="31" string="to implement the changes" type="SBAR">
          <tokens>
            <token id="57" string="to" />
            <token id="58" string="implement" />
            <token id="59" string="the" />
            <token id="60" string="changes" />
          </tokens>
        </chunking>
        <chunking id="32" string="they" type="NP">
          <tokens>
            <token id="38" string="they" />
          </tokens>
        </chunking>
        <chunking id="33" string="recent years" type="NP">
          <tokens>
            <token id="41" string="recent" />
            <token id="42" string="years" />
          </tokens>
        </chunking>
        <chunking id="34" string="this major overhaul" type="NP">
          <tokens>
            <token id="14" string="this" />
            <token id="15" string="major" />
            <token id="16" string="overhaul" />
          </tokens>
        </chunking>
        <chunking id="35" string="though Mr. Christopher said that `` when you see the costs of settlements accelerating '' in police misconduct lawsuits as they have in recent years , `` I 'm not sure there will be a net cost '' increase to implement the changes" type="SBAR">
          <tokens>
            <token id="18" string="though" />
            <token id="19" string="Mr." />
            <token id="20" string="Christopher" />
            <token id="21" string="said" />
            <token id="22" string="that" />
            <token id="23" string="&quot;" />
            <token id="24" string="when" />
            <token id="25" string="you" />
            <token id="26" string="see" />
            <token id="27" string="the" />
            <token id="28" string="costs" />
            <token id="29" string="of" />
            <token id="30" string="settlements" />
            <token id="31" string="accelerating" />
            <token id="32" string="&quot;" />
            <token id="33" string="in" />
            <token id="34" string="police" />
            <token id="35" string="misconduct" />
            <token id="36" string="lawsuits" />
            <token id="37" string="as" />
            <token id="38" string="they" />
            <token id="39" string="have" />
            <token id="40" string="in" />
            <token id="41" string="recent" />
            <token id="42" string="years" />
            <token id="43" string="," />
            <token id="44" string="&quot;" />
            <token id="45" string="I" />
            <token id="46" string="'m" />
            <token id="47" string="not" />
            <token id="48" string="sure" />
            <token id="49" string="there" />
            <token id="50" string="will" />
            <token id="51" string="be" />
            <token id="52" string="a" />
            <token id="53" string="net" />
            <token id="54" string="cost" />
            <token id="55" string="&quot;" />
            <token id="56" string="increase" />
            <token id="57" string="to" />
            <token id="58" string="implement" />
            <token id="59" string="the" />
            <token id="60" string="changes" />
          </tokens>
        </chunking>
        <chunking id="36" string="see the costs of settlements accelerating '' in police misconduct lawsuits as they have in recent years" type="VP">
          <tokens>
            <token id="26" string="see" />
            <token id="27" string="the" />
            <token id="28" string="costs" />
            <token id="29" string="of" />
            <token id="30" string="settlements" />
            <token id="31" string="accelerating" />
            <token id="32" string="&quot;" />
            <token id="33" string="in" />
            <token id="34" string="police" />
            <token id="35" string="misconduct" />
            <token id="36" string="lawsuits" />
            <token id="37" string="as" />
            <token id="38" string="they" />
            <token id="39" string="have" />
            <token id="40" string="in" />
            <token id="41" string="recent" />
            <token id="42" string="years" />
          </tokens>
        </chunking>
        <chunking id="37" string="a net cost '' increase" type="NP">
          <tokens>
            <token id="52" string="a" />
            <token id="53" string="net" />
            <token id="54" string="cost" />
            <token id="55" string="&quot;" />
            <token id="56" string="increase" />
          </tokens>
        </chunking>
        <chunking id="38" string="in recent years" type="VP">
          <tokens>
            <token id="40" string="in" />
            <token id="41" string="recent" />
            <token id="42" string="years" />
          </tokens>
        </chunking>
        <chunking id="39" string="you" type="NP">
          <tokens>
            <token id="25" string="you" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="7">address</governor>
          <dependent id="1">However</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">commission</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">address</governor>
          <dependent id="4">commission</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">address</governor>
          <dependent id="5">did</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="7">address</governor>
          <dependent id="6">n't</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">address</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">pay</governor>
          <dependent id="8">how</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Angeles</governor>
          <dependent id="9">Los</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">pay</governor>
          <dependent id="10">Angeles</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">pay</governor>
          <dependent id="11">would</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">address</governor>
          <dependent id="12">pay</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">overhaul</governor>
          <dependent id="13">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">overhaul</governor>
          <dependent id="14">this</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">overhaul</governor>
          <dependent id="15">major</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">pay</governor>
          <dependent id="16">overhaul</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="21">said</governor>
          <dependent id="18">though</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">Christopher</governor>
          <dependent id="19">Mr.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">said</governor>
          <dependent id="20">Christopher</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="12">pay</governor>
          <dependent id="21">said</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="48">sure</governor>
          <dependent id="22">that</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="26">see</governor>
          <dependent id="24">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">see</governor>
          <dependent id="25">you</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="48">sure</governor>
          <dependent id="26">see</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">costs</governor>
          <dependent id="27">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="31">accelerating</governor>
          <dependent id="28">costs</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">settlements</governor>
          <dependent id="29">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">costs</governor>
          <dependent id="30">settlements</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="26">see</governor>
          <dependent id="31">accelerating</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">lawsuits</governor>
          <dependent id="33">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="36">lawsuits</governor>
          <dependent id="34">police</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="36">lawsuits</governor>
          <dependent id="35">misconduct</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">accelerating</governor>
          <dependent id="36">lawsuits</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="42">years</governor>
          <dependent id="37">as</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="42">years</governor>
          <dependent id="38">they</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="42">years</governor>
          <dependent id="39">have</dependent>
        </dependency>
        <dependency type="case">
          <governor id="42">years</governor>
          <dependent id="40">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="42">years</governor>
          <dependent id="41">recent</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="31">accelerating</governor>
          <dependent id="42">years</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="48">sure</governor>
          <dependent id="45">I</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="48">sure</governor>
          <dependent id="46">'m</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="48">sure</governor>
          <dependent id="47">not</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="21">said</governor>
          <dependent id="48">sure</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="56">increase</governor>
          <dependent id="49">there</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="56">increase</governor>
          <dependent id="50">will</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="56">increase</governor>
          <dependent id="51">be</dependent>
        </dependency>
        <dependency type="det">
          <governor id="56">increase</governor>
          <dependent id="52">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="56">increase</governor>
          <dependent id="53">net</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="56">increase</governor>
          <dependent id="54">cost</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="48">sure</governor>
          <dependent id="56">increase</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="58">implement</governor>
          <dependent id="57">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="56">increase</governor>
          <dependent id="58">implement</dependent>
        </dependency>
        <dependency type="det">
          <governor id="60">changes</governor>
          <dependent id="59">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="58">implement</governor>
          <dependent id="60">changes</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Christopher" type="PERSON" score="0.0">
          <tokens>
            <token id="20" string="Christopher" />
          </tokens>
        </entity>
        <entity id="2" string="recent years" type="DURATION" score="0.0">
          <tokens>
            <token id="41" string="recent" />
            <token id="42" string="years" />
          </tokens>
        </entity>
        <entity id="3" string="Los Angeles" type="LOCATION" score="0.0">
          <tokens>
            <token id="9" string="Los" />
            <token id="10" string="Angeles" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="19" has_coreference="true">
      <content>But with the city still sharply divided over the future of Chief Gates, and a general feeling that taxes are high enough already, it&amp;apost;s questionable whether there will be a popular groundswell to immediately fund changes.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="city" lemma="city" stem="citi" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="still" lemma="still" stem="still" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="sharply" lemma="sharply" stem="sharpli" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="divided" lemma="divide" stem="divid" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="over" lemma="over" stem="over" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="10" string="future" lemma="future" stem="futur" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="Chief" lemma="Chief" stem="chief" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="true" is_refers="true" />
        <token id="13" string="Gates" lemma="Gates" stem="gate" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="general" lemma="general" stem="gener" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="feeling" lemma="feeling" stem="feel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="taxes" lemma="tax" stem="tax" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="high" lemma="high" stem="high" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="enough" lemma="enough" stem="enough" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="already" lemma="already" stem="alreadi" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="questionable" lemma="questionable" stem="question" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="whether" lemma="whether" stem="whether" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="popular" lemma="popular" stem="popular" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="groundswell" lemma="groundswell" stem="groundswel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="immediately" lemma="immediately" stem="immedi" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="fund" lemma="fund" stem="fund" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="changes" lemma="change" stem="chang" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="40" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (PP (IN with) (NP (NP (NP (DT the) (NN city)) (VP (ADVP (RB still)) (ADVP (RB sharply)) (VBN divided) (PP (IN over) (NP (NP (DT the) (NN future)) (PP (IN of) (NP (NNP Chief) (NNP Gates))))))) (, ,) (CC and) (NP (NP (DT a) (JJ general) (NN feeling)) (SBAR (WHNP (WDT that)) (S (NP (NNS taxes)) (VP (VBP are) (ADVP (JJ high)) (ADJP (JJ enough)) (ADVP (RB already)))))))) (, ,) (NP (PRP it)) (VP (VBZ 's) (ADJP (JJ questionable)) (SBAR (IN whether) (S (NP (EX there)) (VP (MD will) (VP (VB be) (NP (DT a) (JJ popular) (NN groundswell) (S (VP (TO to) (VP (ADVP (RB immediately)) (VB fund) (NP (NNS changes))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a popular groundswell to immediately fund changes" type="NP">
          <tokens>
            <token id="33" string="a" />
            <token id="34" string="popular" />
            <token id="35" string="groundswell" />
            <token id="36" string="to" />
            <token id="37" string="immediately" />
            <token id="38" string="fund" />
            <token id="39" string="changes" />
          </tokens>
        </chunking>
        <chunking id="2" string="be a popular groundswell to immediately fund changes" type="VP">
          <tokens>
            <token id="32" string="be" />
            <token id="33" string="a" />
            <token id="34" string="popular" />
            <token id="35" string="groundswell" />
            <token id="36" string="to" />
            <token id="37" string="immediately" />
            <token id="38" string="fund" />
            <token id="39" string="changes" />
          </tokens>
        </chunking>
        <chunking id="3" string="the city" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="city" />
          </tokens>
        </chunking>
        <chunking id="4" string="taxes" type="NP">
          <tokens>
            <token id="20" string="taxes" />
          </tokens>
        </chunking>
        <chunking id="5" string="changes" type="NP">
          <tokens>
            <token id="39" string="changes" />
          </tokens>
        </chunking>
        <chunking id="6" string="Chief Gates" type="NP">
          <tokens>
            <token id="12" string="Chief" />
            <token id="13" string="Gates" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="26" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="are high enough already" type="VP">
          <tokens>
            <token id="21" string="are" />
            <token id="22" string="high" />
            <token id="23" string="enough" />
            <token id="24" string="already" />
          </tokens>
        </chunking>
        <chunking id="9" string="a general feeling that taxes are high enough already" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="general" />
            <token id="18" string="feeling" />
            <token id="19" string="that" />
            <token id="20" string="taxes" />
            <token id="21" string="are" />
            <token id="22" string="high" />
            <token id="23" string="enough" />
            <token id="24" string="already" />
          </tokens>
        </chunking>
        <chunking id="10" string="a general feeling" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="general" />
            <token id="18" string="feeling" />
          </tokens>
        </chunking>
        <chunking id="11" string="there" type="NP">
          <tokens>
            <token id="30" string="there" />
          </tokens>
        </chunking>
        <chunking id="12" string="the city still sharply divided over the future of Chief Gates , and a general feeling that taxes are high enough already" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="city" />
            <token id="5" string="still" />
            <token id="6" string="sharply" />
            <token id="7" string="divided" />
            <token id="8" string="over" />
            <token id="9" string="the" />
            <token id="10" string="future" />
            <token id="11" string="of" />
            <token id="12" string="Chief" />
            <token id="13" string="Gates" />
            <token id="14" string="," />
            <token id="15" string="and" />
            <token id="16" string="a" />
            <token id="17" string="general" />
            <token id="18" string="feeling" />
            <token id="19" string="that" />
            <token id="20" string="taxes" />
            <token id="21" string="are" />
            <token id="22" string="high" />
            <token id="23" string="enough" />
            <token id="24" string="already" />
          </tokens>
        </chunking>
        <chunking id="13" string="to immediately fund changes" type="VP">
          <tokens>
            <token id="36" string="to" />
            <token id="37" string="immediately" />
            <token id="38" string="fund" />
            <token id="39" string="changes" />
          </tokens>
        </chunking>
        <chunking id="14" string="will be a popular groundswell to immediately fund changes" type="VP">
          <tokens>
            <token id="31" string="will" />
            <token id="32" string="be" />
            <token id="33" string="a" />
            <token id="34" string="popular" />
            <token id="35" string="groundswell" />
            <token id="36" string="to" />
            <token id="37" string="immediately" />
            <token id="38" string="fund" />
            <token id="39" string="changes" />
          </tokens>
        </chunking>
        <chunking id="15" string="the city still sharply divided over the future of Chief Gates" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="city" />
            <token id="5" string="still" />
            <token id="6" string="sharply" />
            <token id="7" string="divided" />
            <token id="8" string="over" />
            <token id="9" string="the" />
            <token id="10" string="future" />
            <token id="11" string="of" />
            <token id="12" string="Chief" />
            <token id="13" string="Gates" />
          </tokens>
        </chunking>
        <chunking id="16" string="enough" type="ADJP">
          <tokens>
            <token id="23" string="enough" />
          </tokens>
        </chunking>
        <chunking id="17" string="still sharply divided over the future of Chief Gates" type="VP">
          <tokens>
            <token id="5" string="still" />
            <token id="6" string="sharply" />
            <token id="7" string="divided" />
            <token id="8" string="over" />
            <token id="9" string="the" />
            <token id="10" string="future" />
            <token id="11" string="of" />
            <token id="12" string="Chief" />
            <token id="13" string="Gates" />
          </tokens>
        </chunking>
        <chunking id="18" string="immediately fund changes" type="VP">
          <tokens>
            <token id="37" string="immediately" />
            <token id="38" string="fund" />
            <token id="39" string="changes" />
          </tokens>
        </chunking>
        <chunking id="19" string="the future" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="future" />
          </tokens>
        </chunking>
        <chunking id="20" string="whether there will be a popular groundswell to immediately fund changes" type="SBAR">
          <tokens>
            <token id="29" string="whether" />
            <token id="30" string="there" />
            <token id="31" string="will" />
            <token id="32" string="be" />
            <token id="33" string="a" />
            <token id="34" string="popular" />
            <token id="35" string="groundswell" />
            <token id="36" string="to" />
            <token id="37" string="immediately" />
            <token id="38" string="fund" />
            <token id="39" string="changes" />
          </tokens>
        </chunking>
        <chunking id="21" string="that taxes are high enough already" type="SBAR">
          <tokens>
            <token id="19" string="that" />
            <token id="20" string="taxes" />
            <token id="21" string="are" />
            <token id="22" string="high" />
            <token id="23" string="enough" />
            <token id="24" string="already" />
          </tokens>
        </chunking>
        <chunking id="22" string="questionable" type="ADJP">
          <tokens>
            <token id="28" string="questionable" />
          </tokens>
        </chunking>
        <chunking id="23" string="'s questionable whether there will be a popular groundswell to immediately fund changes" type="VP">
          <tokens>
            <token id="27" string="'s" />
            <token id="28" string="questionable" />
            <token id="29" string="whether" />
            <token id="30" string="there" />
            <token id="31" string="will" />
            <token id="32" string="be" />
            <token id="33" string="a" />
            <token id="34" string="popular" />
            <token id="35" string="groundswell" />
            <token id="36" string="to" />
            <token id="37" string="immediately" />
            <token id="38" string="fund" />
            <token id="39" string="changes" />
          </tokens>
        </chunking>
        <chunking id="24" string="the future of Chief Gates" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="future" />
            <token id="11" string="of" />
            <token id="12" string="Chief" />
            <token id="13" string="Gates" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="28">questionable</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">city</governor>
          <dependent id="2">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">city</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">questionable</governor>
          <dependent id="4">city</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">divided</governor>
          <dependent id="5">still</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">divided</governor>
          <dependent id="6">sharply</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="4">city</governor>
          <dependent id="7">divided</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">future</governor>
          <dependent id="8">over</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">future</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">divided</governor>
          <dependent id="10">future</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Gates</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Gates</governor>
          <dependent id="12">Chief</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">future</governor>
          <dependent id="13">Gates</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">city</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">feeling</governor>
          <dependent id="16">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">feeling</governor>
          <dependent id="17">general</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">city</governor>
          <dependent id="18">feeling</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="23">enough</governor>
          <dependent id="19">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">enough</governor>
          <dependent id="20">taxes</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="23">enough</governor>
          <dependent id="21">are</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="23">enough</governor>
          <dependent id="22">high</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="18">feeling</governor>
          <dependent id="23">enough</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="23">enough</governor>
          <dependent id="24">already</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="28">questionable</governor>
          <dependent id="26">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="28">questionable</governor>
          <dependent id="27">'s</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="28">questionable</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="35">groundswell</governor>
          <dependent id="29">whether</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="35">groundswell</governor>
          <dependent id="30">there</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="35">groundswell</governor>
          <dependent id="31">will</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="35">groundswell</governor>
          <dependent id="32">be</dependent>
        </dependency>
        <dependency type="det">
          <governor id="35">groundswell</governor>
          <dependent id="33">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="35">groundswell</governor>
          <dependent id="34">popular</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="28">questionable</governor>
          <dependent id="35">groundswell</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="38">fund</governor>
          <dependent id="36">to</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="38">fund</governor>
          <dependent id="37">immediately</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="35">groundswell</governor>
          <dependent id="38">fund</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="38">fund</governor>
          <dependent id="39">changes</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Chief" type="TITLE" score="0.0">
          <tokens>
            <token id="12" string="Chief" />
          </tokens>
        </entity>
        <entity id="2" string="the future" type="DATE" score="0.0">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="future" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="20" has_coreference="true">
      <content>Over the years, the city council and the mayor have been reluctant to even add additional officers to the LAPD.</content>
      <tokens>
        <token id="1" string="Over" lemma="over" stem="over" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="true" />
        <token id="3" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="true" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="city" lemma="city" stem="citi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="council" lemma="council" stem="council" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="mayor" lemma="mayor" stem="mayor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="reluctant" lemma="reluctant" stem="reluct" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="add" lemma="add" stem="add" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="additional" lemma="additional" stem="addit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="LAPD" lemma="lapd" stem="lapd" pos="NN" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN Over) (NP (DT the) (NNS years))) (, ,) (NP (NP (DT the) (NN city) (NN council)) (CC and) (NP (DT the) (NN mayor))) (VP (VBP have) (VP (VBN been) (ADJP (JJ reluctant) (S (VP (TO to) (VP (ADVP (RB even)) (VB add) (NP (JJ additional) (NNS officers)) (PP (TO to) (NP (DT the) (NN LAPD))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="even add additional officers to the LAPD" type="VP">
          <tokens>
            <token id="15" string="even" />
            <token id="16" string="add" />
            <token id="17" string="additional" />
            <token id="18" string="officers" />
            <token id="19" string="to" />
            <token id="20" string="the" />
            <token id="21" string="LAPD" />
          </tokens>
        </chunking>
        <chunking id="2" string="the mayor" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="mayor" />
          </tokens>
        </chunking>
        <chunking id="3" string="the years" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="years" />
          </tokens>
        </chunking>
        <chunking id="4" string="the city council" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="city" />
            <token id="7" string="council" />
          </tokens>
        </chunking>
        <chunking id="5" string="additional officers" type="NP">
          <tokens>
            <token id="17" string="additional" />
            <token id="18" string="officers" />
          </tokens>
        </chunking>
        <chunking id="6" string="the city council and the mayor" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="city" />
            <token id="7" string="council" />
            <token id="8" string="and" />
            <token id="9" string="the" />
            <token id="10" string="mayor" />
          </tokens>
        </chunking>
        <chunking id="7" string="the LAPD" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="LAPD" />
          </tokens>
        </chunking>
        <chunking id="8" string="to even add additional officers to the LAPD" type="VP">
          <tokens>
            <token id="14" string="to" />
            <token id="15" string="even" />
            <token id="16" string="add" />
            <token id="17" string="additional" />
            <token id="18" string="officers" />
            <token id="19" string="to" />
            <token id="20" string="the" />
            <token id="21" string="LAPD" />
          </tokens>
        </chunking>
        <chunking id="9" string="have been reluctant to even add additional officers to the LAPD" type="VP">
          <tokens>
            <token id="11" string="have" />
            <token id="12" string="been" />
            <token id="13" string="reluctant" />
            <token id="14" string="to" />
            <token id="15" string="even" />
            <token id="16" string="add" />
            <token id="17" string="additional" />
            <token id="18" string="officers" />
            <token id="19" string="to" />
            <token id="20" string="the" />
            <token id="21" string="LAPD" />
          </tokens>
        </chunking>
        <chunking id="10" string="reluctant to even add additional officers to the LAPD" type="ADJP">
          <tokens>
            <token id="13" string="reluctant" />
            <token id="14" string="to" />
            <token id="15" string="even" />
            <token id="16" string="add" />
            <token id="17" string="additional" />
            <token id="18" string="officers" />
            <token id="19" string="to" />
            <token id="20" string="the" />
            <token id="21" string="LAPD" />
          </tokens>
        </chunking>
        <chunking id="11" string="been reluctant to even add additional officers to the LAPD" type="VP">
          <tokens>
            <token id="12" string="been" />
            <token id="13" string="reluctant" />
            <token id="14" string="to" />
            <token id="15" string="even" />
            <token id="16" string="add" />
            <token id="17" string="additional" />
            <token id="18" string="officers" />
            <token id="19" string="to" />
            <token id="20" string="the" />
            <token id="21" string="LAPD" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">years</governor>
          <dependent id="1">Over</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">years</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">reluctant</governor>
          <dependent id="3">years</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">council</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">council</governor>
          <dependent id="6">city</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">reluctant</governor>
          <dependent id="7">council</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">council</governor>
          <dependent id="8">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">mayor</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">council</governor>
          <dependent id="10">mayor</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="13">reluctant</governor>
          <dependent id="11">have</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="13">reluctant</governor>
          <dependent id="12">been</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">reluctant</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">add</governor>
          <dependent id="14">to</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">add</governor>
          <dependent id="15">even</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="13">reluctant</governor>
          <dependent id="16">add</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">officers</governor>
          <dependent id="17">additional</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">add</governor>
          <dependent id="18">officers</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">LAPD</governor>
          <dependent id="19">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">LAPD</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">add</governor>
          <dependent id="21">LAPD</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="the years" type="DURATION" score="0.0">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="years" />
          </tokens>
        </entity>
        <entity id="2" string="LAPD" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="21" string="LAPD" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="21" has_coreference="false">
      <content>Of the six largest police departments in the U.S., the nation&amp;apost;s second largest city has the fewest officers per thousand residents.</content>
      <tokens>
        <token id="1" string="Of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="six" lemma="six" stem="six" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="4" string="largest" lemma="largest" stem="largest" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="departments" lemma="department" stem="depart" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="U.S." lemma="U.S." stem="u.s." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="nation" lemma="nation" stem="nation" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="second" lemma="second" stem="second" pos="RB" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="15" string="largest" lemma="largest" stem="largest" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="city" lemma="city" stem="citi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="fewest" lemma="fewest" stem="fewest" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="per" lemma="per" stem="per" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="thousand" lemma="thousand" stem="thousand" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="23" string="residents" lemma="resident" stem="resid" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN Of) (NP (NP (DT the) (CD six) (JJS largest) (NN police) (NNS departments)) (PP (IN in) (NP (DT the) (NNP U.S.))))) (, ,) (NP (NP (DT the) (NN nation) (POS 's)) (ADJP (RB second) (JJS largest)) (NN city)) (VP (VBZ has) (NP (NP (DT the) (JJS fewest) (NNS officers)) (PP (IN per) (NP (CD thousand) (NNS residents))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the six largest police departments in the U.S." type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="six" />
            <token id="4" string="largest" />
            <token id="5" string="police" />
            <token id="6" string="departments" />
            <token id="7" string="in" />
            <token id="8" string="the" />
            <token id="9" string="U.S." />
          </tokens>
        </chunking>
        <chunking id="2" string="second largest" type="ADJP">
          <tokens>
            <token id="14" string="second" />
            <token id="15" string="largest" />
          </tokens>
        </chunking>
        <chunking id="3" string="the U.S." type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="U.S." />
          </tokens>
        </chunking>
        <chunking id="4" string="the fewest officers per thousand residents" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="fewest" />
            <token id="20" string="officers" />
            <token id="21" string="per" />
            <token id="22" string="thousand" />
            <token id="23" string="residents" />
          </tokens>
        </chunking>
        <chunking id="5" string="has the fewest officers per thousand residents" type="VP">
          <tokens>
            <token id="17" string="has" />
            <token id="18" string="the" />
            <token id="19" string="fewest" />
            <token id="20" string="officers" />
            <token id="21" string="per" />
            <token id="22" string="thousand" />
            <token id="23" string="residents" />
          </tokens>
        </chunking>
        <chunking id="6" string="the fewest officers" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="fewest" />
            <token id="20" string="officers" />
          </tokens>
        </chunking>
        <chunking id="7" string="the six largest police departments" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="six" />
            <token id="4" string="largest" />
            <token id="5" string="police" />
            <token id="6" string="departments" />
          </tokens>
        </chunking>
        <chunking id="8" string="thousand residents" type="NP">
          <tokens>
            <token id="22" string="thousand" />
            <token id="23" string="residents" />
          </tokens>
        </chunking>
        <chunking id="9" string="the nation 's second largest city" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="nation" />
            <token id="13" string="'s" />
            <token id="14" string="second" />
            <token id="15" string="largest" />
            <token id="16" string="city" />
          </tokens>
        </chunking>
        <chunking id="10" string="the nation 's" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="nation" />
            <token id="13" string="'s" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="6">departments</governor>
          <dependent id="1">Of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">departments</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="6">departments</governor>
          <dependent id="3">six</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">departments</governor>
          <dependent id="4">largest</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">departments</governor>
          <dependent id="5">police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">has</governor>
          <dependent id="6">departments</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">U.S.</governor>
          <dependent id="7">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">U.S.</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">departments</governor>
          <dependent id="9">U.S.</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">nation</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="16">city</governor>
          <dependent id="12">nation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">nation</governor>
          <dependent id="13">'s</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">largest</governor>
          <dependent id="14">second</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">city</governor>
          <dependent id="15">largest</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">has</governor>
          <dependent id="16">city</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="17">has</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">officers</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">officers</governor>
          <dependent id="19">fewest</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">has</governor>
          <dependent id="20">officers</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">residents</governor>
          <dependent id="21">per</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="23">residents</governor>
          <dependent id="22">thousand</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">officers</governor>
          <dependent id="23">residents</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="six" type="NUMBER" score="0.0">
          <tokens>
            <token id="3" string="six" />
          </tokens>
        </entity>
        <entity id="2" string="U.S." type="LOCATION" score="0.0">
          <tokens>
            <token id="9" string="U.S." />
          </tokens>
        </entity>
        <entity id="3" string="second" type="ORDINAL" score="0.0">
          <tokens>
            <token id="14" string="second" />
          </tokens>
        </entity>
        <entity id="4" string="thousand" type="NUMBER" score="0.0">
          <tokens>
            <token id="22" string="thousand" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="22" has_coreference="false">
      <content>There are 8,450 officers here for more than 3.5 million people; Chicago, with a smaller population, has 12,000.</content>
      <tokens>
        <token id="1" string="There" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="8,450" lemma="8,450" stem="8,450" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="4" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="here" lemma="here" stem="here" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="more" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="3.5" lemma="3.5" stem="3.5" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="10" string="million" lemma="million" stem="million" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="11" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Chicago" lemma="Chicago" stem="chicago" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="smaller" lemma="smaller" stem="smaller" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="population" lemma="population" stem="popul" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="12,000" lemma="12,000" stem="12,000" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (EX There)) (VP (VBP are) (ADVP (NP (CD 8,450) (NNS officers)) (RB here)) (PP (IN for) (NP (QP (JJR more) (IN than) (CD 3.5) (CD million)) (NNS people))))) (: ;) (S (NP (NNP Chicago)) (, ,) (PP (IN with) (NP (DT a) (JJR smaller) (NN population))) (, ,) (VP (VBZ has) (NP (CD 12,000)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="more than 3.5 million people" type="NP">
          <tokens>
            <token id="7" string="more" />
            <token id="8" string="than" />
            <token id="9" string="3.5" />
            <token id="10" string="million" />
            <token id="11" string="people" />
          </tokens>
        </chunking>
        <chunking id="2" string="There" type="NP">
          <tokens>
            <token id="1" string="There" />
          </tokens>
        </chunking>
        <chunking id="3" string="Chicago" type="NP">
          <tokens>
            <token id="13" string="Chicago" />
          </tokens>
        </chunking>
        <chunking id="4" string="12,000" type="NP">
          <tokens>
            <token id="21" string="12,000" />
          </tokens>
        </chunking>
        <chunking id="5" string="are 8,450 officers here for more than 3.5 million people" type="VP">
          <tokens>
            <token id="2" string="are" />
            <token id="3" string="8,450" />
            <token id="4" string="officers" />
            <token id="5" string="here" />
            <token id="6" string="for" />
            <token id="7" string="more" />
            <token id="8" string="than" />
            <token id="9" string="3.5" />
            <token id="10" string="million" />
            <token id="11" string="people" />
          </tokens>
        </chunking>
        <chunking id="6" string="8,450 officers" type="NP">
          <tokens>
            <token id="3" string="8,450" />
            <token id="4" string="officers" />
          </tokens>
        </chunking>
        <chunking id="7" string="a smaller population" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="smaller" />
            <token id="18" string="population" />
          </tokens>
        </chunking>
        <chunking id="8" string="has 12,000" type="VP">
          <tokens>
            <token id="20" string="has" />
            <token id="21" string="12,000" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="expl">
          <governor id="2">are</governor>
          <dependent id="1">There</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">are</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="4">officers</governor>
          <dependent id="3">8,450</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="5">here</governor>
          <dependent id="4">officers</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="2">are</governor>
          <dependent id="5">here</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">people</governor>
          <dependent id="6">for</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">million</governor>
          <dependent id="7">more</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="7">more</governor>
          <dependent id="8">than</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">million</governor>
          <dependent id="9">3.5</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="11">people</governor>
          <dependent id="10">million</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">are</governor>
          <dependent id="11">people</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">has</governor>
          <dependent id="13">Chicago</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">population</governor>
          <dependent id="15">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">population</governor>
          <dependent id="16">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">population</governor>
          <dependent id="17">smaller</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">has</governor>
          <dependent id="18">population</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="2">are</governor>
          <dependent id="20">has</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">has</governor>
          <dependent id="21">12,000</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="8,450" type="NUMBER" score="0.0">
          <tokens>
            <token id="3" string="8,450" />
          </tokens>
        </entity>
        <entity id="2" string="Chicago" type="LOCATION" score="0.0">
          <tokens>
            <token id="13" string="Chicago" />
          </tokens>
        </entity>
        <entity id="3" string="12,000" type="NUMBER" score="0.0">
          <tokens>
            <token id="21" string="12,000" />
          </tokens>
        </entity>
        <entity id="4" string="3.5 million" type="NUMBER" score="0.0">
          <tokens>
            <token id="9" string="3.5" />
            <token id="10" string="million" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="23" has_coreference="true">
      <content>However, Michael Yamaki, one of the city&amp;apost;s five police commissioners, believes that given the systemic problems in the department that have come to light, &amp;quot;citizens now will be more willing to fund police issues.&amp;quot;</content>
      <tokens>
        <token id="1" string="However" lemma="however" stem="howev" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Michael" lemma="Michael" stem="michael" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="4" string="Yamaki" lemma="Yamaki" stem="yamaki" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="city" lemma="city" stem="citi" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="five" lemma="five" stem="five" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="12" string="police" lemma="police" stem="polic" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="commissioners" lemma="commissioner" stem="commission" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="believes" lemma="believe" stem="believ" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="given" lemma="give" stem="given" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="systemic" lemma="systemic" stem="system" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="problems" lemma="problem" stem="problem" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="department" lemma="department" stem="depart" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="24" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="26" string="come" lemma="come" stem="come" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="27" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="28" string="light" lemma="light" stem="light" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="29" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="citizens" lemma="citizen" stem="citizen" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="32" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="33" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="willing" lemma="willing" stem="will" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="fund" lemma="fund" stem="fund" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="issues" lemma="issue" stem="issu" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB However)) (, ,) (NP (NP (NNP Michael) (NNP Yamaki)) (, ,) (NP (NP (NP (CD one)) (PP (IN of) (NP (NP (DT the) (NN city) (POS 's)) (CD five) (NNS police)))) (NP (NNS commissioners))) (, ,)) (VP (VBZ believes) (SBAR (IN that) (S (PP (VBN given) (NP (NP (DT the) (JJ systemic) (NNS problems)) (PP (IN in) (NP (NP (DT the) (NN department)) (SBAR (WHNP (WDT that)) (S (VP (VBP have) (VP (VBN come) (PP (TO to) (NP (NN light))))))))))) (, ,) (`` ``) (NP (NNS citizens)) (VP (ADVP (RB now)) (MD will) (VP (VB be) (ADJP (RBR more) (JJ willing) (S (VP (TO to) (VP (VB fund) (NP (NN police) (NNS issues))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="commissioners" type="NP">
          <tokens>
            <token id="13" string="commissioners" />
          </tokens>
        </chunking>
        <chunking id="2" string="one" type="NP">
          <tokens>
            <token id="6" string="one" />
          </tokens>
        </chunking>
        <chunking id="3" string="that given the systemic problems in the department that have come to light , `` citizens now will be more willing to fund police issues" type="SBAR">
          <tokens>
            <token id="16" string="that" />
            <token id="17" string="given" />
            <token id="18" string="the" />
            <token id="19" string="systemic" />
            <token id="20" string="problems" />
            <token id="21" string="in" />
            <token id="22" string="the" />
            <token id="23" string="department" />
            <token id="24" string="that" />
            <token id="25" string="have" />
            <token id="26" string="come" />
            <token id="27" string="to" />
            <token id="28" string="light" />
            <token id="29" string="," />
            <token id="30" string="&quot;" />
            <token id="31" string="citizens" />
            <token id="32" string="now" />
            <token id="33" string="will" />
            <token id="34" string="be" />
            <token id="35" string="more" />
            <token id="36" string="willing" />
            <token id="37" string="to" />
            <token id="38" string="fund" />
            <token id="39" string="police" />
            <token id="40" string="issues" />
          </tokens>
        </chunking>
        <chunking id="4" string="the department that have come to light" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="department" />
            <token id="24" string="that" />
            <token id="25" string="have" />
            <token id="26" string="come" />
            <token id="27" string="to" />
            <token id="28" string="light" />
          </tokens>
        </chunking>
        <chunking id="5" string="one of the city 's five police" type="NP">
          <tokens>
            <token id="6" string="one" />
            <token id="7" string="of" />
            <token id="8" string="the" />
            <token id="9" string="city" />
            <token id="10" string="'s" />
            <token id="11" string="five" />
            <token id="12" string="police" />
          </tokens>
        </chunking>
        <chunking id="6" string="light" type="NP">
          <tokens>
            <token id="28" string="light" />
          </tokens>
        </chunking>
        <chunking id="7" string="come to light" type="VP">
          <tokens>
            <token id="26" string="come" />
            <token id="27" string="to" />
            <token id="28" string="light" />
          </tokens>
        </chunking>
        <chunking id="8" string="police issues" type="NP">
          <tokens>
            <token id="39" string="police" />
            <token id="40" string="issues" />
          </tokens>
        </chunking>
        <chunking id="9" string="the city 's" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="city" />
            <token id="10" string="'s" />
          </tokens>
        </chunking>
        <chunking id="10" string="citizens" type="NP">
          <tokens>
            <token id="31" string="citizens" />
          </tokens>
        </chunking>
        <chunking id="11" string="fund police issues" type="VP">
          <tokens>
            <token id="38" string="fund" />
            <token id="39" string="police" />
            <token id="40" string="issues" />
          </tokens>
        </chunking>
        <chunking id="12" string="Michael Yamaki" type="NP">
          <tokens>
            <token id="3" string="Michael" />
            <token id="4" string="Yamaki" />
          </tokens>
        </chunking>
        <chunking id="13" string="more willing to fund police issues" type="ADJP">
          <tokens>
            <token id="35" string="more" />
            <token id="36" string="willing" />
            <token id="37" string="to" />
            <token id="38" string="fund" />
            <token id="39" string="police" />
            <token id="40" string="issues" />
          </tokens>
        </chunking>
        <chunking id="14" string="to fund police issues" type="VP">
          <tokens>
            <token id="37" string="to" />
            <token id="38" string="fund" />
            <token id="39" string="police" />
            <token id="40" string="issues" />
          </tokens>
        </chunking>
        <chunking id="15" string="believes that given the systemic problems in the department that have come to light , `` citizens now will be more willing to fund police issues" type="VP">
          <tokens>
            <token id="15" string="believes" />
            <token id="16" string="that" />
            <token id="17" string="given" />
            <token id="18" string="the" />
            <token id="19" string="systemic" />
            <token id="20" string="problems" />
            <token id="21" string="in" />
            <token id="22" string="the" />
            <token id="23" string="department" />
            <token id="24" string="that" />
            <token id="25" string="have" />
            <token id="26" string="come" />
            <token id="27" string="to" />
            <token id="28" string="light" />
            <token id="29" string="," />
            <token id="30" string="&quot;" />
            <token id="31" string="citizens" />
            <token id="32" string="now" />
            <token id="33" string="will" />
            <token id="34" string="be" />
            <token id="35" string="more" />
            <token id="36" string="willing" />
            <token id="37" string="to" />
            <token id="38" string="fund" />
            <token id="39" string="police" />
            <token id="40" string="issues" />
          </tokens>
        </chunking>
        <chunking id="16" string="Michael Yamaki , one of the city 's five police commissioners ," type="NP">
          <tokens>
            <token id="3" string="Michael" />
            <token id="4" string="Yamaki" />
            <token id="5" string="," />
            <token id="6" string="one" />
            <token id="7" string="of" />
            <token id="8" string="the" />
            <token id="9" string="city" />
            <token id="10" string="'s" />
            <token id="11" string="five" />
            <token id="12" string="police" />
            <token id="13" string="commissioners" />
            <token id="14" string="," />
          </tokens>
        </chunking>
        <chunking id="17" string="the systemic problems" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="systemic" />
            <token id="20" string="problems" />
          </tokens>
        </chunking>
        <chunking id="18" string="one of the city 's five police commissioners" type="NP">
          <tokens>
            <token id="6" string="one" />
            <token id="7" string="of" />
            <token id="8" string="the" />
            <token id="9" string="city" />
            <token id="10" string="'s" />
            <token id="11" string="five" />
            <token id="12" string="police" />
            <token id="13" string="commissioners" />
          </tokens>
        </chunking>
        <chunking id="19" string="have come to light" type="VP">
          <tokens>
            <token id="25" string="have" />
            <token id="26" string="come" />
            <token id="27" string="to" />
            <token id="28" string="light" />
          </tokens>
        </chunking>
        <chunking id="20" string="now will be more willing to fund police issues" type="VP">
          <tokens>
            <token id="32" string="now" />
            <token id="33" string="will" />
            <token id="34" string="be" />
            <token id="35" string="more" />
            <token id="36" string="willing" />
            <token id="37" string="to" />
            <token id="38" string="fund" />
            <token id="39" string="police" />
            <token id="40" string="issues" />
          </tokens>
        </chunking>
        <chunking id="21" string="that have come to light" type="SBAR">
          <tokens>
            <token id="24" string="that" />
            <token id="25" string="have" />
            <token id="26" string="come" />
            <token id="27" string="to" />
            <token id="28" string="light" />
          </tokens>
        </chunking>
        <chunking id="22" string="the systemic problems in the department that have come to light" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="systemic" />
            <token id="20" string="problems" />
            <token id="21" string="in" />
            <token id="22" string="the" />
            <token id="23" string="department" />
            <token id="24" string="that" />
            <token id="25" string="have" />
            <token id="26" string="come" />
            <token id="27" string="to" />
            <token id="28" string="light" />
          </tokens>
        </chunking>
        <chunking id="23" string="the department" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="department" />
          </tokens>
        </chunking>
        <chunking id="24" string="be more willing to fund police issues" type="VP">
          <tokens>
            <token id="34" string="be" />
            <token id="35" string="more" />
            <token id="36" string="willing" />
            <token id="37" string="to" />
            <token id="38" string="fund" />
            <token id="39" string="police" />
            <token id="40" string="issues" />
          </tokens>
        </chunking>
        <chunking id="25" string="the city 's five police" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="city" />
            <token id="10" string="'s" />
            <token id="11" string="five" />
            <token id="12" string="police" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="15">believes</governor>
          <dependent id="1">However</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">Yamaki</governor>
          <dependent id="3">Michael</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">believes</governor>
          <dependent id="4">Yamaki</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="4">Yamaki</governor>
          <dependent id="6">one</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">police</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">city</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="12">police</governor>
          <dependent id="9">city</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">city</governor>
          <dependent id="10">'s</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="12">police</governor>
          <dependent id="11">five</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">one</governor>
          <dependent id="12">police</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="6">one</governor>
          <dependent id="13">commissioners</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">believes</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="36">willing</governor>
          <dependent id="16">that</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">problems</governor>
          <dependent id="17">given</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">problems</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">problems</governor>
          <dependent id="19">systemic</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="36">willing</governor>
          <dependent id="20">problems</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">department</governor>
          <dependent id="21">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">department</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">problems</governor>
          <dependent id="23">department</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">come</governor>
          <dependent id="24">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="26">come</governor>
          <dependent id="25">have</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="23">department</governor>
          <dependent id="26">come</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">light</governor>
          <dependent id="27">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">come</governor>
          <dependent id="28">light</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="36">willing</governor>
          <dependent id="31">citizens</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="36">willing</governor>
          <dependent id="32">now</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="36">willing</governor>
          <dependent id="33">will</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="36">willing</governor>
          <dependent id="34">be</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="36">willing</governor>
          <dependent id="35">more</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="15">believes</governor>
          <dependent id="36">willing</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="38">fund</governor>
          <dependent id="37">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="36">willing</governor>
          <dependent id="38">fund</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="40">issues</governor>
          <dependent id="39">police</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="38">fund</governor>
          <dependent id="40">issues</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Michael Yamaki" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Michael" />
            <token id="4" string="Yamaki" />
          </tokens>
        </entity>
        <entity id="2" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="6" string="one" />
          </tokens>
        </entity>
        <entity id="3" string="now" type="DATE" score="0.0">
          <tokens>
            <token id="32" string="now" />
          </tokens>
        </entity>
        <entity id="4" string="five" type="NUMBER" score="0.0">
          <tokens>
            <token id="11" string="five" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="24" has_coreference="true">
      <content>The commission&amp;apost;s recommendations will now be reviewed by the City Council, which will weigh whether to adopt them in whole or in part.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="commission" lemma="commission" stem="commiss" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="recommendations" lemma="recommendation" stem="recommend" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="7" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="reviewed" lemma="review" stem="review" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="City" lemma="City" stem="citi" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="12" string="Council" lemma="Council" stem="council" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="weigh" lemma="weigh" stem="weigh" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="whether" lemma="whether" stem="whether" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="adopt" lemma="adopt" stem="adopt" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="whole" lemma="whole" stem="whole" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="part" lemma="part" stem="part" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (NN commission) (POS 's)) (NNS recommendations)) (VP (MD will) (ADVP (RB now)) (VP (VB be) (VP (VBN reviewed) (PP (IN by) (NP (NP (DT the) (NNP City) (NNP Council)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (MD will) (VP (VB weigh) (SBAR (IN whether) (S (VP (TO to) (VP (VB adopt) (NP (PRP them)) (PP (PP (IN in) (NP (JJ whole))) (CC or) (PP (IN in) (NP (NN part))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="reviewed by the City Council , which will weigh whether to adopt them in whole or in part" type="VP">
          <tokens>
            <token id="8" string="reviewed" />
            <token id="9" string="by" />
            <token id="10" string="the" />
            <token id="11" string="City" />
            <token id="12" string="Council" />
            <token id="13" string="," />
            <token id="14" string="which" />
            <token id="15" string="will" />
            <token id="16" string="weigh" />
            <token id="17" string="whether" />
            <token id="18" string="to" />
            <token id="19" string="adopt" />
            <token id="20" string="them" />
            <token id="21" string="in" />
            <token id="22" string="whole" />
            <token id="23" string="or" />
            <token id="24" string="in" />
            <token id="25" string="part" />
          </tokens>
        </chunking>
        <chunking id="2" string="the City Council , which will weigh whether to adopt them in whole or in part" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="City" />
            <token id="12" string="Council" />
            <token id="13" string="," />
            <token id="14" string="which" />
            <token id="15" string="will" />
            <token id="16" string="weigh" />
            <token id="17" string="whether" />
            <token id="18" string="to" />
            <token id="19" string="adopt" />
            <token id="20" string="them" />
            <token id="21" string="in" />
            <token id="22" string="whole" />
            <token id="23" string="or" />
            <token id="24" string="in" />
            <token id="25" string="part" />
          </tokens>
        </chunking>
        <chunking id="3" string="weigh whether to adopt them in whole or in part" type="VP">
          <tokens>
            <token id="16" string="weigh" />
            <token id="17" string="whether" />
            <token id="18" string="to" />
            <token id="19" string="adopt" />
            <token id="20" string="them" />
            <token id="21" string="in" />
            <token id="22" string="whole" />
            <token id="23" string="or" />
            <token id="24" string="in" />
            <token id="25" string="part" />
          </tokens>
        </chunking>
        <chunking id="4" string="adopt them in whole or in part" type="VP">
          <tokens>
            <token id="19" string="adopt" />
            <token id="20" string="them" />
            <token id="21" string="in" />
            <token id="22" string="whole" />
            <token id="23" string="or" />
            <token id="24" string="in" />
            <token id="25" string="part" />
          </tokens>
        </chunking>
        <chunking id="5" string="part" type="NP">
          <tokens>
            <token id="25" string="part" />
          </tokens>
        </chunking>
        <chunking id="6" string="The commission 's recommendations" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="commission" />
            <token id="3" string="'s" />
            <token id="4" string="recommendations" />
          </tokens>
        </chunking>
        <chunking id="7" string="the City Council" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="City" />
            <token id="12" string="Council" />
          </tokens>
        </chunking>
        <chunking id="8" string="be reviewed by the City Council , which will weigh whether to adopt them in whole or in part" type="VP">
          <tokens>
            <token id="7" string="be" />
            <token id="8" string="reviewed" />
            <token id="9" string="by" />
            <token id="10" string="the" />
            <token id="11" string="City" />
            <token id="12" string="Council" />
            <token id="13" string="," />
            <token id="14" string="which" />
            <token id="15" string="will" />
            <token id="16" string="weigh" />
            <token id="17" string="whether" />
            <token id="18" string="to" />
            <token id="19" string="adopt" />
            <token id="20" string="them" />
            <token id="21" string="in" />
            <token id="22" string="whole" />
            <token id="23" string="or" />
            <token id="24" string="in" />
            <token id="25" string="part" />
          </tokens>
        </chunking>
        <chunking id="9" string="whole" type="NP">
          <tokens>
            <token id="22" string="whole" />
          </tokens>
        </chunking>
        <chunking id="10" string="will weigh whether to adopt them in whole or in part" type="VP">
          <tokens>
            <token id="15" string="will" />
            <token id="16" string="weigh" />
            <token id="17" string="whether" />
            <token id="18" string="to" />
            <token id="19" string="adopt" />
            <token id="20" string="them" />
            <token id="21" string="in" />
            <token id="22" string="whole" />
            <token id="23" string="or" />
            <token id="24" string="in" />
            <token id="25" string="part" />
          </tokens>
        </chunking>
        <chunking id="11" string="whether to adopt them in whole or in part" type="SBAR">
          <tokens>
            <token id="17" string="whether" />
            <token id="18" string="to" />
            <token id="19" string="adopt" />
            <token id="20" string="them" />
            <token id="21" string="in" />
            <token id="22" string="whole" />
            <token id="23" string="or" />
            <token id="24" string="in" />
            <token id="25" string="part" />
          </tokens>
        </chunking>
        <chunking id="12" string="them" type="NP">
          <tokens>
            <token id="20" string="them" />
          </tokens>
        </chunking>
        <chunking id="13" string="which will weigh whether to adopt them in whole or in part" type="SBAR">
          <tokens>
            <token id="14" string="which" />
            <token id="15" string="will" />
            <token id="16" string="weigh" />
            <token id="17" string="whether" />
            <token id="18" string="to" />
            <token id="19" string="adopt" />
            <token id="20" string="them" />
            <token id="21" string="in" />
            <token id="22" string="whole" />
            <token id="23" string="or" />
            <token id="24" string="in" />
            <token id="25" string="part" />
          </tokens>
        </chunking>
        <chunking id="14" string="to adopt them in whole or in part" type="VP">
          <tokens>
            <token id="18" string="to" />
            <token id="19" string="adopt" />
            <token id="20" string="them" />
            <token id="21" string="in" />
            <token id="22" string="whole" />
            <token id="23" string="or" />
            <token id="24" string="in" />
            <token id="25" string="part" />
          </tokens>
        </chunking>
        <chunking id="15" string="will now be reviewed by the City Council , which will weigh whether to adopt them in whole or in part" type="VP">
          <tokens>
            <token id="5" string="will" />
            <token id="6" string="now" />
            <token id="7" string="be" />
            <token id="8" string="reviewed" />
            <token id="9" string="by" />
            <token id="10" string="the" />
            <token id="11" string="City" />
            <token id="12" string="Council" />
            <token id="13" string="," />
            <token id="14" string="which" />
            <token id="15" string="will" />
            <token id="16" string="weigh" />
            <token id="17" string="whether" />
            <token id="18" string="to" />
            <token id="19" string="adopt" />
            <token id="20" string="them" />
            <token id="21" string="in" />
            <token id="22" string="whole" />
            <token id="23" string="or" />
            <token id="24" string="in" />
            <token id="25" string="part" />
          </tokens>
        </chunking>
        <chunking id="16" string="The commission 's" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="commission" />
            <token id="3" string="'s" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">commission</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">recommendations</governor>
          <dependent id="2">commission</dependent>
        </dependency>
        <dependency type="case">
          <governor id="2">commission</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="8">reviewed</governor>
          <dependent id="4">recommendations</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">reviewed</governor>
          <dependent id="5">will</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">reviewed</governor>
          <dependent id="6">now</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="8">reviewed</governor>
          <dependent id="7">be</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">reviewed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">Council</governor>
          <dependent id="9">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">Council</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Council</governor>
          <dependent id="11">City</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">reviewed</governor>
          <dependent id="12">Council</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">weigh</governor>
          <dependent id="14">which</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">weigh</governor>
          <dependent id="15">will</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="12">Council</governor>
          <dependent id="16">weigh</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">adopt</governor>
          <dependent id="17">whether</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">adopt</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="16">weigh</governor>
          <dependent id="19">adopt</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="19">adopt</governor>
          <dependent id="19">adopt</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">adopt</governor>
          <dependent id="20">them</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">whole</governor>
          <dependent id="21">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">adopt</governor>
          <dependent id="22">whole</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="19">adopt</governor>
          <dependent id="23">or</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">part</governor>
          <dependent id="24">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">adopt</governor>
          <dependent id="25">part</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="now" type="DATE" score="0.0">
          <tokens>
            <token id="6" string="now" />
          </tokens>
        </entity>
        <entity id="2" string="City Council" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="11" string="City" />
            <token id="12" string="Council" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="25" has_coreference="true">
      <content>Ultimately, voters must decide several issues, including whether to set term limits on the chief&amp;apost;s tenure.</content>
      <tokens>
        <token id="1" string="Ultimately" lemma="ultimately" stem="ultimat" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="voters" lemma="voter" stem="voter" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="must" lemma="must" stem="must" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="decide" lemma="decide" stem="decid" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="several" lemma="several" stem="sever" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="issues" lemma="issue" stem="issu" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="including" lemma="include" stem="includ" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="whether" lemma="whether" stem="whether" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="set" lemma="set" stem="set" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="term" lemma="term" stem="term" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="limits" lemma="limit" stem="limit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="chief" lemma="chief" stem="chief" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="18" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="tenure" lemma="tenure" stem="tenur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Ultimately)) (, ,) (NP (NNS voters)) (VP (MD must) (VP (VB decide) (NP (NP (JJ several) (NNS issues)) (, ,) (PP (VBG including) (SBAR (IN whether) (S (VP (TO to) (VP (VB set) (NP (NN term) (NNS limits)) (PP (IN on) (NP (NP (DT the) (NN chief) (POS 's)) (NN tenure))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="several issues , including whether to set term limits on the chief 's tenure" type="NP">
          <tokens>
            <token id="6" string="several" />
            <token id="7" string="issues" />
            <token id="8" string="," />
            <token id="9" string="including" />
            <token id="10" string="whether" />
            <token id="11" string="to" />
            <token id="12" string="set" />
            <token id="13" string="term" />
            <token id="14" string="limits" />
            <token id="15" string="on" />
            <token id="16" string="the" />
            <token id="17" string="chief" />
            <token id="18" string="'s" />
            <token id="19" string="tenure" />
          </tokens>
        </chunking>
        <chunking id="2" string="must decide several issues , including whether to set term limits on the chief 's tenure" type="VP">
          <tokens>
            <token id="4" string="must" />
            <token id="5" string="decide" />
            <token id="6" string="several" />
            <token id="7" string="issues" />
            <token id="8" string="," />
            <token id="9" string="including" />
            <token id="10" string="whether" />
            <token id="11" string="to" />
            <token id="12" string="set" />
            <token id="13" string="term" />
            <token id="14" string="limits" />
            <token id="15" string="on" />
            <token id="16" string="the" />
            <token id="17" string="chief" />
            <token id="18" string="'s" />
            <token id="19" string="tenure" />
          </tokens>
        </chunking>
        <chunking id="3" string="the chief 's" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="chief" />
            <token id="18" string="'s" />
          </tokens>
        </chunking>
        <chunking id="4" string="voters" type="NP">
          <tokens>
            <token id="3" string="voters" />
          </tokens>
        </chunking>
        <chunking id="5" string="to set term limits on the chief 's tenure" type="VP">
          <tokens>
            <token id="11" string="to" />
            <token id="12" string="set" />
            <token id="13" string="term" />
            <token id="14" string="limits" />
            <token id="15" string="on" />
            <token id="16" string="the" />
            <token id="17" string="chief" />
            <token id="18" string="'s" />
            <token id="19" string="tenure" />
          </tokens>
        </chunking>
        <chunking id="6" string="set term limits on the chief 's tenure" type="VP">
          <tokens>
            <token id="12" string="set" />
            <token id="13" string="term" />
            <token id="14" string="limits" />
            <token id="15" string="on" />
            <token id="16" string="the" />
            <token id="17" string="chief" />
            <token id="18" string="'s" />
            <token id="19" string="tenure" />
          </tokens>
        </chunking>
        <chunking id="7" string="decide several issues , including whether to set term limits on the chief 's tenure" type="VP">
          <tokens>
            <token id="5" string="decide" />
            <token id="6" string="several" />
            <token id="7" string="issues" />
            <token id="8" string="," />
            <token id="9" string="including" />
            <token id="10" string="whether" />
            <token id="11" string="to" />
            <token id="12" string="set" />
            <token id="13" string="term" />
            <token id="14" string="limits" />
            <token id="15" string="on" />
            <token id="16" string="the" />
            <token id="17" string="chief" />
            <token id="18" string="'s" />
            <token id="19" string="tenure" />
          </tokens>
        </chunking>
        <chunking id="8" string="term limits" type="NP">
          <tokens>
            <token id="13" string="term" />
            <token id="14" string="limits" />
          </tokens>
        </chunking>
        <chunking id="9" string="the chief 's tenure" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="chief" />
            <token id="18" string="'s" />
            <token id="19" string="tenure" />
          </tokens>
        </chunking>
        <chunking id="10" string="whether to set term limits on the chief 's tenure" type="SBAR">
          <tokens>
            <token id="10" string="whether" />
            <token id="11" string="to" />
            <token id="12" string="set" />
            <token id="13" string="term" />
            <token id="14" string="limits" />
            <token id="15" string="on" />
            <token id="16" string="the" />
            <token id="17" string="chief" />
            <token id="18" string="'s" />
            <token id="19" string="tenure" />
          </tokens>
        </chunking>
        <chunking id="11" string="several issues" type="NP">
          <tokens>
            <token id="6" string="several" />
            <token id="7" string="issues" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="5">decide</governor>
          <dependent id="1">Ultimately</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">decide</governor>
          <dependent id="3">voters</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">decide</governor>
          <dependent id="4">must</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">decide</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">issues</governor>
          <dependent id="6">several</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">decide</governor>
          <dependent id="7">issues</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">set</governor>
          <dependent id="9">including</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">set</governor>
          <dependent id="10">whether</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">set</governor>
          <dependent id="11">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="7">issues</governor>
          <dependent id="12">set</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">limits</governor>
          <dependent id="13">term</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">set</governor>
          <dependent id="14">limits</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">tenure</governor>
          <dependent id="15">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">chief</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="19">tenure</governor>
          <dependent id="17">chief</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">chief</governor>
          <dependent id="18">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">set</governor>
          <dependent id="19">tenure</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="26" has_coreference="false">
      <content>The commission intends to reconvene in six months to assess the progress.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="commission" lemma="commission" stem="commiss" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="intends" lemma="intend" stem="intend" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="reconvene" lemma="reconvene" stem="reconven" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="six" lemma="six" stem="six" pos="CD" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="8" string="months" lemma="month" stem="month" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="assess" lemma="assess" stem="assess" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="progress" lemma="progress" stem="progress" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN commission)) (VP (VBZ intends) (S (VP (TO to) (VP (VB reconvene) (PP (IN in) (NP (CD six) (NNS months))) (S (VP (TO to) (VP (VB assess) (NP (DT the) (NN progress))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="intends to reconvene in six months to assess the progress" type="VP">
          <tokens>
            <token id="3" string="intends" />
            <token id="4" string="to" />
            <token id="5" string="reconvene" />
            <token id="6" string="in" />
            <token id="7" string="six" />
            <token id="8" string="months" />
            <token id="9" string="to" />
            <token id="10" string="assess" />
            <token id="11" string="the" />
            <token id="12" string="progress" />
          </tokens>
        </chunking>
        <chunking id="2" string="six months" type="NP">
          <tokens>
            <token id="7" string="six" />
            <token id="8" string="months" />
          </tokens>
        </chunking>
        <chunking id="3" string="The commission" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="commission" />
          </tokens>
        </chunking>
        <chunking id="4" string="the progress" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="progress" />
          </tokens>
        </chunking>
        <chunking id="5" string="reconvene in six months to assess the progress" type="VP">
          <tokens>
            <token id="5" string="reconvene" />
            <token id="6" string="in" />
            <token id="7" string="six" />
            <token id="8" string="months" />
            <token id="9" string="to" />
            <token id="10" string="assess" />
            <token id="11" string="the" />
            <token id="12" string="progress" />
          </tokens>
        </chunking>
        <chunking id="6" string="to assess the progress" type="VP">
          <tokens>
            <token id="9" string="to" />
            <token id="10" string="assess" />
            <token id="11" string="the" />
            <token id="12" string="progress" />
          </tokens>
        </chunking>
        <chunking id="7" string="to reconvene in six months to assess the progress" type="VP">
          <tokens>
            <token id="4" string="to" />
            <token id="5" string="reconvene" />
            <token id="6" string="in" />
            <token id="7" string="six" />
            <token id="8" string="months" />
            <token id="9" string="to" />
            <token id="10" string="assess" />
            <token id="11" string="the" />
            <token id="12" string="progress" />
          </tokens>
        </chunking>
        <chunking id="8" string="assess the progress" type="VP">
          <tokens>
            <token id="10" string="assess" />
            <token id="11" string="the" />
            <token id="12" string="progress" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">commission</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">intends</governor>
          <dependent id="2">commission</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">intends</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">reconvene</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">intends</governor>
          <dependent id="5">reconvene</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">months</governor>
          <dependent id="6">in</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="8">months</governor>
          <dependent id="7">six</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">reconvene</governor>
          <dependent id="8">months</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">assess</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">reconvene</governor>
          <dependent id="10">assess</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">progress</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">assess</governor>
          <dependent id="12">progress</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="six months" type="DURATION" score="0.0">
          <tokens>
            <token id="7" string="six" />
            <token id="8" string="months" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="27" has_coreference="true">
      <content>Even before the commission&amp;apost;s report was issued, community groups that monitor the LAPD noted a decline in brutality complaints.</content>
      <tokens>
        <token id="1" string="Even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="before" lemma="before" stem="befor" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="4" string="commission" lemma="commission" stem="commiss" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="5" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="6" string="report" lemma="report" stem="report" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="issued" lemma="issue" stem="issu" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="community" lemma="community" stem="commun" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="groups" lemma="group" stem="group" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="monitor" lemma="monitor" stem="monitor" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="LAPD" lemma="lapd" stem="lapd" pos="NN" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="16" string="noted" lemma="note" stem="note" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="decline" lemma="decline" stem="declin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="brutality" lemma="brutality" stem="brutal" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="complaints" lemma="complaint" stem="complaint" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (RB Even) (IN before) (S (NP (NP (DT the) (NN commission) (POS 's)) (NN report)) (VP (VBD was) (VP (VBN issued))))) (, ,) (NP (NP (NN community) (NNS groups)) (SBAR (WHNP (WDT that)) (S (VP (VBP monitor) (NP (DT the) (NN LAPD)))))) (VP (VBD noted) (NP (DT a) (NN decline)) (PP (IN in) (NP (NN brutality) (NNS complaints)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="brutality complaints" type="NP">
          <tokens>
            <token id="20" string="brutality" />
            <token id="21" string="complaints" />
          </tokens>
        </chunking>
        <chunking id="2" string="that monitor the LAPD" type="SBAR">
          <tokens>
            <token id="12" string="that" />
            <token id="13" string="monitor" />
            <token id="14" string="the" />
            <token id="15" string="LAPD" />
          </tokens>
        </chunking>
        <chunking id="3" string="community groups" type="NP">
          <tokens>
            <token id="10" string="community" />
            <token id="11" string="groups" />
          </tokens>
        </chunking>
        <chunking id="4" string="the LAPD" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="LAPD" />
          </tokens>
        </chunking>
        <chunking id="5" string="Even before the commission 's report was issued" type="SBAR">
          <tokens>
            <token id="1" string="Even" />
            <token id="2" string="before" />
            <token id="3" string="the" />
            <token id="4" string="commission" />
            <token id="5" string="'s" />
            <token id="6" string="report" />
            <token id="7" string="was" />
            <token id="8" string="issued" />
          </tokens>
        </chunking>
        <chunking id="6" string="the commission 's report" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="commission" />
            <token id="5" string="'s" />
            <token id="6" string="report" />
          </tokens>
        </chunking>
        <chunking id="7" string="community groups that monitor the LAPD" type="NP">
          <tokens>
            <token id="10" string="community" />
            <token id="11" string="groups" />
            <token id="12" string="that" />
            <token id="13" string="monitor" />
            <token id="14" string="the" />
            <token id="15" string="LAPD" />
          </tokens>
        </chunking>
        <chunking id="8" string="the commission 's" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="commission" />
            <token id="5" string="'s" />
          </tokens>
        </chunking>
        <chunking id="9" string="noted a decline in brutality complaints" type="VP">
          <tokens>
            <token id="16" string="noted" />
            <token id="17" string="a" />
            <token id="18" string="decline" />
            <token id="19" string="in" />
            <token id="20" string="brutality" />
            <token id="21" string="complaints" />
          </tokens>
        </chunking>
        <chunking id="10" string="a decline" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="decline" />
          </tokens>
        </chunking>
        <chunking id="11" string="was issued" type="VP">
          <tokens>
            <token id="7" string="was" />
            <token id="8" string="issued" />
          </tokens>
        </chunking>
        <chunking id="12" string="issued" type="VP">
          <tokens>
            <token id="8" string="issued" />
          </tokens>
        </chunking>
        <chunking id="13" string="monitor the LAPD" type="VP">
          <tokens>
            <token id="13" string="monitor" />
            <token id="14" string="the" />
            <token id="15" string="LAPD" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="8">issued</governor>
          <dependent id="1">Even</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">issued</governor>
          <dependent id="2">before</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">commission</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="6">report</governor>
          <dependent id="4">commission</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">commission</governor>
          <dependent id="5">'s</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="8">issued</governor>
          <dependent id="6">report</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="8">issued</governor>
          <dependent id="7">was</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="16">noted</governor>
          <dependent id="8">issued</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">groups</governor>
          <dependent id="10">community</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">noted</governor>
          <dependent id="11">groups</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">monitor</governor>
          <dependent id="12">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="11">groups</governor>
          <dependent id="13">monitor</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">LAPD</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">monitor</governor>
          <dependent id="15">LAPD</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="16">noted</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">decline</governor>
          <dependent id="17">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">noted</governor>
          <dependent id="18">decline</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">complaints</governor>
          <dependent id="19">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">complaints</governor>
          <dependent id="20">brutality</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">noted</governor>
          <dependent id="21">complaints</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="LAPD" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="15" string="LAPD" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="28" has_coreference="true">
      <content>The harsh tone of the report was welcome vindication for community leaders who have claimed that police brutality is widespread.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="harsh" lemma="harsh" stem="harsh" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="tone" lemma="tone" stem="tone" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="report" lemma="report" stem="report" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="welcome" lemma="welcome" stem="welcom" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="vindication" lemma="vindication" stem="vindic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="community" lemma="community" stem="commun" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="leaders" lemma="leader" stem="leader" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="claimed" lemma="claim" stem="claim" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="brutality" lemma="brutality" stem="brutal" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="widespread" lemma="widespread" stem="widespread" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (JJ harsh) (NN tone)) (PP (IN of) (NP (DT the) (NN report)))) (VP (VBD was) (NP (NP (JJ welcome) (NN vindication)) (PP (IN for) (NP (NN community) (NNS leaders))) (SBAR (WHNP (WP who)) (S (VP (VBP have) (VP (VBN claimed) (SBAR (IN that) (S (NP (NN police) (NN brutality)) (VP (VBZ is) (ADJP (JJ widespread))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="welcome vindication for community leaders who have claimed that police brutality is widespread" type="NP">
          <tokens>
            <token id="8" string="welcome" />
            <token id="9" string="vindication" />
            <token id="10" string="for" />
            <token id="11" string="community" />
            <token id="12" string="leaders" />
            <token id="13" string="who" />
            <token id="14" string="have" />
            <token id="15" string="claimed" />
            <token id="16" string="that" />
            <token id="17" string="police" />
            <token id="18" string="brutality" />
            <token id="19" string="is" />
            <token id="20" string="widespread" />
          </tokens>
        </chunking>
        <chunking id="2" string="have claimed that police brutality is widespread" type="VP">
          <tokens>
            <token id="14" string="have" />
            <token id="15" string="claimed" />
            <token id="16" string="that" />
            <token id="17" string="police" />
            <token id="18" string="brutality" />
            <token id="19" string="is" />
            <token id="20" string="widespread" />
          </tokens>
        </chunking>
        <chunking id="3" string="is widespread" type="VP">
          <tokens>
            <token id="19" string="is" />
            <token id="20" string="widespread" />
          </tokens>
        </chunking>
        <chunking id="4" string="was welcome vindication for community leaders who have claimed that police brutality is widespread" type="VP">
          <tokens>
            <token id="7" string="was" />
            <token id="8" string="welcome" />
            <token id="9" string="vindication" />
            <token id="10" string="for" />
            <token id="11" string="community" />
            <token id="12" string="leaders" />
            <token id="13" string="who" />
            <token id="14" string="have" />
            <token id="15" string="claimed" />
            <token id="16" string="that" />
            <token id="17" string="police" />
            <token id="18" string="brutality" />
            <token id="19" string="is" />
            <token id="20" string="widespread" />
          </tokens>
        </chunking>
        <chunking id="5" string="The harsh tone" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="harsh" />
            <token id="3" string="tone" />
          </tokens>
        </chunking>
        <chunking id="6" string="community leaders" type="NP">
          <tokens>
            <token id="11" string="community" />
            <token id="12" string="leaders" />
          </tokens>
        </chunking>
        <chunking id="7" string="who have claimed that police brutality is widespread" type="SBAR">
          <tokens>
            <token id="13" string="who" />
            <token id="14" string="have" />
            <token id="15" string="claimed" />
            <token id="16" string="that" />
            <token id="17" string="police" />
            <token id="18" string="brutality" />
            <token id="19" string="is" />
            <token id="20" string="widespread" />
          </tokens>
        </chunking>
        <chunking id="8" string="that police brutality is widespread" type="SBAR">
          <tokens>
            <token id="16" string="that" />
            <token id="17" string="police" />
            <token id="18" string="brutality" />
            <token id="19" string="is" />
            <token id="20" string="widespread" />
          </tokens>
        </chunking>
        <chunking id="9" string="welcome vindication" type="NP">
          <tokens>
            <token id="8" string="welcome" />
            <token id="9" string="vindication" />
          </tokens>
        </chunking>
        <chunking id="10" string="The harsh tone of the report" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="harsh" />
            <token id="3" string="tone" />
            <token id="4" string="of" />
            <token id="5" string="the" />
            <token id="6" string="report" />
          </tokens>
        </chunking>
        <chunking id="11" string="widespread" type="ADJP">
          <tokens>
            <token id="20" string="widespread" />
          </tokens>
        </chunking>
        <chunking id="12" string="police brutality" type="NP">
          <tokens>
            <token id="17" string="police" />
            <token id="18" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="13" string="the report" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="report" />
          </tokens>
        </chunking>
        <chunking id="14" string="claimed that police brutality is widespread" type="VP">
          <tokens>
            <token id="15" string="claimed" />
            <token id="16" string="that" />
            <token id="17" string="police" />
            <token id="18" string="brutality" />
            <token id="19" string="is" />
            <token id="20" string="widespread" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">tone</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">tone</governor>
          <dependent id="2">harsh</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">vindication</governor>
          <dependent id="3">tone</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">report</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">report</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">tone</governor>
          <dependent id="6">report</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="9">vindication</governor>
          <dependent id="7">was</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">vindication</governor>
          <dependent id="8">welcome</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">vindication</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">leaders</governor>
          <dependent id="10">for</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">leaders</governor>
          <dependent id="11">community</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">vindication</governor>
          <dependent id="12">leaders</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">claimed</governor>
          <dependent id="13">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="15">claimed</governor>
          <dependent id="14">have</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="9">vindication</governor>
          <dependent id="15">claimed</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="20">widespread</governor>
          <dependent id="16">that</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">brutality</governor>
          <dependent id="17">police</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">widespread</governor>
          <dependent id="18">brutality</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="20">widespread</governor>
          <dependent id="19">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="15">claimed</governor>
          <dependent id="20">widespread</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="29" has_coreference="false">
      <content>The report &amp;quot;proves once and for all that the Rodney King incident was not an aberration,&amp;quot; said Ramona Ripston, executive director of the American Civil Liberties Union of Southern California.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="report" lemma="report" stem="report" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="proves" lemma="prove" stem="prove" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="once" lemma="once" stem="onc" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="6" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="Rodney" lemma="Rodney" stem="rodnei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="12" string="King" lemma="King" stem="king" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="13" string="incident" lemma="incident" stem="incid" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="aberration" lemma="aberration" stem="aberr" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="Ramona" lemma="Ramona" stem="ramona" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="22" string="Ripston" lemma="Ripston" stem="ripston" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="executive" lemma="executive" stem="execut" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="director" lemma="director" stem="director" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="28" string="American" lemma="American" stem="american" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="29" string="Civil" lemma="Civil" stem="civil" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="30" string="Liberties" lemma="Liberties" stem="liberti" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="31" string="Union" lemma="Union" stem="union" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="32" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="33" string="Southern" lemma="Southern" stem="southern" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="34" string="California" lemma="California" stem="california" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="35" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (S (NP (DT The) (NN report)) (`` ``) (VP (VBZ proves) (ADVP (ADVP (RB once)) (CC and) (PP (IN for) (NP (DT all)))) (SBAR (IN that) (S (NP (DT the) (NNP Rodney) (NNP King) (NN incident)) (VP (VBD was) (RB not) (NP (DT an) (NN aberration))))))) (, ,) ('' '') (VP (VBD said)) (NP (NP (NNP Ramona) (NNP Ripston)) (, ,) (NP (NP (JJ executive) (NN director)) (PP (IN of) (NP (DT the) (NNP American) (NNP Civil) (NNP Liberties) (NNP Union))) (PP (IN of) (NP (NNP Southern) (NNP California))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="executive director of the American Civil Liberties Union of Southern California" type="NP">
          <tokens>
            <token id="24" string="executive" />
            <token id="25" string="director" />
            <token id="26" string="of" />
            <token id="27" string="the" />
            <token id="28" string="American" />
            <token id="29" string="Civil" />
            <token id="30" string="Liberties" />
            <token id="31" string="Union" />
            <token id="32" string="of" />
            <token id="33" string="Southern" />
            <token id="34" string="California" />
          </tokens>
        </chunking>
        <chunking id="2" string="all" type="NP">
          <tokens>
            <token id="8" string="all" />
          </tokens>
        </chunking>
        <chunking id="3" string="was not an aberration" type="VP">
          <tokens>
            <token id="14" string="was" />
            <token id="15" string="not" />
            <token id="16" string="an" />
            <token id="17" string="aberration" />
          </tokens>
        </chunking>
        <chunking id="4" string="an aberration" type="NP">
          <tokens>
            <token id="16" string="an" />
            <token id="17" string="aberration" />
          </tokens>
        </chunking>
        <chunking id="5" string="executive director" type="NP">
          <tokens>
            <token id="24" string="executive" />
            <token id="25" string="director" />
          </tokens>
        </chunking>
        <chunking id="6" string="The report" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="report" />
          </tokens>
        </chunking>
        <chunking id="7" string="that the Rodney King incident was not an aberration" type="SBAR">
          <tokens>
            <token id="9" string="that" />
            <token id="10" string="the" />
            <token id="11" string="Rodney" />
            <token id="12" string="King" />
            <token id="13" string="incident" />
            <token id="14" string="was" />
            <token id="15" string="not" />
            <token id="16" string="an" />
            <token id="17" string="aberration" />
          </tokens>
        </chunking>
        <chunking id="8" string="the Rodney King incident" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="Rodney" />
            <token id="12" string="King" />
            <token id="13" string="incident" />
          </tokens>
        </chunking>
        <chunking id="9" string="proves once and for all that the Rodney King incident was not an aberration" type="VP">
          <tokens>
            <token id="4" string="proves" />
            <token id="5" string="once" />
            <token id="6" string="and" />
            <token id="7" string="for" />
            <token id="8" string="all" />
            <token id="9" string="that" />
            <token id="10" string="the" />
            <token id="11" string="Rodney" />
            <token id="12" string="King" />
            <token id="13" string="incident" />
            <token id="14" string="was" />
            <token id="15" string="not" />
            <token id="16" string="an" />
            <token id="17" string="aberration" />
          </tokens>
        </chunking>
        <chunking id="10" string="Southern California" type="NP">
          <tokens>
            <token id="33" string="Southern" />
            <token id="34" string="California" />
          </tokens>
        </chunking>
        <chunking id="11" string="Ramona Ripston" type="NP">
          <tokens>
            <token id="21" string="Ramona" />
            <token id="22" string="Ripston" />
          </tokens>
        </chunking>
        <chunking id="12" string="the American Civil Liberties Union" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="American" />
            <token id="29" string="Civil" />
            <token id="30" string="Liberties" />
            <token id="31" string="Union" />
          </tokens>
        </chunking>
        <chunking id="13" string="said" type="VP">
          <tokens>
            <token id="20" string="said" />
          </tokens>
        </chunking>
        <chunking id="14" string="Ramona Ripston , executive director of the American Civil Liberties Union of Southern California" type="NP">
          <tokens>
            <token id="21" string="Ramona" />
            <token id="22" string="Ripston" />
            <token id="23" string="," />
            <token id="24" string="executive" />
            <token id="25" string="director" />
            <token id="26" string="of" />
            <token id="27" string="the" />
            <token id="28" string="American" />
            <token id="29" string="Civil" />
            <token id="30" string="Liberties" />
            <token id="31" string="Union" />
            <token id="32" string="of" />
            <token id="33" string="Southern" />
            <token id="34" string="California" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">report</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">proves</governor>
          <dependent id="2">report</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="20">said</governor>
          <dependent id="4">proves</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">and</governor>
          <dependent id="5">once</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">proves</governor>
          <dependent id="6">and</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">all</governor>
          <dependent id="7">for</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">and</governor>
          <dependent id="8">all</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">aberration</governor>
          <dependent id="9">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">incident</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">incident</governor>
          <dependent id="11">Rodney</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">incident</governor>
          <dependent id="12">King</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">aberration</governor>
          <dependent id="13">incident</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="17">aberration</governor>
          <dependent id="14">was</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="17">aberration</governor>
          <dependent id="15">not</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">aberration</governor>
          <dependent id="16">an</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">proves</governor>
          <dependent id="17">aberration</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="20">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">Ripston</governor>
          <dependent id="21">Ramona</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">said</governor>
          <dependent id="22">Ripston</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">director</governor>
          <dependent id="24">executive</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="22">Ripston</governor>
          <dependent id="25">director</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">Union</governor>
          <dependent id="26">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">Union</governor>
          <dependent id="27">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">Union</governor>
          <dependent id="28">American</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">Union</governor>
          <dependent id="29">Civil</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">Union</governor>
          <dependent id="30">Liberties</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">director</governor>
          <dependent id="31">Union</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">California</governor>
          <dependent id="32">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="34">California</governor>
          <dependent id="33">Southern</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">director</governor>
          <dependent id="34">California</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="American Civil Liberties Union of Southern California" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="28" string="American" />
            <token id="29" string="Civil" />
            <token id="30" string="Liberties" />
            <token id="31" string="Union" />
            <token id="32" string="of" />
            <token id="33" string="Southern" />
            <token id="34" string="California" />
          </tokens>
        </entity>
        <entity id="2" string="once" type="DATE" score="0.0">
          <tokens>
            <token id="5" string="once" />
          </tokens>
        </entity>
        <entity id="3" string="Rodney King" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Rodney" />
            <token id="12" string="King" />
          </tokens>
        </entity>
        <entity id="4" string="Ramona Ripston" type="PERSON" score="0.0">
          <tokens>
            <token id="21" string="Ramona" />
            <token id="22" string="Ripston" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="30" has_coreference="true">
      <content>&amp;quot;Any fair reading of the report constitutes an `F&amp;apost; for {Chief Gates&amp;apost;s} job performance.&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Any" lemma="any" stem="any" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="fair" lemma="fair" stem="fair" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="reading" lemma="reading" stem="read" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="report" lemma="report" stem="report" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="constitutes" lemma="constitute" stem="constitut" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="`" lemma="`" stem="`" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="F" lemma="f" stem="f" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="{" lemma="-lcb-" stem="{" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="Chief" lemma="Chief" stem="chief" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="false" is_refers="true" />
        <token id="16" string="Gates" lemma="Gates" stem="gate" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="}" lemma="-rcb-" stem="}" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="job" lemma="job" stem="job" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="performance" lemma="performance" stem="perform" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (NP (DT Any) (JJ fair) (NN reading)) (PP (IN of) (NP (DT the) (NN report)))) (VP (VBZ constitutes) (NP (NP (NP (DT an) (`` `) (NN F) ('' ')) (PP (IN for) (NP (PRN (-LRB- -LCB-) (NP (NNP Chief) (NNP Gates) (POS 's)) (-RRB- -RCB-)) (NN job)))) (NN performance))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="an ` F ' for -LCB- Chief Gates 's -RCB- job performance" type="NP">
          <tokens>
            <token id="9" string="an" />
            <token id="10" string="`" />
            <token id="11" string="F" />
            <token id="12" string="'" />
            <token id="13" string="for" />
            <token id="14" string="{" />
            <token id="15" string="Chief" />
            <token id="16" string="Gates" />
            <token id="17" string="'s" />
            <token id="18" string="}" />
            <token id="19" string="job" />
            <token id="20" string="performance" />
          </tokens>
        </chunking>
        <chunking id="2" string="-LCB- Chief Gates 's -RCB- job" type="NP">
          <tokens>
            <token id="14" string="{" />
            <token id="15" string="Chief" />
            <token id="16" string="Gates" />
            <token id="17" string="'s" />
            <token id="18" string="}" />
            <token id="19" string="job" />
          </tokens>
        </chunking>
        <chunking id="3" string="Any fair reading of the report" type="NP">
          <tokens>
            <token id="2" string="Any" />
            <token id="3" string="fair" />
            <token id="4" string="reading" />
            <token id="5" string="of" />
            <token id="6" string="the" />
            <token id="7" string="report" />
          </tokens>
        </chunking>
        <chunking id="4" string="Any fair reading" type="NP">
          <tokens>
            <token id="2" string="Any" />
            <token id="3" string="fair" />
            <token id="4" string="reading" />
          </tokens>
        </chunking>
        <chunking id="5" string="Chief Gates 's" type="NP">
          <tokens>
            <token id="15" string="Chief" />
            <token id="16" string="Gates" />
            <token id="17" string="'s" />
          </tokens>
        </chunking>
        <chunking id="6" string="an ` F ' for -LCB- Chief Gates 's -RCB- job" type="NP">
          <tokens>
            <token id="9" string="an" />
            <token id="10" string="`" />
            <token id="11" string="F" />
            <token id="12" string="'" />
            <token id="13" string="for" />
            <token id="14" string="{" />
            <token id="15" string="Chief" />
            <token id="16" string="Gates" />
            <token id="17" string="'s" />
            <token id="18" string="}" />
            <token id="19" string="job" />
          </tokens>
        </chunking>
        <chunking id="7" string="an ` F '" type="NP">
          <tokens>
            <token id="9" string="an" />
            <token id="10" string="`" />
            <token id="11" string="F" />
            <token id="12" string="'" />
          </tokens>
        </chunking>
        <chunking id="8" string="the report" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="report" />
          </tokens>
        </chunking>
        <chunking id="9" string="constitutes an ` F ' for -LCB- Chief Gates 's -RCB- job performance" type="VP">
          <tokens>
            <token id="8" string="constitutes" />
            <token id="9" string="an" />
            <token id="10" string="`" />
            <token id="11" string="F" />
            <token id="12" string="'" />
            <token id="13" string="for" />
            <token id="14" string="{" />
            <token id="15" string="Chief" />
            <token id="16" string="Gates" />
            <token id="17" string="'s" />
            <token id="18" string="}" />
            <token id="19" string="job" />
            <token id="20" string="performance" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="4">reading</governor>
          <dependent id="2">Any</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">reading</governor>
          <dependent id="3">fair</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">constitutes</governor>
          <dependent id="4">reading</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">report</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">report</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">reading</governor>
          <dependent id="7">report</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">constitutes</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">F</governor>
          <dependent id="9">an</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">performance</governor>
          <dependent id="11">F</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">job</governor>
          <dependent id="13">for</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Gates</governor>
          <dependent id="15">Chief</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="19">job</governor>
          <dependent id="16">Gates</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">Gates</governor>
          <dependent id="17">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">F</governor>
          <dependent id="19">job</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">constitutes</governor>
          <dependent id="20">performance</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Chief" type="TITLE" score="0.0">
          <tokens>
            <token id="15" string="Chief" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="31" has_coreference="true">
      <content>The report shows a particularly damning pattern of acceptance, and even encouragement, of officers who violate the rules governing excessive force.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="report" lemma="report" stem="report" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="shows" lemma="show" stem="show" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="particularly" lemma="particularly" stem="particularli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="damning" lemma="damning" stem="damn" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="pattern" lemma="pattern" stem="pattern" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="acceptance" lemma="acceptance" stem="accept" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="encouragement" lemma="encouragement" stem="encourag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="violate" lemma="violate" stem="violat" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="rules" lemma="rule" stem="rule" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="21" string="governing" lemma="govern" stem="govern" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="22" string="excessive" lemma="excessive" stem="excess" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="23" string="force" lemma="force" stem="forc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN report)) (VP (VBZ shows) (NP (NP (NP (DT a) (ADJP (RB particularly) (JJ damning)) (NN pattern)) (PP (IN of) (NP (NN acceptance)))) (, ,) (CC and) (RB even) (NP (NN encouragement)) (, ,)) (PP (IN of) (NP (NP (NNS officers)) (SBAR (WHNP (WP who)) (S (VP (VBP violate) (S (NP (DT the) (NNS rules)) (VP (VBG governing) (NP (JJ excessive) (NN force)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="particularly damning" type="ADJP">
          <tokens>
            <token id="5" string="particularly" />
            <token id="6" string="damning" />
          </tokens>
        </chunking>
        <chunking id="2" string="who violate the rules governing excessive force" type="SBAR">
          <tokens>
            <token id="17" string="who" />
            <token id="18" string="violate" />
            <token id="19" string="the" />
            <token id="20" string="rules" />
            <token id="21" string="governing" />
            <token id="22" string="excessive" />
            <token id="23" string="force" />
          </tokens>
        </chunking>
        <chunking id="3" string="a particularly damning pattern of acceptance" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="particularly" />
            <token id="6" string="damning" />
            <token id="7" string="pattern" />
            <token id="8" string="of" />
            <token id="9" string="acceptance" />
          </tokens>
        </chunking>
        <chunking id="4" string="violate the rules governing excessive force" type="VP">
          <tokens>
            <token id="18" string="violate" />
            <token id="19" string="the" />
            <token id="20" string="rules" />
            <token id="21" string="governing" />
            <token id="22" string="excessive" />
            <token id="23" string="force" />
          </tokens>
        </chunking>
        <chunking id="5" string="officers who violate the rules governing excessive force" type="NP">
          <tokens>
            <token id="16" string="officers" />
            <token id="17" string="who" />
            <token id="18" string="violate" />
            <token id="19" string="the" />
            <token id="20" string="rules" />
            <token id="21" string="governing" />
            <token id="22" string="excessive" />
            <token id="23" string="force" />
          </tokens>
        </chunking>
        <chunking id="6" string="excessive force" type="NP">
          <tokens>
            <token id="22" string="excessive" />
            <token id="23" string="force" />
          </tokens>
        </chunking>
        <chunking id="7" string="a particularly damning pattern" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="particularly" />
            <token id="6" string="damning" />
            <token id="7" string="pattern" />
          </tokens>
        </chunking>
        <chunking id="8" string="the rules" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="rules" />
          </tokens>
        </chunking>
        <chunking id="9" string="shows a particularly damning pattern of acceptance , and even encouragement , of officers who violate the rules governing excessive force" type="VP">
          <tokens>
            <token id="3" string="shows" />
            <token id="4" string="a" />
            <token id="5" string="particularly" />
            <token id="6" string="damning" />
            <token id="7" string="pattern" />
            <token id="8" string="of" />
            <token id="9" string="acceptance" />
            <token id="10" string="," />
            <token id="11" string="and" />
            <token id="12" string="even" />
            <token id="13" string="encouragement" />
            <token id="14" string="," />
            <token id="15" string="of" />
            <token id="16" string="officers" />
            <token id="17" string="who" />
            <token id="18" string="violate" />
            <token id="19" string="the" />
            <token id="20" string="rules" />
            <token id="21" string="governing" />
            <token id="22" string="excessive" />
            <token id="23" string="force" />
          </tokens>
        </chunking>
        <chunking id="10" string="The report" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="report" />
          </tokens>
        </chunking>
        <chunking id="11" string="a particularly damning pattern of acceptance , and even encouragement ," type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="particularly" />
            <token id="6" string="damning" />
            <token id="7" string="pattern" />
            <token id="8" string="of" />
            <token id="9" string="acceptance" />
            <token id="10" string="," />
            <token id="11" string="and" />
            <token id="12" string="even" />
            <token id="13" string="encouragement" />
            <token id="14" string="," />
          </tokens>
        </chunking>
        <chunking id="12" string="encouragement" type="NP">
          <tokens>
            <token id="13" string="encouragement" />
          </tokens>
        </chunking>
        <chunking id="13" string="acceptance" type="NP">
          <tokens>
            <token id="9" string="acceptance" />
          </tokens>
        </chunking>
        <chunking id="14" string="governing excessive force" type="VP">
          <tokens>
            <token id="21" string="governing" />
            <token id="22" string="excessive" />
            <token id="23" string="force" />
          </tokens>
        </chunking>
        <chunking id="15" string="officers" type="NP">
          <tokens>
            <token id="16" string="officers" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">report</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">shows</governor>
          <dependent id="2">report</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">shows</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">pattern</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">damning</governor>
          <dependent id="5">particularly</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">pattern</governor>
          <dependent id="6">damning</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">shows</governor>
          <dependent id="7">pattern</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">acceptance</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">pattern</governor>
          <dependent id="9">acceptance</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">pattern</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">pattern</governor>
          <dependent id="12">even</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="7">pattern</governor>
          <dependent id="13">encouragement</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">officers</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">shows</governor>
          <dependent id="16">officers</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">violate</governor>
          <dependent id="17">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="16">officers</governor>
          <dependent id="18">violate</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">rules</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">governing</governor>
          <dependent id="20">rules</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="18">violate</governor>
          <dependent id="21">governing</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">force</governor>
          <dependent id="22">excessive</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">governing</governor>
          <dependent id="23">force</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="32" has_coreference="true">
      <content>One officer who had seven complaints against him that had been sustained -- as well as numerous others that hadn&amp;apost;t been -- was described in his performance evaluation this way: &amp;quot;His contacts with the public are always professional and positive and his attitude with the citizens is one of concern.&amp;quot;</content>
      <tokens>
        <token id="1" string="One" lemma="one" stem="one" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="2" string="officer" lemma="officer" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="seven" lemma="seven" stem="seven" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="6" string="complaints" lemma="complaint" stem="complaint" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="9" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="sustained" lemma="sustain" stem="sustain" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="as" lemma="as" stem="a" pos="RB" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="well" lemma="well" stem="well" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="numerous" lemma="numerous" stem="numer" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="others" lemma="other" stem="other" pos="NNS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="23" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="24" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="25" string="described" lemma="describe" stem="describ" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="26" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="27" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="28" string="performance" lemma="performance" stem="perform" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="29" string="evaluation" lemma="evaluation" stem="evalu" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="30" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="31" string="way" lemma="way" stem="wai" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="32" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="33" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="34" string="His" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="35" string="contacts" lemma="contact" stem="contact" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="36" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="37" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="38" string="public" lemma="public" stem="public" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="39" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="always" lemma="always" stem="alwai" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="professional" lemma="professional" stem="profession" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="positive" lemma="positive" stem="posit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="44" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="46" string="attitude" lemma="attitude" stem="attitud" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="47" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="48" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="49" string="citizens" lemma="citizen" stem="citizen" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="50" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="51" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="52" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="53" string="concern" lemma="concern" stem="concern" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="54" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="55" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (CD One) (NN officer)) (SBAR (WHNP (WP who)) (S (VP (VP (VBD had) (NP (NP (NP (CD seven) (NNS complaints)) (PP (IN against) (NP (PRP him))) (SBAR (WHNP (WDT that)) (S (VP (VBD had) (VP (VBN been) (VP (VBN sustained))))))) (: --) (CONJP (RB as) (RB well) (IN as)) (NP (NP (JJ numerous) (NNS others)) (SBAR (WHNP (WDT that)) (S (VP (VBD had) (RB n't) (VP (VBN been)))))))) (: --) (VP (VBD was) (VP (VBN described) (PP (IN in) (NP (NP (PRP$ his) (NN performance) (NN evaluation)) (NP (DT this) (NN way)))))) (: :) (`` ``) (NP (NP (PRP$ His) (NNS contacts)) (PP (IN with) (NP (DT the) (NN public)))))))) (VP (VBP are) (ADVP (RB always)) (ADJP (JJ professional) (CC and) (JJ positive)))) (CC and) (S (NP (NP (PRP$ his) (NN attitude)) (PP (IN with) (NP (DT the) (NNS citizens)))) (VP (VBZ is) (NP (NP (CD one)) (PP (IN of) (NP (NN concern)))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="one" type="NP">
          <tokens>
            <token id="51" string="one" />
          </tokens>
        </chunking>
        <chunking id="2" string="seven complaints against him that had been sustained -- as well as numerous others that had n't been" type="NP">
          <tokens>
            <token id="5" string="seven" />
            <token id="6" string="complaints" />
            <token id="7" string="against" />
            <token id="8" string="him" />
            <token id="9" string="that" />
            <token id="10" string="had" />
            <token id="11" string="been" />
            <token id="12" string="sustained" />
            <token id="13" string="--" />
            <token id="14" string="as" />
            <token id="15" string="well" />
            <token id="16" string="as" />
            <token id="17" string="numerous" />
            <token id="18" string="others" />
            <token id="19" string="that" />
            <token id="20" string="had" />
            <token id="21" string="n't" />
            <token id="22" string="been" />
          </tokens>
        </chunking>
        <chunking id="3" string="seven complaints" type="NP">
          <tokens>
            <token id="5" string="seven" />
            <token id="6" string="complaints" />
          </tokens>
        </chunking>
        <chunking id="4" string="One officer" type="NP">
          <tokens>
            <token id="1" string="One" />
            <token id="2" string="officer" />
          </tokens>
        </chunking>
        <chunking id="5" string="professional and positive" type="ADJP">
          <tokens>
            <token id="41" string="professional" />
            <token id="42" string="and" />
            <token id="43" string="positive" />
          </tokens>
        </chunking>
        <chunking id="6" string="his attitude" type="NP">
          <tokens>
            <token id="45" string="his" />
            <token id="46" string="attitude" />
          </tokens>
        </chunking>
        <chunking id="7" string="numerous others" type="NP">
          <tokens>
            <token id="17" string="numerous" />
            <token id="18" string="others" />
          </tokens>
        </chunking>
        <chunking id="8" string="concern" type="NP">
          <tokens>
            <token id="53" string="concern" />
          </tokens>
        </chunking>
        <chunking id="9" string="is one of concern" type="VP">
          <tokens>
            <token id="50" string="is" />
            <token id="51" string="one" />
            <token id="52" string="of" />
            <token id="53" string="concern" />
          </tokens>
        </chunking>
        <chunking id="10" string="his attitude with the citizens" type="NP">
          <tokens>
            <token id="45" string="his" />
            <token id="46" string="attitude" />
            <token id="47" string="with" />
            <token id="48" string="the" />
            <token id="49" string="citizens" />
          </tokens>
        </chunking>
        <chunking id="11" string="seven complaints against him that had been sustained" type="NP">
          <tokens>
            <token id="5" string="seven" />
            <token id="6" string="complaints" />
            <token id="7" string="against" />
            <token id="8" string="him" />
            <token id="9" string="that" />
            <token id="10" string="had" />
            <token id="11" string="been" />
            <token id="12" string="sustained" />
          </tokens>
        </chunking>
        <chunking id="12" string="had been sustained" type="VP">
          <tokens>
            <token id="10" string="had" />
            <token id="11" string="been" />
            <token id="12" string="sustained" />
          </tokens>
        </chunking>
        <chunking id="13" string="His contacts" type="NP">
          <tokens>
            <token id="34" string="His" />
            <token id="35" string="contacts" />
          </tokens>
        </chunking>
        <chunking id="14" string="been sustained" type="VP">
          <tokens>
            <token id="11" string="been" />
            <token id="12" string="sustained" />
          </tokens>
        </chunking>
        <chunking id="15" string="his performance evaluation" type="NP">
          <tokens>
            <token id="27" string="his" />
            <token id="28" string="performance" />
            <token id="29" string="evaluation" />
          </tokens>
        </chunking>
        <chunking id="16" string="the citizens" type="NP">
          <tokens>
            <token id="48" string="the" />
            <token id="49" string="citizens" />
          </tokens>
        </chunking>
        <chunking id="17" string="His contacts with the public" type="NP">
          <tokens>
            <token id="34" string="His" />
            <token id="35" string="contacts" />
            <token id="36" string="with" />
            <token id="37" string="the" />
            <token id="38" string="public" />
          </tokens>
        </chunking>
        <chunking id="18" string="been" type="VP">
          <tokens>
            <token id="22" string="been" />
          </tokens>
        </chunking>
        <chunking id="19" string="one of concern" type="NP">
          <tokens>
            <token id="51" string="one" />
            <token id="52" string="of" />
            <token id="53" string="concern" />
          </tokens>
        </chunking>
        <chunking id="20" string="that had been sustained" type="SBAR">
          <tokens>
            <token id="9" string="that" />
            <token id="10" string="had" />
            <token id="11" string="been" />
            <token id="12" string="sustained" />
          </tokens>
        </chunking>
        <chunking id="21" string="described in his performance evaluation this way" type="VP">
          <tokens>
            <token id="25" string="described" />
            <token id="26" string="in" />
            <token id="27" string="his" />
            <token id="28" string="performance" />
            <token id="29" string="evaluation" />
            <token id="30" string="this" />
            <token id="31" string="way" />
          </tokens>
        </chunking>
        <chunking id="22" string="the public" type="NP">
          <tokens>
            <token id="37" string="the" />
            <token id="38" string="public" />
          </tokens>
        </chunking>
        <chunking id="23" string="him" type="NP">
          <tokens>
            <token id="8" string="him" />
          </tokens>
        </chunking>
        <chunking id="24" string="had n't been" type="VP">
          <tokens>
            <token id="20" string="had" />
            <token id="21" string="n't" />
            <token id="22" string="been" />
          </tokens>
        </chunking>
        <chunking id="25" string="are always professional and positive" type="VP">
          <tokens>
            <token id="39" string="are" />
            <token id="40" string="always" />
            <token id="41" string="professional" />
            <token id="42" string="and" />
            <token id="43" string="positive" />
          </tokens>
        </chunking>
        <chunking id="26" string="who had seven complaints against him that had been sustained -- as well as numerous others that had n't been -- was described in his performance evaluation this way : `` His contacts with the public" type="SBAR">
          <tokens>
            <token id="3" string="who" />
            <token id="4" string="had" />
            <token id="5" string="seven" />
            <token id="6" string="complaints" />
            <token id="7" string="against" />
            <token id="8" string="him" />
            <token id="9" string="that" />
            <token id="10" string="had" />
            <token id="11" string="been" />
            <token id="12" string="sustained" />
            <token id="13" string="--" />
            <token id="14" string="as" />
            <token id="15" string="well" />
            <token id="16" string="as" />
            <token id="17" string="numerous" />
            <token id="18" string="others" />
            <token id="19" string="that" />
            <token id="20" string="had" />
            <token id="21" string="n't" />
            <token id="22" string="been" />
            <token id="23" string="--" />
            <token id="24" string="was" />
            <token id="25" string="described" />
            <token id="26" string="in" />
            <token id="27" string="his" />
            <token id="28" string="performance" />
            <token id="29" string="evaluation" />
            <token id="30" string="this" />
            <token id="31" string="way" />
            <token id="32" string=":" />
            <token id="33" string="&quot;" />
            <token id="34" string="His" />
            <token id="35" string="contacts" />
            <token id="36" string="with" />
            <token id="37" string="the" />
            <token id="38" string="public" />
          </tokens>
        </chunking>
        <chunking id="27" string="this way" type="NP">
          <tokens>
            <token id="30" string="this" />
            <token id="31" string="way" />
          </tokens>
        </chunking>
        <chunking id="28" string="sustained" type="VP">
          <tokens>
            <token id="12" string="sustained" />
          </tokens>
        </chunking>
        <chunking id="29" string="his performance evaluation this way" type="NP">
          <tokens>
            <token id="27" string="his" />
            <token id="28" string="performance" />
            <token id="29" string="evaluation" />
            <token id="30" string="this" />
            <token id="31" string="way" />
          </tokens>
        </chunking>
        <chunking id="30" string="was described in his performance evaluation this way" type="VP">
          <tokens>
            <token id="24" string="was" />
            <token id="25" string="described" />
            <token id="26" string="in" />
            <token id="27" string="his" />
            <token id="28" string="performance" />
            <token id="29" string="evaluation" />
            <token id="30" string="this" />
            <token id="31" string="way" />
          </tokens>
        </chunking>
        <chunking id="31" string="that had n't been" type="SBAR">
          <tokens>
            <token id="19" string="that" />
            <token id="20" string="had" />
            <token id="21" string="n't" />
            <token id="22" string="been" />
          </tokens>
        </chunking>
        <chunking id="32" string="had seven complaints against him that had been sustained -- as well as numerous others that had n't been" type="VP">
          <tokens>
            <token id="4" string="had" />
            <token id="5" string="seven" />
            <token id="6" string="complaints" />
            <token id="7" string="against" />
            <token id="8" string="him" />
            <token id="9" string="that" />
            <token id="10" string="had" />
            <token id="11" string="been" />
            <token id="12" string="sustained" />
            <token id="13" string="--" />
            <token id="14" string="as" />
            <token id="15" string="well" />
            <token id="16" string="as" />
            <token id="17" string="numerous" />
            <token id="18" string="others" />
            <token id="19" string="that" />
            <token id="20" string="had" />
            <token id="21" string="n't" />
            <token id="22" string="been" />
          </tokens>
        </chunking>
        <chunking id="33" string="One officer who had seven complaints against him that had been sustained -- as well as numerous others that had n't been -- was described in his performance evaluation this way : `` His contacts with the public" type="NP">
          <tokens>
            <token id="1" string="One" />
            <token id="2" string="officer" />
            <token id="3" string="who" />
            <token id="4" string="had" />
            <token id="5" string="seven" />
            <token id="6" string="complaints" />
            <token id="7" string="against" />
            <token id="8" string="him" />
            <token id="9" string="that" />
            <token id="10" string="had" />
            <token id="11" string="been" />
            <token id="12" string="sustained" />
            <token id="13" string="--" />
            <token id="14" string="as" />
            <token id="15" string="well" />
            <token id="16" string="as" />
            <token id="17" string="numerous" />
            <token id="18" string="others" />
            <token id="19" string="that" />
            <token id="20" string="had" />
            <token id="21" string="n't" />
            <token id="22" string="been" />
            <token id="23" string="--" />
            <token id="24" string="was" />
            <token id="25" string="described" />
            <token id="26" string="in" />
            <token id="27" string="his" />
            <token id="28" string="performance" />
            <token id="29" string="evaluation" />
            <token id="30" string="this" />
            <token id="31" string="way" />
            <token id="32" string=":" />
            <token id="33" string="&quot;" />
            <token id="34" string="His" />
            <token id="35" string="contacts" />
            <token id="36" string="with" />
            <token id="37" string="the" />
            <token id="38" string="public" />
          </tokens>
        </chunking>
        <chunking id="34" string="had seven complaints against him that had been sustained -- as well as numerous others that had n't been -- was described in his performance evaluation this way : `` His contacts with the public" type="VP">
          <tokens>
            <token id="4" string="had" />
            <token id="5" string="seven" />
            <token id="6" string="complaints" />
            <token id="7" string="against" />
            <token id="8" string="him" />
            <token id="9" string="that" />
            <token id="10" string="had" />
            <token id="11" string="been" />
            <token id="12" string="sustained" />
            <token id="13" string="--" />
            <token id="14" string="as" />
            <token id="15" string="well" />
            <token id="16" string="as" />
            <token id="17" string="numerous" />
            <token id="18" string="others" />
            <token id="19" string="that" />
            <token id="20" string="had" />
            <token id="21" string="n't" />
            <token id="22" string="been" />
            <token id="23" string="--" />
            <token id="24" string="was" />
            <token id="25" string="described" />
            <token id="26" string="in" />
            <token id="27" string="his" />
            <token id="28" string="performance" />
            <token id="29" string="evaluation" />
            <token id="30" string="this" />
            <token id="31" string="way" />
            <token id="32" string=":" />
            <token id="33" string="&quot;" />
            <token id="34" string="His" />
            <token id="35" string="contacts" />
            <token id="36" string="with" />
            <token id="37" string="the" />
            <token id="38" string="public" />
          </tokens>
        </chunking>
        <chunking id="35" string="numerous others that had n't been" type="NP">
          <tokens>
            <token id="17" string="numerous" />
            <token id="18" string="others" />
            <token id="19" string="that" />
            <token id="20" string="had" />
            <token id="21" string="n't" />
            <token id="22" string="been" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nummod">
          <governor id="2">officer</governor>
          <dependent id="1">One</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="41">professional</governor>
          <dependent id="2">officer</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">had</governor>
          <dependent id="3">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="2">officer</governor>
          <dependent id="4">had</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="6">complaints</governor>
          <dependent id="5">seven</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">had</governor>
          <dependent id="6">complaints</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">him</governor>
          <dependent id="7">against</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">complaints</governor>
          <dependent id="8">him</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="12">sustained</governor>
          <dependent id="9">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">sustained</governor>
          <dependent id="10">had</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="12">sustained</governor>
          <dependent id="11">been</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="6">complaints</governor>
          <dependent id="12">sustained</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">complaints</governor>
          <dependent id="14">as</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="14">as</governor>
          <dependent id="15">well</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="14">as</governor>
          <dependent id="16">as</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">others</governor>
          <dependent id="17">numerous</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">complaints</governor>
          <dependent id="18">others</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">been</governor>
          <dependent id="19">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="22">been</governor>
          <dependent id="20">had</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="22">been</governor>
          <dependent id="21">n't</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="18">others</governor>
          <dependent id="22">been</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="25">described</governor>
          <dependent id="24">was</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="4">had</governor>
          <dependent id="25">described</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">evaluation</governor>
          <dependent id="26">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="29">evaluation</governor>
          <dependent id="27">his</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="29">evaluation</governor>
          <dependent id="28">performance</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">described</governor>
          <dependent id="29">evaluation</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">way</governor>
          <dependent id="30">this</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="29">evaluation</governor>
          <dependent id="31">way</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="35">contacts</governor>
          <dependent id="34">His</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">had</governor>
          <dependent id="35">contacts</dependent>
        </dependency>
        <dependency type="case">
          <governor id="38">public</governor>
          <dependent id="36">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="38">public</governor>
          <dependent id="37">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="35">contacts</governor>
          <dependent id="38">public</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="41">professional</governor>
          <dependent id="39">are</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="41">professional</governor>
          <dependent id="40">always</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="41">professional</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="41">professional</governor>
          <dependent id="42">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="41">professional</governor>
          <dependent id="43">positive</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="41">professional</governor>
          <dependent id="44">and</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="46">attitude</governor>
          <dependent id="45">his</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="51">one</governor>
          <dependent id="46">attitude</dependent>
        </dependency>
        <dependency type="case">
          <governor id="49">citizens</governor>
          <dependent id="47">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="49">citizens</governor>
          <dependent id="48">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="46">attitude</governor>
          <dependent id="49">citizens</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="51">one</governor>
          <dependent id="50">is</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="41">professional</governor>
          <dependent id="51">one</dependent>
        </dependency>
        <dependency type="case">
          <governor id="53">concern</governor>
          <dependent id="52">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="51">one</governor>
          <dependent id="53">concern</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="One" type="NUMBER" score="0.0">
          <tokens>
            <token id="1" string="One" />
          </tokens>
        </entity>
        <entity id="2" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="51" string="one" />
          </tokens>
        </entity>
        <entity id="3" string="seven" type="NUMBER" score="0.0">
          <tokens>
            <token id="5" string="seven" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="33" has_coreference="true">
      <content>The report also reveals that racially derogatory remarks are made on an ongoing basis within the department; racist jokes and cartoons appear from time to time on bulletin boards in station locker rooms.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="report" lemma="report" stem="report" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="reveals" lemma="reveal" stem="reveal" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="racially" lemma="racially" stem="racial" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="derogatory" lemma="derogatory" stem="derogatori" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="remarks" lemma="remark" stem="remark" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="made" lemma="make" stem="made" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="ongoing" lemma="ongoing" stem="ongo" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="basis" lemma="basis" stem="basi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="within" lemma="within" stem="within" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="department" lemma="department" stem="depart" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="18" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="racist" lemma="racist" stem="racist" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="jokes" lemma="joke" stem="joke" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="cartoons" lemma="cartoon" stem="cartoon" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="appear" lemma="appear" stem="appear" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="26" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="bulletin" lemma="bulletin" stem="bulletin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="boards" lemma="board" stem="board" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="station" lemma="station" stem="station" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="locker" lemma="locker" stem="locker" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="rooms" lemma="room" stem="room" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (DT The) (NN report)) (ADVP (RB also)) (VP (VBZ reveals) (SBAR (IN that) (S (NP (ADJP (RB racially) (JJ derogatory)) (NNS remarks)) (VP (VBP are) (VP (VBN made) (PP (IN on) (NP (NP (DT an) (JJ ongoing) (NN basis)) (PP (IN within) (NP (DT the) (NN department))))))))))) (: ;) (S (NP (JJ racist) (NNS jokes) (CC and) (NNS cartoons)) (VP (VBP appear) (PP (IN from) (NP (NN time))) (PP (TO to) (NP (NP (NN time)) (PP (IN on) (NP (NP (NN bulletin) (NNS boards)) (PP (IN in) (NP (NN station) (NN locker) (NNS rooms))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="reveals that racially derogatory remarks are made on an ongoing basis within the department" type="VP">
          <tokens>
            <token id="4" string="reveals" />
            <token id="5" string="that" />
            <token id="6" string="racially" />
            <token id="7" string="derogatory" />
            <token id="8" string="remarks" />
            <token id="9" string="are" />
            <token id="10" string="made" />
            <token id="11" string="on" />
            <token id="12" string="an" />
            <token id="13" string="ongoing" />
            <token id="14" string="basis" />
            <token id="15" string="within" />
            <token id="16" string="the" />
            <token id="17" string="department" />
          </tokens>
        </chunking>
        <chunking id="2" string="racially derogatory" type="ADJP">
          <tokens>
            <token id="6" string="racially" />
            <token id="7" string="derogatory" />
          </tokens>
        </chunking>
        <chunking id="3" string="station locker rooms" type="NP">
          <tokens>
            <token id="32" string="station" />
            <token id="33" string="locker" />
            <token id="34" string="rooms" />
          </tokens>
        </chunking>
        <chunking id="4" string="made on an ongoing basis within the department" type="VP">
          <tokens>
            <token id="10" string="made" />
            <token id="11" string="on" />
            <token id="12" string="an" />
            <token id="13" string="ongoing" />
            <token id="14" string="basis" />
            <token id="15" string="within" />
            <token id="16" string="the" />
            <token id="17" string="department" />
          </tokens>
        </chunking>
        <chunking id="5" string="time on bulletin boards in station locker rooms" type="NP">
          <tokens>
            <token id="27" string="time" />
            <token id="28" string="on" />
            <token id="29" string="bulletin" />
            <token id="30" string="boards" />
            <token id="31" string="in" />
            <token id="32" string="station" />
            <token id="33" string="locker" />
            <token id="34" string="rooms" />
          </tokens>
        </chunking>
        <chunking id="6" string="are made on an ongoing basis within the department" type="VP">
          <tokens>
            <token id="9" string="are" />
            <token id="10" string="made" />
            <token id="11" string="on" />
            <token id="12" string="an" />
            <token id="13" string="ongoing" />
            <token id="14" string="basis" />
            <token id="15" string="within" />
            <token id="16" string="the" />
            <token id="17" string="department" />
          </tokens>
        </chunking>
        <chunking id="7" string="appear from time to time on bulletin boards in station locker rooms" type="VP">
          <tokens>
            <token id="23" string="appear" />
            <token id="24" string="from" />
            <token id="25" string="time" />
            <token id="26" string="to" />
            <token id="27" string="time" />
            <token id="28" string="on" />
            <token id="29" string="bulletin" />
            <token id="30" string="boards" />
            <token id="31" string="in" />
            <token id="32" string="station" />
            <token id="33" string="locker" />
            <token id="34" string="rooms" />
          </tokens>
        </chunking>
        <chunking id="8" string="an ongoing basis" type="NP">
          <tokens>
            <token id="12" string="an" />
            <token id="13" string="ongoing" />
            <token id="14" string="basis" />
          </tokens>
        </chunking>
        <chunking id="9" string="bulletin boards" type="NP">
          <tokens>
            <token id="29" string="bulletin" />
            <token id="30" string="boards" />
          </tokens>
        </chunking>
        <chunking id="10" string="racially derogatory remarks" type="NP">
          <tokens>
            <token id="6" string="racially" />
            <token id="7" string="derogatory" />
            <token id="8" string="remarks" />
          </tokens>
        </chunking>
        <chunking id="11" string="bulletin boards in station locker rooms" type="NP">
          <tokens>
            <token id="29" string="bulletin" />
            <token id="30" string="boards" />
            <token id="31" string="in" />
            <token id="32" string="station" />
            <token id="33" string="locker" />
            <token id="34" string="rooms" />
          </tokens>
        </chunking>
        <chunking id="12" string="The report" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="report" />
          </tokens>
        </chunking>
        <chunking id="13" string="the department" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="department" />
          </tokens>
        </chunking>
        <chunking id="14" string="racist jokes and cartoons" type="NP">
          <tokens>
            <token id="19" string="racist" />
            <token id="20" string="jokes" />
            <token id="21" string="and" />
            <token id="22" string="cartoons" />
          </tokens>
        </chunking>
        <chunking id="15" string="an ongoing basis within the department" type="NP">
          <tokens>
            <token id="12" string="an" />
            <token id="13" string="ongoing" />
            <token id="14" string="basis" />
            <token id="15" string="within" />
            <token id="16" string="the" />
            <token id="17" string="department" />
          </tokens>
        </chunking>
        <chunking id="16" string="time" type="NP">
          <tokens>
            <token id="25" string="time" />
          </tokens>
        </chunking>
        <chunking id="17" string="that racially derogatory remarks are made on an ongoing basis within the department" type="SBAR">
          <tokens>
            <token id="5" string="that" />
            <token id="6" string="racially" />
            <token id="7" string="derogatory" />
            <token id="8" string="remarks" />
            <token id="9" string="are" />
            <token id="10" string="made" />
            <token id="11" string="on" />
            <token id="12" string="an" />
            <token id="13" string="ongoing" />
            <token id="14" string="basis" />
            <token id="15" string="within" />
            <token id="16" string="the" />
            <token id="17" string="department" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">report</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">reveals</governor>
          <dependent id="2">report</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">reveals</governor>
          <dependent id="3">also</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">reveals</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">made</governor>
          <dependent id="5">that</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">derogatory</governor>
          <dependent id="6">racially</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">remarks</governor>
          <dependent id="7">derogatory</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="10">made</governor>
          <dependent id="8">remarks</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="10">made</governor>
          <dependent id="9">are</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">reveals</governor>
          <dependent id="10">made</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">basis</governor>
          <dependent id="11">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">basis</governor>
          <dependent id="12">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">basis</governor>
          <dependent id="13">ongoing</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">made</governor>
          <dependent id="14">basis</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">department</governor>
          <dependent id="15">within</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">department</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">basis</governor>
          <dependent id="17">department</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">jokes</governor>
          <dependent id="19">racist</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">appear</governor>
          <dependent id="20">jokes</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="20">jokes</governor>
          <dependent id="21">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="20">jokes</governor>
          <dependent id="22">cartoons</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="4">reveals</governor>
          <dependent id="23">appear</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">time</governor>
          <dependent id="24">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">appear</governor>
          <dependent id="25">time</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">time</governor>
          <dependent id="26">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">appear</governor>
          <dependent id="27">time</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">boards</governor>
          <dependent id="28">on</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="30">boards</governor>
          <dependent id="29">bulletin</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">time</governor>
          <dependent id="30">boards</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">rooms</governor>
          <dependent id="31">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="34">rooms</governor>
          <dependent id="32">station</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="34">rooms</governor>
          <dependent id="33">locker</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">boards</governor>
          <dependent id="34">rooms</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="34" has_coreference="false">
      <content>Sexism and homophobia abound.</content>
      <tokens>
        <token id="1" string="Sexism" lemma="Sexism" stem="sexism" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="2" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="homophobia" lemma="homophobia" stem="homophobia" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="abound" lemma="abound" stem="abound" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Sexism)) (CC and) (NP (NN homophobia))) (VP (VBP abound)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="abound" type="VP">
          <tokens>
            <token id="4" string="abound" />
          </tokens>
        </chunking>
        <chunking id="2" string="Sexism" type="NP">
          <tokens>
            <token id="1" string="Sexism" />
          </tokens>
        </chunking>
        <chunking id="3" string="Sexism and homophobia" type="NP">
          <tokens>
            <token id="1" string="Sexism" />
            <token id="2" string="and" />
            <token id="3" string="homophobia" />
          </tokens>
        </chunking>
        <chunking id="4" string="homophobia" type="NP">
          <tokens>
            <token id="3" string="homophobia" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">abound</governor>
          <dependent id="1">Sexism</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="1">Sexism</governor>
          <dependent id="2">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="1">Sexism</governor>
          <dependent id="3">homophobia</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">abound</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Sexism" type="MISC" score="0.0">
          <tokens>
            <token id="1" string="Sexism" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="35" has_coreference="true">
      <content>Minority officers complain that whites dominate managerial posts within the LAPD, possibly contributing to these problems.</content>
      <tokens>
        <token id="1" string="Minority" lemma="Minority" stem="minor" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="complain" lemma="complain" stem="complain" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="whites" lemma="whites" stem="white" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="dominate" lemma="dominate" stem="domin" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="managerial" lemma="managerial" stem="manageri" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="posts" lemma="post" stem="post" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="within" lemma="within" stem="within" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="LAPD" lemma="LAPD" stem="lapd" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="possibly" lemma="possibly" stem="possibli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="contributing" lemma="contribute" stem="contribut" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="these" lemma="these" stem="these" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="problems" lemma="problem" stem="problem" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Minority) (NNS officers)) (VP (VBP complain) (SBAR (IN that) (S (NP (NNS whites)) (VP (VBP dominate) (NP (JJ managerial) (NNS posts)) (PP (IN within) (NP (DT the) (NNP LAPD)))))) (, ,) (S (ADVP (RB possibly)) (VP (VBG contributing) (PP (TO to) (NP (DT these) (NNS problems)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="contributing to these problems" type="VP">
          <tokens>
            <token id="14" string="contributing" />
            <token id="15" string="to" />
            <token id="16" string="these" />
            <token id="17" string="problems" />
          </tokens>
        </chunking>
        <chunking id="2" string="whites" type="NP">
          <tokens>
            <token id="5" string="whites" />
          </tokens>
        </chunking>
        <chunking id="3" string="dominate managerial posts within the LAPD" type="VP">
          <tokens>
            <token id="6" string="dominate" />
            <token id="7" string="managerial" />
            <token id="8" string="posts" />
            <token id="9" string="within" />
            <token id="10" string="the" />
            <token id="11" string="LAPD" />
          </tokens>
        </chunking>
        <chunking id="4" string="complain that whites dominate managerial posts within the LAPD , possibly contributing to these problems" type="VP">
          <tokens>
            <token id="3" string="complain" />
            <token id="4" string="that" />
            <token id="5" string="whites" />
            <token id="6" string="dominate" />
            <token id="7" string="managerial" />
            <token id="8" string="posts" />
            <token id="9" string="within" />
            <token id="10" string="the" />
            <token id="11" string="LAPD" />
            <token id="12" string="," />
            <token id="13" string="possibly" />
            <token id="14" string="contributing" />
            <token id="15" string="to" />
            <token id="16" string="these" />
            <token id="17" string="problems" />
          </tokens>
        </chunking>
        <chunking id="5" string="the LAPD" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="LAPD" />
          </tokens>
        </chunking>
        <chunking id="6" string="Minority officers" type="NP">
          <tokens>
            <token id="1" string="Minority" />
            <token id="2" string="officers" />
          </tokens>
        </chunking>
        <chunking id="7" string="that whites dominate managerial posts within the LAPD" type="SBAR">
          <tokens>
            <token id="4" string="that" />
            <token id="5" string="whites" />
            <token id="6" string="dominate" />
            <token id="7" string="managerial" />
            <token id="8" string="posts" />
            <token id="9" string="within" />
            <token id="10" string="the" />
            <token id="11" string="LAPD" />
          </tokens>
        </chunking>
        <chunking id="8" string="managerial posts" type="NP">
          <tokens>
            <token id="7" string="managerial" />
            <token id="8" string="posts" />
          </tokens>
        </chunking>
        <chunking id="9" string="these problems" type="NP">
          <tokens>
            <token id="16" string="these" />
            <token id="17" string="problems" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">officers</governor>
          <dependent id="1">Minority</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">complain</governor>
          <dependent id="2">officers</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">complain</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">dominate</governor>
          <dependent id="4">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">dominate</governor>
          <dependent id="5">whites</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">complain</governor>
          <dependent id="6">dominate</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">posts</governor>
          <dependent id="7">managerial</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">dominate</governor>
          <dependent id="8">posts</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">LAPD</governor>
          <dependent id="9">within</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">LAPD</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">dominate</governor>
          <dependent id="11">LAPD</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">contributing</governor>
          <dependent id="13">possibly</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">complain</governor>
          <dependent id="14">contributing</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">problems</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">problems</governor>
          <dependent id="16">these</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">contributing</governor>
          <dependent id="17">problems</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="LAPD" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="11" string="LAPD" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="36" has_coreference="true">
      <content>More than 80% of the black, Hispanic and Asian police officers in the force are in the entry-level ranks, the report said.</content>
      <tokens>
        <token id="1" string="More" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="80" lemma="80" stem="80" pos="CD" type="Number" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="4" string="%" lemma="%" stem="%" pos="NN" type="Symbol" isStopWord="true" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="black" lemma="black" stem="black" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="Hispanic" lemma="hispanic" stem="hispan" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="Asian" lemma="asian" stem="asian" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="12" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="16" string="force" lemma="force" stem="forc" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="17" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="entry-level" lemma="entry-level" stem="entry-level" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="ranks" lemma="rank" stem="rank" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="report" lemma="report" stem="report" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="25" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (QP (JJR More) (IN than) (CD 80)) (NN %)) (PP (IN of) (NP (NP (DT the) (ADJP (JJ black) (, ,) (JJ Hispanic) (CC and) (JJ Asian)) (NN police) (NNS officers)) (PP (IN in) (NP (DT the) (NN force)))))) (VP (VBP are) (PP (IN in) (NP (DT the) (JJ entry-level) (NNS ranks))))) (, ,) (NP (DT the) (NN report)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the black , Hispanic and Asian police officers" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="black" />
            <token id="8" string="," />
            <token id="9" string="Hispanic" />
            <token id="10" string="and" />
            <token id="11" string="Asian" />
            <token id="12" string="police" />
            <token id="13" string="officers" />
          </tokens>
        </chunking>
        <chunking id="2" string="black , Hispanic and Asian" type="ADJP">
          <tokens>
            <token id="7" string="black" />
            <token id="8" string="," />
            <token id="9" string="Hispanic" />
            <token id="10" string="and" />
            <token id="11" string="Asian" />
          </tokens>
        </chunking>
        <chunking id="3" string="are in the entry-level ranks" type="VP">
          <tokens>
            <token id="17" string="are" />
            <token id="18" string="in" />
            <token id="19" string="the" />
            <token id="20" string="entry-level" />
            <token id="21" string="ranks" />
          </tokens>
        </chunking>
        <chunking id="4" string="More than 80 %" type="NP">
          <tokens>
            <token id="1" string="More" />
            <token id="2" string="than" />
            <token id="3" string="80" />
            <token id="4" string="%" />
          </tokens>
        </chunking>
        <chunking id="5" string="the entry-level ranks" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="entry-level" />
            <token id="21" string="ranks" />
          </tokens>
        </chunking>
        <chunking id="6" string="the force" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="force" />
          </tokens>
        </chunking>
        <chunking id="7" string="the black , Hispanic and Asian police officers in the force" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="black" />
            <token id="8" string="," />
            <token id="9" string="Hispanic" />
            <token id="10" string="and" />
            <token id="11" string="Asian" />
            <token id="12" string="police" />
            <token id="13" string="officers" />
            <token id="14" string="in" />
            <token id="15" string="the" />
            <token id="16" string="force" />
          </tokens>
        </chunking>
        <chunking id="8" string="the report" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="report" />
          </tokens>
        </chunking>
        <chunking id="9" string="More than 80 % of the black , Hispanic and Asian police officers in the force" type="NP">
          <tokens>
            <token id="1" string="More" />
            <token id="2" string="than" />
            <token id="3" string="80" />
            <token id="4" string="%" />
            <token id="5" string="of" />
            <token id="6" string="the" />
            <token id="7" string="black" />
            <token id="8" string="," />
            <token id="9" string="Hispanic" />
            <token id="10" string="and" />
            <token id="11" string="Asian" />
            <token id="12" string="police" />
            <token id="13" string="officers" />
            <token id="14" string="in" />
            <token id="15" string="the" />
            <token id="16" string="force" />
          </tokens>
        </chunking>
        <chunking id="10" string="said" type="VP">
          <tokens>
            <token id="25" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="3">80</governor>
          <dependent id="1">More</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="1">More</governor>
          <dependent id="2">than</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="4">%</governor>
          <dependent id="3">80</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">ranks</governor>
          <dependent id="4">%</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">officers</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">officers</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">officers</governor>
          <dependent id="7">black</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">black</governor>
          <dependent id="9">Hispanic</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">black</governor>
          <dependent id="10">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">black</governor>
          <dependent id="11">Asian</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">officers</governor>
          <dependent id="12">police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">%</governor>
          <dependent id="13">officers</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">force</governor>
          <dependent id="14">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">force</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">officers</governor>
          <dependent id="16">force</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="21">ranks</governor>
          <dependent id="17">are</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">ranks</governor>
          <dependent id="18">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">ranks</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">ranks</governor>
          <dependent id="20">entry-level</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="25">said</governor>
          <dependent id="21">ranks</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">report</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">said</governor>
          <dependent id="24">report</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="25">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="80 %" type="PERCENT" score="0.0">
          <tokens>
            <token id="3" string="80" />
            <token id="4" string="%" />
          </tokens>
        </entity>
        <entity id="2" string="Asian" type="MISC" score="0.0">
          <tokens>
            <token id="11" string="Asian" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="37" has_coreference="true">
      <content>But the most surprising part of the report was its recommendation that Chief Gates resign, after a transitional period in which he would begin implementing the commission&amp;apost;s proposals.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="most" lemma="most" stem="most" pos="RBS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="surprising" lemma="surprising" stem="surpris" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="part" lemma="part" stem="part" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="8" string="report" lemma="report" stem="report" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="9" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="recommendation" lemma="recommendation" stem="recommend" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Chief" lemma="Chief" stem="chief" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="false" is_refers="true" />
        <token id="14" string="Gates" lemma="Gates" stem="gate" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="resign" lemma="resign" stem="resign" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="transitional" lemma="transitional" stem="transit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="period" lemma="period" stem="period" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="begin" lemma="begin" stem="begin" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="implementing" lemma="implement" stem="implement" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="28" string="commission" lemma="commission" stem="commiss" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="29" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="30" string="proposals" lemma="proposal" stem="propos" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (NP (DT the) (ADJP (RBS most) (JJ surprising)) (NN part)) (PP (IN of) (NP (DT the) (NN report)))) (VP (VBD was) (NP (PRP$ its) (NN recommendation)) (SBAR (IN that) (S (NP (NNP Chief) (NNP Gates)) (VP (VB resign) (, ,) (PP (IN after) (NP (DT a) (JJ transitional) (NN period))) (PP (IN in) (SBAR (WHNP (WDT which)) (S (NP (PRP he)) (VP (MD would) (VP (VB begin) (S (VP (VBG implementing) (NP (NP (DT the) (NN commission) (POS 's)) (NNS proposals))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="its recommendation" type="NP">
          <tokens>
            <token id="10" string="its" />
            <token id="11" string="recommendation" />
          </tokens>
        </chunking>
        <chunking id="2" string="implementing the commission 's proposals" type="VP">
          <tokens>
            <token id="26" string="implementing" />
            <token id="27" string="the" />
            <token id="28" string="commission" />
            <token id="29" string="'s" />
            <token id="30" string="proposals" />
          </tokens>
        </chunking>
        <chunking id="3" string="that Chief Gates resign , after a transitional period in which he would begin implementing the commission 's proposals" type="SBAR">
          <tokens>
            <token id="12" string="that" />
            <token id="13" string="Chief" />
            <token id="14" string="Gates" />
            <token id="15" string="resign" />
            <token id="16" string="," />
            <token id="17" string="after" />
            <token id="18" string="a" />
            <token id="19" string="transitional" />
            <token id="20" string="period" />
            <token id="21" string="in" />
            <token id="22" string="which" />
            <token id="23" string="he" />
            <token id="24" string="would" />
            <token id="25" string="begin" />
            <token id="26" string="implementing" />
            <token id="27" string="the" />
            <token id="28" string="commission" />
            <token id="29" string="'s" />
            <token id="30" string="proposals" />
          </tokens>
        </chunking>
        <chunking id="4" string="the most surprising part of the report" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="most" />
            <token id="4" string="surprising" />
            <token id="5" string="part" />
            <token id="6" string="of" />
            <token id="7" string="the" />
            <token id="8" string="report" />
          </tokens>
        </chunking>
        <chunking id="5" string="the most surprising part" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="most" />
            <token id="4" string="surprising" />
            <token id="5" string="part" />
          </tokens>
        </chunking>
        <chunking id="6" string="was its recommendation that Chief Gates resign , after a transitional period in which he would begin implementing the commission 's proposals" type="VP">
          <tokens>
            <token id="9" string="was" />
            <token id="10" string="its" />
            <token id="11" string="recommendation" />
            <token id="12" string="that" />
            <token id="13" string="Chief" />
            <token id="14" string="Gates" />
            <token id="15" string="resign" />
            <token id="16" string="," />
            <token id="17" string="after" />
            <token id="18" string="a" />
            <token id="19" string="transitional" />
            <token id="20" string="period" />
            <token id="21" string="in" />
            <token id="22" string="which" />
            <token id="23" string="he" />
            <token id="24" string="would" />
            <token id="25" string="begin" />
            <token id="26" string="implementing" />
            <token id="27" string="the" />
            <token id="28" string="commission" />
            <token id="29" string="'s" />
            <token id="30" string="proposals" />
          </tokens>
        </chunking>
        <chunking id="7" string="Chief Gates" type="NP">
          <tokens>
            <token id="13" string="Chief" />
            <token id="14" string="Gates" />
          </tokens>
        </chunking>
        <chunking id="8" string="which he would begin implementing the commission 's proposals" type="SBAR">
          <tokens>
            <token id="22" string="which" />
            <token id="23" string="he" />
            <token id="24" string="would" />
            <token id="25" string="begin" />
            <token id="26" string="implementing" />
            <token id="27" string="the" />
            <token id="28" string="commission" />
            <token id="29" string="'s" />
            <token id="30" string="proposals" />
          </tokens>
        </chunking>
        <chunking id="9" string="would begin implementing the commission 's proposals" type="VP">
          <tokens>
            <token id="24" string="would" />
            <token id="25" string="begin" />
            <token id="26" string="implementing" />
            <token id="27" string="the" />
            <token id="28" string="commission" />
            <token id="29" string="'s" />
            <token id="30" string="proposals" />
          </tokens>
        </chunking>
        <chunking id="10" string="the commission 's" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="commission" />
            <token id="29" string="'s" />
          </tokens>
        </chunking>
        <chunking id="11" string="resign , after a transitional period in which he would begin implementing the commission 's proposals" type="VP">
          <tokens>
            <token id="15" string="resign" />
            <token id="16" string="," />
            <token id="17" string="after" />
            <token id="18" string="a" />
            <token id="19" string="transitional" />
            <token id="20" string="period" />
            <token id="21" string="in" />
            <token id="22" string="which" />
            <token id="23" string="he" />
            <token id="24" string="would" />
            <token id="25" string="begin" />
            <token id="26" string="implementing" />
            <token id="27" string="the" />
            <token id="28" string="commission" />
            <token id="29" string="'s" />
            <token id="30" string="proposals" />
          </tokens>
        </chunking>
        <chunking id="12" string="most surprising" type="ADJP">
          <tokens>
            <token id="3" string="most" />
            <token id="4" string="surprising" />
          </tokens>
        </chunking>
        <chunking id="13" string="begin implementing the commission 's proposals" type="VP">
          <tokens>
            <token id="25" string="begin" />
            <token id="26" string="implementing" />
            <token id="27" string="the" />
            <token id="28" string="commission" />
            <token id="29" string="'s" />
            <token id="30" string="proposals" />
          </tokens>
        </chunking>
        <chunking id="14" string="a transitional period" type="NP">
          <tokens>
            <token id="18" string="a" />
            <token id="19" string="transitional" />
            <token id="20" string="period" />
          </tokens>
        </chunking>
        <chunking id="15" string="the report" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="report" />
          </tokens>
        </chunking>
        <chunking id="16" string="he" type="NP">
          <tokens>
            <token id="23" string="he" />
          </tokens>
        </chunking>
        <chunking id="17" string="the commission 's proposals" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="commission" />
            <token id="29" string="'s" />
            <token id="30" string="proposals" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="11">recommendation</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">part</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">surprising</governor>
          <dependent id="3">most</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">part</governor>
          <dependent id="4">surprising</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">recommendation</governor>
          <dependent id="5">part</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">report</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">report</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">part</governor>
          <dependent id="8">report</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="11">recommendation</governor>
          <dependent id="9">was</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">recommendation</governor>
          <dependent id="10">its</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">recommendation</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">resign</governor>
          <dependent id="12">that</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Gates</governor>
          <dependent id="13">Chief</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">resign</governor>
          <dependent id="14">Gates</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">recommendation</governor>
          <dependent id="15">resign</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">period</governor>
          <dependent id="17">after</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">period</governor>
          <dependent id="18">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">period</governor>
          <dependent id="19">transitional</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">resign</governor>
          <dependent id="20">period</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="25">begin</governor>
          <dependent id="21">in</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="26">implementing</governor>
          <dependent id="22">which</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">begin</governor>
          <dependent id="23">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="25">begin</governor>
          <dependent id="24">would</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="15">resign</governor>
          <dependent id="25">begin</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="25">begin</governor>
          <dependent id="26">implementing</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">commission</governor>
          <dependent id="27">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="30">proposals</governor>
          <dependent id="28">commission</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">commission</governor>
          <dependent id="29">'s</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="26">implementing</governor>
          <dependent id="30">proposals</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Chief" type="TITLE" score="0.0">
          <tokens>
            <token id="13" string="Chief" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="38" has_coreference="true">
      <content>&amp;quot;We&amp;apost;re not startled by any of the things in this report,&amp;quot; the chief said a few hours after its release.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="We" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="'re" lemma="be" stem="'re" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="startled" lemma="startle" stem="startl" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="any" lemma="any" stem="ani" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="things" lemma="thing" stem="thing" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="report" lemma="report" stem="report" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="chief" lemma="chief" stem="chief" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="20" string="few" lemma="few" stem="few" pos="JJ" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="21" string="hours" lemma="hour" stem="hour" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="22" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="release" lemma="release" stem="releas" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP We)) (VP (VBP 're) (RB not) (VP (VBN startled) (PP (IN by) (NP (NP (DT any)) (PP (IN of) (NP (NP (DT the) (NNS things)) (PP (IN in) (NP (DT this) (NN report)))))))))) (, ,) ('' '') (NP (DT the) (NN chief)) (VP (VBD said) (NP (DT a) (JJ few) (NNS hours)) (PP (IN after) (NP (PRP$ its) (NN release)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the things in this report" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="things" />
            <token id="11" string="in" />
            <token id="12" string="this" />
            <token id="13" string="report" />
          </tokens>
        </chunking>
        <chunking id="2" string="said a few hours after its release" type="VP">
          <tokens>
            <token id="18" string="said" />
            <token id="19" string="a" />
            <token id="20" string="few" />
            <token id="21" string="hours" />
            <token id="22" string="after" />
            <token id="23" string="its" />
            <token id="24" string="release" />
          </tokens>
        </chunking>
        <chunking id="3" string="the chief" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="chief" />
          </tokens>
        </chunking>
        <chunking id="4" string="any of the things in this report" type="NP">
          <tokens>
            <token id="7" string="any" />
            <token id="8" string="of" />
            <token id="9" string="the" />
            <token id="10" string="things" />
            <token id="11" string="in" />
            <token id="12" string="this" />
            <token id="13" string="report" />
          </tokens>
        </chunking>
        <chunking id="5" string="this report" type="NP">
          <tokens>
            <token id="12" string="this" />
            <token id="13" string="report" />
          </tokens>
        </chunking>
        <chunking id="6" string="its release" type="NP">
          <tokens>
            <token id="23" string="its" />
            <token id="24" string="release" />
          </tokens>
        </chunking>
        <chunking id="7" string="a few hours" type="NP">
          <tokens>
            <token id="19" string="a" />
            <token id="20" string="few" />
            <token id="21" string="hours" />
          </tokens>
        </chunking>
        <chunking id="8" string="any" type="NP">
          <tokens>
            <token id="7" string="any" />
          </tokens>
        </chunking>
        <chunking id="9" string="startled by any of the things in this report" type="VP">
          <tokens>
            <token id="5" string="startled" />
            <token id="6" string="by" />
            <token id="7" string="any" />
            <token id="8" string="of" />
            <token id="9" string="the" />
            <token id="10" string="things" />
            <token id="11" string="in" />
            <token id="12" string="this" />
            <token id="13" string="report" />
          </tokens>
        </chunking>
        <chunking id="10" string="the things" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="things" />
          </tokens>
        </chunking>
        <chunking id="11" string="We" type="NP">
          <tokens>
            <token id="2" string="We" />
          </tokens>
        </chunking>
        <chunking id="12" string="'re not startled by any of the things in this report" type="VP">
          <tokens>
            <token id="3" string="'re" />
            <token id="4" string="not" />
            <token id="5" string="startled" />
            <token id="6" string="by" />
            <token id="7" string="any" />
            <token id="8" string="of" />
            <token id="9" string="the" />
            <token id="10" string="things" />
            <token id="11" string="in" />
            <token id="12" string="this" />
            <token id="13" string="report" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="5">startled</governor>
          <dependent id="2">We</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="5">startled</governor>
          <dependent id="3">'re</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">startled</governor>
          <dependent id="4">not</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="18">said</governor>
          <dependent id="5">startled</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">any</governor>
          <dependent id="6">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">startled</governor>
          <dependent id="7">any</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">things</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">things</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">any</governor>
          <dependent id="10">things</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">report</governor>
          <dependent id="11">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">report</governor>
          <dependent id="12">this</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">things</governor>
          <dependent id="13">report</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">chief</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">said</governor>
          <dependent id="17">chief</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="18">said</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">hours</governor>
          <dependent id="19">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">hours</governor>
          <dependent id="20">few</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">said</governor>
          <dependent id="21">hours</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">release</governor>
          <dependent id="22">after</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="24">release</governor>
          <dependent id="23">its</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">said</governor>
          <dependent id="24">release</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="a few hours" type="DURATION" score="0.0">
          <tokens>
            <token id="19" string="a" />
            <token id="20" string="few" />
            <token id="21" string="hours" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="39" has_coreference="true">
      <content>He added that he has worked on his own to accomplish some of what the commission suggested, but has often been stymied by budget cuts.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="added" lemma="add" stem="ad" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="worked" lemma="work" stem="work" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="own" lemma="own" stem="own" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="accomplish" lemma="accomplish" stem="accomplish" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="commission" lemma="commission" stem="commiss" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="suggested" lemma="suggest" stem="suggest" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="often" lemma="often" stem="often" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="stymied" lemma="stymie" stem="stymi" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="budget" lemma="budget" stem="budget" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="cuts" lemma="cut" stem="cut" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VBD added) (SBAR (IN that) (S (NP (PRP he)) (VP (VBZ has) (VP (VBN worked) (PP (IN on) (NP (PRP$ his) (JJ own))) (S (VP (TO to) (VP (VB accomplish) (NP (NP (DT some)) (PP (IN of) (SBAR (WHNP (WP what)) (S (NP (DT the) (NN commission)) (VP (VP (VBD suggested)) (, ,) (CC but) (VP (VBZ has) (ADVP (RB often)) (VP (VBN been) (VP (VBN stymied) (PP (IN by) (NP (NN budget) (NNS cuts))))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="has worked on his own to accomplish some of what the commission suggested , but has often been stymied by budget cuts" type="VP">
          <tokens>
            <token id="5" string="has" />
            <token id="6" string="worked" />
            <token id="7" string="on" />
            <token id="8" string="his" />
            <token id="9" string="own" />
            <token id="10" string="to" />
            <token id="11" string="accomplish" />
            <token id="12" string="some" />
            <token id="13" string="of" />
            <token id="14" string="what" />
            <token id="15" string="the" />
            <token id="16" string="commission" />
            <token id="17" string="suggested" />
            <token id="18" string="," />
            <token id="19" string="but" />
            <token id="20" string="has" />
            <token id="21" string="often" />
            <token id="22" string="been" />
            <token id="23" string="stymied" />
            <token id="24" string="by" />
            <token id="25" string="budget" />
            <token id="26" string="cuts" />
          </tokens>
        </chunking>
        <chunking id="2" string="the commission" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="commission" />
          </tokens>
        </chunking>
        <chunking id="3" string="has often been stymied by budget cuts" type="VP">
          <tokens>
            <token id="20" string="has" />
            <token id="21" string="often" />
            <token id="22" string="been" />
            <token id="23" string="stymied" />
            <token id="24" string="by" />
            <token id="25" string="budget" />
            <token id="26" string="cuts" />
          </tokens>
        </chunking>
        <chunking id="4" string="budget cuts" type="NP">
          <tokens>
            <token id="25" string="budget" />
            <token id="26" string="cuts" />
          </tokens>
        </chunking>
        <chunking id="5" string="some of what the commission suggested , but has often been stymied by budget cuts" type="NP">
          <tokens>
            <token id="12" string="some" />
            <token id="13" string="of" />
            <token id="14" string="what" />
            <token id="15" string="the" />
            <token id="16" string="commission" />
            <token id="17" string="suggested" />
            <token id="18" string="," />
            <token id="19" string="but" />
            <token id="20" string="has" />
            <token id="21" string="often" />
            <token id="22" string="been" />
            <token id="23" string="stymied" />
            <token id="24" string="by" />
            <token id="25" string="budget" />
            <token id="26" string="cuts" />
          </tokens>
        </chunking>
        <chunking id="6" string="suggested , but has often been stymied by budget cuts" type="VP">
          <tokens>
            <token id="17" string="suggested" />
            <token id="18" string="," />
            <token id="19" string="but" />
            <token id="20" string="has" />
            <token id="21" string="often" />
            <token id="22" string="been" />
            <token id="23" string="stymied" />
            <token id="24" string="by" />
            <token id="25" string="budget" />
            <token id="26" string="cuts" />
          </tokens>
        </chunking>
        <chunking id="7" string="some" type="NP">
          <tokens>
            <token id="12" string="some" />
          </tokens>
        </chunking>
        <chunking id="8" string="worked on his own to accomplish some of what the commission suggested , but has often been stymied by budget cuts" type="VP">
          <tokens>
            <token id="6" string="worked" />
            <token id="7" string="on" />
            <token id="8" string="his" />
            <token id="9" string="own" />
            <token id="10" string="to" />
            <token id="11" string="accomplish" />
            <token id="12" string="some" />
            <token id="13" string="of" />
            <token id="14" string="what" />
            <token id="15" string="the" />
            <token id="16" string="commission" />
            <token id="17" string="suggested" />
            <token id="18" string="," />
            <token id="19" string="but" />
            <token id="20" string="has" />
            <token id="21" string="often" />
            <token id="22" string="been" />
            <token id="23" string="stymied" />
            <token id="24" string="by" />
            <token id="25" string="budget" />
            <token id="26" string="cuts" />
          </tokens>
        </chunking>
        <chunking id="9" string="stymied by budget cuts" type="VP">
          <tokens>
            <token id="23" string="stymied" />
            <token id="24" string="by" />
            <token id="25" string="budget" />
            <token id="26" string="cuts" />
          </tokens>
        </chunking>
        <chunking id="10" string="his own" type="NP">
          <tokens>
            <token id="8" string="his" />
            <token id="9" string="own" />
          </tokens>
        </chunking>
        <chunking id="11" string="suggested" type="VP">
          <tokens>
            <token id="17" string="suggested" />
          </tokens>
        </chunking>
        <chunking id="12" string="that he has worked on his own to accomplish some of what the commission suggested , but has often been stymied by budget cuts" type="SBAR">
          <tokens>
            <token id="3" string="that" />
            <token id="4" string="he" />
            <token id="5" string="has" />
            <token id="6" string="worked" />
            <token id="7" string="on" />
            <token id="8" string="his" />
            <token id="9" string="own" />
            <token id="10" string="to" />
            <token id="11" string="accomplish" />
            <token id="12" string="some" />
            <token id="13" string="of" />
            <token id="14" string="what" />
            <token id="15" string="the" />
            <token id="16" string="commission" />
            <token id="17" string="suggested" />
            <token id="18" string="," />
            <token id="19" string="but" />
            <token id="20" string="has" />
            <token id="21" string="often" />
            <token id="22" string="been" />
            <token id="23" string="stymied" />
            <token id="24" string="by" />
            <token id="25" string="budget" />
            <token id="26" string="cuts" />
          </tokens>
        </chunking>
        <chunking id="13" string="been stymied by budget cuts" type="VP">
          <tokens>
            <token id="22" string="been" />
            <token id="23" string="stymied" />
            <token id="24" string="by" />
            <token id="25" string="budget" />
            <token id="26" string="cuts" />
          </tokens>
        </chunking>
        <chunking id="14" string="accomplish some of what the commission suggested , but has often been stymied by budget cuts" type="VP">
          <tokens>
            <token id="11" string="accomplish" />
            <token id="12" string="some" />
            <token id="13" string="of" />
            <token id="14" string="what" />
            <token id="15" string="the" />
            <token id="16" string="commission" />
            <token id="17" string="suggested" />
            <token id="18" string="," />
            <token id="19" string="but" />
            <token id="20" string="has" />
            <token id="21" string="often" />
            <token id="22" string="been" />
            <token id="23" string="stymied" />
            <token id="24" string="by" />
            <token id="25" string="budget" />
            <token id="26" string="cuts" />
          </tokens>
        </chunking>
        <chunking id="15" string="to accomplish some of what the commission suggested , but has often been stymied by budget cuts" type="VP">
          <tokens>
            <token id="10" string="to" />
            <token id="11" string="accomplish" />
            <token id="12" string="some" />
            <token id="13" string="of" />
            <token id="14" string="what" />
            <token id="15" string="the" />
            <token id="16" string="commission" />
            <token id="17" string="suggested" />
            <token id="18" string="," />
            <token id="19" string="but" />
            <token id="20" string="has" />
            <token id="21" string="often" />
            <token id="22" string="been" />
            <token id="23" string="stymied" />
            <token id="24" string="by" />
            <token id="25" string="budget" />
            <token id="26" string="cuts" />
          </tokens>
        </chunking>
        <chunking id="16" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="17" string="added that he has worked on his own to accomplish some of what the commission suggested , but has often been stymied by budget cuts" type="VP">
          <tokens>
            <token id="2" string="added" />
            <token id="3" string="that" />
            <token id="4" string="he" />
            <token id="5" string="has" />
            <token id="6" string="worked" />
            <token id="7" string="on" />
            <token id="8" string="his" />
            <token id="9" string="own" />
            <token id="10" string="to" />
            <token id="11" string="accomplish" />
            <token id="12" string="some" />
            <token id="13" string="of" />
            <token id="14" string="what" />
            <token id="15" string="the" />
            <token id="16" string="commission" />
            <token id="17" string="suggested" />
            <token id="18" string="," />
            <token id="19" string="but" />
            <token id="20" string="has" />
            <token id="21" string="often" />
            <token id="22" string="been" />
            <token id="23" string="stymied" />
            <token id="24" string="by" />
            <token id="25" string="budget" />
            <token id="26" string="cuts" />
          </tokens>
        </chunking>
        <chunking id="18" string="he" type="NP">
          <tokens>
            <token id="4" string="he" />
          </tokens>
        </chunking>
        <chunking id="19" string="what the commission suggested , but has often been stymied by budget cuts" type="SBAR">
          <tokens>
            <token id="14" string="what" />
            <token id="15" string="the" />
            <token id="16" string="commission" />
            <token id="17" string="suggested" />
            <token id="18" string="," />
            <token id="19" string="but" />
            <token id="20" string="has" />
            <token id="21" string="often" />
            <token id="22" string="been" />
            <token id="23" string="stymied" />
            <token id="24" string="by" />
            <token id="25" string="budget" />
            <token id="26" string="cuts" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">added</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">added</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">worked</governor>
          <dependent id="3">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">worked</governor>
          <dependent id="4">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">worked</governor>
          <dependent id="5">has</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">added</governor>
          <dependent id="6">worked</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">own</governor>
          <dependent id="7">on</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="9">own</governor>
          <dependent id="8">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">worked</governor>
          <dependent id="9">own</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">accomplish</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">worked</governor>
          <dependent id="11">accomplish</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">accomplish</governor>
          <dependent id="12">some</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">suggested</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">suggested</governor>
          <dependent id="14">what</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">commission</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">suggested</governor>
          <dependent id="16">commission</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="12">some</governor>
          <dependent id="17">suggested</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="17">suggested</governor>
          <dependent id="19">but</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="23">stymied</governor>
          <dependent id="20">has</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="23">stymied</governor>
          <dependent id="21">often</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="23">stymied</governor>
          <dependent id="22">been</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">suggested</governor>
          <dependent id="23">stymied</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">cuts</governor>
          <dependent id="24">by</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">cuts</governor>
          <dependent id="25">budget</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">stymied</governor>
          <dependent id="26">cuts</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="40" has_coreference="true">
      <content>As for the recommendation that he step down, the embattled chief said he will wait until the voters sanction a move to limit a police chief&amp;apost;s tenure.</content>
      <tokens>
        <token id="1" string="As" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="recommendation" lemma="recommendation" stem="recommend" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="step" lemma="step" stem="step" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="down" lemma="down" stem="down" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="embattled" lemma="embattled" stem="embattl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="chief" lemma="chief" stem="chief" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="wait" lemma="wait" stem="wait" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="until" lemma="until" stem="until" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="voters" lemma="voter" stem="voter" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="sanction" lemma="sanction" stem="sanction" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="move" lemma="move" stem="move" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="limit" lemma="limit" stem="limit" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="chief" lemma="chief" stem="chief" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="tenure" lemma="tenure" stem="tenur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN As) (IN for) (NP (NP (DT the) (NN recommendation)) (SBAR (IN that) (S (NP (PRP he)) (VP (VB step) (PRT (RP down))))))) (, ,) (NP (DT the) (JJ embattled) (NN chief)) (VP (VBD said) (SBAR (S (NP (PRP he)) (VP (MD will) (VP (VB wait) (PP (IN until) (NP (NP (DT the) (NNS voters) (NN sanction)) (NP (DT a) (NN move)))) (S (VP (TO to) (VP (VB limit) (NP (NP (DT a) (NN police) (NN chief) (POS 's)) (NN tenure)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the recommendation" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="recommendation" />
          </tokens>
        </chunking>
        <chunking id="2" string="he will wait until the voters sanction a move to limit a police chief 's tenure" type="SBAR">
          <tokens>
            <token id="14" string="he" />
            <token id="15" string="will" />
            <token id="16" string="wait" />
            <token id="17" string="until" />
            <token id="18" string="the" />
            <token id="19" string="voters" />
            <token id="20" string="sanction" />
            <token id="21" string="a" />
            <token id="22" string="move" />
            <token id="23" string="to" />
            <token id="24" string="limit" />
            <token id="25" string="a" />
            <token id="26" string="police" />
            <token id="27" string="chief" />
            <token id="28" string="'s" />
            <token id="29" string="tenure" />
          </tokens>
        </chunking>
        <chunking id="3" string="the embattled chief" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="embattled" />
            <token id="12" string="chief" />
          </tokens>
        </chunking>
        <chunking id="4" string="the voters sanction a move" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="voters" />
            <token id="20" string="sanction" />
            <token id="21" string="a" />
            <token id="22" string="move" />
          </tokens>
        </chunking>
        <chunking id="5" string="a police chief 's" type="NP">
          <tokens>
            <token id="25" string="a" />
            <token id="26" string="police" />
            <token id="27" string="chief" />
            <token id="28" string="'s" />
          </tokens>
        </chunking>
        <chunking id="6" string="will wait until the voters sanction a move to limit a police chief 's tenure" type="VP">
          <tokens>
            <token id="15" string="will" />
            <token id="16" string="wait" />
            <token id="17" string="until" />
            <token id="18" string="the" />
            <token id="19" string="voters" />
            <token id="20" string="sanction" />
            <token id="21" string="a" />
            <token id="22" string="move" />
            <token id="23" string="to" />
            <token id="24" string="limit" />
            <token id="25" string="a" />
            <token id="26" string="police" />
            <token id="27" string="chief" />
            <token id="28" string="'s" />
            <token id="29" string="tenure" />
          </tokens>
        </chunking>
        <chunking id="7" string="said he will wait until the voters sanction a move to limit a police chief 's tenure" type="VP">
          <tokens>
            <token id="13" string="said" />
            <token id="14" string="he" />
            <token id="15" string="will" />
            <token id="16" string="wait" />
            <token id="17" string="until" />
            <token id="18" string="the" />
            <token id="19" string="voters" />
            <token id="20" string="sanction" />
            <token id="21" string="a" />
            <token id="22" string="move" />
            <token id="23" string="to" />
            <token id="24" string="limit" />
            <token id="25" string="a" />
            <token id="26" string="police" />
            <token id="27" string="chief" />
            <token id="28" string="'s" />
            <token id="29" string="tenure" />
          </tokens>
        </chunking>
        <chunking id="8" string="a move" type="NP">
          <tokens>
            <token id="21" string="a" />
            <token id="22" string="move" />
          </tokens>
        </chunking>
        <chunking id="9" string="that he step down" type="SBAR">
          <tokens>
            <token id="5" string="that" />
            <token id="6" string="he" />
            <token id="7" string="step" />
            <token id="8" string="down" />
          </tokens>
        </chunking>
        <chunking id="10" string="to limit a police chief 's tenure" type="VP">
          <tokens>
            <token id="23" string="to" />
            <token id="24" string="limit" />
            <token id="25" string="a" />
            <token id="26" string="police" />
            <token id="27" string="chief" />
            <token id="28" string="'s" />
            <token id="29" string="tenure" />
          </tokens>
        </chunking>
        <chunking id="11" string="a police chief 's tenure" type="NP">
          <tokens>
            <token id="25" string="a" />
            <token id="26" string="police" />
            <token id="27" string="chief" />
            <token id="28" string="'s" />
            <token id="29" string="tenure" />
          </tokens>
        </chunking>
        <chunking id="12" string="step down" type="VP">
          <tokens>
            <token id="7" string="step" />
            <token id="8" string="down" />
          </tokens>
        </chunking>
        <chunking id="13" string="wait until the voters sanction a move to limit a police chief 's tenure" type="VP">
          <tokens>
            <token id="16" string="wait" />
            <token id="17" string="until" />
            <token id="18" string="the" />
            <token id="19" string="voters" />
            <token id="20" string="sanction" />
            <token id="21" string="a" />
            <token id="22" string="move" />
            <token id="23" string="to" />
            <token id="24" string="limit" />
            <token id="25" string="a" />
            <token id="26" string="police" />
            <token id="27" string="chief" />
            <token id="28" string="'s" />
            <token id="29" string="tenure" />
          </tokens>
        </chunking>
        <chunking id="14" string="he" type="NP">
          <tokens>
            <token id="6" string="he" />
          </tokens>
        </chunking>
        <chunking id="15" string="the voters sanction" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="voters" />
            <token id="20" string="sanction" />
          </tokens>
        </chunking>
        <chunking id="16" string="limit a police chief 's tenure" type="VP">
          <tokens>
            <token id="24" string="limit" />
            <token id="25" string="a" />
            <token id="26" string="police" />
            <token id="27" string="chief" />
            <token id="28" string="'s" />
            <token id="29" string="tenure" />
          </tokens>
        </chunking>
        <chunking id="17" string="the recommendation that he step down" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="recommendation" />
            <token id="5" string="that" />
            <token id="6" string="he" />
            <token id="7" string="step" />
            <token id="8" string="down" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">recommendation</governor>
          <dependent id="1">As</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="1">As</governor>
          <dependent id="2">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">recommendation</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">said</governor>
          <dependent id="4">recommendation</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">step</governor>
          <dependent id="5">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">step</governor>
          <dependent id="6">he</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="4">recommendation</governor>
          <dependent id="7">step</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="7">step</governor>
          <dependent id="8">down</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">chief</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">chief</governor>
          <dependent id="11">embattled</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">said</governor>
          <dependent id="12">chief</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">wait</governor>
          <dependent id="14">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">wait</governor>
          <dependent id="15">will</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="13">said</governor>
          <dependent id="16">wait</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">sanction</governor>
          <dependent id="17">until</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">sanction</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">sanction</governor>
          <dependent id="19">voters</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">wait</governor>
          <dependent id="20">sanction</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">move</governor>
          <dependent id="21">a</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="20">sanction</governor>
          <dependent id="22">move</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="24">limit</governor>
          <dependent id="23">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="16">wait</governor>
          <dependent id="24">limit</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">chief</governor>
          <dependent id="25">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">chief</governor>
          <dependent id="26">police</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="29">tenure</governor>
          <dependent id="27">chief</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">chief</governor>
          <dependent id="28">'s</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="24">limit</governor>
          <dependent id="29">tenure</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="41" has_coreference="true">
      <content>Overall, Chief Gates added, &amp;quot;It&amp;apost;s a good report.</content>
      <tokens>
        <token id="1" string="Overall" lemma="overall" stem="overal" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Chief" lemma="Chief" stem="chief" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="false" is_refers="true" />
        <token id="4" string="Gates" lemma="Gates" stem="gate" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="5" string="added" lemma="add" stem="ad" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="good" lemma="good" stem="good" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="report" lemma="report" stem="report" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Overall)) (, ,) (NP (NNP Chief) (NNP Gates)) (VP (VBD added) (, ,) (`` ``) (S (NP (PRP It)) (VP (VBZ 's) (NP (DT a) (JJ good) (NN report))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Chief Gates" type="NP">
          <tokens>
            <token id="3" string="Chief" />
            <token id="4" string="Gates" />
          </tokens>
        </chunking>
        <chunking id="2" string="It" type="NP">
          <tokens>
            <token id="8" string="It" />
          </tokens>
        </chunking>
        <chunking id="3" string="a good report" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="good" />
            <token id="12" string="report" />
          </tokens>
        </chunking>
        <chunking id="4" string="added , `` It 's a good report" type="VP">
          <tokens>
            <token id="5" string="added" />
            <token id="6" string="," />
            <token id="7" string="&quot;" />
            <token id="8" string="It" />
            <token id="9" string="'s" />
            <token id="10" string="a" />
            <token id="11" string="good" />
            <token id="12" string="report" />
          </tokens>
        </chunking>
        <chunking id="5" string="'s a good report" type="VP">
          <tokens>
            <token id="9" string="'s" />
            <token id="10" string="a" />
            <token id="11" string="good" />
            <token id="12" string="report" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="5">added</governor>
          <dependent id="1">Overall</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">Gates</governor>
          <dependent id="3">Chief</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">added</governor>
          <dependent id="4">Gates</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">added</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">report</governor>
          <dependent id="8">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="12">report</governor>
          <dependent id="9">'s</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">report</governor>
          <dependent id="10">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">report</governor>
          <dependent id="11">good</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">added</governor>
          <dependent id="12">report</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Gates" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Gates" />
          </tokens>
        </entity>
        <entity id="2" string="Chief" type="TITLE" score="0.0">
          <tokens>
            <token id="3" string="Chief" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="42" has_coreference="false">
      <content>There&amp;apost;s a lot of thoughtful recommendations.&amp;quot;</content>
      <tokens>
        <token id="1" string="There" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="lot" lemma="lot" stem="lot" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="thoughtful" lemma="thoughtful" stem="thought" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="recommendations" lemma="recommendation" stem="recommend" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (EX There)) (VP (VBZ 's) (NP (NP (DT a) (NN lot)) (PP (IN of) (NP (JJ thoughtful) (NNS recommendations))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="There" type="NP">
          <tokens>
            <token id="1" string="There" />
          </tokens>
        </chunking>
        <chunking id="2" string="a lot of thoughtful recommendations" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="lot" />
            <token id="5" string="of" />
            <token id="6" string="thoughtful" />
            <token id="7" string="recommendations" />
          </tokens>
        </chunking>
        <chunking id="3" string="a lot" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="lot" />
          </tokens>
        </chunking>
        <chunking id="4" string="'s a lot of thoughtful recommendations" type="VP">
          <tokens>
            <token id="2" string="'s" />
            <token id="3" string="a" />
            <token id="4" string="lot" />
            <token id="5" string="of" />
            <token id="6" string="thoughtful" />
            <token id="7" string="recommendations" />
          </tokens>
        </chunking>
        <chunking id="5" string="thoughtful recommendations" type="NP">
          <tokens>
            <token id="6" string="thoughtful" />
            <token id="7" string="recommendations" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="expl">
          <governor id="2">'s</governor>
          <dependent id="1">There</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">lot</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="2">'s</governor>
          <dependent id="4">lot</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">recommendations</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">recommendations</governor>
          <dependent id="6">thoughtful</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">lot</governor>
          <dependent id="7">recommendations</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="43" has_coreference="true">
      <content>And the chief said he will stay to implement them.</content>
      <tokens>
        <token id="1" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="chief" lemma="chief" stem="chief" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="stay" lemma="stay" stem="stai" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="implement" lemma="implement" stem="implement" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC And) (NP (DT the) (NN chief)) (VP (VBD said) (SBAR (S (NP (PRP he)) (VP (MD will) (VP (VB stay) (S (VP (TO to) (VP (VB implement) (NP (PRP them)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the chief" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="chief" />
          </tokens>
        </chunking>
        <chunking id="2" string="said he will stay to implement them" type="VP">
          <tokens>
            <token id="4" string="said" />
            <token id="5" string="he" />
            <token id="6" string="will" />
            <token id="7" string="stay" />
            <token id="8" string="to" />
            <token id="9" string="implement" />
            <token id="10" string="them" />
          </tokens>
        </chunking>
        <chunking id="3" string="he will stay to implement them" type="SBAR">
          <tokens>
            <token id="5" string="he" />
            <token id="6" string="will" />
            <token id="7" string="stay" />
            <token id="8" string="to" />
            <token id="9" string="implement" />
            <token id="10" string="them" />
          </tokens>
        </chunking>
        <chunking id="4" string="will stay to implement them" type="VP">
          <tokens>
            <token id="6" string="will" />
            <token id="7" string="stay" />
            <token id="8" string="to" />
            <token id="9" string="implement" />
            <token id="10" string="them" />
          </tokens>
        </chunking>
        <chunking id="5" string="stay to implement them" type="VP">
          <tokens>
            <token id="7" string="stay" />
            <token id="8" string="to" />
            <token id="9" string="implement" />
            <token id="10" string="them" />
          </tokens>
        </chunking>
        <chunking id="6" string="implement them" type="VP">
          <tokens>
            <token id="9" string="implement" />
            <token id="10" string="them" />
          </tokens>
        </chunking>
        <chunking id="7" string="to implement them" type="VP">
          <tokens>
            <token id="8" string="to" />
            <token id="9" string="implement" />
            <token id="10" string="them" />
          </tokens>
        </chunking>
        <chunking id="8" string="he" type="NP">
          <tokens>
            <token id="5" string="he" />
          </tokens>
        </chunking>
        <chunking id="9" string="them" type="NP">
          <tokens>
            <token id="10" string="them" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="4">said</governor>
          <dependent id="1">And</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">chief</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">said</governor>
          <dependent id="3">chief</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">stay</governor>
          <dependent id="5">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">stay</governor>
          <dependent id="6">will</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">said</governor>
          <dependent id="7">stay</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">implement</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="7">stay</governor>
          <dependent id="9">implement</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">implement</governor>
          <dependent id="10">them</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="44" has_coreference="true">
      <content>Mayor Bradley said he hopes that Chief Gates&amp;apost;s will &amp;quot;follow the commission&amp;apost;s recommendations&amp;quot; to &amp;quot;commence the transition to a new chief of police.&amp;quot;</content>
      <tokens>
        <token id="1" string="Mayor" lemma="Mayor" stem="mayor" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="true" is_refers="false" />
        <token id="2" string="Bradley" lemma="Bradley" stem="bradlei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="hopes" lemma="hope" stem="hope" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Chief" lemma="Chief" stem="chief" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="false" is_refers="true" />
        <token id="8" string="Gates" lemma="Gates" stem="gate" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="9" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="follow" lemma="follow" stem="follow" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="commission" lemma="commission" stem="commiss" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="recommendations" lemma="recommendation" stem="recommend" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="commence" lemma="commence" stem="commenc" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="transition" lemma="transition" stem="transit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="new" lemma="new" stem="new" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="chief" lemma="chief" stem="chief" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Mayor) (NNP Bradley)) (VP (VBD said) (SBAR (S (NP (PRP he)) (VP (VBZ hopes) (SBAR (IN that) (S (NP (NNP Chief) (NNP Gates) (POS 's)) (VP (MD will) (`` ``) (VP (VB follow) (NP (NP (DT the) (NN commission) (POS 's)) (NNS recommendations)) ('' '') (S (VP (TO to) (`` ``) (VP (VB commence) (NP (DT the) (NN transition)) (PP (TO to) (NP (NP (DT a) (JJ new) (NN chief)) (PP (IN of) (NP (NN police)))))))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="to `` commence the transition to a new chief of police" type="VP">
          <tokens>
            <token id="18" string="to" />
            <token id="19" string="&quot;" />
            <token id="20" string="commence" />
            <token id="21" string="the" />
            <token id="22" string="transition" />
            <token id="23" string="to" />
            <token id="24" string="a" />
            <token id="25" string="new" />
            <token id="26" string="chief" />
            <token id="27" string="of" />
            <token id="28" string="police" />
          </tokens>
        </chunking>
        <chunking id="2" string="he hopes that Chief Gates 's will `` follow the commission 's recommendations '' to `` commence the transition to a new chief of police" type="SBAR">
          <tokens>
            <token id="4" string="he" />
            <token id="5" string="hopes" />
            <token id="6" string="that" />
            <token id="7" string="Chief" />
            <token id="8" string="Gates" />
            <token id="9" string="'s" />
            <token id="10" string="will" />
            <token id="11" string="&quot;" />
            <token id="12" string="follow" />
            <token id="13" string="the" />
            <token id="14" string="commission" />
            <token id="15" string="'s" />
            <token id="16" string="recommendations" />
            <token id="17" string="&quot;" />
            <token id="18" string="to" />
            <token id="19" string="&quot;" />
            <token id="20" string="commence" />
            <token id="21" string="the" />
            <token id="22" string="transition" />
            <token id="23" string="to" />
            <token id="24" string="a" />
            <token id="25" string="new" />
            <token id="26" string="chief" />
            <token id="27" string="of" />
            <token id="28" string="police" />
          </tokens>
        </chunking>
        <chunking id="3" string="the transition" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="transition" />
          </tokens>
        </chunking>
        <chunking id="4" string="Mayor Bradley" type="NP">
          <tokens>
            <token id="1" string="Mayor" />
            <token id="2" string="Bradley" />
          </tokens>
        </chunking>
        <chunking id="5" string="commence the transition to a new chief of police" type="VP">
          <tokens>
            <token id="20" string="commence" />
            <token id="21" string="the" />
            <token id="22" string="transition" />
            <token id="23" string="to" />
            <token id="24" string="a" />
            <token id="25" string="new" />
            <token id="26" string="chief" />
            <token id="27" string="of" />
            <token id="28" string="police" />
          </tokens>
        </chunking>
        <chunking id="6" string="Chief Gates 's" type="NP">
          <tokens>
            <token id="7" string="Chief" />
            <token id="8" string="Gates" />
            <token id="9" string="'s" />
          </tokens>
        </chunking>
        <chunking id="7" string="will `` follow the commission 's recommendations '' to `` commence the transition to a new chief of police" type="VP">
          <tokens>
            <token id="10" string="will" />
            <token id="11" string="&quot;" />
            <token id="12" string="follow" />
            <token id="13" string="the" />
            <token id="14" string="commission" />
            <token id="15" string="'s" />
            <token id="16" string="recommendations" />
            <token id="17" string="&quot;" />
            <token id="18" string="to" />
            <token id="19" string="&quot;" />
            <token id="20" string="commence" />
            <token id="21" string="the" />
            <token id="22" string="transition" />
            <token id="23" string="to" />
            <token id="24" string="a" />
            <token id="25" string="new" />
            <token id="26" string="chief" />
            <token id="27" string="of" />
            <token id="28" string="police" />
          </tokens>
        </chunking>
        <chunking id="8" string="the commission 's" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="commission" />
            <token id="15" string="'s" />
          </tokens>
        </chunking>
        <chunking id="9" string="the commission 's recommendations" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="commission" />
            <token id="15" string="'s" />
            <token id="16" string="recommendations" />
          </tokens>
        </chunking>
        <chunking id="10" string="police" type="NP">
          <tokens>
            <token id="28" string="police" />
          </tokens>
        </chunking>
        <chunking id="11" string="said he hopes that Chief Gates 's will `` follow the commission 's recommendations '' to `` commence the transition to a new chief of police" type="VP">
          <tokens>
            <token id="3" string="said" />
            <token id="4" string="he" />
            <token id="5" string="hopes" />
            <token id="6" string="that" />
            <token id="7" string="Chief" />
            <token id="8" string="Gates" />
            <token id="9" string="'s" />
            <token id="10" string="will" />
            <token id="11" string="&quot;" />
            <token id="12" string="follow" />
            <token id="13" string="the" />
            <token id="14" string="commission" />
            <token id="15" string="'s" />
            <token id="16" string="recommendations" />
            <token id="17" string="&quot;" />
            <token id="18" string="to" />
            <token id="19" string="&quot;" />
            <token id="20" string="commence" />
            <token id="21" string="the" />
            <token id="22" string="transition" />
            <token id="23" string="to" />
            <token id="24" string="a" />
            <token id="25" string="new" />
            <token id="26" string="chief" />
            <token id="27" string="of" />
            <token id="28" string="police" />
          </tokens>
        </chunking>
        <chunking id="12" string="a new chief of police" type="NP">
          <tokens>
            <token id="24" string="a" />
            <token id="25" string="new" />
            <token id="26" string="chief" />
            <token id="27" string="of" />
            <token id="28" string="police" />
          </tokens>
        </chunking>
        <chunking id="13" string="that Chief Gates 's will `` follow the commission 's recommendations '' to `` commence the transition to a new chief of police" type="SBAR">
          <tokens>
            <token id="6" string="that" />
            <token id="7" string="Chief" />
            <token id="8" string="Gates" />
            <token id="9" string="'s" />
            <token id="10" string="will" />
            <token id="11" string="&quot;" />
            <token id="12" string="follow" />
            <token id="13" string="the" />
            <token id="14" string="commission" />
            <token id="15" string="'s" />
            <token id="16" string="recommendations" />
            <token id="17" string="&quot;" />
            <token id="18" string="to" />
            <token id="19" string="&quot;" />
            <token id="20" string="commence" />
            <token id="21" string="the" />
            <token id="22" string="transition" />
            <token id="23" string="to" />
            <token id="24" string="a" />
            <token id="25" string="new" />
            <token id="26" string="chief" />
            <token id="27" string="of" />
            <token id="28" string="police" />
          </tokens>
        </chunking>
        <chunking id="14" string="he" type="NP">
          <tokens>
            <token id="4" string="he" />
          </tokens>
        </chunking>
        <chunking id="15" string="a new chief" type="NP">
          <tokens>
            <token id="24" string="a" />
            <token id="25" string="new" />
            <token id="26" string="chief" />
          </tokens>
        </chunking>
        <chunking id="16" string="hopes that Chief Gates 's will `` follow the commission 's recommendations '' to `` commence the transition to a new chief of police" type="VP">
          <tokens>
            <token id="5" string="hopes" />
            <token id="6" string="that" />
            <token id="7" string="Chief" />
            <token id="8" string="Gates" />
            <token id="9" string="'s" />
            <token id="10" string="will" />
            <token id="11" string="&quot;" />
            <token id="12" string="follow" />
            <token id="13" string="the" />
            <token id="14" string="commission" />
            <token id="15" string="'s" />
            <token id="16" string="recommendations" />
            <token id="17" string="&quot;" />
            <token id="18" string="to" />
            <token id="19" string="&quot;" />
            <token id="20" string="commence" />
            <token id="21" string="the" />
            <token id="22" string="transition" />
            <token id="23" string="to" />
            <token id="24" string="a" />
            <token id="25" string="new" />
            <token id="26" string="chief" />
            <token id="27" string="of" />
            <token id="28" string="police" />
          </tokens>
        </chunking>
        <chunking id="17" string="follow the commission 's recommendations '' to `` commence the transition to a new chief of police" type="VP">
          <tokens>
            <token id="12" string="follow" />
            <token id="13" string="the" />
            <token id="14" string="commission" />
            <token id="15" string="'s" />
            <token id="16" string="recommendations" />
            <token id="17" string="&quot;" />
            <token id="18" string="to" />
            <token id="19" string="&quot;" />
            <token id="20" string="commence" />
            <token id="21" string="the" />
            <token id="22" string="transition" />
            <token id="23" string="to" />
            <token id="24" string="a" />
            <token id="25" string="new" />
            <token id="26" string="chief" />
            <token id="27" string="of" />
            <token id="28" string="police" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Bradley</governor>
          <dependent id="1">Mayor</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">said</governor>
          <dependent id="2">Bradley</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">hopes</governor>
          <dependent id="4">he</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">said</governor>
          <dependent id="5">hopes</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">follow</governor>
          <dependent id="6">that</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">Gates</governor>
          <dependent id="7">Chief</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">follow</governor>
          <dependent id="8">Gates</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">Gates</governor>
          <dependent id="9">'s</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">follow</governor>
          <dependent id="10">will</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">hopes</governor>
          <dependent id="12">follow</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">commission</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="16">recommendations</governor>
          <dependent id="14">commission</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">commission</governor>
          <dependent id="15">'s</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">follow</governor>
          <dependent id="16">recommendations</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="20">commence</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="12">follow</governor>
          <dependent id="20">commence</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">transition</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">commence</governor>
          <dependent id="22">transition</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">chief</governor>
          <dependent id="23">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">chief</governor>
          <dependent id="24">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">chief</governor>
          <dependent id="25">new</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">commence</governor>
          <dependent id="26">chief</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">police</governor>
          <dependent id="27">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">chief</governor>
          <dependent id="28">police</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Gates" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Gates" />
          </tokens>
        </entity>
        <entity id="2" string="Bradley" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Bradley" />
          </tokens>
        </entity>
        <entity id="3" string="Chief" type="TITLE" score="0.0">
          <tokens>
            <token id="7" string="Chief" />
          </tokens>
        </entity>
        <entity id="4" string="Mayor" type="TITLE" score="0.0">
          <tokens>
            <token id="1" string="Mayor" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="45" has_coreference="true">
      <content>The mayor, who appointed Gates but lacks the authority to fire him, has previously called for Chief Gates&amp;apost;s resignation.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="mayor" lemma="mayor" stem="mayor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="appointed" lemma="appoint" stem="appoint" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="Gates" lemma="Gates" stem="gate" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="lacks" lemma="lack" stem="lack" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="authority" lemma="authority" stem="author" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="fire" lemma="fire" stem="fire" pos="VB" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="13" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="previously" lemma="previously" stem="previous" pos="RB" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="17" string="called" lemma="call" stem="call" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="Chief" lemma="Chief" stem="chief" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="false" is_refers="true" />
        <token id="20" string="Gates" lemma="Gates" stem="gate" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="21" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="resignation" lemma="resignation" stem="resign" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (NN mayor)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VP (VBD appointed) (NP (NNP Gates))) (CC but) (VP (VBZ lacks) (NP (DT the) (NN authority) (S (VP (TO to) (VP (VB fire) (NP (PRP him)))))))))) (, ,)) (VP (VBZ has) (ADVP (RB previously)) (VP (VBN called) (PP (IN for) (NP (NP (NNP Chief) (NNP Gates) (POS 's)) (NN resignation))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="him" type="NP">
          <tokens>
            <token id="13" string="him" />
          </tokens>
        </chunking>
        <chunking id="2" string="Chief Gates 's resignation" type="NP">
          <tokens>
            <token id="19" string="Chief" />
            <token id="20" string="Gates" />
            <token id="21" string="'s" />
            <token id="22" string="resignation" />
          </tokens>
        </chunking>
        <chunking id="3" string="Chief Gates 's" type="NP">
          <tokens>
            <token id="19" string="Chief" />
            <token id="20" string="Gates" />
            <token id="21" string="'s" />
          </tokens>
        </chunking>
        <chunking id="4" string="lacks the authority to fire him" type="VP">
          <tokens>
            <token id="8" string="lacks" />
            <token id="9" string="the" />
            <token id="10" string="authority" />
            <token id="11" string="to" />
            <token id="12" string="fire" />
            <token id="13" string="him" />
          </tokens>
        </chunking>
        <chunking id="5" string="called for Chief Gates 's resignation" type="VP">
          <tokens>
            <token id="17" string="called" />
            <token id="18" string="for" />
            <token id="19" string="Chief" />
            <token id="20" string="Gates" />
            <token id="21" string="'s" />
            <token id="22" string="resignation" />
          </tokens>
        </chunking>
        <chunking id="6" string="The mayor , who appointed Gates but lacks the authority to fire him ," type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="mayor" />
            <token id="3" string="," />
            <token id="4" string="who" />
            <token id="5" string="appointed" />
            <token id="6" string="Gates" />
            <token id="7" string="but" />
            <token id="8" string="lacks" />
            <token id="9" string="the" />
            <token id="10" string="authority" />
            <token id="11" string="to" />
            <token id="12" string="fire" />
            <token id="13" string="him" />
            <token id="14" string="," />
          </tokens>
        </chunking>
        <chunking id="7" string="fire him" type="VP">
          <tokens>
            <token id="12" string="fire" />
            <token id="13" string="him" />
          </tokens>
        </chunking>
        <chunking id="8" string="Gates" type="NP">
          <tokens>
            <token id="6" string="Gates" />
          </tokens>
        </chunking>
        <chunking id="9" string="has previously called for Chief Gates 's resignation" type="VP">
          <tokens>
            <token id="15" string="has" />
            <token id="16" string="previously" />
            <token id="17" string="called" />
            <token id="18" string="for" />
            <token id="19" string="Chief" />
            <token id="20" string="Gates" />
            <token id="21" string="'s" />
            <token id="22" string="resignation" />
          </tokens>
        </chunking>
        <chunking id="10" string="to fire him" type="VP">
          <tokens>
            <token id="11" string="to" />
            <token id="12" string="fire" />
            <token id="13" string="him" />
          </tokens>
        </chunking>
        <chunking id="11" string="The mayor" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="mayor" />
          </tokens>
        </chunking>
        <chunking id="12" string="the authority to fire him" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="authority" />
            <token id="11" string="to" />
            <token id="12" string="fire" />
            <token id="13" string="him" />
          </tokens>
        </chunking>
        <chunking id="13" string="who appointed Gates but lacks the authority to fire him" type="SBAR">
          <tokens>
            <token id="4" string="who" />
            <token id="5" string="appointed" />
            <token id="6" string="Gates" />
            <token id="7" string="but" />
            <token id="8" string="lacks" />
            <token id="9" string="the" />
            <token id="10" string="authority" />
            <token id="11" string="to" />
            <token id="12" string="fire" />
            <token id="13" string="him" />
          </tokens>
        </chunking>
        <chunking id="14" string="appointed Gates" type="VP">
          <tokens>
            <token id="5" string="appointed" />
            <token id="6" string="Gates" />
          </tokens>
        </chunking>
        <chunking id="15" string="appointed Gates but lacks the authority to fire him" type="VP">
          <tokens>
            <token id="5" string="appointed" />
            <token id="6" string="Gates" />
            <token id="7" string="but" />
            <token id="8" string="lacks" />
            <token id="9" string="the" />
            <token id="10" string="authority" />
            <token id="11" string="to" />
            <token id="12" string="fire" />
            <token id="13" string="him" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">mayor</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">called</governor>
          <dependent id="2">mayor</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">appointed</governor>
          <dependent id="4">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="2">mayor</governor>
          <dependent id="5">appointed</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">appointed</governor>
          <dependent id="6">Gates</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">appointed</governor>
          <dependent id="7">but</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">appointed</governor>
          <dependent id="8">lacks</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">authority</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">lacks</governor>
          <dependent id="10">authority</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">fire</governor>
          <dependent id="11">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="10">authority</governor>
          <dependent id="12">fire</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">fire</governor>
          <dependent id="13">him</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="17">called</governor>
          <dependent id="15">has</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="17">called</governor>
          <dependent id="16">previously</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="17">called</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">resignation</governor>
          <dependent id="18">for</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">Gates</governor>
          <dependent id="19">Chief</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="22">resignation</governor>
          <dependent id="20">Gates</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">Gates</governor>
          <dependent id="21">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">called</governor>
          <dependent id="22">resignation</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="previously" type="DATE" score="0.0">
          <tokens>
            <token id="16" string="previously" />
          </tokens>
        </entity>
        <entity id="2" string="Chief" type="TITLE" score="0.0">
          <tokens>
            <token id="19" string="Chief" />
          </tokens>
        </entity>
        <entity id="3" string="fire" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="12" string="fire" />
          </tokens>
        </entity>
      </entities>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="2" type="NOMINAL">
      <referenced ids_tokens="2-3" string="the commission" id_sentence="1" />
      <mentions>
        <mention ids_tokens="2-4" string="the commission's" id_sentence="13" />
        <mention ids_tokens="1" string="It" id_sentence="14" />
        <mention ids_tokens="1-3" string="The commission's" id_sentence="24" />
        <mention ids_tokens="3-5" string="the commission's" id_sentence="27" />
        <mention ids_tokens="27-29" string="the commission's" id_sentence="37" />
        <mention ids_tokens="13-15" string="the commission's" id_sentence="44" />
      </mentions>
    </coreference>
    <coreference id="3" type="PROPER">
      <referenced ids_tokens="30-31" string="Mr. Gates" id_sentence="1" />
      <mentions>
        <mention ids_tokens="12-13" string="Chief Gates" id_sentence="19" />
        <mention ids_tokens="15-17" string="Chief Gates's" id_sentence="30" />
        <mention ids_tokens="8" string="him" id_sentence="32" />
        <mention ids_tokens="27" string="his" id_sentence="32" />
        <mention ids_tokens="34" string="His" id_sentence="32" />
        <mention ids_tokens="13-14" string="Chief Gates" id_sentence="37" />
        <mention ids_tokens="23" string="he" id_sentence="37" />
        <mention ids_tokens="3-4" string="Chief Gates" id_sentence="41" />
        <mention ids_tokens="7-9" string="Chief Gates's" id_sentence="44" />
        <mention ids_tokens="6" string="Gates" id_sentence="45" />
        <mention ids_tokens="13" string="him" id_sentence="45" />
        <mention ids_tokens="19-21" string="Chief Gates's" id_sentence="45" />
      </mentions>
    </coreference>
    <coreference id="5" type="NOMINAL">
      <referenced ids_tokens="45-46-47" string="a transition period" id_sentence="1" />
      <mentions>
        <mention ids_tokens="23" string="I" id_sentence="2" />
      </mentions>
    </coreference>
    <coreference id="6" type="NOMINAL">
      <referenced ids_tokens="2-3" string="the chief" id_sentence="2" />
      <mentions>
        <mention ids_tokens="16-18" string="the chief's" id_sentence="25" />
        <mention ids_tokens="1" string="He" id_sentence="39" />
        <mention ids_tokens="4" string="he" id_sentence="39" />
        <mention ids_tokens="8" string="his" id_sentence="39" />
        <mention ids_tokens="6" string="he" id_sentence="40" />
        <mention ids_tokens="14" string="he" id_sentence="40" />
        <mention ids_tokens="5" string="he" id_sentence="43" />
      </mentions>
    </coreference>
    <coreference id="7" type="NOMINAL">
      <referenced ids_tokens="13-14-15-16-17" string="community leaders for his ouster" id_sentence="2" />
      <mentions>
        <mention ids_tokens="11-12" string="community leaders" id_sentence="28" />
      </mentions>
    </coreference>
    <coreference id="8" type="PROPER">
      <referenced ids_tokens="1-2-3-4-5-6-7-8-9-10" string="Nearly one-quarter of 650 officers responding to a commission survey" id_sentence="3" />
      <mentions>
        <mention ids_tokens="31-32" string="me a" id_sentence="5" />
      </mentions>
    </coreference>
    <coreference id="9" type="NOMINAL">
      <referenced ids_tokens="1-2" string="Minority officers" id_sentence="35" />
      <mentions>
        <mention ids_tokens="20-23" string="officers toward minority citizens" id_sentence="3" />
      </mentions>
    </coreference>
    <coreference id="11" type="NOMINAL">
      <referenced ids_tokens="1" string="Officers" id_sentence="5" />
      <mentions>
        <mention ids_tokens="38" string="their" id_sentence="8" />
        <mention ids_tokens="49" string="they" id_sentence="8" />
        <mention ids_tokens="16-23" string="officers who violate the rules governing excessive force" id_sentence="31" />
      </mentions>
    </coreference>
    <coreference id="12" type="NOMINAL">
      <referenced ids_tokens="13-14-15-16-17-18" string="evidence of a &quot; significant breakdown" id_sentence="6" />
      <mentions>
        <mention ids_tokens="28" string="I" id_sentence="5" />
      </mentions>
    </coreference>
    <coreference id="13" type="NOMINAL">
      <referenced ids_tokens="4-5-6-7-8-9-10-11-12-13-14-15-16-17-18-19-20-21-22-23-24" string="no effort to monitor or control these messages , evidence of a &quot; significant breakdown in the department 's management responsibility" id_sentence="6" />
      <mentions>
        <mention ids_tokens="2-3" string="This report" id_sentence="9" />
        <mention ids_tokens="6-13" string="a must-read for police chiefs around the country" id_sentence="9" />
        <mention ids_tokens="12-13" string="this report" id_sentence="38" />
        <mention ids_tokens="23" string="its" id_sentence="38" />
      </mentions>
    </coreference>
    <coreference id="14" type="NOMINAL">
      <referenced ids_tokens="20-21-22" string="the department 's" id_sentence="6" />
      <mentions>
        <mention ids_tokens="20-21" string="the department" id_sentence="8" />
        <mention ids_tokens="17-18" string="the department" id_sentence="13" />
        <mention ids_tokens="22-28" string="the department that have come to light" id_sentence="23" />
        <mention ids_tokens="16-17" string="the department" id_sentence="33" />
      </mentions>
    </coreference>
    <coreference id="17" type="NOMINAL">
      <referenced ids_tokens="10-11-12" string="the force 's" id_sentence="8" />
      <mentions>
        <mention ids_tokens="15-16" string="the force" id_sentence="36" />
      </mentions>
    </coreference>
    <coreference id="18" type="NOMINAL">
      <referenced ids_tokens="24-25-26-27-28-29-30-31-32-33-34-35-36-37-38-39-40-41-42-43-44-45-46-47-48-49-50" string="the &quot; community-based &quot; policing style that encourages officers to spend less time in their cars and more time interacting with citizens in the communities they serve" id_sentence="8" />
      <mentions>
        <mention ids_tokens="25" string="time" id_sentence="33" />
      </mentions>
    </coreference>
    <coreference id="19" type="NOMINAL">
      <referenced ids_tokens="48-49" string="the citizens" id_sentence="32" />
      <mentions>
        <mention ids_tokens="45-50" string="citizens in the communities they serve" id_sentence="8" />
        <mention ids_tokens="17" string="citizens" id_sentence="15" />
        <mention ids_tokens="31" string="citizens" id_sentence="23" />
      </mentions>
    </coreference>
    <coreference id="20" type="PROPER">
      <referenced ids_tokens="17-18" string="Hubert Williams" id_sentence="9" />
      <mentions>
        <mention ids_tokens="1-2" string="Mr. Williams" id_sentence="11" />
      </mentions>
    </coreference>
    <coreference id="22" type="NOMINAL">
      <referenced ids_tokens="9-10-11-12-13" string="police chiefs around the country" id_sentence="9" />
      <mentions>
        <mention ids_tokens="7" string="our" id_sentence="12" />
      </mentions>
    </coreference>
    <coreference id="27" type="NOMINAL">
      <referenced ids_tokens="2-3-4-5-6-7-8-9-10-11-12-13-14-15-16" string="the commission 's recommendations are : -- A commission appointed by the mayor that oversees" id_sentence="13" />
      <mentions>
        <mention ids_tokens="1-4" string="The commission's recommendations" id_sentence="24" />
        <mention ids_tokens="13-16" string="the commission's recommendations" id_sentence="44" />
      </mentions>
    </coreference>
    <coreference id="28" type="PROPER">
      <referenced ids_tokens="1" string="Mayor" id_sentence="44" />
      <mentions>
        <mention ids_tokens="13-16" string="the mayor that oversees" id_sentence="13" />
        <mention ids_tokens="9-10" string="the mayor" id_sentence="20" />
        <mention ids_tokens="1-2" string="The mayor" id_sentence="45" />
      </mentions>
    </coreference>
    <coreference id="29" type="NOMINAL">
      <referenced ids_tokens="30-31" string="citizen complaints" id_sentence="13" />
      <mentions>
        <mention ids_tokens="20" string="complaints" id_sentence="15" />
        <mention ids_tokens="19" string="complaints" id_sentence="16" />
      </mentions>
    </coreference>
    <coreference id="30" type="PROPER">
      <referenced ids_tokens="20-21" string="the LAPD" id_sentence="20" />
      <mentions>
        <mention ids_tokens="22" string="LAPD" id_sentence="15" />
        <mention ids_tokens="11" string="LAPD" id_sentence="35" />
      </mentions>
    </coreference>
    <coreference id="31" type="NOMINAL">
      <referenced ids_tokens="2-3-4-5-6-7-8-9-10-11-12-13-14-15-16-17-18-19-20-21-22-23-24-25-26-27-28-29" string="A &quot; major overhaul &quot; of the police disciplinary system and the process used by citizens to file complaints against LAPD officers , especially in excessive force cases" id_sentence="15" />
      <mentions>
        <mention ids_tokens="14-16" string="this major overhaul" id_sentence="18" />
      </mentions>
    </coreference>
    <coreference id="32" type="NOMINAL">
      <referenced ids_tokens="22-23" string="LAPD officers" id_sentence="15" />
      <mentions>
        <mention ids_tokens="13-14" string="officers'" id_sentence="16" />
      </mentions>
    </coreference>
    <coreference id="33" type="NOMINAL">
      <referenced ids_tokens="26-27" string="arrest statistics" id_sentence="17" />
      <mentions>
        <mention ids_tokens="45" string="I" id_sentence="18" />
      </mentions>
    </coreference>
    <coreference id="35" type="PROPER">
      <referenced ids_tokens="41-42" string="recent years" id_sentence="18" />
      <mentions>
        <mention ids_tokens="2-3" string="the years" id_sentence="20" />
      </mentions>
    </coreference>
    <coreference id="36" type="NOMINAL">
      <referenced ids_tokens="59-60" string="the changes" id_sentence="18" />
      <mentions>
        <mention ids_tokens="39" string="changes" id_sentence="19" />
      </mentions>
    </coreference>
    <coreference id="39" type="NOMINAL">
      <referenced ids_tokens="3-4-5-6-7-8-9-10-11-12-13" string="Michael Yamaki , one of the city 's five police commissioners" id_sentence="23" />
      <mentions>
        <mention ids_tokens="20" string="them" id_sentence="24" />
      </mentions>
    </coreference>
    <coreference id="40" type="NOMINAL">
      <referenced ids_tokens="3-4-5-6" string="the commission 's report" id_sentence="27" />
      <mentions>
        <mention ids_tokens="6-7" string="the report" id_sentence="30" />
        <mention ids_tokens="1-2" string="The report" id_sentence="31" />
        <mention ids_tokens="1-2" string="The report" id_sentence="33" />
        <mention ids_tokens="23-24" string="the report" id_sentence="36" />
        <mention ids_tokens="7-8" string="the report" id_sentence="37" />
      </mentions>
    </coreference>
    <coreference id="44" type="LIST">
      <referenced ids_tokens="6-7-8-9-10-11-12-13-14-15-16" string="the black , Hispanic and Asian police officers in the force" id_sentence="36" />
      <mentions>
        <mention ids_tokens="2" string="We" id_sentence="38" />
      </mentions>
    </coreference>
    <coreference id="46" type="NOMINAL">
      <referenced ids_tokens="10-11-12" string="a good report" id_sentence="41" />
      <mentions>
        <mention ids_tokens="3-8" string="the recommendation that he step down" id_sentence="40" />
      </mentions>
    </coreference>
  </coreferences>
</document>
