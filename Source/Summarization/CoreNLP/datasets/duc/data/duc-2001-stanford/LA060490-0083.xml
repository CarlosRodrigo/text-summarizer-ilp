<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="LA060490-0083">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>&amp;quot;Mad cow&amp;quot; disease, an enigmatic nervous disorder that has killed thousands of cattle in Britain, is causing trade friction in Europe and is threatening the $3.7-billion British beef industry.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Mad" lemma="Mad" stem="mad" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="cow" lemma="cow" stem="cow" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="disease" lemma="disease" stem="diseas" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="enigmatic" lemma="enigmatic" stem="enigmat" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="nervous" lemma="nervous" stem="nervou" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="disorder" lemma="disorder" stem="disord" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="killed" lemma="kill" stem="kill" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="thousands" lemma="thousand" stem="thousand" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="cattle" lemma="cattle" stem="cattl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Britain" lemma="Britain" stem="britain" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="causing" lemma="cause" stem="caus" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="trade" lemma="trade" stem="trade" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="friction" lemma="friction" stem="friction" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="Europe" lemma="Europe" stem="europ" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="26" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="threatening" lemma="threaten" stem="threaten" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="31" string="3.7-billion" lemma="3.7-billion" stem="3.7-billion" pos="CD" type="Word" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="32" string="British" lemma="british" stem="british" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="33" string="beef" lemma="beef" stem="beef" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="industry" lemma="industry" stem="industri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (NNP Mad) (NN cow)) ('' '') (NP (NP (NN disease)) (, ,) (NP (NP (DT an) (JJ enigmatic) (JJ nervous) (NN disorder)) (SBAR (WHNP (WDT that)) (S (VP (VBZ has) (VP (VBN killed) (NP (NP (NNS thousands)) (PP (IN of) (NP (NP (NNS cattle)) (PP (IN in) (NP (NNP Britain))))))))))) (, ,)) (VP (VP (VBZ is) (VP (VBG causing) (NP (NP (NN trade) (NN friction)) (PP (IN in) (NP (NNP Europe)))))) (CC and) (VP (VBZ is) (VP (VBG threatening) (NP (DT the) (ADJP (NP ($ $) (CD 3.7-billion)) (JJ British)) (NN beef) (NN industry))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="that has killed thousands of cattle in Britain" type="SBAR">
          <tokens>
            <token id="11" string="that" />
            <token id="12" string="has" />
            <token id="13" string="killed" />
            <token id="14" string="thousands" />
            <token id="15" string="of" />
            <token id="16" string="cattle" />
            <token id="17" string="in" />
            <token id="18" string="Britain" />
          </tokens>
        </chunking>
        <chunking id="2" string="thousands of cattle in Britain" type="NP">
          <tokens>
            <token id="14" string="thousands" />
            <token id="15" string="of" />
            <token id="16" string="cattle" />
            <token id="17" string="in" />
            <token id="18" string="Britain" />
          </tokens>
        </chunking>
        <chunking id="3" string="disease" type="NP">
          <tokens>
            <token id="5" string="disease" />
          </tokens>
        </chunking>
        <chunking id="4" string="Europe" type="NP">
          <tokens>
            <token id="25" string="Europe" />
          </tokens>
        </chunking>
        <chunking id="5" string="an enigmatic nervous disorder" type="NP">
          <tokens>
            <token id="7" string="an" />
            <token id="8" string="enigmatic" />
            <token id="9" string="nervous" />
            <token id="10" string="disorder" />
          </tokens>
        </chunking>
        <chunking id="6" string="killed thousands of cattle in Britain" type="VP">
          <tokens>
            <token id="13" string="killed" />
            <token id="14" string="thousands" />
            <token id="15" string="of" />
            <token id="16" string="cattle" />
            <token id="17" string="in" />
            <token id="18" string="Britain" />
          </tokens>
        </chunking>
        <chunking id="7" string="cattle" type="NP">
          <tokens>
            <token id="16" string="cattle" />
          </tokens>
        </chunking>
        <chunking id="8" string="Britain" type="NP">
          <tokens>
            <token id="18" string="Britain" />
          </tokens>
        </chunking>
        <chunking id="9" string="trade friction" type="NP">
          <tokens>
            <token id="22" string="trade" />
            <token id="23" string="friction" />
          </tokens>
        </chunking>
        <chunking id="10" string="Mad cow" type="NP">
          <tokens>
            <token id="2" string="Mad" />
            <token id="3" string="cow" />
          </tokens>
        </chunking>
        <chunking id="11" string="thousands" type="NP">
          <tokens>
            <token id="14" string="thousands" />
          </tokens>
        </chunking>
        <chunking id="12" string="an enigmatic nervous disorder that has killed thousands of cattle in Britain" type="NP">
          <tokens>
            <token id="7" string="an" />
            <token id="8" string="enigmatic" />
            <token id="9" string="nervous" />
            <token id="10" string="disorder" />
            <token id="11" string="that" />
            <token id="12" string="has" />
            <token id="13" string="killed" />
            <token id="14" string="thousands" />
            <token id="15" string="of" />
            <token id="16" string="cattle" />
            <token id="17" string="in" />
            <token id="18" string="Britain" />
          </tokens>
        </chunking>
        <chunking id="13" string="$ 3.7-billion" type="NP">
          <tokens>
            <token id="30" string="$" />
            <token id="31" string="3.7-billion" />
          </tokens>
        </chunking>
        <chunking id="14" string="the $ 3.7-billion British beef industry" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="$" />
            <token id="31" string="3.7-billion" />
            <token id="32" string="British" />
            <token id="33" string="beef" />
            <token id="34" string="industry" />
          </tokens>
        </chunking>
        <chunking id="15" string="causing trade friction in Europe" type="VP">
          <tokens>
            <token id="21" string="causing" />
            <token id="22" string="trade" />
            <token id="23" string="friction" />
            <token id="24" string="in" />
            <token id="25" string="Europe" />
          </tokens>
        </chunking>
        <chunking id="16" string="trade friction in Europe" type="NP">
          <tokens>
            <token id="22" string="trade" />
            <token id="23" string="friction" />
            <token id="24" string="in" />
            <token id="25" string="Europe" />
          </tokens>
        </chunking>
        <chunking id="17" string="disease , an enigmatic nervous disorder that has killed thousands of cattle in Britain ," type="NP">
          <tokens>
            <token id="5" string="disease" />
            <token id="6" string="," />
            <token id="7" string="an" />
            <token id="8" string="enigmatic" />
            <token id="9" string="nervous" />
            <token id="10" string="disorder" />
            <token id="11" string="that" />
            <token id="12" string="has" />
            <token id="13" string="killed" />
            <token id="14" string="thousands" />
            <token id="15" string="of" />
            <token id="16" string="cattle" />
            <token id="17" string="in" />
            <token id="18" string="Britain" />
            <token id="19" string="," />
          </tokens>
        </chunking>
        <chunking id="18" string="has killed thousands of cattle in Britain" type="VP">
          <tokens>
            <token id="12" string="has" />
            <token id="13" string="killed" />
            <token id="14" string="thousands" />
            <token id="15" string="of" />
            <token id="16" string="cattle" />
            <token id="17" string="in" />
            <token id="18" string="Britain" />
          </tokens>
        </chunking>
        <chunking id="19" string="cattle in Britain" type="NP">
          <tokens>
            <token id="16" string="cattle" />
            <token id="17" string="in" />
            <token id="18" string="Britain" />
          </tokens>
        </chunking>
        <chunking id="20" string="is causing trade friction in Europe and is threatening the $ 3.7-billion British beef industry" type="VP">
          <tokens>
            <token id="20" string="is" />
            <token id="21" string="causing" />
            <token id="22" string="trade" />
            <token id="23" string="friction" />
            <token id="24" string="in" />
            <token id="25" string="Europe" />
            <token id="26" string="and" />
            <token id="27" string="is" />
            <token id="28" string="threatening" />
            <token id="29" string="the" />
            <token id="30" string="$" />
            <token id="31" string="3.7-billion" />
            <token id="32" string="British" />
            <token id="33" string="beef" />
            <token id="34" string="industry" />
          </tokens>
        </chunking>
        <chunking id="21" string="is causing trade friction in Europe" type="VP">
          <tokens>
            <token id="20" string="is" />
            <token id="21" string="causing" />
            <token id="22" string="trade" />
            <token id="23" string="friction" />
            <token id="24" string="in" />
            <token id="25" string="Europe" />
          </tokens>
        </chunking>
        <chunking id="22" string="threatening the $ 3.7-billion British beef industry" type="VP">
          <tokens>
            <token id="28" string="threatening" />
            <token id="29" string="the" />
            <token id="30" string="$" />
            <token id="31" string="3.7-billion" />
            <token id="32" string="British" />
            <token id="33" string="beef" />
            <token id="34" string="industry" />
          </tokens>
        </chunking>
        <chunking id="23" string="$ 3.7-billion British" type="ADJP">
          <tokens>
            <token id="30" string="$" />
            <token id="31" string="3.7-billion" />
            <token id="32" string="British" />
          </tokens>
        </chunking>
        <chunking id="24" string="is threatening the $ 3.7-billion British beef industry" type="VP">
          <tokens>
            <token id="27" string="is" />
            <token id="28" string="threatening" />
            <token id="29" string="the" />
            <token id="30" string="$" />
            <token id="31" string="3.7-billion" />
            <token id="32" string="British" />
            <token id="33" string="beef" />
            <token id="34" string="industry" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">cow</governor>
          <dependent id="2">Mad</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">causing</governor>
          <dependent id="3">cow</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">causing</governor>
          <dependent id="5">disease</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">disorder</governor>
          <dependent id="7">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">disorder</governor>
          <dependent id="8">enigmatic</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">disorder</governor>
          <dependent id="9">nervous</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="5">disease</governor>
          <dependent id="10">disorder</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">killed</governor>
          <dependent id="11">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="13">killed</governor>
          <dependent id="12">has</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="10">disorder</governor>
          <dependent id="13">killed</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">killed</governor>
          <dependent id="14">thousands</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">cattle</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">thousands</governor>
          <dependent id="16">cattle</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">Britain</governor>
          <dependent id="17">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">cattle</governor>
          <dependent id="18">Britain</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="21">causing</governor>
          <dependent id="20">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="21">causing</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">friction</governor>
          <dependent id="22">trade</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">causing</governor>
          <dependent id="23">friction</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">Europe</governor>
          <dependent id="24">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">friction</governor>
          <dependent id="25">Europe</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="21">causing</governor>
          <dependent id="26">and</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="28">threatening</governor>
          <dependent id="27">is</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="21">causing</governor>
          <dependent id="28">threatening</dependent>
        </dependency>
        <dependency type="det">
          <governor id="34">industry</governor>
          <dependent id="29">the</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="31">3.7-billion</governor>
          <dependent id="30">$</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="32">British</governor>
          <dependent id="31">3.7-billion</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="34">industry</governor>
          <dependent id="32">British</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="34">industry</governor>
          <dependent id="33">beef</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="28">threatening</governor>
          <dependent id="34">industry</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="$ 3.7-billion" type="MONEY" score="0.0">
          <tokens>
            <token id="30" string="$" />
            <token id="31" string="3.7-billion" />
          </tokens>
        </entity>
        <entity id="2" string="British" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="32" string="British" />
          </tokens>
        </entity>
        <entity id="3" string="disease" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="5" string="disease" />
          </tokens>
        </entity>
        <entity id="4" string="Europe" type="LOCATION" score="0.0">
          <tokens>
            <token id="25" string="Europe" />
          </tokens>
        </entity>
        <entity id="5" string="Britain" type="LOCATION" score="0.0">
          <tokens>
            <token id="18" string="Britain" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>On Friday, West Germany joined France in a ban on British beef imports, citing health fears related to the mysterious ailment, whose technical name is bovine spongiform encephalopathy (BSE).</content>
      <tokens>
        <token id="1" string="On" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Friday" lemma="Friday" stem="fridai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="West" lemma="West" stem="west" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="5" string="Germany" lemma="Germany" stem="germani" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="6" string="joined" lemma="join" stem="join" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="France" lemma="France" stem="franc" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="8" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="ban" lemma="ban" stem="ban" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="British" lemma="british" stem="british" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="true" is_refers="false" />
        <token id="13" string="beef" lemma="beef" stem="beef" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="imports" lemma="import" stem="import" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="citing" lemma="cite" stem="cite" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="health" lemma="health" stem="health" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="fears" lemma="fear" stem="fear" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="related" lemma="relate" stem="relat" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="mysterious" lemma="mysterious" stem="mysteri" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="ailment" lemma="ailment" stem="ailment" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="whose" lemma="whose" stem="whose" pos="WP$" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="technical" lemma="technical" stem="technic" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="name" lemma="name" stem="name" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="bovine" lemma="bovine" stem="bovin" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="spongiform" lemma="spongiform" stem="spongiform" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="encephalopathy" lemma="encephalopathy" stem="encephalopathi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="BSE" lemma="bse" stem="bse" pos="NN" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="34" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN On) (NP (NNP Friday))) (, ,) (NP (NNP West) (NNP Germany)) (VP (VBD joined) (NP (NP (NNP France)) (PP (IN in) (NP (NP (DT a) (NN ban)) (PP (IN on) (NP (JJ British) (NN beef) (NNS imports)))))) (, ,) (S (VP (VBG citing) (NP (NP (NN health) (NNS fears)) (VP (VBN related) (PP (TO to) (NP (NP (DT the) (JJ mysterious) (NN ailment)) (, ,) (SBAR (WHNP (WP$ whose) (ADJP (JJ technical)) (NN name)) (S (VP (VBZ is) (NP (NP (JJ bovine) (NN spongiform) (NN encephalopathy)) (PRN (-LRB- -LRB-) (NP (NN BSE)) (-RRB- -RRB-))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="related to the mysterious ailment , whose technical name is bovine spongiform encephalopathy -LRB- BSE -RRB-" type="VP">
          <tokens>
            <token id="19" string="related" />
            <token id="20" string="to" />
            <token id="21" string="the" />
            <token id="22" string="mysterious" />
            <token id="23" string="ailment" />
            <token id="24" string="," />
            <token id="25" string="whose" />
            <token id="26" string="technical" />
            <token id="27" string="name" />
            <token id="28" string="is" />
            <token id="29" string="bovine" />
            <token id="30" string="spongiform" />
            <token id="31" string="encephalopathy" />
            <token id="32" string="(" />
            <token id="33" string="BSE" />
            <token id="34" string=")" />
          </tokens>
        </chunking>
        <chunking id="2" string="France in a ban on British beef imports" type="NP">
          <tokens>
            <token id="7" string="France" />
            <token id="8" string="in" />
            <token id="9" string="a" />
            <token id="10" string="ban" />
            <token id="11" string="on" />
            <token id="12" string="British" />
            <token id="13" string="beef" />
            <token id="14" string="imports" />
          </tokens>
        </chunking>
        <chunking id="3" string="technical" type="ADJP">
          <tokens>
            <token id="26" string="technical" />
          </tokens>
        </chunking>
        <chunking id="4" string="bovine spongiform encephalopathy -LRB- BSE -RRB-" type="NP">
          <tokens>
            <token id="29" string="bovine" />
            <token id="30" string="spongiform" />
            <token id="31" string="encephalopathy" />
            <token id="32" string="(" />
            <token id="33" string="BSE" />
            <token id="34" string=")" />
          </tokens>
        </chunking>
        <chunking id="5" string="whose technical name is bovine spongiform encephalopathy -LRB- BSE -RRB-" type="SBAR">
          <tokens>
            <token id="25" string="whose" />
            <token id="26" string="technical" />
            <token id="27" string="name" />
            <token id="28" string="is" />
            <token id="29" string="bovine" />
            <token id="30" string="spongiform" />
            <token id="31" string="encephalopathy" />
            <token id="32" string="(" />
            <token id="33" string="BSE" />
            <token id="34" string=")" />
          </tokens>
        </chunking>
        <chunking id="6" string="is bovine spongiform encephalopathy -LRB- BSE -RRB-" type="VP">
          <tokens>
            <token id="28" string="is" />
            <token id="29" string="bovine" />
            <token id="30" string="spongiform" />
            <token id="31" string="encephalopathy" />
            <token id="32" string="(" />
            <token id="33" string="BSE" />
            <token id="34" string=")" />
          </tokens>
        </chunking>
        <chunking id="7" string="a ban" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="ban" />
          </tokens>
        </chunking>
        <chunking id="8" string="bovine spongiform encephalopathy" type="NP">
          <tokens>
            <token id="29" string="bovine" />
            <token id="30" string="spongiform" />
            <token id="31" string="encephalopathy" />
          </tokens>
        </chunking>
        <chunking id="9" string="health fears related to the mysterious ailment , whose technical name is bovine spongiform encephalopathy -LRB- BSE -RRB-" type="NP">
          <tokens>
            <token id="17" string="health" />
            <token id="18" string="fears" />
            <token id="19" string="related" />
            <token id="20" string="to" />
            <token id="21" string="the" />
            <token id="22" string="mysterious" />
            <token id="23" string="ailment" />
            <token id="24" string="," />
            <token id="25" string="whose" />
            <token id="26" string="technical" />
            <token id="27" string="name" />
            <token id="28" string="is" />
            <token id="29" string="bovine" />
            <token id="30" string="spongiform" />
            <token id="31" string="encephalopathy" />
            <token id="32" string="(" />
            <token id="33" string="BSE" />
            <token id="34" string=")" />
          </tokens>
        </chunking>
        <chunking id="10" string="the mysterious ailment , whose technical name is bovine spongiform encephalopathy -LRB- BSE -RRB-" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="mysterious" />
            <token id="23" string="ailment" />
            <token id="24" string="," />
            <token id="25" string="whose" />
            <token id="26" string="technical" />
            <token id="27" string="name" />
            <token id="28" string="is" />
            <token id="29" string="bovine" />
            <token id="30" string="spongiform" />
            <token id="31" string="encephalopathy" />
            <token id="32" string="(" />
            <token id="33" string="BSE" />
            <token id="34" string=")" />
          </tokens>
        </chunking>
        <chunking id="11" string="West Germany" type="NP">
          <tokens>
            <token id="4" string="West" />
            <token id="5" string="Germany" />
          </tokens>
        </chunking>
        <chunking id="12" string="health fears" type="NP">
          <tokens>
            <token id="17" string="health" />
            <token id="18" string="fears" />
          </tokens>
        </chunking>
        <chunking id="13" string="the mysterious ailment" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="mysterious" />
            <token id="23" string="ailment" />
          </tokens>
        </chunking>
        <chunking id="14" string="joined France in a ban on British beef imports , citing health fears related to the mysterious ailment , whose technical name is bovine spongiform encephalopathy -LRB- BSE -RRB-" type="VP">
          <tokens>
            <token id="6" string="joined" />
            <token id="7" string="France" />
            <token id="8" string="in" />
            <token id="9" string="a" />
            <token id="10" string="ban" />
            <token id="11" string="on" />
            <token id="12" string="British" />
            <token id="13" string="beef" />
            <token id="14" string="imports" />
            <token id="15" string="," />
            <token id="16" string="citing" />
            <token id="17" string="health" />
            <token id="18" string="fears" />
            <token id="19" string="related" />
            <token id="20" string="to" />
            <token id="21" string="the" />
            <token id="22" string="mysterious" />
            <token id="23" string="ailment" />
            <token id="24" string="," />
            <token id="25" string="whose" />
            <token id="26" string="technical" />
            <token id="27" string="name" />
            <token id="28" string="is" />
            <token id="29" string="bovine" />
            <token id="30" string="spongiform" />
            <token id="31" string="encephalopathy" />
            <token id="32" string="(" />
            <token id="33" string="BSE" />
            <token id="34" string=")" />
          </tokens>
        </chunking>
        <chunking id="15" string="BSE" type="NP">
          <tokens>
            <token id="33" string="BSE" />
          </tokens>
        </chunking>
        <chunking id="16" string="Friday" type="NP">
          <tokens>
            <token id="2" string="Friday" />
          </tokens>
        </chunking>
        <chunking id="17" string="a ban on British beef imports" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="ban" />
            <token id="11" string="on" />
            <token id="12" string="British" />
            <token id="13" string="beef" />
            <token id="14" string="imports" />
          </tokens>
        </chunking>
        <chunking id="18" string="British beef imports" type="NP">
          <tokens>
            <token id="12" string="British" />
            <token id="13" string="beef" />
            <token id="14" string="imports" />
          </tokens>
        </chunking>
        <chunking id="19" string="France" type="NP">
          <tokens>
            <token id="7" string="France" />
          </tokens>
        </chunking>
        <chunking id="20" string="citing health fears related to the mysterious ailment , whose technical name is bovine spongiform encephalopathy -LRB- BSE -RRB-" type="VP">
          <tokens>
            <token id="16" string="citing" />
            <token id="17" string="health" />
            <token id="18" string="fears" />
            <token id="19" string="related" />
            <token id="20" string="to" />
            <token id="21" string="the" />
            <token id="22" string="mysterious" />
            <token id="23" string="ailment" />
            <token id="24" string="," />
            <token id="25" string="whose" />
            <token id="26" string="technical" />
            <token id="27" string="name" />
            <token id="28" string="is" />
            <token id="29" string="bovine" />
            <token id="30" string="spongiform" />
            <token id="31" string="encephalopathy" />
            <token id="32" string="(" />
            <token id="33" string="BSE" />
            <token id="34" string=")" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">Friday</governor>
          <dependent id="1">On</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">joined</governor>
          <dependent id="2">Friday</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Germany</governor>
          <dependent id="4">West</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">joined</governor>
          <dependent id="5">Germany</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">joined</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">joined</governor>
          <dependent id="7">France</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">ban</governor>
          <dependent id="8">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">ban</governor>
          <dependent id="9">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">France</governor>
          <dependent id="10">ban</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">imports</governor>
          <dependent id="11">on</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">imports</governor>
          <dependent id="12">British</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">imports</governor>
          <dependent id="13">beef</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">ban</governor>
          <dependent id="14">imports</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="6">joined</governor>
          <dependent id="16">citing</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">fears</governor>
          <dependent id="17">health</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">citing</governor>
          <dependent id="18">fears</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="18">fears</governor>
          <dependent id="19">related</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">ailment</governor>
          <dependent id="20">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">ailment</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">ailment</governor>
          <dependent id="22">mysterious</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">related</governor>
          <dependent id="23">ailment</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="27">name</governor>
          <dependent id="25">whose</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="27">name</governor>
          <dependent id="26">technical</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="31">encephalopathy</governor>
          <dependent id="27">name</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="31">encephalopathy</governor>
          <dependent id="28">is</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="31">encephalopathy</governor>
          <dependent id="29">bovine</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">encephalopathy</governor>
          <dependent id="30">spongiform</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="23">ailment</governor>
          <dependent id="31">encephalopathy</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="31">encephalopathy</governor>
          <dependent id="33">BSE</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="BSE" type="MISC" score="0.0">
          <tokens>
            <token id="33" string="BSE" />
          </tokens>
        </entity>
        <entity id="2" string="British" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="12" string="British" />
          </tokens>
        </entity>
        <entity id="3" string="Friday" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="Friday" />
          </tokens>
        </entity>
        <entity id="4" string="West Germany" type="LOCATION" score="0.0">
          <tokens>
            <token id="4" string="West" />
            <token id="5" string="Germany" />
          </tokens>
        </entity>
        <entity id="5" string="France" type="LOCATION" score="0.0">
          <tokens>
            <token id="7" string="France" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>Concern that the disease can be transmitted to humans has made the subject Topic A in the pubs and press of Britain, and has put a serious crimp in domestic beef sales.</content>
      <tokens>
        <token id="1" string="Concern" lemma="concern" stem="concern" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="disease" lemma="disease" stem="diseas" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="true" is_refers="false" />
        <token id="5" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="transmitted" lemma="transmit" stem="transmit" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="humans" lemma="human" stem="human" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="made" lemma="make" stem="made" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="subject" lemma="subject" stem="subject" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="Topic" lemma="topic" stem="topic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="A" lemma="a" stem="a" pos="NN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="pubs" lemma="pub" stem="pub" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="press" lemma="press" stem="press" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="Britain" lemma="Britain" stem="britain" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="put" lemma="put" stem="put" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="serious" lemma="serious" stem="seriou" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="crimp" lemma="crimp" stem="crimp" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="domestic" lemma="domestic" stem="domest" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="32" string="beef" lemma="beef" stem="beef" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="33" string="sales" lemma="sale" stem="sale" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="34" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NN Concern)) (SBAR (IN that) (S (NP (DT the) (NN disease)) (VP (MD can) (VP (VB be) (VP (VBN transmitted) (PP (TO to) (NP (NNS humans))))))))) (VP (VP (VBZ has) (VP (VBN made) (NP (DT the) (ADJP (JJ subject)) (NN Topic) (NN A)) (PP (IN in) (NP (NP (DT the) (NNS pubs) (CC and) (NN press)) (PP (IN of) (NP (NNP Britain))))))) (, ,) (CC and) (VP (VBZ has) (VP (VBN put) (S (NP (DT a) (JJ serious)) (VP (VB crimp) (PP (IN in) (NP (JJ domestic) (NN beef) (NNS sales)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="subject" type="ADJP">
          <tokens>
            <token id="13" string="subject" />
          </tokens>
        </chunking>
        <chunking id="2" string="can be transmitted to humans" type="VP">
          <tokens>
            <token id="5" string="can" />
            <token id="6" string="be" />
            <token id="7" string="transmitted" />
            <token id="8" string="to" />
            <token id="9" string="humans" />
          </tokens>
        </chunking>
        <chunking id="3" string="domestic beef sales" type="NP">
          <tokens>
            <token id="31" string="domestic" />
            <token id="32" string="beef" />
            <token id="33" string="sales" />
          </tokens>
        </chunking>
        <chunking id="4" string="Concern that the disease can be transmitted to humans" type="NP">
          <tokens>
            <token id="1" string="Concern" />
            <token id="2" string="that" />
            <token id="3" string="the" />
            <token id="4" string="disease" />
            <token id="5" string="can" />
            <token id="6" string="be" />
            <token id="7" string="transmitted" />
            <token id="8" string="to" />
            <token id="9" string="humans" />
          </tokens>
        </chunking>
        <chunking id="5" string="transmitted to humans" type="VP">
          <tokens>
            <token id="7" string="transmitted" />
            <token id="8" string="to" />
            <token id="9" string="humans" />
          </tokens>
        </chunking>
        <chunking id="6" string="has made the subject Topic A in the pubs and press of Britain" type="VP">
          <tokens>
            <token id="10" string="has" />
            <token id="11" string="made" />
            <token id="12" string="the" />
            <token id="13" string="subject" />
            <token id="14" string="Topic" />
            <token id="15" string="A" />
            <token id="16" string="in" />
            <token id="17" string="the" />
            <token id="18" string="pubs" />
            <token id="19" string="and" />
            <token id="20" string="press" />
            <token id="21" string="of" />
            <token id="22" string="Britain" />
          </tokens>
        </chunking>
        <chunking id="7" string="put a serious crimp in domestic beef sales" type="VP">
          <tokens>
            <token id="26" string="put" />
            <token id="27" string="a" />
            <token id="28" string="serious" />
            <token id="29" string="crimp" />
            <token id="30" string="in" />
            <token id="31" string="domestic" />
            <token id="32" string="beef" />
            <token id="33" string="sales" />
          </tokens>
        </chunking>
        <chunking id="8" string="that the disease can be transmitted to humans" type="SBAR">
          <tokens>
            <token id="2" string="that" />
            <token id="3" string="the" />
            <token id="4" string="disease" />
            <token id="5" string="can" />
            <token id="6" string="be" />
            <token id="7" string="transmitted" />
            <token id="8" string="to" />
            <token id="9" string="humans" />
          </tokens>
        </chunking>
        <chunking id="9" string="Britain" type="NP">
          <tokens>
            <token id="22" string="Britain" />
          </tokens>
        </chunking>
        <chunking id="10" string="has made the subject Topic A in the pubs and press of Britain , and has put a serious crimp in domestic beef sales" type="VP">
          <tokens>
            <token id="10" string="has" />
            <token id="11" string="made" />
            <token id="12" string="the" />
            <token id="13" string="subject" />
            <token id="14" string="Topic" />
            <token id="15" string="A" />
            <token id="16" string="in" />
            <token id="17" string="the" />
            <token id="18" string="pubs" />
            <token id="19" string="and" />
            <token id="20" string="press" />
            <token id="21" string="of" />
            <token id="22" string="Britain" />
            <token id="23" string="," />
            <token id="24" string="and" />
            <token id="25" string="has" />
            <token id="26" string="put" />
            <token id="27" string="a" />
            <token id="28" string="serious" />
            <token id="29" string="crimp" />
            <token id="30" string="in" />
            <token id="31" string="domestic" />
            <token id="32" string="beef" />
            <token id="33" string="sales" />
          </tokens>
        </chunking>
        <chunking id="11" string="the disease" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="disease" />
          </tokens>
        </chunking>
        <chunking id="12" string="a serious" type="NP">
          <tokens>
            <token id="27" string="a" />
            <token id="28" string="serious" />
          </tokens>
        </chunking>
        <chunking id="13" string="made the subject Topic A in the pubs and press of Britain" type="VP">
          <tokens>
            <token id="11" string="made" />
            <token id="12" string="the" />
            <token id="13" string="subject" />
            <token id="14" string="Topic" />
            <token id="15" string="A" />
            <token id="16" string="in" />
            <token id="17" string="the" />
            <token id="18" string="pubs" />
            <token id="19" string="and" />
            <token id="20" string="press" />
            <token id="21" string="of" />
            <token id="22" string="Britain" />
          </tokens>
        </chunking>
        <chunking id="14" string="the pubs and press of Britain" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="pubs" />
            <token id="19" string="and" />
            <token id="20" string="press" />
            <token id="21" string="of" />
            <token id="22" string="Britain" />
          </tokens>
        </chunking>
        <chunking id="15" string="has put a serious crimp in domestic beef sales" type="VP">
          <tokens>
            <token id="25" string="has" />
            <token id="26" string="put" />
            <token id="27" string="a" />
            <token id="28" string="serious" />
            <token id="29" string="crimp" />
            <token id="30" string="in" />
            <token id="31" string="domestic" />
            <token id="32" string="beef" />
            <token id="33" string="sales" />
          </tokens>
        </chunking>
        <chunking id="16" string="Concern" type="NP">
          <tokens>
            <token id="1" string="Concern" />
          </tokens>
        </chunking>
        <chunking id="17" string="be transmitted to humans" type="VP">
          <tokens>
            <token id="6" string="be" />
            <token id="7" string="transmitted" />
            <token id="8" string="to" />
            <token id="9" string="humans" />
          </tokens>
        </chunking>
        <chunking id="18" string="the subject Topic A" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="subject" />
            <token id="14" string="Topic" />
            <token id="15" string="A" />
          </tokens>
        </chunking>
        <chunking id="19" string="the pubs and press" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="pubs" />
            <token id="19" string="and" />
            <token id="20" string="press" />
          </tokens>
        </chunking>
        <chunking id="20" string="crimp in domestic beef sales" type="VP">
          <tokens>
            <token id="29" string="crimp" />
            <token id="30" string="in" />
            <token id="31" string="domestic" />
            <token id="32" string="beef" />
            <token id="33" string="sales" />
          </tokens>
        </chunking>
        <chunking id="21" string="humans" type="NP">
          <tokens>
            <token id="9" string="humans" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="11">made</governor>
          <dependent id="1">Concern</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">transmitted</governor>
          <dependent id="2">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">disease</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="7">transmitted</governor>
          <dependent id="4">disease</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">transmitted</governor>
          <dependent id="5">can</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="7">transmitted</governor>
          <dependent id="6">be</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="1">Concern</governor>
          <dependent id="7">transmitted</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">humans</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">transmitted</governor>
          <dependent id="9">humans</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">made</governor>
          <dependent id="10">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">made</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">A</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">A</governor>
          <dependent id="13">subject</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">A</governor>
          <dependent id="14">Topic</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">made</governor>
          <dependent id="15">A</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">pubs</governor>
          <dependent id="16">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">pubs</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">made</governor>
          <dependent id="18">pubs</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="18">pubs</governor>
          <dependent id="19">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="18">pubs</governor>
          <dependent id="20">press</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">Britain</governor>
          <dependent id="21">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">pubs</governor>
          <dependent id="22">Britain</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="11">made</governor>
          <dependent id="24">and</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="26">put</governor>
          <dependent id="25">has</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">made</governor>
          <dependent id="26">put</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">serious</governor>
          <dependent id="27">a</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">crimp</governor>
          <dependent id="28">serious</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="26">put</governor>
          <dependent id="29">crimp</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">sales</governor>
          <dependent id="30">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="33">sales</governor>
          <dependent id="31">domestic</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="33">sales</governor>
          <dependent id="32">beef</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">crimp</governor>
          <dependent id="33">sales</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="disease" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="4" string="disease" />
          </tokens>
        </entity>
        <entity id="2" string="Britain" type="LOCATION" score="0.0">
          <tokens>
            <token id="22" string="Britain" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="false">
      <content>Despite assurances from the British government that the beef is safe, consumers and some scientists remain skeptical.</content>
      <tokens>
        <token id="1" string="Despite" lemma="despite" stem="despit" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="assurances" lemma="assurance" stem="assur" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="British" lemma="british" stem="british" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="6" string="government" lemma="government" stem="govern" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="beef" lemma="beef" stem="beef" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="safe" lemma="safe" stem="safe" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="consumers" lemma="consumer" stem="consum" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="scientists" lemma="scientist" stem="scientist" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="remain" lemma="remain" stem="remain" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="skeptical" lemma="skeptical" stem="skeptic" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN Despite) (NP (NP (NNS assurances)) (PP (IN from) (NP (NP (DT the) (JJ British) (NN government)) (SBAR (IN that) (S (NP (DT the) (NN beef)) (VP (VBZ is) (ADJP (JJ safe))))))))) (, ,) (NP (NP (NNS consumers)) (CC and) (NP (DT some) (NNS scientists))) (VP (VBP remain) (ADJP (JJ skeptical))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="assurances" type="NP">
          <tokens>
            <token id="2" string="assurances" />
          </tokens>
        </chunking>
        <chunking id="2" string="consumers and some scientists" type="NP">
          <tokens>
            <token id="13" string="consumers" />
            <token id="14" string="and" />
            <token id="15" string="some" />
            <token id="16" string="scientists" />
          </tokens>
        </chunking>
        <chunking id="3" string="the British government that the beef is safe" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="British" />
            <token id="6" string="government" />
            <token id="7" string="that" />
            <token id="8" string="the" />
            <token id="9" string="beef" />
            <token id="10" string="is" />
            <token id="11" string="safe" />
          </tokens>
        </chunking>
        <chunking id="4" string="the British government" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="British" />
            <token id="6" string="government" />
          </tokens>
        </chunking>
        <chunking id="5" string="is safe" type="VP">
          <tokens>
            <token id="10" string="is" />
            <token id="11" string="safe" />
          </tokens>
        </chunking>
        <chunking id="6" string="some scientists" type="NP">
          <tokens>
            <token id="15" string="some" />
            <token id="16" string="scientists" />
          </tokens>
        </chunking>
        <chunking id="7" string="the beef" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="beef" />
          </tokens>
        </chunking>
        <chunking id="8" string="remain skeptical" type="VP">
          <tokens>
            <token id="17" string="remain" />
            <token id="18" string="skeptical" />
          </tokens>
        </chunking>
        <chunking id="9" string="assurances from the British government that the beef is safe" type="NP">
          <tokens>
            <token id="2" string="assurances" />
            <token id="3" string="from" />
            <token id="4" string="the" />
            <token id="5" string="British" />
            <token id="6" string="government" />
            <token id="7" string="that" />
            <token id="8" string="the" />
            <token id="9" string="beef" />
            <token id="10" string="is" />
            <token id="11" string="safe" />
          </tokens>
        </chunking>
        <chunking id="10" string="skeptical" type="ADJP">
          <tokens>
            <token id="18" string="skeptical" />
          </tokens>
        </chunking>
        <chunking id="11" string="safe" type="ADJP">
          <tokens>
            <token id="11" string="safe" />
          </tokens>
        </chunking>
        <chunking id="12" string="that the beef is safe" type="SBAR">
          <tokens>
            <token id="7" string="that" />
            <token id="8" string="the" />
            <token id="9" string="beef" />
            <token id="10" string="is" />
            <token id="11" string="safe" />
          </tokens>
        </chunking>
        <chunking id="13" string="consumers" type="NP">
          <tokens>
            <token id="13" string="consumers" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">assurances</governor>
          <dependent id="1">Despite</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">remain</governor>
          <dependent id="2">assurances</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">government</governor>
          <dependent id="3">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">government</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">government</governor>
          <dependent id="5">British</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">assurances</governor>
          <dependent id="6">government</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">safe</governor>
          <dependent id="7">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">beef</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">safe</governor>
          <dependent id="9">beef</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="11">safe</governor>
          <dependent id="10">is</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="6">government</governor>
          <dependent id="11">safe</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">remain</governor>
          <dependent id="13">consumers</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">consumers</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">scientists</governor>
          <dependent id="15">some</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">consumers</governor>
          <dependent id="16">scientists</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="17">remain</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="17">remain</governor>
          <dependent id="18">skeptical</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="British" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="5" string="British" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>British officials complain that the French and German import ban is a result of economic, not health, concerns.</content>
      <tokens>
        <token id="1" string="British" lemma="british" stem="british" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="true" is_refers="false" />
        <token id="2" string="officials" lemma="official" stem="offici" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="complain" lemma="complain" stem="complain" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="French" lemma="french" stem="french" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="7" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="German" lemma="german" stem="german" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="9" string="import" lemma="import" stem="import" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="ban" lemma="ban" stem="ban" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="result" lemma="result" stem="result" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="economic" lemma="economic" stem="econom" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="health" lemma="health" stem="health" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="concerns" lemma="concern" stem="concern" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (JJ British) (NNS officials)) (VP (VBP complain) (SBAR (IN that) (S (NP (DT the) (ADJP (JJ French) (CC and) (JJ German)) (NN import) (NN ban)) (VP (VBZ is) (NP (NP (DT a) (NN result)) (PP (IN of) (NP (JJ economic) (PRN (, ,) (FRAG (RB not) (NP (NN health))) (, ,)) (NNS concerns)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="economic , not health , concerns" type="NP">
          <tokens>
            <token id="15" string="economic" />
            <token id="16" string="," />
            <token id="17" string="not" />
            <token id="18" string="health" />
            <token id="19" string="," />
            <token id="20" string="concerns" />
          </tokens>
        </chunking>
        <chunking id="2" string="that the French and German import ban is a result of economic , not health , concerns" type="SBAR">
          <tokens>
            <token id="4" string="that" />
            <token id="5" string="the" />
            <token id="6" string="French" />
            <token id="7" string="and" />
            <token id="8" string="German" />
            <token id="9" string="import" />
            <token id="10" string="ban" />
            <token id="11" string="is" />
            <token id="12" string="a" />
            <token id="13" string="result" />
            <token id="14" string="of" />
            <token id="15" string="economic" />
            <token id="16" string="," />
            <token id="17" string="not" />
            <token id="18" string="health" />
            <token id="19" string="," />
            <token id="20" string="concerns" />
          </tokens>
        </chunking>
        <chunking id="3" string="the French and German import ban" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="French" />
            <token id="7" string="and" />
            <token id="8" string="German" />
            <token id="9" string="import" />
            <token id="10" string="ban" />
          </tokens>
        </chunking>
        <chunking id="4" string="French and German" type="ADJP">
          <tokens>
            <token id="6" string="French" />
            <token id="7" string="and" />
            <token id="8" string="German" />
          </tokens>
        </chunking>
        <chunking id="5" string="British officials" type="NP">
          <tokens>
            <token id="1" string="British" />
            <token id="2" string="officials" />
          </tokens>
        </chunking>
        <chunking id="6" string="complain that the French and German import ban is a result of economic , not health , concerns" type="VP">
          <tokens>
            <token id="3" string="complain" />
            <token id="4" string="that" />
            <token id="5" string="the" />
            <token id="6" string="French" />
            <token id="7" string="and" />
            <token id="8" string="German" />
            <token id="9" string="import" />
            <token id="10" string="ban" />
            <token id="11" string="is" />
            <token id="12" string="a" />
            <token id="13" string="result" />
            <token id="14" string="of" />
            <token id="15" string="economic" />
            <token id="16" string="," />
            <token id="17" string="not" />
            <token id="18" string="health" />
            <token id="19" string="," />
            <token id="20" string="concerns" />
          </tokens>
        </chunking>
        <chunking id="7" string="is a result of economic , not health , concerns" type="VP">
          <tokens>
            <token id="11" string="is" />
            <token id="12" string="a" />
            <token id="13" string="result" />
            <token id="14" string="of" />
            <token id="15" string="economic" />
            <token id="16" string="," />
            <token id="17" string="not" />
            <token id="18" string="health" />
            <token id="19" string="," />
            <token id="20" string="concerns" />
          </tokens>
        </chunking>
        <chunking id="8" string="a result" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="result" />
          </tokens>
        </chunking>
        <chunking id="9" string="a result of economic , not health , concerns" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="result" />
            <token id="14" string="of" />
            <token id="15" string="economic" />
            <token id="16" string="," />
            <token id="17" string="not" />
            <token id="18" string="health" />
            <token id="19" string="," />
            <token id="20" string="concerns" />
          </tokens>
        </chunking>
        <chunking id="10" string="health" type="NP">
          <tokens>
            <token id="18" string="health" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="2">officials</governor>
          <dependent id="1">British</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">complain</governor>
          <dependent id="2">officials</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">complain</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">result</governor>
          <dependent id="4">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">ban</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">ban</governor>
          <dependent id="6">French</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">French</governor>
          <dependent id="7">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">French</governor>
          <dependent id="8">German</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">ban</governor>
          <dependent id="9">import</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">result</governor>
          <dependent id="10">ban</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="13">result</governor>
          <dependent id="11">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">result</governor>
          <dependent id="12">a</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">complain</governor>
          <dependent id="13">result</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">concerns</governor>
          <dependent id="14">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">concerns</governor>
          <dependent id="15">economic</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="20">concerns</governor>
          <dependent id="17">not</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="17">not</governor>
          <dependent id="18">health</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">result</governor>
          <dependent id="20">concerns</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="French" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="6" string="French" />
          </tokens>
        </entity>
        <entity id="2" string="British" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="1" string="British" />
          </tokens>
        </entity>
        <entity id="3" string="German" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="8" string="German" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="false">
      <content>The price of British beef is dropping in the wake of the &amp;quot;mad cow&amp;quot; scare.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="price" lemma="price" stem="price" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="British" lemma="british" stem="british" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="5" string="beef" lemma="beef" stem="beef" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="dropping" lemma="drop" stem="drop" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="wake" lemma="wake" stem="wake" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="mad" lemma="mad" stem="mad" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="cow" lemma="cow" stem="cow" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="scare" lemma="scare" stem="scare" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (NN price)) (PP (IN of) (NP (JJ British) (NN beef)))) (VP (VBZ is) (VP (VBG dropping) (PP (IN in) (NP (NP (DT the) (NN wake)) (PP (IN of) (NP (DT the) (`` ``) (JJ mad) (NN cow) ('' '') (NN scare))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="is dropping in the wake of the `` mad cow '' scare" type="VP">
          <tokens>
            <token id="6" string="is" />
            <token id="7" string="dropping" />
            <token id="8" string="in" />
            <token id="9" string="the" />
            <token id="10" string="wake" />
            <token id="11" string="of" />
            <token id="12" string="the" />
            <token id="13" string="&quot;" />
            <token id="14" string="mad" />
            <token id="15" string="cow" />
            <token id="16" string="&quot;" />
            <token id="17" string="scare" />
          </tokens>
        </chunking>
        <chunking id="2" string="dropping in the wake of the `` mad cow '' scare" type="VP">
          <tokens>
            <token id="7" string="dropping" />
            <token id="8" string="in" />
            <token id="9" string="the" />
            <token id="10" string="wake" />
            <token id="11" string="of" />
            <token id="12" string="the" />
            <token id="13" string="&quot;" />
            <token id="14" string="mad" />
            <token id="15" string="cow" />
            <token id="16" string="&quot;" />
            <token id="17" string="scare" />
          </tokens>
        </chunking>
        <chunking id="3" string="The price of British beef" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="price" />
            <token id="3" string="of" />
            <token id="4" string="British" />
            <token id="5" string="beef" />
          </tokens>
        </chunking>
        <chunking id="4" string="British beef" type="NP">
          <tokens>
            <token id="4" string="British" />
            <token id="5" string="beef" />
          </tokens>
        </chunking>
        <chunking id="5" string="the wake" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="wake" />
          </tokens>
        </chunking>
        <chunking id="6" string="The price" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="price" />
          </tokens>
        </chunking>
        <chunking id="7" string="the wake of the `` mad cow '' scare" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="wake" />
            <token id="11" string="of" />
            <token id="12" string="the" />
            <token id="13" string="&quot;" />
            <token id="14" string="mad" />
            <token id="15" string="cow" />
            <token id="16" string="&quot;" />
            <token id="17" string="scare" />
          </tokens>
        </chunking>
        <chunking id="8" string="the `` mad cow '' scare" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="&quot;" />
            <token id="14" string="mad" />
            <token id="15" string="cow" />
            <token id="16" string="&quot;" />
            <token id="17" string="scare" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">price</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">dropping</governor>
          <dependent id="2">price</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">beef</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">beef</governor>
          <dependent id="4">British</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">price</governor>
          <dependent id="5">beef</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">dropping</governor>
          <dependent id="6">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">dropping</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">wake</governor>
          <dependent id="8">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">wake</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">dropping</governor>
          <dependent id="10">wake</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">scare</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">scare</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">scare</governor>
          <dependent id="14">mad</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">scare</governor>
          <dependent id="15">cow</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">wake</governor>
          <dependent id="17">scare</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="British" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="4" string="British" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>Therefore, British officials believe, France and West Germany imposed the bans to protect their domestic sales.</content>
      <tokens>
        <token id="1" string="Therefore" lemma="therefore" stem="therefor" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="British" lemma="british" stem="british" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="4" string="officials" lemma="official" stem="offici" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="believe" lemma="believe" stem="believ" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="France" lemma="France" stem="franc" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="8" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="West" lemma="West" stem="west" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="10" string="Germany" lemma="Germany" stem="germani" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="11" string="imposed" lemma="impose" stem="impos" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="bans" lemma="ban" stem="ban" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="protect" lemma="protect" stem="protect" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="domestic" lemma="domestic" stem="domest" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="sales" lemma="sale" stem="sale" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Therefore)) (PRN (, ,) (S (NP (JJ British) (NNS officials)) (VP (VBP believe))) (, ,)) (NP (NNP France) (CC and) (NNP West) (NNP Germany)) (VP (VBD imposed) (NP (DT the) (NNS bans)) (S (VP (TO to) (VP (VB protect) (NP (PRP$ their) (JJ domestic) (NNS sales)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="their domestic sales" type="NP">
          <tokens>
            <token id="16" string="their" />
            <token id="17" string="domestic" />
            <token id="18" string="sales" />
          </tokens>
        </chunking>
        <chunking id="2" string="France and West Germany" type="NP">
          <tokens>
            <token id="7" string="France" />
            <token id="8" string="and" />
            <token id="9" string="West" />
            <token id="10" string="Germany" />
          </tokens>
        </chunking>
        <chunking id="3" string="the bans" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="bans" />
          </tokens>
        </chunking>
        <chunking id="4" string="protect their domestic sales" type="VP">
          <tokens>
            <token id="15" string="protect" />
            <token id="16" string="their" />
            <token id="17" string="domestic" />
            <token id="18" string="sales" />
          </tokens>
        </chunking>
        <chunking id="5" string="British officials" type="NP">
          <tokens>
            <token id="3" string="British" />
            <token id="4" string="officials" />
          </tokens>
        </chunking>
        <chunking id="6" string="to protect their domestic sales" type="VP">
          <tokens>
            <token id="14" string="to" />
            <token id="15" string="protect" />
            <token id="16" string="their" />
            <token id="17" string="domestic" />
            <token id="18" string="sales" />
          </tokens>
        </chunking>
        <chunking id="7" string="believe" type="VP">
          <tokens>
            <token id="5" string="believe" />
          </tokens>
        </chunking>
        <chunking id="8" string="imposed the bans to protect their domestic sales" type="VP">
          <tokens>
            <token id="11" string="imposed" />
            <token id="12" string="the" />
            <token id="13" string="bans" />
            <token id="14" string="to" />
            <token id="15" string="protect" />
            <token id="16" string="their" />
            <token id="17" string="domestic" />
            <token id="18" string="sales" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="11">imposed</governor>
          <dependent id="1">Therefore</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">officials</governor>
          <dependent id="3">British</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">believe</governor>
          <dependent id="4">officials</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="11">imposed</governor>
          <dependent id="5">believe</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Germany</governor>
          <dependent id="7">France</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">France</governor>
          <dependent id="8">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">France</governor>
          <dependent id="9">West</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">imposed</governor>
          <dependent id="10">Germany</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">imposed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">bans</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">imposed</governor>
          <dependent id="13">bans</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">protect</governor>
          <dependent id="14">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="11">imposed</governor>
          <dependent id="15">protect</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="18">sales</governor>
          <dependent id="16">their</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">sales</governor>
          <dependent id="17">domestic</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">protect</governor>
          <dependent id="18">sales</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="British" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="3" string="British" />
          </tokens>
        </entity>
        <entity id="2" string="France" type="LOCATION" score="0.0">
          <tokens>
            <token id="7" string="France" />
          </tokens>
        </entity>
        <entity id="3" string="West Germany" type="LOCATION" score="0.0">
          <tokens>
            <token id="9" string="West" />
            <token id="10" string="Germany" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>&amp;quot;It&amp;apost;s totally unjustified and illegal,&amp;quot; said Patrick Barrow, spokesman for the Meat and Livestock Commission, a trade organization.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="totally" lemma="totally" stem="total" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="unjustified" lemma="unjustified" stem="unjustifi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="illegal" lemma="illegal" stem="illeg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="Patrick" lemma="Patrick" stem="patrick" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="12" string="Barrow" lemma="Barrow" stem="barrow" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="spokesman" lemma="spokesman" stem="spokesman" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Meat" lemma="meat" stem="meat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="Livestock" lemma="Livestock" stem="livestock" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="20" string="Commission" lemma="Commission" stem="commiss" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="trade" lemma="trade" stem="trade" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="organization" lemma="organization" stem="organ" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (NP (PRP It)) (VP (VBZ 's) (ADJP (RB totally) (JJ unjustified) (CC and) (JJ illegal)))) (, ,) ('' '') (VP (VBD said)) (NP (NP (NNP Patrick) (NNP Barrow)) (, ,) (NP (NP (NP (NN spokesman)) (PP (IN for) (NP (DT the) (NN Meat)))) (CC and) (NP (NP (NNP Livestock) (NNP Commission)) (, ,) (NP (DT a) (NN trade) (NN organization))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="spokesman" type="NP">
          <tokens>
            <token id="14" string="spokesman" />
          </tokens>
        </chunking>
        <chunking id="2" string="the Meat" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="Meat" />
          </tokens>
        </chunking>
        <chunking id="3" string="It" type="NP">
          <tokens>
            <token id="2" string="It" />
          </tokens>
        </chunking>
        <chunking id="4" string="spokesman for the Meat and Livestock Commission , a trade organization" type="NP">
          <tokens>
            <token id="14" string="spokesman" />
            <token id="15" string="for" />
            <token id="16" string="the" />
            <token id="17" string="Meat" />
            <token id="18" string="and" />
            <token id="19" string="Livestock" />
            <token id="20" string="Commission" />
            <token id="21" string="," />
            <token id="22" string="a" />
            <token id="23" string="trade" />
            <token id="24" string="organization" />
          </tokens>
        </chunking>
        <chunking id="5" string="'s totally unjustified and illegal" type="VP">
          <tokens>
            <token id="3" string="'s" />
            <token id="4" string="totally" />
            <token id="5" string="unjustified" />
            <token id="6" string="and" />
            <token id="7" string="illegal" />
          </tokens>
        </chunking>
        <chunking id="6" string="spokesman for the Meat" type="NP">
          <tokens>
            <token id="14" string="spokesman" />
            <token id="15" string="for" />
            <token id="16" string="the" />
            <token id="17" string="Meat" />
          </tokens>
        </chunking>
        <chunking id="7" string="Livestock Commission" type="NP">
          <tokens>
            <token id="19" string="Livestock" />
            <token id="20" string="Commission" />
          </tokens>
        </chunking>
        <chunking id="8" string="a trade organization" type="NP">
          <tokens>
            <token id="22" string="a" />
            <token id="23" string="trade" />
            <token id="24" string="organization" />
          </tokens>
        </chunking>
        <chunking id="9" string="Patrick Barrow" type="NP">
          <tokens>
            <token id="11" string="Patrick" />
            <token id="12" string="Barrow" />
          </tokens>
        </chunking>
        <chunking id="10" string="totally unjustified and illegal" type="ADJP">
          <tokens>
            <token id="4" string="totally" />
            <token id="5" string="unjustified" />
            <token id="6" string="and" />
            <token id="7" string="illegal" />
          </tokens>
        </chunking>
        <chunking id="11" string="Patrick Barrow , spokesman for the Meat and Livestock Commission , a trade organization" type="NP">
          <tokens>
            <token id="11" string="Patrick" />
            <token id="12" string="Barrow" />
            <token id="13" string="," />
            <token id="14" string="spokesman" />
            <token id="15" string="for" />
            <token id="16" string="the" />
            <token id="17" string="Meat" />
            <token id="18" string="and" />
            <token id="19" string="Livestock" />
            <token id="20" string="Commission" />
            <token id="21" string="," />
            <token id="22" string="a" />
            <token id="23" string="trade" />
            <token id="24" string="organization" />
          </tokens>
        </chunking>
        <chunking id="12" string="said" type="VP">
          <tokens>
            <token id="10" string="said" />
          </tokens>
        </chunking>
        <chunking id="13" string="Livestock Commission , a trade organization" type="NP">
          <tokens>
            <token id="19" string="Livestock" />
            <token id="20" string="Commission" />
            <token id="21" string="," />
            <token id="22" string="a" />
            <token id="23" string="trade" />
            <token id="24" string="organization" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">unjustified</governor>
          <dependent id="2">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">unjustified</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">unjustified</governor>
          <dependent id="4">totally</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">said</governor>
          <dependent id="5">unjustified</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">unjustified</governor>
          <dependent id="6">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">unjustified</governor>
          <dependent id="7">illegal</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Barrow</governor>
          <dependent id="11">Patrick</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">said</governor>
          <dependent id="12">Barrow</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="12">Barrow</governor>
          <dependent id="14">spokesman</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">Meat</governor>
          <dependent id="15">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">Meat</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">spokesman</governor>
          <dependent id="17">Meat</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="14">spokesman</governor>
          <dependent id="18">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">Commission</governor>
          <dependent id="19">Livestock</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">spokesman</governor>
          <dependent id="20">Commission</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">organization</governor>
          <dependent id="22">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">organization</governor>
          <dependent id="23">trade</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="20">Commission</governor>
          <dependent id="24">organization</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Livestock Commission" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="19" string="Livestock" />
            <token id="20" string="Commission" />
          </tokens>
        </entity>
        <entity id="2" string="Patrick Barrow" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Patrick" />
            <token id="12" string="Barrow" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>France accounted for slightly more than half of Britain&amp;apost;s beef exports last year, buying 70,000 tons of beef worth $264 million.</content>
      <tokens>
        <token id="1" string="France" lemma="France" stem="franc" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="2" string="accounted" lemma="account" stem="account" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="slightly" lemma="slightly" stem="slightli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="more" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="half" lemma="half" stem="half" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Britain" lemma="Britain" stem="britain" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="10" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="beef" lemma="beef" stem="beef" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="exports" lemma="export" stem="export" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="14" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="buying" lemma="buy" stem="bui" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="70,000" lemma="70,000" stem="70,000" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="18" string="tons" lemma="ton" stem="ton" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="beef" lemma="beef" stem="beef" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="worth" lemma="worth" stem="worth" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="23" string="264" lemma="264" stem="264" pos="CD" type="Number" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="24" string="million" lemma="million" stem="million" pos="CD" type="Word" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP France)) (VP (VBD accounted) (PP (IN for) (NP (NP (RB slightly) (QP (JJR more) (IN than) (NN half))) (PP (IN of) (NP (NP (NNP Britain) (POS 's)) (NN beef) (NNS exports))))) (NP-TMP (JJ last) (NN year)) (, ,) (S (VP (VBG buying) (NP (NP (CD 70,000) (NNS tons)) (PP (IN of) (NP (NN beef)))) (FRAG (ADJP (JJ worth) (NP (QP ($ $) (CD 264) (CD million)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="worth $ 264 million" type="ADJP">
          <tokens>
            <token id="21" string="worth" />
            <token id="22" string="$" />
            <token id="23" string="264" />
            <token id="24" string="million" />
          </tokens>
        </chunking>
        <chunking id="2" string="$ 264 million" type="NP">
          <tokens>
            <token id="22" string="$" />
            <token id="23" string="264" />
            <token id="24" string="million" />
          </tokens>
        </chunking>
        <chunking id="3" string="70,000 tons" type="NP">
          <tokens>
            <token id="17" string="70,000" />
            <token id="18" string="tons" />
          </tokens>
        </chunking>
        <chunking id="4" string="accounted for slightly more than half of Britain 's beef exports last year , buying 70,000 tons of beef worth $ 264 million" type="VP">
          <tokens>
            <token id="2" string="accounted" />
            <token id="3" string="for" />
            <token id="4" string="slightly" />
            <token id="5" string="more" />
            <token id="6" string="than" />
            <token id="7" string="half" />
            <token id="8" string="of" />
            <token id="9" string="Britain" />
            <token id="10" string="'s" />
            <token id="11" string="beef" />
            <token id="12" string="exports" />
            <token id="13" string="last" />
            <token id="14" string="year" />
            <token id="15" string="," />
            <token id="16" string="buying" />
            <token id="17" string="70,000" />
            <token id="18" string="tons" />
            <token id="19" string="of" />
            <token id="20" string="beef" />
            <token id="21" string="worth" />
            <token id="22" string="$" />
            <token id="23" string="264" />
            <token id="24" string="million" />
          </tokens>
        </chunking>
        <chunking id="5" string="70,000 tons of beef" type="NP">
          <tokens>
            <token id="17" string="70,000" />
            <token id="18" string="tons" />
            <token id="19" string="of" />
            <token id="20" string="beef" />
          </tokens>
        </chunking>
        <chunking id="6" string="Britain 's" type="NP">
          <tokens>
            <token id="9" string="Britain" />
            <token id="10" string="'s" />
          </tokens>
        </chunking>
        <chunking id="7" string="slightly more than half" type="NP">
          <tokens>
            <token id="4" string="slightly" />
            <token id="5" string="more" />
            <token id="6" string="than" />
            <token id="7" string="half" />
          </tokens>
        </chunking>
        <chunking id="8" string="buying 70,000 tons of beef worth $ 264 million" type="VP">
          <tokens>
            <token id="16" string="buying" />
            <token id="17" string="70,000" />
            <token id="18" string="tons" />
            <token id="19" string="of" />
            <token id="20" string="beef" />
            <token id="21" string="worth" />
            <token id="22" string="$" />
            <token id="23" string="264" />
            <token id="24" string="million" />
          </tokens>
        </chunking>
        <chunking id="9" string="France" type="NP">
          <tokens>
            <token id="1" string="France" />
          </tokens>
        </chunking>
        <chunking id="10" string="slightly more than half of Britain 's beef exports" type="NP">
          <tokens>
            <token id="4" string="slightly" />
            <token id="5" string="more" />
            <token id="6" string="than" />
            <token id="7" string="half" />
            <token id="8" string="of" />
            <token id="9" string="Britain" />
            <token id="10" string="'s" />
            <token id="11" string="beef" />
            <token id="12" string="exports" />
          </tokens>
        </chunking>
        <chunking id="11" string="beef" type="NP">
          <tokens>
            <token id="20" string="beef" />
          </tokens>
        </chunking>
        <chunking id="12" string="Britain 's beef exports" type="NP">
          <tokens>
            <token id="9" string="Britain" />
            <token id="10" string="'s" />
            <token id="11" string="beef" />
            <token id="12" string="exports" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">accounted</governor>
          <dependent id="1">France</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">accounted</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">half</governor>
          <dependent id="3">for</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">half</governor>
          <dependent id="4">slightly</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">half</governor>
          <dependent id="5">more</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="5">more</governor>
          <dependent id="6">than</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">accounted</governor>
          <dependent id="7">half</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">exports</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="12">exports</governor>
          <dependent id="9">Britain</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Britain</governor>
          <dependent id="10">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">exports</governor>
          <dependent id="11">beef</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">half</governor>
          <dependent id="12">exports</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">year</governor>
          <dependent id="13">last</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="2">accounted</governor>
          <dependent id="14">year</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="2">accounted</governor>
          <dependent id="16">buying</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="18">tons</governor>
          <dependent id="17">70,000</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">buying</governor>
          <dependent id="18">tons</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">beef</governor>
          <dependent id="19">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">tons</governor>
          <dependent id="20">beef</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="16">buying</governor>
          <dependent id="21">worth</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="21">worth</governor>
          <dependent id="22">$</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">million</governor>
          <dependent id="23">264</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="22">$</governor>
          <dependent id="24">million</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="$ 264 million" type="MONEY" score="0.0">
          <tokens>
            <token id="22" string="$" />
            <token id="23" string="264" />
            <token id="24" string="million" />
          </tokens>
        </entity>
        <entity id="2" string="Britain" type="LOCATION" score="0.0">
          <tokens>
            <token id="9" string="Britain" />
          </tokens>
        </entity>
        <entity id="3" string="France" type="LOCATION" score="0.0">
          <tokens>
            <token id="1" string="France" />
          </tokens>
        </entity>
        <entity id="4" string="last year" type="DATE" score="0.0">
          <tokens>
            <token id="13" string="last" />
            <token id="14" string="year" />
          </tokens>
        </entity>
        <entity id="5" string="70,000" type="NUMBER" score="0.0">
          <tokens>
            <token id="17" string="70,000" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="10" has_coreference="false">
      <content>West Germany bought $50 million worth last year.</content>
      <tokens>
        <token id="1" string="West" lemma="West" stem="west" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="2" string="Germany" lemma="Germany" stem="germani" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="3" string="bought" lemma="buy" stem="bought" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="5" string="50" lemma="50" stem="50" pos="CD" type="Number" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="6" string="million" lemma="million" stem="million" pos="CD" type="Word" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="7" string="worth" lemma="worth" stem="worth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="9" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP West) (NNP Germany)) (VP (VBD bought) (NP (QP ($ $) (CD 50) (CD million)) (NN worth)) (NP-TMP (JJ last) (NN year))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="$ 50 million worth" type="NP">
          <tokens>
            <token id="4" string="$" />
            <token id="5" string="50" />
            <token id="6" string="million" />
            <token id="7" string="worth" />
          </tokens>
        </chunking>
        <chunking id="2" string="bought $ 50 million worth last year" type="VP">
          <tokens>
            <token id="3" string="bought" />
            <token id="4" string="$" />
            <token id="5" string="50" />
            <token id="6" string="million" />
            <token id="7" string="worth" />
            <token id="8" string="last" />
            <token id="9" string="year" />
          </tokens>
        </chunking>
        <chunking id="3" string="West Germany" type="NP">
          <tokens>
            <token id="1" string="West" />
            <token id="2" string="Germany" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Germany</governor>
          <dependent id="1">West</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">bought</governor>
          <dependent id="2">Germany</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">bought</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="7">worth</governor>
          <dependent id="4">$</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">million</governor>
          <dependent id="5">50</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="4">$</governor>
          <dependent id="6">million</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">bought</governor>
          <dependent id="7">worth</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">year</governor>
          <dependent id="8">last</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="3">bought</governor>
          <dependent id="9">year</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="$ 50 million" type="MONEY" score="0.0">
          <tokens>
            <token id="4" string="$" />
            <token id="5" string="50" />
            <token id="6" string="million" />
          </tokens>
        </entity>
        <entity id="2" string="West Germany" type="LOCATION" score="0.0">
          <tokens>
            <token id="1" string="West" />
            <token id="2" string="Germany" />
          </tokens>
        </entity>
        <entity id="3" string="last year" type="DATE" score="0.0">
          <tokens>
            <token id="8" string="last" />
            <token id="9" string="year" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="11" has_coreference="false">
      <content>Although other countries have recently placed some restrictions on British beef and cattle, the French and German moves were the strongest by far.</content>
      <tokens>
        <token id="1" string="Although" lemma="although" stem="although" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="countries" lemma="country" stem="countri" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="recently" lemma="recently" stem="recent" pos="RB" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="6" string="placed" lemma="place" stem="place" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="restrictions" lemma="restriction" stem="restrict" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="British" lemma="british" stem="british" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="11" string="beef" lemma="beef" stem="beef" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="cattle" lemma="cattle" stem="cattl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="French" lemma="french" stem="french" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="17" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="German" lemma="german" stem="german" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="19" string="moves" lemma="move" stem="move" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="strongest" lemma="strongest" stem="strongest" pos="JJS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="far" lemma="far" stem="far" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN Although) (S (NP (JJ other) (NNS countries)) (VP (VBP have) (ADVP (RB recently)) (VP (VBN placed) (NP (DT some) (NNS restrictions)) (PP (IN on) (NP (JJ British) (NN beef) (CC and) (NNS cattle))))))) (, ,) (NP (DT the) (JJ French) (CC and) (JJ German) (NNS moves)) (VP (VBD were) (NP (DT the) (JJS strongest)) (PP (IN by) (ADVP (RB far)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Although other countries have recently placed some restrictions on British beef and cattle" type="SBAR">
          <tokens>
            <token id="1" string="Although" />
            <token id="2" string="other" />
            <token id="3" string="countries" />
            <token id="4" string="have" />
            <token id="5" string="recently" />
            <token id="6" string="placed" />
            <token id="7" string="some" />
            <token id="8" string="restrictions" />
            <token id="9" string="on" />
            <token id="10" string="British" />
            <token id="11" string="beef" />
            <token id="12" string="and" />
            <token id="13" string="cattle" />
          </tokens>
        </chunking>
        <chunking id="2" string="were the strongest by far" type="VP">
          <tokens>
            <token id="20" string="were" />
            <token id="21" string="the" />
            <token id="22" string="strongest" />
            <token id="23" string="by" />
            <token id="24" string="far" />
          </tokens>
        </chunking>
        <chunking id="3" string="the French and German moves" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="French" />
            <token id="17" string="and" />
            <token id="18" string="German" />
            <token id="19" string="moves" />
          </tokens>
        </chunking>
        <chunking id="4" string="the strongest" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="strongest" />
          </tokens>
        </chunking>
        <chunking id="5" string="placed some restrictions on British beef and cattle" type="VP">
          <tokens>
            <token id="6" string="placed" />
            <token id="7" string="some" />
            <token id="8" string="restrictions" />
            <token id="9" string="on" />
            <token id="10" string="British" />
            <token id="11" string="beef" />
            <token id="12" string="and" />
            <token id="13" string="cattle" />
          </tokens>
        </chunking>
        <chunking id="6" string="have recently placed some restrictions on British beef and cattle" type="VP">
          <tokens>
            <token id="4" string="have" />
            <token id="5" string="recently" />
            <token id="6" string="placed" />
            <token id="7" string="some" />
            <token id="8" string="restrictions" />
            <token id="9" string="on" />
            <token id="10" string="British" />
            <token id="11" string="beef" />
            <token id="12" string="and" />
            <token id="13" string="cattle" />
          </tokens>
        </chunking>
        <chunking id="7" string="other countries" type="NP">
          <tokens>
            <token id="2" string="other" />
            <token id="3" string="countries" />
          </tokens>
        </chunking>
        <chunking id="8" string="some restrictions" type="NP">
          <tokens>
            <token id="7" string="some" />
            <token id="8" string="restrictions" />
          </tokens>
        </chunking>
        <chunking id="9" string="British beef and cattle" type="NP">
          <tokens>
            <token id="10" string="British" />
            <token id="11" string="beef" />
            <token id="12" string="and" />
            <token id="13" string="cattle" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="6">placed</governor>
          <dependent id="1">Although</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">countries</governor>
          <dependent id="2">other</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">placed</governor>
          <dependent id="3">countries</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">placed</governor>
          <dependent id="4">have</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">placed</governor>
          <dependent id="5">recently</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="22">strongest</governor>
          <dependent id="6">placed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">restrictions</governor>
          <dependent id="7">some</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">placed</governor>
          <dependent id="8">restrictions</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">beef</governor>
          <dependent id="9">on</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">beef</governor>
          <dependent id="10">British</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">placed</governor>
          <dependent id="11">beef</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="11">beef</governor>
          <dependent id="12">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">beef</governor>
          <dependent id="13">cattle</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">moves</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">moves</governor>
          <dependent id="16">French</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="16">French</governor>
          <dependent id="17">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">French</governor>
          <dependent id="18">German</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">strongest</governor>
          <dependent id="19">moves</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="22">strongest</governor>
          <dependent id="20">were</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">strongest</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="22">strongest</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">far</governor>
          <dependent id="23">by</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="22">strongest</governor>
          <dependent id="24">far</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="French" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="16" string="French" />
          </tokens>
        </entity>
        <entity id="2" string="British" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="10" string="British" />
          </tokens>
        </entity>
        <entity id="3" string="recently" type="DATE" score="0.0">
          <tokens>
            <token id="5" string="recently" />
          </tokens>
        </entity>
        <entity id="4" string="German" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="18" string="German" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>The United States does not import British beef and recently rescinded permits for the importation of live cattle.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="United" lemma="United" stem="unite" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="3" string="States" lemma="States" stem="state" pos="NNPS" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="4" string="does" lemma="do" stem="doe" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="import" lemma="import" stem="import" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="British" lemma="british" stem="british" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="8" string="beef" lemma="beef" stem="beef" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="recently" lemma="recently" stem="recent" pos="RB" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="11" string="rescinded" lemma="rescind" stem="rescind" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="permits" lemma="permit" stem="permit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="importation" lemma="importation" stem="import" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="live" lemma="live" stem="live" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="cattle" lemma="cattle" stem="cattl" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NNP United) (NNPS States)) (VP (VP (VBZ does) (RB not) (VP (VB import) (NP (JJ British) (NN beef)))) (CC and) (VP (ADVP (RB recently)) (VBD rescinded) (NP (NNS permits)) (PP (IN for) (NP (NP (DT the) (NN importation)) (PP (IN of) (NP (JJ live) (NNS cattle))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="does not import British beef and recently rescinded permits for the importation of live cattle" type="VP">
          <tokens>
            <token id="4" string="does" />
            <token id="5" string="not" />
            <token id="6" string="import" />
            <token id="7" string="British" />
            <token id="8" string="beef" />
            <token id="9" string="and" />
            <token id="10" string="recently" />
            <token id="11" string="rescinded" />
            <token id="12" string="permits" />
            <token id="13" string="for" />
            <token id="14" string="the" />
            <token id="15" string="importation" />
            <token id="16" string="of" />
            <token id="17" string="live" />
            <token id="18" string="cattle" />
          </tokens>
        </chunking>
        <chunking id="2" string="does not import British beef" type="VP">
          <tokens>
            <token id="4" string="does" />
            <token id="5" string="not" />
            <token id="6" string="import" />
            <token id="7" string="British" />
            <token id="8" string="beef" />
          </tokens>
        </chunking>
        <chunking id="3" string="British beef" type="NP">
          <tokens>
            <token id="7" string="British" />
            <token id="8" string="beef" />
          </tokens>
        </chunking>
        <chunking id="4" string="recently rescinded permits for the importation of live cattle" type="VP">
          <tokens>
            <token id="10" string="recently" />
            <token id="11" string="rescinded" />
            <token id="12" string="permits" />
            <token id="13" string="for" />
            <token id="14" string="the" />
            <token id="15" string="importation" />
            <token id="16" string="of" />
            <token id="17" string="live" />
            <token id="18" string="cattle" />
          </tokens>
        </chunking>
        <chunking id="5" string="import British beef" type="VP">
          <tokens>
            <token id="6" string="import" />
            <token id="7" string="British" />
            <token id="8" string="beef" />
          </tokens>
        </chunking>
        <chunking id="6" string="the importation" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="importation" />
          </tokens>
        </chunking>
        <chunking id="7" string="permits" type="NP">
          <tokens>
            <token id="12" string="permits" />
          </tokens>
        </chunking>
        <chunking id="8" string="live cattle" type="NP">
          <tokens>
            <token id="17" string="live" />
            <token id="18" string="cattle" />
          </tokens>
        </chunking>
        <chunking id="9" string="The United States" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="United" />
            <token id="3" string="States" />
          </tokens>
        </chunking>
        <chunking id="10" string="the importation of live cattle" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="importation" />
            <token id="16" string="of" />
            <token id="17" string="live" />
            <token id="18" string="cattle" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">States</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">States</governor>
          <dependent id="2">United</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">import</governor>
          <dependent id="3">States</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">import</governor>
          <dependent id="4">does</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="6">import</governor>
          <dependent id="5">not</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">import</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">beef</governor>
          <dependent id="7">British</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">import</governor>
          <dependent id="8">beef</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">import</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">rescinded</governor>
          <dependent id="10">recently</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">import</governor>
          <dependent id="11">rescinded</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">rescinded</governor>
          <dependent id="12">permits</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">importation</governor>
          <dependent id="13">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">importation</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">rescinded</governor>
          <dependent id="15">importation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">cattle</governor>
          <dependent id="16">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">cattle</governor>
          <dependent id="17">live</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">importation</governor>
          <dependent id="18">cattle</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="British" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="7" string="British" />
          </tokens>
        </entity>
        <entity id="2" string="United States" type="LOCATION" score="0.0">
          <tokens>
            <token id="2" string="United" />
            <token id="3" string="States" />
          </tokens>
        </entity>
        <entity id="3" string="recently" type="DATE" score="0.0">
          <tokens>
            <token id="10" string="recently" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>British officials have been joined by European Community commissioners in protesting the French and Germany import ban.</content>
      <tokens>
        <token id="1" string="British" lemma="british" stem="british" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="2" string="officials" lemma="official" stem="offici" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="joined" lemma="join" stem="join" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="European" lemma="European" stem="european" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="8" string="Community" lemma="Community" stem="commun" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="9" string="commissioners" lemma="commissioner" stem="commission" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="protesting" lemma="protest" stem="protest" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="French" lemma="french" stem="french" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="Germany" lemma="Germany" stem="germani" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="16" string="import" lemma="import" stem="import" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="ban" lemma="ban" stem="ban" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (JJ British) (NNS officials)) (VP (VBP have) (VP (VBN been) (VP (VBN joined) (PP (IN by) (NP (NNP European) (NNP Community) (NNS commissioners))) (PP (IN in) (S (VP (VBG protesting) (NP (DT the) (JJ French) (CC and) (NNP Germany) (NN import) (NN ban)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="joined by European Community commissioners in protesting the French and Germany import ban" type="VP">
          <tokens>
            <token id="5" string="joined" />
            <token id="6" string="by" />
            <token id="7" string="European" />
            <token id="8" string="Community" />
            <token id="9" string="commissioners" />
            <token id="10" string="in" />
            <token id="11" string="protesting" />
            <token id="12" string="the" />
            <token id="13" string="French" />
            <token id="14" string="and" />
            <token id="15" string="Germany" />
            <token id="16" string="import" />
            <token id="17" string="ban" />
          </tokens>
        </chunking>
        <chunking id="2" string="the French and Germany import ban" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="French" />
            <token id="14" string="and" />
            <token id="15" string="Germany" />
            <token id="16" string="import" />
            <token id="17" string="ban" />
          </tokens>
        </chunking>
        <chunking id="3" string="European Community commissioners" type="NP">
          <tokens>
            <token id="7" string="European" />
            <token id="8" string="Community" />
            <token id="9" string="commissioners" />
          </tokens>
        </chunking>
        <chunking id="4" string="protesting the French and Germany import ban" type="VP">
          <tokens>
            <token id="11" string="protesting" />
            <token id="12" string="the" />
            <token id="13" string="French" />
            <token id="14" string="and" />
            <token id="15" string="Germany" />
            <token id="16" string="import" />
            <token id="17" string="ban" />
          </tokens>
        </chunking>
        <chunking id="5" string="British officials" type="NP">
          <tokens>
            <token id="1" string="British" />
            <token id="2" string="officials" />
          </tokens>
        </chunking>
        <chunking id="6" string="have been joined by European Community commissioners in protesting the French and Germany import ban" type="VP">
          <tokens>
            <token id="3" string="have" />
            <token id="4" string="been" />
            <token id="5" string="joined" />
            <token id="6" string="by" />
            <token id="7" string="European" />
            <token id="8" string="Community" />
            <token id="9" string="commissioners" />
            <token id="10" string="in" />
            <token id="11" string="protesting" />
            <token id="12" string="the" />
            <token id="13" string="French" />
            <token id="14" string="and" />
            <token id="15" string="Germany" />
            <token id="16" string="import" />
            <token id="17" string="ban" />
          </tokens>
        </chunking>
        <chunking id="7" string="been joined by European Community commissioners in protesting the French and Germany import ban" type="VP">
          <tokens>
            <token id="4" string="been" />
            <token id="5" string="joined" />
            <token id="6" string="by" />
            <token id="7" string="European" />
            <token id="8" string="Community" />
            <token id="9" string="commissioners" />
            <token id="10" string="in" />
            <token id="11" string="protesting" />
            <token id="12" string="the" />
            <token id="13" string="French" />
            <token id="14" string="and" />
            <token id="15" string="Germany" />
            <token id="16" string="import" />
            <token id="17" string="ban" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="2">officials</governor>
          <dependent id="1">British</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="5">joined</governor>
          <dependent id="2">officials</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">joined</governor>
          <dependent id="3">have</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="5">joined</governor>
          <dependent id="4">been</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">joined</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">commissioners</governor>
          <dependent id="6">by</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">commissioners</governor>
          <dependent id="7">European</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">commissioners</governor>
          <dependent id="8">Community</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">joined</governor>
          <dependent id="9">commissioners</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">protesting</governor>
          <dependent id="10">in</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="5">joined</governor>
          <dependent id="11">protesting</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">French</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">protesting</governor>
          <dependent id="13">French</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">French</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">ban</governor>
          <dependent id="15">Germany</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">ban</governor>
          <dependent id="16">import</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">French</governor>
          <dependent id="17">ban</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="French" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="13" string="French" />
          </tokens>
        </entity>
        <entity id="2" string="British" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="1" string="British" />
          </tokens>
        </entity>
        <entity id="3" string="European Community" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="7" string="European" />
            <token id="8" string="Community" />
          </tokens>
        </entity>
        <entity id="4" string="Germany" type="LOCATION" score="0.0">
          <tokens>
            <token id="15" string="Germany" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="14" has_coreference="false">
      <content>Mad cow disease has been responsible for the deaths of nearly 14,000 cows since it was first noticed in the mid-1980s.</content>
      <tokens>
        <token id="1" string="Mad" lemma="Mad" stem="mad" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="cow" lemma="cow" stem="cow" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="disease" lemma="disease" stem="diseas" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="true" is_refers="false" />
        <token id="4" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="responsible" lemma="responsible" stem="respons" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="deaths" lemma="death" stem="death" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="nearly" lemma="nearly" stem="nearli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="14,000" lemma="14,000" stem="14,000" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="13" string="cows" lemma="cow" stem="cow" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="since" lemma="since" stem="sinc" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="18" string="noticed" lemma="notice" stem="notic" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="21" string="mid-1980s" lemma="mid-1980" stem="mid-1980" pos="NNS" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Mad) (NN cow) (NN disease)) (VP (VBZ has) (VP (VBN been) (ADJP (JJ responsible)) (PP (IN for) (NP (NP (DT the) (NNS deaths)) (PP (IN of) (NP (RB nearly) (CD 14,000) (NNS cows))))) (SBAR (IN since) (S (NP (PRP it)) (VP (VBD was) (ADVP (JJ first)) (VP (VBN noticed) (PP (IN in) (NP (DT the) (NNS mid-1980s))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="noticed in the mid-1980s" type="VP">
          <tokens>
            <token id="18" string="noticed" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="mid-1980s" />
          </tokens>
        </chunking>
        <chunking id="2" string="responsible" type="ADJP">
          <tokens>
            <token id="6" string="responsible" />
          </tokens>
        </chunking>
        <chunking id="3" string="since it was first noticed in the mid-1980s" type="SBAR">
          <tokens>
            <token id="14" string="since" />
            <token id="15" string="it" />
            <token id="16" string="was" />
            <token id="17" string="first" />
            <token id="18" string="noticed" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="mid-1980s" />
          </tokens>
        </chunking>
        <chunking id="4" string="nearly 14,000 cows" type="NP">
          <tokens>
            <token id="11" string="nearly" />
            <token id="12" string="14,000" />
            <token id="13" string="cows" />
          </tokens>
        </chunking>
        <chunking id="5" string="has been responsible for the deaths of nearly 14,000 cows since it was first noticed in the mid-1980s" type="VP">
          <tokens>
            <token id="4" string="has" />
            <token id="5" string="been" />
            <token id="6" string="responsible" />
            <token id="7" string="for" />
            <token id="8" string="the" />
            <token id="9" string="deaths" />
            <token id="10" string="of" />
            <token id="11" string="nearly" />
            <token id="12" string="14,000" />
            <token id="13" string="cows" />
            <token id="14" string="since" />
            <token id="15" string="it" />
            <token id="16" string="was" />
            <token id="17" string="first" />
            <token id="18" string="noticed" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="mid-1980s" />
          </tokens>
        </chunking>
        <chunking id="6" string="the deaths" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="deaths" />
          </tokens>
        </chunking>
        <chunking id="7" string="the mid-1980s" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="mid-1980s" />
          </tokens>
        </chunking>
        <chunking id="8" string="it" type="NP">
          <tokens>
            <token id="15" string="it" />
          </tokens>
        </chunking>
        <chunking id="9" string="been responsible for the deaths of nearly 14,000 cows since it was first noticed in the mid-1980s" type="VP">
          <tokens>
            <token id="5" string="been" />
            <token id="6" string="responsible" />
            <token id="7" string="for" />
            <token id="8" string="the" />
            <token id="9" string="deaths" />
            <token id="10" string="of" />
            <token id="11" string="nearly" />
            <token id="12" string="14,000" />
            <token id="13" string="cows" />
            <token id="14" string="since" />
            <token id="15" string="it" />
            <token id="16" string="was" />
            <token id="17" string="first" />
            <token id="18" string="noticed" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="mid-1980s" />
          </tokens>
        </chunking>
        <chunking id="10" string="the deaths of nearly 14,000 cows" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="deaths" />
            <token id="10" string="of" />
            <token id="11" string="nearly" />
            <token id="12" string="14,000" />
            <token id="13" string="cows" />
          </tokens>
        </chunking>
        <chunking id="11" string="Mad cow disease" type="NP">
          <tokens>
            <token id="1" string="Mad" />
            <token id="2" string="cow" />
            <token id="3" string="disease" />
          </tokens>
        </chunking>
        <chunking id="12" string="was first noticed in the mid-1980s" type="VP">
          <tokens>
            <token id="16" string="was" />
            <token id="17" string="first" />
            <token id="18" string="noticed" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="mid-1980s" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">disease</governor>
          <dependent id="1">Mad</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">disease</governor>
          <dependent id="2">cow</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">responsible</governor>
          <dependent id="3">disease</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">responsible</governor>
          <dependent id="4">has</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">responsible</governor>
          <dependent id="5">been</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">responsible</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">deaths</governor>
          <dependent id="7">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">deaths</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">responsible</governor>
          <dependent id="9">deaths</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">cows</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">cows</governor>
          <dependent id="11">nearly</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="13">cows</governor>
          <dependent id="12">14,000</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">deaths</governor>
          <dependent id="13">cows</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">noticed</governor>
          <dependent id="14">since</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="18">noticed</governor>
          <dependent id="15">it</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="18">noticed</governor>
          <dependent id="16">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">noticed</governor>
          <dependent id="17">first</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="6">responsible</governor>
          <dependent id="18">noticed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">mid-1980s</governor>
          <dependent id="19">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">mid-1980s</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">noticed</governor>
          <dependent id="21">mid-1980s</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="17" string="first" />
          </tokens>
        </entity>
        <entity id="2" string="disease" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="3" string="disease" />
          </tokens>
        </entity>
        <entity id="3" string="14,000" type="NUMBER" score="0.0">
          <tokens>
            <token id="12" string="14,000" />
          </tokens>
        </entity>
        <entity id="4" string="the mid-1980s" type="DATE" score="0.0">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="mid-1980s" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>BSE-infected cows &amp;quot;degenerate very quickly,&amp;quot; said a spokeswoman from Britain&amp;apost;s Ministry of Agriculture.</content>
      <tokens>
        <token id="1" string="BSE-infected" lemma="bse-infected" stem="bse-infect" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="2" string="cows" lemma="cow" stem="cow" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="degenerate" lemma="degenerate" stem="degener" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="very" lemma="very" stem="veri" pos="RB" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="quickly" lemma="quickly" stem="quickli" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="spokeswoman" lemma="spokeswoman" stem="spokeswoman" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Britain" lemma="Britain" stem="britain" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="true" />
        <token id="14" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="15" string="Ministry" lemma="Ministry" stem="ministri" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="16" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="17" string="Agriculture" lemma="Agriculture" stem="agricultur" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (JJ BSE-infected) (NNS cows)) (`` ``) (NP (NP (JJ degenerate)) (ADVP (RB very) (RB quickly))) (, ,) ('' '')) (VP (VBD said) (NP (DT a) (NN spokeswoman)) (PP (IN from) (NP (NP (NP (NNP Britain) (POS 's)) (NNP Ministry)) (PP (IN of) (NP (NNP Agriculture)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="BSE-infected cows `` degenerate very quickly , ''" type="NP">
          <tokens>
            <token id="1" string="BSE-infected" />
            <token id="2" string="cows" />
            <token id="3" string="&quot;" />
            <token id="4" string="degenerate" />
            <token id="5" string="very" />
            <token id="6" string="quickly" />
            <token id="7" string="," />
            <token id="8" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="2" string="BSE-infected cows" type="NP">
          <tokens>
            <token id="1" string="BSE-infected" />
            <token id="2" string="cows" />
          </tokens>
        </chunking>
        <chunking id="3" string="degenerate very quickly" type="NP">
          <tokens>
            <token id="4" string="degenerate" />
            <token id="5" string="very" />
            <token id="6" string="quickly" />
          </tokens>
        </chunking>
        <chunking id="4" string="said a spokeswoman from Britain 's Ministry of Agriculture" type="VP">
          <tokens>
            <token id="9" string="said" />
            <token id="10" string="a" />
            <token id="11" string="spokeswoman" />
            <token id="12" string="from" />
            <token id="13" string="Britain" />
            <token id="14" string="'s" />
            <token id="15" string="Ministry" />
            <token id="16" string="of" />
            <token id="17" string="Agriculture" />
          </tokens>
        </chunking>
        <chunking id="5" string="Britain 's" type="NP">
          <tokens>
            <token id="13" string="Britain" />
            <token id="14" string="'s" />
          </tokens>
        </chunking>
        <chunking id="6" string="Britain 's Ministry of Agriculture" type="NP">
          <tokens>
            <token id="13" string="Britain" />
            <token id="14" string="'s" />
            <token id="15" string="Ministry" />
            <token id="16" string="of" />
            <token id="17" string="Agriculture" />
          </tokens>
        </chunking>
        <chunking id="7" string="Agriculture" type="NP">
          <tokens>
            <token id="17" string="Agriculture" />
          </tokens>
        </chunking>
        <chunking id="8" string="degenerate" type="NP">
          <tokens>
            <token id="4" string="degenerate" />
          </tokens>
        </chunking>
        <chunking id="9" string="a spokeswoman" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="spokeswoman" />
          </tokens>
        </chunking>
        <chunking id="10" string="Britain 's Ministry" type="NP">
          <tokens>
            <token id="13" string="Britain" />
            <token id="14" string="'s" />
            <token id="15" string="Ministry" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="2">cows</governor>
          <dependent id="1">BSE-infected</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">said</governor>
          <dependent id="2">cows</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="2">cows</governor>
          <dependent id="4">degenerate</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">quickly</governor>
          <dependent id="5">very</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">degenerate</governor>
          <dependent id="6">quickly</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">said</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">spokeswoman</governor>
          <dependent id="10">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">said</governor>
          <dependent id="11">spokeswoman</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">Ministry</governor>
          <dependent id="12">from</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="15">Ministry</governor>
          <dependent id="13">Britain</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Britain</governor>
          <dependent id="14">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">said</governor>
          <dependent id="15">Ministry</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">Agriculture</governor>
          <dependent id="16">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">Ministry</governor>
          <dependent id="17">Agriculture</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="BSE-infected" type="MISC" score="0.0">
          <tokens>
            <token id="1" string="BSE-infected" />
          </tokens>
        </entity>
        <entity id="2" string="Britain" type="LOCATION" score="0.0">
          <tokens>
            <token id="13" string="Britain" />
          </tokens>
        </entity>
        <entity id="3" string="Ministry of Agriculture" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="15" string="Ministry" />
            <token id="16" string="of" />
            <token id="17" string="Agriculture" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>The cows become aggressive and then wobbly-legged before dying.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="cows" lemma="cow" stem="cow" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="become" lemma="become" stem="becom" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="aggressive" lemma="aggressive" stem="aggress" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="wobbly-legged" lemma="wobbly-legged" stem="wobbly-leg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="before" lemma="before" stem="befor" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="dying" lemma="die" stem="dy" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NNS cows)) (VP (VBP become) (ADJP (ADJP (JJ aggressive)) (CC and) (ADJP (RB then) (JJ wobbly-legged))) (PP (IN before) (NP (VBG dying)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="The cows" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="cows" />
          </tokens>
        </chunking>
        <chunking id="2" string="dying" type="NP">
          <tokens>
            <token id="9" string="dying" />
          </tokens>
        </chunking>
        <chunking id="3" string="become aggressive and then wobbly-legged before dying" type="VP">
          <tokens>
            <token id="3" string="become" />
            <token id="4" string="aggressive" />
            <token id="5" string="and" />
            <token id="6" string="then" />
            <token id="7" string="wobbly-legged" />
            <token id="8" string="before" />
            <token id="9" string="dying" />
          </tokens>
        </chunking>
        <chunking id="4" string="aggressive" type="ADJP">
          <tokens>
            <token id="4" string="aggressive" />
          </tokens>
        </chunking>
        <chunking id="5" string="then wobbly-legged" type="ADJP">
          <tokens>
            <token id="6" string="then" />
            <token id="7" string="wobbly-legged" />
          </tokens>
        </chunking>
        <chunking id="6" string="aggressive and then wobbly-legged" type="ADJP">
          <tokens>
            <token id="4" string="aggressive" />
            <token id="5" string="and" />
            <token id="6" string="then" />
            <token id="7" string="wobbly-legged" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">cows</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">become</governor>
          <dependent id="2">cows</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">become</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">become</governor>
          <dependent id="4">aggressive</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">aggressive</governor>
          <dependent id="5">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">wobbly-legged</governor>
          <dependent id="6">then</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">aggressive</governor>
          <dependent id="7">wobbly-legged</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">dying</governor>
          <dependent id="8">before</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">become</governor>
          <dependent id="9">dying</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="17" has_coreference="true">
      <content>No one is certain what causes the disease, which affects the cow&amp;apost;s brain.</content>
      <tokens>
        <token id="1" string="No" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="one" lemma="one" stem="on" pos="NN" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="certain" lemma="certain" stem="certain" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="causes" lemma="cause" stem="caus" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="disease" lemma="disease" stem="diseas" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="true" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="affects" lemma="affect" stem="affect" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="cow" lemma="cow" stem="cow" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="brain" lemma="brain" stem="brain" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT No) (NN one)) (VP (VBZ is) (ADJP (JJ certain)) (SBAR (WHNP (WP what)) (S (VP (VBZ causes) (NP (NP (DT the) (NN disease)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ affects) (NP (NP (DT the) (NN cow) (POS 's)) (NN brain)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="No one" type="NP">
          <tokens>
            <token id="1" string="No" />
            <token id="2" string="one" />
          </tokens>
        </chunking>
        <chunking id="2" string="the disease" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="disease" />
          </tokens>
        </chunking>
        <chunking id="3" string="affects the cow 's brain" type="VP">
          <tokens>
            <token id="11" string="affects" />
            <token id="12" string="the" />
            <token id="13" string="cow" />
            <token id="14" string="'s" />
            <token id="15" string="brain" />
          </tokens>
        </chunking>
        <chunking id="4" string="is certain what causes the disease , which affects the cow 's brain" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="certain" />
            <token id="5" string="what" />
            <token id="6" string="causes" />
            <token id="7" string="the" />
            <token id="8" string="disease" />
            <token id="9" string="," />
            <token id="10" string="which" />
            <token id="11" string="affects" />
            <token id="12" string="the" />
            <token id="13" string="cow" />
            <token id="14" string="'s" />
            <token id="15" string="brain" />
          </tokens>
        </chunking>
        <chunking id="5" string="the cow 's" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="cow" />
            <token id="14" string="'s" />
          </tokens>
        </chunking>
        <chunking id="6" string="causes the disease , which affects the cow 's brain" type="VP">
          <tokens>
            <token id="6" string="causes" />
            <token id="7" string="the" />
            <token id="8" string="disease" />
            <token id="9" string="," />
            <token id="10" string="which" />
            <token id="11" string="affects" />
            <token id="12" string="the" />
            <token id="13" string="cow" />
            <token id="14" string="'s" />
            <token id="15" string="brain" />
          </tokens>
        </chunking>
        <chunking id="7" string="which affects the cow 's brain" type="SBAR">
          <tokens>
            <token id="10" string="which" />
            <token id="11" string="affects" />
            <token id="12" string="the" />
            <token id="13" string="cow" />
            <token id="14" string="'s" />
            <token id="15" string="brain" />
          </tokens>
        </chunking>
        <chunking id="8" string="certain" type="ADJP">
          <tokens>
            <token id="4" string="certain" />
          </tokens>
        </chunking>
        <chunking id="9" string="what causes the disease , which affects the cow 's brain" type="SBAR">
          <tokens>
            <token id="5" string="what" />
            <token id="6" string="causes" />
            <token id="7" string="the" />
            <token id="8" string="disease" />
            <token id="9" string="," />
            <token id="10" string="which" />
            <token id="11" string="affects" />
            <token id="12" string="the" />
            <token id="13" string="cow" />
            <token id="14" string="'s" />
            <token id="15" string="brain" />
          </tokens>
        </chunking>
        <chunking id="10" string="the disease , which affects the cow 's brain" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="disease" />
            <token id="9" string="," />
            <token id="10" string="which" />
            <token id="11" string="affects" />
            <token id="12" string="the" />
            <token id="13" string="cow" />
            <token id="14" string="'s" />
            <token id="15" string="brain" />
          </tokens>
        </chunking>
        <chunking id="11" string="the cow 's brain" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="cow" />
            <token id="14" string="'s" />
            <token id="15" string="brain" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="neg">
          <governor id="2">one</governor>
          <dependent id="1">No</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">certain</governor>
          <dependent id="2">one</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">certain</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">certain</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">causes</governor>
          <dependent id="5">what</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">certain</governor>
          <dependent id="6">causes</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">disease</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">causes</governor>
          <dependent id="8">disease</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">affects</governor>
          <dependent id="10">which</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="8">disease</governor>
          <dependent id="11">affects</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">cow</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="15">brain</governor>
          <dependent id="13">cow</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">cow</governor>
          <dependent id="14">'s</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">affects</governor>
          <dependent id="15">brain</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="2" string="one" />
          </tokens>
        </entity>
        <entity id="2" string="disease" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="8" string="disease" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="18" has_coreference="false">
      <content>But the prime suspect is tainted cow feed.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="prime" lemma="prime" stem="prime" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="suspect" lemma="suspect" stem="suspect" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="tainted" lemma="taint" stem="taint" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="cow" lemma="cow" stem="cow" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="feed" lemma="feed" stem="feed" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (DT the) (JJ prime) (NN suspect)) (VP (VBZ is) (VP (VBN tainted) (NP (NN cow) (NN feed)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the prime suspect" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="prime" />
            <token id="4" string="suspect" />
          </tokens>
        </chunking>
        <chunking id="2" string="tainted cow feed" type="VP">
          <tokens>
            <token id="6" string="tainted" />
            <token id="7" string="cow" />
            <token id="8" string="feed" />
          </tokens>
        </chunking>
        <chunking id="3" string="cow feed" type="NP">
          <tokens>
            <token id="7" string="cow" />
            <token id="8" string="feed" />
          </tokens>
        </chunking>
        <chunking id="4" string="is tainted cow feed" type="VP">
          <tokens>
            <token id="5" string="is" />
            <token id="6" string="tainted" />
            <token id="7" string="cow" />
            <token id="8" string="feed" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="6">tainted</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">suspect</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">suspect</governor>
          <dependent id="3">prime</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="6">tainted</governor>
          <dependent id="4">suspect</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="6">tainted</governor>
          <dependent id="5">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">tainted</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">feed</governor>
          <dependent id="7">cow</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">tainted</governor>
          <dependent id="8">feed</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="19" has_coreference="true">
      <content>Some experts believe that cattle contracted the disease as a result of eating food contaminated with the remains of sheep infected with a BSE-like disease called scrapie.</content>
      <tokens>
        <token id="1" string="Some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="experts" lemma="expert" stem="expert" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="believe" lemma="believe" stem="believ" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="cattle" lemma="cattle" stem="cattl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="contracted" lemma="contract" stem="contract" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="disease" lemma="disease" stem="diseas" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="9" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="result" lemma="result" stem="result" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="eating" lemma="eat" stem="eat" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="food" lemma="food" stem="food" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="contaminated" lemma="contaminate" stem="contamin" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="remains" lemma="remains" stem="remain" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="sheep" lemma="sheep" stem="sheep" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="infected" lemma="infect" stem="infect" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="BSE-like" lemma="bse-like" stem="bse-like" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="25" string="disease" lemma="disease" stem="diseas" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="26" string="called" lemma="call" stem="call" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="scrapie" lemma="scrapie" stem="scrapi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT Some) (NNS experts)) (VP (VBP believe) (SBAR (IN that) (S (NP (NNS cattle)) (VP (VBD contracted) (NP (DT the) (NN disease)) (PP (IN as) (NP (NP (DT a) (NN result)) (PP (IN of) (S (VP (VBG eating) (NP (NP (NN food)) (VP (VBN contaminated) (PP (IN with) (NP (NP (DT the) (NNS remains)) (PP (IN of) (NP (NP (NN sheep)) (VP (VBN infected) (PP (IN with) (NP (NP (DT a) (JJ BSE-like) (NN disease)) (VP (VBN called) (NP (NN scrapie))))))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="food contaminated with the remains of sheep infected with a BSE-like disease called scrapie" type="NP">
          <tokens>
            <token id="14" string="food" />
            <token id="15" string="contaminated" />
            <token id="16" string="with" />
            <token id="17" string="the" />
            <token id="18" string="remains" />
            <token id="19" string="of" />
            <token id="20" string="sheep" />
            <token id="21" string="infected" />
            <token id="22" string="with" />
            <token id="23" string="a" />
            <token id="24" string="BSE-like" />
            <token id="25" string="disease" />
            <token id="26" string="called" />
            <token id="27" string="scrapie" />
          </tokens>
        </chunking>
        <chunking id="2" string="a result of eating food contaminated with the remains of sheep infected with a BSE-like disease called scrapie" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="result" />
            <token id="12" string="of" />
            <token id="13" string="eating" />
            <token id="14" string="food" />
            <token id="15" string="contaminated" />
            <token id="16" string="with" />
            <token id="17" string="the" />
            <token id="18" string="remains" />
            <token id="19" string="of" />
            <token id="20" string="sheep" />
            <token id="21" string="infected" />
            <token id="22" string="with" />
            <token id="23" string="a" />
            <token id="24" string="BSE-like" />
            <token id="25" string="disease" />
            <token id="26" string="called" />
            <token id="27" string="scrapie" />
          </tokens>
        </chunking>
        <chunking id="3" string="believe that cattle contracted the disease as a result of eating food contaminated with the remains of sheep infected with a BSE-like disease called scrapie" type="VP">
          <tokens>
            <token id="3" string="believe" />
            <token id="4" string="that" />
            <token id="5" string="cattle" />
            <token id="6" string="contracted" />
            <token id="7" string="the" />
            <token id="8" string="disease" />
            <token id="9" string="as" />
            <token id="10" string="a" />
            <token id="11" string="result" />
            <token id="12" string="of" />
            <token id="13" string="eating" />
            <token id="14" string="food" />
            <token id="15" string="contaminated" />
            <token id="16" string="with" />
            <token id="17" string="the" />
            <token id="18" string="remains" />
            <token id="19" string="of" />
            <token id="20" string="sheep" />
            <token id="21" string="infected" />
            <token id="22" string="with" />
            <token id="23" string="a" />
            <token id="24" string="BSE-like" />
            <token id="25" string="disease" />
            <token id="26" string="called" />
            <token id="27" string="scrapie" />
          </tokens>
        </chunking>
        <chunking id="4" string="a BSE-like disease called scrapie" type="NP">
          <tokens>
            <token id="23" string="a" />
            <token id="24" string="BSE-like" />
            <token id="25" string="disease" />
            <token id="26" string="called" />
            <token id="27" string="scrapie" />
          </tokens>
        </chunking>
        <chunking id="5" string="infected with a BSE-like disease called scrapie" type="VP">
          <tokens>
            <token id="21" string="infected" />
            <token id="22" string="with" />
            <token id="23" string="a" />
            <token id="24" string="BSE-like" />
            <token id="25" string="disease" />
            <token id="26" string="called" />
            <token id="27" string="scrapie" />
          </tokens>
        </chunking>
        <chunking id="6" string="cattle" type="NP">
          <tokens>
            <token id="5" string="cattle" />
          </tokens>
        </chunking>
        <chunking id="7" string="called scrapie" type="VP">
          <tokens>
            <token id="26" string="called" />
            <token id="27" string="scrapie" />
          </tokens>
        </chunking>
        <chunking id="8" string="eating food contaminated with the remains of sheep infected with a BSE-like disease called scrapie" type="VP">
          <tokens>
            <token id="13" string="eating" />
            <token id="14" string="food" />
            <token id="15" string="contaminated" />
            <token id="16" string="with" />
            <token id="17" string="the" />
            <token id="18" string="remains" />
            <token id="19" string="of" />
            <token id="20" string="sheep" />
            <token id="21" string="infected" />
            <token id="22" string="with" />
            <token id="23" string="a" />
            <token id="24" string="BSE-like" />
            <token id="25" string="disease" />
            <token id="26" string="called" />
            <token id="27" string="scrapie" />
          </tokens>
        </chunking>
        <chunking id="9" string="food" type="NP">
          <tokens>
            <token id="14" string="food" />
          </tokens>
        </chunking>
        <chunking id="10" string="a BSE-like disease" type="NP">
          <tokens>
            <token id="23" string="a" />
            <token id="24" string="BSE-like" />
            <token id="25" string="disease" />
          </tokens>
        </chunking>
        <chunking id="11" string="the disease" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="disease" />
          </tokens>
        </chunking>
        <chunking id="12" string="contracted the disease as a result of eating food contaminated with the remains of sheep infected with a BSE-like disease called scrapie" type="VP">
          <tokens>
            <token id="6" string="contracted" />
            <token id="7" string="the" />
            <token id="8" string="disease" />
            <token id="9" string="as" />
            <token id="10" string="a" />
            <token id="11" string="result" />
            <token id="12" string="of" />
            <token id="13" string="eating" />
            <token id="14" string="food" />
            <token id="15" string="contaminated" />
            <token id="16" string="with" />
            <token id="17" string="the" />
            <token id="18" string="remains" />
            <token id="19" string="of" />
            <token id="20" string="sheep" />
            <token id="21" string="infected" />
            <token id="22" string="with" />
            <token id="23" string="a" />
            <token id="24" string="BSE-like" />
            <token id="25" string="disease" />
            <token id="26" string="called" />
            <token id="27" string="scrapie" />
          </tokens>
        </chunking>
        <chunking id="13" string="that cattle contracted the disease as a result of eating food contaminated with the remains of sheep infected with a BSE-like disease called scrapie" type="SBAR">
          <tokens>
            <token id="4" string="that" />
            <token id="5" string="cattle" />
            <token id="6" string="contracted" />
            <token id="7" string="the" />
            <token id="8" string="disease" />
            <token id="9" string="as" />
            <token id="10" string="a" />
            <token id="11" string="result" />
            <token id="12" string="of" />
            <token id="13" string="eating" />
            <token id="14" string="food" />
            <token id="15" string="contaminated" />
            <token id="16" string="with" />
            <token id="17" string="the" />
            <token id="18" string="remains" />
            <token id="19" string="of" />
            <token id="20" string="sheep" />
            <token id="21" string="infected" />
            <token id="22" string="with" />
            <token id="23" string="a" />
            <token id="24" string="BSE-like" />
            <token id="25" string="disease" />
            <token id="26" string="called" />
            <token id="27" string="scrapie" />
          </tokens>
        </chunking>
        <chunking id="14" string="the remains of sheep infected with a BSE-like disease called scrapie" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="remains" />
            <token id="19" string="of" />
            <token id="20" string="sheep" />
            <token id="21" string="infected" />
            <token id="22" string="with" />
            <token id="23" string="a" />
            <token id="24" string="BSE-like" />
            <token id="25" string="disease" />
            <token id="26" string="called" />
            <token id="27" string="scrapie" />
          </tokens>
        </chunking>
        <chunking id="15" string="sheep infected with a BSE-like disease called scrapie" type="NP">
          <tokens>
            <token id="20" string="sheep" />
            <token id="21" string="infected" />
            <token id="22" string="with" />
            <token id="23" string="a" />
            <token id="24" string="BSE-like" />
            <token id="25" string="disease" />
            <token id="26" string="called" />
            <token id="27" string="scrapie" />
          </tokens>
        </chunking>
        <chunking id="16" string="a result" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="result" />
          </tokens>
        </chunking>
        <chunking id="17" string="scrapie" type="NP">
          <tokens>
            <token id="27" string="scrapie" />
          </tokens>
        </chunking>
        <chunking id="18" string="Some experts" type="NP">
          <tokens>
            <token id="1" string="Some" />
            <token id="2" string="experts" />
          </tokens>
        </chunking>
        <chunking id="19" string="contaminated with the remains of sheep infected with a BSE-like disease called scrapie" type="VP">
          <tokens>
            <token id="15" string="contaminated" />
            <token id="16" string="with" />
            <token id="17" string="the" />
            <token id="18" string="remains" />
            <token id="19" string="of" />
            <token id="20" string="sheep" />
            <token id="21" string="infected" />
            <token id="22" string="with" />
            <token id="23" string="a" />
            <token id="24" string="BSE-like" />
            <token id="25" string="disease" />
            <token id="26" string="called" />
            <token id="27" string="scrapie" />
          </tokens>
        </chunking>
        <chunking id="20" string="the remains" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="remains" />
          </tokens>
        </chunking>
        <chunking id="21" string="sheep" type="NP">
          <tokens>
            <token id="20" string="sheep" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">experts</governor>
          <dependent id="1">Some</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">believe</governor>
          <dependent id="2">experts</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">believe</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">contracted</governor>
          <dependent id="4">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">contracted</governor>
          <dependent id="5">cattle</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">believe</governor>
          <dependent id="6">contracted</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">disease</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">contracted</governor>
          <dependent id="8">disease</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">result</governor>
          <dependent id="9">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">result</governor>
          <dependent id="10">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">contracted</governor>
          <dependent id="11">result</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">eating</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="11">result</governor>
          <dependent id="13">eating</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">eating</governor>
          <dependent id="14">food</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="14">food</governor>
          <dependent id="15">contaminated</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">remains</governor>
          <dependent id="16">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">remains</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">contaminated</governor>
          <dependent id="18">remains</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">sheep</governor>
          <dependent id="19">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">remains</governor>
          <dependent id="20">sheep</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="20">sheep</governor>
          <dependent id="21">infected</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">disease</governor>
          <dependent id="22">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">disease</governor>
          <dependent id="23">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">disease</governor>
          <dependent id="24">BSE-like</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">infected</governor>
          <dependent id="25">disease</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="25">disease</governor>
          <dependent id="26">called</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="26">called</governor>
          <dependent id="27">scrapie</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="BSE-like" type="MISC" score="0.0">
          <tokens>
            <token id="24" string="BSE-like" />
          </tokens>
        </entity>
        <entity id="2" string="disease" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="8" string="disease" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="20" has_coreference="false">
      <content>Although government and industry officials have been concerned for some time, mad cow disease did not become a household word until recently.</content>
      <tokens>
        <token id="1" string="Although" lemma="although" stem="although" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="government" lemma="government" stem="govern" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="industry" lemma="industry" stem="industri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="officials" lemma="official" stem="offici" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="concerned" lemma="concern" stem="concern" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="mad" lemma="mad" stem="mad" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="cow" lemma="cow" stem="cow" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="disease" lemma="disease" stem="diseas" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="16" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="become" lemma="become" stem="becom" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="household" lemma="household" stem="household" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="word" lemma="word" stem="word" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="until" lemma="until" stem="until" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="recently" lemma="recently" stem="recent" pos="RB" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN Although) (S (NP (NN government) (CC and) (NN industry) (NNS officials)) (VP (VBP have) (VP (VBN been) (VP (VBN concerned) (PP (IN for) (NP (DT some) (NN time)))))))) (, ,) (NP (JJ mad) (NN cow) (NN disease)) (VP (VBD did) (RB not) (VP (VB become) (NP (DT a) (NN household) (NN word)) (PP (IN until) (ADVP (RB recently))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="been concerned for some time" type="VP">
          <tokens>
            <token id="7" string="been" />
            <token id="8" string="concerned" />
            <token id="9" string="for" />
            <token id="10" string="some" />
            <token id="11" string="time" />
          </tokens>
        </chunking>
        <chunking id="2" string="mad cow disease" type="NP">
          <tokens>
            <token id="13" string="mad" />
            <token id="14" string="cow" />
            <token id="15" string="disease" />
          </tokens>
        </chunking>
        <chunking id="3" string="some time" type="NP">
          <tokens>
            <token id="10" string="some" />
            <token id="11" string="time" />
          </tokens>
        </chunking>
        <chunking id="4" string="become a household word until recently" type="VP">
          <tokens>
            <token id="18" string="become" />
            <token id="19" string="a" />
            <token id="20" string="household" />
            <token id="21" string="word" />
            <token id="22" string="until" />
            <token id="23" string="recently" />
          </tokens>
        </chunking>
        <chunking id="5" string="have been concerned for some time" type="VP">
          <tokens>
            <token id="6" string="have" />
            <token id="7" string="been" />
            <token id="8" string="concerned" />
            <token id="9" string="for" />
            <token id="10" string="some" />
            <token id="11" string="time" />
          </tokens>
        </chunking>
        <chunking id="6" string="Although government and industry officials have been concerned for some time" type="SBAR">
          <tokens>
            <token id="1" string="Although" />
            <token id="2" string="government" />
            <token id="3" string="and" />
            <token id="4" string="industry" />
            <token id="5" string="officials" />
            <token id="6" string="have" />
            <token id="7" string="been" />
            <token id="8" string="concerned" />
            <token id="9" string="for" />
            <token id="10" string="some" />
            <token id="11" string="time" />
          </tokens>
        </chunking>
        <chunking id="7" string="did not become a household word until recently" type="VP">
          <tokens>
            <token id="16" string="did" />
            <token id="17" string="not" />
            <token id="18" string="become" />
            <token id="19" string="a" />
            <token id="20" string="household" />
            <token id="21" string="word" />
            <token id="22" string="until" />
            <token id="23" string="recently" />
          </tokens>
        </chunking>
        <chunking id="8" string="government and industry officials" type="NP">
          <tokens>
            <token id="2" string="government" />
            <token id="3" string="and" />
            <token id="4" string="industry" />
            <token id="5" string="officials" />
          </tokens>
        </chunking>
        <chunking id="9" string="a household word" type="NP">
          <tokens>
            <token id="19" string="a" />
            <token id="20" string="household" />
            <token id="21" string="word" />
          </tokens>
        </chunking>
        <chunking id="10" string="concerned for some time" type="VP">
          <tokens>
            <token id="8" string="concerned" />
            <token id="9" string="for" />
            <token id="10" string="some" />
            <token id="11" string="time" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="8">concerned</governor>
          <dependent id="1">Although</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">officials</governor>
          <dependent id="2">government</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">government</governor>
          <dependent id="3">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">government</governor>
          <dependent id="4">industry</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="8">concerned</governor>
          <dependent id="5">officials</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">concerned</governor>
          <dependent id="6">have</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="8">concerned</governor>
          <dependent id="7">been</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="18">become</governor>
          <dependent id="8">concerned</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">time</governor>
          <dependent id="9">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">time</governor>
          <dependent id="10">some</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">concerned</governor>
          <dependent id="11">time</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">disease</governor>
          <dependent id="13">mad</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">disease</governor>
          <dependent id="14">cow</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">become</governor>
          <dependent id="15">disease</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="18">become</governor>
          <dependent id="16">did</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="18">become</governor>
          <dependent id="17">not</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="18">become</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">word</governor>
          <dependent id="19">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">word</governor>
          <dependent id="20">household</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="18">become</governor>
          <dependent id="21">word</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">recently</governor>
          <dependent id="22">until</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="18">become</governor>
          <dependent id="23">recently</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="disease" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="15" string="disease" />
          </tokens>
        </entity>
        <entity id="2" string="recently" type="DATE" score="0.0">
          <tokens>
            <token id="23" string="recently" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="21" has_coreference="true">
      <content>On May 11, the Ministry of Agriculture revealed that a Siamese cat had died from a disease identical to BSE.</content>
      <tokens>
        <token id="1" string="On" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="May" lemma="May" stem="mai" pos="NNP" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="11" lemma="11" stem="11" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="Ministry" lemma="Ministry" stem="ministri" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="8" string="Agriculture" lemma="Agriculture" stem="agricultur" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="9" string="revealed" lemma="reveal" stem="reveal" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="Siamese" lemma="Siamese" stem="siames" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="13" string="cat" lemma="cat" stem="cat" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="died" lemma="die" stem="di" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="disease" lemma="disease" stem="diseas" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="19" string="identical" lemma="identical" stem="ident" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="BSE" lemma="BSE" stem="bse" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="true" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN On) (NP (NNP May) (CD 11))) (, ,) (NP (NP (DT the) (NNP Ministry)) (PP (IN of) (NP (NNP Agriculture)))) (VP (VBD revealed) (SBAR (IN that) (S (NP (DT a) (NNP Siamese) (NN cat)) (VP (VBD had) (VP (VBN died) (PP (IN from) (NP (NP (DT a) (NN disease)) (ADJP (JJ identical) (PP (TO to) (NP (NNP BSE))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="identical to BSE" type="ADJP">
          <tokens>
            <token id="19" string="identical" />
            <token id="20" string="to" />
            <token id="21" string="BSE" />
          </tokens>
        </chunking>
        <chunking id="2" string="the Ministry" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="Ministry" />
          </tokens>
        </chunking>
        <chunking id="3" string="had died from a disease identical to BSE" type="VP">
          <tokens>
            <token id="14" string="had" />
            <token id="15" string="died" />
            <token id="16" string="from" />
            <token id="17" string="a" />
            <token id="18" string="disease" />
            <token id="19" string="identical" />
            <token id="20" string="to" />
            <token id="21" string="BSE" />
          </tokens>
        </chunking>
        <chunking id="4" string="May 11" type="NP">
          <tokens>
            <token id="2" string="May" />
            <token id="3" string="11" />
          </tokens>
        </chunking>
        <chunking id="5" string="died from a disease identical to BSE" type="VP">
          <tokens>
            <token id="15" string="died" />
            <token id="16" string="from" />
            <token id="17" string="a" />
            <token id="18" string="disease" />
            <token id="19" string="identical" />
            <token id="20" string="to" />
            <token id="21" string="BSE" />
          </tokens>
        </chunking>
        <chunking id="6" string="revealed that a Siamese cat had died from a disease identical to BSE" type="VP">
          <tokens>
            <token id="9" string="revealed" />
            <token id="10" string="that" />
            <token id="11" string="a" />
            <token id="12" string="Siamese" />
            <token id="13" string="cat" />
            <token id="14" string="had" />
            <token id="15" string="died" />
            <token id="16" string="from" />
            <token id="17" string="a" />
            <token id="18" string="disease" />
            <token id="19" string="identical" />
            <token id="20" string="to" />
            <token id="21" string="BSE" />
          </tokens>
        </chunking>
        <chunking id="7" string="a disease" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="disease" />
          </tokens>
        </chunking>
        <chunking id="8" string="the Ministry of Agriculture" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="Ministry" />
            <token id="7" string="of" />
            <token id="8" string="Agriculture" />
          </tokens>
        </chunking>
        <chunking id="9" string="BSE" type="NP">
          <tokens>
            <token id="21" string="BSE" />
          </tokens>
        </chunking>
        <chunking id="10" string="that a Siamese cat had died from a disease identical to BSE" type="SBAR">
          <tokens>
            <token id="10" string="that" />
            <token id="11" string="a" />
            <token id="12" string="Siamese" />
            <token id="13" string="cat" />
            <token id="14" string="had" />
            <token id="15" string="died" />
            <token id="16" string="from" />
            <token id="17" string="a" />
            <token id="18" string="disease" />
            <token id="19" string="identical" />
            <token id="20" string="to" />
            <token id="21" string="BSE" />
          </tokens>
        </chunking>
        <chunking id="11" string="a Siamese cat" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="Siamese" />
            <token id="13" string="cat" />
          </tokens>
        </chunking>
        <chunking id="12" string="Agriculture" type="NP">
          <tokens>
            <token id="8" string="Agriculture" />
          </tokens>
        </chunking>
        <chunking id="13" string="a disease identical to BSE" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="disease" />
            <token id="19" string="identical" />
            <token id="20" string="to" />
            <token id="21" string="BSE" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">May</governor>
          <dependent id="1">On</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">revealed</governor>
          <dependent id="2">May</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="2">May</governor>
          <dependent id="3">11</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">Ministry</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">revealed</governor>
          <dependent id="6">Ministry</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">Agriculture</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">Ministry</governor>
          <dependent id="8">Agriculture</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">revealed</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">died</governor>
          <dependent id="10">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">cat</governor>
          <dependent id="11">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">cat</governor>
          <dependent id="12">Siamese</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">died</governor>
          <dependent id="13">cat</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="15">died</governor>
          <dependent id="14">had</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="9">revealed</governor>
          <dependent id="15">died</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">disease</governor>
          <dependent id="16">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">disease</governor>
          <dependent id="17">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">died</governor>
          <dependent id="18">disease</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">disease</governor>
          <dependent id="19">identical</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">BSE</governor>
          <dependent id="20">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">identical</governor>
          <dependent id="21">BSE</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="BSE" type="MISC" score="0.0">
          <tokens>
            <token id="21" string="BSE" />
          </tokens>
        </entity>
        <entity id="2" string="disease" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="18" string="disease" />
          </tokens>
        </entity>
        <entity id="3" string="Siamese" type="MISC" score="0.0">
          <tokens>
            <token id="12" string="Siamese" />
          </tokens>
        </entity>
        <entity id="4" string="May 11" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="May" />
            <token id="3" string="11" />
          </tokens>
        </entity>
        <entity id="5" string="Ministry of Agriculture" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="6" string="Ministry" />
            <token id="7" string="of" />
            <token id="8" string="Agriculture" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="22" has_coreference="false">
      <content>The press went wild with the story, suggesting, in boldface, that if cats can get it, people can too.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="press" lemma="press" stem="press" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="went" lemma="go" stem="went" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="wild" lemma="wild" stem="wild" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="story" lemma="story" stem="stori" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="suggesting" lemma="suggest" stem="suggest" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="boldface" lemma="boldface" stem="boldfac" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="cats" lemma="cat" stem="cat" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="get" lemma="get" stem="get" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="too" lemma="too" stem="too" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN press)) (VP (VBD went) (NP (NP (JJ wild)) (PP (IN with) (NP (DT the) (NN story))) (, ,) (VP (VBG suggesting) (, ,) (PP (IN in) (NP (NN boldface))) (, ,) (SBAR (IN that) (S (SBAR (IN if) (S (NP (NNS cats)) (VP (MD can) (VP (VB get) (NP (PRP it)))))) (, ,) (NP (NNS people)) (VP (MD can) (ADVP (RB too)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="can get it" type="VP">
          <tokens>
            <token id="17" string="can" />
            <token id="18" string="get" />
            <token id="19" string="it" />
          </tokens>
        </chunking>
        <chunking id="2" string="boldface" type="NP">
          <tokens>
            <token id="12" string="boldface" />
          </tokens>
        </chunking>
        <chunking id="3" string="went wild with the story , suggesting , in boldface , that if cats can get it , people can too" type="VP">
          <tokens>
            <token id="3" string="went" />
            <token id="4" string="wild" />
            <token id="5" string="with" />
            <token id="6" string="the" />
            <token id="7" string="story" />
            <token id="8" string="," />
            <token id="9" string="suggesting" />
            <token id="10" string="," />
            <token id="11" string="in" />
            <token id="12" string="boldface" />
            <token id="13" string="," />
            <token id="14" string="that" />
            <token id="15" string="if" />
            <token id="16" string="cats" />
            <token id="17" string="can" />
            <token id="18" string="get" />
            <token id="19" string="it" />
            <token id="20" string="," />
            <token id="21" string="people" />
            <token id="22" string="can" />
            <token id="23" string="too" />
          </tokens>
        </chunking>
        <chunking id="4" string="it" type="NP">
          <tokens>
            <token id="19" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="people" type="NP">
          <tokens>
            <token id="21" string="people" />
          </tokens>
        </chunking>
        <chunking id="6" string="The press" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="press" />
          </tokens>
        </chunking>
        <chunking id="7" string="can too" type="VP">
          <tokens>
            <token id="22" string="can" />
            <token id="23" string="too" />
          </tokens>
        </chunking>
        <chunking id="8" string="wild with the story , suggesting , in boldface , that if cats can get it , people can too" type="NP">
          <tokens>
            <token id="4" string="wild" />
            <token id="5" string="with" />
            <token id="6" string="the" />
            <token id="7" string="story" />
            <token id="8" string="," />
            <token id="9" string="suggesting" />
            <token id="10" string="," />
            <token id="11" string="in" />
            <token id="12" string="boldface" />
            <token id="13" string="," />
            <token id="14" string="that" />
            <token id="15" string="if" />
            <token id="16" string="cats" />
            <token id="17" string="can" />
            <token id="18" string="get" />
            <token id="19" string="it" />
            <token id="20" string="," />
            <token id="21" string="people" />
            <token id="22" string="can" />
            <token id="23" string="too" />
          </tokens>
        </chunking>
        <chunking id="9" string="if cats can get it" type="SBAR">
          <tokens>
            <token id="15" string="if" />
            <token id="16" string="cats" />
            <token id="17" string="can" />
            <token id="18" string="get" />
            <token id="19" string="it" />
          </tokens>
        </chunking>
        <chunking id="10" string="the story" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="story" />
          </tokens>
        </chunking>
        <chunking id="11" string="cats" type="NP">
          <tokens>
            <token id="16" string="cats" />
          </tokens>
        </chunking>
        <chunking id="12" string="get it" type="VP">
          <tokens>
            <token id="18" string="get" />
            <token id="19" string="it" />
          </tokens>
        </chunking>
        <chunking id="13" string="suggesting , in boldface , that if cats can get it , people can too" type="VP">
          <tokens>
            <token id="9" string="suggesting" />
            <token id="10" string="," />
            <token id="11" string="in" />
            <token id="12" string="boldface" />
            <token id="13" string="," />
            <token id="14" string="that" />
            <token id="15" string="if" />
            <token id="16" string="cats" />
            <token id="17" string="can" />
            <token id="18" string="get" />
            <token id="19" string="it" />
            <token id="20" string="," />
            <token id="21" string="people" />
            <token id="22" string="can" />
            <token id="23" string="too" />
          </tokens>
        </chunking>
        <chunking id="14" string="wild" type="NP">
          <tokens>
            <token id="4" string="wild" />
          </tokens>
        </chunking>
        <chunking id="15" string="that if cats can get it , people can too" type="SBAR">
          <tokens>
            <token id="14" string="that" />
            <token id="15" string="if" />
            <token id="16" string="cats" />
            <token id="17" string="can" />
            <token id="18" string="get" />
            <token id="19" string="it" />
            <token id="20" string="," />
            <token id="21" string="people" />
            <token id="22" string="can" />
            <token id="23" string="too" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">press</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">went</governor>
          <dependent id="2">press</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">went</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">went</governor>
          <dependent id="4">wild</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">story</governor>
          <dependent id="5">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">story</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">wild</governor>
          <dependent id="7">story</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="4">wild</governor>
          <dependent id="9">suggesting</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">boldface</governor>
          <dependent id="11">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">suggesting</governor>
          <dependent id="12">boldface</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">can</governor>
          <dependent id="14">that</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">get</governor>
          <dependent id="15">if</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">get</governor>
          <dependent id="16">cats</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="18">get</governor>
          <dependent id="17">can</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="22">can</governor>
          <dependent id="18">get</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">get</governor>
          <dependent id="19">it</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">can</governor>
          <dependent id="21">people</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="9">suggesting</governor>
          <dependent id="22">can</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="22">can</governor>
          <dependent id="23">too</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="23" has_coreference="false">
      <content>Panic ensued.</content>
      <tokens>
        <token id="1" string="Panic" lemma="panic" stem="panic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="ensued" lemma="ensue" stem="ensu" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NN Panic)) (VP (VBD ensued)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Panic" type="NP">
          <tokens>
            <token id="1" string="Panic" />
          </tokens>
        </chunking>
        <chunking id="2" string="ensued" type="VP">
          <tokens>
            <token id="2" string="ensued" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">ensued</governor>
          <dependent id="1">Panic</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">ensued</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="24" has_coreference="true">
      <content>&amp;quot;BSE has been around for six or seven years,&amp;quot; said David Lewis of the Meat and Livestock Commission.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="BSE" lemma="BSE" stem="bse" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="true" />
        <token id="3" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="around" lemma="around" stem="around" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="six" lemma="six" stem="six" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="8" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="seven" lemma="seven" stem="seven" pos="CD" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="10" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="David" lemma="David" stem="david" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="15" string="Lewis" lemma="Lewis" stem="lewi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="16" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="Meat" lemma="meat" stem="meat" pos="NN" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="19" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="20" string="Livestock" lemma="Livestock" stem="livestock" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="21" string="Commission" lemma="Commission" stem="commiss" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (NP (NNP BSE)) (VP (VBZ has) (VP (VBN been) (ADJP (IN around) (PP (IN for) (NP (CD six) (CC or) (CD seven) (NNS years))))))) (, ,) ('' '') (VP (VBD said)) (NP (NP (NNP David) (NNP Lewis)) (PP (IN of) (NP (NP (DT the) (NN Meat)) (CC and) (NP (NNP Livestock) (NNP Commission))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="has been around for six or seven years" type="VP">
          <tokens>
            <token id="3" string="has" />
            <token id="4" string="been" />
            <token id="5" string="around" />
            <token id="6" string="for" />
            <token id="7" string="six" />
            <token id="8" string="or" />
            <token id="9" string="seven" />
            <token id="10" string="years" />
          </tokens>
        </chunking>
        <chunking id="2" string="six or seven years" type="NP">
          <tokens>
            <token id="7" string="six" />
            <token id="8" string="or" />
            <token id="9" string="seven" />
            <token id="10" string="years" />
          </tokens>
        </chunking>
        <chunking id="3" string="BSE" type="NP">
          <tokens>
            <token id="2" string="BSE" />
          </tokens>
        </chunking>
        <chunking id="4" string="around for six or seven years" type="ADJP">
          <tokens>
            <token id="5" string="around" />
            <token id="6" string="for" />
            <token id="7" string="six" />
            <token id="8" string="or" />
            <token id="9" string="seven" />
            <token id="10" string="years" />
          </tokens>
        </chunking>
        <chunking id="5" string="been around for six or seven years" type="VP">
          <tokens>
            <token id="4" string="been" />
            <token id="5" string="around" />
            <token id="6" string="for" />
            <token id="7" string="six" />
            <token id="8" string="or" />
            <token id="9" string="seven" />
            <token id="10" string="years" />
          </tokens>
        </chunking>
        <chunking id="6" string="Livestock Commission" type="NP">
          <tokens>
            <token id="20" string="Livestock" />
            <token id="21" string="Commission" />
          </tokens>
        </chunking>
        <chunking id="7" string="the Meat and Livestock Commission" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="Meat" />
            <token id="19" string="and" />
            <token id="20" string="Livestock" />
            <token id="21" string="Commission" />
          </tokens>
        </chunking>
        <chunking id="8" string="the Meat" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="Meat" />
          </tokens>
        </chunking>
        <chunking id="9" string="David Lewis" type="NP">
          <tokens>
            <token id="14" string="David" />
            <token id="15" string="Lewis" />
          </tokens>
        </chunking>
        <chunking id="10" string="said" type="VP">
          <tokens>
            <token id="13" string="said" />
          </tokens>
        </chunking>
        <chunking id="11" string="David Lewis of the Meat and Livestock Commission" type="NP">
          <tokens>
            <token id="14" string="David" />
            <token id="15" string="Lewis" />
            <token id="16" string="of" />
            <token id="17" string="the" />
            <token id="18" string="Meat" />
            <token id="19" string="and" />
            <token id="20" string="Livestock" />
            <token id="21" string="Commission" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">around</governor>
          <dependent id="2">BSE</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">around</governor>
          <dependent id="3">has</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">around</governor>
          <dependent id="4">been</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="13">said</governor>
          <dependent id="5">around</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">years</governor>
          <dependent id="6">for</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">years</governor>
          <dependent id="7">six</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">six</governor>
          <dependent id="8">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">six</governor>
          <dependent id="9">seven</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">around</governor>
          <dependent id="10">years</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Lewis</governor>
          <dependent id="14">David</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">said</governor>
          <dependent id="15">Lewis</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">Meat</governor>
          <dependent id="16">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">Meat</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">Lewis</governor>
          <dependent id="18">Meat</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="18">Meat</governor>
          <dependent id="19">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">Commission</governor>
          <dependent id="20">Livestock</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="18">Meat</governor>
          <dependent id="21">Commission</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="six" type="NUMBER" score="0.0">
          <tokens>
            <token id="7" string="six" />
          </tokens>
        </entity>
        <entity id="2" string="Meat and Livestock Commission" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="18" string="Meat" />
            <token id="19" string="and" />
            <token id="20" string="Livestock" />
            <token id="21" string="Commission" />
          </tokens>
        </entity>
        <entity id="3" string="BSE" type="MISC" score="0.0">
          <tokens>
            <token id="2" string="BSE" />
          </tokens>
        </entity>
        <entity id="4" string="David Lewis" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="David" />
            <token id="15" string="Lewis" />
          </tokens>
        </entity>
        <entity id="5" string="seven years" type="DURATION" score="0.0">
          <tokens>
            <token id="9" string="seven" />
            <token id="10" string="years" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="25" has_coreference="true">
      <content>&amp;quot;And until the cat, it hadn&amp;apost;t been brought into the home.&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="until" lemma="until" stem="until" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="cat" lemma="cat" stem="cat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="brought" lemma="bring" stem="brought" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="home" lemma="home" stem="home" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (CC And) (PP (IN until) (NP (DT the) (NN cat))) (, ,) (NP (PRP it)) (VP (VBD had) (RB n't) (VP (VBN been) (VP (VBN brought) (PP (IN into) (NP (DT the) (NN home)))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="the home" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="home" />
          </tokens>
        </chunking>
        <chunking id="2" string="had n't been brought into the home" type="VP">
          <tokens>
            <token id="8" string="had" />
            <token id="9" string="n't" />
            <token id="10" string="been" />
            <token id="11" string="brought" />
            <token id="12" string="into" />
            <token id="13" string="the" />
            <token id="14" string="home" />
          </tokens>
        </chunking>
        <chunking id="3" string="brought into the home" type="VP">
          <tokens>
            <token id="11" string="brought" />
            <token id="12" string="into" />
            <token id="13" string="the" />
            <token id="14" string="home" />
          </tokens>
        </chunking>
        <chunking id="4" string="it" type="NP">
          <tokens>
            <token id="7" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="the cat" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="cat" />
          </tokens>
        </chunking>
        <chunking id="6" string="been brought into the home" type="VP">
          <tokens>
            <token id="10" string="been" />
            <token id="11" string="brought" />
            <token id="12" string="into" />
            <token id="13" string="the" />
            <token id="14" string="home" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="11">brought</governor>
          <dependent id="2">And</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">cat</governor>
          <dependent id="3">until</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">cat</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">brought</governor>
          <dependent id="5">cat</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="11">brought</governor>
          <dependent id="7">it</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">brought</governor>
          <dependent id="8">had</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="11">brought</governor>
          <dependent id="9">n't</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="11">brought</governor>
          <dependent id="10">been</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">brought</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">home</governor>
          <dependent id="12">into</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">home</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">brought</governor>
          <dependent id="14">home</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="26" has_coreference="true">
      <content>Beef sales dropped, with surveys showing that about a quarter of British households had stopped eating it.</content>
      <tokens>
        <token id="1" string="Beef" lemma="beef" stem="beef" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="2" string="sales" lemma="sale" stem="sale" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="dropped" lemma="drop" stem="drop" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="surveys" lemma="survey" stem="survei" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="showing" lemma="show" stem="show" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="10" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="11" string="quarter" lemma="quarter" stem="quarter" pos="NN" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="British" lemma="british" stem="british" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="true" is_refers="false" />
        <token id="14" string="households" lemma="household" stem="household" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="stopped" lemma="stop" stem="stop" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="eating" lemma="eat" stem="eat" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NN Beef) (NNS sales)) (VP (VBD dropped) (, ,) (PP (IN with) (NP (NP (NNS surveys)) (VP (VBG showing) (SBAR (IN that) (IN about) (S (NP (NP (DT a) (NN quarter)) (PP (IN of) (NP (JJ British) (NNS households)))) (VP (VBD had) (VP (VBN stopped) (S (VP (VBG eating) (NP (PRP it)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="surveys showing that about a quarter of British households had stopped eating it" type="NP">
          <tokens>
            <token id="6" string="surveys" />
            <token id="7" string="showing" />
            <token id="8" string="that" />
            <token id="9" string="about" />
            <token id="10" string="a" />
            <token id="11" string="quarter" />
            <token id="12" string="of" />
            <token id="13" string="British" />
            <token id="14" string="households" />
            <token id="15" string="had" />
            <token id="16" string="stopped" />
            <token id="17" string="eating" />
            <token id="18" string="it" />
          </tokens>
        </chunking>
        <chunking id="2" string="dropped , with surveys showing that about a quarter of British households had stopped eating it" type="VP">
          <tokens>
            <token id="3" string="dropped" />
            <token id="4" string="," />
            <token id="5" string="with" />
            <token id="6" string="surveys" />
            <token id="7" string="showing" />
            <token id="8" string="that" />
            <token id="9" string="about" />
            <token id="10" string="a" />
            <token id="11" string="quarter" />
            <token id="12" string="of" />
            <token id="13" string="British" />
            <token id="14" string="households" />
            <token id="15" string="had" />
            <token id="16" string="stopped" />
            <token id="17" string="eating" />
            <token id="18" string="it" />
          </tokens>
        </chunking>
        <chunking id="3" string="stopped eating it" type="VP">
          <tokens>
            <token id="16" string="stopped" />
            <token id="17" string="eating" />
            <token id="18" string="it" />
          </tokens>
        </chunking>
        <chunking id="4" string="British households" type="NP">
          <tokens>
            <token id="13" string="British" />
            <token id="14" string="households" />
          </tokens>
        </chunking>
        <chunking id="5" string="surveys" type="NP">
          <tokens>
            <token id="6" string="surveys" />
          </tokens>
        </chunking>
        <chunking id="6" string="it" type="NP">
          <tokens>
            <token id="18" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="a quarter" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="quarter" />
          </tokens>
        </chunking>
        <chunking id="8" string="eating it" type="VP">
          <tokens>
            <token id="17" string="eating" />
            <token id="18" string="it" />
          </tokens>
        </chunking>
        <chunking id="9" string="Beef sales" type="NP">
          <tokens>
            <token id="1" string="Beef" />
            <token id="2" string="sales" />
          </tokens>
        </chunking>
        <chunking id="10" string="had stopped eating it" type="VP">
          <tokens>
            <token id="15" string="had" />
            <token id="16" string="stopped" />
            <token id="17" string="eating" />
            <token id="18" string="it" />
          </tokens>
        </chunking>
        <chunking id="11" string="that about a quarter of British households had stopped eating it" type="SBAR">
          <tokens>
            <token id="8" string="that" />
            <token id="9" string="about" />
            <token id="10" string="a" />
            <token id="11" string="quarter" />
            <token id="12" string="of" />
            <token id="13" string="British" />
            <token id="14" string="households" />
            <token id="15" string="had" />
            <token id="16" string="stopped" />
            <token id="17" string="eating" />
            <token id="18" string="it" />
          </tokens>
        </chunking>
        <chunking id="12" string="a quarter of British households" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="quarter" />
            <token id="12" string="of" />
            <token id="13" string="British" />
            <token id="14" string="households" />
          </tokens>
        </chunking>
        <chunking id="13" string="showing that about a quarter of British households had stopped eating it" type="VP">
          <tokens>
            <token id="7" string="showing" />
            <token id="8" string="that" />
            <token id="9" string="about" />
            <token id="10" string="a" />
            <token id="11" string="quarter" />
            <token id="12" string="of" />
            <token id="13" string="British" />
            <token id="14" string="households" />
            <token id="15" string="had" />
            <token id="16" string="stopped" />
            <token id="17" string="eating" />
            <token id="18" string="it" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">sales</governor>
          <dependent id="1">Beef</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">dropped</governor>
          <dependent id="2">sales</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">dropped</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">surveys</governor>
          <dependent id="5">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">dropped</governor>
          <dependent id="6">surveys</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="6">surveys</governor>
          <dependent id="7">showing</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">stopped</governor>
          <dependent id="8">that</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">stopped</governor>
          <dependent id="9">about</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">quarter</governor>
          <dependent id="10">a</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">stopped</governor>
          <dependent id="11">quarter</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">households</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">households</governor>
          <dependent id="13">British</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">quarter</governor>
          <dependent id="14">households</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">stopped</governor>
          <dependent id="15">had</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="7">showing</governor>
          <dependent id="16">stopped</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="16">stopped</governor>
          <dependent id="17">eating</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">eating</governor>
          <dependent id="18">it</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="British" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="13" string="British" />
          </tokens>
        </entity>
        <entity id="2" string="about a quarter" type="DURATION" score="0.0">
          <tokens>
            <token id="9" string="about" />
            <token id="10" string="a" />
            <token id="11" string="quarter" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="27" has_coreference="true">
      <content>Two thousand schools dropped beef from their menus.</content>
      <tokens>
        <token id="1" string="Two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="2" string="thousand" lemma="thousand" stem="thousand" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="3" string="schools" lemma="school" stem="school" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="dropped" lemma="drop" stem="drop" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="beef" lemma="beef" stem="beef" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="menus" lemma="menu" stem="menu" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (QP (CD Two) (CD thousand)) (NNS schools)) (VP (VBD dropped) (NP (NN beef)) (PP (IN from) (NP (PRP$ their) (NNS menus)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Two thousand schools" type="NP">
          <tokens>
            <token id="1" string="Two" />
            <token id="2" string="thousand" />
            <token id="3" string="schools" />
          </tokens>
        </chunking>
        <chunking id="2" string="dropped beef from their menus" type="VP">
          <tokens>
            <token id="4" string="dropped" />
            <token id="5" string="beef" />
            <token id="6" string="from" />
            <token id="7" string="their" />
            <token id="8" string="menus" />
          </tokens>
        </chunking>
        <chunking id="3" string="beef" type="NP">
          <tokens>
            <token id="5" string="beef" />
          </tokens>
        </chunking>
        <chunking id="4" string="their menus" type="NP">
          <tokens>
            <token id="7" string="their" />
            <token id="8" string="menus" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">thousand</governor>
          <dependent id="1">Two</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="3">schools</governor>
          <dependent id="2">thousand</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">dropped</governor>
          <dependent id="3">schools</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">dropped</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">dropped</governor>
          <dependent id="5">beef</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">menus</governor>
          <dependent id="6">from</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">menus</governor>
          <dependent id="7">their</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">dropped</governor>
          <dependent id="8">menus</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Two thousand" type="NUMBER" score="0.0">
          <tokens>
            <token id="1" string="Two" />
            <token id="2" string="thousand" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="28" has_coreference="false">
      <content>The government and meat industry fought back.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="government" lemma="government" stem="govern" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="meat" lemma="meat" stem="meat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="industry" lemma="industry" stem="industri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="fought" lemma="fight" stem="fought" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="back" lemma="back" stem="back" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN government) (CC and) (NN meat) (NN industry)) (VP (VBD fought) (ADVP (RB back))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="The government and meat industry" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="government" />
            <token id="3" string="and" />
            <token id="4" string="meat" />
            <token id="5" string="industry" />
          </tokens>
        </chunking>
        <chunking id="2" string="fought back" type="VP">
          <tokens>
            <token id="6" string="fought" />
            <token id="7" string="back" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="5">industry</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">industry</governor>
          <dependent id="2">government</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">government</governor>
          <dependent id="3">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">government</governor>
          <dependent id="4">meat</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">fought</governor>
          <dependent id="5">industry</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">fought</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">fought</governor>
          <dependent id="7">back</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="29" has_coreference="false">
      <content>Some regulations were enacted to fight the disease, but more overt was the publicity campaign: Princess Anne said her family was still eating British beef.</content>
      <tokens>
        <token id="1" string="Some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="regulations" lemma="regulation" stem="regul" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="enacted" lemma="enact" stem="enact" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="fight" lemma="fight" stem="fight" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="disease" lemma="disease" stem="diseas" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="overt" lemma="overt" stem="overt" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="publicity" lemma="publicity" stem="public" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="campaign" lemma="campaign" stem="campaign" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Princess" lemma="Princess" stem="princess" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="true" is_refers="false" />
        <token id="19" string="Anne" lemma="Anne" stem="anne" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="20" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="family" lemma="family" stem="famili" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="still" lemma="still" stem="still" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="eating" lemma="eat" stem="eat" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="British" lemma="british" stem="british" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="27" string="beef" lemma="beef" stem="beef" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (DT Some) (NNS regulations)) (VP (VBD were) (VP (VBN enacted) (S (VP (TO to) (VP (VB fight) (NP (DT the) (NN disease)))))))) (, ,) (CC but) (SINV (FRAG (ADJP (RBR more) (JJ overt))) (VP (VBD was)) (NP (DT the) (NN publicity) (NN campaign))) (: :) (S (NP (NNP Princess) (NNP Anne)) (VP (VBD said) (SBAR (S (NP (PRP$ her) (NN family)) (VP (VBD was) (ADVP (RB still)) (VP (VBG eating) (NP (JJ British) (NN beef)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="said her family was still eating British beef" type="VP">
          <tokens>
            <token id="20" string="said" />
            <token id="21" string="her" />
            <token id="22" string="family" />
            <token id="23" string="was" />
            <token id="24" string="still" />
            <token id="25" string="eating" />
            <token id="26" string="British" />
            <token id="27" string="beef" />
          </tokens>
        </chunking>
        <chunking id="2" string="fight the disease" type="VP">
          <tokens>
            <token id="6" string="fight" />
            <token id="7" string="the" />
            <token id="8" string="disease" />
          </tokens>
        </chunking>
        <chunking id="3" string="was" type="VP">
          <tokens>
            <token id="13" string="was" />
          </tokens>
        </chunking>
        <chunking id="4" string="more overt" type="ADJP">
          <tokens>
            <token id="11" string="more" />
            <token id="12" string="overt" />
          </tokens>
        </chunking>
        <chunking id="5" string="her family was still eating British beef" type="SBAR">
          <tokens>
            <token id="21" string="her" />
            <token id="22" string="family" />
            <token id="23" string="was" />
            <token id="24" string="still" />
            <token id="25" string="eating" />
            <token id="26" string="British" />
            <token id="27" string="beef" />
          </tokens>
        </chunking>
        <chunking id="6" string="the disease" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="disease" />
          </tokens>
        </chunking>
        <chunking id="7" string="eating British beef" type="VP">
          <tokens>
            <token id="25" string="eating" />
            <token id="26" string="British" />
            <token id="27" string="beef" />
          </tokens>
        </chunking>
        <chunking id="8" string="to fight the disease" type="VP">
          <tokens>
            <token id="5" string="to" />
            <token id="6" string="fight" />
            <token id="7" string="the" />
            <token id="8" string="disease" />
          </tokens>
        </chunking>
        <chunking id="9" string="the publicity campaign" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="publicity" />
            <token id="16" string="campaign" />
          </tokens>
        </chunking>
        <chunking id="10" string="enacted to fight the disease" type="VP">
          <tokens>
            <token id="4" string="enacted" />
            <token id="5" string="to" />
            <token id="6" string="fight" />
            <token id="7" string="the" />
            <token id="8" string="disease" />
          </tokens>
        </chunking>
        <chunking id="11" string="her family" type="NP">
          <tokens>
            <token id="21" string="her" />
            <token id="22" string="family" />
          </tokens>
        </chunking>
        <chunking id="12" string="British beef" type="NP">
          <tokens>
            <token id="26" string="British" />
            <token id="27" string="beef" />
          </tokens>
        </chunking>
        <chunking id="13" string="was still eating British beef" type="VP">
          <tokens>
            <token id="23" string="was" />
            <token id="24" string="still" />
            <token id="25" string="eating" />
            <token id="26" string="British" />
            <token id="27" string="beef" />
          </tokens>
        </chunking>
        <chunking id="14" string="Princess Anne" type="NP">
          <tokens>
            <token id="18" string="Princess" />
            <token id="19" string="Anne" />
          </tokens>
        </chunking>
        <chunking id="15" string="were enacted to fight the disease" type="VP">
          <tokens>
            <token id="3" string="were" />
            <token id="4" string="enacted" />
            <token id="5" string="to" />
            <token id="6" string="fight" />
            <token id="7" string="the" />
            <token id="8" string="disease" />
          </tokens>
        </chunking>
        <chunking id="16" string="Some regulations" type="NP">
          <tokens>
            <token id="1" string="Some" />
            <token id="2" string="regulations" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">regulations</governor>
          <dependent id="1">Some</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="4">enacted</governor>
          <dependent id="2">regulations</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="4">enacted</governor>
          <dependent id="3">were</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">enacted</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">fight</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">enacted</governor>
          <dependent id="6">fight</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">disease</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">fight</governor>
          <dependent id="8">disease</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">enacted</governor>
          <dependent id="10">but</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">overt</governor>
          <dependent id="11">more</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="13">was</governor>
          <dependent id="12">overt</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">enacted</governor>
          <dependent id="13">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">campaign</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">campaign</governor>
          <dependent id="15">publicity</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">was</governor>
          <dependent id="16">campaign</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">Anne</governor>
          <dependent id="18">Princess</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">said</governor>
          <dependent id="19">Anne</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">enacted</governor>
          <dependent id="20">said</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="22">family</governor>
          <dependent id="21">her</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">eating</governor>
          <dependent id="22">family</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="25">eating</governor>
          <dependent id="23">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="25">eating</governor>
          <dependent id="24">still</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="20">said</governor>
          <dependent id="25">eating</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="27">beef</governor>
          <dependent id="26">British</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="25">eating</governor>
          <dependent id="27">beef</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="British" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="26" string="British" />
          </tokens>
        </entity>
        <entity id="2" string="disease" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="8" string="disease" />
          </tokens>
        </entity>
        <entity id="3" string="Princess" type="TITLE" score="0.0">
          <tokens>
            <token id="18" string="Princess" />
          </tokens>
        </entity>
        <entity id="4" string="Anne" type="PERSON" score="0.0">
          <tokens>
            <token id="19" string="Anne" />
          </tokens>
        </entity>
      </entities>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="1" type="PROPER">
      <referenced ids_tokens="18" string="Britain" id_sentence="1" />
      <mentions>
        <mention ids_tokens="13-14" string="Britain's" id_sentence="15" />
      </mentions>
    </coreference>
    <coreference id="2" type="NOMINAL">
      <referenced ids_tokens="2-3" string="Mad cow" id_sentence="1" />
      <mentions>
        <mention ids_tokens="12-14" string="the cow's" id_sentence="17" />
      </mentions>
    </coreference>
    <coreference id="3" type="PROPER">
      <referenced ids_tokens="4-5" string="West Germany" id_sentence="2" />
      <mentions>
        <mention ids_tokens="15" string="Germany" id_sentence="13" />
      </mentions>
    </coreference>
    <coreference id="4" type="PROPER">
      <referenced ids_tokens="7-8-9-10-11-12-13-14" string="France in a ban on British beef imports" id_sentence="2" />
      <mentions>
        <mention ids_tokens="7" string="France" id_sentence="7" />
        <mention ids_tokens="2" string="It" id_sentence="8" />
        <mention ids_tokens="1" string="France" id_sentence="9" />
      </mentions>
    </coreference>
    <coreference id="5" type="PROPER">
      <referenced ids_tokens="3-4" string="the disease" id_sentence="3" />
      <mentions>
        <mention ids_tokens="7-15" string="the disease , which affects the cow's brain" id_sentence="17" />
      </mentions>
    </coreference>
    <coreference id="6" type="NOMINAL">
      <referenced ids_tokens="31-32-33" string="domestic beef sales" id_sentence="3" />
      <mentions>
        <mention ids_tokens="1-2" string="Beef sales" id_sentence="26" />
      </mentions>
    </coreference>
    <coreference id="7" type="NOMINAL">
      <referenced ids_tokens="1-2" string="British officials" id_sentence="5" />
      <mentions>
        <mention ids_tokens="16" string="their" id_sentence="7" />
      </mentions>
    </coreference>
    <coreference id="12" type="NOMINAL">
      <referenced ids_tokens="17-18" string="live cattle" id_sentence="12" />
      <mentions>
        <mention ids_tokens="5" string="cattle" id_sentence="19" />
      </mentions>
    </coreference>
    <coreference id="14" type="NOMINAL">
      <referenced ids_tokens="1-2-3-4-5-6-7-8" string="BSE-infected cows &quot; degenerate very quickly , &quot;" id_sentence="15" />
      <mentions>
        <mention ids_tokens="1-2" string="The cows" id_sentence="16" />
      </mentions>
    </coreference>
    <coreference id="15" type="PROPER">
      <referenced ids_tokens="13-14-15-16-17" string="Britain 's Ministry of Agriculture" id_sentence="15" />
      <mentions>
        <mention ids_tokens="5-8" string="the Ministry of Agriculture" id_sentence="21" />
      </mentions>
    </coreference>
    <coreference id="16" type="PROPER">
      <referenced ids_tokens="24" string="BSE-like" id_sentence="19" />
      <mentions>
        <mention ids_tokens="21" string="BSE" id_sentence="21" />
        <mention ids_tokens="2" string="BSE" id_sentence="24" />
        <mention ids_tokens="7" string="it" id_sentence="25" />
      </mentions>
    </coreference>
    <coreference id="17" type="NOMINAL">
      <referenced ids_tokens="11-12-13" string="a Siamese cat" id_sentence="21" />
      <mentions>
        <mention ids_tokens="4-5" string="the cat" id_sentence="25" />
      </mentions>
    </coreference>
    <coreference id="20" type="NOMINAL">
      <referenced ids_tokens="13-14" string="British households" id_sentence="26" />
      <mentions>
        <mention ids_tokens="7" string="their" id_sentence="27" />
      </mentions>
    </coreference>
  </coreferences>
</document>
