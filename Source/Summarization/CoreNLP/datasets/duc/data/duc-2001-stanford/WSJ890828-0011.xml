<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="WSJ890828-0011">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>Though the forms for the 1990 census are already at the printers, Congress is contemplating adding a question: Are you an illegal immigrant?</content>
      <tokens>
        <token id="1" string="Though" lemma="though" stem="though" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="forms" lemma="form" stem="form" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="1990" lemma="1990" stem="1990" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="7" string="census" lemma="census" stem="censu" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="already" lemma="already" stem="alreadi" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="printers" lemma="printer" stem="printer" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Congress" lemma="Congress" stem="congress" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="15" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="contemplating" lemma="contemplate" stem="contempl" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="adding" lemma="add" stem="ad" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="question" lemma="question" stem="question" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="Are" lemma="be" stem="are" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="illegal" lemma="illegal" stem="illeg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="immigrant" lemma="immigrant" stem="immigr" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN Though) (S (NP (NP (DT the) (NNS forms)) (PP (IN for) (NP (DT the) (CD 1990) (NN census)))) (VP (VBP are) (ADVP (RB already)) (PP (IN at) (NP (DT the) (NNS printers)))))) (, ,) (NP (NNP Congress)) (VP (VBZ is) (VP (VBG contemplating) (S (VP (VBG adding) (NP (NP (DT a) (NN question)) (: :) (SQ (VBP Are) (NP (NP (PRP you)) (NP (DT an) (JJ illegal) (JJ immigrant))))))))) (. ?)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the forms" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="forms" />
          </tokens>
        </chunking>
        <chunking id="2" string="is contemplating adding a question : Are you an illegal immigrant" type="VP">
          <tokens>
            <token id="15" string="is" />
            <token id="16" string="contemplating" />
            <token id="17" string="adding" />
            <token id="18" string="a" />
            <token id="19" string="question" />
            <token id="20" string=":" />
            <token id="21" string="Are" />
            <token id="22" string="you" />
            <token id="23" string="an" />
            <token id="24" string="illegal" />
            <token id="25" string="immigrant" />
          </tokens>
        </chunking>
        <chunking id="3" string="you an illegal immigrant" type="NP">
          <tokens>
            <token id="22" string="you" />
            <token id="23" string="an" />
            <token id="24" string="illegal" />
            <token id="25" string="immigrant" />
          </tokens>
        </chunking>
        <chunking id="4" string="a question" type="NP">
          <tokens>
            <token id="18" string="a" />
            <token id="19" string="question" />
          </tokens>
        </chunking>
        <chunking id="5" string="a question : Are you an illegal immigrant" type="NP">
          <tokens>
            <token id="18" string="a" />
            <token id="19" string="question" />
            <token id="20" string=":" />
            <token id="21" string="Are" />
            <token id="22" string="you" />
            <token id="23" string="an" />
            <token id="24" string="illegal" />
            <token id="25" string="immigrant" />
          </tokens>
        </chunking>
        <chunking id="6" string="contemplating adding a question : Are you an illegal immigrant" type="VP">
          <tokens>
            <token id="16" string="contemplating" />
            <token id="17" string="adding" />
            <token id="18" string="a" />
            <token id="19" string="question" />
            <token id="20" string=":" />
            <token id="21" string="Are" />
            <token id="22" string="you" />
            <token id="23" string="an" />
            <token id="24" string="illegal" />
            <token id="25" string="immigrant" />
          </tokens>
        </chunking>
        <chunking id="7" string="the 1990 census" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="1990" />
            <token id="7" string="census" />
          </tokens>
        </chunking>
        <chunking id="8" string="are already at the printers" type="VP">
          <tokens>
            <token id="8" string="are" />
            <token id="9" string="already" />
            <token id="10" string="at" />
            <token id="11" string="the" />
            <token id="12" string="printers" />
          </tokens>
        </chunking>
        <chunking id="9" string="the printers" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="printers" />
          </tokens>
        </chunking>
        <chunking id="10" string="Congress" type="NP">
          <tokens>
            <token id="14" string="Congress" />
          </tokens>
        </chunking>
        <chunking id="11" string="the forms for the 1990 census" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="forms" />
            <token id="4" string="for" />
            <token id="5" string="the" />
            <token id="6" string="1990" />
            <token id="7" string="census" />
          </tokens>
        </chunking>
        <chunking id="12" string="adding a question : Are you an illegal immigrant" type="VP">
          <tokens>
            <token id="17" string="adding" />
            <token id="18" string="a" />
            <token id="19" string="question" />
            <token id="20" string=":" />
            <token id="21" string="Are" />
            <token id="22" string="you" />
            <token id="23" string="an" />
            <token id="24" string="illegal" />
            <token id="25" string="immigrant" />
          </tokens>
        </chunking>
        <chunking id="13" string="Though the forms for the 1990 census are already at the printers" type="SBAR">
          <tokens>
            <token id="1" string="Though" />
            <token id="2" string="the" />
            <token id="3" string="forms" />
            <token id="4" string="for" />
            <token id="5" string="the" />
            <token id="6" string="1990" />
            <token id="7" string="census" />
            <token id="8" string="are" />
            <token id="9" string="already" />
            <token id="10" string="at" />
            <token id="11" string="the" />
            <token id="12" string="printers" />
          </tokens>
        </chunking>
        <chunking id="14" string="an illegal immigrant" type="NP">
          <tokens>
            <token id="23" string="an" />
            <token id="24" string="illegal" />
            <token id="25" string="immigrant" />
          </tokens>
        </chunking>
        <chunking id="15" string="you" type="NP">
          <tokens>
            <token id="22" string="you" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="12">printers</governor>
          <dependent id="1">Though</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">forms</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">printers</governor>
          <dependent id="3">forms</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">census</governor>
          <dependent id="4">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">census</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="7">census</governor>
          <dependent id="6">1990</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">forms</governor>
          <dependent id="7">census</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="12">printers</governor>
          <dependent id="8">are</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">printers</governor>
          <dependent id="9">already</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">printers</governor>
          <dependent id="10">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">printers</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="16">contemplating</governor>
          <dependent id="12">printers</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">contemplating</governor>
          <dependent id="14">Congress</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">contemplating</governor>
          <dependent id="15">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="16">contemplating</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="16">contemplating</governor>
          <dependent id="17">adding</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">question</governor>
          <dependent id="18">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">adding</governor>
          <dependent id="19">question</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="19">question</governor>
          <dependent id="21">Are</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">Are</governor>
          <dependent id="22">you</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">immigrant</governor>
          <dependent id="23">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">immigrant</governor>
          <dependent id="24">illegal</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="22">you</governor>
          <dependent id="25">immigrant</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1990" type="DATE" score="0.0">
          <tokens>
            <token id="6" string="1990" />
          </tokens>
        </entity>
        <entity id="2" string="Congress" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="14" string="Congress" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>The Census Bureau, as it has in the past, is planning to count all residents of the nation regardless of legal status.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="Census" lemma="Census" stem="censu" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="3" string="Bureau" lemma="Bureau" stem="bureau" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="10" string="past" lemma="past" stem="past" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="planning" lemma="plan" stem="plan" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="count" lemma="count" stem="count" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="residents" lemma="resident" stem="resid" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="nation" lemma="nation" stem="nation" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="regardless" lemma="regardless" stem="regardless" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="legal" lemma="legal" stem="legal" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="status" lemma="status" stem="statu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (NNP Census) (NNP Bureau)) (, ,) (SBAR (IN as) (S (NP (PRP it)) (VP (VBZ has) (VP (PP (IN in) (NP (DT the) (NN past))))))) (, ,)) (VP (VBZ is) (VP (VBG planning) (S (VP (TO to) (VP (VB count) (NP (NP (DT all) (NNS residents)) (PP (IN of) (ADVP (NP (DT the) (NN nation)) (RB regardless))) (PP (IN of) (NP (JJ legal) (NN status))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the past" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="past" />
          </tokens>
        </chunking>
        <chunking id="2" string="the nation" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="nation" />
          </tokens>
        </chunking>
        <chunking id="3" string="The Census Bureau" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Census" />
            <token id="3" string="Bureau" />
          </tokens>
        </chunking>
        <chunking id="4" string="legal status" type="NP">
          <tokens>
            <token id="23" string="legal" />
            <token id="24" string="status" />
          </tokens>
        </chunking>
        <chunking id="5" string="as it has in the past" type="SBAR">
          <tokens>
            <token id="5" string="as" />
            <token id="6" string="it" />
            <token id="7" string="has" />
            <token id="8" string="in" />
            <token id="9" string="the" />
            <token id="10" string="past" />
          </tokens>
        </chunking>
        <chunking id="6" string="it" type="NP">
          <tokens>
            <token id="6" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="planning to count all residents of the nation regardless of legal status" type="VP">
          <tokens>
            <token id="13" string="planning" />
            <token id="14" string="to" />
            <token id="15" string="count" />
            <token id="16" string="all" />
            <token id="17" string="residents" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="nation" />
            <token id="21" string="regardless" />
            <token id="22" string="of" />
            <token id="23" string="legal" />
            <token id="24" string="status" />
          </tokens>
        </chunking>
        <chunking id="8" string="in the past" type="VP">
          <tokens>
            <token id="8" string="in" />
            <token id="9" string="the" />
            <token id="10" string="past" />
          </tokens>
        </chunking>
        <chunking id="9" string="is planning to count all residents of the nation regardless of legal status" type="VP">
          <tokens>
            <token id="12" string="is" />
            <token id="13" string="planning" />
            <token id="14" string="to" />
            <token id="15" string="count" />
            <token id="16" string="all" />
            <token id="17" string="residents" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="nation" />
            <token id="21" string="regardless" />
            <token id="22" string="of" />
            <token id="23" string="legal" />
            <token id="24" string="status" />
          </tokens>
        </chunking>
        <chunking id="10" string="to count all residents of the nation regardless of legal status" type="VP">
          <tokens>
            <token id="14" string="to" />
            <token id="15" string="count" />
            <token id="16" string="all" />
            <token id="17" string="residents" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="nation" />
            <token id="21" string="regardless" />
            <token id="22" string="of" />
            <token id="23" string="legal" />
            <token id="24" string="status" />
          </tokens>
        </chunking>
        <chunking id="11" string="all residents of the nation regardless of legal status" type="NP">
          <tokens>
            <token id="16" string="all" />
            <token id="17" string="residents" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="nation" />
            <token id="21" string="regardless" />
            <token id="22" string="of" />
            <token id="23" string="legal" />
            <token id="24" string="status" />
          </tokens>
        </chunking>
        <chunking id="12" string="The Census Bureau , as it has in the past ," type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Census" />
            <token id="3" string="Bureau" />
            <token id="4" string="," />
            <token id="5" string="as" />
            <token id="6" string="it" />
            <token id="7" string="has" />
            <token id="8" string="in" />
            <token id="9" string="the" />
            <token id="10" string="past" />
            <token id="11" string="," />
          </tokens>
        </chunking>
        <chunking id="13" string="count all residents of the nation regardless of legal status" type="VP">
          <tokens>
            <token id="15" string="count" />
            <token id="16" string="all" />
            <token id="17" string="residents" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="nation" />
            <token id="21" string="regardless" />
            <token id="22" string="of" />
            <token id="23" string="legal" />
            <token id="24" string="status" />
          </tokens>
        </chunking>
        <chunking id="14" string="all residents" type="NP">
          <tokens>
            <token id="16" string="all" />
            <token id="17" string="residents" />
          </tokens>
        </chunking>
        <chunking id="15" string="has in the past" type="VP">
          <tokens>
            <token id="7" string="has" />
            <token id="8" string="in" />
            <token id="9" string="the" />
            <token id="10" string="past" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">Bureau</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Bureau</governor>
          <dependent id="2">Census</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">planning</governor>
          <dependent id="3">Bureau</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">past</governor>
          <dependent id="5">as</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">past</governor>
          <dependent id="6">it</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="10">past</governor>
          <dependent id="7">has</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">past</governor>
          <dependent id="8">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">past</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="3">Bureau</governor>
          <dependent id="10">past</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="13">planning</governor>
          <dependent id="12">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">planning</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">count</governor>
          <dependent id="14">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="13">planning</governor>
          <dependent id="15">count</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">residents</governor>
          <dependent id="16">all</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">count</governor>
          <dependent id="17">residents</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">regardless</governor>
          <dependent id="18">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">nation</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="21">regardless</governor>
          <dependent id="20">nation</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="17">residents</governor>
          <dependent id="21">regardless</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">status</governor>
          <dependent id="22">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">status</governor>
          <dependent id="23">legal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">residents</governor>
          <dependent id="24">status</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="the past" type="DATE" score="0.0">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="past" />
          </tokens>
        </entity>
        <entity id="2" string="Census Bureau" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="2" string="Census" />
            <token id="3" string="Bureau" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>But the Senate already has voted to force the Census Bureau to exclude illegal immigrants in preparing tallies for congressional reapportionment.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="Senate" lemma="Senate" stem="senat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="4" string="already" lemma="already" stem="alreadi" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="voted" lemma="vote" stem="vote" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="force" lemma="force" stem="forc" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Census" lemma="Census" stem="censu" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="11" string="Bureau" lemma="Bureau" stem="bureau" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="12" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="exclude" lemma="exclude" stem="exclud" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="illegal" lemma="illegal" stem="illeg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="immigrants" lemma="immigrant" stem="immigr" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="preparing" lemma="prepare" stem="prepar" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="tallies" lemma="tally" stem="talli" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="congressional" lemma="congressional" stem="congression" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="reapportionment" lemma="reapportionment" stem="reapportion" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (DT the) (NNP Senate)) (ADVP (RB already)) (VP (VBZ has) (VP (VBN voted) (S (VP (TO to) (VP (VB force) (S (NP (DT the) (NNP Census) (NNP Bureau)) (VP (TO to) (VP (VB exclude) (NP (JJ illegal) (NNS immigrants)) (PP (IN in) (S (VP (VBG preparing) (NP (NNS tallies)) (PP (IN for) (NP (JJ congressional) (NN reapportionment)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="exclude illegal immigrants in preparing tallies for congressional reapportionment" type="VP">
          <tokens>
            <token id="13" string="exclude" />
            <token id="14" string="illegal" />
            <token id="15" string="immigrants" />
            <token id="16" string="in" />
            <token id="17" string="preparing" />
            <token id="18" string="tallies" />
            <token id="19" string="for" />
            <token id="20" string="congressional" />
            <token id="21" string="reapportionment" />
          </tokens>
        </chunking>
        <chunking id="2" string="the Senate" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="Senate" />
          </tokens>
        </chunking>
        <chunking id="3" string="preparing tallies for congressional reapportionment" type="VP">
          <tokens>
            <token id="17" string="preparing" />
            <token id="18" string="tallies" />
            <token id="19" string="for" />
            <token id="20" string="congressional" />
            <token id="21" string="reapportionment" />
          </tokens>
        </chunking>
        <chunking id="4" string="tallies" type="NP">
          <tokens>
            <token id="18" string="tallies" />
          </tokens>
        </chunking>
        <chunking id="5" string="the Census Bureau" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="Census" />
            <token id="11" string="Bureau" />
          </tokens>
        </chunking>
        <chunking id="6" string="voted to force the Census Bureau to exclude illegal immigrants in preparing tallies for congressional reapportionment" type="VP">
          <tokens>
            <token id="6" string="voted" />
            <token id="7" string="to" />
            <token id="8" string="force" />
            <token id="9" string="the" />
            <token id="10" string="Census" />
            <token id="11" string="Bureau" />
            <token id="12" string="to" />
            <token id="13" string="exclude" />
            <token id="14" string="illegal" />
            <token id="15" string="immigrants" />
            <token id="16" string="in" />
            <token id="17" string="preparing" />
            <token id="18" string="tallies" />
            <token id="19" string="for" />
            <token id="20" string="congressional" />
            <token id="21" string="reapportionment" />
          </tokens>
        </chunking>
        <chunking id="7" string="force the Census Bureau to exclude illegal immigrants in preparing tallies for congressional reapportionment" type="VP">
          <tokens>
            <token id="8" string="force" />
            <token id="9" string="the" />
            <token id="10" string="Census" />
            <token id="11" string="Bureau" />
            <token id="12" string="to" />
            <token id="13" string="exclude" />
            <token id="14" string="illegal" />
            <token id="15" string="immigrants" />
            <token id="16" string="in" />
            <token id="17" string="preparing" />
            <token id="18" string="tallies" />
            <token id="19" string="for" />
            <token id="20" string="congressional" />
            <token id="21" string="reapportionment" />
          </tokens>
        </chunking>
        <chunking id="8" string="to exclude illegal immigrants in preparing tallies for congressional reapportionment" type="VP">
          <tokens>
            <token id="12" string="to" />
            <token id="13" string="exclude" />
            <token id="14" string="illegal" />
            <token id="15" string="immigrants" />
            <token id="16" string="in" />
            <token id="17" string="preparing" />
            <token id="18" string="tallies" />
            <token id="19" string="for" />
            <token id="20" string="congressional" />
            <token id="21" string="reapportionment" />
          </tokens>
        </chunking>
        <chunking id="9" string="congressional reapportionment" type="NP">
          <tokens>
            <token id="20" string="congressional" />
            <token id="21" string="reapportionment" />
          </tokens>
        </chunking>
        <chunking id="10" string="has voted to force the Census Bureau to exclude illegal immigrants in preparing tallies for congressional reapportionment" type="VP">
          <tokens>
            <token id="5" string="has" />
            <token id="6" string="voted" />
            <token id="7" string="to" />
            <token id="8" string="force" />
            <token id="9" string="the" />
            <token id="10" string="Census" />
            <token id="11" string="Bureau" />
            <token id="12" string="to" />
            <token id="13" string="exclude" />
            <token id="14" string="illegal" />
            <token id="15" string="immigrants" />
            <token id="16" string="in" />
            <token id="17" string="preparing" />
            <token id="18" string="tallies" />
            <token id="19" string="for" />
            <token id="20" string="congressional" />
            <token id="21" string="reapportionment" />
          </tokens>
        </chunking>
        <chunking id="11" string="illegal immigrants" type="NP">
          <tokens>
            <token id="14" string="illegal" />
            <token id="15" string="immigrants" />
          </tokens>
        </chunking>
        <chunking id="12" string="to force the Census Bureau to exclude illegal immigrants in preparing tallies for congressional reapportionment" type="VP">
          <tokens>
            <token id="7" string="to" />
            <token id="8" string="force" />
            <token id="9" string="the" />
            <token id="10" string="Census" />
            <token id="11" string="Bureau" />
            <token id="12" string="to" />
            <token id="13" string="exclude" />
            <token id="14" string="illegal" />
            <token id="15" string="immigrants" />
            <token id="16" string="in" />
            <token id="17" string="preparing" />
            <token id="18" string="tallies" />
            <token id="19" string="for" />
            <token id="20" string="congressional" />
            <token id="21" string="reapportionment" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="6">voted</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">Senate</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">voted</governor>
          <dependent id="3">Senate</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">voted</governor>
          <dependent id="4">already</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">voted</governor>
          <dependent id="5">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">voted</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">force</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">voted</governor>
          <dependent id="8">force</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">Bureau</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Bureau</governor>
          <dependent id="10">Census</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">force</governor>
          <dependent id="11">Bureau</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">exclude</governor>
          <dependent id="12">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="8">force</governor>
          <dependent id="13">exclude</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">immigrants</governor>
          <dependent id="14">illegal</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">exclude</governor>
          <dependent id="15">immigrants</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">preparing</governor>
          <dependent id="16">in</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="13">exclude</governor>
          <dependent id="17">preparing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">preparing</governor>
          <dependent id="18">tallies</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">reapportionment</governor>
          <dependent id="19">for</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">reapportionment</governor>
          <dependent id="20">congressional</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">preparing</governor>
          <dependent id="21">reapportionment</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Senate" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="3" string="Senate" />
          </tokens>
        </entity>
        <entity id="2" string="Census Bureau" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="10" string="Census" />
            <token id="11" string="Bureau" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>A majority of the members of the House of Representatives has signaled support.</content>
      <tokens>
        <token id="1" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="majority" lemma="majority" stem="major" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="members" lemma="member" stem="member" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="House" lemma="House" stem="hous" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="10" string="Representatives" lemma="Representatives" stem="repres" pos="NNPS" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="11" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="signaled" lemma="signal" stem="signal" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="support" lemma="support" stem="support" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT A) (NN majority)) (PP (IN of) (NP (NP (DT the) (NNS members)) (PP (IN of) (NP (NP (DT the) (NNP House)) (PP (IN of) (NP (NNPS Representatives)))))))) (VP (VBZ has) (VP (VBN signaled) (NP (NN support)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="A majority" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="majority" />
          </tokens>
        </chunking>
        <chunking id="2" string="the members" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="members" />
          </tokens>
        </chunking>
        <chunking id="3" string="has signaled support" type="VP">
          <tokens>
            <token id="11" string="has" />
            <token id="12" string="signaled" />
            <token id="13" string="support" />
          </tokens>
        </chunking>
        <chunking id="4" string="signaled support" type="VP">
          <tokens>
            <token id="12" string="signaled" />
            <token id="13" string="support" />
          </tokens>
        </chunking>
        <chunking id="5" string="the House" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="House" />
          </tokens>
        </chunking>
        <chunking id="6" string="Representatives" type="NP">
          <tokens>
            <token id="10" string="Representatives" />
          </tokens>
        </chunking>
        <chunking id="7" string="the House of Representatives" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="House" />
            <token id="9" string="of" />
            <token id="10" string="Representatives" />
          </tokens>
        </chunking>
        <chunking id="8" string="support" type="NP">
          <tokens>
            <token id="13" string="support" />
          </tokens>
        </chunking>
        <chunking id="9" string="A majority of the members of the House of Representatives" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="majority" />
            <token id="3" string="of" />
            <token id="4" string="the" />
            <token id="5" string="members" />
            <token id="6" string="of" />
            <token id="7" string="the" />
            <token id="8" string="House" />
            <token id="9" string="of" />
            <token id="10" string="Representatives" />
          </tokens>
        </chunking>
        <chunking id="10" string="the members of the House of Representatives" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="members" />
            <token id="6" string="of" />
            <token id="7" string="the" />
            <token id="8" string="House" />
            <token id="9" string="of" />
            <token id="10" string="Representatives" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">majority</governor>
          <dependent id="1">A</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">signaled</governor>
          <dependent id="2">majority</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">members</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">members</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">majority</governor>
          <dependent id="5">members</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">House</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">House</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">members</governor>
          <dependent id="8">House</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">Representatives</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">House</governor>
          <dependent id="10">Representatives</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">signaled</governor>
          <dependent id="11">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">signaled</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">signaled</governor>
          <dependent id="13">support</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="House of Representatives" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="8" string="House" />
            <token id="9" string="of" />
            <token id="10" string="Representatives" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>&amp;quot;It is wrong to apportion congressional seats by counting people who would be deported if our immigration laws were enforced,&amp;quot; Rep. Thomas Petri (R., Wis.) said in a recent House debate.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="wrong" lemma="wrong" stem="wrong" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="apportion" lemma="apportion" stem="apport" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="congressional" lemma="congressional" stem="congression" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="seats" lemma="seat" stem="seat" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="counting" lemma="count" stem="count" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="deported" lemma="deport" stem="deport" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="our" lemma="we" stem="our" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="18" string="immigration" lemma="immigration" stem="immigr" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="laws" lemma="law" stem="law" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="enforced" lemma="enforce" stem="enforc" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="Rep." lemma="Rep." stem="rep." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="26" string="Petri" lemma="Petri" stem="petri" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="27" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="R." lemma="R." stem="r." pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="29" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="Wis." lemma="Wis." stem="wis." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="31" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="35" string="recent" lemma="recent" stem="recent" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="36" string="House" lemma="House" stem="hous" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="37" string="debate" lemma="debate" stem="debat" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="38" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP It)) (VP (VBZ is) (ADJP (JJ wrong) (S (VP (TO to) (VP (VB apportion) (NP (JJ congressional) (NNS seats)) (PP (IN by) (S (VP (VBG counting) (NP (NP (NNS people)) (SBAR (WHNP (WP who)) (S (VP (MD would) (VP (VB be) (VP (VBN deported) (SBAR (IN if) (S (NP (PRP$ our) (NN immigration) (NNS laws)) (VP (VBD were) (VP (VBN enforced)))))))))))))))))))) (, ,) ('' '') (NP (NP (NNP Rep.) (NNP Thomas) (NNP Petri)) (PRN (-LRB- -LRB-) (NP (NNP R.)) (, ,) (NP (NNP Wis.)) (-RRB- -RRB-))) (VP (VBD said) (PP (IN in) (NP (DT a) (JJ recent) (NNP House) (NN debate)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="is wrong to apportion congressional seats by counting people who would be deported if our immigration laws were enforced" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="wrong" />
            <token id="5" string="to" />
            <token id="6" string="apportion" />
            <token id="7" string="congressional" />
            <token id="8" string="seats" />
            <token id="9" string="by" />
            <token id="10" string="counting" />
            <token id="11" string="people" />
            <token id="12" string="who" />
            <token id="13" string="would" />
            <token id="14" string="be" />
            <token id="15" string="deported" />
            <token id="16" string="if" />
            <token id="17" string="our" />
            <token id="18" string="immigration" />
            <token id="19" string="laws" />
            <token id="20" string="were" />
            <token id="21" string="enforced" />
          </tokens>
        </chunking>
        <chunking id="2" string="were enforced" type="VP">
          <tokens>
            <token id="20" string="were" />
            <token id="21" string="enforced" />
          </tokens>
        </chunking>
        <chunking id="3" string="enforced" type="VP">
          <tokens>
            <token id="21" string="enforced" />
          </tokens>
        </chunking>
        <chunking id="4" string="Wis." type="NP">
          <tokens>
            <token id="30" string="Wis." />
          </tokens>
        </chunking>
        <chunking id="5" string="Rep. Thomas Petri" type="NP">
          <tokens>
            <token id="24" string="Rep." />
            <token id="25" string="Thomas" />
            <token id="26" string="Petri" />
          </tokens>
        </chunking>
        <chunking id="6" string="wrong to apportion congressional seats by counting people who would be deported if our immigration laws were enforced" type="ADJP">
          <tokens>
            <token id="4" string="wrong" />
            <token id="5" string="to" />
            <token id="6" string="apportion" />
            <token id="7" string="congressional" />
            <token id="8" string="seats" />
            <token id="9" string="by" />
            <token id="10" string="counting" />
            <token id="11" string="people" />
            <token id="12" string="who" />
            <token id="13" string="would" />
            <token id="14" string="be" />
            <token id="15" string="deported" />
            <token id="16" string="if" />
            <token id="17" string="our" />
            <token id="18" string="immigration" />
            <token id="19" string="laws" />
            <token id="20" string="were" />
            <token id="21" string="enforced" />
          </tokens>
        </chunking>
        <chunking id="7" string="a recent House debate" type="NP">
          <tokens>
            <token id="34" string="a" />
            <token id="35" string="recent" />
            <token id="36" string="House" />
            <token id="37" string="debate" />
          </tokens>
        </chunking>
        <chunking id="8" string="Rep. Thomas Petri -LRB- R. , Wis. -RRB-" type="NP">
          <tokens>
            <token id="24" string="Rep." />
            <token id="25" string="Thomas" />
            <token id="26" string="Petri" />
            <token id="27" string="(" />
            <token id="28" string="R." />
            <token id="29" string="," />
            <token id="30" string="Wis." />
            <token id="31" string=")" />
          </tokens>
        </chunking>
        <chunking id="9" string="It" type="NP">
          <tokens>
            <token id="2" string="It" />
          </tokens>
        </chunking>
        <chunking id="10" string="people" type="NP">
          <tokens>
            <token id="11" string="people" />
          </tokens>
        </chunking>
        <chunking id="11" string="if our immigration laws were enforced" type="SBAR">
          <tokens>
            <token id="16" string="if" />
            <token id="17" string="our" />
            <token id="18" string="immigration" />
            <token id="19" string="laws" />
            <token id="20" string="were" />
            <token id="21" string="enforced" />
          </tokens>
        </chunking>
        <chunking id="12" string="our immigration laws" type="NP">
          <tokens>
            <token id="17" string="our" />
            <token id="18" string="immigration" />
            <token id="19" string="laws" />
          </tokens>
        </chunking>
        <chunking id="13" string="said in a recent House debate" type="VP">
          <tokens>
            <token id="32" string="said" />
            <token id="33" string="in" />
            <token id="34" string="a" />
            <token id="35" string="recent" />
            <token id="36" string="House" />
            <token id="37" string="debate" />
          </tokens>
        </chunking>
        <chunking id="14" string="apportion congressional seats by counting people who would be deported if our immigration laws were enforced" type="VP">
          <tokens>
            <token id="6" string="apportion" />
            <token id="7" string="congressional" />
            <token id="8" string="seats" />
            <token id="9" string="by" />
            <token id="10" string="counting" />
            <token id="11" string="people" />
            <token id="12" string="who" />
            <token id="13" string="would" />
            <token id="14" string="be" />
            <token id="15" string="deported" />
            <token id="16" string="if" />
            <token id="17" string="our" />
            <token id="18" string="immigration" />
            <token id="19" string="laws" />
            <token id="20" string="were" />
            <token id="21" string="enforced" />
          </tokens>
        </chunking>
        <chunking id="15" string="who would be deported if our immigration laws were enforced" type="SBAR">
          <tokens>
            <token id="12" string="who" />
            <token id="13" string="would" />
            <token id="14" string="be" />
            <token id="15" string="deported" />
            <token id="16" string="if" />
            <token id="17" string="our" />
            <token id="18" string="immigration" />
            <token id="19" string="laws" />
            <token id="20" string="were" />
            <token id="21" string="enforced" />
          </tokens>
        </chunking>
        <chunking id="16" string="to apportion congressional seats by counting people who would be deported if our immigration laws were enforced" type="VP">
          <tokens>
            <token id="5" string="to" />
            <token id="6" string="apportion" />
            <token id="7" string="congressional" />
            <token id="8" string="seats" />
            <token id="9" string="by" />
            <token id="10" string="counting" />
            <token id="11" string="people" />
            <token id="12" string="who" />
            <token id="13" string="would" />
            <token id="14" string="be" />
            <token id="15" string="deported" />
            <token id="16" string="if" />
            <token id="17" string="our" />
            <token id="18" string="immigration" />
            <token id="19" string="laws" />
            <token id="20" string="were" />
            <token id="21" string="enforced" />
          </tokens>
        </chunking>
        <chunking id="17" string="be deported if our immigration laws were enforced" type="VP">
          <tokens>
            <token id="14" string="be" />
            <token id="15" string="deported" />
            <token id="16" string="if" />
            <token id="17" string="our" />
            <token id="18" string="immigration" />
            <token id="19" string="laws" />
            <token id="20" string="were" />
            <token id="21" string="enforced" />
          </tokens>
        </chunking>
        <chunking id="18" string="congressional seats" type="NP">
          <tokens>
            <token id="7" string="congressional" />
            <token id="8" string="seats" />
          </tokens>
        </chunking>
        <chunking id="19" string="counting people who would be deported if our immigration laws were enforced" type="VP">
          <tokens>
            <token id="10" string="counting" />
            <token id="11" string="people" />
            <token id="12" string="who" />
            <token id="13" string="would" />
            <token id="14" string="be" />
            <token id="15" string="deported" />
            <token id="16" string="if" />
            <token id="17" string="our" />
            <token id="18" string="immigration" />
            <token id="19" string="laws" />
            <token id="20" string="were" />
            <token id="21" string="enforced" />
          </tokens>
        </chunking>
        <chunking id="20" string="deported if our immigration laws were enforced" type="VP">
          <tokens>
            <token id="15" string="deported" />
            <token id="16" string="if" />
            <token id="17" string="our" />
            <token id="18" string="immigration" />
            <token id="19" string="laws" />
            <token id="20" string="were" />
            <token id="21" string="enforced" />
          </tokens>
        </chunking>
        <chunking id="21" string="would be deported if our immigration laws were enforced" type="VP">
          <tokens>
            <token id="13" string="would" />
            <token id="14" string="be" />
            <token id="15" string="deported" />
            <token id="16" string="if" />
            <token id="17" string="our" />
            <token id="18" string="immigration" />
            <token id="19" string="laws" />
            <token id="20" string="were" />
            <token id="21" string="enforced" />
          </tokens>
        </chunking>
        <chunking id="22" string="R." type="NP">
          <tokens>
            <token id="28" string="R." />
          </tokens>
        </chunking>
        <chunking id="23" string="people who would be deported if our immigration laws were enforced" type="NP">
          <tokens>
            <token id="11" string="people" />
            <token id="12" string="who" />
            <token id="13" string="would" />
            <token id="14" string="be" />
            <token id="15" string="deported" />
            <token id="16" string="if" />
            <token id="17" string="our" />
            <token id="18" string="immigration" />
            <token id="19" string="laws" />
            <token id="20" string="were" />
            <token id="21" string="enforced" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">wrong</governor>
          <dependent id="2">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">wrong</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="32">said</governor>
          <dependent id="4">wrong</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">apportion</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">wrong</governor>
          <dependent id="6">apportion</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">seats</governor>
          <dependent id="7">congressional</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">apportion</governor>
          <dependent id="8">seats</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">counting</governor>
          <dependent id="9">by</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="6">apportion</governor>
          <dependent id="10">counting</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">counting</governor>
          <dependent id="11">people</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="15">deported</governor>
          <dependent id="12">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="15">deported</governor>
          <dependent id="13">would</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="15">deported</governor>
          <dependent id="14">be</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="11">people</governor>
          <dependent id="15">deported</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="21">enforced</governor>
          <dependent id="16">if</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="19">laws</governor>
          <dependent id="17">our</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">laws</governor>
          <dependent id="18">immigration</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="21">enforced</governor>
          <dependent id="19">laws</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="21">enforced</governor>
          <dependent id="20">were</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="15">deported</governor>
          <dependent id="21">enforced</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">Petri</governor>
          <dependent id="24">Rep.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">Petri</governor>
          <dependent id="25">Thomas</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="32">said</governor>
          <dependent id="26">Petri</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="26">Petri</governor>
          <dependent id="28">R.</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="28">R.</governor>
          <dependent id="30">Wis.</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="32">said</dependent>
        </dependency>
        <dependency type="case">
          <governor id="37">debate</governor>
          <dependent id="33">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="37">debate</governor>
          <dependent id="34">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="37">debate</governor>
          <dependent id="35">recent</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="37">debate</governor>
          <dependent id="36">House</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="32">said</governor>
          <dependent id="37">debate</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Wis." type="LOCATION" score="0.0">
          <tokens>
            <token id="30" string="Wis." />
          </tokens>
        </entity>
        <entity id="2" string="House" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="36" string="House" />
          </tokens>
        </entity>
        <entity id="3" string="Thomas Petri" type="PERSON" score="0.0">
          <tokens>
            <token id="25" string="Thomas" />
            <token id="26" string="Petri" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>Replied Rep. Jim Kolbe (R., Ariz.): &amp;quot;A very clear reading of the Constitution says that we shall count all those who are present.&amp;quot;</content>
      <tokens>
        <token id="1" string="Replied" lemma="reply" stem="repli" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="Rep." lemma="Rep." stem="rep." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Jim" lemma="Jim" stem="jim" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="4" string="Kolbe" lemma="Kolbe" stem="kolb" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="5" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="R." lemma="R." stem="r." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Ariz." lemma="Ariz." stem="ariz." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="9" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="very" lemma="very" stem="veri" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="clear" lemma="clear" stem="clear" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="reading" lemma="reading" stem="read" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="Constitution" lemma="Constitution" stem="constitut" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="shall" lemma="shall" stem="shall" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="count" lemma="count" stem="count" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="all" lemma="all" stem="all" pos="PDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="those" lemma="those" stem="those" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="present" lemma="present" stem="present" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (VBN Replied) (NP (NP (NNP Rep.) (NNP Jim) (NNP Kolbe)) (PRN (-LRB- -LRB-) (NP (NNP R.)) (, ,) (NP (NNP Ariz.)) (-RRB- -RRB-))))) (: :) (`` ``) (S (NP (NP (DT A) (ADJP (RB very) (JJ clear)) (NN reading)) (PP (IN of) (NP (DT the) (NNP Constitution)))) (VP (VBZ says) (SBAR (IN that) (S (NP (PRP we)) (VP (MD shall) (VP (VB count) (NP (NP (PDT all) (DT those)) (SBAR (WHNP (WP who)) (S (VP (VBP are) (ADJP (JJ present)))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="Ariz." type="NP">
          <tokens>
            <token id="8" string="Ariz." />
          </tokens>
        </chunking>
        <chunking id="2" string="Replied Rep. Jim Kolbe -LRB- R. , Ariz. -RRB-" type="VP">
          <tokens>
            <token id="1" string="Replied" />
            <token id="2" string="Rep." />
            <token id="3" string="Jim" />
            <token id="4" string="Kolbe" />
            <token id="5" string="(" />
            <token id="6" string="R." />
            <token id="7" string="," />
            <token id="8" string="Ariz." />
            <token id="9" string=")" />
          </tokens>
        </chunking>
        <chunking id="3" string="are present" type="VP">
          <tokens>
            <token id="27" string="are" />
            <token id="28" string="present" />
          </tokens>
        </chunking>
        <chunking id="4" string="Rep. Jim Kolbe -LRB- R. , Ariz. -RRB-" type="NP">
          <tokens>
            <token id="2" string="Rep." />
            <token id="3" string="Jim" />
            <token id="4" string="Kolbe" />
            <token id="5" string="(" />
            <token id="6" string="R." />
            <token id="7" string="," />
            <token id="8" string="Ariz." />
            <token id="9" string=")" />
          </tokens>
        </chunking>
        <chunking id="5" string="A very clear reading of the Constitution" type="NP">
          <tokens>
            <token id="12" string="A" />
            <token id="13" string="very" />
            <token id="14" string="clear" />
            <token id="15" string="reading" />
            <token id="16" string="of" />
            <token id="17" string="the" />
            <token id="18" string="Constitution" />
          </tokens>
        </chunking>
        <chunking id="6" string="the Constitution" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="Constitution" />
          </tokens>
        </chunking>
        <chunking id="7" string="who are present" type="SBAR">
          <tokens>
            <token id="26" string="who" />
            <token id="27" string="are" />
            <token id="28" string="present" />
          </tokens>
        </chunking>
        <chunking id="8" string="all those who are present" type="NP">
          <tokens>
            <token id="24" string="all" />
            <token id="25" string="those" />
            <token id="26" string="who" />
            <token id="27" string="are" />
            <token id="28" string="present" />
          </tokens>
        </chunking>
        <chunking id="9" string="we" type="NP">
          <tokens>
            <token id="21" string="we" />
          </tokens>
        </chunking>
        <chunking id="10" string="shall count all those who are present" type="VP">
          <tokens>
            <token id="22" string="shall" />
            <token id="23" string="count" />
            <token id="24" string="all" />
            <token id="25" string="those" />
            <token id="26" string="who" />
            <token id="27" string="are" />
            <token id="28" string="present" />
          </tokens>
        </chunking>
        <chunking id="11" string="very clear" type="ADJP">
          <tokens>
            <token id="13" string="very" />
            <token id="14" string="clear" />
          </tokens>
        </chunking>
        <chunking id="12" string="all those" type="NP">
          <tokens>
            <token id="24" string="all" />
            <token id="25" string="those" />
          </tokens>
        </chunking>
        <chunking id="13" string="that we shall count all those who are present" type="SBAR">
          <tokens>
            <token id="20" string="that" />
            <token id="21" string="we" />
            <token id="22" string="shall" />
            <token id="23" string="count" />
            <token id="24" string="all" />
            <token id="25" string="those" />
            <token id="26" string="who" />
            <token id="27" string="are" />
            <token id="28" string="present" />
          </tokens>
        </chunking>
        <chunking id="14" string="A very clear reading" type="NP">
          <tokens>
            <token id="12" string="A" />
            <token id="13" string="very" />
            <token id="14" string="clear" />
            <token id="15" string="reading" />
          </tokens>
        </chunking>
        <chunking id="15" string="R." type="NP">
          <tokens>
            <token id="6" string="R." />
          </tokens>
        </chunking>
        <chunking id="16" string="Rep. Jim Kolbe" type="NP">
          <tokens>
            <token id="2" string="Rep." />
            <token id="3" string="Jim" />
            <token id="4" string="Kolbe" />
          </tokens>
        </chunking>
        <chunking id="17" string="count all those who are present" type="VP">
          <tokens>
            <token id="23" string="count" />
            <token id="24" string="all" />
            <token id="25" string="those" />
            <token id="26" string="who" />
            <token id="27" string="are" />
            <token id="28" string="present" />
          </tokens>
        </chunking>
        <chunking id="18" string="present" type="ADJP">
          <tokens>
            <token id="28" string="present" />
          </tokens>
        </chunking>
        <chunking id="19" string="says that we shall count all those who are present" type="VP">
          <tokens>
            <token id="19" string="says" />
            <token id="20" string="that" />
            <token id="21" string="we" />
            <token id="22" string="shall" />
            <token id="23" string="count" />
            <token id="24" string="all" />
            <token id="25" string="those" />
            <token id="26" string="who" />
            <token id="27" string="are" />
            <token id="28" string="present" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="1">Replied</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">Kolbe</governor>
          <dependent id="2">Rep.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">Kolbe</governor>
          <dependent id="3">Jim</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="1">Replied</governor>
          <dependent id="4">Kolbe</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="4">Kolbe</governor>
          <dependent id="6">R.</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="6">R.</governor>
          <dependent id="8">Ariz.</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">reading</governor>
          <dependent id="12">A</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">clear</governor>
          <dependent id="13">very</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">reading</governor>
          <dependent id="14">clear</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">says</governor>
          <dependent id="15">reading</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">Constitution</governor>
          <dependent id="16">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">Constitution</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">reading</governor>
          <dependent id="18">Constitution</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="1">Replied</governor>
          <dependent id="19">says</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="23">count</governor>
          <dependent id="20">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">count</governor>
          <dependent id="21">we</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="23">count</governor>
          <dependent id="22">shall</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="19">says</governor>
          <dependent id="23">count</dependent>
        </dependency>
        <dependency type="det:predet">
          <governor id="25">those</governor>
          <dependent id="24">all</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="23">count</governor>
          <dependent id="25">those</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="28">present</governor>
          <dependent id="26">who</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="28">present</governor>
          <dependent id="27">are</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="25">those</governor>
          <dependent id="28">present</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Jim Kolbe" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Jim" />
            <token id="4" string="Kolbe" />
          </tokens>
        </entity>
        <entity id="2" string="Ariz." type="LOCATION" score="0.0">
          <tokens>
            <token id="8" string="Ariz." />
          </tokens>
        </entity>
        <entity id="3" string="present" type="DATE" score="0.0">
          <tokens>
            <token id="28" string="present" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>Although the debate is often couched in constitutional arguments, it&amp;apost;s largely driven by geography.</content>
      <tokens>
        <token id="1" string="Although" lemma="although" stem="although" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="debate" lemma="debate" stem="debat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="often" lemma="often" stem="often" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="couched" lemma="couch" stem="couch" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="constitutional" lemma="constitutional" stem="constitut" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="arguments" lemma="argument" stem="argument" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="largely" lemma="largely" stem="larg" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="driven" lemma="drive" stem="driven" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="geography" lemma="geography" stem="geographi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN Although) (S (NP (DT the) (NN debate)) (VP (VBZ is) (ADVP (RB often)) (VP (VBN couched) (PP (IN in) (NP (JJ constitutional) (NNS arguments))))))) (, ,) (NP (PRP it)) (VP (VBZ 's) (ADVP (RB largely)) (VP (VBN driven) (PP (IN by) (NP (NN geography))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="'s largely driven by geography" type="VP">
          <tokens>
            <token id="12" string="'s" />
            <token id="13" string="largely" />
            <token id="14" string="driven" />
            <token id="15" string="by" />
            <token id="16" string="geography" />
          </tokens>
        </chunking>
        <chunking id="2" string="geography" type="NP">
          <tokens>
            <token id="16" string="geography" />
          </tokens>
        </chunking>
        <chunking id="3" string="driven by geography" type="VP">
          <tokens>
            <token id="14" string="driven" />
            <token id="15" string="by" />
            <token id="16" string="geography" />
          </tokens>
        </chunking>
        <chunking id="4" string="Although the debate is often couched in constitutional arguments" type="SBAR">
          <tokens>
            <token id="1" string="Although" />
            <token id="2" string="the" />
            <token id="3" string="debate" />
            <token id="4" string="is" />
            <token id="5" string="often" />
            <token id="6" string="couched" />
            <token id="7" string="in" />
            <token id="8" string="constitutional" />
            <token id="9" string="arguments" />
          </tokens>
        </chunking>
        <chunking id="5" string="is often couched in constitutional arguments" type="VP">
          <tokens>
            <token id="4" string="is" />
            <token id="5" string="often" />
            <token id="6" string="couched" />
            <token id="7" string="in" />
            <token id="8" string="constitutional" />
            <token id="9" string="arguments" />
          </tokens>
        </chunking>
        <chunking id="6" string="it" type="NP">
          <tokens>
            <token id="11" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="the debate" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="debate" />
          </tokens>
        </chunking>
        <chunking id="8" string="constitutional arguments" type="NP">
          <tokens>
            <token id="8" string="constitutional" />
            <token id="9" string="arguments" />
          </tokens>
        </chunking>
        <chunking id="9" string="couched in constitutional arguments" type="VP">
          <tokens>
            <token id="6" string="couched" />
            <token id="7" string="in" />
            <token id="8" string="constitutional" />
            <token id="9" string="arguments" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="6">couched</governor>
          <dependent id="1">Although</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">debate</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="6">couched</governor>
          <dependent id="3">debate</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="6">couched</governor>
          <dependent id="4">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">couched</governor>
          <dependent id="5">often</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="14">driven</governor>
          <dependent id="6">couched</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">arguments</governor>
          <dependent id="7">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">arguments</governor>
          <dependent id="8">constitutional</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">couched</governor>
          <dependent id="9">arguments</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="14">driven</governor>
          <dependent id="11">it</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="14">driven</governor>
          <dependent id="12">'s</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">driven</governor>
          <dependent id="13">largely</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">driven</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">geography</governor>
          <dependent id="15">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">driven</governor>
          <dependent id="16">geography</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>Wisconsin has few illegal immigrants; Arizona has lots.</content>
      <tokens>
        <token id="1" string="Wisconsin" lemma="Wisconsin" stem="wisconsin" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="2" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="few" lemma="few" stem="few" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="illegal" lemma="illegal" stem="illeg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="immigrants" lemma="immigrant" stem="immigr" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Arizona" lemma="Arizona" stem="arizona" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="8" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="lots" lemma="lot" stem="lot" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NNP Wisconsin)) (VP (VBZ has) (NP (JJ few) (JJ illegal) (NNS immigrants)))) (: ;) (S (NP (NNP Arizona)) (VP (VBZ has) (NP (NNS lots)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Arizona" type="NP">
          <tokens>
            <token id="7" string="Arizona" />
          </tokens>
        </chunking>
        <chunking id="2" string="lots" type="NP">
          <tokens>
            <token id="9" string="lots" />
          </tokens>
        </chunking>
        <chunking id="3" string="few illegal immigrants" type="NP">
          <tokens>
            <token id="3" string="few" />
            <token id="4" string="illegal" />
            <token id="5" string="immigrants" />
          </tokens>
        </chunking>
        <chunking id="4" string="has lots" type="VP">
          <tokens>
            <token id="8" string="has" />
            <token id="9" string="lots" />
          </tokens>
        </chunking>
        <chunking id="5" string="Wisconsin" type="NP">
          <tokens>
            <token id="1" string="Wisconsin" />
          </tokens>
        </chunking>
        <chunking id="6" string="has few illegal immigrants" type="VP">
          <tokens>
            <token id="2" string="has" />
            <token id="3" string="few" />
            <token id="4" string="illegal" />
            <token id="5" string="immigrants" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">has</governor>
          <dependent id="1">Wisconsin</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">has</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">immigrants</governor>
          <dependent id="3">few</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">immigrants</governor>
          <dependent id="4">illegal</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">has</governor>
          <dependent id="5">immigrants</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">has</governor>
          <dependent id="7">Arizona</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="2">has</governor>
          <dependent id="8">has</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">has</governor>
          <dependent id="9">lots</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Arizona" type="LOCATION" score="0.0">
          <tokens>
            <token id="7" string="Arizona" />
          </tokens>
        </entity>
        <entity id="2" string="Wisconsin" type="LOCATION" score="0.0">
          <tokens>
            <token id="1" string="Wisconsin" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>&amp;quot;It boils down to regional politics,&amp;quot; says Arturo Vargas, census-program director for the Mexican American Legal Defense and Educational Fund, one of several Hispanic organizations lobbying in favor of counting illegal immigrants.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="boils" lemma="boil" stem="boil" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="down" lemma="down" stem="down" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="regional" lemma="regional" stem="region" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="politics" lemma="politics" stem="polit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="Arturo" lemma="Arturo" stem="arturo" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="12" string="Vargas" lemma="Vargas" stem="varga" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="census-program" lemma="census-program" stem="census-program" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="director" lemma="director" stem="director" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Mexican" lemma="mexican" stem="mexican" pos="JJ" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="19" string="American" lemma="american" stem="american" pos="JJ" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="20" string="Legal" lemma="Legal" stem="legal" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="21" string="Defense" lemma="Defense" stem="defens" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="22" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="23" string="Educational" lemma="Educational" stem="educat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="24" string="Fund" lemma="Fund" stem="fund" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="25" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="27" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="several" lemma="several" stem="sever" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="Hispanic" lemma="hispanic" stem="hispan" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="30" string="organizations" lemma="organization" stem="organ" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="lobbying" lemma="lobby" stem="lobbi" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="favor" lemma="favor" stem="favor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="counting" lemma="count" stem="count" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="illegal" lemma="illegal" stem="illeg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="immigrants" lemma="immigrant" stem="immigr" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (NP (PRP It)) (VP (VBZ boils) (PRT (RP down)) (PP (TO to) (NP (JJ regional) (NNS politics))))) (, ,) ('' '') (VP (VBZ says)) (NP (NP (NNP Arturo) (NNP Vargas)) (, ,) (NP (NP (JJ census-program) (NN director)) (PP (IN for) (NP (NP (DT the) (JJ Mexican) (JJ American) (NNP Legal) (NNP Defense) (CC and) (NNP Educational) (NNP Fund)) (, ,) (NP (NP (CD one)) (PP (IN of) (NP (NP (JJ several) (JJ Hispanic) (NNS organizations)) (VP (VBG lobbying) (PP (IN in) (NP (NP (NN favor)) (PP (IN of) (NP (VBG counting) (JJ illegal) (NNS immigrants))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Arturo Vargas" type="NP">
          <tokens>
            <token id="11" string="Arturo" />
            <token id="12" string="Vargas" />
          </tokens>
        </chunking>
        <chunking id="2" string="one" type="NP">
          <tokens>
            <token id="26" string="one" />
          </tokens>
        </chunking>
        <chunking id="3" string="census-program director for the Mexican American Legal Defense and Educational Fund , one of several Hispanic organizations lobbying in favor of counting illegal immigrants" type="NP">
          <tokens>
            <token id="14" string="census-program" />
            <token id="15" string="director" />
            <token id="16" string="for" />
            <token id="17" string="the" />
            <token id="18" string="Mexican" />
            <token id="19" string="American" />
            <token id="20" string="Legal" />
            <token id="21" string="Defense" />
            <token id="22" string="and" />
            <token id="23" string="Educational" />
            <token id="24" string="Fund" />
            <token id="25" string="," />
            <token id="26" string="one" />
            <token id="27" string="of" />
            <token id="28" string="several" />
            <token id="29" string="Hispanic" />
            <token id="30" string="organizations" />
            <token id="31" string="lobbying" />
            <token id="32" string="in" />
            <token id="33" string="favor" />
            <token id="34" string="of" />
            <token id="35" string="counting" />
            <token id="36" string="illegal" />
            <token id="37" string="immigrants" />
          </tokens>
        </chunking>
        <chunking id="4" string="census-program director" type="NP">
          <tokens>
            <token id="14" string="census-program" />
            <token id="15" string="director" />
          </tokens>
        </chunking>
        <chunking id="5" string="the Mexican American Legal Defense and Educational Fund , one of several Hispanic organizations lobbying in favor of counting illegal immigrants" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="Mexican" />
            <token id="19" string="American" />
            <token id="20" string="Legal" />
            <token id="21" string="Defense" />
            <token id="22" string="and" />
            <token id="23" string="Educational" />
            <token id="24" string="Fund" />
            <token id="25" string="," />
            <token id="26" string="one" />
            <token id="27" string="of" />
            <token id="28" string="several" />
            <token id="29" string="Hispanic" />
            <token id="30" string="organizations" />
            <token id="31" string="lobbying" />
            <token id="32" string="in" />
            <token id="33" string="favor" />
            <token id="34" string="of" />
            <token id="35" string="counting" />
            <token id="36" string="illegal" />
            <token id="37" string="immigrants" />
          </tokens>
        </chunking>
        <chunking id="6" string="regional politics" type="NP">
          <tokens>
            <token id="6" string="regional" />
            <token id="7" string="politics" />
          </tokens>
        </chunking>
        <chunking id="7" string="one of several Hispanic organizations lobbying in favor of counting illegal immigrants" type="NP">
          <tokens>
            <token id="26" string="one" />
            <token id="27" string="of" />
            <token id="28" string="several" />
            <token id="29" string="Hispanic" />
            <token id="30" string="organizations" />
            <token id="31" string="lobbying" />
            <token id="32" string="in" />
            <token id="33" string="favor" />
            <token id="34" string="of" />
            <token id="35" string="counting" />
            <token id="36" string="illegal" />
            <token id="37" string="immigrants" />
          </tokens>
        </chunking>
        <chunking id="8" string="several Hispanic organizations lobbying in favor of counting illegal immigrants" type="NP">
          <tokens>
            <token id="28" string="several" />
            <token id="29" string="Hispanic" />
            <token id="30" string="organizations" />
            <token id="31" string="lobbying" />
            <token id="32" string="in" />
            <token id="33" string="favor" />
            <token id="34" string="of" />
            <token id="35" string="counting" />
            <token id="36" string="illegal" />
            <token id="37" string="immigrants" />
          </tokens>
        </chunking>
        <chunking id="9" string="It" type="NP">
          <tokens>
            <token id="2" string="It" />
          </tokens>
        </chunking>
        <chunking id="10" string="Arturo Vargas , census-program director for the Mexican American Legal Defense and Educational Fund , one of several Hispanic organizations lobbying in favor of counting illegal immigrants" type="NP">
          <tokens>
            <token id="11" string="Arturo" />
            <token id="12" string="Vargas" />
            <token id="13" string="," />
            <token id="14" string="census-program" />
            <token id="15" string="director" />
            <token id="16" string="for" />
            <token id="17" string="the" />
            <token id="18" string="Mexican" />
            <token id="19" string="American" />
            <token id="20" string="Legal" />
            <token id="21" string="Defense" />
            <token id="22" string="and" />
            <token id="23" string="Educational" />
            <token id="24" string="Fund" />
            <token id="25" string="," />
            <token id="26" string="one" />
            <token id="27" string="of" />
            <token id="28" string="several" />
            <token id="29" string="Hispanic" />
            <token id="30" string="organizations" />
            <token id="31" string="lobbying" />
            <token id="32" string="in" />
            <token id="33" string="favor" />
            <token id="34" string="of" />
            <token id="35" string="counting" />
            <token id="36" string="illegal" />
            <token id="37" string="immigrants" />
          </tokens>
        </chunking>
        <chunking id="11" string="lobbying in favor of counting illegal immigrants" type="VP">
          <tokens>
            <token id="31" string="lobbying" />
            <token id="32" string="in" />
            <token id="33" string="favor" />
            <token id="34" string="of" />
            <token id="35" string="counting" />
            <token id="36" string="illegal" />
            <token id="37" string="immigrants" />
          </tokens>
        </chunking>
        <chunking id="12" string="the Mexican American Legal Defense and Educational Fund" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="Mexican" />
            <token id="19" string="American" />
            <token id="20" string="Legal" />
            <token id="21" string="Defense" />
            <token id="22" string="and" />
            <token id="23" string="Educational" />
            <token id="24" string="Fund" />
          </tokens>
        </chunking>
        <chunking id="13" string="says" type="VP">
          <tokens>
            <token id="10" string="says" />
          </tokens>
        </chunking>
        <chunking id="14" string="boils down to regional politics" type="VP">
          <tokens>
            <token id="3" string="boils" />
            <token id="4" string="down" />
            <token id="5" string="to" />
            <token id="6" string="regional" />
            <token id="7" string="politics" />
          </tokens>
        </chunking>
        <chunking id="15" string="favor" type="NP">
          <tokens>
            <token id="33" string="favor" />
          </tokens>
        </chunking>
        <chunking id="16" string="counting illegal immigrants" type="NP">
          <tokens>
            <token id="35" string="counting" />
            <token id="36" string="illegal" />
            <token id="37" string="immigrants" />
          </tokens>
        </chunking>
        <chunking id="17" string="favor of counting illegal immigrants" type="NP">
          <tokens>
            <token id="33" string="favor" />
            <token id="34" string="of" />
            <token id="35" string="counting" />
            <token id="36" string="illegal" />
            <token id="37" string="immigrants" />
          </tokens>
        </chunking>
        <chunking id="18" string="several Hispanic organizations" type="NP">
          <tokens>
            <token id="28" string="several" />
            <token id="29" string="Hispanic" />
            <token id="30" string="organizations" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">boils</governor>
          <dependent id="2">It</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">says</governor>
          <dependent id="3">boils</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="3">boils</governor>
          <dependent id="4">down</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">politics</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">politics</governor>
          <dependent id="6">regional</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">boils</governor>
          <dependent id="7">politics</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">says</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Vargas</governor>
          <dependent id="11">Arturo</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">says</governor>
          <dependent id="12">Vargas</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">director</governor>
          <dependent id="14">census-program</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="12">Vargas</governor>
          <dependent id="15">director</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">Defense</governor>
          <dependent id="16">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">Defense</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">Defense</governor>
          <dependent id="18">Mexican</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">Defense</governor>
          <dependent id="19">American</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">Defense</governor>
          <dependent id="20">Legal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">director</governor>
          <dependent id="21">Defense</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="21">Defense</governor>
          <dependent id="22">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">Fund</governor>
          <dependent id="23">Educational</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="21">Defense</governor>
          <dependent id="24">Fund</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="21">Defense</governor>
          <dependent id="26">one</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">organizations</governor>
          <dependent id="27">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="30">organizations</governor>
          <dependent id="28">several</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="30">organizations</governor>
          <dependent id="29">Hispanic</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">one</governor>
          <dependent id="30">organizations</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="30">organizations</governor>
          <dependent id="31">lobbying</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">favor</governor>
          <dependent id="32">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">lobbying</governor>
          <dependent id="33">favor</dependent>
        </dependency>
        <dependency type="case">
          <governor id="37">immigrants</governor>
          <dependent id="34">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="37">immigrants</governor>
          <dependent id="35">counting</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="37">immigrants</governor>
          <dependent id="36">illegal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="33">favor</governor>
          <dependent id="37">immigrants</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Arturo Vargas" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Arturo" />
            <token id="12" string="Vargas" />
          </tokens>
        </entity>
        <entity id="2" string="Mexican American Legal Defense and Educational Fund" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="18" string="Mexican" />
            <token id="19" string="American" />
            <token id="20" string="Legal" />
            <token id="21" string="Defense" />
            <token id="22" string="and" />
            <token id="23" string="Educational" />
            <token id="24" string="Fund" />
          </tokens>
        </entity>
        <entity id="3" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="26" string="one" />
          </tokens>
        </entity>
        <entity id="4" string="Hispanic" type="MISC" score="0.0">
          <tokens>
            <token id="29" string="Hispanic" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>Counting illegal immigrants in 1990 is likely to mean one less seat in the House for Pennsylvania and one more for California, according to the private Population Reference Bureau.</content>
      <tokens>
        <token id="1" string="Counting" lemma="count" stem="count" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="illegal" lemma="illegal" stem="illeg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="immigrants" lemma="immigrant" stem="immigr" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="1990" lemma="1990" stem="1990" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="6" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="likely" lemma="likely" stem="like" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="mean" lemma="mean" stem="mean" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="11" string="less" lemma="less" stem="less" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="seat" lemma="seat" stem="seat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="House" lemma="House" stem="hous" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="16" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="Pennsylvania" lemma="Pennsylvania" stem="pennsylvania" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="true" />
        <token id="18" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="20" string="more" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="California" lemma="California" stem="california" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="according" lemma="accord" stem="accord" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="private" lemma="private" stem="privat" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="Population" lemma="Population" stem="popul" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="29" string="Reference" lemma="Reference" stem="refer" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="30" string="Bureau" lemma="Bureau" stem="bureau" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="31" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (VBG Counting) (NP (JJ illegal) (NNS immigrants)) (PP (IN in) (NP (CD 1990))))) (VP (VBZ is) (ADJP (JJ likely) (S (VP (TO to) (VP (VB mean) (NP (CD one) (JJR less) (NN seat)) (PP (IN in) (NP (NP (NP (DT the) (NNP House)) (PP (IN for) (NP (NNP Pennsylvania)))) (CC and) (NP (NP (CD one) (JJR more)) (PP (IN for) (NP (NNP California)))))) (, ,) (PP (VBG according) (PP (TO to) (NP (DT the) (JJ private) (NNP Population) (NNP Reference) (NNP Bureau))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the House for Pennsylvania" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="House" />
            <token id="16" string="for" />
            <token id="17" string="Pennsylvania" />
          </tokens>
        </chunking>
        <chunking id="2" string="California" type="NP">
          <tokens>
            <token id="22" string="California" />
          </tokens>
        </chunking>
        <chunking id="3" string="is likely to mean one less seat in the House for Pennsylvania and one more for California , according to the private Population Reference Bureau" type="VP">
          <tokens>
            <token id="6" string="is" />
            <token id="7" string="likely" />
            <token id="8" string="to" />
            <token id="9" string="mean" />
            <token id="10" string="one" />
            <token id="11" string="less" />
            <token id="12" string="seat" />
            <token id="13" string="in" />
            <token id="14" string="the" />
            <token id="15" string="House" />
            <token id="16" string="for" />
            <token id="17" string="Pennsylvania" />
            <token id="18" string="and" />
            <token id="19" string="one" />
            <token id="20" string="more" />
            <token id="21" string="for" />
            <token id="22" string="California" />
            <token id="23" string="," />
            <token id="24" string="according" />
            <token id="25" string="to" />
            <token id="26" string="the" />
            <token id="27" string="private" />
            <token id="28" string="Population" />
            <token id="29" string="Reference" />
            <token id="30" string="Bureau" />
          </tokens>
        </chunking>
        <chunking id="4" string="the House" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="House" />
          </tokens>
        </chunking>
        <chunking id="5" string="the private Population Reference Bureau" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="private" />
            <token id="28" string="Population" />
            <token id="29" string="Reference" />
            <token id="30" string="Bureau" />
          </tokens>
        </chunking>
        <chunking id="6" string="1990" type="NP">
          <tokens>
            <token id="5" string="1990" />
          </tokens>
        </chunking>
        <chunking id="7" string="illegal immigrants" type="NP">
          <tokens>
            <token id="2" string="illegal" />
            <token id="3" string="immigrants" />
          </tokens>
        </chunking>
        <chunking id="8" string="Pennsylvania" type="NP">
          <tokens>
            <token id="17" string="Pennsylvania" />
          </tokens>
        </chunking>
        <chunking id="9" string="to mean one less seat in the House for Pennsylvania and one more for California , according to the private Population Reference Bureau" type="VP">
          <tokens>
            <token id="8" string="to" />
            <token id="9" string="mean" />
            <token id="10" string="one" />
            <token id="11" string="less" />
            <token id="12" string="seat" />
            <token id="13" string="in" />
            <token id="14" string="the" />
            <token id="15" string="House" />
            <token id="16" string="for" />
            <token id="17" string="Pennsylvania" />
            <token id="18" string="and" />
            <token id="19" string="one" />
            <token id="20" string="more" />
            <token id="21" string="for" />
            <token id="22" string="California" />
            <token id="23" string="," />
            <token id="24" string="according" />
            <token id="25" string="to" />
            <token id="26" string="the" />
            <token id="27" string="private" />
            <token id="28" string="Population" />
            <token id="29" string="Reference" />
            <token id="30" string="Bureau" />
          </tokens>
        </chunking>
        <chunking id="10" string="one more" type="NP">
          <tokens>
            <token id="19" string="one" />
            <token id="20" string="more" />
          </tokens>
        </chunking>
        <chunking id="11" string="likely to mean one less seat in the House for Pennsylvania and one more for California , according to the private Population Reference Bureau" type="ADJP">
          <tokens>
            <token id="7" string="likely" />
            <token id="8" string="to" />
            <token id="9" string="mean" />
            <token id="10" string="one" />
            <token id="11" string="less" />
            <token id="12" string="seat" />
            <token id="13" string="in" />
            <token id="14" string="the" />
            <token id="15" string="House" />
            <token id="16" string="for" />
            <token id="17" string="Pennsylvania" />
            <token id="18" string="and" />
            <token id="19" string="one" />
            <token id="20" string="more" />
            <token id="21" string="for" />
            <token id="22" string="California" />
            <token id="23" string="," />
            <token id="24" string="according" />
            <token id="25" string="to" />
            <token id="26" string="the" />
            <token id="27" string="private" />
            <token id="28" string="Population" />
            <token id="29" string="Reference" />
            <token id="30" string="Bureau" />
          </tokens>
        </chunking>
        <chunking id="12" string="one less seat" type="NP">
          <tokens>
            <token id="10" string="one" />
            <token id="11" string="less" />
            <token id="12" string="seat" />
          </tokens>
        </chunking>
        <chunking id="13" string="one more for California" type="NP">
          <tokens>
            <token id="19" string="one" />
            <token id="20" string="more" />
            <token id="21" string="for" />
            <token id="22" string="California" />
          </tokens>
        </chunking>
        <chunking id="14" string="the House for Pennsylvania and one more for California" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="House" />
            <token id="16" string="for" />
            <token id="17" string="Pennsylvania" />
            <token id="18" string="and" />
            <token id="19" string="one" />
            <token id="20" string="more" />
            <token id="21" string="for" />
            <token id="22" string="California" />
          </tokens>
        </chunking>
        <chunking id="15" string="Counting illegal immigrants in 1990" type="VP">
          <tokens>
            <token id="1" string="Counting" />
            <token id="2" string="illegal" />
            <token id="3" string="immigrants" />
            <token id="4" string="in" />
            <token id="5" string="1990" />
          </tokens>
        </chunking>
        <chunking id="16" string="mean one less seat in the House for Pennsylvania and one more for California , according to the private Population Reference Bureau" type="VP">
          <tokens>
            <token id="9" string="mean" />
            <token id="10" string="one" />
            <token id="11" string="less" />
            <token id="12" string="seat" />
            <token id="13" string="in" />
            <token id="14" string="the" />
            <token id="15" string="House" />
            <token id="16" string="for" />
            <token id="17" string="Pennsylvania" />
            <token id="18" string="and" />
            <token id="19" string="one" />
            <token id="20" string="more" />
            <token id="21" string="for" />
            <token id="22" string="California" />
            <token id="23" string="," />
            <token id="24" string="according" />
            <token id="25" string="to" />
            <token id="26" string="the" />
            <token id="27" string="private" />
            <token id="28" string="Population" />
            <token id="29" string="Reference" />
            <token id="30" string="Bureau" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="csubj">
          <governor id="7">likely</governor>
          <dependent id="1">Counting</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">immigrants</governor>
          <dependent id="2">illegal</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="1">Counting</governor>
          <dependent id="3">immigrants</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">1990</governor>
          <dependent id="4">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Counting</governor>
          <dependent id="5">1990</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">likely</governor>
          <dependent id="6">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">likely</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">mean</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="7">likely</governor>
          <dependent id="9">mean</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="12">seat</governor>
          <dependent id="10">one</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">seat</governor>
          <dependent id="11">less</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">mean</governor>
          <dependent id="12">seat</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">House</governor>
          <dependent id="13">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">House</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">mean</governor>
          <dependent id="15">House</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">Pennsylvania</governor>
          <dependent id="16">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">House</governor>
          <dependent id="17">Pennsylvania</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="15">House</governor>
          <dependent id="18">and</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="20">more</governor>
          <dependent id="19">one</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="15">House</governor>
          <dependent id="20">more</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">California</governor>
          <dependent id="21">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">more</governor>
          <dependent id="22">California</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">Bureau</governor>
          <dependent id="24">according</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="24">according</governor>
          <dependent id="25">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">Bureau</governor>
          <dependent id="26">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="30">Bureau</governor>
          <dependent id="27">private</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="30">Bureau</governor>
          <dependent id="28">Population</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="30">Bureau</governor>
          <dependent id="29">Reference</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">mean</governor>
          <dependent id="30">Bureau</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="10" string="one" />
          </tokens>
        </entity>
        <entity id="2" string="California" type="LOCATION" score="0.0">
          <tokens>
            <token id="22" string="California" />
          </tokens>
        </entity>
        <entity id="3" string="Population Reference Bureau" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="28" string="Population" />
            <token id="29" string="Reference" />
            <token id="30" string="Bureau" />
          </tokens>
        </entity>
        <entity id="4" string="House" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="15" string="House" />
          </tokens>
        </entity>
        <entity id="5" string="1990" type="DATE" score="0.0">
          <tokens>
            <token id="5" string="1990" />
          </tokens>
        </entity>
        <entity id="6" string="Pennsylvania" type="LOCATION" score="0.0">
          <tokens>
            <token id="17" string="Pennsylvania" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>The Census Bureau&amp;apost;s chief antagonist in the Senate, Sen. Richard Shelby (D., Ala.), says seats for Connecticut, Michigan, North Carolina and Alabama also are at risk.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="Census" lemma="Census" stem="censu" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="3" string="Bureau" lemma="Bureau" stem="bureau" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="4" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="chief" lemma="chief" stem="chief" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="antagonist" lemma="antagonist" stem="antagonist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Senate" lemma="Senate" stem="senat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Sen." lemma="Sen." stem="sen." pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="Richard" lemma="Richard" stem="richard" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="13" string="Shelby" lemma="Shelby" stem="shelbi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="14" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="D." lemma="D." stem="d." pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="Ala." lemma="Ala." stem="ala." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="18" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="seats" lemma="seat" stem="seat" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="Connecticut" lemma="Connecticut" stem="connecticut" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="Michigan" lemma="Michigan" stem="michigan" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="26" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="North" lemma="North" stem="north" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="28" string="Carolina" lemma="Carolina" stem="carolina" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="29" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="Alabama" lemma="Alabama" stem="alabama" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="31" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="risk" lemma="risk" stem="risk" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NP (NP (DT The) (NNP Census) (NNP Bureau) (POS 's)) (JJ chief) (NN antagonist)) (PP (IN in) (NP (DT the) (NNP Senate)))) (, ,) (NP (NP (NNP Sen.) (NNP Richard) (NNP Shelby)) (PRN (-LRB- -LRB-) (NP (NNP D.)) (, ,) (NP (NNP Ala.)) (-RRB- -RRB-))) (, ,)) (VP (VBZ says) (SBAR (S (NP (NP (NNS seats)) (PP (IN for) (NP (NNP Connecticut) (, ,) (NNP Michigan) (, ,) (NNP North) (NNP Carolina) (CC and) (NNP Alabama)))) (ADVP (RB also)) (VP (VBP are) (PP (IN at) (NP (NN risk))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="The Census Bureau 's chief antagonist in the Senate" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Census" />
            <token id="3" string="Bureau" />
            <token id="4" string="'s" />
            <token id="5" string="chief" />
            <token id="6" string="antagonist" />
            <token id="7" string="in" />
            <token id="8" string="the" />
            <token id="9" string="Senate" />
          </tokens>
        </chunking>
        <chunking id="2" string="Connecticut , Michigan , North Carolina and Alabama" type="NP">
          <tokens>
            <token id="23" string="Connecticut" />
            <token id="24" string="," />
            <token id="25" string="Michigan" />
            <token id="26" string="," />
            <token id="27" string="North" />
            <token id="28" string="Carolina" />
            <token id="29" string="and" />
            <token id="30" string="Alabama" />
          </tokens>
        </chunking>
        <chunking id="3" string="says seats for Connecticut , Michigan , North Carolina and Alabama also are at risk" type="VP">
          <tokens>
            <token id="20" string="says" />
            <token id="21" string="seats" />
            <token id="22" string="for" />
            <token id="23" string="Connecticut" />
            <token id="24" string="," />
            <token id="25" string="Michigan" />
            <token id="26" string="," />
            <token id="27" string="North" />
            <token id="28" string="Carolina" />
            <token id="29" string="and" />
            <token id="30" string="Alabama" />
            <token id="31" string="also" />
            <token id="32" string="are" />
            <token id="33" string="at" />
            <token id="34" string="risk" />
          </tokens>
        </chunking>
        <chunking id="4" string="are at risk" type="VP">
          <tokens>
            <token id="32" string="are" />
            <token id="33" string="at" />
            <token id="34" string="risk" />
          </tokens>
        </chunking>
        <chunking id="5" string="Ala." type="NP">
          <tokens>
            <token id="17" string="Ala." />
          </tokens>
        </chunking>
        <chunking id="6" string="The Census Bureau 's chief antagonist in the Senate , Sen. Richard Shelby -LRB- D. , Ala. -RRB- ," type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Census" />
            <token id="3" string="Bureau" />
            <token id="4" string="'s" />
            <token id="5" string="chief" />
            <token id="6" string="antagonist" />
            <token id="7" string="in" />
            <token id="8" string="the" />
            <token id="9" string="Senate" />
            <token id="10" string="," />
            <token id="11" string="Sen." />
            <token id="12" string="Richard" />
            <token id="13" string="Shelby" />
            <token id="14" string="(" />
            <token id="15" string="D." />
            <token id="16" string="," />
            <token id="17" string="Ala." />
            <token id="18" string=")" />
            <token id="19" string="," />
          </tokens>
        </chunking>
        <chunking id="7" string="D." type="NP">
          <tokens>
            <token id="15" string="D." />
          </tokens>
        </chunking>
        <chunking id="8" string="Sen. Richard Shelby" type="NP">
          <tokens>
            <token id="11" string="Sen." />
            <token id="12" string="Richard" />
            <token id="13" string="Shelby" />
          </tokens>
        </chunking>
        <chunking id="9" string="Sen. Richard Shelby -LRB- D. , Ala. -RRB-" type="NP">
          <tokens>
            <token id="11" string="Sen." />
            <token id="12" string="Richard" />
            <token id="13" string="Shelby" />
            <token id="14" string="(" />
            <token id="15" string="D." />
            <token id="16" string="," />
            <token id="17" string="Ala." />
            <token id="18" string=")" />
          </tokens>
        </chunking>
        <chunking id="10" string="seats" type="NP">
          <tokens>
            <token id="21" string="seats" />
          </tokens>
        </chunking>
        <chunking id="11" string="the Senate" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="Senate" />
          </tokens>
        </chunking>
        <chunking id="12" string="seats for Connecticut , Michigan , North Carolina and Alabama also are at risk" type="SBAR">
          <tokens>
            <token id="21" string="seats" />
            <token id="22" string="for" />
            <token id="23" string="Connecticut" />
            <token id="24" string="," />
            <token id="25" string="Michigan" />
            <token id="26" string="," />
            <token id="27" string="North" />
            <token id="28" string="Carolina" />
            <token id="29" string="and" />
            <token id="30" string="Alabama" />
            <token id="31" string="also" />
            <token id="32" string="are" />
            <token id="33" string="at" />
            <token id="34" string="risk" />
          </tokens>
        </chunking>
        <chunking id="13" string="seats for Connecticut , Michigan , North Carolina and Alabama" type="NP">
          <tokens>
            <token id="21" string="seats" />
            <token id="22" string="for" />
            <token id="23" string="Connecticut" />
            <token id="24" string="," />
            <token id="25" string="Michigan" />
            <token id="26" string="," />
            <token id="27" string="North" />
            <token id="28" string="Carolina" />
            <token id="29" string="and" />
            <token id="30" string="Alabama" />
          </tokens>
        </chunking>
        <chunking id="14" string="The Census Bureau 's chief antagonist" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Census" />
            <token id="3" string="Bureau" />
            <token id="4" string="'s" />
            <token id="5" string="chief" />
            <token id="6" string="antagonist" />
          </tokens>
        </chunking>
        <chunking id="15" string="risk" type="NP">
          <tokens>
            <token id="34" string="risk" />
          </tokens>
        </chunking>
        <chunking id="16" string="The Census Bureau 's" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Census" />
            <token id="3" string="Bureau" />
            <token id="4" string="'s" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">Bureau</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Bureau</governor>
          <dependent id="2">Census</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="6">antagonist</governor>
          <dependent id="3">Bureau</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">Bureau</governor>
          <dependent id="4">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">antagonist</governor>
          <dependent id="5">chief</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">says</governor>
          <dependent id="6">antagonist</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Senate</governor>
          <dependent id="7">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">Senate</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">antagonist</governor>
          <dependent id="9">Senate</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Shelby</governor>
          <dependent id="11">Sen.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Shelby</governor>
          <dependent id="12">Richard</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="6">antagonist</governor>
          <dependent id="13">Shelby</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="13">Shelby</governor>
          <dependent id="15">D.</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="15">D.</governor>
          <dependent id="17">Ala.</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="20">says</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="34">risk</governor>
          <dependent id="21">seats</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">Carolina</governor>
          <dependent id="22">for</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">Carolina</governor>
          <dependent id="23">Connecticut</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="28">Carolina</governor>
          <dependent id="25">Michigan</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="28">Carolina</governor>
          <dependent id="27">North</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">seats</governor>
          <dependent id="28">Carolina</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="28">Carolina</governor>
          <dependent id="29">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="28">Carolina</governor>
          <dependent id="30">Alabama</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="34">risk</governor>
          <dependent id="31">also</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="34">risk</governor>
          <dependent id="32">are</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">risk</governor>
          <dependent id="33">at</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="20">says</governor>
          <dependent id="34">risk</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Senate" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="9" string="Senate" />
          </tokens>
        </entity>
        <entity id="2" string="Richard Shelby" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Richard" />
            <token id="13" string="Shelby" />
          </tokens>
        </entity>
        <entity id="3" string="North Carolina" type="LOCATION" score="0.0">
          <tokens>
            <token id="27" string="North" />
            <token id="28" string="Carolina" />
          </tokens>
        </entity>
        <entity id="4" string="Connecticut" type="LOCATION" score="0.0">
          <tokens>
            <token id="23" string="Connecticut" />
          </tokens>
        </entity>
        <entity id="5" string="Ala." type="LOCATION" score="0.0">
          <tokens>
            <token id="17" string="Ala." />
          </tokens>
        </entity>
        <entity id="6" string="Michigan" type="LOCATION" score="0.0">
          <tokens>
            <token id="25" string="Michigan" />
          </tokens>
        </entity>
        <entity id="7" string="Census Bureau" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="2" string="Census" />
            <token id="3" string="Bureau" />
          </tokens>
        </entity>
        <entity id="8" string="Alabama" type="LOCATION" score="0.0">
          <tokens>
            <token id="30" string="Alabama" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="12" has_coreference="false">
      <content>On the other hand, Texas, Florida and New York could benefit.</content>
      <tokens>
        <token id="1" string="On" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="hand" lemma="hand" stem="hand" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Texas" lemma="Texas" stem="texa" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Florida" lemma="Florida" stem="florida" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="New" lemma="New" stem="new" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="11" string="York" lemma="York" stem="york" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="12" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="benefit" lemma="benefit" stem="benefit" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN On) (NP (DT the) (JJ other) (NN hand))) (, ,) (NP (NP (NNP Texas)) (, ,) (NP (NNP Florida)) (CC and) (NP (NNP New) (NNP York))) (VP (MD could) (VP (VB benefit))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="New York" type="NP">
          <tokens>
            <token id="10" string="New" />
            <token id="11" string="York" />
          </tokens>
        </chunking>
        <chunking id="2" string="the other hand" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="other" />
            <token id="4" string="hand" />
          </tokens>
        </chunking>
        <chunking id="3" string="Texas" type="NP">
          <tokens>
            <token id="6" string="Texas" />
          </tokens>
        </chunking>
        <chunking id="4" string="Texas , Florida and New York" type="NP">
          <tokens>
            <token id="6" string="Texas" />
            <token id="7" string="," />
            <token id="8" string="Florida" />
            <token id="9" string="and" />
            <token id="10" string="New" />
            <token id="11" string="York" />
          </tokens>
        </chunking>
        <chunking id="5" string="could benefit" type="VP">
          <tokens>
            <token id="12" string="could" />
            <token id="13" string="benefit" />
          </tokens>
        </chunking>
        <chunking id="6" string="Florida" type="NP">
          <tokens>
            <token id="8" string="Florida" />
          </tokens>
        </chunking>
        <chunking id="7" string="benefit" type="VP">
          <tokens>
            <token id="13" string="benefit" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">hand</governor>
          <dependent id="1">On</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">hand</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">hand</governor>
          <dependent id="3">other</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">benefit</governor>
          <dependent id="4">hand</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">benefit</governor>
          <dependent id="6">Texas</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">Texas</governor>
          <dependent id="8">Florida</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">Texas</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">York</governor>
          <dependent id="10">New</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">Texas</governor>
          <dependent id="11">York</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="13">benefit</governor>
          <dependent id="12">could</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">benefit</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="New York" type="LOCATION" score="0.0">
          <tokens>
            <token id="10" string="New" />
            <token id="11" string="York" />
          </tokens>
        </entity>
        <entity id="2" string="Texas" type="LOCATION" score="0.0">
          <tokens>
            <token id="6" string="Texas" />
          </tokens>
        </entity>
        <entity id="3" string="Florida" type="LOCATION" score="0.0">
          <tokens>
            <token id="8" string="Florida" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>&amp;quot;Illegal aliens are actually taking representation away from Americans,&amp;quot; says David Ray, spokesman for the Federation for American Immigration Reform.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Illegal" lemma="illegal" stem="illegal" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="aliens" lemma="alien" stem="alien" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="actually" lemma="actually" stem="actual" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="taking" lemma="take" stem="take" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="representation" lemma="representation" stem="represent" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="away" lemma="away" stem="awai" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Americans" lemma="Americans" stem="american" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="David" lemma="David" stem="david" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="15" string="Ray" lemma="Ray" stem="rai" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="spokesman" lemma="spokesman" stem="spokesman" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="Federation" lemma="Federation" stem="feder" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="21" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="22" string="American" lemma="American" stem="american" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="23" string="Immigration" lemma="Immigration" stem="immigrat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="24" string="Reform" lemma="Reform" stem="reform" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (NP (JJ Illegal) (NNS aliens)) (VP (VBP are) (ADVP (RB actually)) (VP (VBG taking) (NP (NN representation)) (ADVP (RB away)) (PP (IN from) (NP (NNPS Americans)))))) (, ,) ('' '') (VP (VBZ says)) (NP (NP (NNP David) (NNP Ray)) (, ,) (NP (NP (NN spokesman)) (PP (IN for) (NP (NP (DT the) (NNP Federation)) (PP (IN for) (NP (NNP American) (NNP Immigration) (NNP Reform))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="David Ray" type="NP">
          <tokens>
            <token id="14" string="David" />
            <token id="15" string="Ray" />
          </tokens>
        </chunking>
        <chunking id="2" string="the Federation for American Immigration Reform" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="Federation" />
            <token id="21" string="for" />
            <token id="22" string="American" />
            <token id="23" string="Immigration" />
            <token id="24" string="Reform" />
          </tokens>
        </chunking>
        <chunking id="3" string="spokesman" type="NP">
          <tokens>
            <token id="17" string="spokesman" />
          </tokens>
        </chunking>
        <chunking id="4" string="taking representation away from Americans" type="VP">
          <tokens>
            <token id="6" string="taking" />
            <token id="7" string="representation" />
            <token id="8" string="away" />
            <token id="9" string="from" />
            <token id="10" string="Americans" />
          </tokens>
        </chunking>
        <chunking id="5" string="Americans" type="NP">
          <tokens>
            <token id="10" string="Americans" />
          </tokens>
        </chunking>
        <chunking id="6" string="spokesman for the Federation for American Immigration Reform" type="NP">
          <tokens>
            <token id="17" string="spokesman" />
            <token id="18" string="for" />
            <token id="19" string="the" />
            <token id="20" string="Federation" />
            <token id="21" string="for" />
            <token id="22" string="American" />
            <token id="23" string="Immigration" />
            <token id="24" string="Reform" />
          </tokens>
        </chunking>
        <chunking id="7" string="American Immigration Reform" type="NP">
          <tokens>
            <token id="22" string="American" />
            <token id="23" string="Immigration" />
            <token id="24" string="Reform" />
          </tokens>
        </chunking>
        <chunking id="8" string="the Federation" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="Federation" />
          </tokens>
        </chunking>
        <chunking id="9" string="representation" type="NP">
          <tokens>
            <token id="7" string="representation" />
          </tokens>
        </chunking>
        <chunking id="10" string="Illegal aliens" type="NP">
          <tokens>
            <token id="2" string="Illegal" />
            <token id="3" string="aliens" />
          </tokens>
        </chunking>
        <chunking id="11" string="says" type="VP">
          <tokens>
            <token id="13" string="says" />
          </tokens>
        </chunking>
        <chunking id="12" string="are actually taking representation away from Americans" type="VP">
          <tokens>
            <token id="4" string="are" />
            <token id="5" string="actually" />
            <token id="6" string="taking" />
            <token id="7" string="representation" />
            <token id="8" string="away" />
            <token id="9" string="from" />
            <token id="10" string="Americans" />
          </tokens>
        </chunking>
        <chunking id="13" string="David Ray , spokesman for the Federation for American Immigration Reform" type="NP">
          <tokens>
            <token id="14" string="David" />
            <token id="15" string="Ray" />
            <token id="16" string="," />
            <token id="17" string="spokesman" />
            <token id="18" string="for" />
            <token id="19" string="the" />
            <token id="20" string="Federation" />
            <token id="21" string="for" />
            <token id="22" string="American" />
            <token id="23" string="Immigration" />
            <token id="24" string="Reform" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="3">aliens</governor>
          <dependent id="2">Illegal</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">taking</governor>
          <dependent id="3">aliens</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">taking</governor>
          <dependent id="4">are</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">taking</governor>
          <dependent id="5">actually</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="13">says</governor>
          <dependent id="6">taking</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">taking</governor>
          <dependent id="7">representation</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">taking</governor>
          <dependent id="8">away</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">Americans</governor>
          <dependent id="9">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">taking</governor>
          <dependent id="10">Americans</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">says</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Ray</governor>
          <dependent id="14">David</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">says</governor>
          <dependent id="15">Ray</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="15">Ray</governor>
          <dependent id="17">spokesman</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">Federation</governor>
          <dependent id="18">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">Federation</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">spokesman</governor>
          <dependent id="20">Federation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">Reform</governor>
          <dependent id="21">for</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">Reform</governor>
          <dependent id="22">American</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">Reform</governor>
          <dependent id="23">Immigration</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">Federation</governor>
          <dependent id="24">Reform</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="David Ray" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="David" />
            <token id="15" string="Ray" />
          </tokens>
        </entity>
        <entity id="2" string="Americans" type="MISC" score="0.0">
          <tokens>
            <token id="10" string="Americans" />
          </tokens>
        </entity>
        <entity id="3" string="Federation for American Immigration Reform" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="20" string="Federation" />
            <token id="21" string="for" />
            <token id="22" string="American" />
            <token id="23" string="Immigration" />
            <token id="24" string="Reform" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>The Census Bureau, based on comparisons of its data with figures kept by the Immigration and Naturalization Service, estimates that it counted about two million illegal immigrants in 1980, half of them in California.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="Census" lemma="Census" stem="censu" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="3" string="Bureau" lemma="Bureau" stem="bureau" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="based" lemma="base" stem="base" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="comparisons" lemma="comparison" stem="comparison" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="data" lemma="datum" stem="data" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="figures" lemma="figure" stem="figur" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="kept" lemma="keep" stem="kept" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="Immigration" lemma="Immigration" stem="immigrat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="17" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="18" string="Naturalization" lemma="Naturalization" stem="natur" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="19" string="Service" lemma="Service" stem="servic" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="estimates" lemma="estimate" stem="estim" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="counted" lemma="count" stem="count" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="27" string="million" lemma="million" stem="million" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="28" string="illegal" lemma="illegal" stem="illeg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="immigrants" lemma="immigrant" stem="immigr" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="1980" lemma="1980" stem="1980" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="32" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="half" lemma="half" stem="half" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="California" lemma="California" stem="california" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="38" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (NNP Census) (NNP Bureau)) (, ,) (VP (VBN based) (PP (IN on) (NP (NP (NNS comparisons)) (PP (IN of) (NP (PRP$ its) (NNS data))))) (PP (IN with) (NP (NP (NNS figures)) (VP (VBN kept) (PP (IN by) (NP (DT the) (NNP Immigration) (CC and) (NNP Naturalization) (NNP Service))))))) (, ,)) (VP (VBZ estimates) (SBAR (IN that) (S (NP (PRP it)) (VP (VBD counted) (PP (IN about) (NP (NP (NP (QP (CD two) (CD million)) (JJ illegal) (NNS immigrants)) (PP (IN in) (NP (CD 1980)))) (, ,) (NP (NP (NN half)) (PP (IN of) (NP (PRP them)))))) (PP (IN in) (NP (NNP California))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="kept by the Immigration and Naturalization Service" type="VP">
          <tokens>
            <token id="13" string="kept" />
            <token id="14" string="by" />
            <token id="15" string="the" />
            <token id="16" string="Immigration" />
            <token id="17" string="and" />
            <token id="18" string="Naturalization" />
            <token id="19" string="Service" />
          </tokens>
        </chunking>
        <chunking id="2" string="that it counted about two million illegal immigrants in 1980 , half of them in California" type="SBAR">
          <tokens>
            <token id="22" string="that" />
            <token id="23" string="it" />
            <token id="24" string="counted" />
            <token id="25" string="about" />
            <token id="26" string="two" />
            <token id="27" string="million" />
            <token id="28" string="illegal" />
            <token id="29" string="immigrants" />
            <token id="30" string="in" />
            <token id="31" string="1980" />
            <token id="32" string="," />
            <token id="33" string="half" />
            <token id="34" string="of" />
            <token id="35" string="them" />
            <token id="36" string="in" />
            <token id="37" string="California" />
          </tokens>
        </chunking>
        <chunking id="3" string="The Census Bureau" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Census" />
            <token id="3" string="Bureau" />
          </tokens>
        </chunking>
        <chunking id="4" string="half" type="NP">
          <tokens>
            <token id="33" string="half" />
          </tokens>
        </chunking>
        <chunking id="5" string="figures" type="NP">
          <tokens>
            <token id="12" string="figures" />
          </tokens>
        </chunking>
        <chunking id="6" string="half of them" type="NP">
          <tokens>
            <token id="33" string="half" />
            <token id="34" string="of" />
            <token id="35" string="them" />
          </tokens>
        </chunking>
        <chunking id="7" string="California" type="NP">
          <tokens>
            <token id="37" string="California" />
          </tokens>
        </chunking>
        <chunking id="8" string="figures kept by the Immigration and Naturalization Service" type="NP">
          <tokens>
            <token id="12" string="figures" />
            <token id="13" string="kept" />
            <token id="14" string="by" />
            <token id="15" string="the" />
            <token id="16" string="Immigration" />
            <token id="17" string="and" />
            <token id="18" string="Naturalization" />
            <token id="19" string="Service" />
          </tokens>
        </chunking>
        <chunking id="9" string="two million illegal immigrants in 1980 , half of them" type="NP">
          <tokens>
            <token id="26" string="two" />
            <token id="27" string="million" />
            <token id="28" string="illegal" />
            <token id="29" string="immigrants" />
            <token id="30" string="in" />
            <token id="31" string="1980" />
            <token id="32" string="," />
            <token id="33" string="half" />
            <token id="34" string="of" />
            <token id="35" string="them" />
          </tokens>
        </chunking>
        <chunking id="10" string="based on comparisons of its data with figures kept by the Immigration and Naturalization Service" type="VP">
          <tokens>
            <token id="5" string="based" />
            <token id="6" string="on" />
            <token id="7" string="comparisons" />
            <token id="8" string="of" />
            <token id="9" string="its" />
            <token id="10" string="data" />
            <token id="11" string="with" />
            <token id="12" string="figures" />
            <token id="13" string="kept" />
            <token id="14" string="by" />
            <token id="15" string="the" />
            <token id="16" string="Immigration" />
            <token id="17" string="and" />
            <token id="18" string="Naturalization" />
            <token id="19" string="Service" />
          </tokens>
        </chunking>
        <chunking id="11" string="two million illegal immigrants" type="NP">
          <tokens>
            <token id="26" string="two" />
            <token id="27" string="million" />
            <token id="28" string="illegal" />
            <token id="29" string="immigrants" />
          </tokens>
        </chunking>
        <chunking id="12" string="1980" type="NP">
          <tokens>
            <token id="31" string="1980" />
          </tokens>
        </chunking>
        <chunking id="13" string="it" type="NP">
          <tokens>
            <token id="23" string="it" />
          </tokens>
        </chunking>
        <chunking id="14" string="them" type="NP">
          <tokens>
            <token id="35" string="them" />
          </tokens>
        </chunking>
        <chunking id="15" string="counted about two million illegal immigrants in 1980 , half of them in California" type="VP">
          <tokens>
            <token id="24" string="counted" />
            <token id="25" string="about" />
            <token id="26" string="two" />
            <token id="27" string="million" />
            <token id="28" string="illegal" />
            <token id="29" string="immigrants" />
            <token id="30" string="in" />
            <token id="31" string="1980" />
            <token id="32" string="," />
            <token id="33" string="half" />
            <token id="34" string="of" />
            <token id="35" string="them" />
            <token id="36" string="in" />
            <token id="37" string="California" />
          </tokens>
        </chunking>
        <chunking id="16" string="The Census Bureau , based on comparisons of its data with figures kept by the Immigration and Naturalization Service ," type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Census" />
            <token id="3" string="Bureau" />
            <token id="4" string="," />
            <token id="5" string="based" />
            <token id="6" string="on" />
            <token id="7" string="comparisons" />
            <token id="8" string="of" />
            <token id="9" string="its" />
            <token id="10" string="data" />
            <token id="11" string="with" />
            <token id="12" string="figures" />
            <token id="13" string="kept" />
            <token id="14" string="by" />
            <token id="15" string="the" />
            <token id="16" string="Immigration" />
            <token id="17" string="and" />
            <token id="18" string="Naturalization" />
            <token id="19" string="Service" />
            <token id="20" string="," />
          </tokens>
        </chunking>
        <chunking id="17" string="the Immigration and Naturalization Service" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="Immigration" />
            <token id="17" string="and" />
            <token id="18" string="Naturalization" />
            <token id="19" string="Service" />
          </tokens>
        </chunking>
        <chunking id="18" string="two million illegal immigrants in 1980" type="NP">
          <tokens>
            <token id="26" string="two" />
            <token id="27" string="million" />
            <token id="28" string="illegal" />
            <token id="29" string="immigrants" />
            <token id="30" string="in" />
            <token id="31" string="1980" />
          </tokens>
        </chunking>
        <chunking id="19" string="estimates that it counted about two million illegal immigrants in 1980 , half of them in California" type="VP">
          <tokens>
            <token id="21" string="estimates" />
            <token id="22" string="that" />
            <token id="23" string="it" />
            <token id="24" string="counted" />
            <token id="25" string="about" />
            <token id="26" string="two" />
            <token id="27" string="million" />
            <token id="28" string="illegal" />
            <token id="29" string="immigrants" />
            <token id="30" string="in" />
            <token id="31" string="1980" />
            <token id="32" string="," />
            <token id="33" string="half" />
            <token id="34" string="of" />
            <token id="35" string="them" />
            <token id="36" string="in" />
            <token id="37" string="California" />
          </tokens>
        </chunking>
        <chunking id="20" string="comparisons" type="NP">
          <tokens>
            <token id="7" string="comparisons" />
          </tokens>
        </chunking>
        <chunking id="21" string="its data" type="NP">
          <tokens>
            <token id="9" string="its" />
            <token id="10" string="data" />
          </tokens>
        </chunking>
        <chunking id="22" string="comparisons of its data" type="NP">
          <tokens>
            <token id="7" string="comparisons" />
            <token id="8" string="of" />
            <token id="9" string="its" />
            <token id="10" string="data" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">Bureau</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Bureau</governor>
          <dependent id="2">Census</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">estimates</governor>
          <dependent id="3">Bureau</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="3">Bureau</governor>
          <dependent id="5">based</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">comparisons</governor>
          <dependent id="6">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">based</governor>
          <dependent id="7">comparisons</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">data</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="10">data</governor>
          <dependent id="9">its</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">comparisons</governor>
          <dependent id="10">data</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">figures</governor>
          <dependent id="11">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">based</governor>
          <dependent id="12">figures</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="12">figures</governor>
          <dependent id="13">kept</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">Service</governor>
          <dependent id="14">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">Service</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">Service</governor>
          <dependent id="16">Immigration</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="16">Immigration</governor>
          <dependent id="17">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">Immigration</governor>
          <dependent id="18">Naturalization</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">kept</governor>
          <dependent id="19">Service</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="21">estimates</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="24">counted</governor>
          <dependent id="22">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">counted</governor>
          <dependent id="23">it</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="21">estimates</governor>
          <dependent id="24">counted</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">immigrants</governor>
          <dependent id="25">about</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">million</governor>
          <dependent id="26">two</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="29">immigrants</governor>
          <dependent id="27">million</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="29">immigrants</governor>
          <dependent id="28">illegal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">counted</governor>
          <dependent id="29">immigrants</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">1980</governor>
          <dependent id="30">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">immigrants</governor>
          <dependent id="31">1980</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="29">immigrants</governor>
          <dependent id="33">half</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">them</governor>
          <dependent id="34">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="33">half</governor>
          <dependent id="35">them</dependent>
        </dependency>
        <dependency type="case">
          <governor id="37">California</governor>
          <dependent id="36">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">counted</governor>
          <dependent id="37">California</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Immigration and Naturalization Service" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="16" string="Immigration" />
            <token id="17" string="and" />
            <token id="18" string="Naturalization" />
            <token id="19" string="Service" />
          </tokens>
        </entity>
        <entity id="2" string="California" type="LOCATION" score="0.0">
          <tokens>
            <token id="37" string="California" />
          </tokens>
        </entity>
        <entity id="3" string="two million" type="NUMBER" score="0.0">
          <tokens>
            <token id="26" string="two" />
            <token id="27" string="million" />
          </tokens>
        </entity>
        <entity id="4" string="1980" type="DATE" score="0.0">
          <tokens>
            <token id="31" string="1980" />
          </tokens>
        </entity>
        <entity id="5" string="Census Bureau" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="2" string="Census" />
            <token id="3" string="Bureau" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>That meant one extra seat in the House for California and New York and one less seat for Indiana and Georgia.</content>
      <tokens>
        <token id="1" string="That" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="meant" lemma="mean" stem="meant" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="4" string="extra" lemma="extra" stem="extra" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="seat" lemma="seat" stem="seat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="House" lemma="House" stem="hous" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="9" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="California" lemma="California" stem="california" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="New" lemma="New" stem="new" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="13" string="York" lemma="York" stem="york" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="16" string="less" lemma="less" stem="less" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="seat" lemma="seat" stem="seat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="Indiana" lemma="Indiana" stem="indiana" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="20" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="Georgia" lemma="Georgia" stem="georgia" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT That)) (VP (VBD meant) (NP (CD one) (JJ extra) (NN seat)) (PP (IN in) (NP (DT the) (NNP House))) (PP (IN for) (NP (NP (NP (NNP California)) (CC and) (NP (NNP New) (NNP York))) (CC and) (NP (NP (CD one) (JJR less) (NN seat)) (PP (IN for) (NP (NNP Indiana) (CC and) (NNP Georgia))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="California and New York" type="NP">
          <tokens>
            <token id="10" string="California" />
            <token id="11" string="and" />
            <token id="12" string="New" />
            <token id="13" string="York" />
          </tokens>
        </chunking>
        <chunking id="2" string="New York" type="NP">
          <tokens>
            <token id="12" string="New" />
            <token id="13" string="York" />
          </tokens>
        </chunking>
        <chunking id="3" string="That" type="NP">
          <tokens>
            <token id="1" string="That" />
          </tokens>
        </chunking>
        <chunking id="4" string="one extra seat" type="NP">
          <tokens>
            <token id="3" string="one" />
            <token id="4" string="extra" />
            <token id="5" string="seat" />
          </tokens>
        </chunking>
        <chunking id="5" string="one less seat for Indiana and Georgia" type="NP">
          <tokens>
            <token id="15" string="one" />
            <token id="16" string="less" />
            <token id="17" string="seat" />
            <token id="18" string="for" />
            <token id="19" string="Indiana" />
            <token id="20" string="and" />
            <token id="21" string="Georgia" />
          </tokens>
        </chunking>
        <chunking id="6" string="California" type="NP">
          <tokens>
            <token id="10" string="California" />
          </tokens>
        </chunking>
        <chunking id="7" string="one less seat" type="NP">
          <tokens>
            <token id="15" string="one" />
            <token id="16" string="less" />
            <token id="17" string="seat" />
          </tokens>
        </chunking>
        <chunking id="8" string="Indiana and Georgia" type="NP">
          <tokens>
            <token id="19" string="Indiana" />
            <token id="20" string="and" />
            <token id="21" string="Georgia" />
          </tokens>
        </chunking>
        <chunking id="9" string="meant one extra seat in the House for California and New York and one less seat for Indiana and Georgia" type="VP">
          <tokens>
            <token id="2" string="meant" />
            <token id="3" string="one" />
            <token id="4" string="extra" />
            <token id="5" string="seat" />
            <token id="6" string="in" />
            <token id="7" string="the" />
            <token id="8" string="House" />
            <token id="9" string="for" />
            <token id="10" string="California" />
            <token id="11" string="and" />
            <token id="12" string="New" />
            <token id="13" string="York" />
            <token id="14" string="and" />
            <token id="15" string="one" />
            <token id="16" string="less" />
            <token id="17" string="seat" />
            <token id="18" string="for" />
            <token id="19" string="Indiana" />
            <token id="20" string="and" />
            <token id="21" string="Georgia" />
          </tokens>
        </chunking>
        <chunking id="10" string="the House" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="House" />
          </tokens>
        </chunking>
        <chunking id="11" string="California and New York and one less seat for Indiana and Georgia" type="NP">
          <tokens>
            <token id="10" string="California" />
            <token id="11" string="and" />
            <token id="12" string="New" />
            <token id="13" string="York" />
            <token id="14" string="and" />
            <token id="15" string="one" />
            <token id="16" string="less" />
            <token id="17" string="seat" />
            <token id="18" string="for" />
            <token id="19" string="Indiana" />
            <token id="20" string="and" />
            <token id="21" string="Georgia" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">meant</governor>
          <dependent id="1">That</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">meant</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="5">seat</governor>
          <dependent id="3">one</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">seat</governor>
          <dependent id="4">extra</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">meant</governor>
          <dependent id="5">seat</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">House</governor>
          <dependent id="6">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">House</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">meant</governor>
          <dependent id="8">House</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">California</governor>
          <dependent id="9">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">meant</governor>
          <dependent id="10">California</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">California</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">York</governor>
          <dependent id="12">New</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">California</governor>
          <dependent id="13">York</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">California</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="17">seat</governor>
          <dependent id="15">one</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">seat</governor>
          <dependent id="16">less</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">California</governor>
          <dependent id="17">seat</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">Indiana</governor>
          <dependent id="18">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">seat</governor>
          <dependent id="19">Indiana</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="19">Indiana</governor>
          <dependent id="20">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="19">Indiana</governor>
          <dependent id="21">Georgia</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="New York" type="LOCATION" score="0.0">
          <tokens>
            <token id="12" string="New" />
            <token id="13" string="York" />
          </tokens>
        </entity>
        <entity id="2" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="3" string="one" />
          </tokens>
        </entity>
        <entity id="3" string="California" type="LOCATION" score="0.0">
          <tokens>
            <token id="10" string="California" />
          </tokens>
        </entity>
        <entity id="4" string="House" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="8" string="House" />
          </tokens>
        </entity>
        <entity id="5" string="Indiana" type="LOCATION" score="0.0">
          <tokens>
            <token id="19" string="Indiana" />
          </tokens>
        </entity>
        <entity id="6" string="Georgia" type="LOCATION" score="0.0">
          <tokens>
            <token id="21" string="Georgia" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>&amp;quot;You end up diluting the vote when you start including illegals,&amp;quot; says Rep. Thomas Ridge (R., Pa.), who leads the charge against the practice in the House.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="You" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="end" lemma="end" stem="end" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="diluting" lemma="dilute" stem="dilut" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="vote" lemma="vote" stem="vote" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="start" lemma="start" stem="start" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="including" lemma="include" stem="includ" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="illegals" lemma="illegal" stem="illeg" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="Rep." lemma="Rep." stem="rep." pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="18" string="Ridge" lemma="Ridge" stem="ridg" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="19" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="R." lemma="R." stem="r." pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="Pa." lemma="Pa." stem="pa." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="true" />
        <token id="23" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="25" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="26" string="leads" lemma="lead" stem="lead" pos="VBZ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="27" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="28" string="charge" lemma="charge" stem="charg" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="29" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="30" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="31" string="practice" lemma="practice" stem="practic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="32" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="33" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="34" string="House" lemma="House" stem="hous" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="35" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (NP (PRP You)) (VP (VBP end) (PRT (RP up)) (S (VP (VBG diluting) (NP (NP (DT the) (NN vote)) (SBAR (WHADVP (WRB when)) (S (NP (PRP you)) (VP (VBP start) (PP (VBG including) (NP (NNS illegals))))))))))) (, ,) ('' '') (VP (VBZ says)) (NP (NP (NNP Rep.) (NNP Thomas) (NNP Ridge)) (PRN (-LRB- -LRB-) (NP (NNP R.)) (, ,) (NP (NNP Pa.)) (-RRB- -RRB-)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBZ leads) (NP (NP (DT the) (NN charge)) (PP (IN against) (NP (NP (DT the) (NN practice)) (PP (IN in) (NP (DT the) (NNP House)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="diluting the vote when you start including illegals" type="VP">
          <tokens>
            <token id="5" string="diluting" />
            <token id="6" string="the" />
            <token id="7" string="vote" />
            <token id="8" string="when" />
            <token id="9" string="you" />
            <token id="10" string="start" />
            <token id="11" string="including" />
            <token id="12" string="illegals" />
          </tokens>
        </chunking>
        <chunking id="2" string="the practice" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="practice" />
          </tokens>
        </chunking>
        <chunking id="3" string="start including illegals" type="VP">
          <tokens>
            <token id="10" string="start" />
            <token id="11" string="including" />
            <token id="12" string="illegals" />
          </tokens>
        </chunking>
        <chunking id="4" string="leads the charge against the practice in the House" type="VP">
          <tokens>
            <token id="26" string="leads" />
            <token id="27" string="the" />
            <token id="28" string="charge" />
            <token id="29" string="against" />
            <token id="30" string="the" />
            <token id="31" string="practice" />
            <token id="32" string="in" />
            <token id="33" string="the" />
            <token id="34" string="House" />
          </tokens>
        </chunking>
        <chunking id="5" string="the House" type="NP">
          <tokens>
            <token id="33" string="the" />
            <token id="34" string="House" />
          </tokens>
        </chunking>
        <chunking id="6" string="end up diluting the vote when you start including illegals" type="VP">
          <tokens>
            <token id="3" string="end" />
            <token id="4" string="up" />
            <token id="5" string="diluting" />
            <token id="6" string="the" />
            <token id="7" string="vote" />
            <token id="8" string="when" />
            <token id="9" string="you" />
            <token id="10" string="start" />
            <token id="11" string="including" />
            <token id="12" string="illegals" />
          </tokens>
        </chunking>
        <chunking id="7" string="Rep. Thomas Ridge -LRB- R. , Pa. -RRB- , who leads the charge against the practice in the House" type="NP">
          <tokens>
            <token id="16" string="Rep." />
            <token id="17" string="Thomas" />
            <token id="18" string="Ridge" />
            <token id="19" string="(" />
            <token id="20" string="R." />
            <token id="21" string="," />
            <token id="22" string="Pa." />
            <token id="23" string=")" />
            <token id="24" string="," />
            <token id="25" string="who" />
            <token id="26" string="leads" />
            <token id="27" string="the" />
            <token id="28" string="charge" />
            <token id="29" string="against" />
            <token id="30" string="the" />
            <token id="31" string="practice" />
            <token id="32" string="in" />
            <token id="33" string="the" />
            <token id="34" string="House" />
          </tokens>
        </chunking>
        <chunking id="8" string="the charge" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="charge" />
          </tokens>
        </chunking>
        <chunking id="9" string="when" type="WHADVP">
          <tokens>
            <token id="8" string="when" />
          </tokens>
        </chunking>
        <chunking id="10" string="says" type="VP">
          <tokens>
            <token id="15" string="says" />
          </tokens>
        </chunking>
        <chunking id="11" string="who leads the charge against the practice in the House" type="SBAR">
          <tokens>
            <token id="25" string="who" />
            <token id="26" string="leads" />
            <token id="27" string="the" />
            <token id="28" string="charge" />
            <token id="29" string="against" />
            <token id="30" string="the" />
            <token id="31" string="practice" />
            <token id="32" string="in" />
            <token id="33" string="the" />
            <token id="34" string="House" />
          </tokens>
        </chunking>
        <chunking id="12" string="the vote when you start including illegals" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="vote" />
            <token id="8" string="when" />
            <token id="9" string="you" />
            <token id="10" string="start" />
            <token id="11" string="including" />
            <token id="12" string="illegals" />
          </tokens>
        </chunking>
        <chunking id="13" string="when you start including illegals" type="SBAR">
          <tokens>
            <token id="8" string="when" />
            <token id="9" string="you" />
            <token id="10" string="start" />
            <token id="11" string="including" />
            <token id="12" string="illegals" />
          </tokens>
        </chunking>
        <chunking id="14" string="Rep. Thomas Ridge" type="NP">
          <tokens>
            <token id="16" string="Rep." />
            <token id="17" string="Thomas" />
            <token id="18" string="Ridge" />
          </tokens>
        </chunking>
        <chunking id="15" string="the charge against the practice in the House" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="charge" />
            <token id="29" string="against" />
            <token id="30" string="the" />
            <token id="31" string="practice" />
            <token id="32" string="in" />
            <token id="33" string="the" />
            <token id="34" string="House" />
          </tokens>
        </chunking>
        <chunking id="16" string="the practice in the House" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="practice" />
            <token id="32" string="in" />
            <token id="33" string="the" />
            <token id="34" string="House" />
          </tokens>
        </chunking>
        <chunking id="17" string="illegals" type="NP">
          <tokens>
            <token id="12" string="illegals" />
          </tokens>
        </chunking>
        <chunking id="18" string="R." type="NP">
          <tokens>
            <token id="20" string="R." />
          </tokens>
        </chunking>
        <chunking id="19" string="the vote" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="vote" />
          </tokens>
        </chunking>
        <chunking id="20" string="Pa." type="NP">
          <tokens>
            <token id="22" string="Pa." />
          </tokens>
        </chunking>
        <chunking id="21" string="You" type="NP">
          <tokens>
            <token id="2" string="You" />
          </tokens>
        </chunking>
        <chunking id="22" string="you" type="NP">
          <tokens>
            <token id="9" string="you" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">end</governor>
          <dependent id="2">You</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="15">says</governor>
          <dependent id="3">end</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="3">end</governor>
          <dependent id="4">up</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">end</governor>
          <dependent id="5">diluting</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">vote</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">diluting</governor>
          <dependent id="7">vote</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">start</governor>
          <dependent id="8">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">start</governor>
          <dependent id="9">you</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="7">vote</governor>
          <dependent id="10">start</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">illegals</governor>
          <dependent id="11">including</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">start</governor>
          <dependent id="12">illegals</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">says</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Ridge</governor>
          <dependent id="16">Rep.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Ridge</governor>
          <dependent id="17">Thomas</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">says</governor>
          <dependent id="18">Ridge</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="18">Ridge</governor>
          <dependent id="20">R.</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="20">R.</governor>
          <dependent id="22">Pa.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">leads</governor>
          <dependent id="25">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="18">Ridge</governor>
          <dependent id="26">leads</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">charge</governor>
          <dependent id="27">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="26">leads</governor>
          <dependent id="28">charge</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">practice</governor>
          <dependent id="29">against</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">practice</governor>
          <dependent id="30">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">charge</governor>
          <dependent id="31">practice</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">House</governor>
          <dependent id="32">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="34">House</governor>
          <dependent id="33">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">practice</governor>
          <dependent id="34">House</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Thomas Ridge" type="PERSON" score="0.0">
          <tokens>
            <token id="17" string="Thomas" />
            <token id="18" string="Ridge" />
          </tokens>
        </entity>
        <entity id="2" string="House" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="34" string="House" />
          </tokens>
        </entity>
        <entity id="3" string="Pa." type="LOCATION" score="0.0">
          <tokens>
            <token id="22" string="Pa." />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="17" has_coreference="false">
      <content>Organizations that represent Hispanics are particularly worried about the congressional campaign.</content>
      <tokens>
        <token id="1" string="Organizations" lemma="Organizations" stem="organiz" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="represent" lemma="represent" stem="repres" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="Hispanics" lemma="Hispanics" stem="hispan" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="5" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="particularly" lemma="particularly" stem="particularli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="worried" lemma="worry" stem="worri" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="congressional" lemma="congressional" stem="congression" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="campaign" lemma="campaign" stem="campaign" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Organizations)) (SBAR (WHNP (WDT that)) (S (VP (VBP represent) (NP (NNPS Hispanics)))))) (VP (VBP are) (ADJP (RB particularly) (VBN worried) (PP (IN about) (NP (DT the) (JJ congressional) (NN campaign))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="that represent Hispanics" type="SBAR">
          <tokens>
            <token id="2" string="that" />
            <token id="3" string="represent" />
            <token id="4" string="Hispanics" />
          </tokens>
        </chunking>
        <chunking id="2" string="are particularly worried about the congressional campaign" type="VP">
          <tokens>
            <token id="5" string="are" />
            <token id="6" string="particularly" />
            <token id="7" string="worried" />
            <token id="8" string="about" />
            <token id="9" string="the" />
            <token id="10" string="congressional" />
            <token id="11" string="campaign" />
          </tokens>
        </chunking>
        <chunking id="3" string="the congressional campaign" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="congressional" />
            <token id="11" string="campaign" />
          </tokens>
        </chunking>
        <chunking id="4" string="Organizations" type="NP">
          <tokens>
            <token id="1" string="Organizations" />
          </tokens>
        </chunking>
        <chunking id="5" string="represent Hispanics" type="VP">
          <tokens>
            <token id="3" string="represent" />
            <token id="4" string="Hispanics" />
          </tokens>
        </chunking>
        <chunking id="6" string="Organizations that represent Hispanics" type="NP">
          <tokens>
            <token id="1" string="Organizations" />
            <token id="2" string="that" />
            <token id="3" string="represent" />
            <token id="4" string="Hispanics" />
          </tokens>
        </chunking>
        <chunking id="7" string="Hispanics" type="NP">
          <tokens>
            <token id="4" string="Hispanics" />
          </tokens>
        </chunking>
        <chunking id="8" string="particularly worried about the congressional campaign" type="ADJP">
          <tokens>
            <token id="6" string="particularly" />
            <token id="7" string="worried" />
            <token id="8" string="about" />
            <token id="9" string="the" />
            <token id="10" string="congressional" />
            <token id="11" string="campaign" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="7">worried</governor>
          <dependent id="1">Organizations</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">represent</governor>
          <dependent id="2">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="1">Organizations</governor>
          <dependent id="3">represent</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">represent</governor>
          <dependent id="4">Hispanics</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="7">worried</governor>
          <dependent id="5">are</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">worried</governor>
          <dependent id="6">particularly</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">worried</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">campaign</governor>
          <dependent id="8">about</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">campaign</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">campaign</governor>
          <dependent id="10">congressional</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">worried</governor>
          <dependent id="11">campaign</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Hispanics" type="MISC" score="0.0">
          <tokens>
            <token id="4" string="Hispanics" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="18" has_coreference="true">
      <content>They fear that any attempt to ascertain the legal status of respondents will exacerbate difficulties the Census Bureau already faces in accurately counting Hispanics and blacks.</content>
      <tokens>
        <token id="1" string="They" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="fear" lemma="fear" stem="fear" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="any" lemma="any" stem="ani" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="attempt" lemma="attempt" stem="attempt" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="ascertain" lemma="ascertain" stem="ascertain" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="legal" lemma="legal" stem="legal" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="status" lemma="status" stem="statu" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="respondents" lemma="respondent" stem="respond" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="exacerbate" lemma="exacerbate" stem="exacerb" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="difficulties" lemma="difficulty" stem="difficulti" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Census" lemma="Census" stem="censu" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="18" string="Bureau" lemma="Bureau" stem="bureau" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="19" string="already" lemma="already" stem="alreadi" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="faces" lemma="face" stem="face" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="accurately" lemma="accurately" stem="accur" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="counting" lemma="count" stem="count" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="Hispanics" lemma="Hispanics" stem="hispan" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="25" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="blacks" lemma="black" stem="black" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP They)) (VP (VBP fear) (SBAR (IN that) (S (NP (DT any) (NN attempt) (S (VP (TO to) (VP (VB ascertain) (NP (NP (DT the) (JJ legal) (NN status)) (PP (IN of) (NP (NNS respondents)))))))) (VP (MD will) (VP (VB exacerbate) (NP (NP (NNS difficulties)) (SBAR (S (NP (DT the) (NNP Census) (NNP Bureau)) (ADVP (RB already)) (VP (VBZ faces) (PP (IN in) (S (ADVP (RB accurately)) (VP (VBG counting) (NP (NP (NNPS Hispanics)) (CC and) (NP (NNS blacks))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="They" type="NP">
          <tokens>
            <token id="1" string="They" />
          </tokens>
        </chunking>
        <chunking id="2" string="the Census Bureau already faces in accurately counting Hispanics and blacks" type="SBAR">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="Census" />
            <token id="18" string="Bureau" />
            <token id="19" string="already" />
            <token id="20" string="faces" />
            <token id="21" string="in" />
            <token id="22" string="accurately" />
            <token id="23" string="counting" />
            <token id="24" string="Hispanics" />
            <token id="25" string="and" />
            <token id="26" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="3" string="fear that any attempt to ascertain the legal status of respondents will exacerbate difficulties the Census Bureau already faces in accurately counting Hispanics and blacks" type="VP">
          <tokens>
            <token id="2" string="fear" />
            <token id="3" string="that" />
            <token id="4" string="any" />
            <token id="5" string="attempt" />
            <token id="6" string="to" />
            <token id="7" string="ascertain" />
            <token id="8" string="the" />
            <token id="9" string="legal" />
            <token id="10" string="status" />
            <token id="11" string="of" />
            <token id="12" string="respondents" />
            <token id="13" string="will" />
            <token id="14" string="exacerbate" />
            <token id="15" string="difficulties" />
            <token id="16" string="the" />
            <token id="17" string="Census" />
            <token id="18" string="Bureau" />
            <token id="19" string="already" />
            <token id="20" string="faces" />
            <token id="21" string="in" />
            <token id="22" string="accurately" />
            <token id="23" string="counting" />
            <token id="24" string="Hispanics" />
            <token id="25" string="and" />
            <token id="26" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="4" string="any attempt to ascertain the legal status of respondents" type="NP">
          <tokens>
            <token id="4" string="any" />
            <token id="5" string="attempt" />
            <token id="6" string="to" />
            <token id="7" string="ascertain" />
            <token id="8" string="the" />
            <token id="9" string="legal" />
            <token id="10" string="status" />
            <token id="11" string="of" />
            <token id="12" string="respondents" />
          </tokens>
        </chunking>
        <chunking id="5" string="counting Hispanics and blacks" type="VP">
          <tokens>
            <token id="23" string="counting" />
            <token id="24" string="Hispanics" />
            <token id="25" string="and" />
            <token id="26" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="6" string="the Census Bureau" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="Census" />
            <token id="18" string="Bureau" />
          </tokens>
        </chunking>
        <chunking id="7" string="to ascertain the legal status of respondents" type="VP">
          <tokens>
            <token id="6" string="to" />
            <token id="7" string="ascertain" />
            <token id="8" string="the" />
            <token id="9" string="legal" />
            <token id="10" string="status" />
            <token id="11" string="of" />
            <token id="12" string="respondents" />
          </tokens>
        </chunking>
        <chunking id="8" string="the legal status of respondents" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="legal" />
            <token id="10" string="status" />
            <token id="11" string="of" />
            <token id="12" string="respondents" />
          </tokens>
        </chunking>
        <chunking id="9" string="Hispanics and blacks" type="NP">
          <tokens>
            <token id="24" string="Hispanics" />
            <token id="25" string="and" />
            <token id="26" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="10" string="blacks" type="NP">
          <tokens>
            <token id="26" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="11" string="respondents" type="NP">
          <tokens>
            <token id="12" string="respondents" />
          </tokens>
        </chunking>
        <chunking id="12" string="will exacerbate difficulties the Census Bureau already faces in accurately counting Hispanics and blacks" type="VP">
          <tokens>
            <token id="13" string="will" />
            <token id="14" string="exacerbate" />
            <token id="15" string="difficulties" />
            <token id="16" string="the" />
            <token id="17" string="Census" />
            <token id="18" string="Bureau" />
            <token id="19" string="already" />
            <token id="20" string="faces" />
            <token id="21" string="in" />
            <token id="22" string="accurately" />
            <token id="23" string="counting" />
            <token id="24" string="Hispanics" />
            <token id="25" string="and" />
            <token id="26" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="13" string="faces in accurately counting Hispanics and blacks" type="VP">
          <tokens>
            <token id="20" string="faces" />
            <token id="21" string="in" />
            <token id="22" string="accurately" />
            <token id="23" string="counting" />
            <token id="24" string="Hispanics" />
            <token id="25" string="and" />
            <token id="26" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="14" string="difficulties" type="NP">
          <tokens>
            <token id="15" string="difficulties" />
          </tokens>
        </chunking>
        <chunking id="15" string="exacerbate difficulties the Census Bureau already faces in accurately counting Hispanics and blacks" type="VP">
          <tokens>
            <token id="14" string="exacerbate" />
            <token id="15" string="difficulties" />
            <token id="16" string="the" />
            <token id="17" string="Census" />
            <token id="18" string="Bureau" />
            <token id="19" string="already" />
            <token id="20" string="faces" />
            <token id="21" string="in" />
            <token id="22" string="accurately" />
            <token id="23" string="counting" />
            <token id="24" string="Hispanics" />
            <token id="25" string="and" />
            <token id="26" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="16" string="ascertain the legal status of respondents" type="VP">
          <tokens>
            <token id="7" string="ascertain" />
            <token id="8" string="the" />
            <token id="9" string="legal" />
            <token id="10" string="status" />
            <token id="11" string="of" />
            <token id="12" string="respondents" />
          </tokens>
        </chunking>
        <chunking id="17" string="difficulties the Census Bureau already faces in accurately counting Hispanics and blacks" type="NP">
          <tokens>
            <token id="15" string="difficulties" />
            <token id="16" string="the" />
            <token id="17" string="Census" />
            <token id="18" string="Bureau" />
            <token id="19" string="already" />
            <token id="20" string="faces" />
            <token id="21" string="in" />
            <token id="22" string="accurately" />
            <token id="23" string="counting" />
            <token id="24" string="Hispanics" />
            <token id="25" string="and" />
            <token id="26" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="18" string="Hispanics" type="NP">
          <tokens>
            <token id="24" string="Hispanics" />
          </tokens>
        </chunking>
        <chunking id="19" string="that any attempt to ascertain the legal status of respondents will exacerbate difficulties the Census Bureau already faces in accurately counting Hispanics and blacks" type="SBAR">
          <tokens>
            <token id="3" string="that" />
            <token id="4" string="any" />
            <token id="5" string="attempt" />
            <token id="6" string="to" />
            <token id="7" string="ascertain" />
            <token id="8" string="the" />
            <token id="9" string="legal" />
            <token id="10" string="status" />
            <token id="11" string="of" />
            <token id="12" string="respondents" />
            <token id="13" string="will" />
            <token id="14" string="exacerbate" />
            <token id="15" string="difficulties" />
            <token id="16" string="the" />
            <token id="17" string="Census" />
            <token id="18" string="Bureau" />
            <token id="19" string="already" />
            <token id="20" string="faces" />
            <token id="21" string="in" />
            <token id="22" string="accurately" />
            <token id="23" string="counting" />
            <token id="24" string="Hispanics" />
            <token id="25" string="and" />
            <token id="26" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="20" string="the legal status" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="legal" />
            <token id="10" string="status" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">fear</governor>
          <dependent id="1">They</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">fear</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">exacerbate</governor>
          <dependent id="3">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">attempt</governor>
          <dependent id="4">any</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">exacerbate</governor>
          <dependent id="5">attempt</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">ascertain</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="5">attempt</governor>
          <dependent id="7">ascertain</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">status</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">status</governor>
          <dependent id="9">legal</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">ascertain</governor>
          <dependent id="10">status</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">respondents</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">status</governor>
          <dependent id="12">respondents</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="14">exacerbate</governor>
          <dependent id="13">will</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">fear</governor>
          <dependent id="14">exacerbate</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">exacerbate</governor>
          <dependent id="15">difficulties</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">Bureau</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Bureau</governor>
          <dependent id="17">Census</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">faces</governor>
          <dependent id="18">Bureau</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="20">faces</governor>
          <dependent id="19">already</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="15">difficulties</governor>
          <dependent id="20">faces</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="23">counting</governor>
          <dependent id="21">in</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="23">counting</governor>
          <dependent id="22">accurately</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="20">faces</governor>
          <dependent id="23">counting</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="23">counting</governor>
          <dependent id="24">Hispanics</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="24">Hispanics</governor>
          <dependent id="25">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="24">Hispanics</governor>
          <dependent id="26">blacks</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Census Bureau" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="17" string="Census" />
            <token id="18" string="Bureau" />
          </tokens>
        </entity>
        <entity id="2" string="Hispanics" type="MISC" score="0.0">
          <tokens>
            <token id="24" string="Hispanics" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="19" has_coreference="true">
      <content>&amp;quot;As it is, the Census Bureau has a tremendous challenge in trying to convince everybody that the census is confidential,&amp;quot; Mr. Vargas says.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="As" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Census" lemma="Census" stem="censu" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="8" string="Bureau" lemma="Bureau" stem="bureau" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="9" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="tremendous" lemma="tremendous" stem="tremend" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="challenge" lemma="challenge" stem="challeng" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="trying" lemma="try" stem="try" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="convince" lemma="convince" stem="convinc" pos="VB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="everybody" lemma="everybody" stem="everybodi" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="20" string="census" lemma="census" stem="censu" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="21" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="confidential" lemma="confidential" stem="confidenti" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="Mr." lemma="Mr." stem="mr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="26" string="Vargas" lemma="Vargas" stem="varga" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="27" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (SBAR (IN As) (S (NP (PRP it)) (VP (VBZ is)))) (, ,) (NP (DT the) (NNP Census) (NNP Bureau)) (VP (VBZ has) (NP (NP (DT a) (JJ tremendous) (NN challenge)) (PP (IN in) (S (VP (VBG trying) (S (VP (TO to) (VP (VB convince) (NP (NN everybody)) (SBAR (IN that) (S (NP (DT the) (NN census)) (VP (VBZ is) (ADJP (JJ confidential)))))))))))))) (, ,) ('' '') (NP (NNP Mr.) (NNP Vargas)) (VP (VBZ says)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="As it is" type="SBAR">
          <tokens>
            <token id="2" string="As" />
            <token id="3" string="it" />
            <token id="4" string="is" />
          </tokens>
        </chunking>
        <chunking id="2" string="everybody" type="NP">
          <tokens>
            <token id="17" string="everybody" />
          </tokens>
        </chunking>
        <chunking id="3" string="a tremendous challenge" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="tremendous" />
            <token id="12" string="challenge" />
          </tokens>
        </chunking>
        <chunking id="4" string="is confidential" type="VP">
          <tokens>
            <token id="21" string="is" />
            <token id="22" string="confidential" />
          </tokens>
        </chunking>
        <chunking id="5" string="the Census Bureau" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="Census" />
            <token id="8" string="Bureau" />
          </tokens>
        </chunking>
        <chunking id="6" string="trying to convince everybody that the census is confidential" type="VP">
          <tokens>
            <token id="14" string="trying" />
            <token id="15" string="to" />
            <token id="16" string="convince" />
            <token id="17" string="everybody" />
            <token id="18" string="that" />
            <token id="19" string="the" />
            <token id="20" string="census" />
            <token id="21" string="is" />
            <token id="22" string="confidential" />
          </tokens>
        </chunking>
        <chunking id="7" string="is" type="VP">
          <tokens>
            <token id="4" string="is" />
          </tokens>
        </chunking>
        <chunking id="8" string="it" type="NP">
          <tokens>
            <token id="3" string="it" />
          </tokens>
        </chunking>
        <chunking id="9" string="confidential" type="ADJP">
          <tokens>
            <token id="22" string="confidential" />
          </tokens>
        </chunking>
        <chunking id="10" string="Mr. Vargas" type="NP">
          <tokens>
            <token id="25" string="Mr." />
            <token id="26" string="Vargas" />
          </tokens>
        </chunking>
        <chunking id="11" string="says" type="VP">
          <tokens>
            <token id="27" string="says" />
          </tokens>
        </chunking>
        <chunking id="12" string="convince everybody that the census is confidential" type="VP">
          <tokens>
            <token id="16" string="convince" />
            <token id="17" string="everybody" />
            <token id="18" string="that" />
            <token id="19" string="the" />
            <token id="20" string="census" />
            <token id="21" string="is" />
            <token id="22" string="confidential" />
          </tokens>
        </chunking>
        <chunking id="13" string="that the census is confidential" type="SBAR">
          <tokens>
            <token id="18" string="that" />
            <token id="19" string="the" />
            <token id="20" string="census" />
            <token id="21" string="is" />
            <token id="22" string="confidential" />
          </tokens>
        </chunking>
        <chunking id="14" string="the census" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="census" />
          </tokens>
        </chunking>
        <chunking id="15" string="has a tremendous challenge in trying to convince everybody that the census is confidential" type="VP">
          <tokens>
            <token id="9" string="has" />
            <token id="10" string="a" />
            <token id="11" string="tremendous" />
            <token id="12" string="challenge" />
            <token id="13" string="in" />
            <token id="14" string="trying" />
            <token id="15" string="to" />
            <token id="16" string="convince" />
            <token id="17" string="everybody" />
            <token id="18" string="that" />
            <token id="19" string="the" />
            <token id="20" string="census" />
            <token id="21" string="is" />
            <token id="22" string="confidential" />
          </tokens>
        </chunking>
        <chunking id="16" string="a tremendous challenge in trying to convince everybody that the census is confidential" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="tremendous" />
            <token id="12" string="challenge" />
            <token id="13" string="in" />
            <token id="14" string="trying" />
            <token id="15" string="to" />
            <token id="16" string="convince" />
            <token id="17" string="everybody" />
            <token id="18" string="that" />
            <token id="19" string="the" />
            <token id="20" string="census" />
            <token id="21" string="is" />
            <token id="22" string="confidential" />
          </tokens>
        </chunking>
        <chunking id="17" string="to convince everybody that the census is confidential" type="VP">
          <tokens>
            <token id="15" string="to" />
            <token id="16" string="convince" />
            <token id="17" string="everybody" />
            <token id="18" string="that" />
            <token id="19" string="the" />
            <token id="20" string="census" />
            <token id="21" string="is" />
            <token id="22" string="confidential" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="4">is</governor>
          <dependent id="2">As</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">is</governor>
          <dependent id="3">it</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="9">has</governor>
          <dependent id="4">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">Bureau</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">Bureau</governor>
          <dependent id="7">Census</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">has</governor>
          <dependent id="8">Bureau</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="27">says</governor>
          <dependent id="9">has</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">challenge</governor>
          <dependent id="10">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">challenge</governor>
          <dependent id="11">tremendous</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">has</governor>
          <dependent id="12">challenge</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">trying</governor>
          <dependent id="13">in</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="12">challenge</governor>
          <dependent id="14">trying</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">convince</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="14">trying</governor>
          <dependent id="16">convince</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">convince</governor>
          <dependent id="17">everybody</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">confidential</governor>
          <dependent id="18">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">census</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">confidential</governor>
          <dependent id="20">census</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="22">confidential</governor>
          <dependent id="21">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="16">convince</governor>
          <dependent id="22">confidential</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">Vargas</governor>
          <dependent id="25">Mr.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">says</governor>
          <dependent id="26">Vargas</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="27">says</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Census Bureau" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="7" string="Census" />
            <token id="8" string="Bureau" />
          </tokens>
        </entity>
        <entity id="2" string="Vargas" type="PERSON" score="0.0">
          <tokens>
            <token id="26" string="Vargas" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="20" has_coreference="true">
      <content>&amp;quot;If the Census Bureau attempts to ask people their immigration status, that&amp;apost;s going to be even harder.&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="If" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Census" lemma="Census" stem="censu" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="5" string="Bureau" lemma="Bureau" stem="bureau" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="6" string="attempts" lemma="attempt" stem="attempt" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="ask" lemma="ask" stem="ask" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="immigration" lemma="immigration" stem="immigr" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="status" lemma="status" stem="statu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="going" lemma="go" stem="go" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="harder" lemma="harder" stem="harder" pos="RBR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (SBAR (IN If) (S (NP (DT the) (NNP Census) (NNP Bureau)) (VP (VBZ attempts) (S (VP (TO to) (VP (VB ask) (S (NP (NNS people)) (NP (PRP$ their) (NN immigration) (NN status))))))))) (, ,) (NP (DT that)) (VP (VBZ 's) (VP (VBG going) (S (VP (TO to) (VP (VB be) (ADVP (RB even) (RBR harder))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="that" type="NP">
          <tokens>
            <token id="14" string="that" />
          </tokens>
        </chunking>
        <chunking id="2" string="to ask people their immigration status" type="VP">
          <tokens>
            <token id="7" string="to" />
            <token id="8" string="ask" />
            <token id="9" string="people" />
            <token id="10" string="their" />
            <token id="11" string="immigration" />
            <token id="12" string="status" />
          </tokens>
        </chunking>
        <chunking id="3" string="ask people their immigration status" type="VP">
          <tokens>
            <token id="8" string="ask" />
            <token id="9" string="people" />
            <token id="10" string="their" />
            <token id="11" string="immigration" />
            <token id="12" string="status" />
          </tokens>
        </chunking>
        <chunking id="4" string="If the Census Bureau attempts to ask people their immigration status" type="SBAR">
          <tokens>
            <token id="2" string="If" />
            <token id="3" string="the" />
            <token id="4" string="Census" />
            <token id="5" string="Bureau" />
            <token id="6" string="attempts" />
            <token id="7" string="to" />
            <token id="8" string="ask" />
            <token id="9" string="people" />
            <token id="10" string="their" />
            <token id="11" string="immigration" />
            <token id="12" string="status" />
          </tokens>
        </chunking>
        <chunking id="5" string="the Census Bureau" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="Census" />
            <token id="5" string="Bureau" />
          </tokens>
        </chunking>
        <chunking id="6" string="to be even harder" type="VP">
          <tokens>
            <token id="17" string="to" />
            <token id="18" string="be" />
            <token id="19" string="even" />
            <token id="20" string="harder" />
          </tokens>
        </chunking>
        <chunking id="7" string="attempts to ask people their immigration status" type="VP">
          <tokens>
            <token id="6" string="attempts" />
            <token id="7" string="to" />
            <token id="8" string="ask" />
            <token id="9" string="people" />
            <token id="10" string="their" />
            <token id="11" string="immigration" />
            <token id="12" string="status" />
          </tokens>
        </chunking>
        <chunking id="8" string="going to be even harder" type="VP">
          <tokens>
            <token id="16" string="going" />
            <token id="17" string="to" />
            <token id="18" string="be" />
            <token id="19" string="even" />
            <token id="20" string="harder" />
          </tokens>
        </chunking>
        <chunking id="9" string="people" type="NP">
          <tokens>
            <token id="9" string="people" />
          </tokens>
        </chunking>
        <chunking id="10" string="their immigration status" type="NP">
          <tokens>
            <token id="10" string="their" />
            <token id="11" string="immigration" />
            <token id="12" string="status" />
          </tokens>
        </chunking>
        <chunking id="11" string="be even harder" type="VP">
          <tokens>
            <token id="18" string="be" />
            <token id="19" string="even" />
            <token id="20" string="harder" />
          </tokens>
        </chunking>
        <chunking id="12" string="'s going to be even harder" type="VP">
          <tokens>
            <token id="15" string="'s" />
            <token id="16" string="going" />
            <token id="17" string="to" />
            <token id="18" string="be" />
            <token id="19" string="even" />
            <token id="20" string="harder" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="6">attempts</governor>
          <dependent id="2">If</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">Bureau</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Bureau</governor>
          <dependent id="4">Census</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">attempts</governor>
          <dependent id="5">Bureau</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="16">going</governor>
          <dependent id="6">attempts</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">ask</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">attempts</governor>
          <dependent id="8">ask</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">status</governor>
          <dependent id="9">people</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="12">status</governor>
          <dependent id="10">their</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">status</governor>
          <dependent id="11">immigration</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="8">ask</governor>
          <dependent id="12">status</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">going</governor>
          <dependent id="14">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">going</governor>
          <dependent id="15">'s</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="16">going</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">be</governor>
          <dependent id="17">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="16">going</governor>
          <dependent id="18">be</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="20">harder</governor>
          <dependent id="19">even</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">be</governor>
          <dependent id="20">harder</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Census Bureau" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="4" string="Census" />
            <token id="5" string="Bureau" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="21" has_coreference="false">
      <content>The Census Bureau agrees.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Census" lemma="Census" stem="censu" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="3" string="Bureau" lemma="Bureau" stem="bureau" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="4" string="agrees" lemma="agree" stem="agre" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NNP Census) (NNP Bureau)) (VP (VBZ agrees)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="agrees" type="VP">
          <tokens>
            <token id="4" string="agrees" />
          </tokens>
        </chunking>
        <chunking id="2" string="The Census Bureau" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Census" />
            <token id="3" string="Bureau" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">Bureau</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Bureau</governor>
          <dependent id="2">Census</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">agrees</governor>
          <dependent id="3">Bureau</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">agrees</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Census Bureau" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="2" string="Census" />
            <token id="3" string="Bureau" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="22" has_coreference="true">
      <content>&amp;quot;We tell people: Put your name down on the census form.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="We" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="tell" lemma="tell" stem="tell" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Put" lemma="put" stem="put" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="your" lemma="you" stem="your" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="name" lemma="name" stem="name" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="down" lemma="down" stem="down" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="census" lemma="census" stem="censu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="form" lemma="form" stem="form" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP We)) (VP (VBP tell) (NP (NP (NNS people)) (: :) (VP (VB Put) (NP (PRP$ your) (NN name)) (PRT (RP down)) (PP (IN on) (NP (DT the) (NN census) (NN form)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the census form" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="census" />
            <token id="13" string="form" />
          </tokens>
        </chunking>
        <chunking id="2" string="people : Put your name down on the census form" type="NP">
          <tokens>
            <token id="4" string="people" />
            <token id="5" string=":" />
            <token id="6" string="Put" />
            <token id="7" string="your" />
            <token id="8" string="name" />
            <token id="9" string="down" />
            <token id="10" string="on" />
            <token id="11" string="the" />
            <token id="12" string="census" />
            <token id="13" string="form" />
          </tokens>
        </chunking>
        <chunking id="3" string="your name" type="NP">
          <tokens>
            <token id="7" string="your" />
            <token id="8" string="name" />
          </tokens>
        </chunking>
        <chunking id="4" string="Put your name down on the census form" type="VP">
          <tokens>
            <token id="6" string="Put" />
            <token id="7" string="your" />
            <token id="8" string="name" />
            <token id="9" string="down" />
            <token id="10" string="on" />
            <token id="11" string="the" />
            <token id="12" string="census" />
            <token id="13" string="form" />
          </tokens>
        </chunking>
        <chunking id="5" string="people" type="NP">
          <tokens>
            <token id="4" string="people" />
          </tokens>
        </chunking>
        <chunking id="6" string="We" type="NP">
          <tokens>
            <token id="2" string="We" />
          </tokens>
        </chunking>
        <chunking id="7" string="tell people : Put your name down on the census form" type="VP">
          <tokens>
            <token id="3" string="tell" />
            <token id="4" string="people" />
            <token id="5" string=":" />
            <token id="6" string="Put" />
            <token id="7" string="your" />
            <token id="8" string="name" />
            <token id="9" string="down" />
            <token id="10" string="on" />
            <token id="11" string="the" />
            <token id="12" string="census" />
            <token id="13" string="form" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">tell</governor>
          <dependent id="2">We</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">tell</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">tell</governor>
          <dependent id="4">people</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="4">people</governor>
          <dependent id="6">Put</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">name</governor>
          <dependent id="7">your</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">Put</governor>
          <dependent id="8">name</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="6">Put</governor>
          <dependent id="9">down</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">form</governor>
          <dependent id="10">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">form</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">form</governor>
          <dependent id="12">census</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">Put</governor>
          <dependent id="13">form</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="23" has_coreference="true">
      <content>We won&amp;apost;t report you to the housing authority {if there are too many occupants},&amp;quot; says Peter Bonpanne, an assistant director.</content>
      <tokens>
        <token id="1" string="We" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="wo" lemma="will" stem="wo" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="report" lemma="report" stem="report" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="housing" lemma="housing" stem="hous" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="authority" lemma="authority" stem="author" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="{" lemma="-lcb-" stem="{" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="too" lemma="too" stem="too" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="many" lemma="many" stem="mani" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="occupants" lemma="occupant" stem="occup" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="}" lemma="-rcb-" stem="}" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="Peter" lemma="Peter" stem="peter" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="22" string="Bonpanne" lemma="Bonpanne" stem="bonpann" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="assistant" lemma="assistant" stem="assist" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="director" lemma="director" stem="director" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (S (NP (PRP We)) (VP (MD wo) (RB n't) (VP (VB report) (NP (PRP you)) (PP (TO to) (NP (NP (DT the) (NN housing) (NN authority)) (PRN (-LRB- -LCB-) (SBAR (IN if) (S (NP (EX there)) (VP (VBP are) (NP (ADJP (RB too) (JJ many)) (NNS occupants))))) (-RRB- -RCB-))))))) (, ,) ('' '') (VP (VBZ says)) (NP (NP (NNP Peter) (NNP Bonpanne)) (, ,) (NP (DT an) (JJ assistant) (NN director))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="if there are too many occupants" type="SBAR">
          <tokens>
            <token id="11" string="if" />
            <token id="12" string="there" />
            <token id="13" string="are" />
            <token id="14" string="too" />
            <token id="15" string="many" />
            <token id="16" string="occupants" />
          </tokens>
        </chunking>
        <chunking id="2" string="too many occupants" type="NP">
          <tokens>
            <token id="14" string="too" />
            <token id="15" string="many" />
            <token id="16" string="occupants" />
          </tokens>
        </chunking>
        <chunking id="3" string="Peter Bonpanne , an assistant director" type="NP">
          <tokens>
            <token id="21" string="Peter" />
            <token id="22" string="Bonpanne" />
            <token id="23" string="," />
            <token id="24" string="an" />
            <token id="25" string="assistant" />
            <token id="26" string="director" />
          </tokens>
        </chunking>
        <chunking id="4" string="Peter Bonpanne" type="NP">
          <tokens>
            <token id="21" string="Peter" />
            <token id="22" string="Bonpanne" />
          </tokens>
        </chunking>
        <chunking id="5" string="We" type="NP">
          <tokens>
            <token id="1" string="We" />
          </tokens>
        </chunking>
        <chunking id="6" string="there" type="NP">
          <tokens>
            <token id="12" string="there" />
          </tokens>
        </chunking>
        <chunking id="7" string="too many" type="ADJP">
          <tokens>
            <token id="14" string="too" />
            <token id="15" string="many" />
          </tokens>
        </chunking>
        <chunking id="8" string="report you to the housing authority -LCB- if there are too many occupants -RCB-" type="VP">
          <tokens>
            <token id="4" string="report" />
            <token id="5" string="you" />
            <token id="6" string="to" />
            <token id="7" string="the" />
            <token id="8" string="housing" />
            <token id="9" string="authority" />
            <token id="10" string="{" />
            <token id="11" string="if" />
            <token id="12" string="there" />
            <token id="13" string="are" />
            <token id="14" string="too" />
            <token id="15" string="many" />
            <token id="16" string="occupants" />
            <token id="17" string="}" />
          </tokens>
        </chunking>
        <chunking id="9" string="says" type="VP">
          <tokens>
            <token id="20" string="says" />
          </tokens>
        </chunking>
        <chunking id="10" string="the housing authority -LCB- if there are too many occupants -RCB-" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="housing" />
            <token id="9" string="authority" />
            <token id="10" string="{" />
            <token id="11" string="if" />
            <token id="12" string="there" />
            <token id="13" string="are" />
            <token id="14" string="too" />
            <token id="15" string="many" />
            <token id="16" string="occupants" />
            <token id="17" string="}" />
          </tokens>
        </chunking>
        <chunking id="11" string="wo n't report you to the housing authority -LCB- if there are too many occupants -RCB-" type="VP">
          <tokens>
            <token id="2" string="wo" />
            <token id="3" string="n't" />
            <token id="4" string="report" />
            <token id="5" string="you" />
            <token id="6" string="to" />
            <token id="7" string="the" />
            <token id="8" string="housing" />
            <token id="9" string="authority" />
            <token id="10" string="{" />
            <token id="11" string="if" />
            <token id="12" string="there" />
            <token id="13" string="are" />
            <token id="14" string="too" />
            <token id="15" string="many" />
            <token id="16" string="occupants" />
            <token id="17" string="}" />
          </tokens>
        </chunking>
        <chunking id="12" string="the housing authority" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="housing" />
            <token id="9" string="authority" />
          </tokens>
        </chunking>
        <chunking id="13" string="are too many occupants" type="VP">
          <tokens>
            <token id="13" string="are" />
            <token id="14" string="too" />
            <token id="15" string="many" />
            <token id="16" string="occupants" />
          </tokens>
        </chunking>
        <chunking id="14" string="an assistant director" type="NP">
          <tokens>
            <token id="24" string="an" />
            <token id="25" string="assistant" />
            <token id="26" string="director" />
          </tokens>
        </chunking>
        <chunking id="15" string="you" type="NP">
          <tokens>
            <token id="5" string="you" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">report</governor>
          <dependent id="1">We</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">report</governor>
          <dependent id="2">wo</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="4">report</governor>
          <dependent id="3">n't</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="20">says</governor>
          <dependent id="4">report</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">report</governor>
          <dependent id="5">you</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">authority</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">authority</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">authority</governor>
          <dependent id="8">housing</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">report</governor>
          <dependent id="9">authority</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">are</governor>
          <dependent id="11">if</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="13">are</governor>
          <dependent id="12">there</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="9">authority</governor>
          <dependent id="13">are</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">many</governor>
          <dependent id="14">too</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">occupants</governor>
          <dependent id="15">many</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">are</governor>
          <dependent id="16">occupants</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="20">says</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">Bonpanne</governor>
          <dependent id="21">Peter</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">says</governor>
          <dependent id="22">Bonpanne</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">director</governor>
          <dependent id="24">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">director</governor>
          <dependent id="25">assistant</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="22">Bonpanne</governor>
          <dependent id="26">director</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Peter Bonpanne" type="PERSON" score="0.0">
          <tokens>
            <token id="21" string="Peter" />
            <token id="22" string="Bonpanne" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="24" has_coreference="true">
      <content>&amp;quot;If they see a lot of questions on there about somebody&amp;apost;s legal status, that could hurt all kinds of people&amp;apost;s participation.&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="If" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="see" lemma="see" stem="see" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="lot" lemma="lot" stem="lot" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="questions" lemma="question" stem="question" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="somebody" lemma="somebody" stem="somebodi" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="legal" lemma="legal" stem="legal" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="status" lemma="status" stem="statu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="hurt" lemma="hurt" stem="hurt" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="kinds" lemma="kind" stem="kind" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="24" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="participation" lemma="participation" stem="particip" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (SBAR (IN If) (S (NP (PRP they)) (VP (VBP see) (NP (NP (DT a) (NN lot)) (PP (IN of) (NP (NP (NNS questions)) (PP (IN on) (NP (EX there)))))) (PP (IN about) (NP (NP (NN somebody) (POS 's)) (JJ legal) (NN status)))))) (, ,) (NP (WDT that)) (VP (MD could) (VP (VB hurt) (NP (NP (DT all) (NNS kinds)) (PP (IN of) (NP (NP (NNS people) (POS 's)) (NN participation)))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="a lot of questions on there" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="lot" />
            <token id="7" string="of" />
            <token id="8" string="questions" />
            <token id="9" string="on" />
            <token id="10" string="there" />
          </tokens>
        </chunking>
        <chunking id="2" string="all kinds" type="NP">
          <tokens>
            <token id="20" string="all" />
            <token id="21" string="kinds" />
          </tokens>
        </chunking>
        <chunking id="3" string="questions on there" type="NP">
          <tokens>
            <token id="8" string="questions" />
            <token id="9" string="on" />
            <token id="10" string="there" />
          </tokens>
        </chunking>
        <chunking id="4" string="hurt all kinds of people 's participation" type="VP">
          <tokens>
            <token id="19" string="hurt" />
            <token id="20" string="all" />
            <token id="21" string="kinds" />
            <token id="22" string="of" />
            <token id="23" string="people" />
            <token id="24" string="'s" />
            <token id="25" string="participation" />
          </tokens>
        </chunking>
        <chunking id="5" string="somebody 's" type="NP">
          <tokens>
            <token id="12" string="somebody" />
            <token id="13" string="'s" />
          </tokens>
        </chunking>
        <chunking id="6" string="people 's" type="NP">
          <tokens>
            <token id="23" string="people" />
            <token id="24" string="'s" />
          </tokens>
        </chunking>
        <chunking id="7" string="questions" type="NP">
          <tokens>
            <token id="8" string="questions" />
          </tokens>
        </chunking>
        <chunking id="8" string="see a lot of questions on there about somebody 's legal status" type="VP">
          <tokens>
            <token id="4" string="see" />
            <token id="5" string="a" />
            <token id="6" string="lot" />
            <token id="7" string="of" />
            <token id="8" string="questions" />
            <token id="9" string="on" />
            <token id="10" string="there" />
            <token id="11" string="about" />
            <token id="12" string="somebody" />
            <token id="13" string="'s" />
            <token id="14" string="legal" />
            <token id="15" string="status" />
          </tokens>
        </chunking>
        <chunking id="9" string="If they see a lot of questions on there about somebody 's legal status" type="SBAR">
          <tokens>
            <token id="2" string="If" />
            <token id="3" string="they" />
            <token id="4" string="see" />
            <token id="5" string="a" />
            <token id="6" string="lot" />
            <token id="7" string="of" />
            <token id="8" string="questions" />
            <token id="9" string="on" />
            <token id="10" string="there" />
            <token id="11" string="about" />
            <token id="12" string="somebody" />
            <token id="13" string="'s" />
            <token id="14" string="legal" />
            <token id="15" string="status" />
          </tokens>
        </chunking>
        <chunking id="10" string="there" type="NP">
          <tokens>
            <token id="10" string="there" />
          </tokens>
        </chunking>
        <chunking id="11" string="that" type="NP">
          <tokens>
            <token id="17" string="that" />
          </tokens>
        </chunking>
        <chunking id="12" string="they" type="NP">
          <tokens>
            <token id="3" string="they" />
          </tokens>
        </chunking>
        <chunking id="13" string="a lot" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="lot" />
          </tokens>
        </chunking>
        <chunking id="14" string="people 's participation" type="NP">
          <tokens>
            <token id="23" string="people" />
            <token id="24" string="'s" />
            <token id="25" string="participation" />
          </tokens>
        </chunking>
        <chunking id="15" string="could hurt all kinds of people 's participation" type="VP">
          <tokens>
            <token id="18" string="could" />
            <token id="19" string="hurt" />
            <token id="20" string="all" />
            <token id="21" string="kinds" />
            <token id="22" string="of" />
            <token id="23" string="people" />
            <token id="24" string="'s" />
            <token id="25" string="participation" />
          </tokens>
        </chunking>
        <chunking id="16" string="somebody 's legal status" type="NP">
          <tokens>
            <token id="12" string="somebody" />
            <token id="13" string="'s" />
            <token id="14" string="legal" />
            <token id="15" string="status" />
          </tokens>
        </chunking>
        <chunking id="17" string="all kinds of people 's participation" type="NP">
          <tokens>
            <token id="20" string="all" />
            <token id="21" string="kinds" />
            <token id="22" string="of" />
            <token id="23" string="people" />
            <token id="24" string="'s" />
            <token id="25" string="participation" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="4">see</governor>
          <dependent id="2">If</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">see</governor>
          <dependent id="3">they</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="19">hurt</governor>
          <dependent id="4">see</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">lot</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">see</governor>
          <dependent id="6">lot</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">questions</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">lot</governor>
          <dependent id="8">questions</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">there</governor>
          <dependent id="9">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">questions</governor>
          <dependent id="10">there</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">status</governor>
          <dependent id="11">about</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="15">status</governor>
          <dependent id="12">somebody</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">somebody</governor>
          <dependent id="13">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">status</governor>
          <dependent id="14">legal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">see</governor>
          <dependent id="15">status</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">hurt</governor>
          <dependent id="17">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="19">hurt</governor>
          <dependent id="18">could</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="19">hurt</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">kinds</governor>
          <dependent id="20">all</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">hurt</governor>
          <dependent id="21">kinds</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">participation</governor>
          <dependent id="22">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="25">participation</governor>
          <dependent id="23">people</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">people</governor>
          <dependent id="24">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">kinds</governor>
          <dependent id="25">participation</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="25" has_coreference="true">
      <content>Although the 106 million census forms can be reprinted if Congress acts soon, wording a question so that illegal immigrants answer accurately is a challenge, Mr. Bonpanne says.</content>
      <tokens>
        <token id="1" string="Although" lemma="although" stem="although" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="106" lemma="106" stem="106" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="4" string="million" lemma="million" stem="million" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="5" string="census" lemma="census" stem="censu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="forms" lemma="form" stem="form" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="reprinted" lemma="reprint" stem="reprint" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Congress" lemma="Congress" stem="congress" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="12" string="acts" lemma="act" stem="act" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="soon" lemma="soon" stem="soon" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="wording" lemma="wording" stem="word" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="question" lemma="question" stem="question" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="so" lemma="so" stem="so" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="illegal" lemma="illegal" stem="illeg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="immigrants" lemma="immigrant" stem="immigr" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="answer" lemma="answer" stem="answer" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="accurately" lemma="accurately" stem="accur" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="26" string="challenge" lemma="challenge" stem="challeng" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="27" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="Mr." lemma="Mr." stem="mr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="29" string="Bonpanne" lemma="Bonpanne" stem="bonpann" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="30" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN Although) (S (NP (DT the) (QP (CD 106) (CD million)) (NN census) (NNS forms)) (VP (MD can) (VP (VB be) (VP (VBN reprinted) (SBAR (IN if) (S (NP (NNP Congress)) (VP (VBZ acts) (ADVP (RB soon)))))))))) (, ,) (NP (NN wording)) (ADVP (NP (DT a) (NN question)) (IN so)) (SBAR (IN that) (S (NP (JJ illegal) (NNS immigrants) (S (VP (VB answer) (ADVP (RB accurately))))) (VP (VBZ is) (NP (DT a) (NN challenge))))) (, ,) (NP (NNP Mr.) (NNP Bonpanne)) (VP (VBZ says)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the 106 million census forms" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="106" />
            <token id="4" string="million" />
            <token id="5" string="census" />
            <token id="6" string="forms" />
          </tokens>
        </chunking>
        <chunking id="2" string="a question" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="question" />
          </tokens>
        </chunking>
        <chunking id="3" string="answer accurately" type="VP">
          <tokens>
            <token id="22" string="answer" />
            <token id="23" string="accurately" />
          </tokens>
        </chunking>
        <chunking id="4" string="that illegal immigrants answer accurately is a challenge" type="SBAR">
          <tokens>
            <token id="19" string="that" />
            <token id="20" string="illegal" />
            <token id="21" string="immigrants" />
            <token id="22" string="answer" />
            <token id="23" string="accurately" />
            <token id="24" string="is" />
            <token id="25" string="a" />
            <token id="26" string="challenge" />
          </tokens>
        </chunking>
        <chunking id="5" string="illegal immigrants answer accurately" type="NP">
          <tokens>
            <token id="20" string="illegal" />
            <token id="21" string="immigrants" />
            <token id="22" string="answer" />
            <token id="23" string="accurately" />
          </tokens>
        </chunking>
        <chunking id="6" string="can be reprinted if Congress acts soon" type="VP">
          <tokens>
            <token id="7" string="can" />
            <token id="8" string="be" />
            <token id="9" string="reprinted" />
            <token id="10" string="if" />
            <token id="11" string="Congress" />
            <token id="12" string="acts" />
            <token id="13" string="soon" />
          </tokens>
        </chunking>
        <chunking id="7" string="Congress" type="NP">
          <tokens>
            <token id="11" string="Congress" />
          </tokens>
        </chunking>
        <chunking id="8" string="be reprinted if Congress acts soon" type="VP">
          <tokens>
            <token id="8" string="be" />
            <token id="9" string="reprinted" />
            <token id="10" string="if" />
            <token id="11" string="Congress" />
            <token id="12" string="acts" />
            <token id="13" string="soon" />
          </tokens>
        </chunking>
        <chunking id="9" string="acts soon" type="VP">
          <tokens>
            <token id="12" string="acts" />
            <token id="13" string="soon" />
          </tokens>
        </chunking>
        <chunking id="10" string="says" type="VP">
          <tokens>
            <token id="30" string="says" />
          </tokens>
        </chunking>
        <chunking id="11" string="if Congress acts soon" type="SBAR">
          <tokens>
            <token id="10" string="if" />
            <token id="11" string="Congress" />
            <token id="12" string="acts" />
            <token id="13" string="soon" />
          </tokens>
        </chunking>
        <chunking id="12" string="wording" type="NP">
          <tokens>
            <token id="15" string="wording" />
          </tokens>
        </chunking>
        <chunking id="13" string="a challenge" type="NP">
          <tokens>
            <token id="25" string="a" />
            <token id="26" string="challenge" />
          </tokens>
        </chunking>
        <chunking id="14" string="is a challenge" type="VP">
          <tokens>
            <token id="24" string="is" />
            <token id="25" string="a" />
            <token id="26" string="challenge" />
          </tokens>
        </chunking>
        <chunking id="15" string="Although the 106 million census forms can be reprinted if Congress acts soon" type="SBAR">
          <tokens>
            <token id="1" string="Although" />
            <token id="2" string="the" />
            <token id="3" string="106" />
            <token id="4" string="million" />
            <token id="5" string="census" />
            <token id="6" string="forms" />
            <token id="7" string="can" />
            <token id="8" string="be" />
            <token id="9" string="reprinted" />
            <token id="10" string="if" />
            <token id="11" string="Congress" />
            <token id="12" string="acts" />
            <token id="13" string="soon" />
          </tokens>
        </chunking>
        <chunking id="16" string="Mr. Bonpanne" type="NP">
          <tokens>
            <token id="28" string="Mr." />
            <token id="29" string="Bonpanne" />
          </tokens>
        </chunking>
        <chunking id="17" string="reprinted if Congress acts soon" type="VP">
          <tokens>
            <token id="9" string="reprinted" />
            <token id="10" string="if" />
            <token id="11" string="Congress" />
            <token id="12" string="acts" />
            <token id="13" string="soon" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="9">reprinted</governor>
          <dependent id="1">Although</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">forms</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">million</governor>
          <dependent id="3">106</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="6">forms</governor>
          <dependent id="4">million</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">forms</governor>
          <dependent id="5">census</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="9">reprinted</governor>
          <dependent id="6">forms</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">reprinted</governor>
          <dependent id="7">can</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="9">reprinted</governor>
          <dependent id="8">be</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="30">says</governor>
          <dependent id="9">reprinted</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">acts</governor>
          <dependent id="10">if</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">acts</governor>
          <dependent id="11">Congress</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="9">reprinted</governor>
          <dependent id="12">acts</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">acts</governor>
          <dependent id="13">soon</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="30">says</governor>
          <dependent id="15">wording</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">question</governor>
          <dependent id="16">a</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="30">says</governor>
          <dependent id="17">question</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">question</governor>
          <dependent id="18">so</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="26">challenge</governor>
          <dependent id="19">that</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">immigrants</governor>
          <dependent id="20">illegal</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">challenge</governor>
          <dependent id="21">immigrants</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="21">immigrants</governor>
          <dependent id="22">answer</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="22">answer</governor>
          <dependent id="23">accurately</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="26">challenge</governor>
          <dependent id="24">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">challenge</governor>
          <dependent id="25">a</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="30">says</governor>
          <dependent id="26">challenge</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="29">Bonpanne</governor>
          <dependent id="28">Mr.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="30">says</governor>
          <dependent id="29">Bonpanne</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="30">says</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="106 million" type="NUMBER" score="0.0">
          <tokens>
            <token id="3" string="106" />
            <token id="4" string="million" />
          </tokens>
        </entity>
        <entity id="2" string="Bonpanne" type="PERSON" score="0.0">
          <tokens>
            <token id="29" string="Bonpanne" />
          </tokens>
        </entity>
        <entity id="3" string="Congress" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="11" string="Congress" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="26" has_coreference="true">
      <content>The bureau already plans to ask one in six respondents if they are citizens.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="bureau" lemma="bureau" stem="bureau" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="already" lemma="already" stem="alreadi" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="plans" lemma="plan" stem="plan" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="ask" lemma="ask" stem="ask" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="8" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="six" lemma="six" stem="six" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="10" string="respondents" lemma="respondent" stem="respond" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="citizens" lemma="citizen" stem="citizen" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN bureau)) (ADVP (RB already)) (VP (VBZ plans) (S (VP (TO to) (VP (VB ask) (NP (CD one)) (PP (IN in) (NP (CD six) (NNS respondents))) (SBAR (IN if) (S (NP (PRP they)) (VP (VBP are) (NP (NNS citizens))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="plans to ask one in six respondents if they are citizens" type="VP">
          <tokens>
            <token id="4" string="plans" />
            <token id="5" string="to" />
            <token id="6" string="ask" />
            <token id="7" string="one" />
            <token id="8" string="in" />
            <token id="9" string="six" />
            <token id="10" string="respondents" />
            <token id="11" string="if" />
            <token id="12" string="they" />
            <token id="13" string="are" />
            <token id="14" string="citizens" />
          </tokens>
        </chunking>
        <chunking id="2" string="they" type="NP">
          <tokens>
            <token id="12" string="they" />
          </tokens>
        </chunking>
        <chunking id="3" string="are citizens" type="VP">
          <tokens>
            <token id="13" string="are" />
            <token id="14" string="citizens" />
          </tokens>
        </chunking>
        <chunking id="4" string="one" type="NP">
          <tokens>
            <token id="7" string="one" />
          </tokens>
        </chunking>
        <chunking id="5" string="to ask one in six respondents if they are citizens" type="VP">
          <tokens>
            <token id="5" string="to" />
            <token id="6" string="ask" />
            <token id="7" string="one" />
            <token id="8" string="in" />
            <token id="9" string="six" />
            <token id="10" string="respondents" />
            <token id="11" string="if" />
            <token id="12" string="they" />
            <token id="13" string="are" />
            <token id="14" string="citizens" />
          </tokens>
        </chunking>
        <chunking id="6" string="ask one in six respondents if they are citizens" type="VP">
          <tokens>
            <token id="6" string="ask" />
            <token id="7" string="one" />
            <token id="8" string="in" />
            <token id="9" string="six" />
            <token id="10" string="respondents" />
            <token id="11" string="if" />
            <token id="12" string="they" />
            <token id="13" string="are" />
            <token id="14" string="citizens" />
          </tokens>
        </chunking>
        <chunking id="7" string="six respondents" type="NP">
          <tokens>
            <token id="9" string="six" />
            <token id="10" string="respondents" />
          </tokens>
        </chunking>
        <chunking id="8" string="The bureau" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="bureau" />
          </tokens>
        </chunking>
        <chunking id="9" string="if they are citizens" type="SBAR">
          <tokens>
            <token id="11" string="if" />
            <token id="12" string="they" />
            <token id="13" string="are" />
            <token id="14" string="citizens" />
          </tokens>
        </chunking>
        <chunking id="10" string="citizens" type="NP">
          <tokens>
            <token id="14" string="citizens" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">bureau</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">plans</governor>
          <dependent id="2">bureau</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">plans</governor>
          <dependent id="3">already</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">plans</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">ask</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">plans</governor>
          <dependent id="6">ask</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">ask</governor>
          <dependent id="7">one</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">respondents</governor>
          <dependent id="8">in</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="10">respondents</governor>
          <dependent id="9">six</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">ask</governor>
          <dependent id="10">respondents</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">citizens</governor>
          <dependent id="11">if</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">citizens</governor>
          <dependent id="12">they</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="14">citizens</governor>
          <dependent id="13">are</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="6">ask</governor>
          <dependent id="14">citizens</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="six" type="NUMBER" score="0.0">
          <tokens>
            <token id="9" string="six" />
          </tokens>
        </entity>
        <entity id="2" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="7" string="one" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="27" has_coreference="true">
      <content>To satisfy congressional critics, it would have to ask everyone that question, and then ask the legal status of anyone who isn&amp;apost;t a citizen.</content>
      <tokens>
        <token id="1" string="To" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="satisfy" lemma="satisfy" stem="satisfi" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="congressional" lemma="congressional" stem="congression" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="critics" lemma="critic" stem="critic" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="ask" lemma="ask" stem="ask" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="everyone" lemma="everyone" stem="everyon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="question" lemma="question" stem="question" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="ask" lemma="ask" stem="ask" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="legal" lemma="legal" stem="legal" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="status" lemma="status" stem="statu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="anyone" lemma="anyone" stem="anyon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="27" string="citizen" lemma="citizen" stem="citizen" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (TO To) (VP (VB satisfy) (NP (JJ congressional) (NNS critics))))) (, ,) (NP (PRP it)) (VP (MD would) (VP (VB have) (S (VP (TO to) (VP (VP (VB ask) (NP (NN everyone)) (SBAR (IN that) (S (VP (NN question))))) (, ,) (CC and) (ADVP (RB then)) (VP (VB ask) (NP (NP (DT the) (JJ legal) (NN status)) (PP (IN of) (NP (NN anyone))) (SBAR (WHNP (WP who)) (S (VP (VBZ is) (RB n't) (NP (DT a) (NN citizen)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="satisfy congressional critics" type="VP">
          <tokens>
            <token id="2" string="satisfy" />
            <token id="3" string="congressional" />
            <token id="4" string="critics" />
          </tokens>
        </chunking>
        <chunking id="2" string="everyone" type="NP">
          <tokens>
            <token id="11" string="everyone" />
          </tokens>
        </chunking>
        <chunking id="3" string="ask everyone that question , and then ask the legal status of anyone who is n't a citizen" type="VP">
          <tokens>
            <token id="10" string="ask" />
            <token id="11" string="everyone" />
            <token id="12" string="that" />
            <token id="13" string="question" />
            <token id="14" string="," />
            <token id="15" string="and" />
            <token id="16" string="then" />
            <token id="17" string="ask" />
            <token id="18" string="the" />
            <token id="19" string="legal" />
            <token id="20" string="status" />
            <token id="21" string="of" />
            <token id="22" string="anyone" />
            <token id="23" string="who" />
            <token id="24" string="is" />
            <token id="25" string="n't" />
            <token id="26" string="a" />
            <token id="27" string="citizen" />
          </tokens>
        </chunking>
        <chunking id="4" string="to ask everyone that question , and then ask the legal status of anyone who is n't a citizen" type="VP">
          <tokens>
            <token id="9" string="to" />
            <token id="10" string="ask" />
            <token id="11" string="everyone" />
            <token id="12" string="that" />
            <token id="13" string="question" />
            <token id="14" string="," />
            <token id="15" string="and" />
            <token id="16" string="then" />
            <token id="17" string="ask" />
            <token id="18" string="the" />
            <token id="19" string="legal" />
            <token id="20" string="status" />
            <token id="21" string="of" />
            <token id="22" string="anyone" />
            <token id="23" string="who" />
            <token id="24" string="is" />
            <token id="25" string="n't" />
            <token id="26" string="a" />
            <token id="27" string="citizen" />
          </tokens>
        </chunking>
        <chunking id="5" string="question" type="VP">
          <tokens>
            <token id="13" string="question" />
          </tokens>
        </chunking>
        <chunking id="6" string="ask the legal status of anyone who is n't a citizen" type="VP">
          <tokens>
            <token id="17" string="ask" />
            <token id="18" string="the" />
            <token id="19" string="legal" />
            <token id="20" string="status" />
            <token id="21" string="of" />
            <token id="22" string="anyone" />
            <token id="23" string="who" />
            <token id="24" string="is" />
            <token id="25" string="n't" />
            <token id="26" string="a" />
            <token id="27" string="citizen" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="6" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="is n't a citizen" type="VP">
          <tokens>
            <token id="24" string="is" />
            <token id="25" string="n't" />
            <token id="26" string="a" />
            <token id="27" string="citizen" />
          </tokens>
        </chunking>
        <chunking id="9" string="would have to ask everyone that question , and then ask the legal status of anyone who is n't a citizen" type="VP">
          <tokens>
            <token id="7" string="would" />
            <token id="8" string="have" />
            <token id="9" string="to" />
            <token id="10" string="ask" />
            <token id="11" string="everyone" />
            <token id="12" string="that" />
            <token id="13" string="question" />
            <token id="14" string="," />
            <token id="15" string="and" />
            <token id="16" string="then" />
            <token id="17" string="ask" />
            <token id="18" string="the" />
            <token id="19" string="legal" />
            <token id="20" string="status" />
            <token id="21" string="of" />
            <token id="22" string="anyone" />
            <token id="23" string="who" />
            <token id="24" string="is" />
            <token id="25" string="n't" />
            <token id="26" string="a" />
            <token id="27" string="citizen" />
          </tokens>
        </chunking>
        <chunking id="10" string="ask everyone that question" type="VP">
          <tokens>
            <token id="10" string="ask" />
            <token id="11" string="everyone" />
            <token id="12" string="that" />
            <token id="13" string="question" />
          </tokens>
        </chunking>
        <chunking id="11" string="To satisfy congressional critics" type="VP">
          <tokens>
            <token id="1" string="To" />
            <token id="2" string="satisfy" />
            <token id="3" string="congressional" />
            <token id="4" string="critics" />
          </tokens>
        </chunking>
        <chunking id="12" string="the legal status of anyone who is n't a citizen" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="legal" />
            <token id="20" string="status" />
            <token id="21" string="of" />
            <token id="22" string="anyone" />
            <token id="23" string="who" />
            <token id="24" string="is" />
            <token id="25" string="n't" />
            <token id="26" string="a" />
            <token id="27" string="citizen" />
          </tokens>
        </chunking>
        <chunking id="13" string="anyone" type="NP">
          <tokens>
            <token id="22" string="anyone" />
          </tokens>
        </chunking>
        <chunking id="14" string="a citizen" type="NP">
          <tokens>
            <token id="26" string="a" />
            <token id="27" string="citizen" />
          </tokens>
        </chunking>
        <chunking id="15" string="congressional critics" type="NP">
          <tokens>
            <token id="3" string="congressional" />
            <token id="4" string="critics" />
          </tokens>
        </chunking>
        <chunking id="16" string="that question" type="SBAR">
          <tokens>
            <token id="12" string="that" />
            <token id="13" string="question" />
          </tokens>
        </chunking>
        <chunking id="17" string="have to ask everyone that question , and then ask the legal status of anyone who is n't a citizen" type="VP">
          <tokens>
            <token id="8" string="have" />
            <token id="9" string="to" />
            <token id="10" string="ask" />
            <token id="11" string="everyone" />
            <token id="12" string="that" />
            <token id="13" string="question" />
            <token id="14" string="," />
            <token id="15" string="and" />
            <token id="16" string="then" />
            <token id="17" string="ask" />
            <token id="18" string="the" />
            <token id="19" string="legal" />
            <token id="20" string="status" />
            <token id="21" string="of" />
            <token id="22" string="anyone" />
            <token id="23" string="who" />
            <token id="24" string="is" />
            <token id="25" string="n't" />
            <token id="26" string="a" />
            <token id="27" string="citizen" />
          </tokens>
        </chunking>
        <chunking id="18" string="who is n't a citizen" type="SBAR">
          <tokens>
            <token id="23" string="who" />
            <token id="24" string="is" />
            <token id="25" string="n't" />
            <token id="26" string="a" />
            <token id="27" string="citizen" />
          </tokens>
        </chunking>
        <chunking id="19" string="the legal status" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="legal" />
            <token id="20" string="status" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="2">satisfy</governor>
          <dependent id="1">To</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="8">have</governor>
          <dependent id="2">satisfy</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">critics</governor>
          <dependent id="3">congressional</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">satisfy</governor>
          <dependent id="4">critics</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">have</governor>
          <dependent id="6">it</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">have</governor>
          <dependent id="7">would</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">have</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">ask</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="8">have</governor>
          <dependent id="10">ask</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">ask</governor>
          <dependent id="11">everyone</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">question</governor>
          <dependent id="12">that</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">ask</governor>
          <dependent id="13">question</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">ask</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="17">ask</governor>
          <dependent id="16">then</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">ask</governor>
          <dependent id="17">ask</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">status</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">status</governor>
          <dependent id="19">legal</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">ask</governor>
          <dependent id="20">status</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">anyone</governor>
          <dependent id="21">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">status</governor>
          <dependent id="22">anyone</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">citizen</governor>
          <dependent id="23">who</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="27">citizen</governor>
          <dependent id="24">is</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="27">citizen</governor>
          <dependent id="25">n't</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">citizen</governor>
          <dependent id="26">a</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="20">status</governor>
          <dependent id="27">citizen</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="28" has_coreference="true">
      <content>Rep. Ridge dismisses the practical problems.</content>
      <tokens>
        <token id="1" string="Rep." lemma="Rep." stem="rep." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="2" string="Ridge" lemma="Ridge" stem="ridg" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="dismisses" lemma="dismiss" stem="dismiss" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="practical" lemma="practical" stem="practic" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="problems" lemma="problem" stem="problem" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Rep.) (NNP Ridge)) (VP (VBZ dismisses) (NP (DT the) (JJ practical) (NNS problems))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Rep. Ridge" type="NP">
          <tokens>
            <token id="1" string="Rep." />
            <token id="2" string="Ridge" />
          </tokens>
        </chunking>
        <chunking id="2" string="the practical problems" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="practical" />
            <token id="6" string="problems" />
          </tokens>
        </chunking>
        <chunking id="3" string="dismisses the practical problems" type="VP">
          <tokens>
            <token id="3" string="dismisses" />
            <token id="4" string="the" />
            <token id="5" string="practical" />
            <token id="6" string="problems" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Ridge</governor>
          <dependent id="1">Rep.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">dismisses</governor>
          <dependent id="2">Ridge</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">dismisses</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">problems</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">problems</governor>
          <dependent id="5">practical</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">dismisses</governor>
          <dependent id="6">problems</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ridge" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Ridge" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="29" has_coreference="true">
      <content>&amp;quot;We&amp;apost;re spending billions on the census, and the only thing we get is a bunch of belly-aching about how difficult it will be,&amp;quot; he complains.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="We" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="'re" lemma="be" stem="'re" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="spending" lemma="spend" stem="spend" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="billions" lemma="billion" stem="billion" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="census" lemma="census" stem="censu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="only" lemma="only" stem="onli" pos="JJ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="thing" lemma="thing" stem="thing" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="15" string="get" lemma="get" stem="get" pos="VBP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="bunch" lemma="bunch" stem="bunch" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="belly-aching" lemma="belly-ache" stem="belly-ach" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="how" lemma="how" stem="how" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="difficult" lemma="difficult" stem="difficult" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="30" string="complains" lemma="complain" stem="complain" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (S (NP (PRP We)) (VP (VBP 're) (VP (VBG spending) (NP (NNS billions)) (PP (IN on) (NP (DT the) (NN census)))))) (, ,) (CC and) (S (NP (NP (DT the) (JJ only) (NN thing)) (SBAR (S (NP (PRP we)) (VP (VBP get))))) (VP (VBZ is) (NP (NP (DT a) (NN bunch)) (PP (IN of) (S (VP (VBG belly-aching) (PP (IN about) (SBAR (WHADJP (WRB how) (JJ difficult)) (S (NP (PRP it)) (VP (MD will) (VP (VB be))))))))))))) (, ,) ('' '') (NP (PRP he)) (VP (VBZ complains)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="billions" type="NP">
          <tokens>
            <token id="5" string="billions" />
          </tokens>
        </chunking>
        <chunking id="2" string="is a bunch of belly-aching about how difficult it will be" type="VP">
          <tokens>
            <token id="16" string="is" />
            <token id="17" string="a" />
            <token id="18" string="bunch" />
            <token id="19" string="of" />
            <token id="20" string="belly-aching" />
            <token id="21" string="about" />
            <token id="22" string="how" />
            <token id="23" string="difficult" />
            <token id="24" string="it" />
            <token id="25" string="will" />
            <token id="26" string="be" />
          </tokens>
        </chunking>
        <chunking id="3" string="spending billions on the census" type="VP">
          <tokens>
            <token id="4" string="spending" />
            <token id="5" string="billions" />
            <token id="6" string="on" />
            <token id="7" string="the" />
            <token id="8" string="census" />
          </tokens>
        </chunking>
        <chunking id="4" string="be" type="VP">
          <tokens>
            <token id="26" string="be" />
          </tokens>
        </chunking>
        <chunking id="5" string="will be" type="VP">
          <tokens>
            <token id="25" string="will" />
            <token id="26" string="be" />
          </tokens>
        </chunking>
        <chunking id="6" string="the only thing we get" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="only" />
            <token id="13" string="thing" />
            <token id="14" string="we" />
            <token id="15" string="get" />
          </tokens>
        </chunking>
        <chunking id="7" string="belly-aching about how difficult it will be" type="VP">
          <tokens>
            <token id="20" string="belly-aching" />
            <token id="21" string="about" />
            <token id="22" string="how" />
            <token id="23" string="difficult" />
            <token id="24" string="it" />
            <token id="25" string="will" />
            <token id="26" string="be" />
          </tokens>
        </chunking>
        <chunking id="8" string="it" type="NP">
          <tokens>
            <token id="24" string="it" />
          </tokens>
        </chunking>
        <chunking id="9" string="a bunch of belly-aching about how difficult it will be" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="bunch" />
            <token id="19" string="of" />
            <token id="20" string="belly-aching" />
            <token id="21" string="about" />
            <token id="22" string="how" />
            <token id="23" string="difficult" />
            <token id="24" string="it" />
            <token id="25" string="will" />
            <token id="26" string="be" />
          </tokens>
        </chunking>
        <chunking id="10" string="We" type="NP">
          <tokens>
            <token id="2" string="We" />
          </tokens>
        </chunking>
        <chunking id="11" string="the only thing" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="only" />
            <token id="13" string="thing" />
          </tokens>
        </chunking>
        <chunking id="12" string="we" type="NP">
          <tokens>
            <token id="14" string="we" />
          </tokens>
        </chunking>
        <chunking id="13" string="'re spending billions on the census" type="VP">
          <tokens>
            <token id="3" string="'re" />
            <token id="4" string="spending" />
            <token id="5" string="billions" />
            <token id="6" string="on" />
            <token id="7" string="the" />
            <token id="8" string="census" />
          </tokens>
        </chunking>
        <chunking id="14" string="we get" type="SBAR">
          <tokens>
            <token id="14" string="we" />
            <token id="15" string="get" />
          </tokens>
        </chunking>
        <chunking id="15" string="a bunch" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="bunch" />
          </tokens>
        </chunking>
        <chunking id="16" string="get" type="VP">
          <tokens>
            <token id="15" string="get" />
          </tokens>
        </chunking>
        <chunking id="17" string="how difficult it will be" type="SBAR">
          <tokens>
            <token id="22" string="how" />
            <token id="23" string="difficult" />
            <token id="24" string="it" />
            <token id="25" string="will" />
            <token id="26" string="be" />
          </tokens>
        </chunking>
        <chunking id="18" string="the census" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="census" />
          </tokens>
        </chunking>
        <chunking id="19" string="complains" type="VP">
          <tokens>
            <token id="30" string="complains" />
          </tokens>
        </chunking>
        <chunking id="20" string="he" type="NP">
          <tokens>
            <token id="29" string="he" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">spending</governor>
          <dependent id="2">We</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">spending</governor>
          <dependent id="3">'re</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="30">complains</governor>
          <dependent id="4">spending</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">spending</governor>
          <dependent id="5">billions</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">census</governor>
          <dependent id="6">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">census</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">spending</governor>
          <dependent id="8">census</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">spending</governor>
          <dependent id="10">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">thing</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">thing</governor>
          <dependent id="12">only</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">bunch</governor>
          <dependent id="13">thing</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">get</governor>
          <dependent id="14">we</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="13">thing</governor>
          <dependent id="15">get</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="18">bunch</governor>
          <dependent id="16">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">bunch</governor>
          <dependent id="17">a</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">spending</governor>
          <dependent id="18">bunch</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="20">belly-aching</governor>
          <dependent id="19">of</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="18">bunch</governor>
          <dependent id="20">belly-aching</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="26">be</governor>
          <dependent id="21">about</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="23">difficult</governor>
          <dependent id="22">how</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="26">be</governor>
          <dependent id="23">difficult</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">be</governor>
          <dependent id="24">it</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="26">be</governor>
          <dependent id="25">will</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="20">belly-aching</governor>
          <dependent id="26">be</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="30">complains</governor>
          <dependent id="29">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="30">complains</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="30" has_coreference="true">
      <content>&amp;quot;The primary purpose of the census is to distribute political power . . . not to gather demographic information.&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="primary" lemma="primary" stem="primari" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="purpose" lemma="purpose" stem="purpos" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="census" lemma="census" stem="censu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="distribute" lemma="distribute" stem="distribut" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="political" lemma="political" stem="polit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="power" lemma="power" stem="power" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string=". . ." lemma="..." stem=". . ." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="gather" lemma="gather" stem="gather" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="demographic" lemma="demographic" stem="demograph" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="information" lemma="information" stem="inform" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (NP (DT The) (JJ primary) (NN purpose)) (PP (IN of) (NP (DT the) (NN census)))) (VP (VBZ is) (S (VP (TO to) (VP (VB distribute) (NP (JJ political) (NN power)) (: ...) (S (RB not) (VP (TO to) (VP (VB gather) (NP (JJ demographic) (NN information))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="to distribute political power ... not to gather demographic information" type="VP">
          <tokens>
            <token id="9" string="to" />
            <token id="10" string="distribute" />
            <token id="11" string="political" />
            <token id="12" string="power" />
            <token id="13" string=". . ." />
            <token id="14" string="not" />
            <token id="15" string="to" />
            <token id="16" string="gather" />
            <token id="17" string="demographic" />
            <token id="18" string="information" />
          </tokens>
        </chunking>
        <chunking id="2" string="political power" type="NP">
          <tokens>
            <token id="11" string="political" />
            <token id="12" string="power" />
          </tokens>
        </chunking>
        <chunking id="3" string="gather demographic information" type="VP">
          <tokens>
            <token id="16" string="gather" />
            <token id="17" string="demographic" />
            <token id="18" string="information" />
          </tokens>
        </chunking>
        <chunking id="4" string="demographic information" type="NP">
          <tokens>
            <token id="17" string="demographic" />
            <token id="18" string="information" />
          </tokens>
        </chunking>
        <chunking id="5" string="The primary purpose of the census" type="NP">
          <tokens>
            <token id="2" string="The" />
            <token id="3" string="primary" />
            <token id="4" string="purpose" />
            <token id="5" string="of" />
            <token id="6" string="the" />
            <token id="7" string="census" />
          </tokens>
        </chunking>
        <chunking id="6" string="The primary purpose" type="NP">
          <tokens>
            <token id="2" string="The" />
            <token id="3" string="primary" />
            <token id="4" string="purpose" />
          </tokens>
        </chunking>
        <chunking id="7" string="the census" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="census" />
          </tokens>
        </chunking>
        <chunking id="8" string="distribute political power ... not to gather demographic information" type="VP">
          <tokens>
            <token id="10" string="distribute" />
            <token id="11" string="political" />
            <token id="12" string="power" />
            <token id="13" string=". . ." />
            <token id="14" string="not" />
            <token id="15" string="to" />
            <token id="16" string="gather" />
            <token id="17" string="demographic" />
            <token id="18" string="information" />
          </tokens>
        </chunking>
        <chunking id="9" string="is to distribute political power ... not to gather demographic information" type="VP">
          <tokens>
            <token id="8" string="is" />
            <token id="9" string="to" />
            <token id="10" string="distribute" />
            <token id="11" string="political" />
            <token id="12" string="power" />
            <token id="13" string=". . ." />
            <token id="14" string="not" />
            <token id="15" string="to" />
            <token id="16" string="gather" />
            <token id="17" string="demographic" />
            <token id="18" string="information" />
          </tokens>
        </chunking>
        <chunking id="10" string="to gather demographic information" type="VP">
          <tokens>
            <token id="15" string="to" />
            <token id="16" string="gather" />
            <token id="17" string="demographic" />
            <token id="18" string="information" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="4">purpose</governor>
          <dependent id="2">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">purpose</governor>
          <dependent id="3">primary</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">is</governor>
          <dependent id="4">purpose</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">census</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">census</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">purpose</governor>
          <dependent id="7">census</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">is</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">distribute</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="8">is</governor>
          <dependent id="10">distribute</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">power</governor>
          <dependent id="11">political</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">distribute</governor>
          <dependent id="12">power</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="16">gather</governor>
          <dependent id="14">not</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">gather</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="10">distribute</governor>
          <dependent id="16">gather</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">information</governor>
          <dependent id="17">demographic</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">gather</governor>
          <dependent id="18">information</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="31" has_coreference="true">
      <content>The Senate, by a vote of 58-41, added a provision to a pending immigration bill to require the government to subtract illegal immigrants when it comes up with figures used for reapportionment.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Senate" lemma="Senate" stem="senat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="vote" lemma="vote" stem="vote" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="58-41" lemma="58-41" stem="58-41" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="added" lemma="add" stem="ad" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="provision" lemma="provision" stem="provis" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="pending" lemma="pend" stem="pend" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="immigration" lemma="immigration" stem="immigr" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="bill" lemma="bill" stem="bill" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="require" lemma="require" stem="requir" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="government" lemma="government" stem="govern" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="23" string="subtract" lemma="subtract" stem="subtract" pos="VB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="illegal" lemma="illegal" stem="illeg" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="25" string="immigrants" lemma="immigrant" stem="immigr" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="26" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="27" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="28" string="comes" lemma="come" stem="come" pos="VBZ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="29" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="30" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="31" string="figures" lemma="figure" stem="figur" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="32" string="used" lemma="use" stem="us" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="33" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="34" string="reapportionment" lemma="reapportionment" stem="reapportion" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="35" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NNP Senate)) (, ,) (PP (IN by) (NP (NP (DT a) (NN vote)) (PP (IN of) (NP (CD 58-41))))) (, ,) (VP (VBD added) (NP (DT a) (NN provision)) (PP (TO to) (NP (DT a) (VBG pending) (NN immigration) (NN bill))) (S (VP (TO to) (VP (VB require) (NP (DT the) (NN government) (S (VP (TO to) (VP (VB subtract) (NP (JJ illegal) (NNS immigrants)) (SBAR (WHADVP (WRB when)) (S (NP (PRP it)) (VP (VBZ comes) (PRT (RP up)) (PP (IN with) (NP (NP (NNS figures)) (VP (VBN used) (PP (IN for) (NP (NN reapportionment))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a pending immigration bill" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="pending" />
            <token id="16" string="immigration" />
            <token id="17" string="bill" />
          </tokens>
        </chunking>
        <chunking id="2" string="58-41" type="NP">
          <tokens>
            <token id="8" string="58-41" />
          </tokens>
        </chunking>
        <chunking id="3" string="comes up with figures used for reapportionment" type="VP">
          <tokens>
            <token id="28" string="comes" />
            <token id="29" string="up" />
            <token id="30" string="with" />
            <token id="31" string="figures" />
            <token id="32" string="used" />
            <token id="33" string="for" />
            <token id="34" string="reapportionment" />
          </tokens>
        </chunking>
        <chunking id="4" string="figures" type="NP">
          <tokens>
            <token id="31" string="figures" />
          </tokens>
        </chunking>
        <chunking id="5" string="subtract illegal immigrants when it comes up with figures used for reapportionment" type="VP">
          <tokens>
            <token id="23" string="subtract" />
            <token id="24" string="illegal" />
            <token id="25" string="immigrants" />
            <token id="26" string="when" />
            <token id="27" string="it" />
            <token id="28" string="comes" />
            <token id="29" string="up" />
            <token id="30" string="with" />
            <token id="31" string="figures" />
            <token id="32" string="used" />
            <token id="33" string="for" />
            <token id="34" string="reapportionment" />
          </tokens>
        </chunking>
        <chunking id="6" string="a vote" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="vote" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="27" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="the government to subtract illegal immigrants when it comes up with figures used for reapportionment" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="government" />
            <token id="22" string="to" />
            <token id="23" string="subtract" />
            <token id="24" string="illegal" />
            <token id="25" string="immigrants" />
            <token id="26" string="when" />
            <token id="27" string="it" />
            <token id="28" string="comes" />
            <token id="29" string="up" />
            <token id="30" string="with" />
            <token id="31" string="figures" />
            <token id="32" string="used" />
            <token id="33" string="for" />
            <token id="34" string="reapportionment" />
          </tokens>
        </chunking>
        <chunking id="9" string="a provision" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="provision" />
          </tokens>
        </chunking>
        <chunking id="10" string="to require the government to subtract illegal immigrants when it comes up with figures used for reapportionment" type="VP">
          <tokens>
            <token id="18" string="to" />
            <token id="19" string="require" />
            <token id="20" string="the" />
            <token id="21" string="government" />
            <token id="22" string="to" />
            <token id="23" string="subtract" />
            <token id="24" string="illegal" />
            <token id="25" string="immigrants" />
            <token id="26" string="when" />
            <token id="27" string="it" />
            <token id="28" string="comes" />
            <token id="29" string="up" />
            <token id="30" string="with" />
            <token id="31" string="figures" />
            <token id="32" string="used" />
            <token id="33" string="for" />
            <token id="34" string="reapportionment" />
          </tokens>
        </chunking>
        <chunking id="11" string="illegal immigrants" type="NP">
          <tokens>
            <token id="24" string="illegal" />
            <token id="25" string="immigrants" />
          </tokens>
        </chunking>
        <chunking id="12" string="The Senate" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Senate" />
          </tokens>
        </chunking>
        <chunking id="13" string="when" type="WHADVP">
          <tokens>
            <token id="26" string="when" />
          </tokens>
        </chunking>
        <chunking id="14" string="require the government to subtract illegal immigrants when it comes up with figures used for reapportionment" type="VP">
          <tokens>
            <token id="19" string="require" />
            <token id="20" string="the" />
            <token id="21" string="government" />
            <token id="22" string="to" />
            <token id="23" string="subtract" />
            <token id="24" string="illegal" />
            <token id="25" string="immigrants" />
            <token id="26" string="when" />
            <token id="27" string="it" />
            <token id="28" string="comes" />
            <token id="29" string="up" />
            <token id="30" string="with" />
            <token id="31" string="figures" />
            <token id="32" string="used" />
            <token id="33" string="for" />
            <token id="34" string="reapportionment" />
          </tokens>
        </chunking>
        <chunking id="15" string="added a provision to a pending immigration bill to require the government to subtract illegal immigrants when it comes up with figures used for reapportionment" type="VP">
          <tokens>
            <token id="10" string="added" />
            <token id="11" string="a" />
            <token id="12" string="provision" />
            <token id="13" string="to" />
            <token id="14" string="a" />
            <token id="15" string="pending" />
            <token id="16" string="immigration" />
            <token id="17" string="bill" />
            <token id="18" string="to" />
            <token id="19" string="require" />
            <token id="20" string="the" />
            <token id="21" string="government" />
            <token id="22" string="to" />
            <token id="23" string="subtract" />
            <token id="24" string="illegal" />
            <token id="25" string="immigrants" />
            <token id="26" string="when" />
            <token id="27" string="it" />
            <token id="28" string="comes" />
            <token id="29" string="up" />
            <token id="30" string="with" />
            <token id="31" string="figures" />
            <token id="32" string="used" />
            <token id="33" string="for" />
            <token id="34" string="reapportionment" />
          </tokens>
        </chunking>
        <chunking id="16" string="reapportionment" type="NP">
          <tokens>
            <token id="34" string="reapportionment" />
          </tokens>
        </chunking>
        <chunking id="17" string="to subtract illegal immigrants when it comes up with figures used for reapportionment" type="VP">
          <tokens>
            <token id="22" string="to" />
            <token id="23" string="subtract" />
            <token id="24" string="illegal" />
            <token id="25" string="immigrants" />
            <token id="26" string="when" />
            <token id="27" string="it" />
            <token id="28" string="comes" />
            <token id="29" string="up" />
            <token id="30" string="with" />
            <token id="31" string="figures" />
            <token id="32" string="used" />
            <token id="33" string="for" />
            <token id="34" string="reapportionment" />
          </tokens>
        </chunking>
        <chunking id="18" string="figures used for reapportionment" type="NP">
          <tokens>
            <token id="31" string="figures" />
            <token id="32" string="used" />
            <token id="33" string="for" />
            <token id="34" string="reapportionment" />
          </tokens>
        </chunking>
        <chunking id="19" string="a vote of 58-41" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="vote" />
            <token id="7" string="of" />
            <token id="8" string="58-41" />
          </tokens>
        </chunking>
        <chunking id="20" string="when it comes up with figures used for reapportionment" type="SBAR">
          <tokens>
            <token id="26" string="when" />
            <token id="27" string="it" />
            <token id="28" string="comes" />
            <token id="29" string="up" />
            <token id="30" string="with" />
            <token id="31" string="figures" />
            <token id="32" string="used" />
            <token id="33" string="for" />
            <token id="34" string="reapportionment" />
          </tokens>
        </chunking>
        <chunking id="21" string="used for reapportionment" type="VP">
          <tokens>
            <token id="32" string="used" />
            <token id="33" string="for" />
            <token id="34" string="reapportionment" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">Senate</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">added</governor>
          <dependent id="2">Senate</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">vote</governor>
          <dependent id="4">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">vote</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">added</governor>
          <dependent id="6">vote</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">58-41</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">vote</governor>
          <dependent id="8">58-41</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">added</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">provision</governor>
          <dependent id="11">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">added</governor>
          <dependent id="12">provision</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">bill</governor>
          <dependent id="13">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">bill</governor>
          <dependent id="14">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">bill</governor>
          <dependent id="15">pending</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">bill</governor>
          <dependent id="16">immigration</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">added</governor>
          <dependent id="17">bill</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">require</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="10">added</governor>
          <dependent id="19">require</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">government</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">require</governor>
          <dependent id="21">government</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="23">subtract</governor>
          <dependent id="22">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="21">government</governor>
          <dependent id="23">subtract</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">immigrants</governor>
          <dependent id="24">illegal</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="23">subtract</governor>
          <dependent id="25">immigrants</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="28">comes</governor>
          <dependent id="26">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="28">comes</governor>
          <dependent id="27">it</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="23">subtract</governor>
          <dependent id="28">comes</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="28">comes</governor>
          <dependent id="29">up</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">figures</governor>
          <dependent id="30">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">comes</governor>
          <dependent id="31">figures</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="31">figures</governor>
          <dependent id="32">used</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">reapportionment</governor>
          <dependent id="33">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="32">used</governor>
          <dependent id="34">reapportionment</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Senate" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="2" string="Senate" />
          </tokens>
        </entity>
        <entity id="2" string="58-41" type="NUMBER" score="0.0">
          <tokens>
            <token id="8" string="58-41" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="32" has_coreference="true">
      <content>Because California, Texas and other populous states that benefit from counting the illegal immigrants have such large delegations in the House, the House has always presented a bigger obstacle to the opponents of counting such immigrants.</content>
      <tokens>
        <token id="1" string="Because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="California" lemma="California" stem="california" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Texas" lemma="Texas" stem="texa" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="5" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="populous" lemma="populous" stem="popul" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="states" lemma="state" stem="state" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="benefit" lemma="benefit" stem="benefit" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="counting" lemma="count" stem="count" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="illegal" lemma="illegal" stem="illeg" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="immigrants" lemma="immigrant" stem="immigr" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="such" lemma="such" stem="such" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="large" lemma="large" stem="larg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="delegations" lemma="delegation" stem="deleg" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="House" lemma="House" stem="hous" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="House" lemma="House" stem="hous" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="26" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="always" lemma="always" stem="alwai" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="presented" lemma="present" stem="present" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="bigger" lemma="bigger" stem="bigger" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="obstacle" lemma="obstacle" stem="obstacl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="34" string="opponents" lemma="opponent" stem="oppon" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="35" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="36" string="counting" lemma="count" stem="count" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="37" string="such" lemma="such" stem="such" pos="JJ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="38" string="immigrants" lemma="immigrant" stem="immigr" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="39" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN Because) (S (NP (NP (NNP California) (, ,) (NNP Texas)) (CC and) (NP (NP (ADJP (JJ other) (JJ populous)) (NNS states)) (SBAR (WHNP (WDT that)) (S (VP (VBP benefit) (PP (IN from) (S (VP (VBG counting) (NP (DT the) (JJ illegal) (NNS immigrants)))))))))) (VP (VBP have) (NP (NP (JJ such) (JJ large) (NNS delegations)) (PP (IN in) (NP (DT the) (NNP House))))))) (, ,) (NP (DT the) (NNP House)) (VP (VBZ has) (ADVP (RB always)) (VP (VBN presented) (NP (DT a) (JJR bigger) (NN obstacle)) (PP (TO to) (NP (NP (DT the) (NNS opponents)) (PP (IN of) (NP (VBG counting) (JJ such) (NNS immigrants))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="California , Texas and other populous states that benefit from counting the illegal immigrants" type="NP">
          <tokens>
            <token id="2" string="California" />
            <token id="3" string="," />
            <token id="4" string="Texas" />
            <token id="5" string="and" />
            <token id="6" string="other" />
            <token id="7" string="populous" />
            <token id="8" string="states" />
            <token id="9" string="that" />
            <token id="10" string="benefit" />
            <token id="11" string="from" />
            <token id="12" string="counting" />
            <token id="13" string="the" />
            <token id="14" string="illegal" />
            <token id="15" string="immigrants" />
          </tokens>
        </chunking>
        <chunking id="2" string="such large delegations" type="NP">
          <tokens>
            <token id="17" string="such" />
            <token id="18" string="large" />
            <token id="19" string="delegations" />
          </tokens>
        </chunking>
        <chunking id="3" string="the illegal immigrants" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="illegal" />
            <token id="15" string="immigrants" />
          </tokens>
        </chunking>
        <chunking id="4" string="the opponents" type="NP">
          <tokens>
            <token id="33" string="the" />
            <token id="34" string="opponents" />
          </tokens>
        </chunking>
        <chunking id="5" string="the opponents of counting such immigrants" type="NP">
          <tokens>
            <token id="33" string="the" />
            <token id="34" string="opponents" />
            <token id="35" string="of" />
            <token id="36" string="counting" />
            <token id="37" string="such" />
            <token id="38" string="immigrants" />
          </tokens>
        </chunking>
        <chunking id="6" string="that benefit from counting the illegal immigrants" type="SBAR">
          <tokens>
            <token id="9" string="that" />
            <token id="10" string="benefit" />
            <token id="11" string="from" />
            <token id="12" string="counting" />
            <token id="13" string="the" />
            <token id="14" string="illegal" />
            <token id="15" string="immigrants" />
          </tokens>
        </chunking>
        <chunking id="7" string="counting the illegal immigrants" type="VP">
          <tokens>
            <token id="12" string="counting" />
            <token id="13" string="the" />
            <token id="14" string="illegal" />
            <token id="15" string="immigrants" />
          </tokens>
        </chunking>
        <chunking id="8" string="the House" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="House" />
          </tokens>
        </chunking>
        <chunking id="9" string="California , Texas" type="NP">
          <tokens>
            <token id="2" string="California" />
            <token id="3" string="," />
            <token id="4" string="Texas" />
          </tokens>
        </chunking>
        <chunking id="10" string="other populous states that benefit from counting the illegal immigrants" type="NP">
          <tokens>
            <token id="6" string="other" />
            <token id="7" string="populous" />
            <token id="8" string="states" />
            <token id="9" string="that" />
            <token id="10" string="benefit" />
            <token id="11" string="from" />
            <token id="12" string="counting" />
            <token id="13" string="the" />
            <token id="14" string="illegal" />
            <token id="15" string="immigrants" />
          </tokens>
        </chunking>
        <chunking id="11" string="presented a bigger obstacle to the opponents of counting such immigrants" type="VP">
          <tokens>
            <token id="28" string="presented" />
            <token id="29" string="a" />
            <token id="30" string="bigger" />
            <token id="31" string="obstacle" />
            <token id="32" string="to" />
            <token id="33" string="the" />
            <token id="34" string="opponents" />
            <token id="35" string="of" />
            <token id="36" string="counting" />
            <token id="37" string="such" />
            <token id="38" string="immigrants" />
          </tokens>
        </chunking>
        <chunking id="12" string="counting such immigrants" type="NP">
          <tokens>
            <token id="36" string="counting" />
            <token id="37" string="such" />
            <token id="38" string="immigrants" />
          </tokens>
        </chunking>
        <chunking id="13" string="a bigger obstacle" type="NP">
          <tokens>
            <token id="29" string="a" />
            <token id="30" string="bigger" />
            <token id="31" string="obstacle" />
          </tokens>
        </chunking>
        <chunking id="14" string="such large delegations in the House" type="NP">
          <tokens>
            <token id="17" string="such" />
            <token id="18" string="large" />
            <token id="19" string="delegations" />
            <token id="20" string="in" />
            <token id="21" string="the" />
            <token id="22" string="House" />
          </tokens>
        </chunking>
        <chunking id="15" string="have such large delegations in the House" type="VP">
          <tokens>
            <token id="16" string="have" />
            <token id="17" string="such" />
            <token id="18" string="large" />
            <token id="19" string="delegations" />
            <token id="20" string="in" />
            <token id="21" string="the" />
            <token id="22" string="House" />
          </tokens>
        </chunking>
        <chunking id="16" string="Because California , Texas and other populous states that benefit from counting the illegal immigrants have such large delegations in the House" type="SBAR">
          <tokens>
            <token id="1" string="Because" />
            <token id="2" string="California" />
            <token id="3" string="," />
            <token id="4" string="Texas" />
            <token id="5" string="and" />
            <token id="6" string="other" />
            <token id="7" string="populous" />
            <token id="8" string="states" />
            <token id="9" string="that" />
            <token id="10" string="benefit" />
            <token id="11" string="from" />
            <token id="12" string="counting" />
            <token id="13" string="the" />
            <token id="14" string="illegal" />
            <token id="15" string="immigrants" />
            <token id="16" string="have" />
            <token id="17" string="such" />
            <token id="18" string="large" />
            <token id="19" string="delegations" />
            <token id="20" string="in" />
            <token id="21" string="the" />
            <token id="22" string="House" />
          </tokens>
        </chunking>
        <chunking id="17" string="benefit from counting the illegal immigrants" type="VP">
          <tokens>
            <token id="10" string="benefit" />
            <token id="11" string="from" />
            <token id="12" string="counting" />
            <token id="13" string="the" />
            <token id="14" string="illegal" />
            <token id="15" string="immigrants" />
          </tokens>
        </chunking>
        <chunking id="18" string="other populous states" type="NP">
          <tokens>
            <token id="6" string="other" />
            <token id="7" string="populous" />
            <token id="8" string="states" />
          </tokens>
        </chunking>
        <chunking id="19" string="other populous" type="ADJP">
          <tokens>
            <token id="6" string="other" />
            <token id="7" string="populous" />
          </tokens>
        </chunking>
        <chunking id="20" string="has always presented a bigger obstacle to the opponents of counting such immigrants" type="VP">
          <tokens>
            <token id="26" string="has" />
            <token id="27" string="always" />
            <token id="28" string="presented" />
            <token id="29" string="a" />
            <token id="30" string="bigger" />
            <token id="31" string="obstacle" />
            <token id="32" string="to" />
            <token id="33" string="the" />
            <token id="34" string="opponents" />
            <token id="35" string="of" />
            <token id="36" string="counting" />
            <token id="37" string="such" />
            <token id="38" string="immigrants" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="16">have</governor>
          <dependent id="1">Because</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">Texas</governor>
          <dependent id="2">California</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">have</governor>
          <dependent id="4">Texas</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">Texas</governor>
          <dependent id="5">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">populous</governor>
          <dependent id="6">other</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">states</governor>
          <dependent id="7">populous</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">Texas</governor>
          <dependent id="8">states</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">benefit</governor>
          <dependent id="9">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="8">states</governor>
          <dependent id="10">benefit</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">counting</governor>
          <dependent id="11">from</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="10">benefit</governor>
          <dependent id="12">counting</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">immigrants</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">immigrants</governor>
          <dependent id="14">illegal</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">counting</governor>
          <dependent id="15">immigrants</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="28">presented</governor>
          <dependent id="16">have</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">delegations</governor>
          <dependent id="17">such</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">delegations</governor>
          <dependent id="18">large</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">have</governor>
          <dependent id="19">delegations</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">House</governor>
          <dependent id="20">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">House</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">delegations</governor>
          <dependent id="22">House</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">House</governor>
          <dependent id="24">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="28">presented</governor>
          <dependent id="25">House</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="28">presented</governor>
          <dependent id="26">has</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="28">presented</governor>
          <dependent id="27">always</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="28">presented</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">obstacle</governor>
          <dependent id="29">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="31">obstacle</governor>
          <dependent id="30">bigger</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="28">presented</governor>
          <dependent id="31">obstacle</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">opponents</governor>
          <dependent id="32">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="34">opponents</governor>
          <dependent id="33">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">presented</governor>
          <dependent id="34">opponents</dependent>
        </dependency>
        <dependency type="case">
          <governor id="38">immigrants</governor>
          <dependent id="35">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="38">immigrants</governor>
          <dependent id="36">counting</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="38">immigrants</governor>
          <dependent id="37">such</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="34">opponents</governor>
          <dependent id="38">immigrants</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="California" type="LOCATION" score="0.0">
          <tokens>
            <token id="2" string="California" />
          </tokens>
        </entity>
        <entity id="2" string="House" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="22" string="House" />
          </tokens>
        </entity>
        <entity id="3" string="Texas" type="LOCATION" score="0.0">
          <tokens>
            <token id="4" string="Texas" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="33" has_coreference="true">
      <content>The House did open the door to an amendment to a spending bill that would have barred census takers from &amp;quot;knowingly&amp;quot; counting any illegal immigrants, but the provision was quickly sidetracked on procedural grounds.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="House" lemma="House" stem="hous" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="3" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="open" lemma="open" stem="open" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="door" lemma="door" stem="door" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="amendment" lemma="amendment" stem="amend" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="spending" lemma="spending" stem="spend" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="bill" lemma="bill" stem="bill" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="barred" lemma="bar" stem="bar" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="census" lemma="census" stem="censu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="takers" lemma="taker" stem="taker" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="knowingly" lemma="knowingly" stem="knowingli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="counting" lemma="count" stem="count" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="any" lemma="any" stem="ani" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="illegal" lemma="illegal" stem="illeg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="immigrants" lemma="immigrant" stem="immigr" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="31" string="provision" lemma="provision" stem="provis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="32" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="quickly" lemma="quickly" stem="quickli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="sidetracked" lemma="sidetrack" stem="sidetrack" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="procedural" lemma="procedural" stem="procedur" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="grounds" lemma="grounds" stem="ground" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (DT The) (NNP House)) (VP (VBD did) (VP (VB open) (NP (DT the) (NN door)) (PP (TO to) (NP (NP (DT an) (NN amendment)) (PP (TO to) (NP (NP (DT a) (NN spending) (NN bill)) (SBAR (WHNP (WDT that)) (S (VP (MD would) (VP (VB have) (VP (VBN barred) (NP (NN census) (NNS takers)) (PP (IN from) (`` ``) (ADVP (RB knowingly)))))))))) ('' '') (VP (VBG counting) (NP (DT any) (JJ illegal) (NNS immigrants)))))))) (, ,) (CC but) (S (NP (DT the) (NN provision)) (VP (VBD was) (ADVP (RB quickly)) (VP (VBN sidetracked) (PP (IN on) (NP (JJ procedural) (NNS grounds)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="an amendment to a spending bill that would have barred census takers from `` knowingly '' counting any illegal immigrants" type="NP">
          <tokens>
            <token id="8" string="an" />
            <token id="9" string="amendment" />
            <token id="10" string="to" />
            <token id="11" string="a" />
            <token id="12" string="spending" />
            <token id="13" string="bill" />
            <token id="14" string="that" />
            <token id="15" string="would" />
            <token id="16" string="have" />
            <token id="17" string="barred" />
            <token id="18" string="census" />
            <token id="19" string="takers" />
            <token id="20" string="from" />
            <token id="21" string="&quot;" />
            <token id="22" string="knowingly" />
            <token id="23" string="&quot;" />
            <token id="24" string="counting" />
            <token id="25" string="any" />
            <token id="26" string="illegal" />
            <token id="27" string="immigrants" />
          </tokens>
        </chunking>
        <chunking id="2" string="would have barred census takers from `` knowingly" type="VP">
          <tokens>
            <token id="15" string="would" />
            <token id="16" string="have" />
            <token id="17" string="barred" />
            <token id="18" string="census" />
            <token id="19" string="takers" />
            <token id="20" string="from" />
            <token id="21" string="&quot;" />
            <token id="22" string="knowingly" />
          </tokens>
        </chunking>
        <chunking id="3" string="open the door to an amendment to a spending bill that would have barred census takers from `` knowingly '' counting any illegal immigrants" type="VP">
          <tokens>
            <token id="4" string="open" />
            <token id="5" string="the" />
            <token id="6" string="door" />
            <token id="7" string="to" />
            <token id="8" string="an" />
            <token id="9" string="amendment" />
            <token id="10" string="to" />
            <token id="11" string="a" />
            <token id="12" string="spending" />
            <token id="13" string="bill" />
            <token id="14" string="that" />
            <token id="15" string="would" />
            <token id="16" string="have" />
            <token id="17" string="barred" />
            <token id="18" string="census" />
            <token id="19" string="takers" />
            <token id="20" string="from" />
            <token id="21" string="&quot;" />
            <token id="22" string="knowingly" />
            <token id="23" string="&quot;" />
            <token id="24" string="counting" />
            <token id="25" string="any" />
            <token id="26" string="illegal" />
            <token id="27" string="immigrants" />
          </tokens>
        </chunking>
        <chunking id="4" string="have barred census takers from `` knowingly" type="VP">
          <tokens>
            <token id="16" string="have" />
            <token id="17" string="barred" />
            <token id="18" string="census" />
            <token id="19" string="takers" />
            <token id="20" string="from" />
            <token id="21" string="&quot;" />
            <token id="22" string="knowingly" />
          </tokens>
        </chunking>
        <chunking id="5" string="sidetracked on procedural grounds" type="VP">
          <tokens>
            <token id="34" string="sidetracked" />
            <token id="35" string="on" />
            <token id="36" string="procedural" />
            <token id="37" string="grounds" />
          </tokens>
        </chunking>
        <chunking id="6" string="counting any illegal immigrants" type="VP">
          <tokens>
            <token id="24" string="counting" />
            <token id="25" string="any" />
            <token id="26" string="illegal" />
            <token id="27" string="immigrants" />
          </tokens>
        </chunking>
        <chunking id="7" string="the door" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="door" />
          </tokens>
        </chunking>
        <chunking id="8" string="that would have barred census takers from `` knowingly" type="SBAR">
          <tokens>
            <token id="14" string="that" />
            <token id="15" string="would" />
            <token id="16" string="have" />
            <token id="17" string="barred" />
            <token id="18" string="census" />
            <token id="19" string="takers" />
            <token id="20" string="from" />
            <token id="21" string="&quot;" />
            <token id="22" string="knowingly" />
          </tokens>
        </chunking>
        <chunking id="9" string="any illegal immigrants" type="NP">
          <tokens>
            <token id="25" string="any" />
            <token id="26" string="illegal" />
            <token id="27" string="immigrants" />
          </tokens>
        </chunking>
        <chunking id="10" string="a spending bill" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="spending" />
            <token id="13" string="bill" />
          </tokens>
        </chunking>
        <chunking id="11" string="did open the door to an amendment to a spending bill that would have barred census takers from `` knowingly '' counting any illegal immigrants" type="VP">
          <tokens>
            <token id="3" string="did" />
            <token id="4" string="open" />
            <token id="5" string="the" />
            <token id="6" string="door" />
            <token id="7" string="to" />
            <token id="8" string="an" />
            <token id="9" string="amendment" />
            <token id="10" string="to" />
            <token id="11" string="a" />
            <token id="12" string="spending" />
            <token id="13" string="bill" />
            <token id="14" string="that" />
            <token id="15" string="would" />
            <token id="16" string="have" />
            <token id="17" string="barred" />
            <token id="18" string="census" />
            <token id="19" string="takers" />
            <token id="20" string="from" />
            <token id="21" string="&quot;" />
            <token id="22" string="knowingly" />
            <token id="23" string="&quot;" />
            <token id="24" string="counting" />
            <token id="25" string="any" />
            <token id="26" string="illegal" />
            <token id="27" string="immigrants" />
          </tokens>
        </chunking>
        <chunking id="12" string="the provision" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="provision" />
          </tokens>
        </chunking>
        <chunking id="13" string="procedural grounds" type="NP">
          <tokens>
            <token id="36" string="procedural" />
            <token id="37" string="grounds" />
          </tokens>
        </chunking>
        <chunking id="14" string="an amendment" type="NP">
          <tokens>
            <token id="8" string="an" />
            <token id="9" string="amendment" />
          </tokens>
        </chunking>
        <chunking id="15" string="census takers" type="NP">
          <tokens>
            <token id="18" string="census" />
            <token id="19" string="takers" />
          </tokens>
        </chunking>
        <chunking id="16" string="was quickly sidetracked on procedural grounds" type="VP">
          <tokens>
            <token id="32" string="was" />
            <token id="33" string="quickly" />
            <token id="34" string="sidetracked" />
            <token id="35" string="on" />
            <token id="36" string="procedural" />
            <token id="37" string="grounds" />
          </tokens>
        </chunking>
        <chunking id="17" string="The House" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="House" />
          </tokens>
        </chunking>
        <chunking id="18" string="a spending bill that would have barred census takers from `` knowingly" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="spending" />
            <token id="13" string="bill" />
            <token id="14" string="that" />
            <token id="15" string="would" />
            <token id="16" string="have" />
            <token id="17" string="barred" />
            <token id="18" string="census" />
            <token id="19" string="takers" />
            <token id="20" string="from" />
            <token id="21" string="&quot;" />
            <token id="22" string="knowingly" />
          </tokens>
        </chunking>
        <chunking id="19" string="barred census takers from `` knowingly" type="VP">
          <tokens>
            <token id="17" string="barred" />
            <token id="18" string="census" />
            <token id="19" string="takers" />
            <token id="20" string="from" />
            <token id="21" string="&quot;" />
            <token id="22" string="knowingly" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">House</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">open</governor>
          <dependent id="2">House</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">open</governor>
          <dependent id="3">did</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">open</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">door</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">open</governor>
          <dependent id="6">door</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">amendment</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">amendment</governor>
          <dependent id="8">an</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">open</governor>
          <dependent id="9">amendment</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">bill</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">bill</governor>
          <dependent id="11">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">bill</governor>
          <dependent id="12">spending</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">amendment</governor>
          <dependent id="13">bill</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">barred</governor>
          <dependent id="14">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="17">barred</governor>
          <dependent id="15">would</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="17">barred</governor>
          <dependent id="16">have</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="13">bill</governor>
          <dependent id="17">barred</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">takers</governor>
          <dependent id="18">census</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">barred</governor>
          <dependent id="19">takers</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">knowingly</governor>
          <dependent id="20">from</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="17">barred</governor>
          <dependent id="22">knowingly</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="9">amendment</governor>
          <dependent id="24">counting</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">immigrants</governor>
          <dependent id="25">any</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="27">immigrants</governor>
          <dependent id="26">illegal</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="24">counting</governor>
          <dependent id="27">immigrants</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">open</governor>
          <dependent id="29">but</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">provision</governor>
          <dependent id="30">the</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="34">sidetracked</governor>
          <dependent id="31">provision</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="34">sidetracked</governor>
          <dependent id="32">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="34">sidetracked</governor>
          <dependent id="33">quickly</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">open</governor>
          <dependent id="34">sidetracked</dependent>
        </dependency>
        <dependency type="case">
          <governor id="37">grounds</governor>
          <dependent id="35">on</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="37">grounds</governor>
          <dependent id="36">procedural</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="34">sidetracked</governor>
          <dependent id="37">grounds</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="House" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="2" string="House" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="34" has_coreference="true">
      <content>All sides in the debate predict a lawsuit no matter what Congress does.</content>
      <tokens>
        <token id="1" string="All" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="sides" lemma="side" stem="side" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="debate" lemma="debate" stem="debat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="predict" lemma="predict" stem="predict" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="lawsuit" lemma="lawsuit" stem="lawsuit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="matter" lemma="matter" stem="matter" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="what" lemma="what" stem="what" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Congress" lemma="Congress" stem="congress" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="13" string="does" lemma="do" stem="doe" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT All) (NNS sides)) (PP (IN in) (NP (DT the) (NN debate)))) (VP (VBP predict) (NP (DT a) (NN lawsuit)) (ADVP (DT no) (NN matter) (SBAR (WHNP (WDT what)) (S (NP (NNP Congress)) (VP (VBZ does)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a lawsuit" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="lawsuit" />
          </tokens>
        </chunking>
        <chunking id="2" string="All sides in the debate" type="NP">
          <tokens>
            <token id="1" string="All" />
            <token id="2" string="sides" />
            <token id="3" string="in" />
            <token id="4" string="the" />
            <token id="5" string="debate" />
          </tokens>
        </chunking>
        <chunking id="3" string="predict a lawsuit no matter what Congress does" type="VP">
          <tokens>
            <token id="6" string="predict" />
            <token id="7" string="a" />
            <token id="8" string="lawsuit" />
            <token id="9" string="no" />
            <token id="10" string="matter" />
            <token id="11" string="what" />
            <token id="12" string="Congress" />
            <token id="13" string="does" />
          </tokens>
        </chunking>
        <chunking id="4" string="does" type="VP">
          <tokens>
            <token id="13" string="does" />
          </tokens>
        </chunking>
        <chunking id="5" string="the debate" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="debate" />
          </tokens>
        </chunking>
        <chunking id="6" string="All sides" type="NP">
          <tokens>
            <token id="1" string="All" />
            <token id="2" string="sides" />
          </tokens>
        </chunking>
        <chunking id="7" string="what Congress does" type="SBAR">
          <tokens>
            <token id="11" string="what" />
            <token id="12" string="Congress" />
            <token id="13" string="does" />
          </tokens>
        </chunking>
        <chunking id="8" string="Congress" type="NP">
          <tokens>
            <token id="12" string="Congress" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">sides</governor>
          <dependent id="1">All</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">predict</governor>
          <dependent id="2">sides</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">debate</governor>
          <dependent id="3">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">debate</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">sides</governor>
          <dependent id="5">debate</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">predict</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">lawsuit</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">predict</governor>
          <dependent id="8">lawsuit</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="10">matter</governor>
          <dependent id="9">no</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">predict</governor>
          <dependent id="10">matter</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">does</governor>
          <dependent id="11">what</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">does</governor>
          <dependent id="12">Congress</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">matter</governor>
          <dependent id="13">does</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Congress" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="12" string="Congress" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="35" has_coreference="true">
      <content>In 1980, a federal appeals court upheld a lower-court decision throwing out a suit that sought to bar the government from counting illegal immigrants.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="1980" lemma="1980" stem="1980" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="federal" lemma="federal" stem="feder" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="appeals" lemma="appeal" stem="appeal" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="court" lemma="court" stem="court" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="upheld" lemma="uphold" stem="upheld" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="lower-court" lemma="lower-court" stem="lower-court" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="decision" lemma="decision" stem="decis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="throwing" lemma="throw" stem="throw" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="suit" lemma="suit" stem="suit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="sought" lemma="seek" stem="sought" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="bar" lemma="bar" stem="bar" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="government" lemma="government" stem="govern" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="22" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="counting" lemma="count" stem="count" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="illegal" lemma="illegal" stem="illeg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="25" string="immigrants" lemma="immigrant" stem="immigr" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (CD 1980))) (, ,) (NP (DT a) (JJ federal) (NNS appeals) (NN court)) (VP (VBD upheld) (NP (DT a) (NN lower-court) (NN decision)) (S (VP (VBG throwing) (PRT (RP out)) (NP (NP (DT a) (NN suit)) (SBAR (WHNP (WDT that)) (S (VP (VBD sought) (S (VP (TO to) (VP (VB bar) (NP (DT the) (NN government)) (PP (IN from) (S (VP (VBG counting) (NP (JJ illegal) (NNS immigrants))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="sought to bar the government from counting illegal immigrants" type="VP">
          <tokens>
            <token id="17" string="sought" />
            <token id="18" string="to" />
            <token id="19" string="bar" />
            <token id="20" string="the" />
            <token id="21" string="government" />
            <token id="22" string="from" />
            <token id="23" string="counting" />
            <token id="24" string="illegal" />
            <token id="25" string="immigrants" />
          </tokens>
        </chunking>
        <chunking id="2" string="1980" type="NP">
          <tokens>
            <token id="2" string="1980" />
          </tokens>
        </chunking>
        <chunking id="3" string="that sought to bar the government from counting illegal immigrants" type="SBAR">
          <tokens>
            <token id="16" string="that" />
            <token id="17" string="sought" />
            <token id="18" string="to" />
            <token id="19" string="bar" />
            <token id="20" string="the" />
            <token id="21" string="government" />
            <token id="22" string="from" />
            <token id="23" string="counting" />
            <token id="24" string="illegal" />
            <token id="25" string="immigrants" />
          </tokens>
        </chunking>
        <chunking id="4" string="illegal immigrants" type="NP">
          <tokens>
            <token id="24" string="illegal" />
            <token id="25" string="immigrants" />
          </tokens>
        </chunking>
        <chunking id="5" string="a lower-court decision" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="lower-court" />
            <token id="11" string="decision" />
          </tokens>
        </chunking>
        <chunking id="6" string="throwing out a suit that sought to bar the government from counting illegal immigrants" type="VP">
          <tokens>
            <token id="12" string="throwing" />
            <token id="13" string="out" />
            <token id="14" string="a" />
            <token id="15" string="suit" />
            <token id="16" string="that" />
            <token id="17" string="sought" />
            <token id="18" string="to" />
            <token id="19" string="bar" />
            <token id="20" string="the" />
            <token id="21" string="government" />
            <token id="22" string="from" />
            <token id="23" string="counting" />
            <token id="24" string="illegal" />
            <token id="25" string="immigrants" />
          </tokens>
        </chunking>
        <chunking id="7" string="to bar the government from counting illegal immigrants" type="VP">
          <tokens>
            <token id="18" string="to" />
            <token id="19" string="bar" />
            <token id="20" string="the" />
            <token id="21" string="government" />
            <token id="22" string="from" />
            <token id="23" string="counting" />
            <token id="24" string="illegal" />
            <token id="25" string="immigrants" />
          </tokens>
        </chunking>
        <chunking id="8" string="upheld a lower-court decision throwing out a suit that sought to bar the government from counting illegal immigrants" type="VP">
          <tokens>
            <token id="8" string="upheld" />
            <token id="9" string="a" />
            <token id="10" string="lower-court" />
            <token id="11" string="decision" />
            <token id="12" string="throwing" />
            <token id="13" string="out" />
            <token id="14" string="a" />
            <token id="15" string="suit" />
            <token id="16" string="that" />
            <token id="17" string="sought" />
            <token id="18" string="to" />
            <token id="19" string="bar" />
            <token id="20" string="the" />
            <token id="21" string="government" />
            <token id="22" string="from" />
            <token id="23" string="counting" />
            <token id="24" string="illegal" />
            <token id="25" string="immigrants" />
          </tokens>
        </chunking>
        <chunking id="9" string="a federal appeals court" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="federal" />
            <token id="6" string="appeals" />
            <token id="7" string="court" />
          </tokens>
        </chunking>
        <chunking id="10" string="a suit" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="suit" />
          </tokens>
        </chunking>
        <chunking id="11" string="the government" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="government" />
          </tokens>
        </chunking>
        <chunking id="12" string="counting illegal immigrants" type="VP">
          <tokens>
            <token id="23" string="counting" />
            <token id="24" string="illegal" />
            <token id="25" string="immigrants" />
          </tokens>
        </chunking>
        <chunking id="13" string="bar the government from counting illegal immigrants" type="VP">
          <tokens>
            <token id="19" string="bar" />
            <token id="20" string="the" />
            <token id="21" string="government" />
            <token id="22" string="from" />
            <token id="23" string="counting" />
            <token id="24" string="illegal" />
            <token id="25" string="immigrants" />
          </tokens>
        </chunking>
        <chunking id="14" string="a suit that sought to bar the government from counting illegal immigrants" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="suit" />
            <token id="16" string="that" />
            <token id="17" string="sought" />
            <token id="18" string="to" />
            <token id="19" string="bar" />
            <token id="20" string="the" />
            <token id="21" string="government" />
            <token id="22" string="from" />
            <token id="23" string="counting" />
            <token id="24" string="illegal" />
            <token id="25" string="immigrants" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">1980</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">upheld</governor>
          <dependent id="2">1980</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">court</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">court</governor>
          <dependent id="5">federal</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">court</governor>
          <dependent id="6">appeals</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">upheld</governor>
          <dependent id="7">court</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">upheld</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">decision</governor>
          <dependent id="9">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">decision</governor>
          <dependent id="10">lower-court</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">upheld</governor>
          <dependent id="11">decision</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="8">upheld</governor>
          <dependent id="12">throwing</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="12">throwing</governor>
          <dependent id="13">out</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">suit</governor>
          <dependent id="14">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">throwing</governor>
          <dependent id="15">suit</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">sought</governor>
          <dependent id="16">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="15">suit</governor>
          <dependent id="17">sought</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">bar</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="17">sought</governor>
          <dependent id="19">bar</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">government</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">bar</governor>
          <dependent id="21">government</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="23">counting</governor>
          <dependent id="22">from</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="19">bar</governor>
          <dependent id="23">counting</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">immigrants</governor>
          <dependent id="24">illegal</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="23">counting</governor>
          <dependent id="25">immigrants</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1980" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="1980" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="36" has_coreference="true">
      <content>A similar suit was dismissed this year when a federal district judge in Pittsburgh ruled that the states that sued -- Pennsylvania, Kansas and Alabama -- couldn&amp;apost;t show they had been harmed.</content>
      <tokens>
        <token id="1" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="similar" lemma="similar" stem="similar" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="suit" lemma="suit" stem="suit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="dismissed" lemma="dismiss" stem="dismiss" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="7" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="8" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="federal" lemma="federal" stem="feder" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="district" lemma="district" stem="district" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="judge" lemma="judge" stem="judg" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Pittsburgh" lemma="Pittsburgh" stem="pittsburgh" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="15" string="ruled" lemma="rule" stem="rule" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="states" lemma="state" stem="state" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="sued" lemma="sue" stem="su" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="Pennsylvania" lemma="Pennsylvania" stem="pennsylvania" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="Kansas" lemma="Kansas" stem="kansa" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="25" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="Alabama" lemma="Alabama" stem="alabama" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="27" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="show" lemma="show" stem="show" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="32" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="harmed" lemma="harm" stem="harm" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT A) (JJ similar) (NN suit)) (VP (VBD was) (VP (VBN dismissed) (NP-TMP (DT this) (NN year)) (SBAR (WHADVP (WRB when)) (S (NP (NP (DT a) (JJ federal) (NN district) (NN judge)) (PP (IN in) (NP (NNP Pittsburgh)))) (VP (VBD ruled) (SBAR (IN that) (S (NP (NP (NP (DT the) (NNS states)) (SBAR (WHNP (WDT that)) (S (VP (VBD sued))))) (PRN (: --) (NP (NP (NNP Pennsylvania)) (, ,) (NP (NNP Kansas) (CC and) (NNP Alabama))) (: --))) (VP (MD could) (RB n't) (VP (VB show) (SBAR (S (NP (PRP they)) (VP (VBD had) (VP (VBN been) (VP (VBN harmed))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Pennsylvania" type="NP">
          <tokens>
            <token id="22" string="Pennsylvania" />
          </tokens>
        </chunking>
        <chunking id="2" string="dismissed this year when a federal district judge in Pittsburgh ruled that the states that sued -- Pennsylvania , Kansas and Alabama -- could n't show they had been harmed" type="VP">
          <tokens>
            <token id="5" string="dismissed" />
            <token id="6" string="this" />
            <token id="7" string="year" />
            <token id="8" string="when" />
            <token id="9" string="a" />
            <token id="10" string="federal" />
            <token id="11" string="district" />
            <token id="12" string="judge" />
            <token id="13" string="in" />
            <token id="14" string="Pittsburgh" />
            <token id="15" string="ruled" />
            <token id="16" string="that" />
            <token id="17" string="the" />
            <token id="18" string="states" />
            <token id="19" string="that" />
            <token id="20" string="sued" />
            <token id="21" string="--" />
            <token id="22" string="Pennsylvania" />
            <token id="23" string="," />
            <token id="24" string="Kansas" />
            <token id="25" string="and" />
            <token id="26" string="Alabama" />
            <token id="27" string="--" />
            <token id="28" string="could" />
            <token id="29" string="n't" />
            <token id="30" string="show" />
            <token id="31" string="they" />
            <token id="32" string="had" />
            <token id="33" string="been" />
            <token id="34" string="harmed" />
          </tokens>
        </chunking>
        <chunking id="3" string="sued" type="VP">
          <tokens>
            <token id="20" string="sued" />
          </tokens>
        </chunking>
        <chunking id="4" string="they had been harmed" type="SBAR">
          <tokens>
            <token id="31" string="they" />
            <token id="32" string="had" />
            <token id="33" string="been" />
            <token id="34" string="harmed" />
          </tokens>
        </chunking>
        <chunking id="5" string="ruled that the states that sued -- Pennsylvania , Kansas and Alabama -- could n't show they had been harmed" type="VP">
          <tokens>
            <token id="15" string="ruled" />
            <token id="16" string="that" />
            <token id="17" string="the" />
            <token id="18" string="states" />
            <token id="19" string="that" />
            <token id="20" string="sued" />
            <token id="21" string="--" />
            <token id="22" string="Pennsylvania" />
            <token id="23" string="," />
            <token id="24" string="Kansas" />
            <token id="25" string="and" />
            <token id="26" string="Alabama" />
            <token id="27" string="--" />
            <token id="28" string="could" />
            <token id="29" string="n't" />
            <token id="30" string="show" />
            <token id="31" string="they" />
            <token id="32" string="had" />
            <token id="33" string="been" />
            <token id="34" string="harmed" />
          </tokens>
        </chunking>
        <chunking id="6" string="was dismissed this year when a federal district judge in Pittsburgh ruled that the states that sued -- Pennsylvania , Kansas and Alabama -- could n't show they had been harmed" type="VP">
          <tokens>
            <token id="4" string="was" />
            <token id="5" string="dismissed" />
            <token id="6" string="this" />
            <token id="7" string="year" />
            <token id="8" string="when" />
            <token id="9" string="a" />
            <token id="10" string="federal" />
            <token id="11" string="district" />
            <token id="12" string="judge" />
            <token id="13" string="in" />
            <token id="14" string="Pittsburgh" />
            <token id="15" string="ruled" />
            <token id="16" string="that" />
            <token id="17" string="the" />
            <token id="18" string="states" />
            <token id="19" string="that" />
            <token id="20" string="sued" />
            <token id="21" string="--" />
            <token id="22" string="Pennsylvania" />
            <token id="23" string="," />
            <token id="24" string="Kansas" />
            <token id="25" string="and" />
            <token id="26" string="Alabama" />
            <token id="27" string="--" />
            <token id="28" string="could" />
            <token id="29" string="n't" />
            <token id="30" string="show" />
            <token id="31" string="they" />
            <token id="32" string="had" />
            <token id="33" string="been" />
            <token id="34" string="harmed" />
          </tokens>
        </chunking>
        <chunking id="7" string="that sued" type="SBAR">
          <tokens>
            <token id="19" string="that" />
            <token id="20" string="sued" />
          </tokens>
        </chunking>
        <chunking id="8" string="A similar suit" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="similar" />
            <token id="3" string="suit" />
          </tokens>
        </chunking>
        <chunking id="9" string="Kansas and Alabama" type="NP">
          <tokens>
            <token id="24" string="Kansas" />
            <token id="25" string="and" />
            <token id="26" string="Alabama" />
          </tokens>
        </chunking>
        <chunking id="10" string="the states that sued -- Pennsylvania , Kansas and Alabama --" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="states" />
            <token id="19" string="that" />
            <token id="20" string="sued" />
            <token id="21" string="--" />
            <token id="22" string="Pennsylvania" />
            <token id="23" string="," />
            <token id="24" string="Kansas" />
            <token id="25" string="and" />
            <token id="26" string="Alabama" />
            <token id="27" string="--" />
          </tokens>
        </chunking>
        <chunking id="11" string="a federal district judge in Pittsburgh" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="federal" />
            <token id="11" string="district" />
            <token id="12" string="judge" />
            <token id="13" string="in" />
            <token id="14" string="Pittsburgh" />
          </tokens>
        </chunking>
        <chunking id="12" string="when" type="WHADVP">
          <tokens>
            <token id="8" string="when" />
          </tokens>
        </chunking>
        <chunking id="13" string="a federal district judge" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="federal" />
            <token id="11" string="district" />
            <token id="12" string="judge" />
          </tokens>
        </chunking>
        <chunking id="14" string="that the states that sued -- Pennsylvania , Kansas and Alabama -- could n't show they had been harmed" type="SBAR">
          <tokens>
            <token id="16" string="that" />
            <token id="17" string="the" />
            <token id="18" string="states" />
            <token id="19" string="that" />
            <token id="20" string="sued" />
            <token id="21" string="--" />
            <token id="22" string="Pennsylvania" />
            <token id="23" string="," />
            <token id="24" string="Kansas" />
            <token id="25" string="and" />
            <token id="26" string="Alabama" />
            <token id="27" string="--" />
            <token id="28" string="could" />
            <token id="29" string="n't" />
            <token id="30" string="show" />
            <token id="31" string="they" />
            <token id="32" string="had" />
            <token id="33" string="been" />
            <token id="34" string="harmed" />
          </tokens>
        </chunking>
        <chunking id="15" string="the states" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="states" />
          </tokens>
        </chunking>
        <chunking id="16" string="they" type="NP">
          <tokens>
            <token id="31" string="they" />
          </tokens>
        </chunking>
        <chunking id="17" string="had been harmed" type="VP">
          <tokens>
            <token id="32" string="had" />
            <token id="33" string="been" />
            <token id="34" string="harmed" />
          </tokens>
        </chunking>
        <chunking id="18" string="Pennsylvania , Kansas and Alabama" type="NP">
          <tokens>
            <token id="22" string="Pennsylvania" />
            <token id="23" string="," />
            <token id="24" string="Kansas" />
            <token id="25" string="and" />
            <token id="26" string="Alabama" />
          </tokens>
        </chunking>
        <chunking id="19" string="been harmed" type="VP">
          <tokens>
            <token id="33" string="been" />
            <token id="34" string="harmed" />
          </tokens>
        </chunking>
        <chunking id="20" string="harmed" type="VP">
          <tokens>
            <token id="34" string="harmed" />
          </tokens>
        </chunking>
        <chunking id="21" string="when a federal district judge in Pittsburgh ruled that the states that sued -- Pennsylvania , Kansas and Alabama -- could n't show they had been harmed" type="SBAR">
          <tokens>
            <token id="8" string="when" />
            <token id="9" string="a" />
            <token id="10" string="federal" />
            <token id="11" string="district" />
            <token id="12" string="judge" />
            <token id="13" string="in" />
            <token id="14" string="Pittsburgh" />
            <token id="15" string="ruled" />
            <token id="16" string="that" />
            <token id="17" string="the" />
            <token id="18" string="states" />
            <token id="19" string="that" />
            <token id="20" string="sued" />
            <token id="21" string="--" />
            <token id="22" string="Pennsylvania" />
            <token id="23" string="," />
            <token id="24" string="Kansas" />
            <token id="25" string="and" />
            <token id="26" string="Alabama" />
            <token id="27" string="--" />
            <token id="28" string="could" />
            <token id="29" string="n't" />
            <token id="30" string="show" />
            <token id="31" string="they" />
            <token id="32" string="had" />
            <token id="33" string="been" />
            <token id="34" string="harmed" />
          </tokens>
        </chunking>
        <chunking id="22" string="could n't show they had been harmed" type="VP">
          <tokens>
            <token id="28" string="could" />
            <token id="29" string="n't" />
            <token id="30" string="show" />
            <token id="31" string="they" />
            <token id="32" string="had" />
            <token id="33" string="been" />
            <token id="34" string="harmed" />
          </tokens>
        </chunking>
        <chunking id="23" string="Pittsburgh" type="NP">
          <tokens>
            <token id="14" string="Pittsburgh" />
          </tokens>
        </chunking>
        <chunking id="24" string="the states that sued" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="states" />
            <token id="19" string="that" />
            <token id="20" string="sued" />
          </tokens>
        </chunking>
        <chunking id="25" string="show they had been harmed" type="VP">
          <tokens>
            <token id="30" string="show" />
            <token id="31" string="they" />
            <token id="32" string="had" />
            <token id="33" string="been" />
            <token id="34" string="harmed" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">suit</governor>
          <dependent id="1">A</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">suit</governor>
          <dependent id="2">similar</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="5">dismissed</governor>
          <dependent id="3">suit</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="5">dismissed</governor>
          <dependent id="4">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">dismissed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">year</governor>
          <dependent id="6">this</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="5">dismissed</governor>
          <dependent id="7">year</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">ruled</governor>
          <dependent id="8">when</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">judge</governor>
          <dependent id="9">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">judge</governor>
          <dependent id="10">federal</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">judge</governor>
          <dependent id="11">district</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">ruled</governor>
          <dependent id="12">judge</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">Pittsburgh</governor>
          <dependent id="13">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">judge</governor>
          <dependent id="14">Pittsburgh</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="5">dismissed</governor>
          <dependent id="15">ruled</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="30">show</governor>
          <dependent id="16">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">states</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="30">show</governor>
          <dependent id="18">states</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">sued</governor>
          <dependent id="19">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="18">states</governor>
          <dependent id="20">sued</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="18">states</governor>
          <dependent id="22">Pennsylvania</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="22">Pennsylvania</governor>
          <dependent id="24">Kansas</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="24">Kansas</governor>
          <dependent id="25">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="24">Kansas</governor>
          <dependent id="26">Alabama</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="30">show</governor>
          <dependent id="28">could</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="30">show</governor>
          <dependent id="29">n't</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="15">ruled</governor>
          <dependent id="30">show</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="34">harmed</governor>
          <dependent id="31">they</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="34">harmed</governor>
          <dependent id="32">had</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="34">harmed</governor>
          <dependent id="33">been</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="30">show</governor>
          <dependent id="34">harmed</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Kansas" type="LOCATION" score="0.0">
          <tokens>
            <token id="24" string="Kansas" />
          </tokens>
        </entity>
        <entity id="2" string="Pittsburgh" type="LOCATION" score="0.0">
          <tokens>
            <token id="14" string="Pittsburgh" />
          </tokens>
        </entity>
        <entity id="3" string="Pennsylvania" type="LOCATION" score="0.0">
          <tokens>
            <token id="22" string="Pennsylvania" />
          </tokens>
        </entity>
        <entity id="4" string="this year" type="DATE" score="0.0">
          <tokens>
            <token id="6" string="this" />
            <token id="7" string="year" />
          </tokens>
        </entity>
        <entity id="5" string="Alabama" type="LOCATION" score="0.0">
          <tokens>
            <token id="26" string="Alabama" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="37" has_coreference="true">
      <content>The Constitution simply calls for apportioning the House on the basis of the &amp;quot;the whole number of persons&amp;quot; in each state.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Constitution" lemma="Constitution" stem="constitut" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="simply" lemma="simply" stem="simpli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="calls" lemma="call" stem="call" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="apportioning" lemma="apportion" stem="apport" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="House" lemma="House" stem="hous" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="9" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="basis" lemma="basis" stem="basi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="whole" lemma="whole" stem="whole" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="number" lemma="number" stem="number" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="persons" lemma="person" stem="person" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="each" lemma="each" stem="each" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="state" lemma="state" stem="state" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NNP Constitution)) (ADVP (RB simply)) (VP (VBZ calls) (PP (IN for) (S (VP (VBG apportioning) (NP (DT the) (NNP House)) (PP (IN on) (NP (NP (DT the) (NN basis)) (PP (IN of) (NP (NP (DT the) (`` ``) (DT the) (JJ whole) (NN number)) (PP (IN of) (NP (NP (NNS persons)) ('' '') (PP (IN in) (NP (DT each) (NN state))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the basis" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="basis" />
          </tokens>
        </chunking>
        <chunking id="2" string="persons" type="NP">
          <tokens>
            <token id="19" string="persons" />
          </tokens>
        </chunking>
        <chunking id="3" string="the `` the whole number of persons '' in each state" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="&quot;" />
            <token id="15" string="the" />
            <token id="16" string="whole" />
            <token id="17" string="number" />
            <token id="18" string="of" />
            <token id="19" string="persons" />
            <token id="20" string="&quot;" />
            <token id="21" string="in" />
            <token id="22" string="each" />
            <token id="23" string="state" />
          </tokens>
        </chunking>
        <chunking id="4" string="persons '' in each state" type="NP">
          <tokens>
            <token id="19" string="persons" />
            <token id="20" string="&quot;" />
            <token id="21" string="in" />
            <token id="22" string="each" />
            <token id="23" string="state" />
          </tokens>
        </chunking>
        <chunking id="5" string="the House" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="House" />
          </tokens>
        </chunking>
        <chunking id="6" string="the basis of the `` the whole number of persons '' in each state" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="basis" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="&quot;" />
            <token id="15" string="the" />
            <token id="16" string="whole" />
            <token id="17" string="number" />
            <token id="18" string="of" />
            <token id="19" string="persons" />
            <token id="20" string="&quot;" />
            <token id="21" string="in" />
            <token id="22" string="each" />
            <token id="23" string="state" />
          </tokens>
        </chunking>
        <chunking id="7" string="each state" type="NP">
          <tokens>
            <token id="22" string="each" />
            <token id="23" string="state" />
          </tokens>
        </chunking>
        <chunking id="8" string="The Constitution" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Constitution" />
          </tokens>
        </chunking>
        <chunking id="9" string="the `` the whole number" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="&quot;" />
            <token id="15" string="the" />
            <token id="16" string="whole" />
            <token id="17" string="number" />
          </tokens>
        </chunking>
        <chunking id="10" string="calls for apportioning the House on the basis of the `` the whole number of persons '' in each state" type="VP">
          <tokens>
            <token id="4" string="calls" />
            <token id="5" string="for" />
            <token id="6" string="apportioning" />
            <token id="7" string="the" />
            <token id="8" string="House" />
            <token id="9" string="on" />
            <token id="10" string="the" />
            <token id="11" string="basis" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="&quot;" />
            <token id="15" string="the" />
            <token id="16" string="whole" />
            <token id="17" string="number" />
            <token id="18" string="of" />
            <token id="19" string="persons" />
            <token id="20" string="&quot;" />
            <token id="21" string="in" />
            <token id="22" string="each" />
            <token id="23" string="state" />
          </tokens>
        </chunking>
        <chunking id="11" string="apportioning the House on the basis of the `` the whole number of persons '' in each state" type="VP">
          <tokens>
            <token id="6" string="apportioning" />
            <token id="7" string="the" />
            <token id="8" string="House" />
            <token id="9" string="on" />
            <token id="10" string="the" />
            <token id="11" string="basis" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="&quot;" />
            <token id="15" string="the" />
            <token id="16" string="whole" />
            <token id="17" string="number" />
            <token id="18" string="of" />
            <token id="19" string="persons" />
            <token id="20" string="&quot;" />
            <token id="21" string="in" />
            <token id="22" string="each" />
            <token id="23" string="state" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">Constitution</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">calls</governor>
          <dependent id="2">Constitution</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">calls</governor>
          <dependent id="3">simply</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">calls</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">apportioning</governor>
          <dependent id="5">for</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">calls</governor>
          <dependent id="6">apportioning</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">House</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">apportioning</governor>
          <dependent id="8">House</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">basis</governor>
          <dependent id="9">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">basis</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">apportioning</governor>
          <dependent id="11">basis</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">number</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">number</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">number</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">number</governor>
          <dependent id="16">whole</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">basis</governor>
          <dependent id="17">number</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">persons</governor>
          <dependent id="18">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">number</governor>
          <dependent id="19">persons</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">state</governor>
          <dependent id="21">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">state</governor>
          <dependent id="22">each</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">persons</governor>
          <dependent id="23">state</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="House" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="8" string="House" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="38" has_coreference="false">
      <content>The Constitution originally called for counting &amp;quot;free persons&amp;quot; and indentured servants, and for counting slaves as three-fifths of a person.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Constitution" lemma="Constitution" stem="constitut" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="originally" lemma="originally" stem="origin" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="called" lemma="call" stem="call" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="counting" lemma="count" stem="count" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="free" lemma="free" stem="free" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="persons" lemma="person" stem="person" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="indentured" lemma="indentured" stem="indentur" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="servants" lemma="servant" stem="servant" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="counting" lemma="count" stem="count" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="slaves" lemma="slave" stem="slave" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="three-fifths" lemma="three-fifths" stem="three-fifth" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="person" lemma="person" stem="person" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NNP Constitution)) (ADVP (RB originally)) (VP (VBD called) (PP (PP (IN for) (S (VP (VBG counting) (NP (NP (`` ``) (JJ free) (NNS persons) ('' '')) (CC and) (NP (JJ indentured) (NNS servants)))))) (, ,) (CC and) (PP (IN for) (S (VP (VBG counting) (NP (NNS slaves)) (PP (IN as) (NP (NP (JJ three-fifths)) (PP (IN of) (NP (DT a) (NN person)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="`` free persons '' and indentured servants" type="NP">
          <tokens>
            <token id="7" string="&quot;" />
            <token id="8" string="free" />
            <token id="9" string="persons" />
            <token id="10" string="&quot;" />
            <token id="11" string="and" />
            <token id="12" string="indentured" />
            <token id="13" string="servants" />
          </tokens>
        </chunking>
        <chunking id="2" string="three-fifths of a person" type="NP">
          <tokens>
            <token id="20" string="three-fifths" />
            <token id="21" string="of" />
            <token id="22" string="a" />
            <token id="23" string="person" />
          </tokens>
        </chunking>
        <chunking id="3" string="slaves" type="NP">
          <tokens>
            <token id="18" string="slaves" />
          </tokens>
        </chunking>
        <chunking id="4" string="`` free persons ''" type="NP">
          <tokens>
            <token id="7" string="&quot;" />
            <token id="8" string="free" />
            <token id="9" string="persons" />
            <token id="10" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="5" string="counting `` free persons '' and indentured servants" type="VP">
          <tokens>
            <token id="6" string="counting" />
            <token id="7" string="&quot;" />
            <token id="8" string="free" />
            <token id="9" string="persons" />
            <token id="10" string="&quot;" />
            <token id="11" string="and" />
            <token id="12" string="indentured" />
            <token id="13" string="servants" />
          </tokens>
        </chunking>
        <chunking id="6" string="three-fifths" type="NP">
          <tokens>
            <token id="20" string="three-fifths" />
          </tokens>
        </chunking>
        <chunking id="7" string="The Constitution" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Constitution" />
          </tokens>
        </chunking>
        <chunking id="8" string="called for counting `` free persons '' and indentured servants , and for counting slaves as three-fifths of a person" type="VP">
          <tokens>
            <token id="4" string="called" />
            <token id="5" string="for" />
            <token id="6" string="counting" />
            <token id="7" string="&quot;" />
            <token id="8" string="free" />
            <token id="9" string="persons" />
            <token id="10" string="&quot;" />
            <token id="11" string="and" />
            <token id="12" string="indentured" />
            <token id="13" string="servants" />
            <token id="14" string="," />
            <token id="15" string="and" />
            <token id="16" string="for" />
            <token id="17" string="counting" />
            <token id="18" string="slaves" />
            <token id="19" string="as" />
            <token id="20" string="three-fifths" />
            <token id="21" string="of" />
            <token id="22" string="a" />
            <token id="23" string="person" />
          </tokens>
        </chunking>
        <chunking id="9" string="indentured servants" type="NP">
          <tokens>
            <token id="12" string="indentured" />
            <token id="13" string="servants" />
          </tokens>
        </chunking>
        <chunking id="10" string="counting slaves as three-fifths of a person" type="VP">
          <tokens>
            <token id="17" string="counting" />
            <token id="18" string="slaves" />
            <token id="19" string="as" />
            <token id="20" string="three-fifths" />
            <token id="21" string="of" />
            <token id="22" string="a" />
            <token id="23" string="person" />
          </tokens>
        </chunking>
        <chunking id="11" string="a person" type="NP">
          <tokens>
            <token id="22" string="a" />
            <token id="23" string="person" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">Constitution</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">called</governor>
          <dependent id="2">Constitution</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">called</governor>
          <dependent id="3">originally</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">called</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">counting</governor>
          <dependent id="5">for</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="4">called</governor>
          <dependent id="6">counting</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">persons</governor>
          <dependent id="8">free</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">counting</governor>
          <dependent id="9">persons</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">persons</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">servants</governor>
          <dependent id="12">indentured</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">persons</governor>
          <dependent id="13">servants</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">counting</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">counting</governor>
          <dependent id="16">for</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">counting</governor>
          <dependent id="17">counting</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">counting</governor>
          <dependent id="18">slaves</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">three-fifths</governor>
          <dependent id="19">as</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">counting</governor>
          <dependent id="20">three-fifths</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">person</governor>
          <dependent id="21">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">person</governor>
          <dependent id="22">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">three-fifths</governor>
          <dependent id="23">person</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="39" has_coreference="true">
      <content>That was changed with the passage of the 14th Amendment in 1868.</content>
      <tokens>
        <token id="1" string="That" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="changed" lemma="change" stem="chang" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="passage" lemma="passage" stem="passag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="14th" lemma="14th" stem="14th" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="true" is_refers="true" />
        <token id="10" string="Amendment" lemma="amendment" stem="amendment" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="1868" lemma="1868" stem="1868" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT That)) (VP (VBD was) (VP (VBN changed) (PP (IN with) (NP (NP (DT the) (NN passage)) (PP (IN of) (NP (NP (DT the) (JJ 14th) (NN Amendment)) (PP (IN in) (NP (CD 1868))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="That" type="NP">
          <tokens>
            <token id="1" string="That" />
          </tokens>
        </chunking>
        <chunking id="2" string="the 14th Amendment in 1868" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="14th" />
            <token id="10" string="Amendment" />
            <token id="11" string="in" />
            <token id="12" string="1868" />
          </tokens>
        </chunking>
        <chunking id="3" string="the passage" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="passage" />
          </tokens>
        </chunking>
        <chunking id="4" string="changed with the passage of the 14th Amendment in 1868" type="VP">
          <tokens>
            <token id="3" string="changed" />
            <token id="4" string="with" />
            <token id="5" string="the" />
            <token id="6" string="passage" />
            <token id="7" string="of" />
            <token id="8" string="the" />
            <token id="9" string="14th" />
            <token id="10" string="Amendment" />
            <token id="11" string="in" />
            <token id="12" string="1868" />
          </tokens>
        </chunking>
        <chunking id="5" string="the passage of the 14th Amendment in 1868" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="passage" />
            <token id="7" string="of" />
            <token id="8" string="the" />
            <token id="9" string="14th" />
            <token id="10" string="Amendment" />
            <token id="11" string="in" />
            <token id="12" string="1868" />
          </tokens>
        </chunking>
        <chunking id="6" string="was changed with the passage of the 14th Amendment in 1868" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="changed" />
            <token id="4" string="with" />
            <token id="5" string="the" />
            <token id="6" string="passage" />
            <token id="7" string="of" />
            <token id="8" string="the" />
            <token id="9" string="14th" />
            <token id="10" string="Amendment" />
            <token id="11" string="in" />
            <token id="12" string="1868" />
          </tokens>
        </chunking>
        <chunking id="7" string="the 14th Amendment" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="14th" />
            <token id="10" string="Amendment" />
          </tokens>
        </chunking>
        <chunking id="8" string="1868" type="NP">
          <tokens>
            <token id="12" string="1868" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="3">changed</governor>
          <dependent id="1">That</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="3">changed</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">changed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">passage</governor>
          <dependent id="4">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">passage</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">changed</governor>
          <dependent id="6">passage</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">Amendment</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">Amendment</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">Amendment</governor>
          <dependent id="9">14th</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">passage</governor>
          <dependent id="10">Amendment</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">1868</governor>
          <dependent id="11">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">Amendment</governor>
          <dependent id="12">1868</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="14th" type="ORDINAL" score="0.0">
          <tokens>
            <token id="9" string="14th" />
          </tokens>
        </entity>
        <entity id="2" string="1868" type="DATE" score="0.0">
          <tokens>
            <token id="12" string="1868" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="40" has_coreference="false">
      <content>Only &amp;quot;Indians not taxed&amp;quot; were excluded, but no one has fallen into that category since 1940.</content>
      <tokens>
        <token id="1" string="Only" lemma="only" stem="only" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Indians" lemma="Indians" stem="indian" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="4" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="taxed" lemma="tax" stem="tax" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="excluded" lemma="exclude" stem="exclud" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="one" lemma="one" stem="on" pos="NN" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="13" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="fallen" lemma="fall" stem="fallen" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="category" lemma="category" stem="categori" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="since" lemma="since" stem="sinc" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="1940" lemma="1940" stem="1940" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (RB Only) (S (`` ``) (S (NP (NNPS Indians)) (VP (ADVP (RB not)) (VBN taxed))) ('' '') (VP (VBD were) (VP (VBN excluded)))) (, ,) (CC but) (S (NP (DT no) (NN one)) (VP (VBZ has) (VP (VBN fallen) (PP (IN into) (NP (NP (DT that) (NN category)) (PP (IN since) (NP (CD 1940)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="were excluded" type="VP">
          <tokens>
            <token id="7" string="were" />
            <token id="8" string="excluded" />
          </tokens>
        </chunking>
        <chunking id="2" string="excluded" type="VP">
          <tokens>
            <token id="8" string="excluded" />
          </tokens>
        </chunking>
        <chunking id="3" string="not taxed" type="VP">
          <tokens>
            <token id="4" string="not" />
            <token id="5" string="taxed" />
          </tokens>
        </chunking>
        <chunking id="4" string="that category since 1940" type="NP">
          <tokens>
            <token id="16" string="that" />
            <token id="17" string="category" />
            <token id="18" string="since" />
            <token id="19" string="1940" />
          </tokens>
        </chunking>
        <chunking id="5" string="1940" type="NP">
          <tokens>
            <token id="19" string="1940" />
          </tokens>
        </chunking>
        <chunking id="6" string="Indians" type="NP">
          <tokens>
            <token id="3" string="Indians" />
          </tokens>
        </chunking>
        <chunking id="7" string="has fallen into that category since 1940" type="VP">
          <tokens>
            <token id="13" string="has" />
            <token id="14" string="fallen" />
            <token id="15" string="into" />
            <token id="16" string="that" />
            <token id="17" string="category" />
            <token id="18" string="since" />
            <token id="19" string="1940" />
          </tokens>
        </chunking>
        <chunking id="8" string="no one" type="NP">
          <tokens>
            <token id="11" string="no" />
            <token id="12" string="one" />
          </tokens>
        </chunking>
        <chunking id="9" string="fallen into that category since 1940" type="VP">
          <tokens>
            <token id="14" string="fallen" />
            <token id="15" string="into" />
            <token id="16" string="that" />
            <token id="17" string="category" />
            <token id="18" string="since" />
            <token id="19" string="1940" />
          </tokens>
        </chunking>
        <chunking id="10" string="that category" type="NP">
          <tokens>
            <token id="16" string="that" />
            <token id="17" string="category" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="8">excluded</governor>
          <dependent id="1">Only</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">taxed</governor>
          <dependent id="3">Indians</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">taxed</governor>
          <dependent id="4">not</dependent>
        </dependency>
        <dependency type="csubjpass">
          <governor id="8">excluded</governor>
          <dependent id="5">taxed</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="8">excluded</governor>
          <dependent id="7">were</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">excluded</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">excluded</governor>
          <dependent id="10">but</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="12">one</governor>
          <dependent id="11">no</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">fallen</governor>
          <dependent id="12">one</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="14">fallen</governor>
          <dependent id="13">has</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">excluded</governor>
          <dependent id="14">fallen</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">category</governor>
          <dependent id="15">into</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">category</governor>
          <dependent id="16">that</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">fallen</governor>
          <dependent id="17">category</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">1940</governor>
          <dependent id="18">since</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">category</governor>
          <dependent id="19">1940</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="12" string="one" />
          </tokens>
        </entity>
        <entity id="2" string="1940" type="DATE" score="0.0">
          <tokens>
            <token id="19" string="1940" />
          </tokens>
        </entity>
        <entity id="3" string="Indians" type="MISC" score="0.0">
          <tokens>
            <token id="3" string="Indians" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="41" has_coreference="true">
      <content>Much of the argument in Congress turns on the use of the word &amp;quot;person&amp;quot; in references to the census.</content>
      <tokens>
        <token id="1" string="Much" lemma="much" stem="much" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="argument" lemma="argument" stem="argument" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Congress" lemma="Congress" stem="congress" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="7" string="turns" lemma="turn" stem="turn" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="use" lemma="use" stem="us" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="word" lemma="word" stem="word" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="person" lemma="person" stem="person" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="references" lemma="reference" stem="refer" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="census" lemma="census" stem="censu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (JJ Much)) (PP (IN of) (NP (NP (DT the) (NN argument)) (PP (IN in) (NP (NNP Congress)))))) (VP (VBZ turns) (PP (IN on) (NP (NP (DT the) (NN use)) (PP (IN of) (NP (NP (DT the) (NN word) (`` ``) (NN person) ('' '')) (PP (IN in) (NP (NNS references))))))) (PP (TO to) (NP (DT the) (NN census)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the use of the word `` person '' in references" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="use" />
            <token id="11" string="of" />
            <token id="12" string="the" />
            <token id="13" string="word" />
            <token id="14" string="&quot;" />
            <token id="15" string="person" />
            <token id="16" string="&quot;" />
            <token id="17" string="in" />
            <token id="18" string="references" />
          </tokens>
        </chunking>
        <chunking id="2" string="turns on the use of the word `` person '' in references to the census" type="VP">
          <tokens>
            <token id="7" string="turns" />
            <token id="8" string="on" />
            <token id="9" string="the" />
            <token id="10" string="use" />
            <token id="11" string="of" />
            <token id="12" string="the" />
            <token id="13" string="word" />
            <token id="14" string="&quot;" />
            <token id="15" string="person" />
            <token id="16" string="&quot;" />
            <token id="17" string="in" />
            <token id="18" string="references" />
            <token id="19" string="to" />
            <token id="20" string="the" />
            <token id="21" string="census" />
          </tokens>
        </chunking>
        <chunking id="3" string="the argument" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="argument" />
          </tokens>
        </chunking>
        <chunking id="4" string="the census" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="census" />
          </tokens>
        </chunking>
        <chunking id="5" string="Much" type="NP">
          <tokens>
            <token id="1" string="Much" />
          </tokens>
        </chunking>
        <chunking id="6" string="the word `` person ''" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="word" />
            <token id="14" string="&quot;" />
            <token id="15" string="person" />
            <token id="16" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="7" string="references" type="NP">
          <tokens>
            <token id="18" string="references" />
          </tokens>
        </chunking>
        <chunking id="8" string="the word `` person '' in references" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="word" />
            <token id="14" string="&quot;" />
            <token id="15" string="person" />
            <token id="16" string="&quot;" />
            <token id="17" string="in" />
            <token id="18" string="references" />
          </tokens>
        </chunking>
        <chunking id="9" string="the use" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="use" />
          </tokens>
        </chunking>
        <chunking id="10" string="Much of the argument in Congress" type="NP">
          <tokens>
            <token id="1" string="Much" />
            <token id="2" string="of" />
            <token id="3" string="the" />
            <token id="4" string="argument" />
            <token id="5" string="in" />
            <token id="6" string="Congress" />
          </tokens>
        </chunking>
        <chunking id="11" string="the argument in Congress" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="argument" />
            <token id="5" string="in" />
            <token id="6" string="Congress" />
          </tokens>
        </chunking>
        <chunking id="12" string="Congress" type="NP">
          <tokens>
            <token id="6" string="Congress" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="7">turns</governor>
          <dependent id="1">Much</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">argument</governor>
          <dependent id="2">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">argument</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Much</governor>
          <dependent id="4">argument</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">Congress</governor>
          <dependent id="5">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">argument</governor>
          <dependent id="6">Congress</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">turns</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">use</governor>
          <dependent id="8">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">use</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">turns</governor>
          <dependent id="10">use</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">person</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">person</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">person</governor>
          <dependent id="13">word</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">use</governor>
          <dependent id="15">person</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">references</governor>
          <dependent id="17">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">person</governor>
          <dependent id="18">references</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">census</governor>
          <dependent id="19">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">census</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">turns</governor>
          <dependent id="21">census</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Congress" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="6" string="Congress" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="42" has_coreference="true">
      <content>Elsewhere in the Constitution, the framers used the word &amp;quot;citizen.&amp;quot;</content>
      <tokens>
        <token id="1" string="Elsewhere" lemma="elsewhere" stem="elsewher" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Constitution" lemma="Constitution" stem="constitut" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="framers" lemma="framer" stem="framer" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="used" lemma="use" stem="us" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="word" lemma="word" stem="word" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="citizen" lemma="citizen" stem="citizen" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (ADVP (RB Elsewhere)) (IN in) (NP (DT the) (NNP Constitution))) (, ,) (NP (DT the) (NNS framers)) (VP (VBD used) (NP (NP (DT the) (NN word)) (`` ``) (NP (NN citizen)))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="the framers" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="framers" />
          </tokens>
        </chunking>
        <chunking id="2" string="the word `` citizen" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="word" />
            <token id="11" string="&quot;" />
            <token id="12" string="citizen" />
          </tokens>
        </chunking>
        <chunking id="3" string="the Constitution" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="Constitution" />
          </tokens>
        </chunking>
        <chunking id="4" string="the word" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="word" />
          </tokens>
        </chunking>
        <chunking id="5" string="citizen" type="NP">
          <tokens>
            <token id="12" string="citizen" />
          </tokens>
        </chunking>
        <chunking id="6" string="used the word `` citizen" type="VP">
          <tokens>
            <token id="8" string="used" />
            <token id="9" string="the" />
            <token id="10" string="word" />
            <token id="11" string="&quot;" />
            <token id="12" string="citizen" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="4">Constitution</governor>
          <dependent id="1">Elsewhere</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">Constitution</governor>
          <dependent id="2">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">Constitution</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">used</governor>
          <dependent id="4">Constitution</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">framers</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">used</governor>
          <dependent id="7">framers</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">used</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">word</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">used</governor>
          <dependent id="10">word</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="10">word</governor>
          <dependent id="12">citizen</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="43" has_coreference="true">
      <content>They wrote, for instance, that only those who have been &amp;quot;seven years a citizen of the United States&amp;quot; can serve in the House.</content>
      <tokens>
        <token id="1" string="They" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="wrote" lemma="write" stem="wrote" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="instance" lemma="instance" stem="instanc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="only" lemma="only" stem="onli" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="those" lemma="those" stem="those" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="seven" lemma="seven" stem="seven" pos="CD" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="15" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="16" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="citizen" lemma="citizen" stem="citizen" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="United" lemma="United" stem="unite" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="21" string="States" lemma="States" stem="state" pos="NNPS" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="22" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="serve" lemma="serve" stem="serv" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="27" string="House" lemma="House" stem="hous" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP They)) (VP (VBD wrote) (, ,) (PP (IN for) (NP (NN instance))) (, ,) (SBAR (IN that) (S (NP (NP (RB only) (DT those)) (SBAR (WHNP (WP who)) (S (VP (VBP have) (VP (VBN been) (NP (`` ``) (NP (CD seven) (NNS years)) (PP (NP (DT a) (NN citizen)) (IN of) (NP (DT the) (NNP United) (NNPS States))) ('' ''))))))) (VP (MD can) (VP (VB serve) (PP (IN in) (NP (DT the) (NNP House)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="They" type="NP">
          <tokens>
            <token id="1" string="They" />
          </tokens>
        </chunking>
        <chunking id="2" string="instance" type="NP">
          <tokens>
            <token id="5" string="instance" />
          </tokens>
        </chunking>
        <chunking id="3" string="only those who have been `` seven years a citizen of the United States ''" type="NP">
          <tokens>
            <token id="8" string="only" />
            <token id="9" string="those" />
            <token id="10" string="who" />
            <token id="11" string="have" />
            <token id="12" string="been" />
            <token id="13" string="&quot;" />
            <token id="14" string="seven" />
            <token id="15" string="years" />
            <token id="16" string="a" />
            <token id="17" string="citizen" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="United" />
            <token id="21" string="States" />
            <token id="22" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="4" string="been `` seven years a citizen of the United States ''" type="VP">
          <tokens>
            <token id="12" string="been" />
            <token id="13" string="&quot;" />
            <token id="14" string="seven" />
            <token id="15" string="years" />
            <token id="16" string="a" />
            <token id="17" string="citizen" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="United" />
            <token id="21" string="States" />
            <token id="22" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="5" string="have been `` seven years a citizen of the United States ''" type="VP">
          <tokens>
            <token id="11" string="have" />
            <token id="12" string="been" />
            <token id="13" string="&quot;" />
            <token id="14" string="seven" />
            <token id="15" string="years" />
            <token id="16" string="a" />
            <token id="17" string="citizen" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="United" />
            <token id="21" string="States" />
            <token id="22" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="6" string="can serve in the House" type="VP">
          <tokens>
            <token id="23" string="can" />
            <token id="24" string="serve" />
            <token id="25" string="in" />
            <token id="26" string="the" />
            <token id="27" string="House" />
          </tokens>
        </chunking>
        <chunking id="7" string="only those" type="NP">
          <tokens>
            <token id="8" string="only" />
            <token id="9" string="those" />
          </tokens>
        </chunking>
        <chunking id="8" string="the House" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="House" />
          </tokens>
        </chunking>
        <chunking id="9" string="serve in the House" type="VP">
          <tokens>
            <token id="24" string="serve" />
            <token id="25" string="in" />
            <token id="26" string="the" />
            <token id="27" string="House" />
          </tokens>
        </chunking>
        <chunking id="10" string="`` seven years a citizen of the United States ''" type="NP">
          <tokens>
            <token id="13" string="&quot;" />
            <token id="14" string="seven" />
            <token id="15" string="years" />
            <token id="16" string="a" />
            <token id="17" string="citizen" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="United" />
            <token id="21" string="States" />
            <token id="22" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="11" string="the United States" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="United" />
            <token id="21" string="States" />
          </tokens>
        </chunking>
        <chunking id="12" string="who have been `` seven years a citizen of the United States ''" type="SBAR">
          <tokens>
            <token id="10" string="who" />
            <token id="11" string="have" />
            <token id="12" string="been" />
            <token id="13" string="&quot;" />
            <token id="14" string="seven" />
            <token id="15" string="years" />
            <token id="16" string="a" />
            <token id="17" string="citizen" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="United" />
            <token id="21" string="States" />
            <token id="22" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="13" string="a citizen" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="citizen" />
          </tokens>
        </chunking>
        <chunking id="14" string="wrote , for instance , that only those who have been `` seven years a citizen of the United States '' can serve in the House" type="VP">
          <tokens>
            <token id="2" string="wrote" />
            <token id="3" string="," />
            <token id="4" string="for" />
            <token id="5" string="instance" />
            <token id="6" string="," />
            <token id="7" string="that" />
            <token id="8" string="only" />
            <token id="9" string="those" />
            <token id="10" string="who" />
            <token id="11" string="have" />
            <token id="12" string="been" />
            <token id="13" string="&quot;" />
            <token id="14" string="seven" />
            <token id="15" string="years" />
            <token id="16" string="a" />
            <token id="17" string="citizen" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="United" />
            <token id="21" string="States" />
            <token id="22" string="&quot;" />
            <token id="23" string="can" />
            <token id="24" string="serve" />
            <token id="25" string="in" />
            <token id="26" string="the" />
            <token id="27" string="House" />
          </tokens>
        </chunking>
        <chunking id="15" string="seven years" type="NP">
          <tokens>
            <token id="14" string="seven" />
            <token id="15" string="years" />
          </tokens>
        </chunking>
        <chunking id="16" string="that only those who have been `` seven years a citizen of the United States '' can serve in the House" type="SBAR">
          <tokens>
            <token id="7" string="that" />
            <token id="8" string="only" />
            <token id="9" string="those" />
            <token id="10" string="who" />
            <token id="11" string="have" />
            <token id="12" string="been" />
            <token id="13" string="&quot;" />
            <token id="14" string="seven" />
            <token id="15" string="years" />
            <token id="16" string="a" />
            <token id="17" string="citizen" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="United" />
            <token id="21" string="States" />
            <token id="22" string="&quot;" />
            <token id="23" string="can" />
            <token id="24" string="serve" />
            <token id="25" string="in" />
            <token id="26" string="the" />
            <token id="27" string="House" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">wrote</governor>
          <dependent id="1">They</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">wrote</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">instance</governor>
          <dependent id="4">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">wrote</governor>
          <dependent id="5">instance</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="24">serve</governor>
          <dependent id="7">that</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">those</governor>
          <dependent id="8">only</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">serve</governor>
          <dependent id="9">those</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">years</governor>
          <dependent id="10">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="15">years</governor>
          <dependent id="11">have</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="15">years</governor>
          <dependent id="12">been</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="15">years</governor>
          <dependent id="14">seven</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="9">those</governor>
          <dependent id="15">years</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">citizen</governor>
          <dependent id="16">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">years</governor>
          <dependent id="17">citizen</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">citizen</governor>
          <dependent id="18">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">States</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">States</governor>
          <dependent id="20">United</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="17">citizen</governor>
          <dependent id="21">States</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="24">serve</governor>
          <dependent id="23">can</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">wrote</governor>
          <dependent id="24">serve</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">House</governor>
          <dependent id="25">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">House</governor>
          <dependent id="26">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">serve</governor>
          <dependent id="27">House</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="United States" type="LOCATION" score="0.0">
          <tokens>
            <token id="20" string="United" />
            <token id="21" string="States" />
          </tokens>
        </entity>
        <entity id="2" string="House" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="27" string="House" />
          </tokens>
        </entity>
        <entity id="3" string="seven years" type="DURATION" score="0.0">
          <tokens>
            <token id="14" string="seven" />
            <token id="15" string="years" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="44" has_coreference="true">
      <content>The word &amp;quot;person&amp;quot; was repeated in the 14th Amendment, which was drafted after the Civil War.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="word" lemma="word" stem="word" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="person" lemma="person" stem="person" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="repeated" lemma="repeat" stem="repeat" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="14th" lemma="14th" stem="14th" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="true" is_refers="false" />
        <token id="11" string="Amendment" lemma="amendment" stem="amendment" pos="NN" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="drafted" lemma="draft" stem="draft" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Civil" lemma="civil" stem="civil" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="19" string="War" lemma="war" stem="war" pos="NN" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN word) (`` ``) (NN person) ('' '')) (VP (VBD was) (VP (VBN repeated) (PP (IN in) (NP (NP (DT the) (JJ 14th) (NN Amendment)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBD was) (VP (VBN drafted) (PP (IN after) (NP (DT the) (JJ Civil) (NN War))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="repeated in the 14th Amendment , which was drafted after the Civil War" type="VP">
          <tokens>
            <token id="7" string="repeated" />
            <token id="8" string="in" />
            <token id="9" string="the" />
            <token id="10" string="14th" />
            <token id="11" string="Amendment" />
            <token id="12" string="," />
            <token id="13" string="which" />
            <token id="14" string="was" />
            <token id="15" string="drafted" />
            <token id="16" string="after" />
            <token id="17" string="the" />
            <token id="18" string="Civil" />
            <token id="19" string="War" />
          </tokens>
        </chunking>
        <chunking id="2" string="was drafted after the Civil War" type="VP">
          <tokens>
            <token id="14" string="was" />
            <token id="15" string="drafted" />
            <token id="16" string="after" />
            <token id="17" string="the" />
            <token id="18" string="Civil" />
            <token id="19" string="War" />
          </tokens>
        </chunking>
        <chunking id="3" string="was repeated in the 14th Amendment , which was drafted after the Civil War" type="VP">
          <tokens>
            <token id="6" string="was" />
            <token id="7" string="repeated" />
            <token id="8" string="in" />
            <token id="9" string="the" />
            <token id="10" string="14th" />
            <token id="11" string="Amendment" />
            <token id="12" string="," />
            <token id="13" string="which" />
            <token id="14" string="was" />
            <token id="15" string="drafted" />
            <token id="16" string="after" />
            <token id="17" string="the" />
            <token id="18" string="Civil" />
            <token id="19" string="War" />
          </tokens>
        </chunking>
        <chunking id="4" string="The word `` person ''" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="word" />
            <token id="3" string="&quot;" />
            <token id="4" string="person" />
            <token id="5" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="5" string="drafted after the Civil War" type="VP">
          <tokens>
            <token id="15" string="drafted" />
            <token id="16" string="after" />
            <token id="17" string="the" />
            <token id="18" string="Civil" />
            <token id="19" string="War" />
          </tokens>
        </chunking>
        <chunking id="6" string="which was drafted after the Civil War" type="SBAR">
          <tokens>
            <token id="13" string="which" />
            <token id="14" string="was" />
            <token id="15" string="drafted" />
            <token id="16" string="after" />
            <token id="17" string="the" />
            <token id="18" string="Civil" />
            <token id="19" string="War" />
          </tokens>
        </chunking>
        <chunking id="7" string="the 14th Amendment" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="14th" />
            <token id="11" string="Amendment" />
          </tokens>
        </chunking>
        <chunking id="8" string="the Civil War" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="Civil" />
            <token id="19" string="War" />
          </tokens>
        </chunking>
        <chunking id="9" string="the 14th Amendment , which was drafted after the Civil War" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="14th" />
            <token id="11" string="Amendment" />
            <token id="12" string="," />
            <token id="13" string="which" />
            <token id="14" string="was" />
            <token id="15" string="drafted" />
            <token id="16" string="after" />
            <token id="17" string="the" />
            <token id="18" string="Civil" />
            <token id="19" string="War" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="4">person</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">person</governor>
          <dependent id="2">word</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="7">repeated</governor>
          <dependent id="4">person</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="7">repeated</governor>
          <dependent id="6">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">repeated</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Amendment</governor>
          <dependent id="8">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">Amendment</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">Amendment</governor>
          <dependent id="10">14th</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">repeated</governor>
          <dependent id="11">Amendment</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="15">drafted</governor>
          <dependent id="13">which</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="15">drafted</governor>
          <dependent id="14">was</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="11">Amendment</governor>
          <dependent id="15">drafted</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">War</governor>
          <dependent id="16">after</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">War</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">War</governor>
          <dependent id="18">Civil</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">drafted</governor>
          <dependent id="19">War</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="14th" type="ORDINAL" score="0.0">
          <tokens>
            <token id="10" string="14th" />
          </tokens>
        </entity>
        <entity id="2" string="Amendment" type="MISC" score="0.0">
          <tokens>
            <token id="11" string="Amendment" />
          </tokens>
        </entity>
        <entity id="3" string="Civil War" type="MISC" score="0.0">
          <tokens>
            <token id="18" string="Civil" />
            <token id="19" string="War" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="45" has_coreference="true">
      <content>Those in Congress and at the Census Bureau who favor continuing the practice of counting all residents of the U.S. conclude that this language unambiguously resolves the debate.</content>
      <tokens>
        <token id="1" string="Those" lemma="those" stem="those" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="Congress" lemma="Congress" stem="congress" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="4" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="7" string="Census" lemma="Census" stem="censu" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="8" string="Bureau" lemma="Bureau" stem="bureau" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="9" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="10" string="favor" lemma="favor" stem="favor" pos="VBP" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="11" string="continuing" lemma="continue" stem="continu" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="13" string="practice" lemma="practice" stem="practic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="14" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="15" string="counting" lemma="count" stem="count" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="16" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="17" string="residents" lemma="resident" stem="resid" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="18" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="20" string="U.S." lemma="U.S." stem="u.s." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="true" />
        <token id="21" string="conclude" lemma="conclude" stem="conclud" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="language" lemma="language" stem="languag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="unambiguously" lemma="unambiguously" stem="unambigu" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="resolves" lemma="resolve" stem="resolv" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="28" string="debate" lemma="debate" stem="debat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT Those)) (PP (PP (IN in) (NP (NNP Congress))) (CC and) (PP (IN at) (NP (NP (DT the) (NNP Census) (NNP Bureau)) (SBAR (WHNP (WP who)) (S (VP (VBP favor) (S (VP (VBG continuing) (NP (NP (DT the) (NN practice)) (PP (IN of) (S (VP (VBG counting) (NP (NP (DT all) (NNS residents)) (PP (IN of) (NP (DT the) (NNP U.S.))))))))))))))))) (VP (VBP conclude) (SBAR (IN that) (S (NP (DT this) (NN language)) (ADVP (RB unambiguously)) (VP (VBZ resolves) (NP (DT the) (NN debate)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the practice" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="practice" />
          </tokens>
        </chunking>
        <chunking id="2" string="who favor continuing the practice of counting all residents of the U.S." type="SBAR">
          <tokens>
            <token id="9" string="who" />
            <token id="10" string="favor" />
            <token id="11" string="continuing" />
            <token id="12" string="the" />
            <token id="13" string="practice" />
            <token id="14" string="of" />
            <token id="15" string="counting" />
            <token id="16" string="all" />
            <token id="17" string="residents" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="U.S." />
          </tokens>
        </chunking>
        <chunking id="3" string="the Census Bureau who favor continuing the practice of counting all residents of the U.S." type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="Census" />
            <token id="8" string="Bureau" />
            <token id="9" string="who" />
            <token id="10" string="favor" />
            <token id="11" string="continuing" />
            <token id="12" string="the" />
            <token id="13" string="practice" />
            <token id="14" string="of" />
            <token id="15" string="counting" />
            <token id="16" string="all" />
            <token id="17" string="residents" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="U.S." />
          </tokens>
        </chunking>
        <chunking id="4" string="the Census Bureau" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="Census" />
            <token id="8" string="Bureau" />
          </tokens>
        </chunking>
        <chunking id="5" string="Those in Congress and at the Census Bureau who favor continuing the practice of counting all residents of the U.S." type="NP">
          <tokens>
            <token id="1" string="Those" />
            <token id="2" string="in" />
            <token id="3" string="Congress" />
            <token id="4" string="and" />
            <token id="5" string="at" />
            <token id="6" string="the" />
            <token id="7" string="Census" />
            <token id="8" string="Bureau" />
            <token id="9" string="who" />
            <token id="10" string="favor" />
            <token id="11" string="continuing" />
            <token id="12" string="the" />
            <token id="13" string="practice" />
            <token id="14" string="of" />
            <token id="15" string="counting" />
            <token id="16" string="all" />
            <token id="17" string="residents" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="U.S." />
          </tokens>
        </chunking>
        <chunking id="6" string="continuing the practice of counting all residents of the U.S." type="VP">
          <tokens>
            <token id="11" string="continuing" />
            <token id="12" string="the" />
            <token id="13" string="practice" />
            <token id="14" string="of" />
            <token id="15" string="counting" />
            <token id="16" string="all" />
            <token id="17" string="residents" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="U.S." />
          </tokens>
        </chunking>
        <chunking id="7" string="resolves the debate" type="VP">
          <tokens>
            <token id="26" string="resolves" />
            <token id="27" string="the" />
            <token id="28" string="debate" />
          </tokens>
        </chunking>
        <chunking id="8" string="the debate" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="debate" />
          </tokens>
        </chunking>
        <chunking id="9" string="this language" type="NP">
          <tokens>
            <token id="23" string="this" />
            <token id="24" string="language" />
          </tokens>
        </chunking>
        <chunking id="10" string="Congress" type="NP">
          <tokens>
            <token id="3" string="Congress" />
          </tokens>
        </chunking>
        <chunking id="11" string="conclude that this language unambiguously resolves the debate" type="VP">
          <tokens>
            <token id="21" string="conclude" />
            <token id="22" string="that" />
            <token id="23" string="this" />
            <token id="24" string="language" />
            <token id="25" string="unambiguously" />
            <token id="26" string="resolves" />
            <token id="27" string="the" />
            <token id="28" string="debate" />
          </tokens>
        </chunking>
        <chunking id="12" string="all residents of the U.S." type="NP">
          <tokens>
            <token id="16" string="all" />
            <token id="17" string="residents" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="U.S." />
          </tokens>
        </chunking>
        <chunking id="13" string="the practice of counting all residents of the U.S." type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="practice" />
            <token id="14" string="of" />
            <token id="15" string="counting" />
            <token id="16" string="all" />
            <token id="17" string="residents" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="U.S." />
          </tokens>
        </chunking>
        <chunking id="14" string="favor continuing the practice of counting all residents of the U.S." type="VP">
          <tokens>
            <token id="10" string="favor" />
            <token id="11" string="continuing" />
            <token id="12" string="the" />
            <token id="13" string="practice" />
            <token id="14" string="of" />
            <token id="15" string="counting" />
            <token id="16" string="all" />
            <token id="17" string="residents" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="U.S." />
          </tokens>
        </chunking>
        <chunking id="15" string="the U.S." type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="U.S." />
          </tokens>
        </chunking>
        <chunking id="16" string="all residents" type="NP">
          <tokens>
            <token id="16" string="all" />
            <token id="17" string="residents" />
          </tokens>
        </chunking>
        <chunking id="17" string="Those" type="NP">
          <tokens>
            <token id="1" string="Those" />
          </tokens>
        </chunking>
        <chunking id="18" string="that this language unambiguously resolves the debate" type="SBAR">
          <tokens>
            <token id="22" string="that" />
            <token id="23" string="this" />
            <token id="24" string="language" />
            <token id="25" string="unambiguously" />
            <token id="26" string="resolves" />
            <token id="27" string="the" />
            <token id="28" string="debate" />
          </tokens>
        </chunking>
        <chunking id="19" string="counting all residents of the U.S." type="VP">
          <tokens>
            <token id="15" string="counting" />
            <token id="16" string="all" />
            <token id="17" string="residents" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="U.S." />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="conj">
          <governor id="1">Those</governor>
          <dependent id="1">Those</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">conclude</governor>
          <dependent id="1">Those</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">Congress</governor>
          <dependent id="2">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Those</governor>
          <dependent id="3">Congress</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="1">Those</governor>
          <dependent id="4">and</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">Bureau</governor>
          <dependent id="5">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">Bureau</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">Bureau</governor>
          <dependent id="7">Census</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Those</governor>
          <dependent id="8">Bureau</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">favor</governor>
          <dependent id="9">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="8">Bureau</governor>
          <dependent id="10">favor</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="10">favor</governor>
          <dependent id="11">continuing</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">practice</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">continuing</governor>
          <dependent id="13">practice</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">counting</governor>
          <dependent id="14">of</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="13">practice</governor>
          <dependent id="15">counting</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">residents</governor>
          <dependent id="16">all</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">counting</governor>
          <dependent id="17">residents</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">U.S.</governor>
          <dependent id="18">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">U.S.</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">residents</governor>
          <dependent id="20">U.S.</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="21">conclude</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="26">resolves</governor>
          <dependent id="22">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">language</governor>
          <dependent id="23">this</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">resolves</governor>
          <dependent id="24">language</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="26">resolves</governor>
          <dependent id="25">unambiguously</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="21">conclude</governor>
          <dependent id="26">resolves</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">debate</governor>
          <dependent id="27">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="26">resolves</governor>
          <dependent id="28">debate</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="U.S." type="LOCATION" score="0.0">
          <tokens>
            <token id="20" string="U.S." />
          </tokens>
        </entity>
        <entity id="2" string="Census Bureau" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="7" string="Census" />
            <token id="8" string="Bureau" />
          </tokens>
        </entity>
        <entity id="3" string="Congress" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="3" string="Congress" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="46" has_coreference="true">
      <content>Their opponents say the drafters of the Constitution and the 14th Amendment never even considered the concept of an &amp;quot;illegal immigrant,&amp;quot; let alone contemplated their current numbers.</content>
      <tokens>
        <token id="1" string="Their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="opponents" lemma="opponent" stem="oppon" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="say" lemma="say" stem="sai" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="drafters" lemma="drafter" stem="drafter" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Constitution" lemma="Constitution" stem="constitut" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="14th" lemma="14th" stem="14th" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="12" string="Amendment" lemma="amendment" stem="amendment" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="considered" lemma="consider" stem="consid" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="concept" lemma="concept" stem="concept" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="illegal" lemma="illegal" stem="illeg" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="immigrant" lemma="immigrant" stem="immigr" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="let" lemma="let" stem="let" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="alone" lemma="alone" stem="alon" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="contemplated" lemma="contemplate" stem="contempl" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="29" string="current" lemma="current" stem="current" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="30" string="numbers" lemma="number" stem="number" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP$ Their) (NNS opponents)) (VP (VBP say) (NP (NP (DT the) (NNS drafters)) (PP (IN of) (NP (NP (DT the) (NNP Constitution)) (CC and) (NP (DT the) (JJ 14th) (NN Amendment))))) (SBAR (ADVP (RB never)) (RB even) (FRAG (VP (VBN considered) (NP (NP (DT the) (NN concept)) (PP (IN of) (NP (NP (DT an) (`` ``) (JJ illegal)) (JJ immigrant)))) (, ,) ('' '') (S (VP (VB let) (VP (ADVP (RB alone)) (VBN contemplated) (NP (PRP$ their) (JJ current) (NNS numbers))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the concept of an `` illegal immigrant" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="concept" />
            <token id="18" string="of" />
            <token id="19" string="an" />
            <token id="20" string="&quot;" />
            <token id="21" string="illegal" />
            <token id="22" string="immigrant" />
          </tokens>
        </chunking>
        <chunking id="2" string="their current numbers" type="NP">
          <tokens>
            <token id="28" string="their" />
            <token id="29" string="current" />
            <token id="30" string="numbers" />
          </tokens>
        </chunking>
        <chunking id="3" string="the Constitution and the 14th Amendment" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="Constitution" />
            <token id="9" string="and" />
            <token id="10" string="the" />
            <token id="11" string="14th" />
            <token id="12" string="Amendment" />
          </tokens>
        </chunking>
        <chunking id="4" string="the Constitution" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="Constitution" />
          </tokens>
        </chunking>
        <chunking id="5" string="let alone contemplated their current numbers" type="VP">
          <tokens>
            <token id="25" string="let" />
            <token id="26" string="alone" />
            <token id="27" string="contemplated" />
            <token id="28" string="their" />
            <token id="29" string="current" />
            <token id="30" string="numbers" />
          </tokens>
        </chunking>
        <chunking id="6" string="an `` illegal immigrant" type="NP">
          <tokens>
            <token id="19" string="an" />
            <token id="20" string="&quot;" />
            <token id="21" string="illegal" />
            <token id="22" string="immigrant" />
          </tokens>
        </chunking>
        <chunking id="7" string="an `` illegal" type="NP">
          <tokens>
            <token id="19" string="an" />
            <token id="20" string="&quot;" />
            <token id="21" string="illegal" />
          </tokens>
        </chunking>
        <chunking id="8" string="the 14th Amendment" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="14th" />
            <token id="12" string="Amendment" />
          </tokens>
        </chunking>
        <chunking id="9" string="Their opponents" type="NP">
          <tokens>
            <token id="1" string="Their" />
            <token id="2" string="opponents" />
          </tokens>
        </chunking>
        <chunking id="10" string="alone contemplated their current numbers" type="VP">
          <tokens>
            <token id="26" string="alone" />
            <token id="27" string="contemplated" />
            <token id="28" string="their" />
            <token id="29" string="current" />
            <token id="30" string="numbers" />
          </tokens>
        </chunking>
        <chunking id="11" string="say the drafters of the Constitution and the 14th Amendment never even considered the concept of an `` illegal immigrant , '' let alone contemplated their current numbers" type="VP">
          <tokens>
            <token id="3" string="say" />
            <token id="4" string="the" />
            <token id="5" string="drafters" />
            <token id="6" string="of" />
            <token id="7" string="the" />
            <token id="8" string="Constitution" />
            <token id="9" string="and" />
            <token id="10" string="the" />
            <token id="11" string="14th" />
            <token id="12" string="Amendment" />
            <token id="13" string="never" />
            <token id="14" string="even" />
            <token id="15" string="considered" />
            <token id="16" string="the" />
            <token id="17" string="concept" />
            <token id="18" string="of" />
            <token id="19" string="an" />
            <token id="20" string="&quot;" />
            <token id="21" string="illegal" />
            <token id="22" string="immigrant" />
            <token id="23" string="," />
            <token id="24" string="&quot;" />
            <token id="25" string="let" />
            <token id="26" string="alone" />
            <token id="27" string="contemplated" />
            <token id="28" string="their" />
            <token id="29" string="current" />
            <token id="30" string="numbers" />
          </tokens>
        </chunking>
        <chunking id="12" string="the drafters of the Constitution and the 14th Amendment" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="drafters" />
            <token id="6" string="of" />
            <token id="7" string="the" />
            <token id="8" string="Constitution" />
            <token id="9" string="and" />
            <token id="10" string="the" />
            <token id="11" string="14th" />
            <token id="12" string="Amendment" />
          </tokens>
        </chunking>
        <chunking id="13" string="the concept" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="concept" />
          </tokens>
        </chunking>
        <chunking id="14" string="never even considered the concept of an `` illegal immigrant , '' let alone contemplated their current numbers" type="SBAR">
          <tokens>
            <token id="13" string="never" />
            <token id="14" string="even" />
            <token id="15" string="considered" />
            <token id="16" string="the" />
            <token id="17" string="concept" />
            <token id="18" string="of" />
            <token id="19" string="an" />
            <token id="20" string="&quot;" />
            <token id="21" string="illegal" />
            <token id="22" string="immigrant" />
            <token id="23" string="," />
            <token id="24" string="&quot;" />
            <token id="25" string="let" />
            <token id="26" string="alone" />
            <token id="27" string="contemplated" />
            <token id="28" string="their" />
            <token id="29" string="current" />
            <token id="30" string="numbers" />
          </tokens>
        </chunking>
        <chunking id="15" string="the drafters" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="drafters" />
          </tokens>
        </chunking>
        <chunking id="16" string="considered the concept of an `` illegal immigrant , '' let alone contemplated their current numbers" type="VP">
          <tokens>
            <token id="15" string="considered" />
            <token id="16" string="the" />
            <token id="17" string="concept" />
            <token id="18" string="of" />
            <token id="19" string="an" />
            <token id="20" string="&quot;" />
            <token id="21" string="illegal" />
            <token id="22" string="immigrant" />
            <token id="23" string="," />
            <token id="24" string="&quot;" />
            <token id="25" string="let" />
            <token id="26" string="alone" />
            <token id="27" string="contemplated" />
            <token id="28" string="their" />
            <token id="29" string="current" />
            <token id="30" string="numbers" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="2">opponents</governor>
          <dependent id="1">Their</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">say</governor>
          <dependent id="2">opponents</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">say</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">drafters</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">say</governor>
          <dependent id="5">drafters</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">Constitution</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">Constitution</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">drafters</governor>
          <dependent id="8">Constitution</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">Constitution</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">Amendment</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">Amendment</governor>
          <dependent id="11">14th</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">Constitution</governor>
          <dependent id="12">Amendment</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="15">considered</governor>
          <dependent id="13">never</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">considered</governor>
          <dependent id="14">even</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="3">say</governor>
          <dependent id="15">considered</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">concept</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">considered</governor>
          <dependent id="17">concept</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">illegal</governor>
          <dependent id="18">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">illegal</governor>
          <dependent id="19">an</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">concept</governor>
          <dependent id="21">illegal</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">illegal</governor>
          <dependent id="22">immigrant</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="15">considered</governor>
          <dependent id="25">let</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="27">contemplated</governor>
          <dependent id="26">alone</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="25">let</governor>
          <dependent id="27">contemplated</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="30">numbers</governor>
          <dependent id="28">their</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="30">numbers</governor>
          <dependent id="29">current</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="27">contemplated</governor>
          <dependent id="30">numbers</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="14th" type="ORDINAL" score="0.0">
          <tokens>
            <token id="11" string="14th" />
          </tokens>
        </entity>
        <entity id="2" string="current" type="DATE" score="0.0">
          <tokens>
            <token id="29" string="current" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="47" has_coreference="true">
      <content>--- @ Estimates of Illegal Aliens @ Counted in 1980 Census @ TOTAL U.S. 2,057,000 @ California 1,024,000 @ New York 234,000 @ Texas 186,000 @ Illinois 135,000 @ Florida 80,000 @ Source: Census Bureau</content>
      <tokens>
        <token id="1" string="---" lemma="--" stem="---" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="@" lemma="@" stem="@" pos="SYM" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Estimates" lemma="estimate" stem="estimat" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Illegal" lemma="illegal" stem="illegal" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="Aliens" lemma="alien" stem="alien" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="@" lemma="@" stem="@" pos="IN" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Counted" lemma="count" stem="count" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="1980" lemma="1980" stem="1980" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="11" string="Census" lemma="Census" stem="censu" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="@" lemma="@" stem="@" pos="IN" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="TOTAL" lemma="total" stem="total" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="U.S." lemma="U.S." stem="u.s." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="15" string="2,057,000" lemma="2,057,000" stem="2,057,000" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="16" string="@" lemma="@" stem="@" pos="IN" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="California" lemma="California" stem="california" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="18" string="1,024,000" lemma="1,024,000" stem="1,024,000" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="19" string="@" lemma="@" stem="@" pos="IN" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="New" lemma="New" stem="new" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="21" string="York" lemma="York" stem="york" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="22" string="234,000" lemma="234,000" stem="234,000" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="23" string="@" lemma="@" stem="@" pos="SYM" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="Texas" lemma="Texas" stem="texa" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="25" string="186,000" lemma="186,000" stem="186,000" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="26" string="@" lemma="@" stem="@" pos="IN" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="Illinois" lemma="Illinois" stem="illinoi" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="28" string="135,000" lemma="135,000" stem="135,000" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="29" string="@" lemma="@" stem="@" pos="SYM" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="Florida" lemma="Florida" stem="florida" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="31" string="80,000" lemma="80,000" stem="80,000" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="32" string="@" lemma="@" stem="@" pos="IN" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="Source" lemma="source" stem="sourc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="Census" lemma="Census" stem="censu" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="36" string="Bureau" lemma="Bureau" stem="bureau" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (PRN (: --) (FRAG (X (X (SYM @)) (NP (NNS Estimates))) (PP (IN of) (NP (JJ Illegal))))) (NNS Aliens)) (SBAR (IN @) (SINV (VP (VBN Counted) (PP (IN in) (NP (NP (CD 1980) (NNP Census)) (PP (IN @) (NP (JJ TOTAL) (NNP U.S.) (CD 2,057,000))))) (PP (IN @) (NP (NNP California) (CD 1,024,000))) (PP (IN @) (NP (NP (NNP New) (NNP York) (CD 234,000)) (X (X (SYM @)) (NP (NP (NNP Texas) (CD 186,000)) (PP (IN @) (NP (NNP Illinois) (CD 135,000)) (X (X (SYM @)) (NP (NP (NNP Florida) (CD 80,000)) (PP (IN @) (NP (NN Source))))))))))) (: :) (NP (NNP Census) (NNP Bureau)))))))</syntactictree>
      <chunkings>
        <chunking id="1" string="Florida 80,000 @ Source" type="NP">
          <tokens>
            <token id="30" string="Florida" />
            <token id="31" string="80,000" />
            <token id="32" string="@" />
            <token id="33" string="Source" />
          </tokens>
        </chunking>
        <chunking id="2" string="1980 Census @ TOTAL U.S. 2,057,000" type="NP">
          <tokens>
            <token id="10" string="1980" />
            <token id="11" string="Census" />
            <token id="12" string="@" />
            <token id="13" string="TOTAL" />
            <token id="14" string="U.S." />
            <token id="15" string="2,057,000" />
          </tokens>
        </chunking>
        <chunking id="3" string="Illegal" type="NP">
          <tokens>
            <token id="5" string="Illegal" />
          </tokens>
        </chunking>
        <chunking id="4" string="Texas 186,000" type="NP">
          <tokens>
            <token id="24" string="Texas" />
            <token id="25" string="186,000" />
          </tokens>
        </chunking>
        <chunking id="5" string="New York 234,000" type="NP">
          <tokens>
            <token id="20" string="New" />
            <token id="21" string="York" />
            <token id="22" string="234,000" />
          </tokens>
        </chunking>
        <chunking id="6" string="Census Bureau" type="NP">
          <tokens>
            <token id="35" string="Census" />
            <token id="36" string="Bureau" />
          </tokens>
        </chunking>
        <chunking id="7" string="-- @ Estimates of Illegal Aliens" type="NP">
          <tokens>
            <token id="1" string="---" />
            <token id="2" string="@" />
            <token id="3" string="Estimates" />
            <token id="4" string="of" />
            <token id="5" string="Illegal" />
            <token id="6" string="Aliens" />
          </tokens>
        </chunking>
        <chunking id="8" string="TOTAL U.S. 2,057,000" type="NP">
          <tokens>
            <token id="13" string="TOTAL" />
            <token id="14" string="U.S." />
            <token id="15" string="2,057,000" />
          </tokens>
        </chunking>
        <chunking id="9" string="Estimates" type="NP">
          <tokens>
            <token id="3" string="Estimates" />
          </tokens>
        </chunking>
        <chunking id="10" string="New York 234,000 @ Texas 186,000 @ Illinois 135,000 @ Florida 80,000 @ Source" type="NP">
          <tokens>
            <token id="20" string="New" />
            <token id="21" string="York" />
            <token id="22" string="234,000" />
            <token id="23" string="@" />
            <token id="24" string="Texas" />
            <token id="25" string="186,000" />
            <token id="26" string="@" />
            <token id="27" string="Illinois" />
            <token id="28" string="135,000" />
            <token id="29" string="@" />
            <token id="30" string="Florida" />
            <token id="31" string="80,000" />
            <token id="32" string="@" />
            <token id="33" string="Source" />
          </tokens>
        </chunking>
        <chunking id="11" string="Source" type="NP">
          <tokens>
            <token id="33" string="Source" />
          </tokens>
        </chunking>
        <chunking id="12" string="California 1,024,000" type="NP">
          <tokens>
            <token id="17" string="California" />
            <token id="18" string="1,024,000" />
          </tokens>
        </chunking>
        <chunking id="13" string="Texas 186,000 @ Illinois 135,000 @ Florida 80,000 @ Source" type="NP">
          <tokens>
            <token id="24" string="Texas" />
            <token id="25" string="186,000" />
            <token id="26" string="@" />
            <token id="27" string="Illinois" />
            <token id="28" string="135,000" />
            <token id="29" string="@" />
            <token id="30" string="Florida" />
            <token id="31" string="80,000" />
            <token id="32" string="@" />
            <token id="33" string="Source" />
          </tokens>
        </chunking>
        <chunking id="14" string="Illinois 135,000" type="NP">
          <tokens>
            <token id="27" string="Illinois" />
            <token id="28" string="135,000" />
          </tokens>
        </chunking>
        <chunking id="15" string="-- @ Estimates of Illegal Aliens @ Counted in 1980 Census @ TOTAL U.S. 2,057,000 @ California 1,024,000 @ New York 234,000 @ Texas 186,000 @ Illinois 135,000 @ Florida 80,000 @ Source : Census Bureau" type="NP">
          <tokens>
            <token id="1" string="---" />
            <token id="2" string="@" />
            <token id="3" string="Estimates" />
            <token id="4" string="of" />
            <token id="5" string="Illegal" />
            <token id="6" string="Aliens" />
            <token id="7" string="@" />
            <token id="8" string="Counted" />
            <token id="9" string="in" />
            <token id="10" string="1980" />
            <token id="11" string="Census" />
            <token id="12" string="@" />
            <token id="13" string="TOTAL" />
            <token id="14" string="U.S." />
            <token id="15" string="2,057,000" />
            <token id="16" string="@" />
            <token id="17" string="California" />
            <token id="18" string="1,024,000" />
            <token id="19" string="@" />
            <token id="20" string="New" />
            <token id="21" string="York" />
            <token id="22" string="234,000" />
            <token id="23" string="@" />
            <token id="24" string="Texas" />
            <token id="25" string="186,000" />
            <token id="26" string="@" />
            <token id="27" string="Illinois" />
            <token id="28" string="135,000" />
            <token id="29" string="@" />
            <token id="30" string="Florida" />
            <token id="31" string="80,000" />
            <token id="32" string="@" />
            <token id="33" string="Source" />
            <token id="34" string=":" />
            <token id="35" string="Census" />
            <token id="36" string="Bureau" />
          </tokens>
        </chunking>
        <chunking id="16" string="Counted in 1980 Census @ TOTAL U.S. 2,057,000 @ California 1,024,000 @ New York 234,000 @ Texas 186,000 @ Illinois 135,000 @ Florida 80,000 @ Source" type="VP">
          <tokens>
            <token id="8" string="Counted" />
            <token id="9" string="in" />
            <token id="10" string="1980" />
            <token id="11" string="Census" />
            <token id="12" string="@" />
            <token id="13" string="TOTAL" />
            <token id="14" string="U.S." />
            <token id="15" string="2,057,000" />
            <token id="16" string="@" />
            <token id="17" string="California" />
            <token id="18" string="1,024,000" />
            <token id="19" string="@" />
            <token id="20" string="New" />
            <token id="21" string="York" />
            <token id="22" string="234,000" />
            <token id="23" string="@" />
            <token id="24" string="Texas" />
            <token id="25" string="186,000" />
            <token id="26" string="@" />
            <token id="27" string="Illinois" />
            <token id="28" string="135,000" />
            <token id="29" string="@" />
            <token id="30" string="Florida" />
            <token id="31" string="80,000" />
            <token id="32" string="@" />
            <token id="33" string="Source" />
          </tokens>
        </chunking>
        <chunking id="17" string="1980 Census" type="NP">
          <tokens>
            <token id="10" string="1980" />
            <token id="11" string="Census" />
          </tokens>
        </chunking>
        <chunking id="18" string="@ Counted in 1980 Census @ TOTAL U.S. 2,057,000 @ California 1,024,000 @ New York 234,000 @ Texas 186,000 @ Illinois 135,000 @ Florida 80,000 @ Source : Census Bureau" type="SBAR">
          <tokens>
            <token id="7" string="@" />
            <token id="8" string="Counted" />
            <token id="9" string="in" />
            <token id="10" string="1980" />
            <token id="11" string="Census" />
            <token id="12" string="@" />
            <token id="13" string="TOTAL" />
            <token id="14" string="U.S." />
            <token id="15" string="2,057,000" />
            <token id="16" string="@" />
            <token id="17" string="California" />
            <token id="18" string="1,024,000" />
            <token id="19" string="@" />
            <token id="20" string="New" />
            <token id="21" string="York" />
            <token id="22" string="234,000" />
            <token id="23" string="@" />
            <token id="24" string="Texas" />
            <token id="25" string="186,000" />
            <token id="26" string="@" />
            <token id="27" string="Illinois" />
            <token id="28" string="135,000" />
            <token id="29" string="@" />
            <token id="30" string="Florida" />
            <token id="31" string="80,000" />
            <token id="32" string="@" />
            <token id="33" string="Source" />
            <token id="34" string=":" />
            <token id="35" string="Census" />
            <token id="36" string="Bureau" />
          </tokens>
        </chunking>
        <chunking id="19" string="Florida 80,000" type="NP">
          <tokens>
            <token id="30" string="Florida" />
            <token id="31" string="80,000" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="dep">
          <governor id="3">Estimates</governor>
          <dependent id="2">@</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="6">Aliens</governor>
          <dependent id="3">Estimates</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">Illegal</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">Estimates</governor>
          <dependent id="5">Illegal</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">Aliens</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="8">Counted</governor>
          <dependent id="7">@</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="6">Aliens</governor>
          <dependent id="8">Counted</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Census</governor>
          <dependent id="9">in</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="11">Census</governor>
          <dependent id="10">1980</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">Counted</governor>
          <dependent id="11">Census</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">U.S.</governor>
          <dependent id="12">@</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">U.S.</governor>
          <dependent id="13">TOTAL</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">Census</governor>
          <dependent id="14">U.S.</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="14">U.S.</governor>
          <dependent id="15">2,057,000</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">California</governor>
          <dependent id="16">@</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">Counted</governor>
          <dependent id="17">California</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="17">California</governor>
          <dependent id="18">1,024,000</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">York</governor>
          <dependent id="19">@</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">York</governor>
          <dependent id="20">New</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">Counted</governor>
          <dependent id="21">York</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="21">York</governor>
          <dependent id="22">234,000</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="24">Texas</governor>
          <dependent id="23">@</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="21">York</governor>
          <dependent id="24">Texas</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="24">Texas</governor>
          <dependent id="25">186,000</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">Illinois</governor>
          <dependent id="26">@</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">Texas</governor>
          <dependent id="27">Illinois</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="27">Illinois</governor>
          <dependent id="28">135,000</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="30">Florida</governor>
          <dependent id="29">@</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="27">Illinois</governor>
          <dependent id="30">Florida</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="30">Florida</governor>
          <dependent id="31">80,000</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">Source</governor>
          <dependent id="32">@</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">Florida</governor>
          <dependent id="33">Source</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="36">Bureau</governor>
          <dependent id="35">Census</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="8">Counted</governor>
          <dependent id="36">Bureau</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="New York" type="LOCATION" score="0.0">
          <tokens>
            <token id="20" string="New" />
            <token id="21" string="York" />
          </tokens>
        </entity>
        <entity id="2" string="1,024,000" type="NUMBER" score="0.0">
          <tokens>
            <token id="18" string="1,024,000" />
          </tokens>
        </entity>
        <entity id="3" string="California" type="LOCATION" score="0.0">
          <tokens>
            <token id="17" string="California" />
          </tokens>
        </entity>
        <entity id="4" string="234,000" type="NUMBER" score="0.0">
          <tokens>
            <token id="22" string="234,000" />
          </tokens>
        </entity>
        <entity id="5" string="1980" type="DATE" score="0.0">
          <tokens>
            <token id="10" string="1980" />
          </tokens>
        </entity>
        <entity id="6" string="Census Bureau" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="35" string="Census" />
            <token id="36" string="Bureau" />
          </tokens>
        </entity>
        <entity id="7" string="Florida" type="LOCATION" score="0.0">
          <tokens>
            <token id="30" string="Florida" />
          </tokens>
        </entity>
        <entity id="8" string="135,000" type="NUMBER" score="0.0">
          <tokens>
            <token id="28" string="135,000" />
          </tokens>
        </entity>
        <entity id="9" string="2,057,000" type="NUMBER" score="0.0">
          <tokens>
            <token id="15" string="2,057,000" />
          </tokens>
        </entity>
        <entity id="10" string="80,000" type="NUMBER" score="0.0">
          <tokens>
            <token id="31" string="80,000" />
          </tokens>
        </entity>
        <entity id="11" string="U.S." type="LOCATION" score="0.0">
          <tokens>
            <token id="14" string="U.S." />
          </tokens>
        </entity>
        <entity id="12" string="Texas" type="LOCATION" score="0.0">
          <tokens>
            <token id="24" string="Texas" />
          </tokens>
        </entity>
        <entity id="13" string="Illinois" type="LOCATION" score="0.0">
          <tokens>
            <token id="27" string="Illinois" />
          </tokens>
        </entity>
        <entity id="14" string="186,000" type="NUMBER" score="0.0">
          <tokens>
            <token id="25" string="186,000" />
          </tokens>
        </entity>
      </entities>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="2" type="NOMINAL">
      <referenced ids_tokens="5-6-7" string="the 1990 census" id_sentence="1" />
      <mentions>
        <mention ids_tokens="19-20" string="the census" id_sentence="19" />
        <mention ids_tokens="7-8" string="the census" id_sentence="29" />
        <mention ids_tokens="6-7" string="the census" id_sentence="30" />
        <mention ids_tokens="20-21" string="the census" id_sentence="41" />
      </mentions>
    </coreference>
    <coreference id="3" type="PROPER">
      <referenced ids_tokens="2-3" string="Census Bureau" id_sentence="2" />
      <mentions>
        <mention ids_tokens="9" string="its" id_sentence="14" />
        <mention ids_tokens="23" string="it" id_sentence="14" />
        <mention ids_tokens="1" string="That" id_sentence="15" />
      </mentions>
    </coreference>
    <coreference id="4" type="PROPER">
      <referenced ids_tokens="1-2-3" string="The Census Bureau" id_sentence="2" />
      <mentions>
        <mention ids_tokens="1-4" string="The Census Bureau's" id_sentence="11" />
        <mention ids_tokens="1-19" string="The Census Bureau , based on comparisons of its data with figures kept by the Immigration and Naturalization Service" id_sentence="14" />
        <mention ids_tokens="1-2" string="The bureau" id_sentence="26" />
        <mention ids_tokens="6" string="it" id_sentence="27" />
        <mention ids_tokens="6-20" string="the Census Bureau who favor continuing the practice of counting all residents of the U.S." id_sentence="45" />
      </mentions>
    </coreference>
    <coreference id="5" type="PROPER">
      <referenced ids_tokens="2-3" string="the Senate" id_sentence="3" />
      <mentions>
        <mention ids_tokens="9" string="Senate" id_sentence="11" />
        <mention ids_tokens="2" string="Senate" id_sentence="31" />
        <mention ids_tokens="27" string="it" id_sentence="31" />
      </mentions>
    </coreference>
    <coreference id="6" type="NOMINAL">
      <referenced ids_tokens="13-14-15" string="the illegal immigrants" id_sentence="32" />
      <mentions>
        <mention ids_tokens="14-15" string="illegal immigrants" id_sentence="3" />
        <mention ids_tokens="2-3" string="illegal immigrants" id_sentence="10" />
        <mention ids_tokens="24-25" string="illegal immigrants" id_sentence="31" />
        <mention ids_tokens="24-25" string="illegal immigrants" id_sentence="35" />
        <mention ids_tokens="31" string="they" id_sentence="36" />
      </mentions>
    </coreference>
    <coreference id="7" type="NOMINAL">
      <referenced ids_tokens="4-5-6-7-8-9-10" string="the members of the House of Representatives" id_sentence="4" />
      <mentions>
        <mention ids_tokens="17" string="our" id_sentence="5" />
      </mentions>
    </coreference>
    <coreference id="8" type="PROPER">
      <referenced ids_tokens="7-8-9-10" string="the House of Representatives" id_sentence="4" />
      <mentions>
        <mention ids_tokens="36" string="House" id_sentence="5" />
        <mention ids_tokens="14-17" string="the House for Pennsylvania" id_sentence="10" />
        <mention ids_tokens="7-8" string="the House" id_sentence="15" />
        <mention ids_tokens="33-34" string="the House" id_sentence="16" />
        <mention ids_tokens="21-22" string="the House" id_sentence="32" />
        <mention ids_tokens="22" string="House" id_sentence="32" />
        <mention ids_tokens="24-25" string="the House" id_sentence="32" />
        <mention ids_tokens="1-2" string="The House" id_sentence="33" />
        <mention ids_tokens="7-8" string="the House" id_sentence="37" />
        <mention ids_tokens="26-27" string="the House" id_sentence="43" />
      </mentions>
    </coreference>
    <coreference id="9" type="PROPER">
      <referenced ids_tokens="30" string="Wis." id_sentence="5" />
      <mentions>
        <mention ids_tokens="1" string="Wisconsin" id_sentence="8" />
        <mention ids_tokens="2" string="It" id_sentence="9" />
      </mentions>
    </coreference>
    <coreference id="10" type="NOMINAL">
      <referenced ids_tokens="11-12-13-14-15-16-17-18-19-20-21" string="people who would be deported if our immigration laws were enforced" id_sentence="5" />
      <mentions>
        <mention ids_tokens="21" string="we" id_sentence="6" />
        <mention ids_tokens="9" string="people" id_sentence="20" />
        <mention ids_tokens="23-24" string="people's" id_sentence="24" />
      </mentions>
    </coreference>
    <coreference id="12" type="NOMINAL">
      <referenced ids_tokens="34-35-36-37" string="a recent House debate" id_sentence="5" />
      <mentions>
        <mention ids_tokens="2-3" string="the debate" id_sentence="7" />
        <mention ids_tokens="11" string="it" id_sentence="7" />
        <mention ids_tokens="4-5" string="the debate" id_sentence="34" />
        <mention ids_tokens="27-28" string="the debate" id_sentence="45" />
      </mentions>
    </coreference>
    <coreference id="13" type="PROPER">
      <referenced ids_tokens="8" string="Ariz." id_sentence="6" />
      <mentions>
        <mention ids_tokens="7" string="Arizona" id_sentence="8" />
      </mentions>
    </coreference>
    <coreference id="14" type="PROPER">
      <referenced ids_tokens="17-18" string="the Constitution" id_sentence="6" />
      <mentions>
        <mention ids_tokens="1" string="That" id_sentence="39" />
      </mentions>
    </coreference>
    <coreference id="15" type="PROPER">
      <referenced ids_tokens="11-12" string="Arturo Vargas" id_sentence="9" />
      <mentions>
        <mention ids_tokens="25-26" string="Mr. Vargas" id_sentence="19" />
      </mentions>
    </coreference>
    <coreference id="16" type="PROPER">
      <referenced ids_tokens="17" string="Pennsylvania" id_sentence="10" />
      <mentions>
        <mention ids_tokens="22" string="Pa." id_sentence="16" />
      </mentions>
    </coreference>
    <coreference id="18" type="PROPER">
      <referenced ids_tokens="17" string="Ala." id_sentence="11" />
      <mentions>
        <mention ids_tokens="26" string="Alabama" id_sentence="36" />
      </mentions>
    </coreference>
    <coreference id="22" type="PROPER">
      <referenced ids_tokens="14-15" string="David Ray" id_sentence="13" />
      <mentions>
        <mention ids_tokens="2" string="You" id_sentence="16" />
        <mention ids_tokens="9" string="you" id_sentence="16" />
      </mentions>
    </coreference>
    <coreference id="24" type="NOMINAL">
      <referenced ids_tokens="12" string="illegals" id_sentence="16" />
      <mentions>
        <mention ids_tokens="1" string="They" id_sentence="18" />
        <mention ids_tokens="10" string="their" id_sentence="20" />
        <mention ids_tokens="14" string="that" id_sentence="20" />
        <mention ids_tokens="2" string="We" id_sentence="22" />
        <mention ids_tokens="1" string="We" id_sentence="23" />
      </mentions>
    </coreference>
    <coreference id="25" type="PROPER">
      <referenced ids_tokens="16-17-18-19-20-21-22-23-24-25-26-27-28-29-30-31-32-33-34" string="Rep. Thomas Ridge ( R. , Pa. ) , who leads the charge against the practice in the House" id_sentence="16" />
      <mentions>
        <mention ids_tokens="1-2" string="Rep. Ridge" id_sentence="28" />
        <mention ids_tokens="29" string="he" id_sentence="29" />
      </mentions>
    </coreference>
    <coreference id="27" type="NOMINAL">
      <referenced ids_tokens="8-9-10-11-12" string="the legal status of respondents" id_sentence="18" />
      <mentions>
        <mention ids_tokens="3" string="it" id_sentence="19" />
      </mentions>
    </coreference>
    <coreference id="28" type="NOMINAL">
      <referenced ids_tokens="10-11-12-13-14-15-16-17-18-19-20-21-22" string="a tremendous challenge in trying to convince everybody that the census is confidential" id_sentence="19" />
      <mentions>
        <mention ids_tokens="25-26" string="a challenge" id_sentence="25" />
      </mentions>
    </coreference>
    <coreference id="29" type="PRONOMINAL">
      <referenced ids_tokens="7" string="your" id_sentence="22" />
      <mentions>
        <mention ids_tokens="5" string="you" id_sentence="23" />
      </mentions>
    </coreference>
    <coreference id="30" type="PROPER">
      <referenced ids_tokens="21-22" string="Peter Bonpanne" id_sentence="23" />
      <mentions>
        <mention ids_tokens="28-29" string="Mr. Bonpanne" id_sentence="25" />
      </mentions>
    </coreference>
    <coreference id="33" type="NOMINAL">
      <referenced ids_tokens="3-4" string="congressional critics" id_sentence="27" />
      <mentions>
        <mention ids_tokens="2" string="We" id_sentence="29" />
        <mention ids_tokens="14" string="we" id_sentence="29" />
      </mentions>
    </coreference>
    <coreference id="36" type="NOMINAL">
      <referenced ids_tokens="11-12" string="a provision" id_sentence="31" />
      <mentions>
        <mention ids_tokens="30-31" string="the provision" id_sentence="33" />
      </mentions>
    </coreference>
    <coreference id="37" type="NOMINAL">
      <referenced ids_tokens="20-21-22-23-24-25-26-27-28-29-30-31-32-33-34" string="the government to subtract illegal immigrants when it comes up with figures used for reapportionment" id_sentence="31" />
      <mentions>
        <mention ids_tokens="20-21" string="the government" id_sentence="35" />
      </mentions>
    </coreference>
    <coreference id="38" type="NOMINAL">
      <referenced ids_tokens="33-34-35-36-37-38" string="the opponents of counting such immigrants" id_sentence="32" />
      <mentions>
        <mention ids_tokens="1-2" string="Their opponents" id_sentence="46" />
        <mention ids_tokens="28" string="their" id_sentence="46" />
      </mentions>
    </coreference>
    <coreference id="40" type="PROPER">
      <referenced ids_tokens="9-10-11" string="the 14th Amendment" id_sentence="44" />
      <mentions>
        <mention ids_tokens="8-12" string="the 14th Amendment in 1868" id_sentence="39" />
      </mentions>
    </coreference>
    <coreference id="41" type="NOMINAL">
      <referenced ids_tokens="12-13-14-15-16-17-18" string="the word &quot; person &quot; in references" id_sentence="41" />
      <mentions>
        <mention ids_tokens="1-5" string="The word &quot; person &quot;" id_sentence="44" />
      </mentions>
    </coreference>
    <coreference id="42" type="NOMINAL">
      <referenced ids_tokens="6-7" string="the framers" id_sentence="42" />
      <mentions>
        <mention ids_tokens="1" string="They" id_sentence="43" />
      </mentions>
    </coreference>
    <coreference id="43" type="NOMINAL">
      <referenced ids_tokens="1-2-3-4-5-6-7-8-9-10-11-12-13-14-15-16-17-18-19-20" string="Those in Congress and at the Census Bureau who favor continuing the practice of counting all residents of the U.S." id_sentence="45" />
      <mentions>
        <mention ids_tokens="1" string="Their" id_sentence="46" />
      </mentions>
    </coreference>
    <coreference id="44" type="NOMINAL">
      <referenced ids_tokens="19-20-21-22" string="an &quot; illegal immigrant" id_sentence="46" />
      <mentions>
        <mention ids_tokens="5" string="Illegal" id_sentence="47" />
      </mentions>
    </coreference>
  </coreferences>
</document>
