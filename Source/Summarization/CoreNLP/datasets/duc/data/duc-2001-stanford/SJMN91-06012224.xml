<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="SJMN91-06012224">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>In his first race after a two-year suspension for drug use, Ben Johnson proved Friday night that he can run fast even without the anabolic steroid that caused his expulsion from the 1988 Olympics in Seoul, South Korea.; But the 29-year-old Canadian, whose indoor and outdoor world records were washed away by admissions that he used performance-enhancing substances for seven years, managed only to finish second in the 50-meter dash of the Hamilton Spectator Games.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="true" is_refers="false" />
        <token id="4" string="race" lemma="race" stem="race" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="two-year" lemma="two-year" stem="two-year" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="8" string="suspension" lemma="suspension" stem="suspens" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="drug" lemma="drug" stem="drug" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="use" lemma="use" stem="us" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Ben" lemma="Ben" stem="ben" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="14" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="15" string="proved" lemma="prove" stem="prove" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="Friday" lemma="Friday" stem="fridai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="17" string="night" lemma="night" stem="night" pos="NN" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="18" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="run" lemma="run" stem="run" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="fast" lemma="fast" stem="fast" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="without" lemma="without" stem="without" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="anabolic" lemma="anabolic" stem="anabol" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="steroid" lemma="steroid" stem="steroid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="caused" lemma="cause" stem="caus" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="expulsion" lemma="expulsion" stem="expuls" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="34" string="1988" lemma="1988" stem="1988" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="35" string="Olympics" lemma="Olympics" stem="olympic" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="36" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="Seoul" lemma="Seoul" stem="seoul" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="38" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="South" lemma="South" stem="south" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="40" string="Korea." lemma="Korea." stem="korea." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="41" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="44" string="29-year-old" lemma="29-year-old" stem="29-year-old" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="45" string="Canadian" lemma="canadian" stem="canadian" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="true" is_refers="false" />
        <token id="46" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="47" string="whose" lemma="whose" stem="whose" pos="WP$" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="48" string="indoor" lemma="indoor" stem="indoor" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="49" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="50" string="outdoor" lemma="outdoor" stem="outdoor" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="51" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="52" string="records" lemma="record" stem="record" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="53" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="54" string="washed" lemma="wash" stem="wash" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="55" string="away" lemma="away" stem="awai" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="56" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="57" string="admissions" lemma="admission" stem="admiss" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="58" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="59" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="60" string="used" lemma="use" stem="us" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="61" string="performance-enhancing" lemma="performance-enhancing" stem="performance-enhanc" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="62" string="substances" lemma="substance" stem="substanc" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="63" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="64" string="seven" lemma="seven" stem="seven" pos="CD" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="65" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="66" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="67" string="managed" lemma="manage" stem="manag" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="68" string="only" lemma="only" stem="onli" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="69" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="70" string="finish" lemma="finish" stem="finish" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="71" string="second" lemma="second" stem="second" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="true" is_refers="false" />
        <token id="72" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="73" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="74" string="50-meter" lemma="50-meter" stem="50-meter" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="75" string="dash" lemma="dash" stem="dash" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="76" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="77" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="78" string="Hamilton" lemma="Hamilton" stem="hamilton" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="79" string="Spectator" lemma="Spectator" stem="spectat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="80" string="Games" lemma="Games" stem="game" pos="NNPS" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="81" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (PP (IN In) (NP (NP (PRP$ his) (JJ first) (NN race)) (PP (IN after) (NP (NP (DT a) (JJ two-year) (NN suspension)) (PP (IN for) (NP (NN drug) (NN use))))))) (, ,) (NP (NNP Ben) (NNP Johnson)) (VP (VBD proved) (NP-TMP (NNP Friday) (NN night)) (SBAR (IN that) (S (NP (PRP he)) (VP (MD can) (VP (VB run) (ADVP (RB fast) (RB even)) (PP (IN without) (NP (NP (DT the) (JJ anabolic) (NN steroid)) (SBAR (WHNP (WDT that)) (S (VP (VBD caused) (NP (PRP$ his) (NN expulsion)) (PP (IN from) (NP (DT the) (CD 1988) (NNPS Olympics))) (PP (IN in) (NP (NP (NNP Seoul)) (, ,) (NP (NNP South) (NNP Korea.))))))))))))))) (: ;) (CC But) (S (NP (NP (DT the) (JJ 29-year-old) (JJ Canadian)) (, ,) (SBAR (WHNP (WP$ whose) (NP (JJ indoor) (CC and) (JJ outdoor) (NN world))) (S (NP (NNS records)) (VP (VBD were) (VP (VBN washed) (ADVP (RB away)) (PP (IN by) (NP (NNS admissions))) (SBAR (IN that) (S (NP (PRP he)) (VP (VBD used) (NP (JJ performance-enhancing) (NNS substances)) (PP (IN for) (NP (CD seven) (NNS years)))))))))) (, ,)) (VP (VBD managed) (ADVP (RB only)) (S (VP (TO to) (VP (VB finish) (ADJP (JJ second)) (PP (IN in) (NP (NP (DT the) (JJ 50-meter) (NN dash)) (PP (IN of) (NP (DT the) (NNP Hamilton) (NNP Spectator) (NNPS Games)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="used performance-enhancing substances for seven years" type="VP">
          <tokens>
            <token id="60" string="used" />
            <token id="61" string="performance-enhancing" />
            <token id="62" string="substances" />
            <token id="63" string="for" />
            <token id="64" string="seven" />
            <token id="65" string="years" />
          </tokens>
        </chunking>
        <chunking id="2" string="his first race" type="NP">
          <tokens>
            <token id="2" string="his" />
            <token id="3" string="first" />
            <token id="4" string="race" />
          </tokens>
        </chunking>
        <chunking id="3" string="run fast even without the anabolic steroid that caused his expulsion from the 1988 Olympics in Seoul , South Korea." type="VP">
          <tokens>
            <token id="21" string="run" />
            <token id="22" string="fast" />
            <token id="23" string="even" />
            <token id="24" string="without" />
            <token id="25" string="the" />
            <token id="26" string="anabolic" />
            <token id="27" string="steroid" />
            <token id="28" string="that" />
            <token id="29" string="caused" />
            <token id="30" string="his" />
            <token id="31" string="expulsion" />
            <token id="32" string="from" />
            <token id="33" string="the" />
            <token id="34" string="1988" />
            <token id="35" string="Olympics" />
            <token id="36" string="in" />
            <token id="37" string="Seoul" />
            <token id="38" string="," />
            <token id="39" string="South" />
            <token id="40" string="Korea." />
          </tokens>
        </chunking>
        <chunking id="4" string="proved Friday night that he can run fast even without the anabolic steroid that caused his expulsion from the 1988 Olympics in Seoul , South Korea." type="VP">
          <tokens>
            <token id="15" string="proved" />
            <token id="16" string="Friday" />
            <token id="17" string="night" />
            <token id="18" string="that" />
            <token id="19" string="he" />
            <token id="20" string="can" />
            <token id="21" string="run" />
            <token id="22" string="fast" />
            <token id="23" string="even" />
            <token id="24" string="without" />
            <token id="25" string="the" />
            <token id="26" string="anabolic" />
            <token id="27" string="steroid" />
            <token id="28" string="that" />
            <token id="29" string="caused" />
            <token id="30" string="his" />
            <token id="31" string="expulsion" />
            <token id="32" string="from" />
            <token id="33" string="the" />
            <token id="34" string="1988" />
            <token id="35" string="Olympics" />
            <token id="36" string="in" />
            <token id="37" string="Seoul" />
            <token id="38" string="," />
            <token id="39" string="South" />
            <token id="40" string="Korea." />
          </tokens>
        </chunking>
        <chunking id="5" string="admissions" type="NP">
          <tokens>
            <token id="57" string="admissions" />
          </tokens>
        </chunking>
        <chunking id="6" string="that he used performance-enhancing substances for seven years" type="SBAR">
          <tokens>
            <token id="58" string="that" />
            <token id="59" string="he" />
            <token id="60" string="used" />
            <token id="61" string="performance-enhancing" />
            <token id="62" string="substances" />
            <token id="63" string="for" />
            <token id="64" string="seven" />
            <token id="65" string="years" />
          </tokens>
        </chunking>
        <chunking id="7" string="Ben Johnson" type="NP">
          <tokens>
            <token id="13" string="Ben" />
            <token id="14" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="8" string="the 29-year-old Canadian , whose indoor and outdoor world records were washed away by admissions that he used performance-enhancing substances for seven years ," type="NP">
          <tokens>
            <token id="43" string="the" />
            <token id="44" string="29-year-old" />
            <token id="45" string="Canadian" />
            <token id="46" string="," />
            <token id="47" string="whose" />
            <token id="48" string="indoor" />
            <token id="49" string="and" />
            <token id="50" string="outdoor" />
            <token id="51" string="world" />
            <token id="52" string="records" />
            <token id="53" string="were" />
            <token id="54" string="washed" />
            <token id="55" string="away" />
            <token id="56" string="by" />
            <token id="57" string="admissions" />
            <token id="58" string="that" />
            <token id="59" string="he" />
            <token id="60" string="used" />
            <token id="61" string="performance-enhancing" />
            <token id="62" string="substances" />
            <token id="63" string="for" />
            <token id="64" string="seven" />
            <token id="65" string="years" />
            <token id="66" string="," />
          </tokens>
        </chunking>
        <chunking id="9" string="the Hamilton Spectator Games" type="NP">
          <tokens>
            <token id="77" string="the" />
            <token id="78" string="Hamilton" />
            <token id="79" string="Spectator" />
            <token id="80" string="Games" />
          </tokens>
        </chunking>
        <chunking id="10" string="to finish second in the 50-meter dash of the Hamilton Spectator Games" type="VP">
          <tokens>
            <token id="69" string="to" />
            <token id="70" string="finish" />
            <token id="71" string="second" />
            <token id="72" string="in" />
            <token id="73" string="the" />
            <token id="74" string="50-meter" />
            <token id="75" string="dash" />
            <token id="76" string="of" />
            <token id="77" string="the" />
            <token id="78" string="Hamilton" />
            <token id="79" string="Spectator" />
            <token id="80" string="Games" />
          </tokens>
        </chunking>
        <chunking id="11" string="seven years" type="NP">
          <tokens>
            <token id="64" string="seven" />
            <token id="65" string="years" />
          </tokens>
        </chunking>
        <chunking id="12" string="his first race after a two-year suspension for drug use" type="NP">
          <tokens>
            <token id="2" string="his" />
            <token id="3" string="first" />
            <token id="4" string="race" />
            <token id="5" string="after" />
            <token id="6" string="a" />
            <token id="7" string="two-year" />
            <token id="8" string="suspension" />
            <token id="9" string="for" />
            <token id="10" string="drug" />
            <token id="11" string="use" />
          </tokens>
        </chunking>
        <chunking id="13" string="he" type="NP">
          <tokens>
            <token id="19" string="he" />
          </tokens>
        </chunking>
        <chunking id="14" string="caused his expulsion from the 1988 Olympics in Seoul , South Korea." type="VP">
          <tokens>
            <token id="29" string="caused" />
            <token id="30" string="his" />
            <token id="31" string="expulsion" />
            <token id="32" string="from" />
            <token id="33" string="the" />
            <token id="34" string="1988" />
            <token id="35" string="Olympics" />
            <token id="36" string="in" />
            <token id="37" string="Seoul" />
            <token id="38" string="," />
            <token id="39" string="South" />
            <token id="40" string="Korea." />
          </tokens>
        </chunking>
        <chunking id="15" string="the 50-meter dash of the Hamilton Spectator Games" type="NP">
          <tokens>
            <token id="73" string="the" />
            <token id="74" string="50-meter" />
            <token id="75" string="dash" />
            <token id="76" string="of" />
            <token id="77" string="the" />
            <token id="78" string="Hamilton" />
            <token id="79" string="Spectator" />
            <token id="80" string="Games" />
          </tokens>
        </chunking>
        <chunking id="16" string="performance-enhancing substances" type="NP">
          <tokens>
            <token id="61" string="performance-enhancing" />
            <token id="62" string="substances" />
          </tokens>
        </chunking>
        <chunking id="17" string="the anabolic steroid that caused his expulsion from the 1988 Olympics in Seoul , South Korea." type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="anabolic" />
            <token id="27" string="steroid" />
            <token id="28" string="that" />
            <token id="29" string="caused" />
            <token id="30" string="his" />
            <token id="31" string="expulsion" />
            <token id="32" string="from" />
            <token id="33" string="the" />
            <token id="34" string="1988" />
            <token id="35" string="Olympics" />
            <token id="36" string="in" />
            <token id="37" string="Seoul" />
            <token id="38" string="," />
            <token id="39" string="South" />
            <token id="40" string="Korea." />
          </tokens>
        </chunking>
        <chunking id="18" string="were washed away by admissions that he used performance-enhancing substances for seven years" type="VP">
          <tokens>
            <token id="53" string="were" />
            <token id="54" string="washed" />
            <token id="55" string="away" />
            <token id="56" string="by" />
            <token id="57" string="admissions" />
            <token id="58" string="that" />
            <token id="59" string="he" />
            <token id="60" string="used" />
            <token id="61" string="performance-enhancing" />
            <token id="62" string="substances" />
            <token id="63" string="for" />
            <token id="64" string="seven" />
            <token id="65" string="years" />
          </tokens>
        </chunking>
        <chunking id="19" string="that caused his expulsion from the 1988 Olympics in Seoul , South Korea." type="SBAR">
          <tokens>
            <token id="28" string="that" />
            <token id="29" string="caused" />
            <token id="30" string="his" />
            <token id="31" string="expulsion" />
            <token id="32" string="from" />
            <token id="33" string="the" />
            <token id="34" string="1988" />
            <token id="35" string="Olympics" />
            <token id="36" string="in" />
            <token id="37" string="Seoul" />
            <token id="38" string="," />
            <token id="39" string="South" />
            <token id="40" string="Korea." />
          </tokens>
        </chunking>
        <chunking id="20" string="records" type="NP">
          <tokens>
            <token id="52" string="records" />
          </tokens>
        </chunking>
        <chunking id="21" string="second" type="ADJP">
          <tokens>
            <token id="71" string="second" />
          </tokens>
        </chunking>
        <chunking id="22" string="the 29-year-old Canadian" type="NP">
          <tokens>
            <token id="43" string="the" />
            <token id="44" string="29-year-old" />
            <token id="45" string="Canadian" />
          </tokens>
        </chunking>
        <chunking id="23" string="his expulsion" type="NP">
          <tokens>
            <token id="30" string="his" />
            <token id="31" string="expulsion" />
          </tokens>
        </chunking>
        <chunking id="24" string="washed away by admissions that he used performance-enhancing substances for seven years" type="VP">
          <tokens>
            <token id="54" string="washed" />
            <token id="55" string="away" />
            <token id="56" string="by" />
            <token id="57" string="admissions" />
            <token id="58" string="that" />
            <token id="59" string="he" />
            <token id="60" string="used" />
            <token id="61" string="performance-enhancing" />
            <token id="62" string="substances" />
            <token id="63" string="for" />
            <token id="64" string="seven" />
            <token id="65" string="years" />
          </tokens>
        </chunking>
        <chunking id="25" string="the 50-meter dash" type="NP">
          <tokens>
            <token id="73" string="the" />
            <token id="74" string="50-meter" />
            <token id="75" string="dash" />
          </tokens>
        </chunking>
        <chunking id="26" string="a two-year suspension" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="two-year" />
            <token id="8" string="suspension" />
          </tokens>
        </chunking>
        <chunking id="27" string="indoor and outdoor world" type="NP">
          <tokens>
            <token id="48" string="indoor" />
            <token id="49" string="and" />
            <token id="50" string="outdoor" />
            <token id="51" string="world" />
          </tokens>
        </chunking>
        <chunking id="28" string="that he can run fast even without the anabolic steroid that caused his expulsion from the 1988 Olympics in Seoul , South Korea." type="SBAR">
          <tokens>
            <token id="18" string="that" />
            <token id="19" string="he" />
            <token id="20" string="can" />
            <token id="21" string="run" />
            <token id="22" string="fast" />
            <token id="23" string="even" />
            <token id="24" string="without" />
            <token id="25" string="the" />
            <token id="26" string="anabolic" />
            <token id="27" string="steroid" />
            <token id="28" string="that" />
            <token id="29" string="caused" />
            <token id="30" string="his" />
            <token id="31" string="expulsion" />
            <token id="32" string="from" />
            <token id="33" string="the" />
            <token id="34" string="1988" />
            <token id="35" string="Olympics" />
            <token id="36" string="in" />
            <token id="37" string="Seoul" />
            <token id="38" string="," />
            <token id="39" string="South" />
            <token id="40" string="Korea." />
          </tokens>
        </chunking>
        <chunking id="29" string="Seoul" type="NP">
          <tokens>
            <token id="37" string="Seoul" />
          </tokens>
        </chunking>
        <chunking id="30" string="can run fast even without the anabolic steroid that caused his expulsion from the 1988 Olympics in Seoul , South Korea." type="VP">
          <tokens>
            <token id="20" string="can" />
            <token id="21" string="run" />
            <token id="22" string="fast" />
            <token id="23" string="even" />
            <token id="24" string="without" />
            <token id="25" string="the" />
            <token id="26" string="anabolic" />
            <token id="27" string="steroid" />
            <token id="28" string="that" />
            <token id="29" string="caused" />
            <token id="30" string="his" />
            <token id="31" string="expulsion" />
            <token id="32" string="from" />
            <token id="33" string="the" />
            <token id="34" string="1988" />
            <token id="35" string="Olympics" />
            <token id="36" string="in" />
            <token id="37" string="Seoul" />
            <token id="38" string="," />
            <token id="39" string="South" />
            <token id="40" string="Korea." />
          </tokens>
        </chunking>
        <chunking id="31" string="a two-year suspension for drug use" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="two-year" />
            <token id="8" string="suspension" />
            <token id="9" string="for" />
            <token id="10" string="drug" />
            <token id="11" string="use" />
          </tokens>
        </chunking>
        <chunking id="32" string="South Korea." type="NP">
          <tokens>
            <token id="39" string="South" />
            <token id="40" string="Korea." />
          </tokens>
        </chunking>
        <chunking id="33" string="drug use" type="NP">
          <tokens>
            <token id="10" string="drug" />
            <token id="11" string="use" />
          </tokens>
        </chunking>
        <chunking id="34" string="the anabolic steroid" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="anabolic" />
            <token id="27" string="steroid" />
          </tokens>
        </chunking>
        <chunking id="35" string="Seoul , South Korea." type="NP">
          <tokens>
            <token id="37" string="Seoul" />
            <token id="38" string="," />
            <token id="39" string="South" />
            <token id="40" string="Korea." />
          </tokens>
        </chunking>
        <chunking id="36" string="managed only to finish second in the 50-meter dash of the Hamilton Spectator Games" type="VP">
          <tokens>
            <token id="67" string="managed" />
            <token id="68" string="only" />
            <token id="69" string="to" />
            <token id="70" string="finish" />
            <token id="71" string="second" />
            <token id="72" string="in" />
            <token id="73" string="the" />
            <token id="74" string="50-meter" />
            <token id="75" string="dash" />
            <token id="76" string="of" />
            <token id="77" string="the" />
            <token id="78" string="Hamilton" />
            <token id="79" string="Spectator" />
            <token id="80" string="Games" />
          </tokens>
        </chunking>
        <chunking id="37" string="whose indoor and outdoor world records were washed away by admissions that he used performance-enhancing substances for seven years" type="SBAR">
          <tokens>
            <token id="47" string="whose" />
            <token id="48" string="indoor" />
            <token id="49" string="and" />
            <token id="50" string="outdoor" />
            <token id="51" string="world" />
            <token id="52" string="records" />
            <token id="53" string="were" />
            <token id="54" string="washed" />
            <token id="55" string="away" />
            <token id="56" string="by" />
            <token id="57" string="admissions" />
            <token id="58" string="that" />
            <token id="59" string="he" />
            <token id="60" string="used" />
            <token id="61" string="performance-enhancing" />
            <token id="62" string="substances" />
            <token id="63" string="for" />
            <token id="64" string="seven" />
            <token id="65" string="years" />
          </tokens>
        </chunking>
        <chunking id="38" string="the 1988 Olympics" type="NP">
          <tokens>
            <token id="33" string="the" />
            <token id="34" string="1988" />
            <token id="35" string="Olympics" />
          </tokens>
        </chunking>
        <chunking id="39" string="finish second in the 50-meter dash of the Hamilton Spectator Games" type="VP">
          <tokens>
            <token id="70" string="finish" />
            <token id="71" string="second" />
            <token id="72" string="in" />
            <token id="73" string="the" />
            <token id="74" string="50-meter" />
            <token id="75" string="dash" />
            <token id="76" string="of" />
            <token id="77" string="the" />
            <token id="78" string="Hamilton" />
            <token id="79" string="Spectator" />
            <token id="80" string="Games" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">race</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">race</governor>
          <dependent id="2">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">race</governor>
          <dependent id="3">first</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">proved</governor>
          <dependent id="4">race</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">suspension</governor>
          <dependent id="5">after</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">suspension</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">suspension</governor>
          <dependent id="7">two-year</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">race</governor>
          <dependent id="8">suspension</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">use</governor>
          <dependent id="9">for</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">use</governor>
          <dependent id="10">drug</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">suspension</governor>
          <dependent id="11">use</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Johnson</governor>
          <dependent id="13">Ben</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">proved</governor>
          <dependent id="14">Johnson</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">proved</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">night</governor>
          <dependent id="16">Friday</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="15">proved</governor>
          <dependent id="17">night</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="21">run</governor>
          <dependent id="18">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">run</governor>
          <dependent id="19">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="21">run</governor>
          <dependent id="20">can</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="15">proved</governor>
          <dependent id="21">run</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="23">even</governor>
          <dependent id="22">fast</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="21">run</governor>
          <dependent id="23">even</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">steroid</governor>
          <dependent id="24">without</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">steroid</governor>
          <dependent id="25">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="27">steroid</governor>
          <dependent id="26">anabolic</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">run</governor>
          <dependent id="27">steroid</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">caused</governor>
          <dependent id="28">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="27">steroid</governor>
          <dependent id="29">caused</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="31">expulsion</governor>
          <dependent id="30">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="29">caused</governor>
          <dependent id="31">expulsion</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">Olympics</governor>
          <dependent id="32">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="35">Olympics</governor>
          <dependent id="33">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="35">Olympics</governor>
          <dependent id="34">1988</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">caused</governor>
          <dependent id="35">Olympics</dependent>
        </dependency>
        <dependency type="case">
          <governor id="37">Seoul</governor>
          <dependent id="36">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">caused</governor>
          <dependent id="37">Seoul</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="40">Korea.</governor>
          <dependent id="39">South</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="37">Seoul</governor>
          <dependent id="40">Korea.</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="15">proved</governor>
          <dependent id="42">But</dependent>
        </dependency>
        <dependency type="det">
          <governor id="45">Canadian</governor>
          <dependent id="43">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="45">Canadian</governor>
          <dependent id="44">29-year-old</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="67">managed</governor>
          <dependent id="45">Canadian</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="51">world</governor>
          <dependent id="47">whose</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="51">world</governor>
          <dependent id="48">indoor</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="48">indoor</governor>
          <dependent id="49">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="48">indoor</governor>
          <dependent id="50">outdoor</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="54">washed</governor>
          <dependent id="51">world</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="54">washed</governor>
          <dependent id="52">records</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="54">washed</governor>
          <dependent id="53">were</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="45">Canadian</governor>
          <dependent id="54">washed</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="54">washed</governor>
          <dependent id="55">away</dependent>
        </dependency>
        <dependency type="case">
          <governor id="57">admissions</governor>
          <dependent id="56">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="54">washed</governor>
          <dependent id="57">admissions</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="60">used</governor>
          <dependent id="58">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="60">used</governor>
          <dependent id="59">he</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="54">washed</governor>
          <dependent id="60">used</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="62">substances</governor>
          <dependent id="61">performance-enhancing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="60">used</governor>
          <dependent id="62">substances</dependent>
        </dependency>
        <dependency type="case">
          <governor id="65">years</governor>
          <dependent id="63">for</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="65">years</governor>
          <dependent id="64">seven</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="60">used</governor>
          <dependent id="65">years</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="15">proved</governor>
          <dependent id="67">managed</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="67">managed</governor>
          <dependent id="68">only</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="70">finish</governor>
          <dependent id="69">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="67">managed</governor>
          <dependent id="70">finish</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="70">finish</governor>
          <dependent id="71">second</dependent>
        </dependency>
        <dependency type="case">
          <governor id="75">dash</governor>
          <dependent id="72">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="75">dash</governor>
          <dependent id="73">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="75">dash</governor>
          <dependent id="74">50-meter</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="70">finish</governor>
          <dependent id="75">dash</dependent>
        </dependency>
        <dependency type="case">
          <governor id="80">Games</governor>
          <dependent id="76">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="80">Games</governor>
          <dependent id="77">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="80">Games</governor>
          <dependent id="78">Hamilton</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="80">Games</governor>
          <dependent id="79">Spectator</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="75">dash</governor>
          <dependent id="80">Games</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="3" string="first" />
          </tokens>
        </entity>
        <entity id="2" string="Canadian" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="45" string="Canadian" />
          </tokens>
        </entity>
        <entity id="3" string="night" type="TIME" score="0.0">
          <tokens>
            <token id="17" string="night" />
          </tokens>
        </entity>
        <entity id="4" string="second" type="ORDINAL" score="0.0">
          <tokens>
            <token id="71" string="second" />
          </tokens>
        </entity>
        <entity id="5" string="29-year-old" type="DURATION" score="0.0">
          <tokens>
            <token id="44" string="29-year-old" />
          </tokens>
        </entity>
        <entity id="6" string="Ben Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="13" string="Ben" />
            <token id="14" string="Johnson" />
          </tokens>
        </entity>
        <entity id="7" string="1988" type="DATE" score="0.0">
          <tokens>
            <token id="34" string="1988" />
          </tokens>
        </entity>
        <entity id="8" string="Seoul" type="LOCATION" score="0.0">
          <tokens>
            <token id="37" string="Seoul" />
          </tokens>
        </entity>
        <entity id="9" string="Friday" type="DATE" score="0.0">
          <tokens>
            <token id="16" string="Friday" />
          </tokens>
        </entity>
        <entity id="10" string="Olympics" type="MISC" score="0.0">
          <tokens>
            <token id="35" string="Olympics" />
          </tokens>
        </entity>
        <entity id="11" string="South Korea." type="LOCATION" score="0.0">
          <tokens>
            <token id="39" string="South" />
            <token id="40" string="Korea." />
          </tokens>
        </entity>
        <entity id="12" string="Hamilton Spectator Games" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="78" string="Hamilton" />
            <token id="79" string="Spectator" />
            <token id="80" string="Games" />
          </tokens>
        </entity>
        <entity id="13" string="two-year" type="DURATION" score="0.0">
          <tokens>
            <token id="7" string="two-year" />
          </tokens>
        </entity>
        <entity id="14" string="seven years" type="DURATION" score="0.0">
          <tokens>
            <token id="64" string="seven" />
            <token id="65" string="years" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>His time of 5.77 seconds was eclipsed by the 5.75-second time of Daron Council, a former narcotics officer who now works in crime prevention for the Alachua County, Fla., sheriff&amp;apost;s department.</content>
      <tokens>
        <token id="1" string="His" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="5.77" lemma="5.77" stem="5.77" pos="CD" type="Number" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="5" string="seconds" lemma="seconds" stem="second" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="6" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="eclipsed" lemma="eclipse" stem="eclips" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="5.75-second" lemma="5.75-second" stem="5.75-second" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="11" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Daron" lemma="Daron" stem="daron" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="14" string="Council" lemma="Council" stem="council" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="former" lemma="former" stem="former" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="narcotics" lemma="narcotic" stem="narcot" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="officer" lemma="officer" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="22" string="works" lemma="work" stem="work" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="crime" lemma="crime" stem="crime" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="prevention" lemma="prevention" stem="prevent" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="Alachua" lemma="Alachua" stem="alachua" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="29" string="County" lemma="County" stem="counti" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="30" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="Fla." lemma="Fla." stem="fla." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="32" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="sheriff" lemma="sheriff" stem="sheriff" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="department" lemma="department" stem="depart" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (PRP$ His) (NN time)) (PP (IN of) (NP (CD 5.77) (NNS seconds)))) (VP (VBD was) (VP (VBN eclipsed) (PP (IN by) (NP (NP (DT the) (JJ 5.75-second) (NN time)) (PP (IN of) (NP (NP (NNP Daron) (NNP Council)) (, ,) (NP (NP (DT a) (JJ former) (NNS narcotics) (NN officer)) (SBAR (WHNP (WP who)) (S (ADVP (RB now)) (VP (VBZ works) (PP (IN in) (NP (NP (NN crime) (NN prevention)) (PP (IN for) (NP (NP (DT the) (NAC (NP (NNP Alachua) (NNP County)) (, ,) (NP (NNP Fla.)) (, ,)) (NN sheriff) (POS 's)) (NN department))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Daron Council , a former narcotics officer who now works in crime prevention for the Alachua County , Fla. , sheriff 's department" type="NP">
          <tokens>
            <token id="13" string="Daron" />
            <token id="14" string="Council" />
            <token id="15" string="," />
            <token id="16" string="a" />
            <token id="17" string="former" />
            <token id="18" string="narcotics" />
            <token id="19" string="officer" />
            <token id="20" string="who" />
            <token id="21" string="now" />
            <token id="22" string="works" />
            <token id="23" string="in" />
            <token id="24" string="crime" />
            <token id="25" string="prevention" />
            <token id="26" string="for" />
            <token id="27" string="the" />
            <token id="28" string="Alachua" />
            <token id="29" string="County" />
            <token id="30" string="," />
            <token id="31" string="Fla." />
            <token id="32" string="," />
            <token id="33" string="sheriff" />
            <token id="34" string="'s" />
            <token id="35" string="department" />
          </tokens>
        </chunking>
        <chunking id="2" string="crime prevention for the Alachua County , Fla. , sheriff 's department" type="NP">
          <tokens>
            <token id="24" string="crime" />
            <token id="25" string="prevention" />
            <token id="26" string="for" />
            <token id="27" string="the" />
            <token id="28" string="Alachua" />
            <token id="29" string="County" />
            <token id="30" string="," />
            <token id="31" string="Fla." />
            <token id="32" string="," />
            <token id="33" string="sheriff" />
            <token id="34" string="'s" />
            <token id="35" string="department" />
          </tokens>
        </chunking>
        <chunking id="3" string="His time" type="NP">
          <tokens>
            <token id="1" string="His" />
            <token id="2" string="time" />
          </tokens>
        </chunking>
        <chunking id="4" string="was eclipsed by the 5.75-second time of Daron Council , a former narcotics officer who now works in crime prevention for the Alachua County , Fla. , sheriff 's department" type="VP">
          <tokens>
            <token id="6" string="was" />
            <token id="7" string="eclipsed" />
            <token id="8" string="by" />
            <token id="9" string="the" />
            <token id="10" string="5.75-second" />
            <token id="11" string="time" />
            <token id="12" string="of" />
            <token id="13" string="Daron" />
            <token id="14" string="Council" />
            <token id="15" string="," />
            <token id="16" string="a" />
            <token id="17" string="former" />
            <token id="18" string="narcotics" />
            <token id="19" string="officer" />
            <token id="20" string="who" />
            <token id="21" string="now" />
            <token id="22" string="works" />
            <token id="23" string="in" />
            <token id="24" string="crime" />
            <token id="25" string="prevention" />
            <token id="26" string="for" />
            <token id="27" string="the" />
            <token id="28" string="Alachua" />
            <token id="29" string="County" />
            <token id="30" string="," />
            <token id="31" string="Fla." />
            <token id="32" string="," />
            <token id="33" string="sheriff" />
            <token id="34" string="'s" />
            <token id="35" string="department" />
          </tokens>
        </chunking>
        <chunking id="5" string="the 5.75-second time" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="5.75-second" />
            <token id="11" string="time" />
          </tokens>
        </chunking>
        <chunking id="6" string="His time of 5.77 seconds" type="NP">
          <tokens>
            <token id="1" string="His" />
            <token id="2" string="time" />
            <token id="3" string="of" />
            <token id="4" string="5.77" />
            <token id="5" string="seconds" />
          </tokens>
        </chunking>
        <chunking id="7" string="the Alachua County , Fla. , sheriff 's department" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="Alachua" />
            <token id="29" string="County" />
            <token id="30" string="," />
            <token id="31" string="Fla." />
            <token id="32" string="," />
            <token id="33" string="sheriff" />
            <token id="34" string="'s" />
            <token id="35" string="department" />
          </tokens>
        </chunking>
        <chunking id="8" string="crime prevention" type="NP">
          <tokens>
            <token id="24" string="crime" />
            <token id="25" string="prevention" />
          </tokens>
        </chunking>
        <chunking id="9" string="a former narcotics officer who now works in crime prevention for the Alachua County , Fla. , sheriff 's department" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="former" />
            <token id="18" string="narcotics" />
            <token id="19" string="officer" />
            <token id="20" string="who" />
            <token id="21" string="now" />
            <token id="22" string="works" />
            <token id="23" string="in" />
            <token id="24" string="crime" />
            <token id="25" string="prevention" />
            <token id="26" string="for" />
            <token id="27" string="the" />
            <token id="28" string="Alachua" />
            <token id="29" string="County" />
            <token id="30" string="," />
            <token id="31" string="Fla." />
            <token id="32" string="," />
            <token id="33" string="sheriff" />
            <token id="34" string="'s" />
            <token id="35" string="department" />
          </tokens>
        </chunking>
        <chunking id="10" string="who now works in crime prevention for the Alachua County , Fla. , sheriff 's department" type="SBAR">
          <tokens>
            <token id="20" string="who" />
            <token id="21" string="now" />
            <token id="22" string="works" />
            <token id="23" string="in" />
            <token id="24" string="crime" />
            <token id="25" string="prevention" />
            <token id="26" string="for" />
            <token id="27" string="the" />
            <token id="28" string="Alachua" />
            <token id="29" string="County" />
            <token id="30" string="," />
            <token id="31" string="Fla." />
            <token id="32" string="," />
            <token id="33" string="sheriff" />
            <token id="34" string="'s" />
            <token id="35" string="department" />
          </tokens>
        </chunking>
        <chunking id="11" string="works in crime prevention for the Alachua County , Fla. , sheriff 's department" type="VP">
          <tokens>
            <token id="22" string="works" />
            <token id="23" string="in" />
            <token id="24" string="crime" />
            <token id="25" string="prevention" />
            <token id="26" string="for" />
            <token id="27" string="the" />
            <token id="28" string="Alachua" />
            <token id="29" string="County" />
            <token id="30" string="," />
            <token id="31" string="Fla." />
            <token id="32" string="," />
            <token id="33" string="sheriff" />
            <token id="34" string="'s" />
            <token id="35" string="department" />
          </tokens>
        </chunking>
        <chunking id="12" string="the 5.75-second time of Daron Council , a former narcotics officer who now works in crime prevention for the Alachua County , Fla. , sheriff 's department" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="5.75-second" />
            <token id="11" string="time" />
            <token id="12" string="of" />
            <token id="13" string="Daron" />
            <token id="14" string="Council" />
            <token id="15" string="," />
            <token id="16" string="a" />
            <token id="17" string="former" />
            <token id="18" string="narcotics" />
            <token id="19" string="officer" />
            <token id="20" string="who" />
            <token id="21" string="now" />
            <token id="22" string="works" />
            <token id="23" string="in" />
            <token id="24" string="crime" />
            <token id="25" string="prevention" />
            <token id="26" string="for" />
            <token id="27" string="the" />
            <token id="28" string="Alachua" />
            <token id="29" string="County" />
            <token id="30" string="," />
            <token id="31" string="Fla." />
            <token id="32" string="," />
            <token id="33" string="sheriff" />
            <token id="34" string="'s" />
            <token id="35" string="department" />
          </tokens>
        </chunking>
        <chunking id="13" string="a former narcotics officer" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="former" />
            <token id="18" string="narcotics" />
            <token id="19" string="officer" />
          </tokens>
        </chunking>
        <chunking id="14" string="Fla." type="NP">
          <tokens>
            <token id="31" string="Fla." />
          </tokens>
        </chunking>
        <chunking id="15" string="eclipsed by the 5.75-second time of Daron Council , a former narcotics officer who now works in crime prevention for the Alachua County , Fla. , sheriff 's department" type="VP">
          <tokens>
            <token id="7" string="eclipsed" />
            <token id="8" string="by" />
            <token id="9" string="the" />
            <token id="10" string="5.75-second" />
            <token id="11" string="time" />
            <token id="12" string="of" />
            <token id="13" string="Daron" />
            <token id="14" string="Council" />
            <token id="15" string="," />
            <token id="16" string="a" />
            <token id="17" string="former" />
            <token id="18" string="narcotics" />
            <token id="19" string="officer" />
            <token id="20" string="who" />
            <token id="21" string="now" />
            <token id="22" string="works" />
            <token id="23" string="in" />
            <token id="24" string="crime" />
            <token id="25" string="prevention" />
            <token id="26" string="for" />
            <token id="27" string="the" />
            <token id="28" string="Alachua" />
            <token id="29" string="County" />
            <token id="30" string="," />
            <token id="31" string="Fla." />
            <token id="32" string="," />
            <token id="33" string="sheriff" />
            <token id="34" string="'s" />
            <token id="35" string="department" />
          </tokens>
        </chunking>
        <chunking id="16" string="Alachua County" type="NP">
          <tokens>
            <token id="28" string="Alachua" />
            <token id="29" string="County" />
          </tokens>
        </chunking>
        <chunking id="17" string="5.77 seconds" type="NP">
          <tokens>
            <token id="4" string="5.77" />
            <token id="5" string="seconds" />
          </tokens>
        </chunking>
        <chunking id="18" string="the Alachua County , Fla. , sheriff 's" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="Alachua" />
            <token id="29" string="County" />
            <token id="30" string="," />
            <token id="31" string="Fla." />
            <token id="32" string="," />
            <token id="33" string="sheriff" />
            <token id="34" string="'s" />
          </tokens>
        </chunking>
        <chunking id="19" string="Daron Council" type="NP">
          <tokens>
            <token id="13" string="Daron" />
            <token id="14" string="Council" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="2">time</governor>
          <dependent id="1">His</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="7">eclipsed</governor>
          <dependent id="2">time</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">seconds</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="5">seconds</governor>
          <dependent id="4">5.77</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">time</governor>
          <dependent id="5">seconds</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="7">eclipsed</governor>
          <dependent id="6">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">eclipsed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">time</governor>
          <dependent id="8">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">time</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">time</governor>
          <dependent id="10">5.75-second</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">eclipsed</governor>
          <dependent id="11">time</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">Council</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Council</governor>
          <dependent id="13">Daron</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">time</governor>
          <dependent id="14">Council</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">officer</governor>
          <dependent id="16">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">officer</governor>
          <dependent id="17">former</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">officer</governor>
          <dependent id="18">narcotics</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="14">Council</governor>
          <dependent id="19">officer</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">works</governor>
          <dependent id="20">who</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="22">works</governor>
          <dependent id="21">now</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="19">officer</governor>
          <dependent id="22">works</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">prevention</governor>
          <dependent id="23">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">prevention</governor>
          <dependent id="24">crime</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">works</governor>
          <dependent id="25">prevention</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">department</governor>
          <dependent id="26">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="33">sheriff</governor>
          <dependent id="27">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="29">County</governor>
          <dependent id="28">Alachua</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="33">sheriff</governor>
          <dependent id="29">County</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="29">County</governor>
          <dependent id="31">Fla.</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="35">department</governor>
          <dependent id="33">sheriff</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">sheriff</governor>
          <dependent id="34">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">prevention</governor>
          <dependent id="35">department</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Fla." type="LOCATION" score="0.0">
          <tokens>
            <token id="31" string="Fla." />
          </tokens>
        </entity>
        <entity id="2" string="now" type="DATE" score="0.0">
          <tokens>
            <token id="21" string="now" />
          </tokens>
        </entity>
        <entity id="3" string="Alachua County" type="LOCATION" score="0.0">
          <tokens>
            <token id="28" string="Alachua" />
            <token id="29" string="County" />
          </tokens>
        </entity>
        <entity id="4" string="5.75-second" type="DURATION" score="0.0">
          <tokens>
            <token id="10" string="5.75-second" />
          </tokens>
        </entity>
        <entity id="5" string="5.77 seconds" type="DURATION" score="0.0">
          <tokens>
            <token id="4" string="5.77" />
            <token id="5" string="seconds" />
          </tokens>
        </entity>
        <entity id="6" string="Daron Council" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="13" string="Daron" />
            <token id="14" string="Council" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>The brief race produced a record crowd of 17,050 and drew nearly 500 journalists from 14 countries in North America, Europe and Asia.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="brief" lemma="brief" stem="brief" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="race" lemma="race" stem="race" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="produced" lemma="produce" stem="produc" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="record" lemma="record" stem="record" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="crowd" lemma="crowd" stem="crowd" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="17,050" lemma="17,050" stem="17,050" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="10" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="drew" lemma="draw" stem="drew" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="nearly" lemma="nearly" stem="nearli" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="500" lemma="500" stem="500" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="14" string="journalists" lemma="journalist" stem="journalist" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="14" lemma="14" stem="14" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="17" string="countries" lemma="country" stem="countri" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="North" lemma="North" stem="north" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="20" string="America" lemma="America" stem="america" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="Europe" lemma="Europe" stem="europ" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="23" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="Asia" lemma="Asia" stem="asia" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (JJ brief) (NN race)) (VP (VP (VBD produced) (NP (NP (DT a) (NN record) (NN crowd)) (PP (IN of) (NP (CD 17,050))))) (CC and) (VP (VBD drew) (NP (QP (RB nearly) (CD 500)) (NNS journalists)) (PP (IN from) (NP (NP (CD 14) (NNS countries)) (PP (IN in) (NP (NNP North) (NNP America) (, ,) (NNP Europe) (CC and) (NNP Asia))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="produced a record crowd of 17,050 and drew nearly 500 journalists from 14 countries in North America , Europe and Asia" type="VP">
          <tokens>
            <token id="4" string="produced" />
            <token id="5" string="a" />
            <token id="6" string="record" />
            <token id="7" string="crowd" />
            <token id="8" string="of" />
            <token id="9" string="17,050" />
            <token id="10" string="and" />
            <token id="11" string="drew" />
            <token id="12" string="nearly" />
            <token id="13" string="500" />
            <token id="14" string="journalists" />
            <token id="15" string="from" />
            <token id="16" string="14" />
            <token id="17" string="countries" />
            <token id="18" string="in" />
            <token id="19" string="North" />
            <token id="20" string="America" />
            <token id="21" string="," />
            <token id="22" string="Europe" />
            <token id="23" string="and" />
            <token id="24" string="Asia" />
          </tokens>
        </chunking>
        <chunking id="2" string="a record crowd" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="record" />
            <token id="7" string="crowd" />
          </tokens>
        </chunking>
        <chunking id="3" string="drew nearly 500 journalists from 14 countries in North America , Europe and Asia" type="VP">
          <tokens>
            <token id="11" string="drew" />
            <token id="12" string="nearly" />
            <token id="13" string="500" />
            <token id="14" string="journalists" />
            <token id="15" string="from" />
            <token id="16" string="14" />
            <token id="17" string="countries" />
            <token id="18" string="in" />
            <token id="19" string="North" />
            <token id="20" string="America" />
            <token id="21" string="," />
            <token id="22" string="Europe" />
            <token id="23" string="and" />
            <token id="24" string="Asia" />
          </tokens>
        </chunking>
        <chunking id="4" string="nearly 500 journalists" type="NP">
          <tokens>
            <token id="12" string="nearly" />
            <token id="13" string="500" />
            <token id="14" string="journalists" />
          </tokens>
        </chunking>
        <chunking id="5" string="14 countries in North America , Europe and Asia" type="NP">
          <tokens>
            <token id="16" string="14" />
            <token id="17" string="countries" />
            <token id="18" string="in" />
            <token id="19" string="North" />
            <token id="20" string="America" />
            <token id="21" string="," />
            <token id="22" string="Europe" />
            <token id="23" string="and" />
            <token id="24" string="Asia" />
          </tokens>
        </chunking>
        <chunking id="6" string="14 countries" type="NP">
          <tokens>
            <token id="16" string="14" />
            <token id="17" string="countries" />
          </tokens>
        </chunking>
        <chunking id="7" string="produced a record crowd of 17,050" type="VP">
          <tokens>
            <token id="4" string="produced" />
            <token id="5" string="a" />
            <token id="6" string="record" />
            <token id="7" string="crowd" />
            <token id="8" string="of" />
            <token id="9" string="17,050" />
          </tokens>
        </chunking>
        <chunking id="8" string="a record crowd of 17,050" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="record" />
            <token id="7" string="crowd" />
            <token id="8" string="of" />
            <token id="9" string="17,050" />
          </tokens>
        </chunking>
        <chunking id="9" string="North America , Europe and Asia" type="NP">
          <tokens>
            <token id="19" string="North" />
            <token id="20" string="America" />
            <token id="21" string="," />
            <token id="22" string="Europe" />
            <token id="23" string="and" />
            <token id="24" string="Asia" />
          </tokens>
        </chunking>
        <chunking id="10" string="17,050" type="NP">
          <tokens>
            <token id="9" string="17,050" />
          </tokens>
        </chunking>
        <chunking id="11" string="The brief race" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="brief" />
            <token id="3" string="race" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">race</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">race</governor>
          <dependent id="2">brief</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">produced</governor>
          <dependent id="3">race</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">produced</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">crowd</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">crowd</governor>
          <dependent id="6">record</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">produced</governor>
          <dependent id="7">crowd</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">17,050</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">crowd</governor>
          <dependent id="9">17,050</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">produced</governor>
          <dependent id="10">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">produced</governor>
          <dependent id="11">drew</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">500</governor>
          <dependent id="12">nearly</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="14">journalists</governor>
          <dependent id="13">500</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">drew</governor>
          <dependent id="14">journalists</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">countries</governor>
          <dependent id="15">from</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="17">countries</governor>
          <dependent id="16">14</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">drew</governor>
          <dependent id="17">countries</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">America</governor>
          <dependent id="18">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">America</governor>
          <dependent id="19">North</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">countries</governor>
          <dependent id="20">America</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="20">America</governor>
          <dependent id="22">Europe</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="20">America</governor>
          <dependent id="23">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="20">America</governor>
          <dependent id="24">Asia</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="14" type="NUMBER" score="0.0">
          <tokens>
            <token id="16" string="14" />
          </tokens>
        </entity>
        <entity id="2" string="500" type="NUMBER" score="0.0">
          <tokens>
            <token id="13" string="500" />
          </tokens>
        </entity>
        <entity id="3" string="Europe" type="LOCATION" score="0.0">
          <tokens>
            <token id="22" string="Europe" />
          </tokens>
        </entity>
        <entity id="4" string="Asia" type="LOCATION" score="0.0">
          <tokens>
            <token id="24" string="Asia" />
          </tokens>
        </entity>
        <entity id="5" string="North America" type="LOCATION" score="0.0">
          <tokens>
            <token id="19" string="North" />
            <token id="20" string="America" />
          </tokens>
        </entity>
        <entity id="6" string="17,050" type="NUMBER" score="0.0">
          <tokens>
            <token id="9" string="17,050" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>They were attracted by the return of Johnson, whose day of infamy, Sept. 24, 1988, has assured him a millennium of fame.</content>
      <tokens>
        <token id="1" string="They" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="attracted" lemma="attract" stem="attract" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="return" lemma="return" stem="return" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="whose" lemma="whose" stem="whose" pos="WP$" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="day" lemma="day" stem="dai" pos="NN" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="infamy" lemma="infamy" stem="infami" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="Sept." lemma="Sept." stem="sept." pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="16" string="24" lemma="24" stem="24" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="18" string="1988" lemma="1988" stem="1988" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="assured" lemma="assure" stem="assur" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="24" string="millennium" lemma="millennium" stem="millennium" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="25" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="fame" lemma="fame" stem="fame" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP They)) (VP (VBD were) (VP (VBN attracted) (PP (IN by) (NP (NP (DT the) (NN return)) (PP (IN of) (NP (NNP Johnson))) (, ,) (SBAR (WHNP (WHNP (WP$ whose) (NN day)) (PP (IN of) (NP (NP (NN infamy)) (, ,) (NP (NNP Sept.) (CD 24) (, ,) (CD 1988)) (, ,)))) (S (VP (VBZ has) (VP (VBN assured) (S (NP (PRP him)) (NP (NP (DT a) (JJ millennium)) (PP (IN of) (NP (NN fame))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="They" type="NP">
          <tokens>
            <token id="1" string="They" />
          </tokens>
        </chunking>
        <chunking id="2" string="infamy" type="NP">
          <tokens>
            <token id="13" string="infamy" />
          </tokens>
        </chunking>
        <chunking id="3" string="a millennium" type="NP">
          <tokens>
            <token id="23" string="a" />
            <token id="24" string="millennium" />
          </tokens>
        </chunking>
        <chunking id="4" string="Johnson" type="NP">
          <tokens>
            <token id="8" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="5" string="attracted by the return of Johnson , whose day of infamy , Sept. 24 , 1988 , has assured him a millennium of fame" type="VP">
          <tokens>
            <token id="3" string="attracted" />
            <token id="4" string="by" />
            <token id="5" string="the" />
            <token id="6" string="return" />
            <token id="7" string="of" />
            <token id="8" string="Johnson" />
            <token id="9" string="," />
            <token id="10" string="whose" />
            <token id="11" string="day" />
            <token id="12" string="of" />
            <token id="13" string="infamy" />
            <token id="14" string="," />
            <token id="15" string="Sept." />
            <token id="16" string="24" />
            <token id="17" string="," />
            <token id="18" string="1988" />
            <token id="19" string="," />
            <token id="20" string="has" />
            <token id="21" string="assured" />
            <token id="22" string="him" />
            <token id="23" string="a" />
            <token id="24" string="millennium" />
            <token id="25" string="of" />
            <token id="26" string="fame" />
          </tokens>
        </chunking>
        <chunking id="6" string="him" type="NP">
          <tokens>
            <token id="22" string="him" />
          </tokens>
        </chunking>
        <chunking id="7" string="has assured him a millennium of fame" type="VP">
          <tokens>
            <token id="20" string="has" />
            <token id="21" string="assured" />
            <token id="22" string="him" />
            <token id="23" string="a" />
            <token id="24" string="millennium" />
            <token id="25" string="of" />
            <token id="26" string="fame" />
          </tokens>
        </chunking>
        <chunking id="8" string="whose day of infamy , Sept. 24 , 1988 , has assured him a millennium of fame" type="SBAR">
          <tokens>
            <token id="10" string="whose" />
            <token id="11" string="day" />
            <token id="12" string="of" />
            <token id="13" string="infamy" />
            <token id="14" string="," />
            <token id="15" string="Sept." />
            <token id="16" string="24" />
            <token id="17" string="," />
            <token id="18" string="1988" />
            <token id="19" string="," />
            <token id="20" string="has" />
            <token id="21" string="assured" />
            <token id="22" string="him" />
            <token id="23" string="a" />
            <token id="24" string="millennium" />
            <token id="25" string="of" />
            <token id="26" string="fame" />
          </tokens>
        </chunking>
        <chunking id="9" string="a millennium of fame" type="NP">
          <tokens>
            <token id="23" string="a" />
            <token id="24" string="millennium" />
            <token id="25" string="of" />
            <token id="26" string="fame" />
          </tokens>
        </chunking>
        <chunking id="10" string="infamy , Sept. 24 , 1988 ," type="NP">
          <tokens>
            <token id="13" string="infamy" />
            <token id="14" string="," />
            <token id="15" string="Sept." />
            <token id="16" string="24" />
            <token id="17" string="," />
            <token id="18" string="1988" />
            <token id="19" string="," />
          </tokens>
        </chunking>
        <chunking id="11" string="the return of Johnson , whose day of infamy , Sept. 24 , 1988 , has assured him a millennium of fame" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="return" />
            <token id="7" string="of" />
            <token id="8" string="Johnson" />
            <token id="9" string="," />
            <token id="10" string="whose" />
            <token id="11" string="day" />
            <token id="12" string="of" />
            <token id="13" string="infamy" />
            <token id="14" string="," />
            <token id="15" string="Sept." />
            <token id="16" string="24" />
            <token id="17" string="," />
            <token id="18" string="1988" />
            <token id="19" string="," />
            <token id="20" string="has" />
            <token id="21" string="assured" />
            <token id="22" string="him" />
            <token id="23" string="a" />
            <token id="24" string="millennium" />
            <token id="25" string="of" />
            <token id="26" string="fame" />
          </tokens>
        </chunking>
        <chunking id="12" string="were attracted by the return of Johnson , whose day of infamy , Sept. 24 , 1988 , has assured him a millennium of fame" type="VP">
          <tokens>
            <token id="2" string="were" />
            <token id="3" string="attracted" />
            <token id="4" string="by" />
            <token id="5" string="the" />
            <token id="6" string="return" />
            <token id="7" string="of" />
            <token id="8" string="Johnson" />
            <token id="9" string="," />
            <token id="10" string="whose" />
            <token id="11" string="day" />
            <token id="12" string="of" />
            <token id="13" string="infamy" />
            <token id="14" string="," />
            <token id="15" string="Sept." />
            <token id="16" string="24" />
            <token id="17" string="," />
            <token id="18" string="1988" />
            <token id="19" string="," />
            <token id="20" string="has" />
            <token id="21" string="assured" />
            <token id="22" string="him" />
            <token id="23" string="a" />
            <token id="24" string="millennium" />
            <token id="25" string="of" />
            <token id="26" string="fame" />
          </tokens>
        </chunking>
        <chunking id="13" string="Sept. 24 , 1988" type="NP">
          <tokens>
            <token id="15" string="Sept." />
            <token id="16" string="24" />
            <token id="17" string="," />
            <token id="18" string="1988" />
          </tokens>
        </chunking>
        <chunking id="14" string="fame" type="NP">
          <tokens>
            <token id="26" string="fame" />
          </tokens>
        </chunking>
        <chunking id="15" string="the return" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="return" />
          </tokens>
        </chunking>
        <chunking id="16" string="assured him a millennium of fame" type="VP">
          <tokens>
            <token id="21" string="assured" />
            <token id="22" string="him" />
            <token id="23" string="a" />
            <token id="24" string="millennium" />
            <token id="25" string="of" />
            <token id="26" string="fame" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="3">attracted</governor>
          <dependent id="1">They</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="3">attracted</governor>
          <dependent id="2">were</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">attracted</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">return</governor>
          <dependent id="4">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">return</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">attracted</governor>
          <dependent id="6">return</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">Johnson</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">return</governor>
          <dependent id="8">Johnson</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">day</governor>
          <dependent id="10">whose</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">assured</governor>
          <dependent id="11">day</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">infamy</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">day</governor>
          <dependent id="13">infamy</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="13">infamy</governor>
          <dependent id="15">Sept.</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="15">Sept.</governor>
          <dependent id="16">24</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="15">Sept.</governor>
          <dependent id="18">1988</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="21">assured</governor>
          <dependent id="20">has</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="6">return</governor>
          <dependent id="21">assured</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">millennium</governor>
          <dependent id="22">him</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">millennium</governor>
          <dependent id="23">a</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="21">assured</governor>
          <dependent id="24">millennium</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">fame</governor>
          <dependent id="25">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">millennium</governor>
          <dependent id="26">fame</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="a millennium" type="DURATION" score="0.0">
          <tokens>
            <token id="23" string="a" />
            <token id="24" string="millennium" />
          </tokens>
        </entity>
        <entity id="2" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Johnson" />
          </tokens>
        </entity>
        <entity id="3" string="day" type="DURATION" score="0.0">
          <tokens>
            <token id="11" string="day" />
          </tokens>
        </entity>
        <entity id="4" string="Sept. 24 , 1988" type="DATE" score="0.0">
          <tokens>
            <token id="15" string="Sept." />
            <token id="16" string="24" />
            <token id="17" string="," />
            <token id="18" string="1988" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>He would merely have been a gold medalist if a positive test at the 1988 Olympics had not turned him into the most vilified champion in the history of the Games.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="merely" lemma="merely" stem="mere" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="gold" lemma="gold" stem="gold" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="medalist" lemma="medalist" stem="medalist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="positive" lemma="positive" stem="posit" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="test" lemma="test" stem="test" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="1988" lemma="1988" stem="1988" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="16" string="Olympics" lemma="Olympics" stem="olympic" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="17" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="turned" lemma="turn" stem="turn" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="most" lemma="most" stem="most" pos="RBS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="vilified" lemma="vilify" stem="vilifi" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="champion" lemma="champion" stem="champion" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="history" lemma="history" stem="histori" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="31" string="Games" lemma="Games" stem="game" pos="NNPS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (MD would) (ADVP (RB merely)) (VP (VB have) (VP (VBN been) (NP (DT a) (NN gold) (NN medalist)) (SBAR (IN if) (S (NP (NP (DT a) (JJ positive) (NN test)) (PP (IN at) (NP (DT the) (CD 1988) (NNPS Olympics)))) (VP (VBD had) (RB not) (VP (VBN turned) (NP (PRP him)) (PP (IN into) (NP (NP (DT the) (RBS most)) (VP (VBN vilified) (NP (NN champion)) (PP (IN in) (NP (NP (DT the) (NN history)) (PP (IN of) (NP (DT the) (NNPS Games))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a gold medalist" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="gold" />
            <token id="8" string="medalist" />
          </tokens>
        </chunking>
        <chunking id="2" string="him" type="NP">
          <tokens>
            <token id="20" string="him" />
          </tokens>
        </chunking>
        <chunking id="3" string="been a gold medalist if a positive test at the 1988 Olympics had not turned him into the most vilified champion in the history of the Games" type="VP">
          <tokens>
            <token id="5" string="been" />
            <token id="6" string="a" />
            <token id="7" string="gold" />
            <token id="8" string="medalist" />
            <token id="9" string="if" />
            <token id="10" string="a" />
            <token id="11" string="positive" />
            <token id="12" string="test" />
            <token id="13" string="at" />
            <token id="14" string="the" />
            <token id="15" string="1988" />
            <token id="16" string="Olympics" />
            <token id="17" string="had" />
            <token id="18" string="not" />
            <token id="19" string="turned" />
            <token id="20" string="him" />
            <token id="21" string="into" />
            <token id="22" string="the" />
            <token id="23" string="most" />
            <token id="24" string="vilified" />
            <token id="25" string="champion" />
            <token id="26" string="in" />
            <token id="27" string="the" />
            <token id="28" string="history" />
            <token id="29" string="of" />
            <token id="30" string="the" />
            <token id="31" string="Games" />
          </tokens>
        </chunking>
        <chunking id="4" string="the most" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="most" />
          </tokens>
        </chunking>
        <chunking id="5" string="would merely have been a gold medalist if a positive test at the 1988 Olympics had not turned him into the most vilified champion in the history of the Games" type="VP">
          <tokens>
            <token id="2" string="would" />
            <token id="3" string="merely" />
            <token id="4" string="have" />
            <token id="5" string="been" />
            <token id="6" string="a" />
            <token id="7" string="gold" />
            <token id="8" string="medalist" />
            <token id="9" string="if" />
            <token id="10" string="a" />
            <token id="11" string="positive" />
            <token id="12" string="test" />
            <token id="13" string="at" />
            <token id="14" string="the" />
            <token id="15" string="1988" />
            <token id="16" string="Olympics" />
            <token id="17" string="had" />
            <token id="18" string="not" />
            <token id="19" string="turned" />
            <token id="20" string="him" />
            <token id="21" string="into" />
            <token id="22" string="the" />
            <token id="23" string="most" />
            <token id="24" string="vilified" />
            <token id="25" string="champion" />
            <token id="26" string="in" />
            <token id="27" string="the" />
            <token id="28" string="history" />
            <token id="29" string="of" />
            <token id="30" string="the" />
            <token id="31" string="Games" />
          </tokens>
        </chunking>
        <chunking id="6" string="the Games" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="Games" />
          </tokens>
        </chunking>
        <chunking id="7" string="if a positive test at the 1988 Olympics had not turned him into the most vilified champion in the history of the Games" type="SBAR">
          <tokens>
            <token id="9" string="if" />
            <token id="10" string="a" />
            <token id="11" string="positive" />
            <token id="12" string="test" />
            <token id="13" string="at" />
            <token id="14" string="the" />
            <token id="15" string="1988" />
            <token id="16" string="Olympics" />
            <token id="17" string="had" />
            <token id="18" string="not" />
            <token id="19" string="turned" />
            <token id="20" string="him" />
            <token id="21" string="into" />
            <token id="22" string="the" />
            <token id="23" string="most" />
            <token id="24" string="vilified" />
            <token id="25" string="champion" />
            <token id="26" string="in" />
            <token id="27" string="the" />
            <token id="28" string="history" />
            <token id="29" string="of" />
            <token id="30" string="the" />
            <token id="31" string="Games" />
          </tokens>
        </chunking>
        <chunking id="8" string="vilified champion in the history of the Games" type="VP">
          <tokens>
            <token id="24" string="vilified" />
            <token id="25" string="champion" />
            <token id="26" string="in" />
            <token id="27" string="the" />
            <token id="28" string="history" />
            <token id="29" string="of" />
            <token id="30" string="the" />
            <token id="31" string="Games" />
          </tokens>
        </chunking>
        <chunking id="9" string="have been a gold medalist if a positive test at the 1988 Olympics had not turned him into the most vilified champion in the history of the Games" type="VP">
          <tokens>
            <token id="4" string="have" />
            <token id="5" string="been" />
            <token id="6" string="a" />
            <token id="7" string="gold" />
            <token id="8" string="medalist" />
            <token id="9" string="if" />
            <token id="10" string="a" />
            <token id="11" string="positive" />
            <token id="12" string="test" />
            <token id="13" string="at" />
            <token id="14" string="the" />
            <token id="15" string="1988" />
            <token id="16" string="Olympics" />
            <token id="17" string="had" />
            <token id="18" string="not" />
            <token id="19" string="turned" />
            <token id="20" string="him" />
            <token id="21" string="into" />
            <token id="22" string="the" />
            <token id="23" string="most" />
            <token id="24" string="vilified" />
            <token id="25" string="champion" />
            <token id="26" string="in" />
            <token id="27" string="the" />
            <token id="28" string="history" />
            <token id="29" string="of" />
            <token id="30" string="the" />
            <token id="31" string="Games" />
          </tokens>
        </chunking>
        <chunking id="10" string="a positive test" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="positive" />
            <token id="12" string="test" />
          </tokens>
        </chunking>
        <chunking id="11" string="the most vilified champion in the history of the Games" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="most" />
            <token id="24" string="vilified" />
            <token id="25" string="champion" />
            <token id="26" string="in" />
            <token id="27" string="the" />
            <token id="28" string="history" />
            <token id="29" string="of" />
            <token id="30" string="the" />
            <token id="31" string="Games" />
          </tokens>
        </chunking>
        <chunking id="12" string="the history" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="history" />
          </tokens>
        </chunking>
        <chunking id="13" string="a positive test at the 1988 Olympics" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="positive" />
            <token id="12" string="test" />
            <token id="13" string="at" />
            <token id="14" string="the" />
            <token id="15" string="1988" />
            <token id="16" string="Olympics" />
          </tokens>
        </chunking>
        <chunking id="14" string="the 1988 Olympics" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="1988" />
            <token id="16" string="Olympics" />
          </tokens>
        </chunking>
        <chunking id="15" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="16" string="the history of the Games" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="history" />
            <token id="29" string="of" />
            <token id="30" string="the" />
            <token id="31" string="Games" />
          </tokens>
        </chunking>
        <chunking id="17" string="had not turned him into the most vilified champion in the history of the Games" type="VP">
          <tokens>
            <token id="17" string="had" />
            <token id="18" string="not" />
            <token id="19" string="turned" />
            <token id="20" string="him" />
            <token id="21" string="into" />
            <token id="22" string="the" />
            <token id="23" string="most" />
            <token id="24" string="vilified" />
            <token id="25" string="champion" />
            <token id="26" string="in" />
            <token id="27" string="the" />
            <token id="28" string="history" />
            <token id="29" string="of" />
            <token id="30" string="the" />
            <token id="31" string="Games" />
          </tokens>
        </chunking>
        <chunking id="18" string="turned him into the most vilified champion in the history of the Games" type="VP">
          <tokens>
            <token id="19" string="turned" />
            <token id="20" string="him" />
            <token id="21" string="into" />
            <token id="22" string="the" />
            <token id="23" string="most" />
            <token id="24" string="vilified" />
            <token id="25" string="champion" />
            <token id="26" string="in" />
            <token id="27" string="the" />
            <token id="28" string="history" />
            <token id="29" string="of" />
            <token id="30" string="the" />
            <token id="31" string="Games" />
          </tokens>
        </chunking>
        <chunking id="19" string="champion" type="NP">
          <tokens>
            <token id="25" string="champion" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="8">medalist</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">medalist</governor>
          <dependent id="2">would</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">medalist</governor>
          <dependent id="3">merely</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">medalist</governor>
          <dependent id="4">have</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="8">medalist</governor>
          <dependent id="5">been</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">medalist</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">medalist</governor>
          <dependent id="7">gold</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">medalist</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">turned</governor>
          <dependent id="9">if</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">test</governor>
          <dependent id="10">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">test</governor>
          <dependent id="11">positive</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">turned</governor>
          <dependent id="12">test</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">Olympics</governor>
          <dependent id="13">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">Olympics</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="16">Olympics</governor>
          <dependent id="15">1988</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">test</governor>
          <dependent id="16">Olympics</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="19">turned</governor>
          <dependent id="17">had</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="19">turned</governor>
          <dependent id="18">not</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="8">medalist</governor>
          <dependent id="19">turned</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">turned</governor>
          <dependent id="20">him</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">the</governor>
          <dependent id="21">into</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">turned</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="22">the</governor>
          <dependent id="23">most</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="22">the</governor>
          <dependent id="24">vilified</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="24">vilified</governor>
          <dependent id="25">champion</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">history</governor>
          <dependent id="26">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">history</governor>
          <dependent id="27">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">vilified</governor>
          <dependent id="28">history</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">Games</governor>
          <dependent id="29">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">Games</governor>
          <dependent id="30">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">history</governor>
          <dependent id="31">Games</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1988" type="DATE" score="0.0">
          <tokens>
            <token id="15" string="1988" />
          </tokens>
        </entity>
        <entity id="2" string="Olympics" type="MISC" score="0.0">
          <tokens>
            <token id="16" string="Olympics" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>It also led to the two-year suspension from the sport that made an epic event of Johnson&amp;apost;s race Friday.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="led" lemma="lead" stem="led" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="two-year" lemma="two-year" stem="two-year" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="true" />
        <token id="7" string="suspension" lemma="suspension" stem="suspens" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="sport" lemma="sport" stem="sport" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="made" lemma="make" stem="made" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="epic" lemma="epic" stem="epic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="event" lemma="event" stem="event" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="18" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="race" lemma="race" stem="race" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="Friday" lemma="Friday" stem="fridai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP It)) (ADVP (RB also)) (VP (VBD led) (PP (TO to) (NP (DT the) (JJ two-year) (NN suspension))) (PP (IN from) (NP (NP (DT the) (NN sport)) (SBAR (WHNP (WDT that)) (S (VP (VBD made) (NP (NP (DT an) (NN epic) (NN event)) (PP (IN of) (NP (NP (NNP Johnson) (POS 's)) (NN race)))) (NP-TMP (NNP Friday)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="that made an epic event of Johnson 's race Friday" type="SBAR">
          <tokens>
            <token id="11" string="that" />
            <token id="12" string="made" />
            <token id="13" string="an" />
            <token id="14" string="epic" />
            <token id="15" string="event" />
            <token id="16" string="of" />
            <token id="17" string="Johnson" />
            <token id="18" string="'s" />
            <token id="19" string="race" />
            <token id="20" string="Friday" />
          </tokens>
        </chunking>
        <chunking id="2" string="made an epic event of Johnson 's race Friday" type="VP">
          <tokens>
            <token id="12" string="made" />
            <token id="13" string="an" />
            <token id="14" string="epic" />
            <token id="15" string="event" />
            <token id="16" string="of" />
            <token id="17" string="Johnson" />
            <token id="18" string="'s" />
            <token id="19" string="race" />
            <token id="20" string="Friday" />
          </tokens>
        </chunking>
        <chunking id="3" string="an epic event" type="NP">
          <tokens>
            <token id="13" string="an" />
            <token id="14" string="epic" />
            <token id="15" string="event" />
          </tokens>
        </chunking>
        <chunking id="4" string="the sport" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="sport" />
          </tokens>
        </chunking>
        <chunking id="5" string="led to the two-year suspension from the sport that made an epic event of Johnson 's race Friday" type="VP">
          <tokens>
            <token id="3" string="led" />
            <token id="4" string="to" />
            <token id="5" string="the" />
            <token id="6" string="two-year" />
            <token id="7" string="suspension" />
            <token id="8" string="from" />
            <token id="9" string="the" />
            <token id="10" string="sport" />
            <token id="11" string="that" />
            <token id="12" string="made" />
            <token id="13" string="an" />
            <token id="14" string="epic" />
            <token id="15" string="event" />
            <token id="16" string="of" />
            <token id="17" string="Johnson" />
            <token id="18" string="'s" />
            <token id="19" string="race" />
            <token id="20" string="Friday" />
          </tokens>
        </chunking>
        <chunking id="6" string="an epic event of Johnson 's race" type="NP">
          <tokens>
            <token id="13" string="an" />
            <token id="14" string="epic" />
            <token id="15" string="event" />
            <token id="16" string="of" />
            <token id="17" string="Johnson" />
            <token id="18" string="'s" />
            <token id="19" string="race" />
          </tokens>
        </chunking>
        <chunking id="7" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="8" string="Johnson 's race" type="NP">
          <tokens>
            <token id="17" string="Johnson" />
            <token id="18" string="'s" />
            <token id="19" string="race" />
          </tokens>
        </chunking>
        <chunking id="9" string="Johnson 's" type="NP">
          <tokens>
            <token id="17" string="Johnson" />
            <token id="18" string="'s" />
          </tokens>
        </chunking>
        <chunking id="10" string="the two-year suspension" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="two-year" />
            <token id="7" string="suspension" />
          </tokens>
        </chunking>
        <chunking id="11" string="the sport that made an epic event of Johnson 's race Friday" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="sport" />
            <token id="11" string="that" />
            <token id="12" string="made" />
            <token id="13" string="an" />
            <token id="14" string="epic" />
            <token id="15" string="event" />
            <token id="16" string="of" />
            <token id="17" string="Johnson" />
            <token id="18" string="'s" />
            <token id="19" string="race" />
            <token id="20" string="Friday" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">led</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">led</governor>
          <dependent id="2">also</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">led</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">suspension</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">suspension</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">suspension</governor>
          <dependent id="6">two-year</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">led</governor>
          <dependent id="7">suspension</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">sport</governor>
          <dependent id="8">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">sport</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">led</governor>
          <dependent id="10">sport</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">made</governor>
          <dependent id="11">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="10">sport</governor>
          <dependent id="12">made</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">event</governor>
          <dependent id="13">an</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">event</governor>
          <dependent id="14">epic</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">made</governor>
          <dependent id="15">event</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">race</governor>
          <dependent id="16">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="19">race</governor>
          <dependent id="17">Johnson</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">Johnson</governor>
          <dependent id="18">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">event</governor>
          <dependent id="19">race</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="12">made</governor>
          <dependent id="20">Friday</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="17" string="Johnson" />
          </tokens>
        </entity>
        <entity id="2" string="Friday" type="DATE" score="0.0">
          <tokens>
            <token id="20" string="Friday" />
          </tokens>
        </entity>
        <entity id="3" string="two-year" type="DURATION" score="0.0">
          <tokens>
            <token id="6" string="two-year" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>Johnson got off to an uncharacteristically slow start and finished second by a few inches to Council.</content>
      <tokens>
        <token id="1" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="got" lemma="get" stem="got" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="off" lemma="off" stem="off" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="uncharacteristically" lemma="uncharacteristically" stem="uncharacterist" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="slow" lemma="slow" stem="slow" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="start" lemma="start" stem="start" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="finished" lemma="finish" stem="finish" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="second" lemma="second" stem="second" pos="RB" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="12" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="few" lemma="few" stem="few" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="inches" lemma="inch" stem="inch" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Council" lemma="Council" stem="council" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Johnson)) (VP (VP (VBD got) (PRT (RP off)) (PP (TO to) (NP (DT an) (ADJP (RB uncharacteristically) (JJ slow)) (NN start)))) (CC and) (VP (VBD finished) (ADVP (RB second) (PP (IN by) (NP (DT a) (JJ few) (NNS inches)))) (PP (TO to) (NP (NNP Council))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Johnson" type="NP">
          <tokens>
            <token id="1" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="2" string="got off to an uncharacteristically slow start" type="VP">
          <tokens>
            <token id="2" string="got" />
            <token id="3" string="off" />
            <token id="4" string="to" />
            <token id="5" string="an" />
            <token id="6" string="uncharacteristically" />
            <token id="7" string="slow" />
            <token id="8" string="start" />
          </tokens>
        </chunking>
        <chunking id="3" string="an uncharacteristically slow start" type="NP">
          <tokens>
            <token id="5" string="an" />
            <token id="6" string="uncharacteristically" />
            <token id="7" string="slow" />
            <token id="8" string="start" />
          </tokens>
        </chunking>
        <chunking id="4" string="uncharacteristically slow" type="ADJP">
          <tokens>
            <token id="6" string="uncharacteristically" />
            <token id="7" string="slow" />
          </tokens>
        </chunking>
        <chunking id="5" string="got off to an uncharacteristically slow start and finished second by a few inches to Council" type="VP">
          <tokens>
            <token id="2" string="got" />
            <token id="3" string="off" />
            <token id="4" string="to" />
            <token id="5" string="an" />
            <token id="6" string="uncharacteristically" />
            <token id="7" string="slow" />
            <token id="8" string="start" />
            <token id="9" string="and" />
            <token id="10" string="finished" />
            <token id="11" string="second" />
            <token id="12" string="by" />
            <token id="13" string="a" />
            <token id="14" string="few" />
            <token id="15" string="inches" />
            <token id="16" string="to" />
            <token id="17" string="Council" />
          </tokens>
        </chunking>
        <chunking id="6" string="finished second by a few inches to Council" type="VP">
          <tokens>
            <token id="10" string="finished" />
            <token id="11" string="second" />
            <token id="12" string="by" />
            <token id="13" string="a" />
            <token id="14" string="few" />
            <token id="15" string="inches" />
            <token id="16" string="to" />
            <token id="17" string="Council" />
          </tokens>
        </chunking>
        <chunking id="7" string="a few inches" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="few" />
            <token id="15" string="inches" />
          </tokens>
        </chunking>
        <chunking id="8" string="Council" type="NP">
          <tokens>
            <token id="17" string="Council" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">got</governor>
          <dependent id="1">Johnson</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">got</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="2">got</governor>
          <dependent id="3">off</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">start</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">start</governor>
          <dependent id="5">an</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">slow</governor>
          <dependent id="6">uncharacteristically</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">start</governor>
          <dependent id="7">slow</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">got</governor>
          <dependent id="8">start</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">got</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">got</governor>
          <dependent id="10">finished</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">finished</governor>
          <dependent id="11">second</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">inches</governor>
          <dependent id="12">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">inches</governor>
          <dependent id="13">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">inches</governor>
          <dependent id="14">few</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">second</governor>
          <dependent id="15">inches</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">Council</governor>
          <dependent id="16">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">finished</governor>
          <dependent id="17">Council</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Johnson" />
          </tokens>
        </entity>
        <entity id="2" string="second" type="ORDINAL" score="0.0">
          <tokens>
            <token id="11" string="second" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>&amp;quot;I got caught in the blocks,&amp;quot; Johnson said.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="got" lemma="get" stem="got" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="caught" lemma="catch" stem="caught" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="blocks" lemma="block" stem="block" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="11" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP I)) (VP (VBD got) (VP (VBN caught) (PP (IN in) (NP (DT the) (NNS blocks)))))) (, ,) ('' '') (NP (NNP Johnson)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Johnson" type="NP">
          <tokens>
            <token id="10" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="2" string="caught in the blocks" type="VP">
          <tokens>
            <token id="4" string="caught" />
            <token id="5" string="in" />
            <token id="6" string="the" />
            <token id="7" string="blocks" />
          </tokens>
        </chunking>
        <chunking id="3" string="the blocks" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="blocks" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="got caught in the blocks" type="VP">
          <tokens>
            <token id="3" string="got" />
            <token id="4" string="caught" />
            <token id="5" string="in" />
            <token id="6" string="the" />
            <token id="7" string="blocks" />
          </tokens>
        </chunking>
        <chunking id="6" string="said" type="VP">
          <tokens>
            <token id="11" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="4">caught</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="4">caught</governor>
          <dependent id="3">got</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">said</governor>
          <dependent id="4">caught</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">blocks</governor>
          <dependent id="5">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">blocks</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">caught</governor>
          <dependent id="7">blocks</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">said</governor>
          <dependent id="10">Johnson</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Johnson" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>By then, the start had been delayed eight minutes by two false starts and a problem with the board track.</content>
      <tokens>
        <token id="1" string="By" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="start" lemma="start" stem="start" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="delayed" lemma="delay" stem="delai" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="eight" lemma="eight" stem="eight" pos="CD" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="10" string="minutes" lemma="minute" stem="minut" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="11" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="13" string="false" lemma="false" stem="fals" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="starts" lemma="start" stem="start" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="problem" lemma="problem" stem="problem" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="board" lemma="board" stem="board" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="track" lemma="track" stem="track" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN By) (NP (RB then))) (, ,) (NP (DT the) (NN start)) (VP (VBD had) (VP (VBN been) (VP (VBN delayed) (NP-TMP (CD eight) (NNS minutes)) (PP (IN by) (NP (NP (CD two) (JJ false) (NNS starts)) (CC and) (NP (DT a) (NN problem)))) (PP (IN with) (NP (DT the) (NN board) (NN track)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the start" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="start" />
          </tokens>
        </chunking>
        <chunking id="2" string="been delayed eight minutes by two false starts and a problem with the board track" type="VP">
          <tokens>
            <token id="7" string="been" />
            <token id="8" string="delayed" />
            <token id="9" string="eight" />
            <token id="10" string="minutes" />
            <token id="11" string="by" />
            <token id="12" string="two" />
            <token id="13" string="false" />
            <token id="14" string="starts" />
            <token id="15" string="and" />
            <token id="16" string="a" />
            <token id="17" string="problem" />
            <token id="18" string="with" />
            <token id="19" string="the" />
            <token id="20" string="board" />
            <token id="21" string="track" />
          </tokens>
        </chunking>
        <chunking id="3" string="delayed eight minutes by two false starts and a problem with the board track" type="VP">
          <tokens>
            <token id="8" string="delayed" />
            <token id="9" string="eight" />
            <token id="10" string="minutes" />
            <token id="11" string="by" />
            <token id="12" string="two" />
            <token id="13" string="false" />
            <token id="14" string="starts" />
            <token id="15" string="and" />
            <token id="16" string="a" />
            <token id="17" string="problem" />
            <token id="18" string="with" />
            <token id="19" string="the" />
            <token id="20" string="board" />
            <token id="21" string="track" />
          </tokens>
        </chunking>
        <chunking id="4" string="two false starts" type="NP">
          <tokens>
            <token id="12" string="two" />
            <token id="13" string="false" />
            <token id="14" string="starts" />
          </tokens>
        </chunking>
        <chunking id="5" string="two false starts and a problem" type="NP">
          <tokens>
            <token id="12" string="two" />
            <token id="13" string="false" />
            <token id="14" string="starts" />
            <token id="15" string="and" />
            <token id="16" string="a" />
            <token id="17" string="problem" />
          </tokens>
        </chunking>
        <chunking id="6" string="the board track" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="board" />
            <token id="21" string="track" />
          </tokens>
        </chunking>
        <chunking id="7" string="then" type="NP">
          <tokens>
            <token id="2" string="then" />
          </tokens>
        </chunking>
        <chunking id="8" string="had been delayed eight minutes by two false starts and a problem with the board track" type="VP">
          <tokens>
            <token id="6" string="had" />
            <token id="7" string="been" />
            <token id="8" string="delayed" />
            <token id="9" string="eight" />
            <token id="10" string="minutes" />
            <token id="11" string="by" />
            <token id="12" string="two" />
            <token id="13" string="false" />
            <token id="14" string="starts" />
            <token id="15" string="and" />
            <token id="16" string="a" />
            <token id="17" string="problem" />
            <token id="18" string="with" />
            <token id="19" string="the" />
            <token id="20" string="board" />
            <token id="21" string="track" />
          </tokens>
        </chunking>
        <chunking id="9" string="a problem" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="problem" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">then</governor>
          <dependent id="1">By</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">delayed</governor>
          <dependent id="2">then</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">start</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="8">delayed</governor>
          <dependent id="5">start</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">delayed</governor>
          <dependent id="6">had</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="8">delayed</governor>
          <dependent id="7">been</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">delayed</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="10">minutes</governor>
          <dependent id="9">eight</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="8">delayed</governor>
          <dependent id="10">minutes</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">starts</governor>
          <dependent id="11">by</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="14">starts</governor>
          <dependent id="12">two</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">starts</governor>
          <dependent id="13">false</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">delayed</governor>
          <dependent id="14">starts</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="14">starts</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">problem</governor>
          <dependent id="16">a</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">starts</governor>
          <dependent id="17">problem</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">track</governor>
          <dependent id="18">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">track</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">track</governor>
          <dependent id="20">board</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">delayed</governor>
          <dependent id="21">track</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="eight minutes" type="DURATION" score="0.0">
          <tokens>
            <token id="9" string="eight" />
            <token id="10" string="minutes" />
          </tokens>
        </entity>
        <entity id="2" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="12" string="two" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>Johnson took his second-place finish in stride.</content>
      <tokens>
        <token id="1" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="took" lemma="take" stem="took" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="4" string="second-place" lemma="second-place" stem="second-plac" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="finish" lemma="finish" stem="finish" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="stride" lemma="stride" stem="stride" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Johnson)) (VP (VBD took) (NP (PRP$ his) (JJ second-place) (NN finish)) (PP (IN in) (NP (NN stride)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Johnson" type="NP">
          <tokens>
            <token id="1" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="2" string="his second-place finish" type="NP">
          <tokens>
            <token id="3" string="his" />
            <token id="4" string="second-place" />
            <token id="5" string="finish" />
          </tokens>
        </chunking>
        <chunking id="3" string="took his second-place finish in stride" type="VP">
          <tokens>
            <token id="2" string="took" />
            <token id="3" string="his" />
            <token id="4" string="second-place" />
            <token id="5" string="finish" />
            <token id="6" string="in" />
            <token id="7" string="stride" />
          </tokens>
        </chunking>
        <chunking id="4" string="stride" type="NP">
          <tokens>
            <token id="7" string="stride" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">took</governor>
          <dependent id="1">Johnson</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">took</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">finish</governor>
          <dependent id="3">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">finish</governor>
          <dependent id="4">second-place</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">took</governor>
          <dependent id="5">finish</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">stride</governor>
          <dependent id="6">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">took</governor>
          <dependent id="7">stride</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Johnson" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>&amp;quot;I think it was a success,&amp;quot; Johnson said.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="think" lemma="think" stem="think" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="success" lemma="success" stem="success" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="11" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP I)) (VP (VBP think) (SBAR (S (NP (PRP it)) (VP (VBD was) (NP (DT a) (NN success))))))) (, ,) ('' '') (NP (NNP Johnson)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Johnson" type="NP">
          <tokens>
            <token id="10" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="2" string="it was a success" type="SBAR">
          <tokens>
            <token id="4" string="it" />
            <token id="5" string="was" />
            <token id="6" string="a" />
            <token id="7" string="success" />
          </tokens>
        </chunking>
        <chunking id="3" string="was a success" type="VP">
          <tokens>
            <token id="5" string="was" />
            <token id="6" string="a" />
            <token id="7" string="success" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="think it was a success" type="VP">
          <tokens>
            <token id="3" string="think" />
            <token id="4" string="it" />
            <token id="5" string="was" />
            <token id="6" string="a" />
            <token id="7" string="success" />
          </tokens>
        </chunking>
        <chunking id="6" string="it" type="NP">
          <tokens>
            <token id="4" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="a success" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="success" />
          </tokens>
        </chunking>
        <chunking id="8" string="said" type="VP">
          <tokens>
            <token id="11" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">think</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">said</governor>
          <dependent id="3">think</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">success</governor>
          <dependent id="4">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">success</governor>
          <dependent id="5">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">success</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">think</governor>
          <dependent id="7">success</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">said</governor>
          <dependent id="10">Johnson</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Johnson" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>&amp;quot;There was a lot of pressure on me because it was my first race back, and it was hard to concentrate on the race with the way the fans were yelling for me.&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="There" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="lot" lemma="lot" stem="lot" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="pressure" lemma="pressure" stem="pressur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="my" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="true" />
        <token id="15" string="race" lemma="race" stem="race" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="back" lemma="back" stem="back" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="hard" lemma="hard" stem="hard" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="concentrate" lemma="concentrate" stem="concentr" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="26" string="race" lemma="race" stem="race" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="27" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="way" lemma="way" stem="wai" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="31" string="fans" lemma="fan" stem="fan" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="32" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="yelling" lemma="yell" stem="yell" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="36" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (EX There)) (VP (VBD was) (NP (NP (DT a) (NN lot)) (PP (IN of) (NP (NN pressure)))) (PP (IN on) (NP (PRP me))) (SBAR (IN because) (S (NP (PRP it)) (VP (VBD was) (NP (PRP$ my) (JJ first) (NN race)) (ADVP (RB back))))))) (, ,) (CC and) (S (NP (PRP it)) (VP (VBD was) (ADJP (JJ hard) (S (VP (TO to) (VP (VB concentrate) (PP (IN on) (NP (DT the) (NN race))) (PP (IN with) (NP (NP (DT the) (NN way)) (SBAR (S (NP (DT the) (NNS fans)) (VP (VBD were) (VP (VBG yelling) (PP (IN for) (NP (PRP me))))))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="the way the fans were yelling for me" type="NP">
          <tokens>
            <token id="28" string="the" />
            <token id="29" string="way" />
            <token id="30" string="the" />
            <token id="31" string="fans" />
            <token id="32" string="were" />
            <token id="33" string="yelling" />
            <token id="34" string="for" />
            <token id="35" string="me" />
          </tokens>
        </chunking>
        <chunking id="2" string="yelling for me" type="VP">
          <tokens>
            <token id="33" string="yelling" />
            <token id="34" string="for" />
            <token id="35" string="me" />
          </tokens>
        </chunking>
        <chunking id="3" string="was hard to concentrate on the race with the way the fans were yelling for me" type="VP">
          <tokens>
            <token id="20" string="was" />
            <token id="21" string="hard" />
            <token id="22" string="to" />
            <token id="23" string="concentrate" />
            <token id="24" string="on" />
            <token id="25" string="the" />
            <token id="26" string="race" />
            <token id="27" string="with" />
            <token id="28" string="the" />
            <token id="29" string="way" />
            <token id="30" string="the" />
            <token id="31" string="fans" />
            <token id="32" string="were" />
            <token id="33" string="yelling" />
            <token id="34" string="for" />
            <token id="35" string="me" />
          </tokens>
        </chunking>
        <chunking id="4" string="to concentrate on the race with the way the fans were yelling for me" type="VP">
          <tokens>
            <token id="22" string="to" />
            <token id="23" string="concentrate" />
            <token id="24" string="on" />
            <token id="25" string="the" />
            <token id="26" string="race" />
            <token id="27" string="with" />
            <token id="28" string="the" />
            <token id="29" string="way" />
            <token id="30" string="the" />
            <token id="31" string="fans" />
            <token id="32" string="were" />
            <token id="33" string="yelling" />
            <token id="34" string="for" />
            <token id="35" string="me" />
          </tokens>
        </chunking>
        <chunking id="5" string="concentrate on the race with the way the fans were yelling for me" type="VP">
          <tokens>
            <token id="23" string="concentrate" />
            <token id="24" string="on" />
            <token id="25" string="the" />
            <token id="26" string="race" />
            <token id="27" string="with" />
            <token id="28" string="the" />
            <token id="29" string="way" />
            <token id="30" string="the" />
            <token id="31" string="fans" />
            <token id="32" string="were" />
            <token id="33" string="yelling" />
            <token id="34" string="for" />
            <token id="35" string="me" />
          </tokens>
        </chunking>
        <chunking id="6" string="pressure" type="NP">
          <tokens>
            <token id="7" string="pressure" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="11" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="were yelling for me" type="VP">
          <tokens>
            <token id="32" string="were" />
            <token id="33" string="yelling" />
            <token id="34" string="for" />
            <token id="35" string="me" />
          </tokens>
        </chunking>
        <chunking id="9" string="a lot of pressure" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="lot" />
            <token id="6" string="of" />
            <token id="7" string="pressure" />
          </tokens>
        </chunking>
        <chunking id="10" string="because it was my first race back" type="SBAR">
          <tokens>
            <token id="10" string="because" />
            <token id="11" string="it" />
            <token id="12" string="was" />
            <token id="13" string="my" />
            <token id="14" string="first" />
            <token id="15" string="race" />
            <token id="16" string="back" />
          </tokens>
        </chunking>
        <chunking id="11" string="was my first race back" type="VP">
          <tokens>
            <token id="12" string="was" />
            <token id="13" string="my" />
            <token id="14" string="first" />
            <token id="15" string="race" />
            <token id="16" string="back" />
          </tokens>
        </chunking>
        <chunking id="12" string="the fans" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="fans" />
          </tokens>
        </chunking>
        <chunking id="13" string="There" type="NP">
          <tokens>
            <token id="2" string="There" />
          </tokens>
        </chunking>
        <chunking id="14" string="the way" type="NP">
          <tokens>
            <token id="28" string="the" />
            <token id="29" string="way" />
          </tokens>
        </chunking>
        <chunking id="15" string="a lot" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="lot" />
          </tokens>
        </chunking>
        <chunking id="16" string="me" type="NP">
          <tokens>
            <token id="9" string="me" />
          </tokens>
        </chunking>
        <chunking id="17" string="was a lot of pressure on me because it was my first race back" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="a" />
            <token id="5" string="lot" />
            <token id="6" string="of" />
            <token id="7" string="pressure" />
            <token id="8" string="on" />
            <token id="9" string="me" />
            <token id="10" string="because" />
            <token id="11" string="it" />
            <token id="12" string="was" />
            <token id="13" string="my" />
            <token id="14" string="first" />
            <token id="15" string="race" />
            <token id="16" string="back" />
          </tokens>
        </chunking>
        <chunking id="18" string="hard to concentrate on the race with the way the fans were yelling for me" type="ADJP">
          <tokens>
            <token id="21" string="hard" />
            <token id="22" string="to" />
            <token id="23" string="concentrate" />
            <token id="24" string="on" />
            <token id="25" string="the" />
            <token id="26" string="race" />
            <token id="27" string="with" />
            <token id="28" string="the" />
            <token id="29" string="way" />
            <token id="30" string="the" />
            <token id="31" string="fans" />
            <token id="32" string="were" />
            <token id="33" string="yelling" />
            <token id="34" string="for" />
            <token id="35" string="me" />
          </tokens>
        </chunking>
        <chunking id="19" string="my first race" type="NP">
          <tokens>
            <token id="13" string="my" />
            <token id="14" string="first" />
            <token id="15" string="race" />
          </tokens>
        </chunking>
        <chunking id="20" string="the race" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="race" />
          </tokens>
        </chunking>
        <chunking id="21" string="the fans were yelling for me" type="SBAR">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="fans" />
            <token id="32" string="were" />
            <token id="33" string="yelling" />
            <token id="34" string="for" />
            <token id="35" string="me" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="expl">
          <governor id="3">was</governor>
          <dependent id="2">There</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">lot</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">was</governor>
          <dependent id="5">lot</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">pressure</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">lot</governor>
          <dependent id="7">pressure</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">me</governor>
          <dependent id="8">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">was</governor>
          <dependent id="9">me</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">race</governor>
          <dependent id="10">because</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">race</governor>
          <dependent id="11">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="15">race</governor>
          <dependent id="12">was</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="15">race</governor>
          <dependent id="13">my</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">race</governor>
          <dependent id="14">first</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">was</governor>
          <dependent id="15">race</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">race</governor>
          <dependent id="16">back</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">was</governor>
          <dependent id="18">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">hard</governor>
          <dependent id="19">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="21">hard</governor>
          <dependent id="20">was</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">was</governor>
          <dependent id="21">hard</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="23">concentrate</governor>
          <dependent id="22">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="21">hard</governor>
          <dependent id="23">concentrate</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">race</governor>
          <dependent id="24">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">race</governor>
          <dependent id="25">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">concentrate</governor>
          <dependent id="26">race</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">way</governor>
          <dependent id="27">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">way</governor>
          <dependent id="28">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">concentrate</governor>
          <dependent id="29">way</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">fans</governor>
          <dependent id="30">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="33">yelling</governor>
          <dependent id="31">fans</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="33">yelling</governor>
          <dependent id="32">were</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="29">way</governor>
          <dependent id="33">yelling</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">me</governor>
          <dependent id="34">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="33">yelling</governor>
          <dependent id="35">me</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="14" string="first" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>; It was Johnson&amp;apost;s first indoor loss in 11 meets dating to February 1987.</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="5" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="7" string="indoor" lemma="indoor" stem="indoor" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="loss" lemma="loss" stem="loss" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="11" lemma="11" stem="11" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="11" string="meets" lemma="meet" stem="meet" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="dating" lemma="date" stem="date" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="February" lemma="February" stem="februari" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="15" string="1987" lemma="1987" stem="1987" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ;) (NP (PRP It)) (VP (VBD was) (NP (NP (NP (NNP Johnson) (POS 's)) (JJ first) (JJ indoor) (NN loss)) (PP (IN in) (NP (CD 11))) (SBAR (S (VP (VBZ meets) (S (VP (VBG dating) (PP (TO to) (NP (NNP February) (CD 1987)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="was Johnson 's first indoor loss in 11 meets dating to February 1987" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="Johnson" />
            <token id="5" string="'s" />
            <token id="6" string="first" />
            <token id="7" string="indoor" />
            <token id="8" string="loss" />
            <token id="9" string="in" />
            <token id="10" string="11" />
            <token id="11" string="meets" />
            <token id="12" string="dating" />
            <token id="13" string="to" />
            <token id="14" string="February" />
            <token id="15" string="1987" />
          </tokens>
        </chunking>
        <chunking id="2" string="dating to February 1987" type="VP">
          <tokens>
            <token id="12" string="dating" />
            <token id="13" string="to" />
            <token id="14" string="February" />
            <token id="15" string="1987" />
          </tokens>
        </chunking>
        <chunking id="3" string="meets dating to February 1987" type="SBAR">
          <tokens>
            <token id="11" string="meets" />
            <token id="12" string="dating" />
            <token id="13" string="to" />
            <token id="14" string="February" />
            <token id="15" string="1987" />
          </tokens>
        </chunking>
        <chunking id="4" string="Johnson 's first indoor loss" type="NP">
          <tokens>
            <token id="4" string="Johnson" />
            <token id="5" string="'s" />
            <token id="6" string="first" />
            <token id="7" string="indoor" />
            <token id="8" string="loss" />
          </tokens>
        </chunking>
        <chunking id="5" string="It" type="NP">
          <tokens>
            <token id="2" string="It" />
          </tokens>
        </chunking>
        <chunking id="6" string="February 1987" type="NP">
          <tokens>
            <token id="14" string="February" />
            <token id="15" string="1987" />
          </tokens>
        </chunking>
        <chunking id="7" string="Johnson 's first indoor loss in 11 meets dating to February 1987" type="NP">
          <tokens>
            <token id="4" string="Johnson" />
            <token id="5" string="'s" />
            <token id="6" string="first" />
            <token id="7" string="indoor" />
            <token id="8" string="loss" />
            <token id="9" string="in" />
            <token id="10" string="11" />
            <token id="11" string="meets" />
            <token id="12" string="dating" />
            <token id="13" string="to" />
            <token id="14" string="February" />
            <token id="15" string="1987" />
          </tokens>
        </chunking>
        <chunking id="8" string="Johnson 's" type="NP">
          <tokens>
            <token id="4" string="Johnson" />
            <token id="5" string="'s" />
          </tokens>
        </chunking>
        <chunking id="9" string="11" type="NP">
          <tokens>
            <token id="10" string="11" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="8">loss</governor>
          <dependent id="2">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="8">loss</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">loss</governor>
          <dependent id="4">Johnson</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">Johnson</governor>
          <dependent id="5">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">loss</governor>
          <dependent id="6">first</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">loss</governor>
          <dependent id="7">indoor</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">loss</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">11</governor>
          <dependent id="9">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">loss</governor>
          <dependent id="10">11</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="8">loss</governor>
          <dependent id="11">meets</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="11">meets</governor>
          <dependent id="12">dating</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">February</governor>
          <dependent id="13">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">dating</governor>
          <dependent id="14">February</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="14">February</governor>
          <dependent id="15">1987</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="6" string="first" />
          </tokens>
        </entity>
        <entity id="2" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Johnson" />
          </tokens>
        </entity>
        <entity id="3" string="February 1987" type="DATE" score="0.0">
          <tokens>
            <token id="14" string="February" />
            <token id="15" string="1987" />
          </tokens>
        </entity>
        <entity id="4" string="11" type="NUMBER" score="0.0">
          <tokens>
            <token id="10" string="11" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>His time was far from the 5.55 he ran in 1987 that is still listed as the fastest ever at 50 meters.</content>
      <tokens>
        <token id="1" string="His" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="far" lemma="far" stem="far" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="5.55" lemma="5.55" stem="5.55" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="8" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="ran" lemma="run" stem="ran" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="1987" lemma="1987" stem="1987" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="12" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="still" lemma="still" stem="still" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="listed" lemma="list" stem="list" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="fastest" lemma="fastest" stem="fastest" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="ever" lemma="ever" stem="ever" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="50" lemma="50" stem="50" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="22" string="meters" lemma="meter" stem="meter" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP$ His) (NN time)) (VP (VBD was) (ADVP (RB far) (PP (IN from) (NP (DT the) (CD 5.55)))))) (NP (PRP he)) (VP (VBD ran) (PP (IN in) (NP (NP (CD 1987)) (SBAR (WHNP (WDT that)) (S (VP (VBZ is) (ADVP (RB still)) (VP (VBN listed) (PP (IN as) (NP (NP (DT the) (JJS fastest) (RB ever)) (PP (IN at) (NP (CD 50) (NNS meters)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the 5.55" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="5.55" />
          </tokens>
        </chunking>
        <chunking id="2" string="His time" type="NP">
          <tokens>
            <token id="1" string="His" />
            <token id="2" string="time" />
          </tokens>
        </chunking>
        <chunking id="3" string="the fastest ever at 50 meters" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="fastest" />
            <token id="19" string="ever" />
            <token id="20" string="at" />
            <token id="21" string="50" />
            <token id="22" string="meters" />
          </tokens>
        </chunking>
        <chunking id="4" string="is still listed as the fastest ever at 50 meters" type="VP">
          <tokens>
            <token id="13" string="is" />
            <token id="14" string="still" />
            <token id="15" string="listed" />
            <token id="16" string="as" />
            <token id="17" string="the" />
            <token id="18" string="fastest" />
            <token id="19" string="ever" />
            <token id="20" string="at" />
            <token id="21" string="50" />
            <token id="22" string="meters" />
          </tokens>
        </chunking>
        <chunking id="5" string="1987 that is still listed as the fastest ever at 50 meters" type="NP">
          <tokens>
            <token id="11" string="1987" />
            <token id="12" string="that" />
            <token id="13" string="is" />
            <token id="14" string="still" />
            <token id="15" string="listed" />
            <token id="16" string="as" />
            <token id="17" string="the" />
            <token id="18" string="fastest" />
            <token id="19" string="ever" />
            <token id="20" string="at" />
            <token id="21" string="50" />
            <token id="22" string="meters" />
          </tokens>
        </chunking>
        <chunking id="6" string="1987" type="NP">
          <tokens>
            <token id="11" string="1987" />
          </tokens>
        </chunking>
        <chunking id="7" string="the fastest ever" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="fastest" />
            <token id="19" string="ever" />
          </tokens>
        </chunking>
        <chunking id="8" string="listed as the fastest ever at 50 meters" type="VP">
          <tokens>
            <token id="15" string="listed" />
            <token id="16" string="as" />
            <token id="17" string="the" />
            <token id="18" string="fastest" />
            <token id="19" string="ever" />
            <token id="20" string="at" />
            <token id="21" string="50" />
            <token id="22" string="meters" />
          </tokens>
        </chunking>
        <chunking id="9" string="was far from the 5.55" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="far" />
            <token id="5" string="from" />
            <token id="6" string="the" />
            <token id="7" string="5.55" />
          </tokens>
        </chunking>
        <chunking id="10" string="he" type="NP">
          <tokens>
            <token id="8" string="he" />
          </tokens>
        </chunking>
        <chunking id="11" string="that is still listed as the fastest ever at 50 meters" type="SBAR">
          <tokens>
            <token id="12" string="that" />
            <token id="13" string="is" />
            <token id="14" string="still" />
            <token id="15" string="listed" />
            <token id="16" string="as" />
            <token id="17" string="the" />
            <token id="18" string="fastest" />
            <token id="19" string="ever" />
            <token id="20" string="at" />
            <token id="21" string="50" />
            <token id="22" string="meters" />
          </tokens>
        </chunking>
        <chunking id="12" string="ran in 1987 that is still listed as the fastest ever at 50 meters" type="VP">
          <tokens>
            <token id="9" string="ran" />
            <token id="10" string="in" />
            <token id="11" string="1987" />
            <token id="12" string="that" />
            <token id="13" string="is" />
            <token id="14" string="still" />
            <token id="15" string="listed" />
            <token id="16" string="as" />
            <token id="17" string="the" />
            <token id="18" string="fastest" />
            <token id="19" string="ever" />
            <token id="20" string="at" />
            <token id="21" string="50" />
            <token id="22" string="meters" />
          </tokens>
        </chunking>
        <chunking id="13" string="50 meters" type="NP">
          <tokens>
            <token id="21" string="50" />
            <token id="22" string="meters" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="2">time</governor>
          <dependent id="1">His</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">was</governor>
          <dependent id="2">time</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="9">ran</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">5.55</governor>
          <dependent id="4">far</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="4">far</governor>
          <dependent id="5">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">5.55</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">was</governor>
          <dependent id="7">5.55</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">ran</governor>
          <dependent id="8">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">ran</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">1987</governor>
          <dependent id="10">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">ran</governor>
          <dependent id="11">1987</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="15">listed</governor>
          <dependent id="12">that</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="15">listed</governor>
          <dependent id="13">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">listed</governor>
          <dependent id="14">still</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="11">1987</governor>
          <dependent id="15">listed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">ever</governor>
          <dependent id="16">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">ever</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">ever</governor>
          <dependent id="18">fastest</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">listed</governor>
          <dependent id="19">ever</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">meters</governor>
          <dependent id="20">at</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="22">meters</governor>
          <dependent id="21">50</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">ever</governor>
          <dependent id="22">meters</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="5.55" type="NUMBER" score="0.0">
          <tokens>
            <token id="7" string="5.55" />
          </tokens>
        </entity>
        <entity id="2" string="1987" type="DATE" score="0.0">
          <tokens>
            <token id="11" string="1987" />
          </tokens>
        </entity>
        <entity id="3" string="50" type="NUMBER" score="0.0">
          <tokens>
            <token id="21" string="50" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>&amp;quot;I&amp;apost;m in very good shape, but I&amp;apost;m not in racing shape,&amp;quot; Johnson said as he was escorted to drug testing, for which he was randomly selected.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="'m" lemma="be" stem="'m" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="very" lemma="very" stem="veri" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="good" lemma="good" stem="good" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="shape" lemma="shape" stem="shape" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="'m" lemma="be" stem="'m" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="racing" lemma="race" stem="race" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="shape" lemma="shape" stem="shape" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="19" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="escorted" lemma="escort" stem="escort" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="drug" lemma="drug" stem="drug" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="testing" lemma="testing" stem="test" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="31" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="randomly" lemma="randomly" stem="randomli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="selected" lemma="select" stem="select" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (S (NP (PRP I)) (VP (VBP 'm) (PP (IN in) (NP (ADJP (RB very) (JJ good)) (NN shape))))) (, ,) (CC but) (S (NP (PRP I)) (VP (VBP 'm) (RB not) (PP (IN in) (NP (VBG racing) (NN shape)))))) (, ,) ('' '') (NP (NNP Johnson)) (VP (VBD said) (SBAR (IN as) (S (NP (PRP he)) (VP (VBD was) (VP (VBN escorted) (PP (TO to) (NP (NP (NN drug) (NN testing)) (, ,) (SBAR (WHPP (IN for) (WHNP (WDT which))) (S (NP (PRP he)) (VP (VBD was) (ADJP (RB randomly) (VBN selected)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="as he was escorted to drug testing , for which he was randomly selected" type="SBAR">
          <tokens>
            <token id="20" string="as" />
            <token id="21" string="he" />
            <token id="22" string="was" />
            <token id="23" string="escorted" />
            <token id="24" string="to" />
            <token id="25" string="drug" />
            <token id="26" string="testing" />
            <token id="27" string="," />
            <token id="28" string="for" />
            <token id="29" string="which" />
            <token id="30" string="he" />
            <token id="31" string="was" />
            <token id="32" string="randomly" />
            <token id="33" string="selected" />
          </tokens>
        </chunking>
        <chunking id="2" string="Johnson" type="NP">
          <tokens>
            <token id="18" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="3" string="'m in very good shape" type="VP">
          <tokens>
            <token id="3" string="'m" />
            <token id="4" string="in" />
            <token id="5" string="very" />
            <token id="6" string="good" />
            <token id="7" string="shape" />
          </tokens>
        </chunking>
        <chunking id="4" string="randomly selected" type="ADJP">
          <tokens>
            <token id="32" string="randomly" />
            <token id="33" string="selected" />
          </tokens>
        </chunking>
        <chunking id="5" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="6" string="was randomly selected" type="VP">
          <tokens>
            <token id="31" string="was" />
            <token id="32" string="randomly" />
            <token id="33" string="selected" />
          </tokens>
        </chunking>
        <chunking id="7" string="very good" type="ADJP">
          <tokens>
            <token id="5" string="very" />
            <token id="6" string="good" />
          </tokens>
        </chunking>
        <chunking id="8" string="racing shape" type="NP">
          <tokens>
            <token id="14" string="racing" />
            <token id="15" string="shape" />
          </tokens>
        </chunking>
        <chunking id="9" string="very good shape" type="NP">
          <tokens>
            <token id="5" string="very" />
            <token id="6" string="good" />
            <token id="7" string="shape" />
          </tokens>
        </chunking>
        <chunking id="10" string="'m not in racing shape" type="VP">
          <tokens>
            <token id="11" string="'m" />
            <token id="12" string="not" />
            <token id="13" string="in" />
            <token id="14" string="racing" />
            <token id="15" string="shape" />
          </tokens>
        </chunking>
        <chunking id="11" string="said as he was escorted to drug testing , for which he was randomly selected" type="VP">
          <tokens>
            <token id="19" string="said" />
            <token id="20" string="as" />
            <token id="21" string="he" />
            <token id="22" string="was" />
            <token id="23" string="escorted" />
            <token id="24" string="to" />
            <token id="25" string="drug" />
            <token id="26" string="testing" />
            <token id="27" string="," />
            <token id="28" string="for" />
            <token id="29" string="which" />
            <token id="30" string="he" />
            <token id="31" string="was" />
            <token id="32" string="randomly" />
            <token id="33" string="selected" />
          </tokens>
        </chunking>
        <chunking id="12" string="was escorted to drug testing , for which he was randomly selected" type="VP">
          <tokens>
            <token id="22" string="was" />
            <token id="23" string="escorted" />
            <token id="24" string="to" />
            <token id="25" string="drug" />
            <token id="26" string="testing" />
            <token id="27" string="," />
            <token id="28" string="for" />
            <token id="29" string="which" />
            <token id="30" string="he" />
            <token id="31" string="was" />
            <token id="32" string="randomly" />
            <token id="33" string="selected" />
          </tokens>
        </chunking>
        <chunking id="13" string="escorted to drug testing , for which he was randomly selected" type="VP">
          <tokens>
            <token id="23" string="escorted" />
            <token id="24" string="to" />
            <token id="25" string="drug" />
            <token id="26" string="testing" />
            <token id="27" string="," />
            <token id="28" string="for" />
            <token id="29" string="which" />
            <token id="30" string="he" />
            <token id="31" string="was" />
            <token id="32" string="randomly" />
            <token id="33" string="selected" />
          </tokens>
        </chunking>
        <chunking id="14" string="he" type="NP">
          <tokens>
            <token id="21" string="he" />
          </tokens>
        </chunking>
        <chunking id="15" string="drug testing" type="NP">
          <tokens>
            <token id="25" string="drug" />
            <token id="26" string="testing" />
          </tokens>
        </chunking>
        <chunking id="16" string="drug testing , for which he was randomly selected" type="NP">
          <tokens>
            <token id="25" string="drug" />
            <token id="26" string="testing" />
            <token id="27" string="," />
            <token id="28" string="for" />
            <token id="29" string="which" />
            <token id="30" string="he" />
            <token id="31" string="was" />
            <token id="32" string="randomly" />
            <token id="33" string="selected" />
          </tokens>
        </chunking>
        <chunking id="17" string="for which he was randomly selected" type="SBAR">
          <tokens>
            <token id="28" string="for" />
            <token id="29" string="which" />
            <token id="30" string="he" />
            <token id="31" string="was" />
            <token id="32" string="randomly" />
            <token id="33" string="selected" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="7">shape</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">shape</governor>
          <dependent id="3">'m</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">shape</governor>
          <dependent id="4">in</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">good</governor>
          <dependent id="5">very</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">shape</governor>
          <dependent id="6">good</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="19">said</governor>
          <dependent id="7">shape</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">shape</governor>
          <dependent id="9">but</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">shape</governor>
          <dependent id="10">I</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="15">shape</governor>
          <dependent id="11">'m</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="15">shape</governor>
          <dependent id="12">not</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">shape</governor>
          <dependent id="13">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">shape</governor>
          <dependent id="14">racing</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">shape</governor>
          <dependent id="15">shape</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">said</governor>
          <dependent id="18">Johnson</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="19">said</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="23">escorted</governor>
          <dependent id="20">as</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="23">escorted</governor>
          <dependent id="21">he</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="23">escorted</governor>
          <dependent id="22">was</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="19">said</governor>
          <dependent id="23">escorted</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">testing</governor>
          <dependent id="24">to</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">testing</governor>
          <dependent id="25">drug</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">escorted</governor>
          <dependent id="26">testing</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">which</governor>
          <dependent id="28">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="33">selected</governor>
          <dependent id="29">which</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="33">selected</governor>
          <dependent id="30">he</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="33">selected</governor>
          <dependent id="31">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="33">selected</governor>
          <dependent id="32">randomly</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="26">testing</governor>
          <dependent id="33">selected</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="18" string="Johnson" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>It was a different-looking Johnson than the one who had bolted to apparent victory in the Olympics.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="different-looking" lemma="different-looking" stem="different-look" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="6" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="9" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="bolted" lemma="bolt" stem="bolt" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="apparent" lemma="apparent" stem="appar" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="victory" lemma="victory" stem="victori" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="17" string="Olympics" lemma="Olympics" stem="olympic" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="true" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP It)) (VP (VBD was) (NP (NP (DT a) (JJ different-looking) (NNP Johnson)) (PP (IN than) (NP (DT the) (CD one))) (SBAR (WHNP (WP who)) (S (VP (VBD had) (VP (VBN bolted) (PP (TO to) (NP (NP (JJ apparent) (NN victory)) (PP (IN in) (NP (DT the) (NNPS Olympics))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="apparent victory in the Olympics" type="NP">
          <tokens>
            <token id="13" string="apparent" />
            <token id="14" string="victory" />
            <token id="15" string="in" />
            <token id="16" string="the" />
            <token id="17" string="Olympics" />
          </tokens>
        </chunking>
        <chunking id="2" string="a different-looking Johnson" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="different-looking" />
            <token id="5" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="3" string="the Olympics" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="Olympics" />
          </tokens>
        </chunking>
        <chunking id="4" string="bolted to apparent victory in the Olympics" type="VP">
          <tokens>
            <token id="11" string="bolted" />
            <token id="12" string="to" />
            <token id="13" string="apparent" />
            <token id="14" string="victory" />
            <token id="15" string="in" />
            <token id="16" string="the" />
            <token id="17" string="Olympics" />
          </tokens>
        </chunking>
        <chunking id="5" string="who had bolted to apparent victory in the Olympics" type="SBAR">
          <tokens>
            <token id="9" string="who" />
            <token id="10" string="had" />
            <token id="11" string="bolted" />
            <token id="12" string="to" />
            <token id="13" string="apparent" />
            <token id="14" string="victory" />
            <token id="15" string="in" />
            <token id="16" string="the" />
            <token id="17" string="Olympics" />
          </tokens>
        </chunking>
        <chunking id="6" string="had bolted to apparent victory in the Olympics" type="VP">
          <tokens>
            <token id="10" string="had" />
            <token id="11" string="bolted" />
            <token id="12" string="to" />
            <token id="13" string="apparent" />
            <token id="14" string="victory" />
            <token id="15" string="in" />
            <token id="16" string="the" />
            <token id="17" string="Olympics" />
          </tokens>
        </chunking>
        <chunking id="7" string="apparent victory" type="NP">
          <tokens>
            <token id="13" string="apparent" />
            <token id="14" string="victory" />
          </tokens>
        </chunking>
        <chunking id="8" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="9" string="the one" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="one" />
          </tokens>
        </chunking>
        <chunking id="10" string="was a different-looking Johnson than the one who had bolted to apparent victory in the Olympics" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="a" />
            <token id="4" string="different-looking" />
            <token id="5" string="Johnson" />
            <token id="6" string="than" />
            <token id="7" string="the" />
            <token id="8" string="one" />
            <token id="9" string="who" />
            <token id="10" string="had" />
            <token id="11" string="bolted" />
            <token id="12" string="to" />
            <token id="13" string="apparent" />
            <token id="14" string="victory" />
            <token id="15" string="in" />
            <token id="16" string="the" />
            <token id="17" string="Olympics" />
          </tokens>
        </chunking>
        <chunking id="11" string="a different-looking Johnson than the one who had bolted to apparent victory in the Olympics" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="different-looking" />
            <token id="5" string="Johnson" />
            <token id="6" string="than" />
            <token id="7" string="the" />
            <token id="8" string="one" />
            <token id="9" string="who" />
            <token id="10" string="had" />
            <token id="11" string="bolted" />
            <token id="12" string="to" />
            <token id="13" string="apparent" />
            <token id="14" string="victory" />
            <token id="15" string="in" />
            <token id="16" string="the" />
            <token id="17" string="Olympics" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">Johnson</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">Johnson</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">Johnson</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">Johnson</governor>
          <dependent id="4">different-looking</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">Johnson</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">one</governor>
          <dependent id="6">than</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">one</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">Johnson</governor>
          <dependent id="8">one</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">bolted</governor>
          <dependent id="9">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">bolted</governor>
          <dependent id="10">had</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="5">Johnson</governor>
          <dependent id="11">bolted</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">victory</governor>
          <dependent id="12">to</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">victory</governor>
          <dependent id="13">apparent</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">bolted</governor>
          <dependent id="14">victory</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">Olympics</governor>
          <dependent id="15">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">Olympics</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">victory</governor>
          <dependent id="17">Olympics</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Johnson" />
          </tokens>
        </entity>
        <entity id="2" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="8" string="one" />
          </tokens>
        </entity>
        <entity id="3" string="Olympics" type="MISC" score="0.0">
          <tokens>
            <token id="17" string="Olympics" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="17" has_coreference="true">
      <content>This Johnson wasn&amp;apost;t as bulky in the upper body, nor was his face as puffy.</content>
      <tokens>
        <token id="1" string="This" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="bulky" lemma="bulky" stem="bulki" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="upper" lemma="upper" stem="upper" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="body" lemma="body" stem="bodi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="nor" lemma="nor" stem="nor" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="face" lemma="face" stem="face" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="puffy" lemma="puffy" stem="puffi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (DT This) (NNP Johnson)) (VP (VBD was) (RB n't) (PP (IN as) (NP (NP (JJ bulky)) (PP (IN in) (NP (DT the) (JJ upper) (NN body))))))) (, ,) (CC nor) (SQ (VBD was) (NP (NP (PRP$ his) (NN face)) (PP (IN as) (NP (NN puffy))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="his face" type="NP">
          <tokens>
            <token id="14" string="his" />
            <token id="15" string="face" />
          </tokens>
        </chunking>
        <chunking id="2" string="puffy" type="NP">
          <tokens>
            <token id="17" string="puffy" />
          </tokens>
        </chunking>
        <chunking id="3" string="the upper body" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="upper" />
            <token id="10" string="body" />
          </tokens>
        </chunking>
        <chunking id="4" string="was n't as bulky in the upper body" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="n't" />
            <token id="5" string="as" />
            <token id="6" string="bulky" />
            <token id="7" string="in" />
            <token id="8" string="the" />
            <token id="9" string="upper" />
            <token id="10" string="body" />
          </tokens>
        </chunking>
        <chunking id="5" string="bulky in the upper body" type="NP">
          <tokens>
            <token id="6" string="bulky" />
            <token id="7" string="in" />
            <token id="8" string="the" />
            <token id="9" string="upper" />
            <token id="10" string="body" />
          </tokens>
        </chunking>
        <chunking id="6" string="bulky" type="NP">
          <tokens>
            <token id="6" string="bulky" />
          </tokens>
        </chunking>
        <chunking id="7" string="his face as puffy" type="NP">
          <tokens>
            <token id="14" string="his" />
            <token id="15" string="face" />
            <token id="16" string="as" />
            <token id="17" string="puffy" />
          </tokens>
        </chunking>
        <chunking id="8" string="This Johnson" type="NP">
          <tokens>
            <token id="1" string="This" />
            <token id="2" string="Johnson" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">Johnson</governor>
          <dependent id="1">This</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">bulky</governor>
          <dependent id="2">Johnson</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">bulky</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="6">bulky</governor>
          <dependent id="4">n't</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">bulky</governor>
          <dependent id="5">as</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">bulky</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">body</governor>
          <dependent id="7">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">body</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">body</governor>
          <dependent id="9">upper</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">bulky</governor>
          <dependent id="10">body</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">bulky</governor>
          <dependent id="12">nor</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">bulky</governor>
          <dependent id="13">was</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="15">face</governor>
          <dependent id="14">his</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">was</governor>
          <dependent id="15">face</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">puffy</governor>
          <dependent id="16">as</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">face</governor>
          <dependent id="17">puffy</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Johnson" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="18" has_coreference="true">
      <content>Despite Johnson&amp;apost;s trimness, he said he weighed the same -- 174 pounds -- and was lifting the same amount of weight -- bench-pressing 365 pounds -- as before his two-year suspension for testing positive for a performance-enhancing steroid.</content>
      <tokens>
        <token id="1" string="Despite" lemma="despite" stem="despit" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="3" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="4" string="trimness" lemma="trimness" stem="trim" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="weighed" lemma="weigh" stem="weigh" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="same" lemma="same" stem="same" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="174" lemma="174" stem="174" pos="CD" type="Number" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="14" string="pounds" lemma="pound" stem="pound" pos="NNS" type="Word" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="15" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="lifting" lemma="lift" stem="lift" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="same" lemma="same" stem="same" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="amount" lemma="amount" stem="amount" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="weight" lemma="weight" stem="weight" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="bench-pressing" lemma="bench-press" stem="bench-press" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="365" lemma="365" stem="365" pos="CD" type="Number" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="27" string="pounds" lemma="pound" stem="pound" pos="NNS" type="Word" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="28" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="before" lemma="before" stem="befor" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="32" string="two-year" lemma="two-year" stem="two-year" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="true" />
        <token id="33" string="suspension" lemma="suspension" stem="suspens" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="34" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="testing" lemma="testing" stem="test" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="positive" lemma="positive" stem="posit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="39" string="performance-enhancing" lemma="performance-enhancing" stem="performance-enhanc" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="40" string="steroid" lemma="steroid" stem="steroid" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="41" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN Despite) (NP (NP (NNP Johnson) (POS 's)) (NN trimness))) (, ,) (NP (PRP he)) (VP (VBD said) (SBAR (S (NP (PRP he)) (VP (VP (VBD weighed) (NP (NP (DT the) (JJ same)) (PRN (: --) (NP (CD 174) (NNS pounds)) (: --)))) (CC and) (VP (VBD was) (VP (VBG lifting) (NP (NP (DT the) (JJ same) (NN amount)) (PP (IN of) (NP (NN weight))) (PRN (: --) (VP (VBG bench-pressing) (NP (CD 365) (NNS pounds))) (: --)) (ADJP (IN as) (PP (IN before) (NP (PRP$ his) (JJ two-year) (NN suspension))) (PP (IN for) (NP (NP (NN testing)) (ADJP (JJ positive) (PP (IN for) (NP (DT a) (JJ performance-enhancing) (NN steroid)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="174 pounds" type="NP">
          <tokens>
            <token id="13" string="174" />
            <token id="14" string="pounds" />
          </tokens>
        </chunking>
        <chunking id="2" string="his two-year suspension" type="NP">
          <tokens>
            <token id="31" string="his" />
            <token id="32" string="two-year" />
            <token id="33" string="suspension" />
          </tokens>
        </chunking>
        <chunking id="3" string="a performance-enhancing steroid" type="NP">
          <tokens>
            <token id="38" string="a" />
            <token id="39" string="performance-enhancing" />
            <token id="40" string="steroid" />
          </tokens>
        </chunking>
        <chunking id="4" string="the same -- 174 pounds --" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="same" />
            <token id="12" string="--" />
            <token id="13" string="174" />
            <token id="14" string="pounds" />
            <token id="15" string="--" />
          </tokens>
        </chunking>
        <chunking id="5" string="weight" type="NP">
          <tokens>
            <token id="23" string="weight" />
          </tokens>
        </chunking>
        <chunking id="6" string="positive for a performance-enhancing steroid" type="ADJP">
          <tokens>
            <token id="36" string="positive" />
            <token id="37" string="for" />
            <token id="38" string="a" />
            <token id="39" string="performance-enhancing" />
            <token id="40" string="steroid" />
          </tokens>
        </chunking>
        <chunking id="7" string="bench-pressing 365 pounds" type="VP">
          <tokens>
            <token id="25" string="bench-pressing" />
            <token id="26" string="365" />
            <token id="27" string="pounds" />
          </tokens>
        </chunking>
        <chunking id="8" string="Johnson 's trimness" type="NP">
          <tokens>
            <token id="2" string="Johnson" />
            <token id="3" string="'s" />
            <token id="4" string="trimness" />
          </tokens>
        </chunking>
        <chunking id="9" string="said he weighed the same -- 174 pounds -- and was lifting the same amount of weight -- bench-pressing 365 pounds -- as before his two-year suspension for testing positive for a performance-enhancing steroid" type="VP">
          <tokens>
            <token id="7" string="said" />
            <token id="8" string="he" />
            <token id="9" string="weighed" />
            <token id="10" string="the" />
            <token id="11" string="same" />
            <token id="12" string="--" />
            <token id="13" string="174" />
            <token id="14" string="pounds" />
            <token id="15" string="--" />
            <token id="16" string="and" />
            <token id="17" string="was" />
            <token id="18" string="lifting" />
            <token id="19" string="the" />
            <token id="20" string="same" />
            <token id="21" string="amount" />
            <token id="22" string="of" />
            <token id="23" string="weight" />
            <token id="24" string="--" />
            <token id="25" string="bench-pressing" />
            <token id="26" string="365" />
            <token id="27" string="pounds" />
            <token id="28" string="--" />
            <token id="29" string="as" />
            <token id="30" string="before" />
            <token id="31" string="his" />
            <token id="32" string="two-year" />
            <token id="33" string="suspension" />
            <token id="34" string="for" />
            <token id="35" string="testing" />
            <token id="36" string="positive" />
            <token id="37" string="for" />
            <token id="38" string="a" />
            <token id="39" string="performance-enhancing" />
            <token id="40" string="steroid" />
          </tokens>
        </chunking>
        <chunking id="10" string="lifting the same amount of weight -- bench-pressing 365 pounds -- as before his two-year suspension for testing positive for a performance-enhancing steroid" type="VP">
          <tokens>
            <token id="18" string="lifting" />
            <token id="19" string="the" />
            <token id="20" string="same" />
            <token id="21" string="amount" />
            <token id="22" string="of" />
            <token id="23" string="weight" />
            <token id="24" string="--" />
            <token id="25" string="bench-pressing" />
            <token id="26" string="365" />
            <token id="27" string="pounds" />
            <token id="28" string="--" />
            <token id="29" string="as" />
            <token id="30" string="before" />
            <token id="31" string="his" />
            <token id="32" string="two-year" />
            <token id="33" string="suspension" />
            <token id="34" string="for" />
            <token id="35" string="testing" />
            <token id="36" string="positive" />
            <token id="37" string="for" />
            <token id="38" string="a" />
            <token id="39" string="performance-enhancing" />
            <token id="40" string="steroid" />
          </tokens>
        </chunking>
        <chunking id="11" string="weighed the same -- 174 pounds -- and was lifting the same amount of weight -- bench-pressing 365 pounds -- as before his two-year suspension for testing positive for a performance-enhancing steroid" type="VP">
          <tokens>
            <token id="9" string="weighed" />
            <token id="10" string="the" />
            <token id="11" string="same" />
            <token id="12" string="--" />
            <token id="13" string="174" />
            <token id="14" string="pounds" />
            <token id="15" string="--" />
            <token id="16" string="and" />
            <token id="17" string="was" />
            <token id="18" string="lifting" />
            <token id="19" string="the" />
            <token id="20" string="same" />
            <token id="21" string="amount" />
            <token id="22" string="of" />
            <token id="23" string="weight" />
            <token id="24" string="--" />
            <token id="25" string="bench-pressing" />
            <token id="26" string="365" />
            <token id="27" string="pounds" />
            <token id="28" string="--" />
            <token id="29" string="as" />
            <token id="30" string="before" />
            <token id="31" string="his" />
            <token id="32" string="two-year" />
            <token id="33" string="suspension" />
            <token id="34" string="for" />
            <token id="35" string="testing" />
            <token id="36" string="positive" />
            <token id="37" string="for" />
            <token id="38" string="a" />
            <token id="39" string="performance-enhancing" />
            <token id="40" string="steroid" />
          </tokens>
        </chunking>
        <chunking id="12" string="was lifting the same amount of weight -- bench-pressing 365 pounds -- as before his two-year suspension for testing positive for a performance-enhancing steroid" type="VP">
          <tokens>
            <token id="17" string="was" />
            <token id="18" string="lifting" />
            <token id="19" string="the" />
            <token id="20" string="same" />
            <token id="21" string="amount" />
            <token id="22" string="of" />
            <token id="23" string="weight" />
            <token id="24" string="--" />
            <token id="25" string="bench-pressing" />
            <token id="26" string="365" />
            <token id="27" string="pounds" />
            <token id="28" string="--" />
            <token id="29" string="as" />
            <token id="30" string="before" />
            <token id="31" string="his" />
            <token id="32" string="two-year" />
            <token id="33" string="suspension" />
            <token id="34" string="for" />
            <token id="35" string="testing" />
            <token id="36" string="positive" />
            <token id="37" string="for" />
            <token id="38" string="a" />
            <token id="39" string="performance-enhancing" />
            <token id="40" string="steroid" />
          </tokens>
        </chunking>
        <chunking id="13" string="testing positive for a performance-enhancing steroid" type="NP">
          <tokens>
            <token id="35" string="testing" />
            <token id="36" string="positive" />
            <token id="37" string="for" />
            <token id="38" string="a" />
            <token id="39" string="performance-enhancing" />
            <token id="40" string="steroid" />
          </tokens>
        </chunking>
        <chunking id="14" string="weighed the same -- 174 pounds --" type="VP">
          <tokens>
            <token id="9" string="weighed" />
            <token id="10" string="the" />
            <token id="11" string="same" />
            <token id="12" string="--" />
            <token id="13" string="174" />
            <token id="14" string="pounds" />
            <token id="15" string="--" />
          </tokens>
        </chunking>
        <chunking id="15" string="the same" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="same" />
          </tokens>
        </chunking>
        <chunking id="16" string="testing" type="NP">
          <tokens>
            <token id="35" string="testing" />
          </tokens>
        </chunking>
        <chunking id="17" string="the same amount" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="same" />
            <token id="21" string="amount" />
          </tokens>
        </chunking>
        <chunking id="18" string="he weighed the same -- 174 pounds -- and was lifting the same amount of weight -- bench-pressing 365 pounds -- as before his two-year suspension for testing positive for a performance-enhancing steroid" type="SBAR">
          <tokens>
            <token id="8" string="he" />
            <token id="9" string="weighed" />
            <token id="10" string="the" />
            <token id="11" string="same" />
            <token id="12" string="--" />
            <token id="13" string="174" />
            <token id="14" string="pounds" />
            <token id="15" string="--" />
            <token id="16" string="and" />
            <token id="17" string="was" />
            <token id="18" string="lifting" />
            <token id="19" string="the" />
            <token id="20" string="same" />
            <token id="21" string="amount" />
            <token id="22" string="of" />
            <token id="23" string="weight" />
            <token id="24" string="--" />
            <token id="25" string="bench-pressing" />
            <token id="26" string="365" />
            <token id="27" string="pounds" />
            <token id="28" string="--" />
            <token id="29" string="as" />
            <token id="30" string="before" />
            <token id="31" string="his" />
            <token id="32" string="two-year" />
            <token id="33" string="suspension" />
            <token id="34" string="for" />
            <token id="35" string="testing" />
            <token id="36" string="positive" />
            <token id="37" string="for" />
            <token id="38" string="a" />
            <token id="39" string="performance-enhancing" />
            <token id="40" string="steroid" />
          </tokens>
        </chunking>
        <chunking id="19" string="he" type="NP">
          <tokens>
            <token id="6" string="he" />
          </tokens>
        </chunking>
        <chunking id="20" string="the same amount of weight -- bench-pressing 365 pounds -- as before his two-year suspension for testing positive for a performance-enhancing steroid" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="same" />
            <token id="21" string="amount" />
            <token id="22" string="of" />
            <token id="23" string="weight" />
            <token id="24" string="--" />
            <token id="25" string="bench-pressing" />
            <token id="26" string="365" />
            <token id="27" string="pounds" />
            <token id="28" string="--" />
            <token id="29" string="as" />
            <token id="30" string="before" />
            <token id="31" string="his" />
            <token id="32" string="two-year" />
            <token id="33" string="suspension" />
            <token id="34" string="for" />
            <token id="35" string="testing" />
            <token id="36" string="positive" />
            <token id="37" string="for" />
            <token id="38" string="a" />
            <token id="39" string="performance-enhancing" />
            <token id="40" string="steroid" />
          </tokens>
        </chunking>
        <chunking id="21" string="365 pounds" type="NP">
          <tokens>
            <token id="26" string="365" />
            <token id="27" string="pounds" />
          </tokens>
        </chunking>
        <chunking id="22" string="as before his two-year suspension for testing positive for a performance-enhancing steroid" type="ADJP">
          <tokens>
            <token id="29" string="as" />
            <token id="30" string="before" />
            <token id="31" string="his" />
            <token id="32" string="two-year" />
            <token id="33" string="suspension" />
            <token id="34" string="for" />
            <token id="35" string="testing" />
            <token id="36" string="positive" />
            <token id="37" string="for" />
            <token id="38" string="a" />
            <token id="39" string="performance-enhancing" />
            <token id="40" string="steroid" />
          </tokens>
        </chunking>
        <chunking id="23" string="Johnson 's" type="NP">
          <tokens>
            <token id="2" string="Johnson" />
            <token id="3" string="'s" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">trimness</governor>
          <dependent id="1">Despite</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">trimness</governor>
          <dependent id="2">Johnson</dependent>
        </dependency>
        <dependency type="case">
          <governor id="2">Johnson</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">said</governor>
          <dependent id="4">trimness</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">said</governor>
          <dependent id="6">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">weighed</governor>
          <dependent id="8">he</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">said</governor>
          <dependent id="9">weighed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">same</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">weighed</governor>
          <dependent id="11">same</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="14">pounds</governor>
          <dependent id="13">174</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="11">same</governor>
          <dependent id="14">pounds</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">weighed</governor>
          <dependent id="16">and</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="18">lifting</governor>
          <dependent id="17">was</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">weighed</governor>
          <dependent id="18">lifting</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">amount</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">amount</governor>
          <dependent id="20">same</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">lifting</governor>
          <dependent id="21">amount</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">weight</governor>
          <dependent id="22">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">amount</governor>
          <dependent id="23">weight</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="21">amount</governor>
          <dependent id="25">bench-pressing</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="27">pounds</governor>
          <dependent id="26">365</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="25">bench-pressing</governor>
          <dependent id="27">pounds</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">amount</governor>
          <dependent id="29">as</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">suspension</governor>
          <dependent id="30">before</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="33">suspension</governor>
          <dependent id="31">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="33">suspension</governor>
          <dependent id="32">two-year</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">as</governor>
          <dependent id="33">suspension</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">testing</governor>
          <dependent id="34">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">as</governor>
          <dependent id="35">testing</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="35">testing</governor>
          <dependent id="36">positive</dependent>
        </dependency>
        <dependency type="case">
          <governor id="40">steroid</governor>
          <dependent id="37">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="40">steroid</governor>
          <dependent id="38">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="40">steroid</governor>
          <dependent id="39">performance-enhancing</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="36">positive</governor>
          <dependent id="40">steroid</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="174 pounds" type="MONEY" score="0.0">
          <tokens>
            <token id="13" string="174" />
            <token id="14" string="pounds" />
          </tokens>
        </entity>
        <entity id="2" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Johnson" />
          </tokens>
        </entity>
        <entity id="3" string="two-year" type="DURATION" score="0.0">
          <tokens>
            <token id="32" string="two-year" />
          </tokens>
        </entity>
        <entity id="4" string="365 pounds" type="MONEY" score="0.0">
          <tokens>
            <token id="26" string="365" />
            <token id="27" string="pounds" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="19" has_coreference="true">
      <content>&amp;quot;People are saying I&amp;apost;m smaller,&amp;quot; Johnson said before the race.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="People" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="saying" lemma="say" stem="sai" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="'m" lemma="be" stem="'m" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="smaller" lemma="smaller" stem="smaller" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="11" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="before" lemma="before" stem="befor" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="race" lemma="race" stem="race" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (NNS People)) (VP (VBP are) (VP (VBG saying) (SBAR (S (NP (PRP I)) (VP (VBP 'm) (ADJP (JJR smaller)))))))) (, ,) ('' '') (NP (NNP Johnson)) (VP (VBD said) (PP (IN before) (NP (DT the) (NN race)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="are saying I 'm smaller" type="VP">
          <tokens>
            <token id="3" string="are" />
            <token id="4" string="saying" />
            <token id="5" string="I" />
            <token id="6" string="'m" />
            <token id="7" string="smaller" />
          </tokens>
        </chunking>
        <chunking id="2" string="Johnson" type="NP">
          <tokens>
            <token id="10" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="3" string="said before the race" type="VP">
          <tokens>
            <token id="11" string="said" />
            <token id="12" string="before" />
            <token id="13" string="the" />
            <token id="14" string="race" />
          </tokens>
        </chunking>
        <chunking id="4" string="smaller" type="ADJP">
          <tokens>
            <token id="7" string="smaller" />
          </tokens>
        </chunking>
        <chunking id="5" string="'m smaller" type="VP">
          <tokens>
            <token id="6" string="'m" />
            <token id="7" string="smaller" />
          </tokens>
        </chunking>
        <chunking id="6" string="saying I 'm smaller" type="VP">
          <tokens>
            <token id="4" string="saying" />
            <token id="5" string="I" />
            <token id="6" string="'m" />
            <token id="7" string="smaller" />
          </tokens>
        </chunking>
        <chunking id="7" string="I" type="NP">
          <tokens>
            <token id="5" string="I" />
          </tokens>
        </chunking>
        <chunking id="8" string="People" type="NP">
          <tokens>
            <token id="2" string="People" />
          </tokens>
        </chunking>
        <chunking id="9" string="the race" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="race" />
          </tokens>
        </chunking>
        <chunking id="10" string="I 'm smaller" type="SBAR">
          <tokens>
            <token id="5" string="I" />
            <token id="6" string="'m" />
            <token id="7" string="smaller" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">saying</governor>
          <dependent id="2">People</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">saying</governor>
          <dependent id="3">are</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">said</governor>
          <dependent id="4">saying</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">smaller</governor>
          <dependent id="5">I</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">smaller</governor>
          <dependent id="6">'m</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">saying</governor>
          <dependent id="7">smaller</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">said</governor>
          <dependent id="10">Johnson</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">said</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">race</governor>
          <dependent id="12">before</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">race</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">said</governor>
          <dependent id="14">race</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Johnson" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="20" has_coreference="false">
      <content>&amp;quot;Size doesn&amp;apost;t matter.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Size" lemma="size" stem="size" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="does" lemma="do" stem="doe" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="matter" lemma="matter" stem="matter" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (NN Size)) (VP (VBZ does) (RB n't) (VP (VB matter))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="does n't matter" type="VP">
          <tokens>
            <token id="3" string="does" />
            <token id="4" string="n't" />
            <token id="5" string="matter" />
          </tokens>
        </chunking>
        <chunking id="2" string="Size" type="NP">
          <tokens>
            <token id="2" string="Size" />
          </tokens>
        </chunking>
        <chunking id="3" string="matter" type="VP">
          <tokens>
            <token id="5" string="matter" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">matter</governor>
          <dependent id="2">Size</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">matter</governor>
          <dependent id="3">does</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">matter</governor>
          <dependent id="4">n't</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">matter</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="21" has_coreference="true">
      <content>It&amp;apost;s how fast you run . . . it&amp;apost;s speed.&amp;quot;</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="how" lemma="how" stem="how" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="fast" lemma="fast" stem="fast" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="run" lemma="run" stem="run" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string=". . ." lemma="..." stem=". . ." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="speed" lemma="speed" stem="speed" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP It)) (VP (VBZ 's) (SBAR (WHADVP (WRB how) (RB fast)) (S (NP (PRP you)) (VP (VBP run)))))) (: ...) (S (NP (PRP it)) (VP (VBZ 's) (NP (NN speed)))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="'s how fast you run" type="VP">
          <tokens>
            <token id="2" string="'s" />
            <token id="3" string="how" />
            <token id="4" string="fast" />
            <token id="5" string="you" />
            <token id="6" string="run" />
          </tokens>
        </chunking>
        <chunking id="2" string="how fast you run" type="SBAR">
          <tokens>
            <token id="3" string="how" />
            <token id="4" string="fast" />
            <token id="5" string="you" />
            <token id="6" string="run" />
          </tokens>
        </chunking>
        <chunking id="3" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="4" string="how fast" type="WHADVP">
          <tokens>
            <token id="3" string="how" />
            <token id="4" string="fast" />
          </tokens>
        </chunking>
        <chunking id="5" string="it" type="NP">
          <tokens>
            <token id="8" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="run" type="VP">
          <tokens>
            <token id="6" string="run" />
          </tokens>
        </chunking>
        <chunking id="7" string="'s speed" type="VP">
          <tokens>
            <token id="9" string="'s" />
            <token id="10" string="speed" />
          </tokens>
        </chunking>
        <chunking id="8" string="you" type="NP">
          <tokens>
            <token id="5" string="you" />
          </tokens>
        </chunking>
        <chunking id="9" string="speed" type="NP">
          <tokens>
            <token id="10" string="speed" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">'s</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">fast</governor>
          <dependent id="3">how</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">run</governor>
          <dependent id="4">fast</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">run</governor>
          <dependent id="5">you</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">'s</governor>
          <dependent id="6">run</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">speed</governor>
          <dependent id="8">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="10">speed</governor>
          <dependent id="9">'s</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="2">'s</governor>
          <dependent id="10">speed</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="22" has_coreference="true">
      <content>; When he was introduced before the race, Johnson was given a thunderous standing ovation.</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="When" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="introduced" lemma="introduce" stem="introduc" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="before" lemma="before" stem="befor" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="race" lemma="race" stem="race" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="11" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="given" lemma="give" stem="given" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="thunderous" lemma="thunderous" stem="thunder" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="standing" lemma="standing" stem="stand" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="ovation" lemma="ovation" stem="ovat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ;) (SBAR (WHADVP (WRB When)) (S (NP (PRP he)) (VP (VBD was) (VP (VBN introduced) (PP (IN before) (NP (DT the) (NN race))))))) (, ,) (NP (NNP Johnson)) (VP (VBD was) (VP (VBN given) (NP (DT a) (JJ thunderous) (NN standing) (NN ovation)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="When" type="WHADVP">
          <tokens>
            <token id="2" string="When" />
          </tokens>
        </chunking>
        <chunking id="2" string="given a thunderous standing ovation" type="VP">
          <tokens>
            <token id="12" string="given" />
            <token id="13" string="a" />
            <token id="14" string="thunderous" />
            <token id="15" string="standing" />
            <token id="16" string="ovation" />
          </tokens>
        </chunking>
        <chunking id="3" string="When he was introduced before the race" type="SBAR">
          <tokens>
            <token id="2" string="When" />
            <token id="3" string="he" />
            <token id="4" string="was" />
            <token id="5" string="introduced" />
            <token id="6" string="before" />
            <token id="7" string="the" />
            <token id="8" string="race" />
          </tokens>
        </chunking>
        <chunking id="4" string="Johnson" type="NP">
          <tokens>
            <token id="10" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="5" string="introduced before the race" type="VP">
          <tokens>
            <token id="5" string="introduced" />
            <token id="6" string="before" />
            <token id="7" string="the" />
            <token id="8" string="race" />
          </tokens>
        </chunking>
        <chunking id="6" string="was introduced before the race" type="VP">
          <tokens>
            <token id="4" string="was" />
            <token id="5" string="introduced" />
            <token id="6" string="before" />
            <token id="7" string="the" />
            <token id="8" string="race" />
          </tokens>
        </chunking>
        <chunking id="7" string="he" type="NP">
          <tokens>
            <token id="3" string="he" />
          </tokens>
        </chunking>
        <chunking id="8" string="was given a thunderous standing ovation" type="VP">
          <tokens>
            <token id="11" string="was" />
            <token id="12" string="given" />
            <token id="13" string="a" />
            <token id="14" string="thunderous" />
            <token id="15" string="standing" />
            <token id="16" string="ovation" />
          </tokens>
        </chunking>
        <chunking id="9" string="a thunderous standing ovation" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="thunderous" />
            <token id="15" string="standing" />
            <token id="16" string="ovation" />
          </tokens>
        </chunking>
        <chunking id="10" string="the race" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="race" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="5">introduced</governor>
          <dependent id="2">When</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="5">introduced</governor>
          <dependent id="3">he</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="5">introduced</governor>
          <dependent id="4">was</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="12">given</governor>
          <dependent id="5">introduced</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">race</governor>
          <dependent id="6">before</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">race</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">introduced</governor>
          <dependent id="8">race</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="12">given</governor>
          <dependent id="10">Johnson</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="12">given</governor>
          <dependent id="11">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">given</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">ovation</governor>
          <dependent id="13">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">ovation</governor>
          <dependent id="14">thunderous</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">ovation</governor>
          <dependent id="15">standing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">given</governor>
          <dependent id="16">ovation</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Johnson" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="23" has_coreference="true">
      <content>When the race ended, the fans thought he had won and broke into loud cheering.</content>
      <tokens>
        <token id="1" string="When" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="race" lemma="race" stem="race" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="ended" lemma="end" stem="end" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="fans" lemma="fan" stem="fan" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="thought" lemma="think" stem="thought" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="won" lemma="win" stem="won" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="broke" lemma="break" stem="broke" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="loud" lemma="loud" stem="loud" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="cheering" lemma="cheer" stem="cheer" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (WHADVP (WRB When)) (S (NP (DT the) (NN race)) (VP (VBD ended)))) (, ,) (NP (DT the) (NNS fans)) (VP (VP (VBD thought) (SBAR (S (NP (PRP he)) (VP (VBD had) (VP (VBN won)))))) (CC and) (VP (VBD broke) (PP (IN into) (S (ADVP (JJ loud)) (VP (VBG cheering)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="thought he had won and broke into loud cheering" type="VP">
          <tokens>
            <token id="8" string="thought" />
            <token id="9" string="he" />
            <token id="10" string="had" />
            <token id="11" string="won" />
            <token id="12" string="and" />
            <token id="13" string="broke" />
            <token id="14" string="into" />
            <token id="15" string="loud" />
            <token id="16" string="cheering" />
          </tokens>
        </chunking>
        <chunking id="2" string="When the race ended" type="SBAR">
          <tokens>
            <token id="1" string="When" />
            <token id="2" string="the" />
            <token id="3" string="race" />
            <token id="4" string="ended" />
          </tokens>
        </chunking>
        <chunking id="3" string="he had won" type="SBAR">
          <tokens>
            <token id="9" string="he" />
            <token id="10" string="had" />
            <token id="11" string="won" />
          </tokens>
        </chunking>
        <chunking id="4" string="thought he had won" type="VP">
          <tokens>
            <token id="8" string="thought" />
            <token id="9" string="he" />
            <token id="10" string="had" />
            <token id="11" string="won" />
          </tokens>
        </chunking>
        <chunking id="5" string="cheering" type="VP">
          <tokens>
            <token id="16" string="cheering" />
          </tokens>
        </chunking>
        <chunking id="6" string="When" type="WHADVP">
          <tokens>
            <token id="1" string="When" />
          </tokens>
        </chunking>
        <chunking id="7" string="the fans" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="fans" />
          </tokens>
        </chunking>
        <chunking id="8" string="won" type="VP">
          <tokens>
            <token id="11" string="won" />
          </tokens>
        </chunking>
        <chunking id="9" string="ended" type="VP">
          <tokens>
            <token id="4" string="ended" />
          </tokens>
        </chunking>
        <chunking id="10" string="broke into loud cheering" type="VP">
          <tokens>
            <token id="13" string="broke" />
            <token id="14" string="into" />
            <token id="15" string="loud" />
            <token id="16" string="cheering" />
          </tokens>
        </chunking>
        <chunking id="11" string="he" type="NP">
          <tokens>
            <token id="9" string="he" />
          </tokens>
        </chunking>
        <chunking id="12" string="the race" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="race" />
          </tokens>
        </chunking>
        <chunking id="13" string="had won" type="VP">
          <tokens>
            <token id="10" string="had" />
            <token id="11" string="won" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="4">ended</governor>
          <dependent id="1">When</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">race</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">ended</governor>
          <dependent id="3">race</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="8">thought</governor>
          <dependent id="4">ended</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">fans</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">thought</governor>
          <dependent id="7">fans</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">thought</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">won</governor>
          <dependent id="9">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">won</governor>
          <dependent id="10">had</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="8">thought</governor>
          <dependent id="11">won</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">thought</governor>
          <dependent id="12">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">thought</governor>
          <dependent id="13">broke</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">cheering</governor>
          <dependent id="14">into</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">cheering</governor>
          <dependent id="15">loud</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="13">broke</governor>
          <dependent id="16">cheering</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="24" has_coreference="true">
      <content>Banners welcoming him back were draped around the arena.</content>
      <tokens>
        <token id="1" string="Banners" lemma="banner" stem="banner" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="welcoming" lemma="welcome" stem="welcom" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="back" lemma="back" stem="back" pos="RP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="draped" lemma="drape" stem="drape" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="around" lemma="around" stem="around" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="arena" lemma="arena" stem="arena" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNS Banners)) (VP (VBG welcoming) (NP (PRP him)) (PRT (RP back)))) (VP (VBD were) (VP (VBN draped) (PP (IN around) (NP (DT the) (NN arena))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="draped around the arena" type="VP">
          <tokens>
            <token id="6" string="draped" />
            <token id="7" string="around" />
            <token id="8" string="the" />
            <token id="9" string="arena" />
          </tokens>
        </chunking>
        <chunking id="2" string="Banners" type="NP">
          <tokens>
            <token id="1" string="Banners" />
          </tokens>
        </chunking>
        <chunking id="3" string="Banners welcoming him back" type="NP">
          <tokens>
            <token id="1" string="Banners" />
            <token id="2" string="welcoming" />
            <token id="3" string="him" />
            <token id="4" string="back" />
          </tokens>
        </chunking>
        <chunking id="4" string="welcoming him back" type="VP">
          <tokens>
            <token id="2" string="welcoming" />
            <token id="3" string="him" />
            <token id="4" string="back" />
          </tokens>
        </chunking>
        <chunking id="5" string="him" type="NP">
          <tokens>
            <token id="3" string="him" />
          </tokens>
        </chunking>
        <chunking id="6" string="the arena" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="arena" />
          </tokens>
        </chunking>
        <chunking id="7" string="were draped around the arena" type="VP">
          <tokens>
            <token id="5" string="were" />
            <token id="6" string="draped" />
            <token id="7" string="around" />
            <token id="8" string="the" />
            <token id="9" string="arena" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="6">draped</governor>
          <dependent id="1">Banners</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="1">Banners</governor>
          <dependent id="2">welcoming</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">welcoming</governor>
          <dependent id="3">him</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="2">welcoming</governor>
          <dependent id="4">back</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="6">draped</governor>
          <dependent id="5">were</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">draped</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">arena</governor>
          <dependent id="7">around</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">arena</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">draped</governor>
          <dependent id="9">arena</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="25" has_coreference="true">
      <content>One said, &amp;quot;Ben Knows Track and Field -- Just Do It, Ben.&amp;quot;</content>
      <tokens>
        <token id="1" string="One" lemma="one" stem="one" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Ben" lemma="Ben" stem="ben" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="6" string="Knows" lemma="Knows" stem="know" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="7" string="Track" lemma="Track" stem="track" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="8" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Field" lemma="Field" stem="field" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="Ben" lemma="Ben" stem="ben" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (CD One)) (VP (VBD said) (, ,) (`` ``) (S (NP (NP (NNP Ben) (NNP Knows) (NNP Track) (CC and) (NNP Field)) (: --) (VP (ADVP (RB Just)) (VBP Do) (NP (PRP It))) (, ,)) (NP (NNP Ben)))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="Ben Knows Track and Field -- Just Do It ," type="NP">
          <tokens>
            <token id="5" string="Ben" />
            <token id="6" string="Knows" />
            <token id="7" string="Track" />
            <token id="8" string="and" />
            <token id="9" string="Field" />
            <token id="10" string="--" />
            <token id="11" string="Just" />
            <token id="12" string="Do" />
            <token id="13" string="It" />
            <token id="14" string="," />
          </tokens>
        </chunking>
        <chunking id="2" string="One" type="NP">
          <tokens>
            <token id="1" string="One" />
          </tokens>
        </chunking>
        <chunking id="3" string="It" type="NP">
          <tokens>
            <token id="13" string="It" />
          </tokens>
        </chunking>
        <chunking id="4" string="Ben" type="NP">
          <tokens>
            <token id="15" string="Ben" />
          </tokens>
        </chunking>
        <chunking id="5" string="Ben Knows Track and Field" type="NP">
          <tokens>
            <token id="5" string="Ben" />
            <token id="6" string="Knows" />
            <token id="7" string="Track" />
            <token id="8" string="and" />
            <token id="9" string="Field" />
          </tokens>
        </chunking>
        <chunking id="6" string="Just Do It" type="VP">
          <tokens>
            <token id="11" string="Just" />
            <token id="12" string="Do" />
            <token id="13" string="It" />
          </tokens>
        </chunking>
        <chunking id="7" string="said , `` Ben Knows Track and Field -- Just Do It , Ben" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="," />
            <token id="4" string="&quot;" />
            <token id="5" string="Ben" />
            <token id="6" string="Knows" />
            <token id="7" string="Track" />
            <token id="8" string="and" />
            <token id="9" string="Field" />
            <token id="10" string="--" />
            <token id="11" string="Just" />
            <token id="12" string="Do" />
            <token id="13" string="It" />
            <token id="14" string="," />
            <token id="15" string="Ben" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">One</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Track</governor>
          <dependent id="5">Ben</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Track</governor>
          <dependent id="6">Knows</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">Ben</governor>
          <dependent id="7">Track</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">Track</governor>
          <dependent id="8">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">Track</governor>
          <dependent id="9">Field</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">Do</governor>
          <dependent id="11">Just</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="7">Track</governor>
          <dependent id="12">Do</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">Do</governor>
          <dependent id="13">It</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="2">said</governor>
          <dependent id="15">Ben</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="One" type="NUMBER" score="0.0">
          <tokens>
            <token id="1" string="One" />
          </tokens>
        </entity>
        <entity id="2" string="Ben Knows Track" type="MISC" score="0.0">
          <tokens>
            <token id="5" string="Ben" />
            <token id="6" string="Knows" />
            <token id="7" string="Track" />
          </tokens>
        </entity>
        <entity id="3" string="Ben" type="PERSON" score="0.0">
          <tokens>
            <token id="15" string="Ben" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="26" has_coreference="true">
      <content>Another said, &amp;quot;Go Ben Go!&amp;quot;</content>
      <tokens>
        <token id="1" string="Another" lemma="another" stem="another" pos="DT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Go" lemma="go" stem="go" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="Ben" lemma="Ben" stem="ben" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="Go" lemma="go" stem="go" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="!" lemma="!" stem="!" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT Another)) (VP (VBD said) (, ,) (`` ``) (S (VP (VB Go) (S (NP (NNP Ben)) (VP (VB Go)))))) (. !) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="Go Ben Go" type="VP">
          <tokens>
            <token id="5" string="Go" />
            <token id="6" string="Ben" />
            <token id="7" string="Go" />
          </tokens>
        </chunking>
        <chunking id="2" string="said , `` Go Ben Go" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="," />
            <token id="4" string="&quot;" />
            <token id="5" string="Go" />
            <token id="6" string="Ben" />
            <token id="7" string="Go" />
          </tokens>
        </chunking>
        <chunking id="3" string="Go" type="VP">
          <tokens>
            <token id="7" string="Go" />
          </tokens>
        </chunking>
        <chunking id="4" string="Ben" type="NP">
          <tokens>
            <token id="6" string="Ben" />
          </tokens>
        </chunking>
        <chunking id="5" string="Another" type="NP">
          <tokens>
            <token id="1" string="Another" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">Another</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="5">Go</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">Go</governor>
          <dependent id="6">Ben</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">Go</governor>
          <dependent id="7">Go</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="27" has_coreference="true">
      <content>and a third read, &amp;quot;Burn Rubber, Ben.&amp;quot;</content>
      <tokens>
        <token id="1" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="third" lemma="third" stem="third" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="4" string="read" lemma="read" stem="read" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Burn" lemma="burn" stem="burn" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="Rubber" lemma="Rubber" stem="rubber" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Ben" lemma="Ben" stem="ben" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (FRAG (CC and) (NP (NP (DT a) (JJ third) (NN read)) (, ,) (SBAR (`` ``) (S (VP (VB Burn) (NP (NP (NNP Rubber)) (, ,) (NP (NNP Ben))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="Rubber" type="NP">
          <tokens>
            <token id="8" string="Rubber" />
          </tokens>
        </chunking>
        <chunking id="2" string="a third read" type="NP">
          <tokens>
            <token id="2" string="a" />
            <token id="3" string="third" />
            <token id="4" string="read" />
          </tokens>
        </chunking>
        <chunking id="3" string="Rubber , Ben" type="NP">
          <tokens>
            <token id="8" string="Rubber" />
            <token id="9" string="," />
            <token id="10" string="Ben" />
          </tokens>
        </chunking>
        <chunking id="4" string="Ben" type="NP">
          <tokens>
            <token id="10" string="Ben" />
          </tokens>
        </chunking>
        <chunking id="5" string="a third read , `` Burn Rubber , Ben" type="NP">
          <tokens>
            <token id="2" string="a" />
            <token id="3" string="third" />
            <token id="4" string="read" />
            <token id="5" string="," />
            <token id="6" string="&quot;" />
            <token id="7" string="Burn" />
            <token id="8" string="Rubber" />
            <token id="9" string="," />
            <token id="10" string="Ben" />
          </tokens>
        </chunking>
        <chunking id="6" string="`` Burn Rubber , Ben" type="SBAR">
          <tokens>
            <token id="6" string="&quot;" />
            <token id="7" string="Burn" />
            <token id="8" string="Rubber" />
            <token id="9" string="," />
            <token id="10" string="Ben" />
          </tokens>
        </chunking>
        <chunking id="7" string="Burn Rubber , Ben" type="VP">
          <tokens>
            <token id="7" string="Burn" />
            <token id="8" string="Rubber" />
            <token id="9" string="," />
            <token id="10" string="Ben" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="4">read</governor>
          <dependent id="1">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">read</governor>
          <dependent id="2">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">read</governor>
          <dependent id="3">third</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">read</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="4">read</governor>
          <dependent id="7">Burn</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">Burn</governor>
          <dependent id="8">Rubber</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="8">Rubber</governor>
          <dependent id="10">Ben</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="third" type="ORDINAL" score="0.0">
          <tokens>
            <token id="3" string="third" />
          </tokens>
        </entity>
        <entity id="2" string="Ben" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Ben" />
          </tokens>
        </entity>
      </entities>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="2" type="PROPER">
      <referenced ids_tokens="13-14" string="Ben Johnson" id_sentence="1" />
      <mentions>
        <mention ids_tokens="8" string="Johnson" id_sentence="4" />
        <mention ids_tokens="22" string="him" id_sentence="4" />
        <mention ids_tokens="1" string="He" id_sentence="5" />
        <mention ids_tokens="20" string="him" id_sentence="5" />
        <mention ids_tokens="17-18" string="Johnson's" id_sentence="6" />
        <mention ids_tokens="1" string="Johnson" id_sentence="7" />
        <mention ids_tokens="10" string="Johnson" id_sentence="8" />
        <mention ids_tokens="1" string="Johnson" id_sentence="10" />
        <mention ids_tokens="3" string="his" id_sentence="10" />
        <mention ids_tokens="2" string="I" id_sentence="11" />
        <mention ids_tokens="10" string="Johnson" id_sentence="11" />
        <mention ids_tokens="9" string="me" id_sentence="12" />
        <mention ids_tokens="13" string="my" id_sentence="12" />
        <mention ids_tokens="35" string="me" id_sentence="12" />
        <mention ids_tokens="4-5" string="Johnson's" id_sentence="13" />
        <mention ids_tokens="1" string="His" id_sentence="14" />
        <mention ids_tokens="8" string="he" id_sentence="14" />
        <mention ids_tokens="18" string="Johnson" id_sentence="15" />
        <mention ids_tokens="2-3" string="Johnson's" id_sentence="18" />
        <mention ids_tokens="10" string="Johnson" id_sentence="19" />
        <mention ids_tokens="10" string="Johnson" id_sentence="22" />
        <mention ids_tokens="15" string="Ben" id_sentence="25" />
        <mention ids_tokens="6" string="Ben" id_sentence="26" />
        <mention ids_tokens="10" string="Ben" id_sentence="27" />
      </mentions>
    </coreference>
    <coreference id="4" type="NOMINAL">
      <referenced ids_tokens="2-3-4-5-6-7-8-9-10-11" string="his first race after a two-year suspension for drug use" id_sentence="1" />
      <mentions>
        <mention ids_tokens="11" string="it" id_sentence="12" />
        <mention ids_tokens="13-15" string="my first race" id_sentence="12" />
        <mention ids_tokens="25-26" string="the race" id_sentence="12" />
        <mention ids_tokens="13-14" string="the race" id_sentence="19" />
        <mention ids_tokens="1" string="It" id_sentence="21" />
        <mention ids_tokens="8" string="it" id_sentence="21" />
        <mention ids_tokens="7-8" string="the race" id_sentence="22" />
        <mention ids_tokens="2-3" string="the race" id_sentence="23" />
      </mentions>
    </coreference>
    <coreference id="6" type="NOMINAL">
      <referenced ids_tokens="6-7-8-9-10-11" string="a two-year suspension for drug use" id_sentence="1" />
      <mentions>
        <mention ids_tokens="5-7" string="the two-year suspension" id_sentence="6" />
        <mention ids_tokens="31-33" string="his two-year suspension" id_sentence="18" />
      </mentions>
    </coreference>
    <coreference id="7" type="PROPER">
      <referenced ids_tokens="33-34-35" string="the 1988 Olympics" id_sentence="1" />
      <mentions>
        <mention ids_tokens="16-17" string="the Olympics" id_sentence="16" />
      </mentions>
    </coreference>
    <coreference id="9" type="PROPER">
      <referenced ids_tokens="77-78-79-80" string="the Hamilton Spectator Games" id_sentence="1" />
      <mentions>
        <mention ids_tokens="30-31" string="the Games" id_sentence="5" />
      </mentions>
    </coreference>
    <coreference id="10" type="PROPER">
      <referenced ids_tokens="13-14" string="Daron Council" id_sentence="2" />
      <mentions>
        <mention ids_tokens="17" string="Council" id_sentence="7" />
        <mention ids_tokens="2" string="I" id_sentence="8" />
      </mentions>
    </coreference>
    <coreference id="11" type="NOMINAL">
      <referenced ids_tokens="1-2-3-4-5" string="His time of 5.77 seconds" id_sentence="2" />
      <mentions>
        <mention ids_tokens="1-2" string="His time" id_sentence="14" />
      </mentions>
    </coreference>
    <coreference id="12" type="NOMINAL">
      <referenced ids_tokens="12-13-14" string="nearly 500 journalists" id_sentence="3" />
      <mentions>
        <mention ids_tokens="1" string="They" id_sentence="4" />
      </mentions>
    </coreference>
    <coreference id="13" type="NOMINAL">
      <referenced ids_tokens="10-11-12-13-14-15-16" string="a positive test at the 1988 Olympics" id_sentence="5" />
      <mentions>
        <mention ids_tokens="1" string="It" id_sentence="6" />
      </mentions>
    </coreference>
    <coreference id="14" type="NOMINAL">
      <referenced ids_tokens="5-6-7-8" string="an uncharacteristically slow start" id_sentence="7" />
      <mentions>
        <mention ids_tokens="4-5" string="the start" id_sentence="9" />
      </mentions>
    </coreference>
    <coreference id="15" type="NOMINAL">
      <referenced ids_tokens="3-4-5" string="his second-place finish" id_sentence="10" />
      <mentions>
        <mention ids_tokens="4" string="it" id_sentence="11" />
        <mention ids_tokens="6-7" string="a success" id_sentence="11" />
      </mentions>
    </coreference>
    <coreference id="17" type="NOMINAL">
      <referenced ids_tokens="21-22" string="50 meters" id_sentence="14" />
      <mentions>
        <mention ids_tokens="2" string="I" id_sentence="15" />
        <mention ids_tokens="10" string="I" id_sentence="15" />
        <mention ids_tokens="21" string="he" id_sentence="15" />
        <mention ids_tokens="30" string="he" id_sentence="15" />
      </mentions>
    </coreference>
    <coreference id="18" type="PROPER">
      <referenced ids_tokens="3-4-5-6-7-8-9-10-11-12-13-14-15-16-17" string="a different-looking Johnson than the one who had bolted to apparent victory in the Olympics" id_sentence="16" />
      <mentions>
        <mention ids_tokens="1-2" string="This Johnson" id_sentence="17" />
        <mention ids_tokens="14" string="his" id_sentence="17" />
      </mentions>
    </coreference>
    <coreference id="20" type="NOMINAL">
      <referenced ids_tokens="38-39-40" string="a performance-enhancing steroid" id_sentence="18" />
      <mentions>
        <mention ids_tokens="5" string="I" id_sentence="19" />
      </mentions>
    </coreference>
    <coreference id="21" type="PRONOMINAL">
      <referenced ids_tokens="5" string="you" id_sentence="21" />
      <mentions>
        <mention ids_tokens="3" string="he" id_sentence="22" />
        <mention ids_tokens="9" string="he" id_sentence="23" />
        <mention ids_tokens="3" string="him" id_sentence="24" />
      </mentions>
    </coreference>
  </coreferences>
</document>
